{"kernel_name": "bfs", "kernel_api": "cuda", "code": {"bfs.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n#define MAX_THREADS_PER_BLOCK 256\n\n#include \"util.h\"\n\n\n\nstruct Node\n{\n  int starting;\n  int no_of_edges;\n};\n\n__global__ void\nKernel(const Node* __restrict__ d_graph_nodes, \n       const int* __restrict__ d_graph_edges,\n       char* __restrict__ d_graph_mask,\n       char* __restrict__ d_updatind_graph_mask,\n       const char *__restrict__ d_graph_visited,\n       int* __restrict__ d_cost,\n       const int no_of_nodes) \n{\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if( tid<no_of_nodes && d_graph_mask[tid])\n  {\n    d_graph_mask[tid]=0;\n    const int num_edges = d_graph_nodes[tid].no_of_edges;\n    const int starting = d_graph_nodes[tid].starting;\n\n    for(int i=starting; i<(num_edges + starting); i++)\n    {\n      int id = d_graph_edges[i];\n      if(!d_graph_visited[id])\n      {\n        d_cost[id]=d_cost[tid]+1;\n        d_updatind_graph_mask[id]=1;\n      }\n    }\n  }\n}\n\n__global__ void\nKernel2(char* __restrict__ d_graph_mask,\n        char* __restrict__ d_updatind_graph_mask,\n        char* __restrict__ d_graph_visited,\n        char* __restrict__ d_over,\n        const int no_of_nodes)\n{\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if( tid<no_of_nodes && d_updatind_graph_mask[tid])\n  {\n    d_graph_mask[tid]=1;\n    d_graph_visited[tid]=1;\n    *d_over=1;\n    d_updatind_graph_mask[tid]=0;\n  }\n}\n\nvoid run_bfs_cpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size,\n    int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask,\n    char *h_graph_visited, int *h_cost_ref)\n{\n  char stop;\n  do{\n    \n\n    stop=0;\n    for(int tid = 0; tid < no_of_nodes; tid++ )\n    {\n      if (h_graph_mask[tid] == 1){ \n        h_graph_mask[tid]=0;\n        for(int i=h_graph_nodes[tid].starting; \n            i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++){\n          int id = h_graph_edges[i];  \n\n          if(!h_graph_visited[id]){   \n\n            h_cost_ref[id]=h_cost_ref[tid]+1;\n            h_updating_graph_mask[id]=1;\n          }\n        }\n      }    \n    }\n\n    for(int tid=0; tid< no_of_nodes ; tid++ )\n    {\n      if (h_updating_graph_mask[tid] == 1){\n        h_graph_mask[tid]=1;\n        h_graph_visited[tid]=1;\n        stop=1;\n        h_updating_graph_mask[tid]=0;\n      }\n    }\n  }\n  while(stop);\n}\n\nvoid Usage(int argc, char**argv){\n  fprintf(stderr,\"Usage: %s <input_file>\\n\", argv[0]);\n}\n\n\n\nvoid run_bfs_gpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size,\n    int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask,\n    char *h_graph_visited, int *h_cost)\n{\n\n  Node* d_graph_nodes;\n  cudaMalloc((void**) &d_graph_nodes, sizeof(Node)*no_of_nodes) ;\n  cudaMemcpy(d_graph_nodes, h_graph_nodes, sizeof(Node)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n  int* d_graph_edges;\n  cudaMalloc((void**) &d_graph_edges, sizeof(int)*edge_list_size) ;\n  cudaMemcpy( d_graph_edges, h_graph_edges, sizeof(int)*edge_list_size, cudaMemcpyHostToDevice) ;\n\n  char* d_graph_mask;\n  cudaMalloc((void**) &d_graph_mask, sizeof(char)*no_of_nodes) ;\n  cudaMemcpy(d_graph_mask, h_graph_mask, sizeof(char)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n  char* d_updating_graph_mask;\n  cudaMalloc((void**) &d_updating_graph_mask, sizeof(char)*no_of_nodes) ;\n  cudaMemcpy(d_updating_graph_mask, h_updating_graph_mask, sizeof(char)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n  char* d_graph_visited;\n  cudaMalloc((void**) &d_graph_visited, sizeof(char)*no_of_nodes) ;\n  cudaMemcpy(d_graph_visited, h_graph_visited, sizeof(char)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n  int* d_cost;\n  cudaMalloc((void**) &d_cost, sizeof(int)*no_of_nodes);\n  cudaMemcpy(d_cost, h_cost, sizeof(int)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n  char h_over;\n  char *d_over;\n  cudaMalloc((void**) &d_over, sizeof(char));\n\n  \n\n  dim3 grid((no_of_nodes + MAX_THREADS_PER_BLOCK - 1) / MAX_THREADS_PER_BLOCK);\n  dim3 threads(MAX_THREADS_PER_BLOCK);\n\n  long time = 0;\n  do {\n    h_over = 0;\n    cudaMemcpy(d_over, &h_over, sizeof(char), cudaMemcpyHostToDevice) ;\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    Kernel<<< grid, threads >>>(d_graph_nodes, d_graph_edges, d_graph_mask, d_updating_graph_mask, \n                                d_graph_visited, d_cost, no_of_nodes);\n    Kernel2<<< grid, threads >>>(d_graph_mask, d_updating_graph_mask, d_graph_visited, d_over, no_of_nodes);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    cudaMemcpy(&h_over, d_over, sizeof(char), cudaMemcpyDeviceToHost) ;\n  } while(h_over);\n\n  printf(\"Total kernel execution time : %f (us)\\n\", time * 1e-3f);\n\n  \n\n  cudaMemcpy(h_cost, d_cost, sizeof(int)*no_of_nodes, cudaMemcpyDeviceToHost) ;\n\n  cudaFree(d_graph_nodes);\n  cudaFree(d_graph_edges);\n  cudaFree(d_graph_mask);\n  cudaFree(d_updating_graph_mask);\n  cudaFree(d_graph_visited);\n  cudaFree(d_cost);\n  cudaFree(d_over);\n}\n\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char * argv[])\n{\n  int no_of_nodes;\n  int edge_list_size;\n  FILE *fp;\n  Node* h_graph_nodes;\n  char *h_graph_mask, *h_updating_graph_mask, *h_graph_visited;\n  char *input_f;\n  if(argc!=2){\n    Usage(argc, argv);\n    exit(0);\n  }\n\n  input_f = argv[1];\n  printf(\"Reading File\\n\");\n  \n\n  fp = fopen(input_f,\"r\");\n  if(!fp){\n    printf(\"Error Reading graph file %s\\n\", input_f);\n    return 1;\n  }\n\n  int source = 0;\n\n  fscanf(fp,\"%d\",&no_of_nodes);\n\n  \n\n  h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n  h_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_updating_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_graph_visited = (char*) malloc(sizeof(char)*no_of_nodes);\n\n  int start, edgeno;   \n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    fscanf(fp,\"%d %d\",&start,&edgeno);\n    h_graph_nodes[i].starting = start;\n    h_graph_nodes[i].no_of_edges = edgeno;\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n  \n\n  fscanf(fp,\"%d\",&source);\n  source=0;\n  \n\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  fscanf(fp,\"%d\",&edge_list_size);\n  int id,cost;\n  int* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n  for(int i=0; i < edge_list_size ; i++){\n    fscanf(fp,\"%d\",&id);\n    fscanf(fp,\"%d\",&cost);\n    h_graph_edges[i] = id;\n  }\n\n  if(fp) fclose(fp);    \n  \n\n  int *h_cost = (int*) malloc(sizeof(int)*no_of_nodes);\n  int *h_cost_ref = (int*)malloc(sizeof(int)*no_of_nodes);\n  for(int i=0;i<no_of_nodes;i++){\n    h_cost[i]=-1;\n    h_cost_ref[i] = -1;\n  }\n  h_cost[source]=0;\n  h_cost_ref[source]=0;    \n\n  printf(\"run bfs (#nodes = %d) on device\\n\", no_of_nodes);\n  run_bfs_gpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost);  \n\n  printf(\"run bfs (#nodes = %d) on host (cpu) \\n\", no_of_nodes);\n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n  \n\n  source=0;\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  run_bfs_cpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost_ref);\n\n  \n\n  compare_results<int>(h_cost_ref, h_cost, no_of_nodes);\n\n  free(h_graph_nodes);\n  free(h_graph_mask);\n  free(h_updating_graph_mask);\n  free(h_graph_visited);\n  free(h_cost);\n  free(h_cost_ref);\n\n  return 0;\n}\n"}}
{"kernel_name": "bfs", "kernel_api": "hip", "code": {"bfs.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define MAX_THREADS_PER_BLOCK 256\n\n#include \"util.h\"\n\n\n\nstruct Node\n{\n  int starting;\n  int no_of_edges;\n};\n\n__global__ void\nKernel(const Node* __restrict__ d_graph_nodes, \n       const int* __restrict__ d_graph_edges,\n       char* __restrict__ d_graph_mask,\n       char* __restrict__ d_updatind_graph_mask,\n       const char *__restrict__ d_graph_visited,\n       int* __restrict__ d_cost,\n       const int no_of_nodes) \n{\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if( tid<no_of_nodes && d_graph_mask[tid])\n  {\n    d_graph_mask[tid]=0;\n    const int num_edges = d_graph_nodes[tid].no_of_edges;\n    const int starting = d_graph_nodes[tid].starting;\n\n    for(int i=starting; i<(num_edges + starting); i++)\n    {\n      int id = d_graph_edges[i];\n      if(!d_graph_visited[id])\n      {\n        d_cost[id]=d_cost[tid]+1;\n        d_updatind_graph_mask[id]=1;\n      }\n    }\n  }\n}\n\n__global__ void\nKernel2(char* __restrict__ d_graph_mask,\n        char* __restrict__ d_updatind_graph_mask,\n        char* __restrict__ d_graph_visited,\n        char* __restrict__ d_over,\n        const int no_of_nodes)\n{\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if( tid<no_of_nodes && d_updatind_graph_mask[tid])\n  {\n    d_graph_mask[tid]=1;\n    d_graph_visited[tid]=1;\n    *d_over=1;\n    d_updatind_graph_mask[tid]=0;\n  }\n}\n\nvoid run_bfs_cpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size,\n    int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask,\n    char *h_graph_visited, int *h_cost_ref)\n{\n  char stop;\n  do{\n    \n\n    stop=0;\n    for(int tid = 0; tid < no_of_nodes; tid++ )\n    {\n      if (h_graph_mask[tid] == 1){ \n        h_graph_mask[tid]=0;\n        for(int i=h_graph_nodes[tid].starting; \n            i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++){\n          int id = h_graph_edges[i];  \n\n          if(!h_graph_visited[id]){   \n\n            h_cost_ref[id]=h_cost_ref[tid]+1;\n            h_updating_graph_mask[id]=1;\n          }\n        }\n      }    \n    }\n\n    for(int tid=0; tid< no_of_nodes ; tid++ )\n    {\n      if (h_updating_graph_mask[tid] == 1){\n        h_graph_mask[tid]=1;\n        h_graph_visited[tid]=1;\n        stop=1;\n        h_updating_graph_mask[tid]=0;\n      }\n    }\n  }\n  while(stop);\n}\n\nvoid Usage(int argc, char**argv){\n  fprintf(stderr,\"Usage: %s <input_file>\\n\", argv[0]);\n}\n\n\n\nvoid run_bfs_gpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size,\n    int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask,\n    char *h_graph_visited, int *h_cost)\n{\n\n  Node* d_graph_nodes;\n  hipMalloc((void**) &d_graph_nodes, sizeof(Node)*no_of_nodes) ;\n  hipMemcpy(d_graph_nodes, h_graph_nodes, sizeof(Node)*no_of_nodes, hipMemcpyHostToDevice) ;\n\n  int* d_graph_edges;\n  hipMalloc((void**) &d_graph_edges, sizeof(int)*edge_list_size) ;\n  hipMemcpy( d_graph_edges, h_graph_edges, sizeof(int)*edge_list_size, hipMemcpyHostToDevice) ;\n\n  char* d_graph_mask;\n  hipMalloc((void**) &d_graph_mask, sizeof(char)*no_of_nodes) ;\n  hipMemcpy(d_graph_mask, h_graph_mask, sizeof(char)*no_of_nodes, hipMemcpyHostToDevice) ;\n\n  char* d_updating_graph_mask;\n  hipMalloc((void**) &d_updating_graph_mask, sizeof(char)*no_of_nodes) ;\n  hipMemcpy(d_updating_graph_mask, h_updating_graph_mask, sizeof(char)*no_of_nodes, hipMemcpyHostToDevice) ;\n\n  char* d_graph_visited;\n  hipMalloc((void**) &d_graph_visited, sizeof(char)*no_of_nodes) ;\n  hipMemcpy(d_graph_visited, h_graph_visited, sizeof(char)*no_of_nodes, hipMemcpyHostToDevice) ;\n\n  int* d_cost;\n  hipMalloc((void**) &d_cost, sizeof(int)*no_of_nodes);\n  hipMemcpy(d_cost, h_cost, sizeof(int)*no_of_nodes, hipMemcpyHostToDevice) ;\n\n  char h_over;\n  char *d_over;\n  hipMalloc((void**) &d_over, sizeof(char));\n\n  \n\n  dim3 grid((no_of_nodes + MAX_THREADS_PER_BLOCK - 1) / MAX_THREADS_PER_BLOCK);\n  dim3 threads(MAX_THREADS_PER_BLOCK);\n\n  long time = 0;\n  do {\n    h_over = 0;\n    hipMemcpy(d_over, &h_over, sizeof(char), hipMemcpyHostToDevice) ;\n\n    auto start = std::chrono::steady_clock::now();\n\n    hipLaunchKernelGGL(Kernel, grid, threads , 0, 0, d_graph_nodes, d_graph_edges, d_graph_mask, d_updating_graph_mask, \n                                d_graph_visited, d_cost, no_of_nodes);\n    hipLaunchKernelGGL(Kernel2, grid, threads , 0, 0, d_graph_mask, d_updating_graph_mask, d_graph_visited, d_over, no_of_nodes);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    hipMemcpy(&h_over, d_over, sizeof(char), hipMemcpyDeviceToHost) ;\n  } while(h_over);\n\n  printf(\"Total kernel execution time : %f (us)\\n\", time * 1e-3f);\n\n  \n\n  hipMemcpy(h_cost, d_cost, sizeof(int)*no_of_nodes, hipMemcpyDeviceToHost) ;\n\n  hipFree(d_graph_nodes);\n  hipFree(d_graph_edges);\n  hipFree(d_graph_mask);\n  hipFree(d_updating_graph_mask);\n  hipFree(d_graph_visited);\n  hipFree(d_cost);\n  hipFree(d_over);\n}\n\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char * argv[])\n{\n  int no_of_nodes;\n  int edge_list_size;\n  FILE *fp;\n  Node* h_graph_nodes;\n  char *h_graph_mask, *h_updating_graph_mask, *h_graph_visited;\n  char *input_f;\n  if(argc!=2){\n    Usage(argc, argv);\n    exit(0);\n  }\n\n  input_f = argv[1];\n  printf(\"Reading File\\n\");\n  \n\n  fp = fopen(input_f,\"r\");\n  if(!fp){\n    printf(\"Error Reading graph file %s\\n\", input_f);\n    return 1;\n  }\n\n  int source = 0;\n\n  fscanf(fp,\"%d\",&no_of_nodes);\n\n  \n\n  h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n  h_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_updating_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_graph_visited = (char*) malloc(sizeof(char)*no_of_nodes);\n\n  int start, edgeno;   \n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    fscanf(fp,\"%d %d\",&start,&edgeno);\n    h_graph_nodes[i].starting = start;\n    h_graph_nodes[i].no_of_edges = edgeno;\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n  \n\n  fscanf(fp,\"%d\",&source);\n  source=0;\n  \n\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  fscanf(fp,\"%d\",&edge_list_size);\n  int id,cost;\n  int* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n  for(int i=0; i < edge_list_size ; i++){\n    fscanf(fp,\"%d\",&id);\n    fscanf(fp,\"%d\",&cost);\n    h_graph_edges[i] = id;\n  }\n\n  if(fp) fclose(fp);    \n  \n\n  int *h_cost = (int*) malloc(sizeof(int)*no_of_nodes);\n  int *h_cost_ref = (int*)malloc(sizeof(int)*no_of_nodes);\n  for(int i=0;i<no_of_nodes;i++){\n    h_cost[i]=-1;\n    h_cost_ref[i] = -1;\n  }\n  h_cost[source]=0;\n  h_cost_ref[source]=0;    \n\n  printf(\"run bfs (#nodes = %d) on device\\n\", no_of_nodes);\n  run_bfs_gpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost);  \n\n  printf(\"run bfs (#nodes = %d) on host (cpu) \\n\", no_of_nodes);\n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n  \n\n  source=0;\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  run_bfs_cpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost_ref);\n\n  \n\n  compare_results<int>(h_cost_ref, h_cost, no_of_nodes);\n\n  free(h_graph_nodes);\n  free(h_graph_mask);\n  free(h_updating_graph_mask);\n  free(h_graph_visited);\n  free(h_cost);\n  free(h_cost_ref);\n\n  return 0;\n}\n"}}
{"kernel_name": "bfs", "kernel_api": "omp", "code": {"bfs.cpp": "#include <cstdlib>\n#include <iostream>\n#include <string>\n#include <cstring>\n#include <cstdio>\n#include <chrono>\n#include <omp.h>\n\n#include \"util.h\"\n\n#define MAX_THREADS_PER_BLOCK 256\n\n\n\nstruct Node\n{\n  int starting;\n  int no_of_edges;\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\nvoid run_bfs_cpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size, \\\n    int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask, \\\n    char *h_graph_visited, int *h_cost_ref){\n  char stop;\n  do{\n    \n\n    stop=0;\n    for(int tid = 0; tid < no_of_nodes; tid++ )\n    {\n      if (h_graph_mask[tid] == 1){ \n        h_graph_mask[tid]=0;\n        for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++){\n          int id = h_graph_edges[i];  \n\n          if(!h_graph_visited[id]){  \n\n            h_cost_ref[id]=h_cost_ref[tid]+1;\n            h_updating_graph_mask[id]=1;\n          }\n        }\n      }    \n    }\n\n    for(int tid=0; tid< no_of_nodes ; tid++ )\n    {\n      if (h_updating_graph_mask[tid] == 1){\n        h_graph_mask[tid]=1;\n        h_graph_visited[tid]=1;\n        stop=1;\n        h_updating_graph_mask[tid]=0;\n      }\n    }\n  }\n  while(stop);\n}\n\n\n\n\n\n\nvoid run_bfs_gpu(int no_of_nodes, Node *d_graph_nodes, int edge_list_size, \\\n    int *d_graph_edges, char *d_graph_mask, char *d_updating_graph_mask, \\\n    char *d_graph_visited, int *d_cost) throw(std::string)\n{\n  char d_over[1];\n\n#pragma omp target data map(to: d_graph_nodes[0:no_of_nodes], \\\n                                d_graph_edges[0:edge_list_size], \\\n                                d_graph_visited[0:no_of_nodes], \\\n                                d_graph_mask[0:no_of_nodes], \\\n                                d_updating_graph_mask[0:no_of_nodes]) \\\n                        map(alloc: d_over[0:1])\\\n                        map(tofrom: d_cost[0:no_of_nodes])\n  {\n    long time = 0;\n    do {\n      d_over[0] = 0;\n      #pragma omp target update to (d_over[0:1])\n\n      auto start = std::chrono::steady_clock::now();\n\n      #pragma omp target teams distribute parallel for thread_limit(MAX_THREADS_PER_BLOCK)\n      for (int tid = 0; tid < no_of_nodes; tid++) {\n        if(d_graph_mask[tid]){\n          d_graph_mask[tid]=0;\n          const int num_edges = d_graph_nodes[tid].no_of_edges;\n          const int starting = d_graph_nodes[tid].starting;\n\n          for(int i=starting; i<(num_edges + starting); i++) {\n            int id = d_graph_edges[i];\n            if(!d_graph_visited[id]){\n              d_cost[id]=d_cost[tid]+1;\n              d_updating_graph_mask[id]=1;\n            }\n          }\n        }  \n      }\n\n      #pragma omp target teams distribute parallel for thread_limit(MAX_THREADS_PER_BLOCK) \n      for (int tid = 0; tid < no_of_nodes; tid++) {\n        if(d_updating_graph_mask[tid]){\n          d_graph_mask[tid]=1;\n          d_graph_visited[tid]=1;\n          d_over[0]=1;\n          d_updating_graph_mask[tid]=0;\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n      #pragma omp target update from (d_over[0:1])\n\n    } while (d_over[0]);\n\n    printf(\"Total kernel execution time : %f (us)\\n\", time * 1e-3f);\n  }\n}\n\nvoid Usage(int argc, char**argv){\n\n  fprintf(stderr,\"Usage: %s <input_file>\\n\", argv[0]);\n\n}\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char * argv[])\n{\n  int no_of_nodes;\n  int edge_list_size;\n  FILE *fp;\n  Node* h_graph_nodes;\n  char *h_graph_mask, *h_updating_graph_mask, *h_graph_visited;\n  char *input_f;\n  if(argc!=2){\n    Usage(argc, argv);\n    exit(0);\n  }\n\n  input_f = argv[1];\n  printf(\"Reading File\\n\");\n  \n\n  fp = fopen(input_f,\"r\");\n  if(!fp){\n    printf(\"Error Reading graph file %s\\n\", input_f);\n    return 1;\n  }\n\n  int source = 0;\n\n  fscanf(fp,\"%d\",&no_of_nodes);\n\n  \n\n  h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n  h_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_updating_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_graph_visited = (char*) malloc(sizeof(char)*no_of_nodes);\n\n  int start, edgeno;   \n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    fscanf(fp,\"%d %d\",&start,&edgeno);\n    h_graph_nodes[i].starting = start;\n    h_graph_nodes[i].no_of_edges = edgeno;\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n  \n\n  fscanf(fp,\"%d\",&source);\n  source=0;\n  \n\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  fscanf(fp,\"%d\",&edge_list_size);\n  int id,cost;\n  int* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n  for(int i=0; i < edge_list_size ; i++){\n    fscanf(fp,\"%d\",&id);\n    fscanf(fp,\"%d\",&cost);\n    h_graph_edges[i] = id;\n  }\n\n  if(fp) fclose(fp);    \n  \n\n  int  *h_cost = (int*) malloc(sizeof(int)*no_of_nodes);\n  int *h_cost_ref = (int*)malloc(sizeof(int)*no_of_nodes);\n  for(int i=0;i<no_of_nodes;i++){\n    h_cost[i]=-1;\n    h_cost_ref[i] = -1;\n  }\n  h_cost[source]=0;\n  h_cost_ref[source]=0;    \n\n  printf(\"run bfs (#nodes = %d) on device\\n\", no_of_nodes);\n  run_bfs_gpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost);  \n\n  printf(\"run bfs (#nodes = %d) on host (cpu) \\n\", no_of_nodes);\n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n\n  \n\n  source=0;\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  run_bfs_cpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost_ref);\n\n  \n\n  compare_results<int>(h_cost_ref, h_cost, no_of_nodes);\n\n  free(h_graph_nodes);\n  free(h_graph_mask);\n  free(h_updating_graph_mask);\n  free(h_graph_visited);\n  free(h_cost);\n  free(h_cost_ref);\n\n  return 0;\n}\n"}}
{"kernel_name": "bfs", "kernel_api": "serial", "code": {"bfs.cpp": "#include <cstdlib>\n#include <iostream>\n#include <string>\n#include <cstring>\n#include <cstdio>\n#include <chrono>\n\n#include \"util.h\"\n\n#define MAX_THREADS_PER_BLOCK 256\n\n\n\nstruct Node\n{\n  int starting;\n  int no_of_edges;\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\nvoid run_bfs_cpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size, \\\n    int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask, \\\n    char *h_graph_visited, int *h_cost_ref){\n  char stop;\n  do{\n    \n\n    stop=0;\n    for(int tid = 0; tid < no_of_nodes; tid++ )\n    {\n      if (h_graph_mask[tid] == 1){ \n        h_graph_mask[tid]=0;\n        for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++){\n          int id = h_graph_edges[i];  \n\n          if(!h_graph_visited[id]){  \n\n            h_cost_ref[id]=h_cost_ref[tid]+1;\n            h_updating_graph_mask[id]=1;\n          }\n        }\n      }    \n    }\n\n    for(int tid=0; tid< no_of_nodes ; tid++ )\n    {\n      if (h_updating_graph_mask[tid] == 1){\n        h_graph_mask[tid]=1;\n        h_graph_visited[tid]=1;\n        stop=1;\n        h_updating_graph_mask[tid]=0;\n      }\n    }\n  }\n  while(stop);\n}\n\n\n\n\n\n\nvoid run_bfs_gpu(int no_of_nodes, Node *d_graph_nodes, int edge_list_size, \\\n    int *d_graph_edges, char *d_graph_mask, char *d_updating_graph_mask, \\\n    char *d_graph_visited, int *d_cost) throw(std::string)\n{\n  char d_over[1];\n\n  {\n    long time = 0;\n    do {\n      d_over[0] = 0;\n      \n      auto start = std::chrono::steady_clock::now();\n\n            for (int tid = 0; tid < no_of_nodes; tid++) {\n        if(d_graph_mask[tid]){\n          d_graph_mask[tid]=0;\n          const int num_edges = d_graph_nodes[tid].no_of_edges;\n          const int starting = d_graph_nodes[tid].starting;\n\n          for(int i=starting; i<(num_edges + starting); i++) {\n            int id = d_graph_edges[i];\n            if(!d_graph_visited[id]){\n              d_cost[id]=d_cost[tid]+1;\n              d_updating_graph_mask[id]=1;\n            }\n          }\n        }  \n      }\n\n            for (int tid = 0; tid < no_of_nodes; tid++) {\n        if(d_updating_graph_mask[tid]){\n          d_graph_mask[tid]=1;\n          d_graph_visited[tid]=1;\n          d_over[0]=1;\n          d_updating_graph_mask[tid]=0;\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n      \n    } while (d_over[0]);\n\n    printf(\"Total kernel execution time : %f (us)\\n\", time * 1e-3f);\n  }\n}\n\nvoid Usage(int argc, char**argv){\n\n  fprintf(stderr,\"Usage: %s <input_file>\\n\", argv[0]);\n\n}\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char * argv[])\n{\n  int no_of_nodes;\n  int edge_list_size;\n  FILE *fp;\n  Node* h_graph_nodes;\n  char *h_graph_mask, *h_updating_graph_mask, *h_graph_visited;\n  char *input_f;\n  if(argc!=2){\n    Usage(argc, argv);\n    exit(0);\n  }\n\n  input_f = argv[1];\n  printf(\"Reading File\\n\");\n  \n\n  fp = fopen(input_f,\"r\");\n  if(!fp){\n    printf(\"Error Reading graph file %s\\n\", input_f);\n    return 1;\n  }\n\n  int source = 0;\n\n  fscanf(fp,\"%d\",&no_of_nodes);\n\n  \n\n  h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n  h_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_updating_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_graph_visited = (char*) malloc(sizeof(char)*no_of_nodes);\n\n  int start, edgeno;   \n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    fscanf(fp,\"%d %d\",&start,&edgeno);\n    h_graph_nodes[i].starting = start;\n    h_graph_nodes[i].no_of_edges = edgeno;\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n  \n\n  fscanf(fp,\"%d\",&source);\n  source=0;\n  \n\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  fscanf(fp,\"%d\",&edge_list_size);\n  int id,cost;\n  int* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n  for(int i=0; i < edge_list_size ; i++){\n    fscanf(fp,\"%d\",&id);\n    fscanf(fp,\"%d\",&cost);\n    h_graph_edges[i] = id;\n  }\n\n  if(fp) fclose(fp);    \n  \n\n  int  *h_cost = (int*) malloc(sizeof(int)*no_of_nodes);\n  int *h_cost_ref = (int*)malloc(sizeof(int)*no_of_nodes);\n  for(int i=0;i<no_of_nodes;i++){\n    h_cost[i]=-1;\n    h_cost_ref[i] = -1;\n  }\n  h_cost[source]=0;\n  h_cost_ref[source]=0;    \n\n  printf(\"run bfs (#nodes = %d) on device\\n\", no_of_nodes);\n  run_bfs_gpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost);  \n\n  printf(\"run bfs (#nodes = %d) on host (cpu) \\n\", no_of_nodes);\n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n\n  \n\n  source=0;\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  run_bfs_cpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost_ref);\n\n  \n\n  compare_results<int>(h_cost_ref, h_cost, no_of_nodes);\n\n  free(h_graph_nodes);\n  free(h_graph_mask);\n  free(h_updating_graph_mask);\n  free(h_graph_visited);\n  free(h_cost);\n  free(h_cost_ref);\n\n  return 0;\n}"}}
{"kernel_name": "bfs", "kernel_api": "sycl", "code": {"bfs.cpp": "\n\n\n#include <cstdlib>\n#include <iostream>\n#include <string>\n#include <cstring>\n#include <cstdio>\n#include <sycl/sycl.hpp>\n#include \"util.h\"\n\n#define MAX_THREADS_PER_BLOCK 256\n\n\n\nstruct Node\n{\n  int starting;\n  int no_of_edges;\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\nvoid run_bfs_cpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size, \\\n    int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask, \\\n    char *h_graph_visited, int *h_cost_ref){\n  char stop;\n  do{\n    \n\n    stop=0;\n    for(int tid = 0; tid < no_of_nodes; tid++ )\n    {\n      if (h_graph_mask[tid] == 1){ \n        h_graph_mask[tid]=0;\n        for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++){\n          int id = h_graph_edges[i];  \n\n          if(!h_graph_visited[id]){  \n\n            h_cost_ref[id]=h_cost_ref[tid]+1;\n            h_updating_graph_mask[id]=1;\n          }\n        }\n      }    \n    }\n\n    for(int tid=0; tid< no_of_nodes ; tid++ )\n    {\n      if (h_updating_graph_mask[tid] == 1){\n        h_graph_mask[tid]=1;\n        h_graph_visited[tid]=1;\n        stop=1;\n        h_updating_graph_mask[tid]=0;\n      }\n    }\n  }\n  while(stop);\n}\n\n\n\n\n\n\nvoid run_bfs_gpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size,\n    int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask,\n    char *h_graph_visited, int *h_cost) noexcept(false) {\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  Node *d_graph_nodes = sycl::malloc_device<Node>(no_of_nodes, q);\n  q.memcpy(d_graph_nodes, h_graph_nodes, no_of_nodes * sizeof(Node));\n\n  int *d_graph_edges = sycl::malloc_device<int>(edge_list_size, q); \n  q.memcpy(d_graph_edges, h_graph_edges, edge_list_size * sizeof(int));\n\n  char *d_graph_mask = sycl::malloc_device<char>(no_of_nodes, q);\n  q.memcpy(d_graph_mask, h_graph_mask, no_of_nodes * sizeof(char));\n\n  char *d_updating_graph_mask = sycl::malloc_device<char>(no_of_nodes, q);\n  q.memcpy(d_updating_graph_mask, h_updating_graph_mask, no_of_nodes * sizeof(char));\n\n  char *d_graph_visited = sycl::malloc_device<char>(no_of_nodes, q);\n  q.memcpy(d_graph_visited, h_graph_visited, no_of_nodes * sizeof(char));\n\n  int *d_cost= sycl::malloc_device<int>(no_of_nodes, q);\n  q.memcpy(d_cost, h_cost, no_of_nodes * sizeof(int));\n\n  char h_over;\n  char *d_over = sycl::malloc_device<char>(1, q);\n\n  int global_work_size = (no_of_nodes + MAX_THREADS_PER_BLOCK - 1) / MAX_THREADS_PER_BLOCK * MAX_THREADS_PER_BLOCK;\n  sycl::range<1> gws (global_work_size);\n  sycl::range<1> lws (MAX_THREADS_PER_BLOCK);\n\n  long time = 0;\n  do {\n    h_over = 0;\n    q.memcpy(d_over, &h_over, sizeof(char)).wait();\n    \n    auto start = std::chrono::steady_clock::now();\n\n    q.submit([&](sycl::handler& cgh) {\n      cgh.parallel_for<class kernel1>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int tid = item.get_global_id(0);\n        if (tid<no_of_nodes && d_graph_mask[tid]) {\n          d_graph_mask[tid]=0;\n          const int num_edges = d_graph_nodes[tid].no_of_edges;\n          const int starting = d_graph_nodes[tid].starting;\n\n          for(int i=starting; i<(num_edges + starting); i++) {\n            int id = d_graph_edges[i];\n            if(!d_graph_visited[id]){\n              d_cost[id]=d_cost[tid]+1;\n              d_updating_graph_mask[id]=1;\n            }\n          }\n        }    \n      });\n    });\n\n    q.submit([&](sycl::handler& cgh) {\n      cgh.parallel_for<class kernel2>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int tid = item.get_global_id(0);\n        if (tid<no_of_nodes && d_updating_graph_mask[tid]) {\n          d_graph_mask[tid]=1;\n          d_graph_visited[tid]=1;\n          d_over[0]=1;\n          d_updating_graph_mask[tid]=0;\n        }\n      });\n    }).wait();\n\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    q.memcpy(&h_over, d_over, sizeof(char)).wait();\n  }\n  while (h_over);\n\n  printf(\"Total kernel execution time : %f (us)\\n\", time * 1e-3f);\n\n  q.memcpy(h_cost, d_cost, sizeof(int)*no_of_nodes).wait();\n\n  free(d_graph_nodes, q);\n  free(d_graph_edges, q);\n  free(d_graph_mask, q);\n  free(d_updating_graph_mask, q);\n  free(d_graph_visited, q);\n  free(d_cost, q);\n  free(d_over, q);\n}\n\nvoid Usage(int argc, char**argv){\n\n  fprintf(stderr,\"Usage: %s <input_file>\\n\", argv[0]);\n\n}\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char * argv[])\n{\n  int no_of_nodes;\n  int edge_list_size;\n  FILE *fp;\n  Node* h_graph_nodes;\n  char *h_graph_mask, *h_updating_graph_mask, *h_graph_visited;\n  char *input_f;\n  if(argc!=2){\n    Usage(argc, argv);\n    exit(0);\n  }\n\n  input_f = argv[1];\n  printf(\"Reading File\\n\");\n  \n\n  fp = fopen(input_f,\"r\");\n  if(!fp){\n    printf(\"Error Reading graph file %s\\n\", input_f);\n    return 1;\n  }\n\n  int source = 0;\n\n  fscanf(fp,\"%d\",&no_of_nodes);\n\n  \n\n  h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n  h_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_updating_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n  h_graph_visited = (char*) malloc(sizeof(char)*no_of_nodes);\n\n  int start, edgeno;   \n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    fscanf(fp,\"%d %d\",&start,&edgeno);\n    h_graph_nodes[i].starting = start;\n    h_graph_nodes[i].no_of_edges = edgeno;\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n  \n\n  fscanf(fp,\"%d\",&source);\n  source=0;\n  \n\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  fscanf(fp,\"%d\",&edge_list_size);\n  int id,cost;\n  int* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n  for(int i=0; i < edge_list_size ; i++){\n    fscanf(fp,\"%d\",&id);\n    fscanf(fp,\"%d\",&cost);\n    h_graph_edges[i] = id;\n  }\n\n  if(fp) fclose(fp);    \n\n  \n\n  int *h_cost = (int*) malloc(sizeof(int)*no_of_nodes);\n  int *h_cost_ref = (int*) malloc(sizeof(int)*no_of_nodes);\n  for(int i=0;i<no_of_nodes;i++){\n    h_cost[i]=-1;\n    h_cost_ref[i] = -1;\n  }\n  h_cost[source]=0;\n  h_cost_ref[source]=0;    \n\n  printf(\"run bfs (#nodes = %d) on device\\n\", no_of_nodes);\n  run_bfs_gpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost);  \n\n  printf(\"run bfs (#nodes = %d) on host (cpu) \\n\", no_of_nodes);\n  \n\n  for(int i = 0; i < no_of_nodes; i++){\n    h_graph_mask[i]=0;\n    h_updating_graph_mask[i]=0;\n    h_graph_visited[i]=0;\n  }\n\n  \n\n  source=0;\n  h_graph_mask[source]=1;\n  h_graph_visited[source]=1;\n  run_bfs_cpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, \n      h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost_ref);\n\n  \n\n  compare_results<int>(h_cost_ref, h_cost, no_of_nodes);\n  free(h_graph_nodes);\n  free(h_graph_mask);\n  free(h_updating_graph_mask);\n  free(h_graph_visited);\n  free(h_cost);\n  free(h_cost_ref);\n  return 0;\n}\n"}}
{"kernel_name": "bsearch", "kernel_api": "cuda", "code": {"main.cu": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n#include <cuda.h>\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\ntemplate <typename T>\n__global__ void\nkernel_BS (const T* __restrict__ acc_a,\n           const T* __restrict__ acc_z,\n            size_t* __restrict__ acc_r,\n           const size_t n)\n{ \n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  T z = acc_z[i];\n  size_t low = 0;\n  size_t high = n;\n  while (high - low > 1) {\n    size_t mid = low + (high - low)/2;\n    if (z < acc_a[mid])\n      high = mid;\n    else\n      low = mid;\n  }\n  acc_r[i] = low;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS2 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  unsigned  nbits = 0;\n  while (n >> nbits) nbits++;\n  size_t k = 1ULL << (nbits - 1);\n  T z = acc_z[i];\n  size_t idx = (acc_a[k] <= z) ? k : 0;\n  while (k >>= 1) {\n    size_t r = idx | k;\n    if (r < n && z >= acc_a[r]) { \n      idx = r;\n    }\n  }\n  acc_r[i] = idx;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS3 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  unsigned nbits = 0;\n  while (n >> nbits) nbits++;\n  size_t k = 1ULL << (nbits - 1);\n  T z = acc_z[i];\n  size_t idx = (acc_a[k] <= z) ? k : 0;\n  while (k >>= 1) {\n    size_t r = idx | k;\n    size_t w = r < n ? r : n; \n    if (z >= acc_a[w]) { \n      idx = r;\n    }\n  }\n  acc_r[i] = idx;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS4 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  __shared__  size_t k;\n\n  size_t gid = blockIdx.x*blockDim.x+threadIdx.x;\n  size_t lid = threadIdx.x; \n\n  if (lid == 0) {\n    unsigned nbits = 0;\n    while (n >> nbits) nbits++;\n    k = 1ULL << (nbits - 1);\n  }\n  __syncthreads();\n\n  size_t p = k;\n  T z = acc_z[gid];\n  size_t idx = (acc_a[p] <= z) ? p : 0;\n  while (p >>= 1) {\n    size_t r = idx | p;\n    size_t w = r < n ? r : n;\n    if (z >= acc_a[w]) { \n      idx = r;\n    }\n  }\n  acc_r[gid] = idx;\n}\n\ntemplate <typename T>\nvoid bs ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs1) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs2 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS2<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs2) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs3 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS3<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs3) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs4 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS4<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs4) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n  for (size_t i = 0; i < zSize; ++i)\n  {\n    \n\n    if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n    {\n      std::cout << msg << \": incorrect result:\" << std::endl;\n      std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n      std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n      break;\n    }\n    \n\n    r[i] = 0xFFFFFFFF;\n  }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) z[i] = rand() % N;\n\n  Real_t* d_a;\n  Real_t* d_z;\n  size_t *d_r;\n  cudaMalloc((void**)&d_a, sizeof(Real_t)*aSize);\n  cudaMalloc((void**)&d_z, sizeof(Real_t)*zSize);\n  cudaMalloc((void**)&d_r, sizeof(size_t)*zSize);\n  cudaMemcpy(d_a, a, sizeof(Real_t)*aSize, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_z, z, sizeof(Real_t)*zSize, cudaMemcpyHostToDevice);\n\n  bs(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(r, d_r, sizeof(size_t)*zSize, cudaMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs\");\n#endif\n\n  bs2(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(r, d_r, sizeof(size_t)*zSize, cudaMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs2\");\n#endif\n\n  bs3(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(r, d_r, sizeof(size_t)*zSize, cudaMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs3\");\n#endif\n\n  bs4(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(r, d_r, sizeof(size_t)*zSize, cudaMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs4\");\n#endif\n\n  cudaFree(d_a);\n  cudaFree(d_z);\n  cudaFree(d_r);\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "bsearch", "kernel_api": "hip", "code": {"main.cu": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n#include <hip/hip_runtime.h>\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\ntemplate <typename T>\n__global__ void\nkernel_BS (const T* __restrict__ acc_a,\n           const T* __restrict__ acc_z,\n            size_t* __restrict__ acc_r,\n           const size_t n)\n{ \n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  T z = acc_z[i];\n  size_t low = 0;\n  size_t high = n;\n  while (high - low > 1) {\n    size_t mid = low + (high - low)/2;\n    if (z < acc_a[mid])\n      high = mid;\n    else\n      low = mid;\n  }\n  acc_r[i] = low;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS2 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  unsigned  nbits = 0;\n  while (n >> nbits) nbits++;\n  size_t k = 1ULL << (nbits - 1);\n  T z = acc_z[i];\n  size_t idx = (acc_a[k] <= z) ? k : 0;\n  while (k >>= 1) {\n    size_t r = idx | k;\n    if (r < n && z >= acc_a[r]) { \n      idx = r;\n    }\n  }\n  acc_r[i] = idx;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS3 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  unsigned nbits = 0;\n  while (n >> nbits) nbits++;\n  size_t k = 1ULL << (nbits - 1);\n  T z = acc_z[i];\n  size_t idx = (acc_a[k] <= z) ? k : 0;\n  while (k >>= 1) {\n    size_t r = idx | k;\n    size_t w = r < n ? r : n; \n    if (z >= acc_a[w]) { \n      idx = r;\n    }\n  }\n  acc_r[i] = idx;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS4 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  __shared__  size_t k;\n\n  size_t gid = blockIdx.x*blockDim.x+threadIdx.x;\n  size_t lid = threadIdx.x; \n\n  if (lid == 0) {\n    unsigned nbits = 0;\n    while (n >> nbits) nbits++;\n    k = 1ULL << (nbits - 1);\n  }\n  __syncthreads();\n\n  size_t p = k;\n  T z = acc_z[gid];\n  size_t idx = (acc_a[p] <= z) ? p : 0;\n  while (p >>= 1) {\n    size_t r = idx | p;\n    size_t w = r < n ? r : n;\n    if (z >= acc_a[w]) { \n      idx = r;\n    }\n  }\n  acc_r[gid] = idx;\n}\n\ntemplate <typename T>\nvoid bs ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs1) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs2 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS2<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs2) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs3 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS3<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs3) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs4 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS4<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs4) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n  for (size_t i = 0; i < zSize; ++i)\n  {\n    \n\n    if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n    {\n      std::cout << msg << \": incorrect result:\" << std::endl;\n      std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n      std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n      break;\n    }\n    \n\n    r[i] = 0xFFFFFFFF;\n  }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) z[i] = rand() % N;\n\n  Real_t* d_a;\n  Real_t* d_z;\n  size_t *d_r;\n  hipMalloc((void**)&d_a, sizeof(Real_t)*aSize);\n  hipMalloc((void**)&d_z, sizeof(Real_t)*zSize);\n  hipMalloc((void**)&d_r, sizeof(size_t)*zSize);\n  hipMemcpy(d_a, a, sizeof(Real_t)*aSize, hipMemcpyHostToDevice);\n  hipMemcpy(d_z, z, sizeof(Real_t)*zSize, hipMemcpyHostToDevice);\n\n  bs(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  hipMemcpy(r, d_r, sizeof(size_t)*zSize, hipMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs\");\n#endif\n\n  bs2(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  hipMemcpy(r, d_r, sizeof(size_t)*zSize, hipMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs2\");\n#endif\n\n  bs3(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  hipMemcpy(r, d_r, sizeof(size_t)*zSize, hipMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs3\");\n#endif\n\n  bs4(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  hipMemcpy(r, d_r, sizeof(size_t)*zSize, hipMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs4\");\n#endif\n\n  hipFree(d_a);\n  hipFree(d_z);\n  hipFree(d_r);\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "bsearch", "kernel_api": "omp", "code": {"main.cpp": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n#include <omp.h>\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\ntemplate <typename T>\nvoid bs ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < zSize; i++) { \n      T z = acc_z[i];\n      size_t low = 0;\n      size_t high = n;\n      while (high - low > 1) {\n        size_t mid = low + (high - low)/2;\n        if (z < acc_a[mid])\n          high = mid;\n        else\n          low = mid;\n      }\n      acc_r[i] = low;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs1) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs2 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < zSize; i++) { \n      unsigned  nbits = 0;\n      while (n >> nbits) nbits++;\n      size_t k = 1ULL << (nbits - 1);\n      T z = acc_z[i];\n      size_t idx = (acc_a[k] <= z) ? k : 0;\n      while (k >>= 1) {\n        size_t r = idx | k;\n        if (r < n && z >= acc_a[r]) { \n          idx = r;\n        }\n      }\n      acc_r[i] = idx;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs2) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs3 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < zSize; i++) { \n      unsigned nbits = 0;\n      while (n >> nbits) nbits++;\n      size_t k = 1ULL << (nbits - 1);\n      T z = acc_z[i];\n      size_t idx = (acc_a[k] <= z) ? k : 0;\n      while (k >>= 1) {\n        size_t r = idx | k;\n        size_t w = r < n ? r : n; \n        if (z >= acc_a[w]) { \n          idx = r;\n        }\n      }\n      acc_r[i] = idx;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs3) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs4 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(zSize/256)  thread_limit(256)\n    {\n      size_t k;\n      #pragma omp parallel\n      {\n        size_t lid = omp_get_thread_num();\n        size_t gid = omp_get_team_num()*omp_get_num_threads()+lid;\n        if (lid == 0) {\n          unsigned nbits = 0;\n          while (n >> nbits) nbits++;\n          k = 1ULL << (nbits - 1);\n        }\n        #pragma omp barrier\n\n        size_t p = k;\n        T z = acc_z[gid];\n        size_t idx = (acc_a[p] <= z) ? p : 0;\n        while (p >>= 1) {\n          size_t r = idx | p;\n          size_t w = r < n ? r : n;\n          if (z >= acc_a[w]) { \n            idx = r;\n          }\n        }\n        acc_r[gid] = idx;\n      }\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs4) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n  for (size_t i = 0; i < zSize; ++i)\n  {\n    \n\n    if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n    {\n      std::cout << msg << \": incorrect result:\" << std::endl;\n      std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n      std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n      break;\n    }\n    \n\n    r[i] = 0xFFFFFFFF;\n  }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) { \n    z[i] = rand() % N;\n  }\n\n  #pragma omp target data map(to: a[0:aSize], z[0:zSize]) \\\n                          map(from: r[0:zSize])\n  {\n    bs(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n    #pragma omp target update from (r[0:zSize])\n    verify(a, z, r, aSize, zSize, \"bs1\");\n  #endif\n  \n    bs2(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n    #pragma omp target update from (r[0:zSize])\n    verify(a, z, r, aSize, zSize, \"bs2\");\n  #endif\n  \n    bs3(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n    #pragma omp target update from (r[0:zSize])\n    verify(a, z, r, aSize, zSize, \"bs3\");\n  #endif\n  \n    bs4(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n    #pragma omp target update from (r[0:zSize])\n    verify(a, z, r, aSize, zSize, \"bs4\");\n  #endif\n  }\n\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "bsearch", "kernel_api": "serial", "code": {"main.cpp": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\ntemplate <typename T>\nvoid bs ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n        for (int i = 0; i < zSize; i++) { \n      T z = acc_z[i];\n      size_t low = 0;\n      size_t high = n;\n      while (high - low > 1) {\n        size_t mid = low + (high - low)/2;\n        if (z < acc_a[mid])\n          high = mid;\n        else\n          low = mid;\n      }\n      acc_r[i] = low;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs1) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs2 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n        for (int i = 0; i < zSize; i++) { \n      unsigned  nbits = 0;\n      while (n >> nbits) nbits++;\n      size_t k = 1ULL << (nbits - 1);\n      T z = acc_z[i];\n      size_t idx = (acc_a[k] <= z) ? k : 0;\n      while (k >>= 1) {\n        size_t r = idx | k;\n        if (r < n && z >= acc_a[r]) { \n          idx = r;\n        }\n      }\n      acc_r[i] = idx;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs2) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs3 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n        for (int i = 0; i < zSize; i++) { \n      unsigned nbits = 0;\n      while (n >> nbits) nbits++;\n      size_t k = 1ULL << (nbits - 1);\n      T z = acc_z[i];\n      size_t idx = (acc_a[k] <= z) ? k : 0;\n      while (k >>= 1) {\n        size_t r = idx | k;\n        size_t w = r < n ? r : n; \n        if (z >= acc_a[w]) { \n          idx = r;\n        }\n      }\n      acc_r[i] = idx;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs3) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs4 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n        {\n      size_t k;\n            {\n        size_t lid = omp_get_thread_num();\n        size_t gid = omp_get_team_num()*omp_get_num_threads()+lid;\n        if (lid == 0) {\n          unsigned nbits = 0;\n          while (n >> nbits) nbits++;\n          k = 1ULL << (nbits - 1);\n        }\n        \n        size_t p = k;\n        T z = acc_z[gid];\n        size_t idx = (acc_a[p] <= z) ? p : 0;\n        while (p >>= 1) {\n          size_t r = idx | p;\n          size_t w = r < n ? r : n;\n          if (z >= acc_a[w]) { \n            idx = r;\n          }\n        }\n        acc_r[gid] = idx;\n      }\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs4) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n  for (size_t i = 0; i < zSize; ++i)\n  {\n    \n\n    if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n    {\n      std::cout << msg << \": incorrect result:\" << std::endl;\n      std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n      std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n      break;\n    }\n    \n\n    r[i] = 0xFFFFFFFF;\n  }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) { \n    z[i] = rand() % N;\n  }\n\n    {\n    bs(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n        verify(a, z, r, aSize, zSize, \"bs1\");\n  #endif\n  \n    bs2(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n        verify(a, z, r, aSize, zSize, \"bs2\");\n  #endif\n  \n    bs3(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n        verify(a, z, r, aSize, zSize, \"bs3\");\n  #endif\n  \n    bs4(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n        verify(a, z, r, aSize, zSize, \"bs4\");\n  #endif\n  }\n\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}"}}
{"kernel_name": "bsearch", "kernel_api": "sycl", "code": {"main.cpp": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include \"bs.h\"\n#include \"bs2.h\"\n#include \"bs3.h\"\n#include \"bs4.h\"\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n    for (size_t i = 0; i < zSize; ++i)\n    {\n        \n\n        if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n        {\n          std::cout << msg << \": incorrect result:\" << std::endl;\n          std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n          std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n          break;\n        }\n        \n\n        r[i] = 0xFFFFFFFF;\n    }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) z[i] = rand() % N;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  Real_t *d_a = sycl::malloc_device<Real_t>(aSize, q);\n  q.memcpy(d_a, a, aSize * sizeof(Real_t));\n\n  Real_t *d_z = sycl::malloc_device<Real_t>(zSize, q);\n  q.memcpy(d_z, z, zSize * sizeof(Real_t));\n\n  size_t *d_r = sycl::malloc_device<size_t>(zSize, q);\n\n  bs(q, aSize, zSize, d_a, d_z, d_r, N, repeat);  \n\n#ifdef DEBUG\n  q.memcpy(r, d_r, zSize * sizeof(size_t)).wait();\n  verify(a, z, r, aSize, zSize, \"bs\");\n#endif\n\n  bs2(q, aSize, zSize, d_a, d_z, d_r, N, repeat);  \n\n#ifdef DEBUG\n  q.memcpy(r, d_r, zSize * sizeof(size_t)).wait();\n  verify(a, z, r, aSize, zSize, \"bs2\");\n#endif\n\n  bs3(q, aSize, zSize, d_a, d_z, d_r, N, repeat);  \n\n#ifdef DEBUG\n  q.memcpy(r, d_r, zSize * sizeof(size_t)).wait();\n  verify(a, z, r, aSize, zSize, \"bs3\");\n#endif\n\n  bs4(q, aSize, zSize, d_a, d_z, d_r, N, repeat);  \n\n#ifdef DEBUG\n  q.memcpy(r, d_r, zSize * sizeof(size_t)).wait();\n  verify(a, z, r, aSize, zSize, \"bs4\");\n#endif\n\n  sycl::free(d_a, q);\n  sycl::free(d_z, q);\n  sycl::free(d_r, q);\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "keogh", "kernel_api": "cuda", "code": {"main.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n\n\n__global__\nvoid lb_keogh(const float *__restrict__ subject,\n              const float *__restrict__ avgs,\n              const float *__restrict__ stds, \n                    float *__restrict__ lb_keogh,\n              const float *__restrict__ lower_bound,\n              const float *__restrict__ upper_bound,\n              const int M,\n              const int N) \n{\n  \n\n  extern __shared__ float cache[];\n\n  int lid = threadIdx.x;\n  int blockSize = blockDim.x * blockIdx.x;\n  int idx = blockSize + lid;\n\n  for (int k = lid; k < blockDim.x + M; k += blockDim.x)\n    if (blockSize + k < N) cache[k] = subject[blockSize + k];\n\n  __syncthreads();\n\n  if (idx < N-M+1) {\n\n    \n\n    float residues = 0;\n    float avg = avgs[idx];\n    float std = stds[idx];\n\n    for (int i = 0; i < M; ++i) {\n      \n\n      float value = (cache[lid+i] - avg) / std;\n      float lower = value - lower_bound[i];\n      float upper = value - upper_bound[i];\n\n      \n\n      residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n    }\n\n    lb_keogh[idx] = residues;\n  }\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower = (float*) malloc (sizeof(float)*N);\n  float *upper = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower[i] = (float)rand() / (float)RAND_MAX;\n\n  float *d_subject = NULL, *d_avgs = NULL, *d_stds = NULL, \n        *d_lb = NULL, *d_lower = NULL, *d_upper = NULL;\n\n  cudaMalloc(&d_subject, sizeof(float)*N);\n  cudaMalloc(&d_avgs, sizeof(float)*(N-M+1));\n  cudaMalloc(&d_stds, sizeof(float)*(N-M+1));\n  cudaMalloc(&d_lb, sizeof(float)*(N-M+1));\n  cudaMalloc(&d_lower, sizeof(float)*M);\n  cudaMalloc(&d_upper, sizeof(float)*M);\n\n  cudaMemcpy(d_subject, subject, sizeof(float)*N, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_avgs, avgs, sizeof(float)*(N-M+1), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_stds, stds, sizeof(float)*(N-M+1), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_lower, lower, sizeof(float)*M, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_upper, upper, sizeof(float)*M, cudaMemcpyHostToDevice);\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n  int smem_size = (M+blocks)*sizeof(float);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    lb_keogh<<<grids, blocks, smem_size>>>\n      (d_subject, d_avgs, d_stds, d_lb, d_lower, d_upper, M, N);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(lb, d_lb, sizeof(float)*(N-M+1), cudaMemcpyDeviceToHost);\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower, upper, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabsf(lb[i] - lb_h[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_lb);\n  cudaFree(d_avgs);\n  cudaFree(d_stds);\n  cudaFree(d_subject);\n  cudaFree(d_lower);\n  cudaFree(d_upper);\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower);\n  free(upper);\n  return 0;\n}\n"}}
{"kernel_name": "keogh", "kernel_api": "hip", "code": {"main.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n\n\n__global__\nvoid lb_keogh(const float *__restrict__ subject,\n              const float *__restrict__ avgs,\n              const float *__restrict__ stds, \n                    float *__restrict__ lb_keogh,\n              const float *__restrict__ lower_bound,\n              const float *__restrict__ upper_bound,\n              const int M,\n              const int N) \n{\n  \n\n  extern __shared__ float cache[];\n\n  int lid = threadIdx.x;\n  int blockSize = blockDim.x * blockIdx.x;\n  int idx = blockSize + lid;\n\n  for (int k = lid; k < blockDim.x + M; k += blockDim.x)\n    if (blockSize + k < N) cache[k] = subject[blockSize + k];\n\n  __syncthreads();\n\n  if (idx < N-M+1) {\n\n    \n\n    float residues = 0;\n    float avg = avgs[idx];\n    float std = stds[idx];\n\n    for (int i = 0; i < M; ++i) {\n      \n\n      float value = (cache[lid+i] - avg) / std;\n      float lower = value - lower_bound[i];\n      float upper = value - upper_bound[i];\n\n      \n\n      residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n    }\n\n    lb_keogh[idx] = residues;\n  }\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower = (float*) malloc (sizeof(float)*N);\n  float *upper = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower[i] = (float)rand() / (float)RAND_MAX;\n\n  float *d_subject = NULL, *d_avgs = NULL, *d_stds = NULL, \n        *d_lb = NULL, *d_lower = NULL, *d_upper = NULL;\n\n  hipMalloc(&d_subject, sizeof(float)*N);\n  hipMalloc(&d_avgs, sizeof(float)*(N-M+1));\n  hipMalloc(&d_stds, sizeof(float)*(N-M+1));\n  hipMalloc(&d_lb, sizeof(float)*(N-M+1));\n  hipMalloc(&d_lower, sizeof(float)*M);\n  hipMalloc(&d_upper, sizeof(float)*M);\n\n  hipMemcpy(d_subject, subject, sizeof(float)*N, hipMemcpyHostToDevice);\n  hipMemcpy(d_avgs, avgs, sizeof(float)*(N-M+1), hipMemcpyHostToDevice);\n  hipMemcpy(d_stds, stds, sizeof(float)*(N-M+1), hipMemcpyHostToDevice);\n  hipMemcpy(d_lower, lower, sizeof(float)*M, hipMemcpyHostToDevice);\n  hipMemcpy(d_upper, upper, sizeof(float)*M, hipMemcpyHostToDevice);\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n  int smem_size = (M+blocks)*sizeof(float);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(lb_keogh, grids, blocks, smem_size, 0, d_subject, d_avgs, d_stds, d_lb, d_lower, d_upper, M, N);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(lb, d_lb, sizeof(float)*(N-M+1), hipMemcpyDeviceToHost);\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower, upper, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabsf(lb[i] - lb_h[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_lb);\n  hipFree(d_avgs);\n  hipFree(d_stds);\n  hipFree(d_subject);\n  hipFree(d_lower);\n  hipFree(d_upper);\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower);\n  free(upper);\n  return 0;\n}\n"}}
{"kernel_name": "keogh", "kernel_api": "omp", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return -1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower_bound = (float*) malloc (sizeof(float)*N);\n  float *upper_bound = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper_bound[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower_bound[i] = (float)rand() / (float)RAND_MAX;\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n\n  #pragma omp target data map (to: subject[0:N], \\\n                                   avgs[0:N-M+1],\\\n                                   stds[0:N-M+1],\\\n                                   lower_bound[0:N],\\\n                                   upper_bound[0:N])\\\n                          map(from: lb[0:N-M+1])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target teams distribute num_teams(grids) thread_limit(blocks)\n      for (int idx = 0; idx < N-M+1; idx++) {\n        \n\n        float residues = 0;\n        float avg = avgs[idx];\n        float std = stds[idx];\n\n        #pragma omp parallel for reduction(+:residues)\n        for (int i = 0; i < M; ++i) {\n          \n\n          float value = (subject[idx+i] - avg) / std;\n          float lower = value - lower_bound[i];\n          float upper = value - upper_bound[i];\n\n          \n\n          residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n        }\n\n        lb[idx] = residues;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower_bound, upper_bound, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabs(lb[i] - lb_h[i]) > 1e-3) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower_bound);\n  free(upper_bound);\n  return 0;\n}\n"}}
{"kernel_name": "keogh", "kernel_api": "serial", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return -1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower_bound = (float*) malloc (sizeof(float)*N);\n  float *upper_bound = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper_bound[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower_bound[i] = (float)rand() / (float)RAND_MAX;\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n            for (int idx = 0; idx < N-M+1; idx++) {\n        \n\n        float residues = 0;\n        float avg = avgs[idx];\n        float std = stds[idx];\n\n                for (int i = 0; i < M; ++i) {\n          \n\n          float value = (subject[idx+i] - avg) / std;\n          float lower = value - lower_bound[i];\n          float upper = value - upper_bound[i];\n\n          \n\n          residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n        }\n\n        lb[idx] = residues;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower_bound, upper_bound, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabs(lb[i] - lb_h[i]) > 1e-3) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower_bound);\n  free(upper_bound);\n  return 0;\n}"}}
{"kernel_name": "keogh", "kernel_api": "sycl", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return -1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower = (float*) malloc (sizeof(float)*N);\n  float *upper = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower[i] = (float)rand() / (float)RAND_MAX;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_subject = sycl::malloc_device<float>(N, q);\n  q.memcpy(d_subject, subject, sizeof(float)*N);\n\n  float *d_avgs = sycl::malloc_device<float>(N-M+1, q);\n  q.memcpy(d_avgs, avgs, sizeof(float)*(N-M+1));\n\n  float *d_stds = sycl::malloc_device<float>(N-M+1, q);\n  q.memcpy(d_stds, stds, sizeof(float)*(N-M+1));\n\n  float *d_lb = sycl::malloc_device<float>(N-M+1, q);\n\n  float *d_lower = sycl::malloc_device<float>(N, q);\n  q.memcpy(d_lower, lower, sizeof(float)*M);\n\n  float *d_upper = sycl::malloc_device<float>(N, q);\n  q.memcpy(d_upper, upper, sizeof(float)*M);\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n  sycl::range<1> gws (grids * blocks);\n  sycl::range<1> lws (blocks);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> cache (sycl::range<1>(M+blocks), cgh);\n      cgh.parallel_for<class lp_koegh>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int lid = item.get_local_id(0);\n        int blockDim = item.get_local_range(0);\n        int blockIdx = item.get_group(0);\n        int blockSize = blockDim * blockIdx;\n        int idx = blockSize + lid;\n\n        for (int k = lid; k < blockDim + M; k += blockDim)\n          if (blockSize + k < N) {\n            cache[k] = d_subject[blockSize + k];\n          }\n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        if (idx < N-M+1) {\n\n          \n\n          float residues = 0;\n          float avg = d_avgs[idx];\n          float std = d_stds[idx];\n\n          for (int i = 0; i < M; ++i) {\n            \n\n            float value = (cache[lid+i] - avg) / std;\n            float lower = value - d_lower[i];\n            float upper = value - d_upper[i];\n\n            \n\n            residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n          }\n\n          d_lb[idx] = residues;\n        }\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(lb, d_lb, sizeof(float)*(N-M+1)).wait();\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower, upper, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabs(lb[i] - lb_h[i]) > 1e-3) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_lb, q);\n  sycl::free(d_avgs, q);\n  sycl::free(d_stds, q);\n  sycl::free(d_subject, q);\n  sycl::free(d_lower, q);\n  sycl::free(d_upper, q);\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower);\n  free(upper);\n  return 0;\n}\n\n\n"}}
{"kernel_name": "s8n", "kernel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"reference.h\"\n\n__global__\nvoid k_cube_select(int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = blockIdx.x;\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 8;\n  int temp_dist[8];\n  for(int i = threadIdx.x; i < n; i += blockDim.x) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 8;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 8 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 4 + _y * 2 + _z;\n      if(dist < temp_dist[temp_idx]) {\n        idx_out[i * 8 + temp_idx] = j;\n        temp_dist[temp_idx] = dist;\n      }\n    }\n  }\n}\n\n__global__\nvoid k_cube_select_two(int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = blockIdx.x;\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 16;\n  int temp_dist[16];\n  for(int i = threadIdx.x; i < n; i += blockDim.x) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 16;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 16 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 8 + _y * 4 + _z * 2;\n      bool flag = false;\n      for(int k = 0; k < 2; k ++) {\n        if (dist < temp_dist[temp_idx + k]) {\n          flag = true;\n        }\n        if (flag) {\n          for (int kk = 1; kk >= k + 1; kk --) {\n            idx_out[i * 16 + temp_idx + kk] = idx_out[i * 16 + temp_idx + kk - 1];\n            temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n          }\n          idx_out[i * 16 + temp_idx + k] = j;\n          temp_dist[temp_idx + k] = dist;\n          break;\n        }\n      }\n    }\n  }\n}\n\n__global__\nvoid k_cube_select_four(int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = blockIdx.x;\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 32;\n  int temp_dist[32];\n  for(int i = threadIdx.x; i < n; i += blockDim.x) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 32;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 32 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 16 + _y * 8 + _z * 4;\n      bool flag = false;\n      for(int k = 0; k < 4; k ++) {\n        if (dist < temp_dist[temp_idx + k]) {\n          flag = true;\n        }\n        if (flag) {\n          for (int kk = 3; kk >= k + 1; kk --) {\n            idx_out[i * 32 + temp_idx + kk] = idx_out[i * 32 + temp_idx + kk - 1];\n            temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n          }\n          idx_out[i * 32 + temp_idx + k] = j;\n          temp_dist[temp_idx + k] = dist;\n          break;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of batches> <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int b = atoi(argv[1]);\n  const int n = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = b * n * 3;\n  size_t input_size_bytes = input_size * sizeof(int);\n\n  size_t output_size = b * n * 8;\n  size_t output_size_bytes = output_size * sizeof(int);\n\n  const int radius = 512;\n\n  int *h_xyz, *d_xyz;\n  int *d_out, *d_out2, *d_out4;\n  int *h_out, *h_out2, *h_out4;\n  int *r_out, *r_out2, *r_out4;\n\n  h_xyz = (int*) malloc (input_size_bytes);\n  h_out = (int*) malloc (output_size_bytes);\n  r_out = (int*) malloc (output_size_bytes);\n  h_out2 = (int*) malloc (2 * output_size_bytes);\n  r_out2 = (int*) malloc (2 * output_size_bytes);\n  h_out4 = (int*) malloc (4 * output_size_bytes);\n  r_out4 = (int*) malloc (4 * output_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_int_distribution<> distr (-256, 255);\n  for (int i = 0; i < input_size; i++) {\n    h_xyz[i] = distr(g);\n  }\n\n  cudaMalloc((void**)&d_xyz, input_size_bytes);\n  cudaMemcpy(d_xyz, h_xyz, input_size_bytes, cudaMemcpyHostToDevice);\n  cudaMalloc((void**)&d_out, output_size_bytes);\n  cudaMalloc((void**)&d_out2, 2 * output_size_bytes);\n  cudaMalloc((void**)&d_out4, 4 * output_size_bytes);\n\n  dim3 grids (b);\n  dim3 blocks (512);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n   k_cube_select<<<grids, blocks>>>(b, n, radius, d_xyz, d_out); \n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_out, d_out, output_size_bytes, cudaMemcpyDeviceToHost);\n  cube_select(b, n, radius, h_xyz, r_out);\n  int error = memcmp(h_out, r_out, output_size_bytes);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    k_cube_select_two<<<grids, blocks>>>(b, n, radius, d_xyz, d_out2); \n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_out2, d_out2, 2 * output_size_bytes, cudaMemcpyDeviceToHost);\n  cube_select_two(b, n, radius, h_xyz, r_out2);\n  error += memcmp(h_out2, r_out2, 2 * output_size_bytes);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    k_cube_select_four<<<grids, blocks>>>(b, n, radius, d_xyz, d_out4); \n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select4 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_out4, d_out4, 4 * output_size_bytes, cudaMemcpyDeviceToHost);\n  cube_select_four(b, n, radius, h_xyz, r_out4);\n  error += memcmp(h_out4, r_out4, 4 * output_size_bytes);\n\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  free(h_xyz);\n  free(h_out);\n  free(h_out2);\n  free(h_out4);\n  free(r_out);\n  free(r_out2);\n  free(r_out4);\n  cudaFree(d_xyz);\n  cudaFree(d_out);\n  cudaFree(d_out2);\n  cudaFree(d_out4);\n  return 0;\n}\n"}}
{"kernel_name": "s8n", "kernel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n__global__\nvoid k_cube_select(int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = blockIdx.x;\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 8;\n  int temp_dist[8];\n  for(int i = threadIdx.x; i < n; i += blockDim.x) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 8;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 8 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 4 + _y * 2 + _z;\n      if(dist < temp_dist[temp_idx]) {\n        idx_out[i * 8 + temp_idx] = j;\n        temp_dist[temp_idx] = dist;\n      }\n    }\n  }\n}\n\n__global__\nvoid k_cube_select_two(int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = blockIdx.x;\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 16;\n  int temp_dist[16];\n  for(int i = threadIdx.x; i < n; i += blockDim.x) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 16;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 16 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 8 + _y * 4 + _z * 2;\n      bool flag = false;\n      for(int k = 0; k < 2; k ++) {\n        if (dist < temp_dist[temp_idx + k]) {\n          flag = true;\n        }\n        if (flag) {\n          for (int kk = 1; kk >= k + 1; kk --) {\n            idx_out[i * 16 + temp_idx + kk] = idx_out[i * 16 + temp_idx + kk - 1];\n            temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n          }\n          idx_out[i * 16 + temp_idx + k] = j;\n          temp_dist[temp_idx + k] = dist;\n          break;\n        }\n      }\n    }\n  }\n}\n\n__global__\nvoid k_cube_select_four(int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = blockIdx.x;\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 32;\n  int temp_dist[32];\n  for(int i = threadIdx.x; i < n; i += blockDim.x) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 32;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 32 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 16 + _y * 8 + _z * 4;\n      bool flag = false;\n      for(int k = 0; k < 4; k ++) {\n        if (dist < temp_dist[temp_idx + k]) {\n          flag = true;\n        }\n        if (flag) {\n          for (int kk = 3; kk >= k + 1; kk --) {\n            idx_out[i * 32 + temp_idx + kk] = idx_out[i * 32 + temp_idx + kk - 1];\n            temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n          }\n          idx_out[i * 32 + temp_idx + k] = j;\n          temp_dist[temp_idx + k] = dist;\n          break;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of batches> <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int b = atoi(argv[1]);\n  const int n = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = b * n * 3;\n  size_t input_size_bytes = input_size * sizeof(int);\n\n  size_t output_size = b * n * 8;\n  size_t output_size_bytes = output_size * sizeof(int);\n\n  const int radius = 512;\n\n  int *h_xyz, *d_xyz;\n  int *d_out, *d_out2, *d_out4;\n  int *h_out, *h_out2, *h_out4;\n  int *r_out, *r_out2, *r_out4;\n\n  h_xyz = (int*) malloc (input_size_bytes);\n  h_out = (int*) malloc (output_size_bytes);\n  r_out = (int*) malloc (output_size_bytes);\n  h_out2 = (int*) malloc (2 * output_size_bytes);\n  r_out2 = (int*) malloc (2 * output_size_bytes);\n  h_out4 = (int*) malloc (4 * output_size_bytes);\n  r_out4 = (int*) malloc (4 * output_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_int_distribution<> distr (-256, 255);\n  for (int i = 0; i < input_size; i++) {\n    h_xyz[i] = distr(g);\n  }\n\n  hipMalloc((void**)&d_xyz, input_size_bytes);\n  hipMemcpy(d_xyz, h_xyz, input_size_bytes, hipMemcpyHostToDevice);\n  hipMalloc((void**)&d_out, output_size_bytes);\n  hipMalloc((void**)&d_out2, 2 * output_size_bytes);\n  hipMalloc((void**)&d_out4, 4 * output_size_bytes);\n\n  dim3 grids (b);\n  dim3 blocks (512);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n   k_cube_select<<<grids, blocks>>>(b, n, radius, d_xyz, d_out); \n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_out, d_out, output_size_bytes, hipMemcpyDeviceToHost);\n  cube_select(b, n, radius, h_xyz, r_out);\n  int error = memcmp(h_out, r_out, output_size_bytes);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    k_cube_select_two<<<grids, blocks>>>(b, n, radius, d_xyz, d_out2); \n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_out2, d_out2, 2 * output_size_bytes, hipMemcpyDeviceToHost);\n  cube_select_two(b, n, radius, h_xyz, r_out2);\n  error += memcmp(h_out2, r_out2, 2 * output_size_bytes);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    k_cube_select_four<<<grids, blocks>>>(b, n, radius, d_xyz, d_out4); \n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select4 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_out4, d_out4, 4 * output_size_bytes, hipMemcpyDeviceToHost);\n  cube_select_four(b, n, radius, h_xyz, r_out4);\n  error += memcmp(h_out4, r_out4, 4 * output_size_bytes);\n\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  free(h_xyz);\n  free(h_out);\n  free(h_out2);\n  free(h_out4);\n  free(r_out);\n  free(r_out2);\n  free(r_out4);\n  hipFree(d_xyz);\n  hipFree(d_out);\n  hipFree(d_out2);\n  hipFree(d_out4);\n  return 0;\n}\n"}}
{"kernel_name": "s8n", "kernel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"reference.h\"\n\nvoid k_cube_select(int b, int n, int radius, const int* in, int* out) {\n  #pragma omp target teams distribute num_teams(b) \n  for (int batch_idx = 0; batch_idx < b; batch_idx++) {\n    auto xyz = in + batch_idx * n * 3;\n    auto idx_out = out + batch_idx * n * 8;\n    #pragma omp parallel for num_threads(512)\n    for(int i = 0; i < n; i++) {\n      int temp_dist[8];\n      int x = xyz[i * 3];\n      int y = xyz[i * 3 + 1];\n      int z = xyz[i * 3 + 2];\n      for(int j = 0; j < 8;j ++) {\n        temp_dist[j] = radius;\n        idx_out[i * 8 + j] = i; \n\n      }\n      for(int j = 0; j < n; j ++) {\n        if(i != j) continue;\n        int tx = xyz[j * 3];\n        int ty = xyz[j * 3 + 1];\n        int tz = xyz[j * 3 + 2];\n        int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n        if(dist > radius) continue;\n        int _x = (tx > x);\n        int _y = (ty > y);\n        int _z = (tz > z);\n        int temp_idx = _x * 4 + _y * 2 + _z;\n        if(dist < temp_dist[temp_idx]) {\n          idx_out[i * 8 + temp_idx] = j;\n          temp_dist[temp_idx] = dist;\n        }\n      }\n    }\n  }\n}\n\nvoid k_cube_select_two(int b, int n, int radius, const int* in, int* out) {\n  #pragma omp target teams distribute num_teams(b) \n  for (int batch_idx = 0; batch_idx < b; batch_idx++) {\n    auto xyz = in + batch_idx * n * 3;\n    auto idx_out = out + batch_idx * n * 16;\n    #pragma omp parallel for num_threads(512)\n    for(int i = 0; i < n; i++) {\n      int temp_dist[16];\n      int x = xyz[i * 3];\n      int y = xyz[i * 3 + 1];\n      int z = xyz[i * 3 + 2];\n      for(int j = 0; j < 16;j ++) {\n        temp_dist[j] = radius;\n        idx_out[i * 16 + j] = i; \n\n      }\n      for(int j = 0; j < n; j ++) {\n        if(i == j) continue;\n        int tx = xyz[j * 3];\n        int ty = xyz[j * 3 + 1];\n        int tz = xyz[j * 3 + 2];\n        int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n        if(dist > radius) continue;\n        int _x = (tx > x);\n        int _y = (ty > y);\n        int _z = (tz > z);\n        int temp_idx = _x * 8 + _y * 4 + _z * 2;\n        bool flag = false;\n        for(int k = 0; k < 2; k ++) {\n          if (dist < temp_dist[temp_idx + k]) {\n            flag = true;\n          }\n          if (flag) {\n            for (int kk = 1; kk >= k + 1; kk --) {\n              idx_out[i * 16 + temp_idx + kk] = idx_out[i * 16 + temp_idx + kk - 1];\n              temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n            }\n            idx_out[i * 16 + temp_idx + k] = j;\n            temp_dist[temp_idx + k] = dist;\n            break;\n          }\n        }\n      }\n    }\n  }\n}\n\nvoid k_cube_select_four(int b, int n, int radius, const int* in, int* out) {\n  #pragma omp target teams distribute num_teams(b) \n  for (int batch_idx = 0; batch_idx < b; batch_idx++) {\n    auto xyz = in + batch_idx * n * 3;\n    auto idx_out = out + batch_idx * n * 32;\n    #pragma omp parallel for num_threads(512)\n    for(int i = 0; i < n; i++) {\n      int temp_dist[32];\n      int x = xyz[i * 3];\n      int y = xyz[i * 3 + 1];\n      int z = xyz[i * 3 + 2];\n      for(int j = 0; j < 32;j ++) {\n        temp_dist[j] = radius;\n        idx_out[i * 32 + j] = i; \n\n      }\n      for(int j = 0; j < n; j ++) {\n        if(i == j) continue;\n        int tx = xyz[j * 3];\n        int ty = xyz[j * 3 + 1];\n        int tz = xyz[j * 3 + 2];\n        int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n        if(dist > radius) continue;\n        int _x = (tx > x);\n        int _y = (ty > y);\n        int _z = (tz > z);\n        int temp_idx = _x * 16 + _y * 8 + _z * 4;\n        bool flag = false;\n        for(int k = 0; k < 4; k ++) {\n          if (dist < temp_dist[temp_idx + k]) {\n            flag = true;\n          }\n          if (flag) {\n            for (int kk = 3; kk >= k + 1; kk --) {\n              idx_out[i * 32 + temp_idx + kk] = idx_out[i * 32 + temp_idx + kk - 1];\n              temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n            }\n            idx_out[i * 32 + temp_idx + k] = j;\n            temp_dist[temp_idx + k] = dist;\n            break;\n          }\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of batches> <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int b = atoi(argv[1]);\n  const int n = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = b * n * 3;\n  size_t input_size_bytes = input_size * sizeof(int);\n\n  size_t output_size = b * n * 8;\n  size_t output_size_bytes = output_size * sizeof(int);\n\n  const int radius = 512;\n\n  int *h_xyz;\n  int *h_out, *h_out2, *h_out4;\n  int *r_out, *r_out2, *r_out4;\n\n  h_xyz = (int*) malloc (input_size_bytes);\n  h_out = (int*) malloc (output_size_bytes);\n  r_out = (int*) malloc (output_size_bytes);\n  h_out2 = (int*) malloc (2 * output_size_bytes);\n  r_out2 = (int*) malloc (2 * output_size_bytes);\n  h_out4 = (int*) malloc (4 * output_size_bytes);\n  r_out4 = (int*) malloc (4 * output_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_int_distribution<> distr (-256, 255);\n  for (int i = 0; i < input_size; i++) {\n    h_xyz[i] = distr(g);\n  }\n\n  #pragma omp target data map (to: h_xyz[0:input_size]) \\\n                          map (alloc: h_out[0:output_size], \\\n                                      h_out2[0:output_size*2], \\\n                                      h_out4[0:output_size*4])\n  {\n    auto start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n     k_cube_select(b, n, radius, h_xyz, h_out); \n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of select kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    #pragma omp target update from (h_out[0:output_size])\n    cube_select(b, n, radius, h_xyz, r_out);\n    int error = memcmp(h_out, r_out, output_size_bytes);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      k_cube_select_two(b, n, radius, h_xyz, h_out2); \n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of select2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    #pragma omp target update from (h_out2[0:output_size * 2])\n    cube_select_two(b, n, radius, h_xyz, r_out2);\n    error += memcmp(h_out2, r_out2, 2 * output_size_bytes);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      k_cube_select_four(b, n, radius, h_xyz, h_out4); \n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of select4 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    #pragma omp target update from (h_out4[0:output_size * 4])\n    cube_select_four(b, n, radius, h_xyz, r_out4);\n    error += memcmp(h_out4, r_out4, 4 * output_size_bytes);\n\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  }\n  \n  free(h_xyz);\n  free(h_out);\n  free(h_out2);\n  free(h_out4);\n  free(r_out);\n  free(r_out2);\n  free(r_out4);\n  return 0;\n}\n"}}
{"kernel_name": "s8n", "kernel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\nvoid k_cube_select(int b, int n, int radius, const int* in, int* out) {\n    for (int batch_idx = 0; batch_idx < b; batch_idx++) {\n    auto xyz = in + batch_idx * n * 3;\n    auto idx_out = out + batch_idx * n * 8;\n        for(int i = 0; i < n; i++) {\n      int temp_dist[8];\n      int x = xyz[i * 3];\n      int y = xyz[i * 3 + 1];\n      int z = xyz[i * 3 + 2];\n      for(int j = 0; j < 8;j ++) {\n        temp_dist[j] = radius;\n        idx_out[i * 8 + j] = i; \n\n      }\n      for(int j = 0; j < n; j ++) {\n        if(i != j) continue;\n        int tx = xyz[j * 3];\n        int ty = xyz[j * 3 + 1];\n        int tz = xyz[j * 3 + 2];\n        int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n        if(dist > radius) continue;\n        int _x = (tx > x);\n        int _y = (ty > y);\n        int _z = (tz > z);\n        int temp_idx = _x * 4 + _y * 2 + _z;\n        if(dist < temp_dist[temp_idx]) {\n          idx_out[i * 8 + temp_idx] = j;\n          temp_dist[temp_idx] = dist;\n        }\n      }\n    }\n  }\n}\n\nvoid k_cube_select_two(int b, int n, int radius, const int* in, int* out) {\n    for (int batch_idx = 0; batch_idx < b; batch_idx++) {\n    auto xyz = in + batch_idx * n * 3;\n    auto idx_out = out + batch_idx * n * 16;\n        for(int i = 0; i < n; i++) {\n      int temp_dist[16];\n      int x = xyz[i * 3];\n      int y = xyz[i * 3 + 1];\n      int z = xyz[i * 3 + 2];\n      for(int j = 0; j < 16;j ++) {\n        temp_dist[j] = radius;\n        idx_out[i * 16 + j] = i; \n\n      }\n      for(int j = 0; j < n; j ++) {\n        if(i == j) continue;\n        int tx = xyz[j * 3];\n        int ty = xyz[j * 3 + 1];\n        int tz = xyz[j * 3 + 2];\n        int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n        if(dist > radius) continue;\n        int _x = (tx > x);\n        int _y = (ty > y);\n        int _z = (tz > z);\n        int temp_idx = _x * 8 + _y * 4 + _z * 2;\n        bool flag = false;\n        for(int k = 0; k < 2; k ++) {\n          if (dist < temp_dist[temp_idx + k]) {\n            flag = true;\n          }\n          if (flag) {\n            for (int kk = 1; kk >= k + 1; kk --) {\n              idx_out[i * 16 + temp_idx + kk] = idx_out[i * 16 + temp_idx + kk - 1];\n              temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n            }\n            idx_out[i * 16 + temp_idx + k] = j;\n            temp_dist[temp_idx + k] = dist;\n            break;\n          }\n        }\n      }\n    }\n  }\n}\n\nvoid k_cube_select_four(int b, int n, int radius, const int* in, int* out) {\n    for (int batch_idx = 0; batch_idx < b; batch_idx++) {\n    auto xyz = in + batch_idx * n * 3;\n    auto idx_out = out + batch_idx * n * 32;\n        for(int i = 0; i < n; i++) {\n      int temp_dist[32];\n      int x = xyz[i * 3];\n      int y = xyz[i * 3 + 1];\n      int z = xyz[i * 3 + 2];\n      for(int j = 0; j < 32;j ++) {\n        temp_dist[j] = radius;\n        idx_out[i * 32 + j] = i; \n\n      }\n      for(int j = 0; j < n; j ++) {\n        if(i == j) continue;\n        int tx = xyz[j * 3];\n        int ty = xyz[j * 3 + 1];\n        int tz = xyz[j * 3 + 2];\n        int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n        if(dist > radius) continue;\n        int _x = (tx > x);\n        int _y = (ty > y);\n        int _z = (tz > z);\n        int temp_idx = _x * 16 + _y * 8 + _z * 4;\n        bool flag = false;\n        for(int k = 0; k < 4; k ++) {\n          if (dist < temp_dist[temp_idx + k]) {\n            flag = true;\n          }\n          if (flag) {\n            for (int kk = 3; kk >= k + 1; kk --) {\n              idx_out[i * 32 + temp_idx + kk] = idx_out[i * 32 + temp_idx + kk - 1];\n              temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n            }\n            idx_out[i * 32 + temp_idx + k] = j;\n            temp_dist[temp_idx + k] = dist;\n            break;\n          }\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of batches> <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int b = atoi(argv[1]);\n  const int n = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = b * n * 3;\n  size_t input_size_bytes = input_size * sizeof(int);\n\n  size_t output_size = b * n * 8;\n  size_t output_size_bytes = output_size * sizeof(int);\n\n  const int radius = 512;\n\n  int *h_xyz;\n  int *h_out, *h_out2, *h_out4;\n  int *r_out, *r_out2, *r_out4;\n\n  h_xyz = (int*) malloc (input_size_bytes);\n  h_out = (int*) malloc (output_size_bytes);\n  r_out = (int*) malloc (output_size_bytes);\n  h_out2 = (int*) malloc (2 * output_size_bytes);\n  r_out2 = (int*) malloc (2 * output_size_bytes);\n  h_out4 = (int*) malloc (4 * output_size_bytes);\n  r_out4 = (int*) malloc (4 * output_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_int_distribution<> distr (-256, 255);\n  for (int i = 0; i < input_size; i++) {\n    h_xyz[i] = distr(g);\n  }\n\n    {\n    auto start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n     k_cube_select(b, n, radius, h_xyz, h_out); \n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of select kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n        cube_select(b, n, radius, h_xyz, r_out);\n    int error = memcmp(h_out, r_out, output_size_bytes);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      k_cube_select_two(b, n, radius, h_xyz, h_out2); \n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of select2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n        cube_select_two(b, n, radius, h_xyz, r_out2);\n    error += memcmp(h_out2, r_out2, 2 * output_size_bytes);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      k_cube_select_four(b, n, radius, h_xyz, h_out4); \n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of select4 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n        cube_select_four(b, n, radius, h_xyz, r_out4);\n    error += memcmp(h_out4, r_out4, 4 * output_size_bytes);\n\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  }\n  \n  free(h_xyz);\n  free(h_out);\n  free(h_out2);\n  free(h_out4);\n  free(r_out);\n  free(r_out2);\n  free(r_out4);\n  return 0;\n}"}}
{"kernel_name": "s8n", "kernel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nvoid cube_select(sycl::nd_item<1> &item, int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = item.get_group(0);\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 8;\n  int temp_dist[8];\n  for(int i = item.get_local_id(0); i < n; i += item.get_local_range(0)) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 8;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 8 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 4 + _y * 2 + _z;\n      if(dist < temp_dist[temp_idx]) {\n        idx_out[i * 8 + temp_idx] = j;\n        temp_dist[temp_idx] = dist;\n      }\n    }\n  }\n}\n\nvoid cube_select_two(sycl::nd_item<1> &item, int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = item.get_group(0);\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 16;\n  int temp_dist[16];\n  for(int i = item.get_local_id(0); i < n; i += item.get_local_range(0)) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 16;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 16 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 8 + _y * 4 + _z * 2;\n      bool flag = false;\n      for(int k = 0; k < 2; k ++) {\n        if (dist < temp_dist[temp_idx + k]) {\n          flag = true;\n        }\n        if (flag) {\n          for (int kk = 1; kk >= k + 1; kk --) {\n            idx_out[i * 16 + temp_idx + kk] = idx_out[i * 16 + temp_idx + kk - 1];\n            temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n          }\n          idx_out[i * 16 + temp_idx + k] = j;\n          temp_dist[temp_idx + k] = dist;\n          break;\n        }\n      }\n    }\n  }\n}\n\nvoid cube_select_four(sycl::nd_item<1> &item, int b, int n, int radius, const int* xyz, int* idx_out) {\n  int batch_idx = item.get_group(0);\n  xyz += batch_idx * n * 3;\n  idx_out += batch_idx * n * 32;\n  int temp_dist[32];\n  for(int i = item.get_local_id(0); i < n; i += item.get_local_range(0)) {\n    int x = xyz[i * 3];\n    int y = xyz[i * 3 + 1];\n    int z = xyz[i * 3 + 2];\n    for(int j = 0; j < 32;j ++) {\n      temp_dist[j] = radius;\n      idx_out[i * 32 + j] = i; \n\n    }\n    for(int j = 0; j < n; j ++) {\n      if(i == j) continue;\n      int tx = xyz[j * 3];\n      int ty = xyz[j * 3 + 1];\n      int tz = xyz[j * 3 + 2];\n      int dist = (x - tx) * (x - tx) + (y - ty) * (y - ty) + (z - tz) * (z - tz);\n      if(dist > radius) continue;\n      int _x = (tx > x);\n      int _y = (ty > y);\n      int _z = (tz > z);\n      int temp_idx = _x * 16 + _y * 8 + _z * 4;\n      bool flag = false;\n      for(int k = 0; k < 4; k ++) {\n        if (dist < temp_dist[temp_idx + k]) {\n          flag = true;\n        }\n        if (flag) {\n          for (int kk = 3; kk >= k + 1; kk --) {\n            idx_out[i * 32 + temp_idx + kk] = idx_out[i * 32 + temp_idx + kk - 1];\n            temp_dist[temp_idx + kk] = temp_dist[temp_idx + kk - 1];\n          }\n          idx_out[i * 32 + temp_idx + k] = j;\n          temp_dist[temp_idx + k] = dist;\n          break;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of batches> <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int b = atoi(argv[1]);\n  const int n = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = b * n * 3;\n  size_t input_size_bytes = input_size * sizeof(int);\n\n  size_t output_size = b * n * 8;\n  size_t output_size_bytes = output_size * sizeof(int);\n\n  const int radius = 512;\n\n  int *h_xyz, *d_xyz;\n  int *d_out, *d_out2, *d_out4;\n  int *h_out, *h_out2, *h_out4;\n  int *r_out, *r_out2, *r_out4;\n\n  h_xyz = (int*) malloc (input_size_bytes);\n  h_out = (int*) malloc (output_size_bytes);\n  r_out = (int*) malloc (output_size_bytes);\n  h_out2 = (int*) malloc (2 * output_size_bytes);\n  r_out2 = (int*) malloc (2 * output_size_bytes);\n  h_out4 = (int*) malloc (4 * output_size_bytes);\n  r_out4 = (int*) malloc (4 * output_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_int_distribution<> distr (-256, 255);\n  for (int i = 0; i < input_size; i++) {\n    h_xyz[i] = distr(g);\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  d_xyz = sycl::malloc_device<int>(input_size, q);\n  q.memcpy(d_xyz, h_xyz, input_size_bytes);\n\n  d_out  = sycl::malloc_device<int>(output_size, q);\n  d_out2 = sycl::malloc_device<int>(2 * output_size, q);\n  d_out4 = sycl::malloc_device<int>(4 * output_size, q);\n\n  sycl::range<1> gws (b * 512);\n  sycl::range<1> lws (512);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class select>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        cube_select(item, b, n, radius, d_xyz, d_out); \n      });\n    });\n  }\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(h_out, d_out, output_size_bytes).wait();\n  cube_select(b, n, radius, h_xyz, r_out);\n  int error = memcmp(h_out, r_out, output_size_bytes);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class select2>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        cube_select_two(item, b, n, radius, d_xyz, d_out2); \n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(h_out2, d_out2, 2 * output_size_bytes).wait();\n  cube_select_two(b, n, radius, h_xyz, r_out2);\n  error += memcmp(h_out2, r_out2, 2 * output_size_bytes);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class select4>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        cube_select_four(item, b, n, radius, d_xyz, d_out4); \n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of select4 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(h_out4, d_out4, 4 * output_size_bytes).wait();\n  cube_select_four(b, n, radius, h_xyz, r_out4);\n  error += memcmp(h_out4, r_out4, 4 * output_size_bytes);\n\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(h_xyz);\n  free(h_out);\n  free(h_out2);\n  free(h_out4);\n  free(r_out);\n  free(r_out2);\n  free(r_out4);\n  sycl::free(d_xyz, q);\n  sycl::free(d_out, q);\n  sycl::free(d_out2, q);\n  sycl::free(d_out4, q);\n  return 0;\n}\n"}}
{"kernel_name": "tsp", "kernel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <limits.h>\n#include <chrono>\n#include <cuda.h>\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define tilesize 128\n#define dist(a, b) int(sqrtf((px[a] - px[b]) * (px[a] - px[b]) + (py[a] - py[b]) * (py[a] - py[b])))\n#define swap(a, b) {float tmp = a;  a = b;  b = tmp;}\n\n__device__\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n__global__\nvoid TwoOpt(int cities, \n    const float *__restrict posx_d,\n    const float *__restrict posy_d,\n    int *__restrict glob_d,\n    int *__restrict climbs_d,\n    int *__restrict best_d)\n{\n  extern __shared__ int buf_s[];\n  __shared__ float px_s[tilesize];\n  __shared__ float py_s[tilesize];\n  __shared__ int bf_s[tilesize];\n\n  int *buf = &glob_d[blockIdx.x * ((3 * cities + 2 + 31) / 32 * 32)];\n  float *px = (float *)(&buf[cities]);\n  float *py = &px[cities + 1];\n\n  for (int i = threadIdx.x; i < cities; i += blockDim.x) px[i] = posx_d[i];\n  for (int i = threadIdx.x; i < cities; i += blockDim.x) py[i] = posy_d[i];\n  __syncthreads();\n\n  if (threadIdx.x == 0) {  \n\n    unsigned int seed = blockIdx.x;\n    for (unsigned int i = 1; i < cities; i++) {\n      int j = (int)(LCG_random(&seed) * (cities - 1)) + 1;\n      swap(px[i], px[j]);\n      swap(py[i], py[j]);\n    }\n    px[cities] = px[0];\n    py[cities] = py[0];\n  }\n  __syncthreads();\n\n  int minchange;\n  do {\n    for (int i = threadIdx.x; i < cities; i += blockDim.x) buf[i] = -dist(i, i + 1);\n    __syncthreads();\n\n    minchange = 0;\n    int mini = 1;\n    int minj = 0;\n    for (int ii = 0; ii < cities - 2; ii += blockDim.x) {\n      int i = ii + threadIdx.x;\n      float pxi0, pyi0, pxi1, pyi1, pxj1, pyj1;\n      if (i < cities - 2) {\n        minchange -= buf[i];\n        pxi0 = px[i];\n        pyi0 = py[i];\n        pxi1 = px[i + 1];\n        pyi1 = py[i + 1];\n        pxj1 = px[cities];\n        pyj1 = py[cities];\n      }\n      for (int jj = cities - 1; jj >= ii + 2; jj -= tilesize) {\n        int bound = jj - tilesize + 1;\n        for (int k = threadIdx.x; k < tilesize; k += blockDim.x) {\n          if (k + bound >= ii + 2) {\n            px_s[k] = px[k + bound];\n            py_s[k] = py[k + bound];\n            bf_s[k] = buf[k + bound];\n          }\n        }\n        __syncthreads();\n\n        int lower = bound;\n        if (lower < i + 2) lower = i + 2;\n        for (int j = jj; j >= lower; j--) {\n          int jm = j - bound;\n          float pxj0 = px_s[jm];\n          float pyj0 = py_s[jm];\n          int change = bf_s[jm]\n            + int(sqrtf((pxi0 - pxj0) * (pxi0 - pxj0) + (pyi0 - pyj0) * (pyi0 - pyj0)))\n            + int(sqrtf((pxi1 - pxj1) * (pxi1 - pxj1) + (pyi1 - pyj1) * (pyi1 - pyj1)));\n          pxj1 = pxj0;\n          pyj1 = pyj0;\n          if (minchange > change) {\n            minchange = change;\n            mini = i;\n            minj = j;\n          }\n        }\n        __syncthreads();\n      }\n\n      if (i < cities - 2) {\n        minchange += buf[i];\n      }\n    }\n    __syncthreads();\n\n    int change = buf_s[threadIdx.x] = minchange;\n    if (threadIdx.x == 0) atomicAdd(climbs_d, 1);  \n\n    __syncthreads();\n\n    int j = blockDim.x;\n    do {\n      int k = (j + 1) / 2;\n      if ((threadIdx.x + k) < j) {\n        int tmp = buf_s[threadIdx.x + k];\n        if (change > tmp) change = tmp;\n        buf_s[threadIdx.x] = change;\n      }\n      j = k;\n      __syncthreads();\n    } while (j > 1);\n\n    if (minchange == buf_s[0]) {\n      buf_s[1] = threadIdx.x;  \n\n    }\n    __syncthreads();\n\n    if (threadIdx.x == buf_s[1]) {\n      buf_s[2] = mini + 1;\n      buf_s[3] = minj;\n    }\n    __syncthreads();\n\n    minchange = buf_s[0];\n    mini = buf_s[2];\n    int sum = buf_s[3] + mini;\n    for (int i = threadIdx.x; (i + i) < sum; i += blockDim.x) {\n      if (mini <= i) {\n        int j = sum - i;\n        swap(px[i], px[j]);\n        swap(py[i], py[j]);\n      }\n    }\n    __syncthreads();\n  } while (minchange < 0);\n\n  int term = 0;\n  for (int i = threadIdx.x; i < cities; i += blockDim.x) {\n    term += dist(i, i + 1);\n  }\n  buf_s[threadIdx.x] = term;\n  __syncthreads();\n\n  int j = blockDim.x;\n  do {\n    int k = (j + 1) / 2;\n    if ((threadIdx.x + k) < j) {\n      term += buf_s[threadIdx.x + k];\n    }\n    __syncthreads();\n    if ((threadIdx.x + k) < j) {\n      buf_s[threadIdx.x] = term;\n    }\n    j = k;\n    __syncthreads();\n  } while (j > 1);\n\n  if (threadIdx.x == 0) {\n    atomicMin(best_d, term);\n  }\n}\n\n\n\n\n\n\n\n\nstatic int best_thread_count(int cities)\n{\n  int max, best, threads, smem, blocks, thr, perf, bthr;\n\n  max = cities - 2;\n  if (max > 256) max = 256;\n  best = 0;\n  bthr = 4;\n  for (threads = 1; threads <= max; threads++) {\n    smem = sizeof(int) * threads + 2 * sizeof(float) * tilesize + sizeof(int) * tilesize;\n    blocks = (16384 * 2) / smem;\n    if (blocks > 16) blocks = 16;\n    thr = (threads + 31) / 32 * 32;\n    while (blocks * thr > 2048) blocks--;\n    perf = threads * blocks;\n    if (perf > best) {\n      best = perf;\n      bthr = threads;\n    }\n  }\n\n  return bthr;\n}\n\nint main(int argc, char *argv[])\n{\n  printf(\"2-opt TSP CUDA GPU code v2.3\\n\");\n  printf(\"Copyright (c) 2014-2020, Texas State University. All rights reserved.\\n\");\n\n  if (argc != 4) {\n    fprintf(stderr, \"\\narguments: <input_file> <restart_count> <repeat>\\n\");\n    exit(-1);\n  }\n\n  FILE *f = fopen(argv[1], \"rt\");\n  if (f == NULL) {fprintf(stderr, \"could not open file %s\\n\", argv[1]);  exit(-1);}\n\n  int restarts = atoi(argv[2]);\n  if (restarts < 1) {fprintf(stderr, \"restart_count is too small: %d\\n\", restarts); exit(-1);}\n\n  int repeat = atoi(argv[3]);\n\n  \n\n  \n\n  \n\n  int ch, in1;\n  float in2, in3;\n  char str[256];\n\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != ':')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n\n  int cities = atoi(str);\n  if (cities < 100) {\n    fprintf(stderr, \"the problem size must be at least 100 for this version of the code\\n\");\n    fclose(f);\n    exit(-1);\n  } \n\n  ch = getc(f); \n  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n  if (strcmp(str, \"NODE_COORD_SECTION\") != 0) {\n    fprintf(stderr, \"wrong file format\\n\");\n    fclose(f);\n    exit(-1);\n  }\n\n  float *posx = (float *)malloc(sizeof(float) * cities);\n  if (posx == NULL) fprintf(stderr, \"cannot allocate posx\\n\");\n  float *posy = (float *)malloc(sizeof(float) * cities);\n  if (posy == NULL) fprintf(stderr, \"cannot allocate posy\\n\");\n\n  int cnt = 0;\n  while (fscanf(f, \"%d %f %f\\n\", &in1, &in2, &in3)) {\n    posx[cnt] = in2;\n    posy[cnt] = in3;\n    cnt++;\n    if (cnt > cities) fprintf(stderr, \"input too long\\n\");\n    if (cnt != in1) fprintf(stderr, \"input line mismatch: expected %d instead of %d\\n\", cnt, in1);\n  }\n  if (cnt != cities) fprintf(stderr, \"read %d instead of %d cities\\n\", cnt, cities);\n\n  fscanf(f, \"%s\", str);\n  if (strcmp(str, \"EOF\") != 0) fprintf(stderr, \"didn't see 'EOF' at end of file\\n\");\n\n  fclose(f);\n\n  printf(\"configuration: %d cities, %d restarts, %s input\\n\", cities, restarts, argv[1]);\n\n  \n\n  \n\n  \n\n  float *posx_d, *posy_d;\n  int *glob_d;\n  int *climbs_d;\n  int *best_d;\n  int climbs = 0;\n  int best = INT_MAX;\n\n  cudaMalloc((void**)&climbs_d, sizeof(int));\n  cudaMalloc((void**)&best_d, sizeof(int));\n  cudaMalloc((void**)&posx_d, sizeof(float) * cities);\n  cudaMalloc((void**)&posy_d, sizeof(float) * cities);\n  cudaMalloc((void**)&glob_d, sizeof(int) * restarts * ((3 * cities + 2 + 31) / 32 * 32));\n\n  cudaMemcpy(posx_d, posx, sizeof(float) * cities, cudaMemcpyHostToDevice);\n  cudaMemcpy(posy_d, posy, sizeof(float) * cities, cudaMemcpyHostToDevice);\n\n  int threads = best_thread_count(cities);\n  printf(\"thread block size: %d\\n\", threads);\n\n  double ktime = 0.0;\n\n  for (int i = 0; i <= repeat; i++) {\n    cudaMemcpy(climbs_d, &climbs, sizeof(int), cudaMemcpyHostToDevice);\n    cudaMemcpy(best_d, &best, sizeof(int), cudaMemcpyHostToDevice);\n\n    auto kstart = std::chrono::steady_clock::now();\n\n    TwoOpt<<<restarts, threads, sizeof(int) * threads>>>(cities, posx_d, posy_d, glob_d, climbs_d, best_d);\n\n    cudaDeviceSynchronize();\n    auto kend = std::chrono::steady_clock::now();\n    if (i > 0)\n      ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n  }\n\n  cudaMemcpy(&best, best_d, sizeof(int), cudaMemcpyDeviceToHost);\n  cudaMemcpy(&climbs, climbs_d, sizeof(int), cudaMemcpyDeviceToHost);\n\n  long long moves = 1LL * climbs * (cities - 2) * (cities - 1) / 2;\n\n  printf(\"Average kernel time: %.4f s\\n\", ktime * 1e-9f / repeat);\n  printf(\"%.3f Gmoves/s\\n\", moves * repeat / ktime);\n  printf(\"Best found tour length is %d with %d climbers\\n\", best, climbs);\n\n  \n\n  if (best < 38000 && best >= 35002)\n    printf(\"PASS\\n\");\n  else\n    printf(\"FAIL\\n\");\n\n  cudaFree(glob_d);\n  cudaFree(best_d);\n  cudaFree(climbs_d);\n  cudaFree(posx_d);\n  cudaFree(posy_d);\n  free(posx);\n  free(posy);\n  return 0;\n}\n"}}
{"kernel_name": "tsp", "kernel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <limits.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define tilesize 128\n#define dist(a, b) int(sqrtf((px[a] - px[b]) * (px[a] - px[b]) + (py[a] - py[b]) * (py[a] - py[b])))\n#define swap(a, b) {float tmp = a;  a = b;  b = tmp;}\n\n__device__\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n__global__\nvoid TwoOpt(int cities, \n    const float *__restrict posx_d,\n    const float *__restrict posy_d,\n    int *__restrict glob_d,\n    int *__restrict climbs_d,\n    int *__restrict best_d)\n{\n  extern __shared__ int buf_s[];\n  __shared__ float px_s[tilesize];\n  __shared__ float py_s[tilesize];\n  __shared__ int bf_s[tilesize];\n\n  int *buf = &glob_d[blockIdx.x * ((3 * cities + 2 + 31) / 32 * 32)];\n  float *px = (float *)(&buf[cities]);\n  float *py = &px[cities + 1];\n\n  for (int i = threadIdx.x; i < cities; i += blockDim.x) px[i] = posx_d[i];\n  for (int i = threadIdx.x; i < cities; i += blockDim.x) py[i] = posy_d[i];\n  __syncthreads();\n\n  if (threadIdx.x == 0) {  \n\n    unsigned int seed = blockIdx.x;\n    for (unsigned int i = 1; i < cities; i++) {\n      int j = (int)(LCG_random(&seed) * (cities - 1)) + 1;\n      swap(px[i], px[j]);\n      swap(py[i], py[j]);\n    }\n    px[cities] = px[0];\n    py[cities] = py[0];\n  }\n  __syncthreads();\n\n  int minchange;\n  do {\n    for (int i = threadIdx.x; i < cities; i += blockDim.x) buf[i] = -dist(i, i + 1);\n    __syncthreads();\n\n    minchange = 0;\n    int mini = 1;\n    int minj = 0;\n    for (int ii = 0; ii < cities - 2; ii += blockDim.x) {\n      int i = ii + threadIdx.x;\n      float pxi0, pyi0, pxi1, pyi1, pxj1, pyj1;\n      if (i < cities - 2) {\n        minchange -= buf[i];\n        pxi0 = px[i];\n        pyi0 = py[i];\n        pxi1 = px[i + 1];\n        pyi1 = py[i + 1];\n        pxj1 = px[cities];\n        pyj1 = py[cities];\n      }\n      for (int jj = cities - 1; jj >= ii + 2; jj -= tilesize) {\n        int bound = jj - tilesize + 1;\n        for (int k = threadIdx.x; k < tilesize; k += blockDim.x) {\n          if (k + bound >= ii + 2) {\n            px_s[k] = px[k + bound];\n            py_s[k] = py[k + bound];\n            bf_s[k] = buf[k + bound];\n          }\n        }\n        __syncthreads();\n\n        int lower = bound;\n        if (lower < i + 2) lower = i + 2;\n        for (int j = jj; j >= lower; j--) {\n          int jm = j - bound;\n          float pxj0 = px_s[jm];\n          float pyj0 = py_s[jm];\n          int change = bf_s[jm]\n            + int(sqrtf((pxi0 - pxj0) * (pxi0 - pxj0) + (pyi0 - pyj0) * (pyi0 - pyj0)))\n            + int(sqrtf((pxi1 - pxj1) * (pxi1 - pxj1) + (pyi1 - pyj1) * (pyi1 - pyj1)));\n          pxj1 = pxj0;\n          pyj1 = pyj0;\n          if (minchange > change) {\n            minchange = change;\n            mini = i;\n            minj = j;\n          }\n        }\n        __syncthreads();\n      }\n\n      if (i < cities - 2) {\n        minchange += buf[i];\n      }\n    }\n    __syncthreads();\n\n    int change = buf_s[threadIdx.x] = minchange;\n    if (threadIdx.x == 0) atomicAdd(climbs_d, 1);  \n\n    __syncthreads();\n\n    int j = blockDim.x;\n    do {\n      int k = (j + 1) / 2;\n      if ((threadIdx.x + k) < j) {\n        int tmp = buf_s[threadIdx.x + k];\n        if (change > tmp) change = tmp;\n        buf_s[threadIdx.x] = change;\n      }\n      j = k;\n      __syncthreads();\n    } while (j > 1);\n\n    if (minchange == buf_s[0]) {\n      buf_s[1] = threadIdx.x;  \n\n    }\n    __syncthreads();\n\n    if (threadIdx.x == buf_s[1]) {\n      buf_s[2] = mini + 1;\n      buf_s[3] = minj;\n    }\n    __syncthreads();\n\n    minchange = buf_s[0];\n    mini = buf_s[2];\n    int sum = buf_s[3] + mini;\n    for (int i = threadIdx.x; (i + i) < sum; i += blockDim.x) {\n      if (mini <= i) {\n        int j = sum - i;\n        swap(px[i], px[j]);\n        swap(py[i], py[j]);\n      }\n    }\n    __syncthreads();\n  } while (minchange < 0);\n\n  int term = 0;\n  for (int i = threadIdx.x; i < cities; i += blockDim.x) {\n    term += dist(i, i + 1);\n  }\n  buf_s[threadIdx.x] = term;\n  __syncthreads();\n\n  int j = blockDim.x;\n  do {\n    int k = (j + 1) / 2;\n    if ((threadIdx.x + k) < j) {\n      term += buf_s[threadIdx.x + k];\n    }\n    __syncthreads();\n    if ((threadIdx.x + k) < j) {\n      buf_s[threadIdx.x] = term;\n    }\n    j = k;\n    __syncthreads();\n  } while (j > 1);\n\n  if (threadIdx.x == 0) {\n    atomicMin(best_d, term);\n  }\n}\n\n\n\n\n\n\n\n\nstatic int best_thread_count(int cities)\n{\n  int max, best, threads, smem, blocks, thr, perf, bthr;\n\n  max = cities - 2;\n  if (max > 256) max = 256;\n  best = 0;\n  bthr = 4;\n  for (threads = 1; threads <= max; threads++) {\n    smem = sizeof(int) * threads + 2 * sizeof(float) * tilesize + sizeof(int) * tilesize;\n    blocks = (16384 * 2) / smem;\n    if (blocks > 16) blocks = 16;\n    thr = (threads + 31) / 32 * 32;\n    while (blocks * thr > 2048) blocks--;\n    perf = threads * blocks;\n    if (perf > best) {\n      best = perf;\n      bthr = threads;\n    }\n  }\n\n  return bthr;\n}\n\nint main(int argc, char *argv[])\n{\n  printf(\"2-opt TSP HIP GPU code v2.3\\n\");\n  printf(\"Copyright (c) 2014-2020, Texas State University. All rights reserved.\\n\");\n\n  if (argc != 4) {\n    fprintf(stderr, \"\\narguments: <input_file> <restart_count> <repeat>\\n\");\n    exit(-1);\n  }\n\n  FILE *f = fopen(argv[1], \"rt\");\n  if (f == NULL) {fprintf(stderr, \"could not open file %s\\n\", argv[1]);  exit(-1);}\n\n  int restarts = atoi(argv[2]);\n  if (restarts < 1) {fprintf(stderr, \"restart_count is too small: %d\\n\", restarts); exit(-1);}\n\n  int repeat = atoi(argv[3]);\n\n  \n\n  \n\n  \n\n  int ch, in1;\n  float in2, in3;\n  char str[256];\n\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != ':')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n\n  int cities = atoi(str);\n  if (cities < 100) {\n    fprintf(stderr, \"the problem size must be at least 100 for this version of the code\\n\");\n    fclose(f);\n    exit(-1);\n  } \n\n  ch = getc(f); \n  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n  if (strcmp(str, \"NODE_COORD_SECTION\") != 0) {\n    fprintf(stderr, \"wrong file format\\n\");\n    fclose(f);\n    exit(-1);\n  }\n\n  float *posx = (float *)malloc(sizeof(float) * cities);\n  if (posx == NULL) fprintf(stderr, \"cannot allocate posx\\n\");\n  float *posy = (float *)malloc(sizeof(float) * cities);\n  if (posy == NULL) fprintf(stderr, \"cannot allocate posy\\n\");\n\n  int cnt = 0;\n  while (fscanf(f, \"%d %f %f\\n\", &in1, &in2, &in3)) {\n    posx[cnt] = in2;\n    posy[cnt] = in3;\n    cnt++;\n    if (cnt > cities) fprintf(stderr, \"input too long\\n\");\n    if (cnt != in1) fprintf(stderr, \"input line mismatch: expected %d instead of %d\\n\", cnt, in1);\n  }\n  if (cnt != cities) fprintf(stderr, \"read %d instead of %d cities\\n\", cnt, cities);\n\n  fscanf(f, \"%s\", str);\n  if (strcmp(str, \"EOF\") != 0) fprintf(stderr, \"didn't see 'EOF' at end of file\\n\");\n\n  fclose(f);\n\n  printf(\"configuration: %d cities, %d restarts, %s input\\n\", cities, restarts, argv[1]);\n\n  \n\n  \n\n  \n\n  float *posx_d, *posy_d;\n  int *glob_d;\n  int *climbs_d;\n  int *best_d;\n  int climbs = 0;\n  int best = INT_MAX;\n\n  hipMalloc((void**)&climbs_d, sizeof(int));\n  hipMalloc((void**)&best_d, sizeof(int));\n  hipMalloc((void**)&posx_d, sizeof(float) * cities);\n  hipMalloc((void**)&posy_d, sizeof(float) * cities);\n  hipMalloc((void**)&glob_d, sizeof(int) * restarts * ((3 * cities + 2 + 31) / 32 * 32));\n\n  hipMemcpy(posx_d, posx, sizeof(float) * cities, hipMemcpyHostToDevice);\n  hipMemcpy(posy_d, posy, sizeof(float) * cities, hipMemcpyHostToDevice);\n\n  int threads = best_thread_count(cities);\n  printf(\"thread block size: %d\\n\", threads);\n\n  double ktime = 0.0;\n\n  for (int i = 0; i <= repeat; i++) {\n    hipMemcpy(climbs_d, &climbs, sizeof(int), hipMemcpyHostToDevice);\n    hipMemcpy(best_d, &best, sizeof(int), hipMemcpyHostToDevice);\n\n    auto kstart = std::chrono::steady_clock::now();\n\n    TwoOpt<<<restarts, threads, sizeof(int) * threads>>>(cities, posx_d, posy_d, glob_d, climbs_d, best_d);\n\n    hipDeviceSynchronize();\n    auto kend = std::chrono::steady_clock::now();\n    if (i > 0)\n      ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n  }\n\n  hipMemcpy(&best, best_d, sizeof(int), hipMemcpyDeviceToHost);\n  hipMemcpy(&climbs, climbs_d, sizeof(int), hipMemcpyDeviceToHost);\n\n  long long moves = 1LL * climbs * (cities - 2) * (cities - 1) / 2;\n\n  printf(\"Average kernel time: %.4f s\\n\", ktime * 1e-9f / repeat);\n  printf(\"%.3f Gmoves/s\\n\", moves * repeat / ktime);\n  printf(\"Best found tour length is %d with %d climbers\\n\", best, climbs);\n\n  \n\n  if (best < 38000 && best >= 35002)\n    printf(\"PASS\\n\");\n  else\n    printf(\"FAIL\\n\");\n\n  hipFree(glob_d);\n  hipFree(best_d);\n  hipFree(climbs_d);\n  hipFree(posx_d);\n  hipFree(posy_d);\n  free(posx);\n  free(posy);\n  return 0;\n}\n"}}
{"kernel_name": "tsp", "kernel_api": "omp", "code": {"main.cpp": "\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <limits.h>\n#include <chrono>\n#include <omp.h>\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define tilesize 128\n#define dist(a, b) int(sqrtf((px[a] - px[b]) * (px[a] - px[b]) + (py[a] - py[b]) * (py[a] - py[b])))\n#define swap(a, b) {float tmp = a;  a = b;  b = tmp;}\n\n#pragma omp declare target\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n#pragma omp end declare target\n\n\n\n\n\n\n\n\nstatic int best_thread_count(int cities)\n{\n  int max, best, threads, smem, blocks, thr, perf, bthr;\n\n  max = cities - 2;\n  if (max > 256) max = 256;\n  best = 0;\n  bthr = 4;\n  for (threads = 1; threads <= max; threads++) {\n    smem = sizeof(int) * threads + 2 * sizeof(float) * tilesize + sizeof(int) * tilesize;\n    blocks = (16384 * 2) / smem;\n    if (blocks > 16) blocks = 16;\n    thr = (threads + 31) / 32 * 32;\n    while (blocks * thr > 2048) blocks--;\n    perf = threads * blocks;\n    if (perf > best) {\n      best = perf;\n      bthr = threads;\n    }\n  }\n\n  return bthr;\n}\n\nint main(int argc, char *argv[])\n{\n  printf(\"2-opt TSP OpenMP target offloading GPU code v2.3\\n\");\n  printf(\"Copyright (c) 2014-2020, Texas State University. All rights reserved.\\n\");\n\n  if (argc != 4) {\n    fprintf(stderr, \"\\narguments: <input_file> <restart_count> <repeat>\\n\");\n    exit(-1);\n  }\n\n  FILE *f = fopen(argv[1], \"rt\");\n  if (f == NULL) {fprintf(stderr, \"could not open file %s\\n\", argv[1]);  exit(-1);}\n\n  int restarts = atoi(argv[2]);\n  if (restarts < 1) {fprintf(stderr, \"restart_count is too small: %d\\n\", restarts); exit(-1);}\n\n  int repeat = atoi(argv[3]);\n\n  \n\n  \n\n  \n\n  int ch, in1;\n  float in2, in3;\n  char str[256];\n\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != ':')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n\n  int cities = atoi(str);\n  if (cities < 100) {\n    fprintf(stderr, \"the problem size must be at least 100 for this version of the code\\n\");\n    fclose(f);\n    exit(-1);\n  } \n\n  ch = getc(f); \n  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n  if (strcmp(str, \"NODE_COORD_SECTION\") != 0) {\n    fprintf(stderr, \"wrong file format\\n\");\n    fclose(f);\n    exit(-1);\n  }\n\n  float *posx = (float *)malloc(sizeof(float) * cities);\n  if (posx == NULL) fprintf(stderr, \"cannot allocate posx\\n\");\n  float *posy = (float *)malloc(sizeof(float) * cities);\n  if (posy == NULL) fprintf(stderr, \"cannot allocate posy\\n\");\n\n  int cnt = 0;\n  while (fscanf(f, \"%d %f %f\\n\", &in1, &in2, &in3)) {\n    posx[cnt] = in2;\n    posy[cnt] = in3;\n    cnt++;\n    if (cnt > cities) fprintf(stderr, \"input too long\\n\");\n    if (cnt != in1) fprintf(stderr, \"input line mismatch: expected %d instead of %d\\n\", cnt, in1);\n  }\n  if (cnt != cities) fprintf(stderr, \"read %d instead of %d cities\\n\", cnt, cities);\n\n  fscanf(f, \"%s\", str);\n  if (strcmp(str, \"EOF\") != 0) fprintf(stderr, \"didn't see 'EOF' at end of file\\n\");\n\n  fclose(f);\n\n  printf(\"configuration: %d cities, %d restarts, %s input\\n\", cities, restarts, argv[1]);\n\n  \n\n  \n\n  \n\n  int climbs[1] = {0};\n  int best[1] = {INT_MAX};\n\n  const int glob_size = restarts * ((3 * cities + 2 + 31) / 32 * 32);\n  int* glob = (int*) malloc (sizeof(int) * glob_size); \n\n  #pragma omp target data map(to: posx[0:cities], posy[0:cities]) \\\n                          map(alloc: glob[0:glob_size]) \\\n                          map(alloc: climbs[0:1], best[0:1])\n  {\n\n  int threads = best_thread_count(cities);\n  printf(\"number of threads per team: %d\\n\", threads);\n\n  double ktime = 0.0;\n\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target update to (climbs[0:1])\n    #pragma omp target update to (best[0:1])\n\n    auto kstart = std::chrono::steady_clock::now();\n\n    #pragma omp target teams num_teams(restarts) thread_limit(threads)\n    {\n      float px_s[tilesize];\n      float py_s[tilesize];\n      float bf_s[tilesize];\n      float buf_s[128];\n      #pragma omp parallel \n      {\n        const int lid = omp_get_thread_num();\n        const int bid = omp_get_team_num();\n        const int dim = omp_get_num_threads();\n\n        int *buf = &glob[bid * ((3 * cities + 2 + 31) / 32 * 32)];\n        float *px = (float *)(&buf[cities]);\n        float *py = &px[cities + 1];\n\n        for (int i = lid; i < cities; i += dim) px[i] = posx[i];\n        for (int i = lid; i < cities; i += dim) py[i] = posy[i];\n        #pragma omp barrier\n\n        if (lid == 0) {  \n\n          unsigned int seed = bid;\n          for (unsigned int i = 1; i < cities; i++) {\n            int j = (int)(LCG_random(&seed) * (cities - 1)) + 1;\n            swap(px[i], px[j]);\n            swap(py[i], py[j]);\n          }\n          px[cities] = px[0];\n          py[cities] = py[0];\n        }\n        #pragma omp barrier\n\n        int minchange;\n        do {\n          for (int i = lid; i < cities; i += dim) buf[i] = -dist(i, i + 1);\n          #pragma omp barrier\n\n          minchange = 0;\n          int mini = 1;\n          int minj = 0;\n          for (int ii = 0; ii < cities - 2; ii += dim) {\n            int i = ii + lid;\n            float pxi0, pyi0, pxi1, pyi1, pxj1, pyj1;\n            if (i < cities - 2) {\n              minchange -= buf[i];\n              pxi0 = px[i];\n              pyi0 = py[i];\n              pxi1 = px[i + 1];\n              pyi1 = py[i + 1];\n              pxj1 = px[cities];\n              pyj1 = py[cities];\n            }\n            for (int jj = cities - 1; jj >= ii + 2; jj -= tilesize) {\n              int bound = jj - tilesize + 1;\n              for (int k = lid; k < tilesize; k += dim) {\n                if (k + bound >= ii + 2) {\n                  px_s[k] = px[k + bound];\n                  py_s[k] = py[k + bound];\n                  bf_s[k] = buf[k + bound];\n                }\n              }\n              #pragma omp barrier\n\n              int lower = bound;\n              if (lower < i + 2) lower = i + 2;\n              for (int j = jj; j >= lower; j--) {\n                int jm = j - bound;\n                float pxj0 = px_s[jm];\n                float pyj0 = py_s[jm];\n                int change = bf_s[jm]\n                  + int(sqrtf((pxi0 - pxj0) * (pxi0 - pxj0) + (pyi0 - pyj0) * (pyi0 - pyj0)))\n                  + int(sqrtf((pxi1 - pxj1) * (pxi1 - pxj1) + (pyi1 - pyj1) * (pyi1 - pyj1)));\n                pxj1 = pxj0;\n                pyj1 = pyj0;\n                if (minchange > change) {\n                  minchange = change;\n                  mini = i;\n                  minj = j;\n                }\n              }\n              #pragma omp barrier\n            }\n\n            if (i < cities - 2) {\n              minchange += buf[i];\n            }\n          }\n          #pragma omp barrier\n\n          int change = buf_s[lid] = minchange;\n          if (lid == 0) {\n            #pragma omp atomic\n            climbs[0]++;\n          }\n          #pragma omp barrier\n\n          int j = dim;\n          do {\n            int k = (j + 1) / 2;\n            if ((lid + k) < j) {\n              int tmp = buf_s[lid + k];\n              if (change > tmp) change = tmp;\n              buf_s[lid] = change;\n            }\n            j = k;\n            #pragma omp barrier\n          } while (j > 1);\n\n          if (minchange == buf_s[0]) {\n            buf_s[1] = lid;  \n\n          }\n          #pragma omp barrier\n\n          if (lid == buf_s[1]) {\n            buf_s[2] = mini + 1;\n            buf_s[3] = minj;\n          }\n          #pragma omp barrier\n\n          minchange = buf_s[0];\n          mini = buf_s[2];\n          int sum = buf_s[3] + mini;\n          for (int i = lid; (i + i) < sum; i += dim) {\n            if (mini <= i) {\n              int j = sum - i;\n              swap(px[i], px[j]);\n              swap(py[i], py[j]);\n            }\n          }\n          #pragma omp barrier\n        } while (minchange < 0);\n\n        int term = 0;\n        for (int i = lid; i < cities; i += dim) {\n          term += dist(i, i + 1);\n        }\n        buf_s[lid] = term;\n        #pragma omp barrier\n\n        int j = dim;\n        do {\n          int k = (j + 1) / 2;\n          if ((lid + k) < j) {\n            term += buf_s[lid + k];\n          }\n          #pragma omp barrier\n          if ((lid + k) < j) {\n            buf_s[lid] = term;\n          }\n          j = k;\n          #pragma omp barrier\n        } while (j > 1);\n\n        if (lid == 0) {\n          int t;\n          #pragma omp atomic capture\n          {\n            t = best[0];\n            best[0] = (term < best[0]) ? term : best[0];\n          }\n        }\n      }\n    }\n\n    auto kend = std::chrono::steady_clock::now();\n    if (i > 0)\n      ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n  }\n\n  #pragma omp target update from (climbs[0:1])\n  #pragma omp target update from (best[0:1])\n\n  long long moves = 1LL * climbs[0] * (cities - 2) * (cities - 1) / 2;\n\n  printf(\"Average kernel time: %.4f s\\n\", ktime * 1e-9f / repeat);\n  printf(\"%.3f Gmoves/s\\n\", moves * repeat / ktime);\n  printf(\"Best found tour length is %d with %d climbers\\n\", best[0], climbs[0]);\n\n  \n\n  if (best[0] < 38000 && best[0] >= 35002)\n    printf(\"PASS\\n\");\n  else\n    printf(\"FAIL\\n\");\n\n  }\n\n  free(posx);\n  free(posy);\n  free(glob);\n  return 0;\n}\n"}}
{"kernel_name": "tsp", "kernel_api": "serial", "code": {"main.cpp": "\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <limits.h>\n#include <chrono>\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define tilesize 128\n#define dist(a, b) int(sqrtf((px[a] - px[b]) * (px[a] - px[b]) + (py[a] - py[b]) * (py[a] - py[b])))\n#define swap(a, b) {float tmp = a;  a = b;  b = tmp;}\n\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n\n\n\n\n\n\n\nstatic int best_thread_count(int cities)\n{\n  int max, best, threads, smem, blocks, thr, perf, bthr;\n\n  max = cities - 2;\n  if (max > 256) max = 256;\n  best = 0;\n  bthr = 4;\n  for (threads = 1; threads <= max; threads++) {\n    smem = sizeof(int) * threads + 2 * sizeof(float) * tilesize + sizeof(int) * tilesize;\n    blocks = (16384 * 2) / smem;\n    if (blocks > 16) blocks = 16;\n    thr = (threads + 31) / 32 * 32;\n    while (blocks * thr > 2048) blocks--;\n    perf = threads * blocks;\n    if (perf > best) {\n      best = perf;\n      bthr = threads;\n    }\n  }\n\n  return bthr;\n}\n\nint main(int argc, char *argv[])\n{\n  printf(\"2-opt TSP OpenMP target offloading GPU code v2.3\\n\");\n  printf(\"Copyright (c) 2014-2020, Texas State University. All rights reserved.\\n\");\n\n  if (argc != 4) {\n    fprintf(stderr, \"\\narguments: <input_file> <restart_count> <repeat>\\n\");\n    exit(-1);\n  }\n\n  FILE *f = fopen(argv[1], \"rt\");\n  if (f == NULL) {fprintf(stderr, \"could not open file %s\\n\", argv[1]);  exit(-1);}\n\n  int restarts = atoi(argv[2]);\n  if (restarts < 1) {fprintf(stderr, \"restart_count is too small: %d\\n\", restarts); exit(-1);}\n\n  int repeat = atoi(argv[3]);\n\n  \n\n  \n\n  \n\n  int ch, in1;\n  float in2, in3;\n  char str[256];\n\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != ':')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n\n  int cities = atoi(str);\n  if (cities < 100) {\n    fprintf(stderr, \"the problem size must be at least 100 for this version of the code\\n\");\n    fclose(f);\n    exit(-1);\n  } \n\n  ch = getc(f); \n  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n  if (strcmp(str, \"NODE_COORD_SECTION\") != 0) {\n    fprintf(stderr, \"wrong file format\\n\");\n    fclose(f);\n    exit(-1);\n  }\n\n  float *posx = (float *)malloc(sizeof(float) * cities);\n  if (posx == NULL) fprintf(stderr, \"cannot allocate posx\\n\");\n  float *posy = (float *)malloc(sizeof(float) * cities);\n  if (posy == NULL) fprintf(stderr, \"cannot allocate posy\\n\");\n\n  int cnt = 0;\n  while (fscanf(f, \"%d %f %f\\n\", &in1, &in2, &in3)) {\n    posx[cnt] = in2;\n    posy[cnt] = in3;\n    cnt++;\n    if (cnt > cities) fprintf(stderr, \"input too long\\n\");\n    if (cnt != in1) fprintf(stderr, \"input line mismatch: expected %d instead of %d\\n\", cnt, in1);\n  }\n  if (cnt != cities) fprintf(stderr, \"read %d instead of %d cities\\n\", cnt, cities);\n\n  fscanf(f, \"%s\", str);\n  if (strcmp(str, \"EOF\") != 0) fprintf(stderr, \"didn't see 'EOF' at end of file\\n\");\n\n  fclose(f);\n\n  printf(\"configuration: %d cities, %d restarts, %s input\\n\", cities, restarts, argv[1]);\n\n  \n\n  \n\n  \n\n  int climbs[1] = {0};\n  int best[1] = {INT_MAX};\n\n  const int glob_size = restarts * ((3 * cities + 2 + 31) / 32 * 32);\n  int* glob = (int*) malloc (sizeof(int) * glob_size); \n\n    {\n\n  int threads = best_thread_count(cities);\n  printf(\"number of threads per team: %d\\n\", threads);\n\n  double ktime = 0.0;\n\n  for (int i = 0; i < repeat; i++) {\n        \n    auto kstart = std::chrono::steady_clock::now();\n\n        {\n      float px_s[tilesize];\n      float py_s[tilesize];\n      float bf_s[tilesize];\n      float buf_s[128];\n            {\n        const int lid = omp_get_thread_num();\n        const int bid = omp_get_team_num();\n        const int dim = omp_get_num_threads();\n\n        int *buf = &glob[bid * ((3 * cities + 2 + 31) / 32 * 32)];\n        float *px = (float *)(&buf[cities]);\n        float *py = &px[cities + 1];\n\n        for (int i = lid; i < cities; i += dim) px[i] = posx[i];\n        for (int i = lid; i < cities; i += dim) py[i] = posy[i];\n        \n        if (lid == 0) {  \n\n          unsigned int seed = bid;\n          for (unsigned int i = 1; i < cities; i++) {\n            int j = (int)(LCG_random(&seed) * (cities - 1)) + 1;\n            swap(px[i], px[j]);\n            swap(py[i], py[j]);\n          }\n          px[cities] = px[0];\n          py[cities] = py[0];\n        }\n        \n        int minchange;\n        do {\n          for (int i = lid; i < cities; i += dim) buf[i] = -dist(i, i + 1);\n          \n          minchange = 0;\n          int mini = 1;\n          int minj = 0;\n          for (int ii = 0; ii < cities - 2; ii += dim) {\n            int i = ii + lid;\n            float pxi0, pyi0, pxi1, pyi1, pxj1, pyj1;\n            if (i < cities - 2) {\n              minchange -= buf[i];\n              pxi0 = px[i];\n              pyi0 = py[i];\n              pxi1 = px[i + 1];\n              pyi1 = py[i + 1];\n              pxj1 = px[cities];\n              pyj1 = py[cities];\n            }\n            for (int jj = cities - 1; jj >= ii + 2; jj -= tilesize) {\n              int bound = jj - tilesize + 1;\n              for (int k = lid; k < tilesize; k += dim) {\n                if (k + bound >= ii + 2) {\n                  px_s[k] = px[k + bound];\n                  py_s[k] = py[k + bound];\n                  bf_s[k] = buf[k + bound];\n                }\n              }\n              \n              int lower = bound;\n              if (lower < i + 2) lower = i + 2;\n              for (int j = jj; j >= lower; j--) {\n                int jm = j - bound;\n                float pxj0 = px_s[jm];\n                float pyj0 = py_s[jm];\n                int change = bf_s[jm]\n                  + int(sqrtf((pxi0 - pxj0) * (pxi0 - pxj0) + (pyi0 - pyj0) * (pyi0 - pyj0)))\n                  + int(sqrtf((pxi1 - pxj1) * (pxi1 - pxj1) + (pyi1 - pyj1) * (pyi1 - pyj1)));\n                pxj1 = pxj0;\n                pyj1 = pyj0;\n                if (minchange > change) {\n                  minchange = change;\n                  mini = i;\n                  minj = j;\n                }\n              }\n                          }\n\n            if (i < cities - 2) {\n              minchange += buf[i];\n            }\n          }\n          \n          int change = buf_s[lid] = minchange;\n          if (lid == 0) {\n                        climbs[0]++;\n          }\n          \n          int j = dim;\n          do {\n            int k = (j + 1) / 2;\n            if ((lid + k) < j) {\n              int tmp = buf_s[lid + k];\n              if (change > tmp) change = tmp;\n              buf_s[lid] = change;\n            }\n            j = k;\n                      } while (j > 1);\n\n          if (minchange == buf_s[0]) {\n            buf_s[1] = lid;  \n\n          }\n          \n          if (lid == buf_s[1]) {\n            buf_s[2] = mini + 1;\n            buf_s[3] = minj;\n          }\n          \n          minchange = buf_s[0];\n          mini = buf_s[2];\n          int sum = buf_s[3] + mini;\n          for (int i = lid; (i + i) < sum; i += dim) {\n            if (mini <= i) {\n              int j = sum - i;\n              swap(px[i], px[j]);\n              swap(py[i], py[j]);\n            }\n          }\n                  } while (minchange < 0);\n\n        int term = 0;\n        for (int i = lid; i < cities; i += dim) {\n          term += dist(i, i + 1);\n        }\n        buf_s[lid] = term;\n        \n        int j = dim;\n        do {\n          int k = (j + 1) / 2;\n          if ((lid + k) < j) {\n            term += buf_s[lid + k];\n          }\n                    if ((lid + k) < j) {\n            buf_s[lid] = term;\n          }\n          j = k;\n                  } while (j > 1);\n\n        if (lid == 0) {\n          int t;\n                    {\n            t = best[0];\n            best[0] = (term < best[0]) ? term : best[0];\n          }\n        }\n      }\n    }\n\n    auto kend = std::chrono::steady_clock::now();\n    if (i > 0)\n      ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n  }\n\n    \n  long long moves = 1LL * climbs[0] * (cities - 2) * (cities - 1) / 2;\n\n  printf(\"Average kernel time: %.4f s\\n\", ktime * 1e-9f / repeat);\n  printf(\"%.3f Gmoves/s\\n\", moves * repeat / ktime);\n  printf(\"Best found tour length is %d with %d climbers\\n\", best[0], climbs[0]);\n\n  \n\n  if (best[0] < 38000 && best[0] >= 35002)\n    printf(\"PASS\\n\");\n  else\n    printf(\"FAIL\\n\");\n\n  }\n\n  free(posx);\n  free(posy);\n  free(glob);\n  return 0;\n}"}}
{"kernel_name": "tsp", "kernel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <limits.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define tilesize 128\n#define dist(a, b) int(sycl::sqrt((px[a] - px[b]) * (px[a] - px[b]) + (py[a] - py[b]) * (py[a] - py[b])))\n#define swap(a, b) {float tmp = a;  a = b;  b = tmp;}\n\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n\n\n\n\n\n\n\nstatic int best_thread_count(int cities)\n{\n  int max, best, threads, smem, blocks, thr, perf, bthr;\n\n  max = cities - 2;\n  if (max > 256) max = 256;\n  best = 0;\n  bthr = 4;\n  for (threads = 1; threads <= max; threads++) {\n    smem = sizeof(int) * threads + 2 * sizeof(float) * tilesize + sizeof(int) * tilesize;\n    blocks = (16384 * 2) / smem;\n    if (blocks > 16) blocks = 16;\n    thr = (threads + 31) / 32 * 32;\n    while (blocks * thr > 2048) blocks--;\n    perf = threads * blocks;\n    if (perf > best) {\n      best = perf;\n      bthr = threads;\n    }\n  }\n\n  return bthr;\n}\n\ninline int atomicAdd(int &var, int val) \n{\n  auto atm = sycl::atomic_ref<int,\n    sycl::memory_order::relaxed,\n    sycl::memory_scope::device,\n    sycl::access::address_space::global_space>(var);\n  return atm.fetch_add(val);\n}\n\ninline int atomicMin(int &var, int val) \n{\n  auto atm = sycl::atomic_ref<int,\n    sycl::memory_order::relaxed,\n    sycl::memory_scope::device,\n    sycl::access::address_space::global_space>(var);\n  return atm.fetch_min(val);\n}\n\nint main(int argc, char *argv[])\n{\n  printf(\"2-opt TSP SYCL GPU code v2.3\\n\");\n  printf(\"Copyright (c) 2014-2020, Texas State University. All rights reserved.\\n\");\n\n  if (argc != 4) {\n    fprintf(stderr, \"\\narguments: <input_file> <restart_count> <repeat>\\n\");\n    exit(-1);\n  }\n\n  FILE *f = fopen(argv[1], \"rt\");\n  if (f == NULL) {fprintf(stderr, \"could not open file %s\\n\", argv[1]);  exit(-1);}\n\n  int restarts = atoi(argv[2]);\n  if (restarts < 1) {fprintf(stderr, \"restart_count is too small: %d\\n\", restarts); exit(-1);}\n\n  int repeat = atoi(argv[3]);\n\n  \n\n  \n\n  \n\n  int ch, in1;\n  float in2, in3;\n  char str[256];\n\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  ch = getc(f);  while ((ch != EOF) && (ch != ':')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n\n  int cities = atoi(str);\n  if (cities < 100) {\n    fprintf(stderr, \"the problem size must be at least 100 for this version of the code\\n\");\n    fclose(f);\n    exit(-1);\n  }\n\n  ch = getc(f);\n  while ((ch != EOF) && (ch != '\\n')) ch = getc(f);\n  fscanf(f, \"%s\\n\", str);\n  if (strcmp(str, \"NODE_COORD_SECTION\") != 0) {\n    fprintf(stderr, \"wrong file format\\n\");\n    fclose(f);\n    exit(-1);\n  }\n\n  float *posx = (float *)malloc(sizeof(float) * cities);\n  if (posx == NULL) fprintf(stderr, \"cannot allocate posx\\n\");\n  float *posy = (float *)malloc(sizeof(float) * cities);\n  if (posy == NULL) fprintf(stderr, \"cannot allocate posy\\n\");\n\n  int cnt = 0;\n  while (fscanf(f, \"%d %f %f\\n\", &in1, &in2, &in3)) {\n    posx[cnt] = in2;\n    posy[cnt] = in3;\n    cnt++;\n    if (cnt > cities) fprintf(stderr, \"input too long\\n\");\n    if (cnt != in1) fprintf(stderr, \"input line mismatch: expected %d instead of %d\\n\", cnt, in1);\n  }\n  if (cnt != cities) fprintf(stderr, \"read %d instead of %d cities\\n\", cnt, cities);\n\n  fscanf(f, \"%s\", str);\n  if (strcmp(str, \"EOF\") != 0) fprintf(stderr, \"didn't see 'EOF' at end of file\\n\");\n\n  fclose(f);\n\n  printf(\"configuration: %d cities, %d restarts, %s input\\n\", cities, restarts, argv[1]);\n\n  \n\n  \n\n  \n\n  int climbs = 0;\n  int best = INT_MAX;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *climbs_d = sycl::malloc_device<int>(1, q);\n  int *best_d = sycl::malloc_device<int>(1, q);\n  int *glob_d = sycl::malloc_device<int>(restarts * (3 * cities + 2 + 31) / 32 * 32, q);\n\n  float *posx_d = sycl::malloc_device<float>(cities, q);\n  q.memcpy(posx_d, posx, sizeof(float) * cities);\n\n  float *posy_d = sycl::malloc_device<float>(cities, q);\n  q.memcpy(posy_d, posy, sizeof(float) * cities);\n\n  int threads = best_thread_count(cities);\n  printf(\"work-group size: %d\\n\", threads);\n\n  sycl::range<1> gws (restarts * threads);\n  sycl::range<1> lws (threads);\n\n  double ktime = 0.0;\n\n  for (int i = 0; i <= repeat; i++) {\n    q.memcpy(climbs_d, &climbs, sizeof(int));\n    q.memcpy(best_d, &best, sizeof(int));\n\n    q.wait();\n    auto kstart = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> px_s(sycl::range<1>(tilesize), cgh);\n      sycl::local_accessor<float, 1> py_s(sycl::range<1>(tilesize), cgh);\n      sycl::local_accessor<int, 1> bf_s(sycl::range<1>(tilesize), cgh);\n      sycl::local_accessor<int, 1> buf_s(sycl::range<1>(threads), cgh);\n      cgh.parallel_for<class k>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        const int lid = item.get_local_id(0);\n        const int bid = item.get_group(0);\n        const int dim = item.get_local_range(0);\n\n        int *buf = &glob_d[bid * ((3 * cities + 2 + 31) / 32 * 32)];\n        float *px = (float *)(&buf[cities]);\n        float *py = &px[cities + 1];\n\n        for (int i = lid; i < cities; i += dim) px[i] = posx_d[i];\n        for (int i = lid; i < cities; i += dim) py[i] = posy_d[i];\n        item.barrier(sycl::access::fence_space::local_space);\n\n        if (lid == 0) {  \n\n          unsigned int seed = bid;\n          for (unsigned int i = 1; i < cities; i++) {\n            int j = (int)(LCG_random(&seed) * (cities - 1)) + 1;\n            swap(px[i], px[j]);\n            swap(py[i], py[j]);\n          }\n          px[cities] = px[0];\n          py[cities] = py[0];\n        }\n        item.barrier(sycl::access::fence_space::local_space);\n\n        int minchange;\n        do {\n          for (int i = lid; i < cities; i += dim) buf[i] = -dist(i, i + 1);\n          item.barrier(sycl::access::fence_space::local_space);\n\n          minchange = 0;\n          int mini = 1;\n          int minj = 0;\n          for (int ii = 0; ii < cities - 2; ii += dim) {\n            int i = ii + lid;\n            float pxi0, pyi0, pxi1, pyi1, pxj1, pyj1;\n            if (i < cities - 2) {\n              minchange -= buf[i];\n              pxi0 = px[i];\n              pyi0 = py[i];\n              pxi1 = px[i + 1];\n              pyi1 = py[i + 1];\n              pxj1 = px[cities];\n              pyj1 = py[cities];\n            }\n            for (int jj = cities - 1; jj >= ii + 2; jj -= tilesize) {\n              int bound = jj - tilesize + 1;\n              for (int k = lid; k < tilesize; k += dim) {\n                if (k + bound >= ii + 2) {\n                  px_s[k] = px[k + bound];\n                  py_s[k] = py[k + bound];\n                  bf_s[k] = buf[k + bound];\n                }\n              }\n              item.barrier(sycl::access::fence_space::local_space);\n\n              int lower = bound;\n              if (lower < i + 2) lower = i + 2;\n              for (int j = jj; j >= lower; j--) {\n                int jm = j - bound;\n                float pxj0 = px_s[jm];\n                float pyj0 = py_s[jm];\n                int change = bf_s[jm]\n                  + int(sycl::sqrt((pxi0 - pxj0) * (pxi0 - pxj0) + (pyi0 - pyj0) * (pyi0 - pyj0)))\n                  + int(sycl::sqrt((pxi1 - pxj1) * (pxi1 - pxj1) + (pyi1 - pyj1) * (pyi1 - pyj1)));\n                pxj1 = pxj0;\n                pyj1 = pyj0;\n                if (minchange > change) {\n                  minchange = change;\n                  mini = i;\n                  minj = j;\n                }\n              }\n              item.barrier(sycl::access::fence_space::local_space);\n            }\n\n            if (i < cities - 2) {\n              minchange += buf[i];\n            }\n          }\n          item.barrier(sycl::access::fence_space::local_space);\n\n          int change = buf_s[lid] = minchange;\n          if (lid == 0) atomicAdd(climbs_d[0], 1);  \n\n          item.barrier(sycl::access::fence_space::local_space);\n\n          int j = dim;\n          do {\n            int k = (j + 1) / 2;\n            if ((lid + k) < j) {\n              int tmp = buf_s[lid + k];\n              if (change > tmp) change = tmp;\n              buf_s[lid] = change;\n            }\n            j = k;\n            item.barrier(sycl::access::fence_space::local_space);\n          } while (j > 1);\n\n          if (minchange == buf_s[0]) {\n            buf_s[1] = lid;  \n\n          }\n          item.barrier(sycl::access::fence_space::local_space);\n\n          if (lid == buf_s[1]) {\n            buf_s[2] = mini + 1;\n            buf_s[3] = minj;\n          }\n          item.barrier(sycl::access::fence_space::local_space);\n\n          minchange = buf_s[0];\n          mini = buf_s[2];\n          int sum = buf_s[3] + mini;\n          for (int i = lid; (i + i) < sum; i += dim) {\n            if (mini <= i) {\n              int j = sum - i;\n              swap(px[i], px[j]);\n              swap(py[i], py[j]);\n            }\n          }\n          item.barrier(sycl::access::fence_space::local_space);\n        } while (minchange < 0);\n\n        int term = 0;\n        for (int i = lid; i < cities; i += dim) {\n          term += dist(i, i + 1);\n        }\n        buf_s[lid] = term;\n        item.barrier(sycl::access::fence_space::local_space);\n\n        int j = dim;\n        do {\n          int k = (j + 1) / 2;\n          if ((lid + k) < j) {\n            term += buf_s[lid + k];\n          }\n          item.barrier(sycl::access::fence_space::local_space);\n          if ((lid + k) < j) {\n            buf_s[lid] = term;\n          }\n          j = k;\n          item.barrier(sycl::access::fence_space::local_space);\n        } while (j > 1);\n\n        if (lid == 0) {\n          atomicMin(best_d[0], term);\n        }\n      });\n    });\n\n    q.wait();\n    auto kend = std::chrono::steady_clock::now();\n    if (i > 0)\n      ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n  }\n\n  q.memcpy(&best, best_d, sizeof(int));\n  q.memcpy(&climbs, climbs_d, sizeof(int));\n  q.wait();\n\n  long long moves = 1LL * climbs * (cities - 2) * (cities - 1) / 2;\n\n  printf(\"Average kernel time: %.4f s\\n\", ktime * 1e-9f / repeat);\n  printf(\"%.3f Gmoves/s\\n\", moves * repeat / ktime);\n  printf(\"Best found tour length is %d with %d climbers\\n\", best, climbs);\n\n  \n\n  if (best < 38000 && best >= 35002)\n    printf(\"PASS\\n\");\n  else\n    printf(\"FAIL\\n\");\n\n  sycl::free(glob_d, q);\n  sycl::free(best_d, q);\n  sycl::free(climbs_d, q);\n  sycl::free(posx_d, q);\n  free(posx);\n  free(posy);\n  return 0;\n}\n"}}
