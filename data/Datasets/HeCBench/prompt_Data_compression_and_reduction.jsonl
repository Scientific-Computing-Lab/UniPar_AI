{"kernel_name": "atomicCost", "parallel_api": "cuda", "code": {"main.cu": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n\nstatic void CheckError( cudaError_t err, const char *file, int line ) {\n  if (err != cudaSuccess) {\n    printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ), file, line );\n  }\n}\n#define CHECK_ERROR( err ) (CheckError( err, __FILE__, __LINE__ ))\n\n#define BLOCK_SIZE 256\n\n\n\ntemplate <typename T>\n__global__ void woAtomicOnGlobalMem(T* result, int size)\n{\n  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  for ( unsigned int i = tid * size; i < (tid + 1) * size; i++){\n    result[tid] += i % 2;\n  }\n}\n\n\n\ntemplate <typename T>\n__global__ void wiAtomicOnGlobalMem(T* result, int size)\n{\n  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  for ( unsigned int i = tid * size; i < (tid + 1) * size; i++){\n    atomicAdd(&result[tid], i % 2);\n  }\n}\n\ntemplate <typename T>\nvoid atomicCost (int length, int size, int repeat)\n{\n  printf(\"\\n\\n\");\n  printf(\"Each thread sums up %d elements\\n\", size);\n\n  int num_threads = length / size;\n  assert(length % size == 0);\n  assert(num_threads % BLOCK_SIZE == 0);\n\n  size_t result_size = sizeof(T) * num_threads;\n\n  T* result_wi = (T*) malloc (result_size);\n  T* result_wo = (T*) malloc (result_size);\n\n  T *d_result_wi, *d_result_wo;\n  CHECK_ERROR( cudaMalloc((void **)&d_result_wi, result_size) );\n  CHECK_ERROR( cudaMemset(d_result_wi, 0, result_size) );\n  CHECK_ERROR( cudaMalloc((void **)&d_result_wo, result_size) );\n  CHECK_ERROR( cudaMemset(d_result_wo, 0, result_size) );\n\n  dim3 block (BLOCK_SIZE);\n  dim3 grid (num_threads / BLOCK_SIZE);\n\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    wiAtomicOnGlobalMem<T><<<grid, block>>>(d_result_wi, size);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WithAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n  CHECK_ERROR( cudaMemcpy(result_wi, d_result_wi, result_size, cudaMemcpyDeviceToHost) );\n\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    woAtomicOnGlobalMem<T><<<grid, block>>>(d_result_wo, size);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WithoutAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n  CHECK_ERROR( cudaMemcpy(result_wo, d_result_wo, result_size, cudaMemcpyDeviceToHost) );\n\n  int diff = memcmp(result_wi, result_wo, result_size);\n  printf(\"%s\\n\", diff ? \"FAIL\" : \"PASS\");\n\n  free(result_wi);\n  free(result_wo);\n  cudaFree(d_result_wi);\n  cudaFree(d_result_wo);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <N> <repeat>\\n\", argv[0]);\n    printf(\"N: the number of elements to sum per thread (1 - 16)\\n\");\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int length = 922521600;\n  assert(length % BLOCK_SIZE == 0);\n\n  printf(\"\\nFP64 atomic add\\n\");\n  atomicCost<double>(length, nelems, repeat);\n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicCost<int>(length, nelems, repeat);\n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicCost<float>(length, nelems, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "atomicCost", "parallel_api": "omp", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n\n#define BLOCK_SIZE 256\n\n\n\ntemplate <typename T>\nvoid woAtomicOnGlobalMem(T* result, int size, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for (unsigned int tid = 0; tid < n; tid++) {\n    for ( unsigned int i = tid * size; i < (tid + 1) * size; i++) {\n      result[tid] += i % 2;\n    }\n  }\n}\n\n\n\ntemplate <typename T>\nvoid wiAtomicOnGlobalMem(T* result, int size, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for (unsigned int tid = 0; tid < n; tid++) {\n    for ( unsigned int i = tid * size; i < (tid + 1) * size; i++) {\n      #pragma omp atomic update\n      result[tid] += i % 2;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid atomicCost (int length, int size, int repeat)\n{\n  printf(\"\\n\\n\");\n  printf(\"Each thread sums up %d elements\\n\", size);\n\n  int num_threads = length / size;\n  assert(length % size == 0);\n  assert(num_threads % BLOCK_SIZE == 0);\n\n  size_t result_size = sizeof(T) * num_threads;\n\n  T* result_wi = (T*) malloc (result_size);\n  T* result_wo = (T*) malloc (result_size);\n  memset(result_wi, 0, result_size);\n  memset(result_wo, 0, result_size);\n\n  #pragma omp target data map(alloc: result_wi[0:num_threads], result_wo[0:num_threads])\n  {\n    auto start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      wiAtomicOnGlobalMem<T>(result_wi, size, num_threads);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WithAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n    #pragma omp target update from (result_wi[0:num_threads])\n\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      woAtomicOnGlobalMem<T>(result_wo, size, num_threads);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WithoutAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n    #pragma omp target update from (result_wo[0:num_threads])\n\n    int diff = memcmp(result_wi, result_wo, result_size);\n    printf(\"%s\\n\", diff ? \"FAIL\" : \"PASS\");\n  }\n\n  free(result_wi);\n  free(result_wo);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <N> <repeat>\\n\", argv[0]);\n    printf(\"N: the number of elements to sum per thread (1 - 16)\\n\");\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int length = 922521600;\n  assert(length % BLOCK_SIZE == 0);\n\n  printf(\"\\nFP64 atomic add\\n\");\n  atomicCost<double>(length, nelems, repeat);\n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicCost<int>(length, nelems, repeat);\n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicCost<float>(length, nelems, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "atomicCost", "parallel_api": "serial", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n\n#define BLOCK_SIZE 256\n\n\n\ntemplate <typename T>\nvoid woAtomicOnGlobalMem(T* result, int size, int n)\n{\n    for (unsigned int tid = 0; tid < n; tid++) {\n    for ( unsigned int i = tid * size; i < (tid + 1) * size; i++) {\n      result[tid] += i % 2;\n    }\n  }\n}\n\n\n\ntemplate <typename T>\nvoid wiAtomicOnGlobalMem(T* result, int size, int n)\n{\n    for (unsigned int tid = 0; tid < n; tid++) {\n    for ( unsigned int i = tid * size; i < (tid + 1) * size; i++) {\n            result[tid] += i % 2;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid atomicCost (int length, int size, int repeat)\n{\n  printf(\"\\n\\n\");\n  printf(\"Each thread sums up %d elements\\n\", size);\n\n  int num_threads = length / size;\n  assert(length % size == 0);\n  assert(num_threads % BLOCK_SIZE == 0);\n\n  size_t result_size = sizeof(T) * num_threads;\n\n  T* result_wi = (T*) malloc (result_size);\n  T* result_wo = (T*) malloc (result_size);\n  memset(result_wi, 0, result_size);\n  memset(result_wo, 0, result_size);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      wiAtomicOnGlobalMem<T>(result_wi, size, num_threads);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WithAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n    \n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      woAtomicOnGlobalMem<T>(result_wo, size, num_threads);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WithoutAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n    \n    int diff = memcmp(result_wi, result_wo, result_size);\n    printf(\"%s\\n\", diff ? \"FAIL\" : \"PASS\");\n  }\n\n  free(result_wi);\n  free(result_wo);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <N> <repeat>\\n\", argv[0]);\n    printf(\"N: the number of elements to sum per thread (1 - 16)\\n\");\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int length = 922521600;\n  assert(length % BLOCK_SIZE == 0);\n\n  printf(\"\\nFP64 atomic add\\n\");\n  atomicCost<double>(length, nelems, repeat);\n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicCost<int>(length, nelems, repeat);\n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicCost<float>(length, nelems, repeat);\n\n  return 0;\n}"}}