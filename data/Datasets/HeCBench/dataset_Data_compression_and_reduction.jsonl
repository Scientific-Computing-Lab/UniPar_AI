{"kernel_name": "atomicCost", "parallel_api": "cuda", "code": {"main.cu": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n\nstatic void CheckError( cudaError_t err, const char *file, int line ) {\n  if (err != cudaSuccess) {\n    printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ), file, line );\n  }\n}\n#define CHECK_ERROR( err ) (CheckError( err, __FILE__, __LINE__ ))\n\n#define BLOCK_SIZE 256\n\n\n\ntemplate <typename T>\n__global__ void woAtomicOnGlobalMem(T* result, int size)\n{\n  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  for ( unsigned int i = tid * size; i < (tid + 1) * size; i++){\n    result[tid] += i % 2;\n  }\n}\n\n\n\ntemplate <typename T>\n__global__ void wiAtomicOnGlobalMem(T* result, int size)\n{\n  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  for ( unsigned int i = tid * size; i < (tid + 1) * size; i++){\n    atomicAdd(&result[tid], i % 2);\n  }\n}\n\ntemplate <typename T>\nvoid atomicCost (int length, int size, int repeat)\n{\n  printf(\"\\n\\n\");\n  printf(\"Each thread sums up %d elements\\n\", size);\n\n  int num_threads = length / size;\n  assert(length % size == 0);\n  assert(num_threads % BLOCK_SIZE == 0);\n\n  size_t result_size = sizeof(T) * num_threads;\n\n  T* result_wi = (T*) malloc (result_size);\n  T* result_wo = (T*) malloc (result_size);\n\n  T *d_result_wi, *d_result_wo;\n  CHECK_ERROR( cudaMalloc((void **)&d_result_wi, result_size) );\n  CHECK_ERROR( cudaMemset(d_result_wi, 0, result_size) );\n  CHECK_ERROR( cudaMalloc((void **)&d_result_wo, result_size) );\n  CHECK_ERROR( cudaMemset(d_result_wo, 0, result_size) );\n\n  dim3 block (BLOCK_SIZE);\n  dim3 grid (num_threads / BLOCK_SIZE);\n\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    wiAtomicOnGlobalMem<T><<<grid, block>>>(d_result_wi, size);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WithAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n  CHECK_ERROR( cudaMemcpy(result_wi, d_result_wi, result_size, cudaMemcpyDeviceToHost) );\n\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    woAtomicOnGlobalMem<T><<<grid, block>>>(d_result_wo, size);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WithoutAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n  CHECK_ERROR( cudaMemcpy(result_wo, d_result_wo, result_size, cudaMemcpyDeviceToHost) );\n\n  int diff = memcmp(result_wi, result_wo, result_size);\n  printf(\"%s\\n\", diff ? \"FAIL\" : \"PASS\");\n\n  free(result_wi);\n  free(result_wo);\n  cudaFree(d_result_wi);\n  cudaFree(d_result_wo);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <N> <repeat>\\n\", argv[0]);\n    printf(\"N: the number of elements to sum per thread (1 - 16)\\n\");\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int length = 922521600;\n  assert(length % BLOCK_SIZE == 0);\n\n  printf(\"\\nFP64 atomic add\\n\");\n  atomicCost<double>(length, nelems, repeat);\n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicCost<int>(length, nelems, repeat);\n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicCost<float>(length, nelems, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "atomicCost", "parallel_api": "hip", "code": {"main.cu": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\nstatic void CheckError( hipError_t err, const char *file, int line ) {\n  if (err != hipSuccess) {\n    printf( \"%s in %s at line %d\\n\", hipGetErrorString( err ), file, line );\n  }\n}\n#define CHECK_ERROR( err ) (CheckError( err, __FILE__, __LINE__ ))\n\n#define BLOCK_SIZE 256\n\n\n\ntemplate <typename T>\n__global__ void woAtomicOnGlobalMem(T* result, int size)\n{\n  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  for ( unsigned int i = tid * size; i < (tid + 1) * size; i++){\n    result[tid] += i % 2;\n  }\n}\n\n\n\ntemplate <typename T>\n__global__ void wiAtomicOnGlobalMem(T* result, int size)\n{\n  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  for ( unsigned int i = tid * size; i < (tid + 1) * size; i++){\n    atomicAdd(&result[tid], i % 2);\n  }\n}\n\ntemplate <typename T>\nvoid atomicCost (int length, int size, int repeat)\n{\n  printf(\"\\n\\n\");\n  printf(\"Each thread sums up %d elements\\n\", size);\n\n  int num_threads = length / size;\n  assert(length % size == 0);\n  assert(num_threads % BLOCK_SIZE == 0);\n\n  size_t result_size = sizeof(T) * num_threads;\n\n  T* result_wi = (T*) malloc (result_size);\n  T* result_wo = (T*) malloc (result_size);\n\n  T *d_result_wi, *d_result_wo;\n  CHECK_ERROR( hipMalloc((void **)&d_result_wi, result_size) );\n  CHECK_ERROR( hipMemset(d_result_wi, 0, result_size) );\n  CHECK_ERROR( hipMalloc((void **)&d_result_wo, result_size) );\n  CHECK_ERROR( hipMemset(d_result_wo, 0, result_size) );\n\n  dim3 block (BLOCK_SIZE);\n  dim3 grid (num_threads / BLOCK_SIZE);\n\n  CHECK_ERROR( hipDeviceSynchronize() );\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    wiAtomicOnGlobalMem<T><<<grid, block>>>(d_result_wi, size);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WithAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n  CHECK_ERROR( hipMemcpy(result_wi, d_result_wi, result_size, hipMemcpyDeviceToHost) );\n\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    woAtomicOnGlobalMem<T><<<grid, block>>>(d_result_wo, size);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WithoutAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n  CHECK_ERROR( hipMemcpy(result_wo, d_result_wo, result_size, hipMemcpyDeviceToHost) );\n\n  int diff = memcmp(result_wi, result_wo, result_size);\n  printf(\"%s\\n\", diff ? \"FAIL\" : \"PASS\");\n\n  free(result_wi);\n  free(result_wo);\n  hipFree(d_result_wi);\n  hipFree(d_result_wo);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <N> <repeat>\\n\", argv[0]);\n    printf(\"N: the number of elements to sum per thread (1 - 16)\\n\");\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int length = 922521600;\n  assert(length % BLOCK_SIZE == 0);\n\n  printf(\"\\nFP64 atomic add\\n\");\n  atomicCost<double>(length, nelems, repeat);\n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicCost<int>(length, nelems, repeat);\n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicCost<float>(length, nelems, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "atomicCost", "parallel_api": "omp", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n\n#define BLOCK_SIZE 256\n\n\n\ntemplate <typename T>\nvoid woAtomicOnGlobalMem(T* result, int size, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for (unsigned int tid = 0; tid < n; tid++) {\n    for ( unsigned int i = tid * size; i < (tid + 1) * size; i++) {\n      result[tid] += i % 2;\n    }\n  }\n}\n\n\n\ntemplate <typename T>\nvoid wiAtomicOnGlobalMem(T* result, int size, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for (unsigned int tid = 0; tid < n; tid++) {\n    for ( unsigned int i = tid * size; i < (tid + 1) * size; i++) {\n      #pragma omp atomic update\n      result[tid] += i % 2;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid atomicCost (int length, int size, int repeat)\n{\n  printf(\"\\n\\n\");\n  printf(\"Each thread sums up %d elements\\n\", size);\n\n  int num_threads = length / size;\n  assert(length % size == 0);\n  assert(num_threads % BLOCK_SIZE == 0);\n\n  size_t result_size = sizeof(T) * num_threads;\n\n  T* result_wi = (T*) malloc (result_size);\n  T* result_wo = (T*) malloc (result_size);\n  memset(result_wi, 0, result_size);\n  memset(result_wo, 0, result_size);\n\n  #pragma omp target data map(alloc: result_wi[0:num_threads], result_wo[0:num_threads])\n  {\n    auto start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      wiAtomicOnGlobalMem<T>(result_wi, size, num_threads);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WithAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n    #pragma omp target update from (result_wi[0:num_threads])\n\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      woAtomicOnGlobalMem<T>(result_wo, size, num_threads);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WithoutAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n    #pragma omp target update from (result_wo[0:num_threads])\n\n    int diff = memcmp(result_wi, result_wo, result_size);\n    printf(\"%s\\n\", diff ? \"FAIL\" : \"PASS\");\n  }\n\n  free(result_wi);\n  free(result_wo);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <N> <repeat>\\n\", argv[0]);\n    printf(\"N: the number of elements to sum per thread (1 - 16)\\n\");\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int length = 922521600;\n  assert(length % BLOCK_SIZE == 0);\n\n  printf(\"\\nFP64 atomic add\\n\");\n  atomicCost<double>(length, nelems, repeat);\n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicCost<int>(length, nelems, repeat);\n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicCost<float>(length, nelems, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "atomicCost", "parallel_api": "serial", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n\n#define BLOCK_SIZE 256\n\n\n\ntemplate <typename T>\nvoid woAtomicOnGlobalMem(T* result, int size, int n)\n{\n    for (unsigned int tid = 0; tid < n; tid++) {\n    for ( unsigned int i = tid * size; i < (tid + 1) * size; i++) {\n      result[tid] += i % 2;\n    }\n  }\n}\n\n\n\ntemplate <typename T>\nvoid wiAtomicOnGlobalMem(T* result, int size, int n)\n{\n    for (unsigned int tid = 0; tid < n; tid++) {\n    for ( unsigned int i = tid * size; i < (tid + 1) * size; i++) {\n            result[tid] += i % 2;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid atomicCost (int length, int size, int repeat)\n{\n  printf(\"\\n\\n\");\n  printf(\"Each thread sums up %d elements\\n\", size);\n\n  int num_threads = length / size;\n  assert(length % size == 0);\n  assert(num_threads % BLOCK_SIZE == 0);\n\n  size_t result_size = sizeof(T) * num_threads;\n\n  T* result_wi = (T*) malloc (result_size);\n  T* result_wo = (T*) malloc (result_size);\n  memset(result_wi, 0, result_size);\n  memset(result_wo, 0, result_size);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      wiAtomicOnGlobalMem<T>(result_wi, size, num_threads);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WithAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n    \n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      woAtomicOnGlobalMem<T>(result_wo, size, num_threads);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WithoutAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n    \n    int diff = memcmp(result_wi, result_wo, result_size);\n    printf(\"%s\\n\", diff ? \"FAIL\" : \"PASS\");\n  }\n\n  free(result_wi);\n  free(result_wo);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <N> <repeat>\\n\", argv[0]);\n    printf(\"N: the number of elements to sum per thread (1 - 16)\\n\");\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int length = 922521600;\n  assert(length % BLOCK_SIZE == 0);\n\n  printf(\"\\nFP64 atomic add\\n\");\n  atomicCost<double>(length, nelems, repeat);\n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicCost<int>(length, nelems, repeat);\n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicCost<float>(length, nelems, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "atomicCost", "parallel_api": "sycl", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define BLOCK_SIZE 256\n\n\n\ntemplate <typename T>\nvoid woAtomicOnGlobalMem(T* result, int size, sycl::nd_item<1> &item)\n{\n  unsigned int tid = item.get_global_id(0);\n  for ( unsigned int i = tid * size; i < (tid + 1) * size; i++){\n    result[tid] += i % 2;\n  }\n}\n\n\n\ntemplate <typename T>\nvoid wiAtomicOnGlobalMem(T* result, int size, sycl::nd_item<1> &item)\n{\n  unsigned int tid = item.get_global_id(0);\n  auto ao = sycl::atomic_ref<T,\n            sycl::memory_order::relaxed,\n            sycl::memory_scope::device,\n            sycl::access::address_space::global_space> (result[tid]);\n  for ( unsigned int i = tid * size; i < (tid + 1) * size; i++){\n    ao.fetch_add(i % 2);\n  }\n}\n\ntemplate <typename T>\nclass noAtomicKernel;\n\ntemplate <typename T>\nclass atomicKernel;\n\ntemplate <typename T>\nvoid atomicCost (int length, int size, int repeat)\n{\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  printf(\"\\n\\n\");\n  printf(\"Each thread sums up %d elements\\n\", size);\n\n  int num_threads = length / size;\n  assert(length % size == 0);\n  assert(num_threads % BLOCK_SIZE == 0);\n\n  size_t result_size = sizeof(T) * num_threads;\n\n  T* result_wi = (T*) malloc (result_size);\n  T* result_wo = (T*) malloc (result_size);\n\n  T* d_result_wi = (T *)sycl::malloc_device(result_size, q);\n  q.memset(d_result_wi, 0, result_size);\n\n  T* d_result_wo = (T *)sycl::malloc_device(result_size, q);\n  q.memset(d_result_wo, 0, result_size);\n\n  sycl::range<1> lws (BLOCK_SIZE);\n  sycl::range<1> gws (num_threads);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class noAtomicKernel<T>>(\n        sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        wiAtomicOnGlobalMem<T>(d_result_wi, size, item);\n      });\n    });\n  }\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WithAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n  q.memcpy(result_wi, d_result_wi, result_size).wait();\n\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class atomicKernel<T>>(\n        sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        woAtomicOnGlobalMem<T>(d_result_wo, size, item);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WithoutAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n  q.memcpy(result_wo, d_result_wo, result_size).wait();\n\n  int diff = memcmp(result_wi, result_wo, result_size);\n  printf(\"%s\\n\", diff ? \"FAIL\" : \"PASS\");\n\n  free(result_wi);\n  free(result_wo);\n  free(d_result_wi, q);\n  free(d_result_wo, q);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <N> <repeat>\\n\", argv[0]);\n    printf(\"N: the number of elements to sum per thread (1 - 16)\\n\");\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int length = 922521600;\n  assert(length % BLOCK_SIZE == 0);\n\n  printf(\"\\nFP64 atomic add\\n\");\n  atomicCost<double>(length, nelems, repeat);\n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicCost<int>(length, nelems, repeat);\n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicCost<float>(length, nelems, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "atomicPerf", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n\nstatic void CheckError( cudaError_t err, const char *file, int line ) {\n  if (err != cudaSuccess) {\n    printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ), file, line );\n  }\n}\n#define CHECK_ERROR( err ) (CheckError( err, __FILE__, __LINE__ ))\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\n__global__ void BlockRangeAtomicOnGlobalMem(T* data, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+threadIdx.x, (T)1);  \n\n  }\n}\n\ntemplate <typename T>\n__global__ void WarpRangeAtomicOnGlobalMem(T* data, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+(i & 0x1F), (T)1); \n\n  }\n}\n\ntemplate <typename T>\n__global__ void SingleRangeAtomicOnGlobalMem(T* data, int offset, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+offset, (T)1);    \n\n  }\n}\n\ntemplate <typename T>\n__global__ void BlockRangeAtomicOnSharedMem(T* data, int n)\n{\n  __shared__ T smem_data[BLOCK_SIZE];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data+threadIdx.x, (T)1);\n  }\n  if (blockIdx.x == gridDim.x)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\n__global__ void WarpRangeAtomicOnSharedMem(T* data, int n)\n{\n  __shared__ T smem_data[32];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data+(i & 0x1F), (T)1);\n  }\n  if (blockIdx.x == gridDim.x && threadIdx.x < 0x1F)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\n__global__ void SingleRangeAtomicOnSharedMem(T* data, int offset, int n)\n{\n  __shared__ T smem_data[BLOCK_SIZE];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data + offset, (T)1);\n  }\n  if (blockIdx.x == gridDim.x && threadIdx.x == 0)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) {\n    data[i] = i%1024+1;\n  }\n\n  T* d_data;\n  CHECK_ERROR( cudaMalloc((void **)&d_data, data_size) );\n\n  dim3 block (BLOCK_SIZE);\n  dim3 grid (n / BLOCK_SIZE);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    BlockRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    WarpRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    SingleRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, i % BLOCK_SIZE, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    BlockRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    WarpRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    SingleRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, i % BLOCK_SIZE, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  free(data);\n  cudaFree(d_data); \n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}\n"}}
{"kernel_name": "atomicPerf", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\nstatic void CheckError( hipError_t err, const char *file, int line ) {\n  if (err != hipSuccess) {\n    printf( \"%s in %s at line %d\\n\", hipGetErrorString( err ), file, line );\n  }\n}\n#define CHECK_ERROR( err ) (CheckError( err, __FILE__, __LINE__ ))\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\n__global__ void BlockRangeAtomicOnGlobalMem(T* data, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+threadIdx.x, (T)1);  \n\n  }\n}\n\ntemplate <typename T>\n__global__ void WarpRangeAtomicOnGlobalMem(T* data, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+(i & 0x1F), (T)1); \n\n  }\n}\n\ntemplate <typename T>\n__global__ void SingleRangeAtomicOnGlobalMem(T* data, int offset, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+offset, (T)1);    \n\n  }\n}\n\ntemplate <typename T>\n__global__ void BlockRangeAtomicOnSharedMem(T* data, int n)\n{\n  __shared__ T smem_data[BLOCK_SIZE];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data+threadIdx.x, (T)1);\n  }\n  if (blockIdx.x == gridDim.x)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\n__global__ void WarpRangeAtomicOnSharedMem(T* data, int n)\n{\n  __shared__ T smem_data[32];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data+(i & 0x1F), (T)1);\n  }\n  if (blockIdx.x == gridDim.x && threadIdx.x < 0x1F)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\n__global__ void SingleRangeAtomicOnSharedMem(T* data, int offset, int n)\n{\n  __shared__ T smem_data[BLOCK_SIZE];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data + offset, (T)1);\n  }\n  if (blockIdx.x == gridDim.x && threadIdx.x == 0)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) {\n    data[i] = i%1024+1;\n  }\n\n  T* d_data;\n  CHECK_ERROR( hipMalloc((void **)&d_data, data_size) );\n\n  dim3 block (BLOCK_SIZE);\n  dim3 grid (n / BLOCK_SIZE);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    BlockRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    WarpRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    SingleRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, i % BLOCK_SIZE, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    BlockRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    WarpRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    SingleRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, i % BLOCK_SIZE, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  free(data);\n  hipFree(d_data); \n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}\n"}}
{"kernel_name": "atomicPerf", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <omp.h>\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnGlobalMem(T* data, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for ( unsigned int i = 0; i < n; i++) {\n    #pragma omp atomic update\n    data[i % BLOCK_SIZE]++;  \n\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnGlobalMem(T* data, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for ( unsigned int i = 0; i < n; i++) {\n    #pragma omp atomic update\n    data[i & 0x1F]++; \n\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnGlobalMem(T* data, int offset, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for ( unsigned int i = 0; i < n; i++) {\n    #pragma omp atomic update\n    data[0]++;    \n\n  }\n}\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnSharedMem(T* data, int n)\n{\n  #pragma omp target teams num_teams(n / BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T smem_data[BLOCK_SIZE];\n    #pragma omp parallel \n    {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[threadIdx_x]++;\n      }\n      if (blockIdx_x == gridDim_x)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnSharedMem(T* data, int n)\n{\n  #pragma omp target teams num_teams(n / BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T smem_data[32];\n    #pragma omp parallel \n    {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[i & 0x1F]++;\n      }\n      if (blockIdx_x == gridDim_x && threadIdx_x < 0x1F)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnSharedMem(T* data, int offset, int n)\n{\n  #pragma omp target teams num_teams(n / BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T smem_data[BLOCK_SIZE];\n    #pragma omp parallel \n    {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[offset]++;\n      }\n      if (blockIdx_x == gridDim_x && threadIdx_x == 0)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) data[i] = i%1024+1;\n\n  #pragma omp target data map(alloc: data[0:t])\n  {\n    #pragma omp target update to (data[0:t])\n    auto start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      BlockRangeAtomicOnGlobalMem<T>(data, n);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      WarpRangeAtomicOnGlobalMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      SingleRangeAtomicOnGlobalMem<T>(data, i % BLOCK_SIZE, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      BlockRangeAtomicOnSharedMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      WarpRangeAtomicOnSharedMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      SingleRangeAtomicOnSharedMem<T>(data, i % BLOCK_SIZE, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n  }\n  free(data);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}\n"}}
{"kernel_name": "atomicPerf", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnGlobalMem(T* data, int n)\n{\n    for ( unsigned int i = 0; i < n; i++) {\n        data[i % BLOCK_SIZE]++;  \n\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnGlobalMem(T* data, int n)\n{\n    for ( unsigned int i = 0; i < n; i++) {\n        data[i & 0x1F]++; \n\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnGlobalMem(T* data, int offset, int n)\n{\n    for ( unsigned int i = 0; i < n; i++) {\n        data[0]++;    \n\n  }\n}\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnSharedMem(T* data, int n)\n{\n    {\n    T smem_data[BLOCK_SIZE];\n        {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[threadIdx_x]++;\n      }\n      if (blockIdx_x == gridDim_x)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnSharedMem(T* data, int n)\n{\n    {\n    T smem_data[32];\n        {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[i & 0x1F]++;\n      }\n      if (blockIdx_x == gridDim_x && threadIdx_x < 0x1F)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnSharedMem(T* data, int offset, int n)\n{\n    {\n    T smem_data[BLOCK_SIZE];\n        {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[offset]++;\n      }\n      if (blockIdx_x == gridDim_x && threadIdx_x == 0)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) data[i] = i%1024+1;\n\n    {\n        auto start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      BlockRangeAtomicOnGlobalMem<T>(data, n);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      WarpRangeAtomicOnGlobalMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      SingleRangeAtomicOnGlobalMem<T>(data, i % BLOCK_SIZE, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      BlockRangeAtomicOnSharedMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      WarpRangeAtomicOnSharedMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      SingleRangeAtomicOnSharedMem<T>(data, i % BLOCK_SIZE, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n  }\n  free(data);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}"}}
{"kernel_name": "atomicPerf", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnGlobalMem(T* data, int n, sycl::nd_item<1> &item)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (data[item.get_local_id(0)]);\n    ao.fetch_add((T)1); \n\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnGlobalMem(T* data, int n, sycl::nd_item<1> &item)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (data[i & 0x1F]);\n    ao.fetch_add((T)1); \n\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnGlobalMem(T* data, int offset, int n, sycl::nd_item<1> &item)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (data[offset]);\n    ao.fetch_add((T)1); \n\n  }\n}\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnSharedMem(T* data, int n, sycl::nd_item<1> item,\n                                 T *smem_data)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (smem_data[item.get_local_id(0)]);\n    ao.fetch_add((T)1); \n\n  }\n  if (item.get_group(0) == item.get_group_range(0))\n    data[item.get_local_id(0)] = smem_data[item.get_local_id(0)];\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnSharedMem(T* data, int n, sycl::nd_item<1> item,\n                                T *smem_data)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (smem_data[i & 0x1F]);\n    ao.fetch_add((T)1); \n\n  }\n  if (item.get_group(0) == item.get_group_range(0) &&\n      item.get_local_id(0) < 0x1F)\n    data[item.get_local_id(0)] = smem_data[item.get_local_id(0)];\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnSharedMem(T* data, int offset, int n, sycl::nd_item<1> item,\n                                  T *smem_data)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (smem_data[offset]);\n    ao.fetch_add((T)1); \n\n  }\n  if (item.get_group(0) == item.get_group_range(0) &&\n      item.get_local_id(0) == 0)\n    data[item.get_local_id(0)] = smem_data[item.get_local_id(0)];\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n  \n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) {\n    data[i] = i%1024+1;\n  }\n\n  T* d_data = (T *)sycl::malloc_device(data_size, q);\n\n  sycl::range<1> lws (BLOCK_SIZE);\n  sycl::range<1> gws (n);\n\n  q.memcpy(d_data, data, data_size).wait();\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        BlockRangeAtomicOnGlobalMem<T>(d_data, n, item);\n      });\n    });\n  }\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        WarpRangeAtomicOnGlobalMem<T>(d_data, n, item);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        SingleRangeAtomicOnGlobalMem<T>(d_data, i % BLOCK_SIZE, n, item);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> smem (sycl::range<1>(BLOCK_SIZE), cgh);\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        BlockRangeAtomicOnSharedMem<T>(d_data, n, item, smem.get_pointer());\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> smem (sycl::range<1>(32), cgh);\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        WarpRangeAtomicOnSharedMem<T>(d_data, n, item, smem.get_pointer());\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> smem (sycl::range<1>(BLOCK_SIZE), cgh);\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        SingleRangeAtomicOnSharedMem<T>(d_data, i % BLOCK_SIZE,\n                                        n, item, smem.get_pointer());\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  free(data);\n  sycl::free(d_data, q);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}\n"}}
{"kernel_name": "contract", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <cuda.h>\n#include \"kernel.h\"\n\nint rounded_division(int number1, int number2) {\n  if (number1 % number2 == 0)\n    return number1 / number2;\n  return number1 / number2 + 1;\n}\n\ntemplate <typename T>\nvoid contract (const int max_N, const int max_C, const int repeat) {\n  \n\n  const size_t tensor_size = (size_t)max_N * max_N * max_N * max_C;\n  const size_t tensor_size_byte = tensor_size * sizeof(T);\n\n  T* tensor_value = (T*) malloc (tensor_size_byte);\n  for (size_t i = 0; i < tensor_size; i++)\n    tensor_value[i] = 1;\n\n  T* device_tensor_value;\n  cudaMalloc(&device_tensor_value, tensor_size_byte);\n\n  \n\n  const size_t adj_size = max_N * max_N;\n  const size_t adj_size_byte = adj_size * sizeof(T);\n  \n  \n\n  T* adj_value = (T*) malloc (adj_size_byte);\n  for (size_t i = 0; i < adj_size; i++) adj_value[i] = 1;\n\n  T* device_adj_value;\n  cudaMalloc((void**)&device_adj_value, adj_size_byte);\n\n  \n\n  const size_t output_size = max_N * max_N * max_C * nContractions;\n  const size_t output_size_byte = max_N * max_N * max_C * nContractions * sizeof(T);\n\n  T* value = (T*) malloc (output_size_byte);\n\n  T* device_value;\n  cudaMalloc((void**)&device_value, output_size_byte);\n\n  \n\n  cudaMemcpy(device_tensor_value, tensor_value, tensor_size_byte, cudaMemcpyHostToDevice);\n  cudaMemcpy(device_adj_value, adj_value, adj_size_byte, cudaMemcpyHostToDevice);\n\n  const int nThreads = 256;\n  dim3 dimGrid(rounded_division(output_size, nThreads));\n  dim3 dimBlock(nThreads);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    contraction <<< dimGrid, dimBlock >>> (\n      device_tensor_value, device_adj_value, device_value, output_size, max_N, max_C);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(value, device_value, output_size_byte, cudaMemcpyDeviceToHost);\n\n  double checksum = 0;\n  for (size_t i = 0; i < output_size; i++) checksum += value[i];\n  printf(\"Checksum: %lf min:%lf max:%lf\\n\", checksum, \n         *std::min_element(value, value+output_size),\n         *std::max_element(value, value+output_size));\n\n  cudaFree(device_value);\n  cudaFree(device_tensor_value);\n  cudaFree(device_adj_value);\n  free(value);\n  free(tensor_value);\n  free(adj_value);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n \n  int max_N = atoi(argv[1]);\n  int max_C = nContractions;\n  int repeat = atoi(argv[2]);\n\n  contract<float>(max_N, max_C, repeat);\n  contract<double>(max_N, max_C, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "contract", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"kernel.h\"\n\nint rounded_division(int number1, int number2) {\n  if (number1 % number2 == 0)\n    return number1 / number2;\n  return number1 / number2 + 1;\n}\n\ntemplate <typename T>\nvoid contract (const int max_N, const int max_C, const int repeat) {\n  \n\n  const size_t tensor_size = (size_t)max_N * max_N * max_N * max_C;\n  const size_t tensor_size_byte = tensor_size * sizeof(T);\n\n  T* tensor_value = (T*) malloc (tensor_size_byte);\n  for (size_t i = 0; i < tensor_size; i++)\n    tensor_value[i] = 1;\n\n  T* device_tensor_value;\n  hipMalloc(&device_tensor_value, tensor_size_byte);\n\n  \n\n  const size_t adj_size = max_N * max_N;\n  const size_t adj_size_byte = adj_size * sizeof(T);\n  \n  \n\n  T* adj_value = (T*) malloc (adj_size_byte);\n  for (size_t i = 0; i < adj_size; i++) adj_value[i] = 1;\n\n  T* device_adj_value;\n  hipMalloc((void**)&device_adj_value, adj_size_byte);\n\n  \n\n  const size_t output_size = max_N * max_N * max_C * nContractions;\n  const size_t output_size_byte = max_N * max_N * max_C * nContractions * sizeof(T);\n\n  T* value = (T*) malloc (output_size_byte);\n\n  T* device_value;\n  hipMalloc((void**)&device_value, output_size_byte);\n\n  \n\n  hipMemcpy(device_tensor_value, tensor_value, tensor_size_byte, hipMemcpyHostToDevice);\n  hipMemcpy(device_adj_value, adj_value, adj_size_byte, hipMemcpyHostToDevice);\n\n  const int nThreads = 256;\n  dim3 dimGrid(rounded_division(output_size, nThreads));\n  dim3 dimBlock(nThreads);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(contraction, dimGrid, dimBlock , 0, 0, \n      device_tensor_value, device_adj_value, device_value, output_size, max_N, max_C);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(value, device_value, output_size_byte, hipMemcpyDeviceToHost);\n\n  double checksum = 0;\n  for (size_t i = 0; i < output_size; i++) checksum += value[i];\n  printf(\"Checksum: %lf min:%lf max:%lf\\n\", checksum, \n         *std::min_element(value, value+output_size),\n         *std::max_element(value, value+output_size));\n\n  hipFree(device_value);\n  hipFree(device_tensor_value);\n  hipFree(device_adj_value);\n  free(value);\n  free(tensor_value);\n  free(adj_value);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n \n  int max_N = atoi(argv[1]);\n  int max_C = nContractions;\n  int repeat = atoi(argv[2]);\n\n  contract<float>(max_N, max_C, repeat);\n  contract<double>(max_N, max_C, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "contract", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <omp.h>\n\nconst int nContractions = 18;  \n\n\ntemplate <typename T>\nvoid contraction (\n  const T *__restrict tensor,\n  const T *__restrict adj,\n        T *__restrict value,\n  const int output_size, \n  const int N, \n  const int nChanels)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int tid = 0; tid < output_size; tid++) {\n    int C = nChanels;\n    int B = N * C;\n    int A = N * B;\n    int Y = nChanels * nContractions;\n\n    int f = (tid % Y) % nChanels;\n    int Case = (tid % Y) / nChanels + 1;\n    int y = (tid / Y) % N;\n    int x = (tid / Y) / N;\n\n    int a, b, c, d, e;\n    T adj_value;\n\n    T sum = (T)0;\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 1) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 2) {    \n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (b = 0; b < N; ++b) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }  \n    }\n\n    \n\n    if (Case == 3) {    \n      b = x;\n      c = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            for (a = 0; a < N; ++a) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }  \n    }\n\n    \n\n    if (Case == 4) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (a = 0; a < N; ++a) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 5) {    \n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (a = 0; a < N; ++a) {\n          for (b = 0; b < N; ++b) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 6) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          c = d;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n\n    \n\n    if (Case == 7) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        e = d;\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 8) {\n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (b = 0; b < N; ++b) {\n            c = b;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 9) {\n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          b = e;\n          for (c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 10) {\n      b = x;\n      c = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            a = d;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 11) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (a = 0; a < N; ++a) {\n            c = a;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 12) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          a = e;\n          for (int c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 13) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          c = e;\n          for (int a = 0; a < N; ++a) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 14) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int a = 0; a < N; ++a) {\n          b = a;\n          for (int c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 15) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int b = 0; b < N; ++b) {\n          c = b;\n          for (int a = 0; a < N; ++a) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 16) {\n      a = x;\n      d = y;\n\n      for (int e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          b = e;\n          c = e;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }  \n\n    \n\n    if (Case == 17) {\n      b = x;\n      d = y;\n\n      for (int e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          a = e;\n          c = e;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n\n    \n\n    if (Case == 18) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int a = 0; a < N; ++a) {\n          b = a;\n          c = a;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n    value[tid] = sum;\n  }\n}\n\nint rounded_division(int number1, int number2) {\n  if (number1 % number2 == 0)\n    return number1 / number2;\n  return number1 / number2 + 1;\n}\n\ntemplate <typename T>\nvoid contract (const int max_N, const int max_C, const int repeat) {\n  \n\n  const size_t tensor_size = (size_t)max_N * max_N * max_N * max_C;\n  const size_t tensor_size_byte = tensor_size * sizeof(T);\n\n  T* tensor_value = (T*) malloc (tensor_size_byte);\n  for (size_t i = 0; i < tensor_size; i++)\n    tensor_value[i] = 1;\n\n  \n\n  const size_t adj_size = max_N * max_N;\n  const size_t adj_size_byte = adj_size * sizeof(T);\n  \n  \n\n  T* adj_value = (T*) malloc (adj_size_byte);\n  for (size_t i = 0; i < adj_size; i++) adj_value[i] = 1;\n\n  \n\n  const size_t output_size = max_N * max_N * max_C * nContractions;\n  const size_t output_size_byte = max_N * max_N * max_C * nContractions * sizeof(T);\n\n  T* value = (T*) malloc (output_size_byte);\n\n  \n\n  #pragma omp target data map (to: tensor_value[0:tensor_size], adj_value[0:adj_size]) \\\n                          map (from: value[0:output_size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      contraction(tensor_value, adj_value, value, output_size, max_N, max_C);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  double checksum = 0;\n  for (size_t i = 0; i < output_size; i++) checksum += value[i];\n  printf(\"Checksum: %lf min:%lf max:%lf\\n\", checksum, \n         *std::min_element(value, value+output_size),\n         *std::max_element(value, value+output_size));\n\n  free(value);\n  free(tensor_value);\n  free(adj_value);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n \n  int max_N = atoi(argv[1]);\n  int max_C = nContractions;\n  int repeat = atoi(argv[2]);\n\n  contract<float>(max_N, max_C, repeat);\n  contract<double>(max_N, max_C, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "contract", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n\nconst int nContractions = 18;  \n\n\ntemplate <typename T>\nvoid contraction (\n  const T *__restrict tensor,\n  const T *__restrict adj,\n        T *__restrict value,\n  const int output_size, \n  const int N, \n  const int nChanels)\n{\n    for (int tid = 0; tid < output_size; tid++) {\n    int C = nChanels;\n    int B = N * C;\n    int A = N * B;\n    int Y = nChanels * nContractions;\n\n    int f = (tid % Y) % nChanels;\n    int Case = (tid % Y) / nChanels + 1;\n    int y = (tid / Y) % N;\n    int x = (tid / Y) / N;\n\n    int a, b, c, d, e;\n    T adj_value;\n\n    T sum = (T)0;\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 1) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 2) {    \n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (b = 0; b < N; ++b) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }  \n    }\n\n    \n\n    if (Case == 3) {    \n      b = x;\n      c = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            for (a = 0; a < N; ++a) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }  \n    }\n\n    \n\n    if (Case == 4) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (a = 0; a < N; ++a) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 5) {    \n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (a = 0; a < N; ++a) {\n          for (b = 0; b < N; ++b) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 6) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          c = d;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n\n    \n\n    if (Case == 7) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        e = d;\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 8) {\n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (b = 0; b < N; ++b) {\n            c = b;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 9) {\n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          b = e;\n          for (c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 10) {\n      b = x;\n      c = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            a = d;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 11) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (a = 0; a < N; ++a) {\n            c = a;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 12) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          a = e;\n          for (int c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 13) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          c = e;\n          for (int a = 0; a < N; ++a) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 14) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int a = 0; a < N; ++a) {\n          b = a;\n          for (int c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 15) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int b = 0; b < N; ++b) {\n          c = b;\n          for (int a = 0; a < N; ++a) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 16) {\n      a = x;\n      d = y;\n\n      for (int e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          b = e;\n          c = e;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }  \n\n    \n\n    if (Case == 17) {\n      b = x;\n      d = y;\n\n      for (int e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          a = e;\n          c = e;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n\n    \n\n    if (Case == 18) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int a = 0; a < N; ++a) {\n          b = a;\n          c = a;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n    value[tid] = sum;\n  }\n}\n\nint rounded_division(int number1, int number2) {\n  if (number1 % number2 == 0)\n    return number1 / number2;\n  return number1 / number2 + 1;\n}\n\ntemplate <typename T>\nvoid contract (const int max_N, const int max_C, const int repeat) {\n  \n\n  const size_t tensor_size = (size_t)max_N * max_N * max_N * max_C;\n  const size_t tensor_size_byte = tensor_size * sizeof(T);\n\n  T* tensor_value = (T*) malloc (tensor_size_byte);\n  for (size_t i = 0; i < tensor_size; i++)\n    tensor_value[i] = 1;\n\n  \n\n  const size_t adj_size = max_N * max_N;\n  const size_t adj_size_byte = adj_size * sizeof(T);\n  \n  \n\n  T* adj_value = (T*) malloc (adj_size_byte);\n  for (size_t i = 0; i < adj_size; i++) adj_value[i] = 1;\n\n  \n\n  const size_t output_size = max_N * max_N * max_C * nContractions;\n  const size_t output_size_byte = max_N * max_N * max_C * nContractions * sizeof(T);\n\n  T* value = (T*) malloc (output_size_byte);\n\n  \n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      contraction(tensor_value, adj_value, value, output_size, max_N, max_C);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  double checksum = 0;\n  for (size_t i = 0; i < output_size; i++) checksum += value[i];\n  printf(\"Checksum: %lf min:%lf max:%lf\\n\", checksum, \n         *std::min_element(value, value+output_size),\n         *std::max_element(value, value+output_size));\n\n  free(value);\n  free(tensor_value);\n  free(adj_value);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n \n  int max_N = atoi(argv[1]);\n  int max_C = nContractions;\n  int repeat = atoi(argv[2]);\n\n  contract<float>(max_N, max_C, repeat);\n  contract<double>(max_N, max_C, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "contract", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nconst int nContractions = 18;  \n\n\ntemplate <typename T>\nclass tensor_aggregate;\n\ntemplate <typename T>\nvoid contraction (\n  sycl::nd_item<1> &item,\n  const T *__restrict tensor,\n  const T *__restrict adj,\n        T *__restrict value,\n  const int output_size, \n  const int N, \n  const int nChanels)\n{\n  int tid = item.get_global_id(0);\n\n  if (tid < output_size) {  \n    int C = nChanels;\n    int B = N * C;\n    int A = N * B;\n    int Y = nChanels * nContractions;\n\n    int f = (tid % Y) % nChanels;\n    int Case = (tid % Y) / nChanels + 1;\n    int y = (tid / Y) % N;\n    int x = (tid / Y) / N;\n\n    int a, b, c, d, e;\n    T adj_value;\n\n    T sum = (T)0;\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 1) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 2) {    \n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (b = 0; b < N; ++b) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }  \n    }\n\n    \n\n    if (Case == 3) {    \n      b = x;\n      c = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            for (a = 0; a < N; ++a) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }  \n    }\n\n    \n\n    if (Case == 4) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (a = 0; a < N; ++a) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 5) {    \n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (a = 0; a < N; ++a) {\n          for (b = 0; b < N; ++b) {\n            for (c = 0; c < N; ++c) {\n              sum += tensor[a * A + b * B + c * C + f] * adj_value;\n            }\n          }\n        }\n      }\n    }\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 6) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          c = d;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n\n    \n\n    if (Case == 7) {\n      a = x;\n      b = y;\n\n      for (d = 0; d < N; ++d) {\n        e = d;\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 8) {\n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (b = 0; b < N; ++b) {\n            c = b;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 9) {\n      a = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          b = e;\n          for (c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 10) {\n      b = x;\n      c = y;\n\n      for (d = 0; d < N; ++d) {\n        for (e = 0; e < N; ++e) {\n          adj_value = adj[d * N + e];\n          if (adj_value > 0) {\n            a = d;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 11) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          for (a = 0; a < N; ++a) {\n            c = a;\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 12) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          a = e;\n          for (int c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 13) {\n      b = x;\n      d = y;\n\n      for (e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          c = e;\n          for (int a = 0; a < N; ++a) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 14) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int a = 0; a < N; ++a) {\n          b = a;\n          for (int c = 0; c < N; ++c) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    if (Case == 15) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int b = 0; b < N; ++b) {\n          c = b;\n          for (int a = 0; a < N; ++a) {\n            sum += tensor[a * A + b * B + c * C + f] * adj_value;\n          }\n        }\n      }\n    }\n\n    \n\n    \n\n    \n\n\n    \n\n    if (Case == 16) {\n      a = x;\n      d = y;\n\n      for (int e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          b = e;\n          c = e;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }  \n\n    \n\n    if (Case == 17) {\n      b = x;\n      d = y;\n\n      for (int e = 0; e < N; ++e) {\n        adj_value = adj[d * N + e];\n        if (adj_value > 0) {\n          a = e;\n          c = e;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n\n    \n\n    if (Case == 18) {\n      d = x;\n      e = y;\n\n      adj_value = adj[d * N + e];\n      if (adj_value > 0) {\n        for (int a = 0; a < N; ++a) {\n          b = a;\n          c = a;\n          sum += tensor[a * A + b * B + c * C + f] * adj_value;\n        }\n      }\n    }\n\n    value[tid] = sum;\n  }\n}\n\nint rounded_division(int number1, int number2) {\n  if (number1 % number2 == 0)\n    return number1 / number2;\n  return number1 / number2 + 1;\n}\n\ntemplate <typename T>\nvoid contract (sycl::queue &q, const int max_N, const int max_C, const int repeat) {\n  \n\n  const size_t tensor_size = (size_t)max_N * max_N * max_N * max_C;\n  const size_t tensor_size_byte = tensor_size * sizeof(T);\n\n  T* tensor_value = (T*) malloc (tensor_size_byte);\n  for (size_t i = 0; i < tensor_size; i++)\n    tensor_value[i] = 1;\n\n  T* d_tensor_value = (T*) sycl::malloc_device (tensor_size_byte, q);\n  q.memcpy(d_tensor_value, tensor_value, tensor_size_byte);\n\n  \n\n  const size_t adj_size = max_N * max_N;\n  const size_t adj_size_byte = adj_size * sizeof(T);\n  \n  \n\n  T* adj_value = (T*) malloc (adj_size_byte);\n  for (int i = 0; i < adj_size; i++) adj_value[i] = 1;\n\n  T* d_adj_value = (T*) sycl::malloc_device (adj_size_byte, q);\n  q.memcpy(d_adj_value, adj_value, adj_size_byte);\n\n  \n\n  const size_t output_size = max_N * max_N * max_C * nContractions;\n  const size_t output_size_byte = max_N * max_N * max_C * nContractions * sizeof(T);\n\n  T* value = (T*) malloc (output_size_byte);\n  T* d_value = (T*) sycl::malloc_device (output_size_byte, q);\n\n  \n\n  const int nThreads = 256;\n  sycl::range<1> gws (rounded_division(output_size, nThreads) * nThreads);\n  sycl::range<1> lws (nThreads);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class tensor_aggregate<T>>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        contraction<T>(item, d_tensor_value, d_adj_value, d_value,\n                       output_size, max_N, max_C);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(value, d_value, output_size_byte).wait();\n\n  double checksum = 0;\n  for (size_t i = 0; i < output_size; i++) checksum += value[i];\n  printf(\"Checksum: %lf min:%lf max:%lf\\n\", checksum, \n         *std::min_element(value, value+output_size),\n         *std::max_element(value, value+output_size));\n\n  free(value);\n  free(tensor_value);\n  free(adj_value);\n  sycl::free(d_value, q);\n  sycl::free(d_tensor_value, q);\n  sycl::free(d_adj_value, q);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n \n  int max_N = atoi(argv[1]);\n  int max_C = nContractions;\n  int repeat = atoi(argv[2]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  contract<float>(q, max_N, max_C, repeat);\n  contract<double>(q, max_N, max_C, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "filter", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <cuda.h>\n#include <cooperative_groups.h>\n\n__global__ \nvoid filter (int *__restrict__ dst,\n             int *__restrict__ nres,\n             const int*__restrict__ src,\n             int n)\n{\n  __shared__ int l_n;\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  \n\n  if (threadIdx.x == 0)\n    l_n = 0;\n  __syncthreads();\n\n  \n\n  \n\n  int d, pos;\n\n  if(i < n) {\n    d = src[i];\n    if(d > 0)\n      pos = atomicAdd(&l_n, 1);\n  }\n  __syncthreads();\n\n  \n\n  if(threadIdx.x == 0)\n    l_n = atomicAdd(nres, l_n);\n  __syncthreads();\n\n  \n\n  if(i < n && d > 0) {\n    pos += l_n; \n\n    dst[pos] = d;\n  }\n  __syncthreads();\n}\n\n\n__device__ int atomicAggInc(int *ctr) {\n  auto g = cooperative_groups::coalesced_threads();\n  int warp_res = 0;\n  if(g.thread_rank() == 0)\n    warp_res = atomicAdd(ctr, g.size());\n  return g.shfl(warp_res, 0) + g.thread_rank();\n}\n\n__global__\nvoid filter2 (int *__restrict__ dst,\n              int *__restrict__ nres,\n              const int*__restrict__ src,\n              int n)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if(i < n && src[i] > 0)\n    dst[atomicAggInc(nres)] = src[i];\n}\n\n\n\n\nbool check(int *d_nres, int *d_output, int h_nres, std::vector<int> &h_output) {\n  int nres;\n  cudaMemcpy(&nres, d_nres, sizeof(int), cudaMemcpyDeviceToHost);\n\n  std::vector<int> output (nres);\n\n  cudaMemcpy(output.data(), d_output, sizeof(int) * nres, cudaMemcpyDeviceToHost);\n\n  \n\n  cudaMemset(d_output, 0, sizeof(int) * nres);\n\n  std::sort(output.begin(), output.end());\n\n  bool equal = (h_nres == nres) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_nres, output.begin());\n  return equal;\n}\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  \n\n  std::vector<int> h_output (num_elems);\n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n\n  \n\n  int *d_input, *d_output, *d_nres;\n\n  cudaMalloc(&d_input, sizeof(int) * num_elems);\n  cudaMalloc(&d_output, sizeof(int) * num_elems);\n  cudaMalloc(&d_nres, sizeof(int));\n\n  cudaMemcpy(d_input, input.data(),\n             sizeof(int) * num_elems, cudaMemcpyHostToDevice);\n\n  dim3 dimBlock (block_size);\n  dim3 dimGrid ((num_elems + block_size - 1) / block_size);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    cudaMemset(d_nres, 0, sizeof(int));\n    filter<<<dimGrid, dimBlock>>>(d_output, d_nres, d_input, num_elems);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (shared memory) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  bool match = check(d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    cudaMemset(d_nres, 0, sizeof(int));\n    filter2<<<dimGrid, dimBlock>>>(d_output, d_nres, d_input, num_elems);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (global aggregate) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  match = check(d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_input);\n  cudaFree(d_output);\n  cudaFree(d_nres);\n\n  return 0;\n}\n"}}
{"kernel_name": "filter", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <hip/hip_runtime.h>\n#include <hip/hip_cooperative_groups.h>\n\n__global__ \nvoid filter (int *__restrict__ dst,\n             int *__restrict__ nres,\n             const int*__restrict__ src,\n             int n)\n{\n  __shared__ int l_n;\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  \n\n  if (threadIdx.x == 0)\n    l_n = 0;\n  __syncthreads();\n\n  \n\n  \n\n  int d, pos;\n\n  if(i < n) {\n    d = src[i];\n    if(d > 0)\n      pos = atomicAdd(&l_n, 1);\n  }\n  __syncthreads();\n\n  \n\n  if(threadIdx.x == 0)\n    l_n = atomicAdd(nres, l_n);\n  __syncthreads();\n\n  \n\n  if(i < n && d > 0) {\n    pos += l_n; \n\n    dst[pos] = d;\n  }\n  __syncthreads();\n}\n\n__device__ int atomicAggInc(int *ctr) {\n  auto g = cooperative_groups::coalesced_threads();\n  int warp_res = 0;\n  if(g.thread_rank() == 0)\n    warp_res = atomicAdd(ctr, g.size());\n  return g.shfl(warp_res, 0) + g.thread_rank();\n}\n\n__global__\nvoid filter2 (int *__restrict__ dst,\n              int *__restrict__ nres,\n              const int*__restrict__ src,\n              int n)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if(i < n && src[i] > 0)\n    dst[atomicAggInc(nres)] = src[i];\n}\n\n\n\n\nbool check(int *d_nres, int *d_output, int h_nres, std::vector<int> &h_output) {\n  int nres;\n  hipMemcpy(&nres, d_nres, sizeof(int), hipMemcpyDeviceToHost);\n\n  std::vector<int> output (nres);\n\n  hipMemcpy(output.data(), d_output, sizeof(int) * nres, hipMemcpyDeviceToHost);\n\n  \n\n  hipMemset(d_output, 0, sizeof(int) * nres);\n\n  std::sort(output.begin(), output.end());\n\n  bool equal = (h_nres == nres) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_nres, output.begin());\n  return equal;\n}\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  \n\n  std::vector<int> h_output (num_elems);\n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n\n  \n\n  int *d_input, *d_output, *d_nres;\n\n  hipMalloc(&d_input, sizeof(int) * num_elems);\n  hipMalloc(&d_output, sizeof(int) * num_elems);\n  hipMalloc(&d_nres, sizeof(int));\n\n  hipMemcpy(d_input, input.data(),\n             sizeof(int) * num_elems, hipMemcpyHostToDevice);\n\n  dim3 dimBlock (block_size);\n  dim3 dimGrid ((num_elems + block_size - 1) / block_size);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipMemset(d_nres, 0, sizeof(int));\n    filter<<<dimGrid, dimBlock>>>(d_output, d_nres, d_input, num_elems);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (shared memory) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  bool match = check(d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipMemset(d_nres, 0, sizeof(int));\n    filter2<<<dimGrid, dimBlock>>>(d_output, d_nres, d_input, num_elems);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (global aggregate) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  match = check(d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_input);\n  hipFree(d_output);\n  hipFree(d_nres);\n\n  return 0;\n}\n"}}
{"kernel_name": "filter", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <omp.h>\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n  std::vector<int> output (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  int *data_to_filter = input.data();\n  int *filtered_data = output.data();\n  int nres[1];\n\n  #pragma omp target data map(to: data_to_filter[0:num_elems]) \\\n                          map(from: nres[0:1]) \\\n                          map(from: filtered_data[0:num_elems])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      nres[0] = 0;\n      #pragma omp target update to (nres[0:1]) \n\n\n      #pragma omp target teams num_teams((num_elems+block_size-1)/block_size) \\\n      thread_limit(block_size) \n      {\n        int l_n;\n        #pragma omp parallel \n        {\n          int i = omp_get_team_num() * omp_get_num_threads() + omp_get_thread_num() ;\n          if (omp_get_thread_num() == 0)\n            l_n = 0;\n          #pragma omp barrier\n          int d, pos;\n        \n          if(i < num_elems) {\n            d = data_to_filter[i];\n            if(d > 0) {\n              #pragma omp atomic capture\n              pos = l_n++;\n            }\n          }\n          #pragma omp barrier\n  \n          \n\n          if (omp_get_thread_num() == 0) {\n            \n\n             int old;\n             #pragma omp atomic capture\n             {\n                old = nres[0];\n                nres[0] += l_n; \n             }\n             l_n = old;\n          }\n          #pragma omp barrier\n        \n          \n\n          if(i < num_elems && d > 0) {\n            pos += l_n; \n\n            filtered_data[pos] = d;\n          }\n          #pragma omp barrier\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %lf (ms)\\n\", (time * 1e-6) / repeat);\n  }\n\n  std::vector<int> h_output (num_elems);\n\n  \n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n  std::sort(output.begin(), output.begin() + nres[0]);\n\n  bool equal = (h_flt_count == nres[0]) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_flt_count, output.begin());\n\n  printf(\"\\nFilter using shared memory %s \\n\",\n         equal ? \"PASS\" : \"FAIL\");\n\n  return 0;\n}\n"}}
{"kernel_name": "filter", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n  std::vector<int> output (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  int *data_to_filter = input.data();\n  int *filtered_data = output.data();\n  int nres[1];\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      nres[0] = 0;\n      \n\n            {\n        int l_n;\n                {\n          int i = omp_get_team_num() * omp_get_num_threads() + omp_get_thread_num() ;\n          if (omp_get_thread_num() == 0)\n            l_n = 0;\n                    int d, pos;\n        \n          if(i < num_elems) {\n            d = data_to_filter[i];\n            if(d > 0) {\n                            pos = l_n++;\n            }\n          }\n            \n          \n\n          if (omp_get_thread_num() == 0) {\n            \n\n             int old;\n                          {\n                old = nres[0];\n                nres[0] += l_n; \n             }\n             l_n = old;\n          }\n                  \n          \n\n          if(i < num_elems && d > 0) {\n            pos += l_n; \n\n            filtered_data[pos] = d;\n          }\n                  }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %lf (ms)\\n\", (time * 1e-6) / repeat);\n  }\n\n  std::vector<int> h_output (num_elems);\n\n  \n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n  std::sort(output.begin(), output.begin() + nres[0]);\n\n  bool equal = (h_flt_count == nres[0]) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_flt_count, output.begin());\n\n  printf(\"\\nFilter using shared memory %s \\n\",\n         equal ? \"PASS\" : \"FAIL\");\n\n  return 0;\n}"}}
{"kernel_name": "filter", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <sycl/sycl.hpp>\n\n\n\nbool check(sycl::queue &q, int *d_nres, int *d_output, int h_nres, std::vector<int> &h_output) {\n  int nres;\n  q.memcpy(&nres, d_nres, sizeof(int)).wait();\n\n  std::vector<int> output (nres);\n\n  q.memcpy(output.data(), d_output, sizeof(int) * nres).wait();\n\n  \n\n  q.memset(d_output, 0, sizeof(int) * nres);\n\n  std::sort(output.begin(), output.end());\n\n  bool equal = (h_nres == nres) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_nres, output.begin());\n  return equal;\n}\n\nvoid filter(int *__restrict d_output,\n            int *__restrict d_nres,\n            const int*__restrict__ d_input,\n            const int num_elems,\n            int &l_n,\n            sycl::nd_item<1> &item)\n{\n  int i = item.get_global_id(0);\n\n  \n\n  if (item.get_local_id(0) == 0) l_n = 0;\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  \n\n  int d, pos;\n\n  if(i < num_elems) {\n    d = d_input[i];\n    if(d > 0) {\n      auto ao = sycl::atomic_ref<int,\n                sycl::memory_order::relaxed,\n                sycl::memory_scope::work_group,\n                sycl::access::address_space::local_space> (l_n);\n      pos = ao.fetch_add(1);\n    }\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  if(item.get_local_id(0) == 0) {\n    auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (d_nres[0]);\n    l_n = ao.fetch_add(l_n);\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  if(i < num_elems && d > 0) {\n    pos += l_n; \n\n    d_output[pos] = d;\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n}\n\nint atomicAggInc(int *ctr) {\n  auto g = sycl::ext::oneapi::experimental::this_kernel::get_opportunistic_group();\n  int warp_res = 0;\n  if (g.leader()) {\n    auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (ctr[0]);\n    warp_res = ao.fetch_add(g.get_local_linear_range());\n  }\n  return sycl::group_broadcast(g, warp_res) + g.get_local_linear_id();\n}\n\n\nvoid filter2 (int *__restrict__ dst,\n              int *__restrict__ nres,\n              const int*__restrict__ src,\n              int n,\n              const sycl::nd_item<1> &item)\n{\n  int i = item.get_global_id(0);\n  if (i < n && src[i] > 0)\n    dst[atomicAggInc(nres)] = src[i];\n}\n\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  \n\n  std::vector<int> h_output (num_elems);\n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_input, *d_output, *d_nres;\n\n  d_input = sycl::malloc_device<int>(num_elems, q);\n  d_output = sycl::malloc_device<int>(num_elems, q);\n  d_nres = sycl::malloc_device<int>(1, q);\n\n  q.memcpy(d_input, input.data(), sizeof(int) * num_elems);\n\n  sycl::range<1> lws (block_size);\n  sycl::range<1> gws ((num_elems + block_size - 1) / block_size * block_size);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.memset(d_nres, 0, sizeof(int));\n    q.submit([&](sycl::handler &h) {\n      sycl::local_accessor <int, 0> l_n (h);\n      h.parallel_for<class filter_sharedMem>(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        filter(d_output, d_nres, d_input, num_elems, l_n, item);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (shared memory) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  bool match = check(q, d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.memset(d_nres, 0, sizeof(int));\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class filter_atomicAggInc>(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        filter2(d_output, d_nres, d_input, num_elems, item);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (global aggregate) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  match = check(q, d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_input, q);\n  sycl::free(d_output, q);\n  sycl::free(d_nres, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "fpc", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>      \n\n#include <stdlib.h> \n#include <chrono>\n#include <cuda.h>\n\ntypedef unsigned long ulong;\n\nulong * convertBuffer2Array (char *cbuffer, unsigned size, unsigned step)\n{\n  unsigned i,j; \n  ulong * values = NULL;\n  posix_memalign((void**)&values, 1024, sizeof(ulong)*size/step);\n  for (i = 0; i < size / step; i++) {\n    values[i] = 0;    \n\n  }\n  for (i = 0; i < size; i += step ){\n    for (j = 0; j < step; j++){\n      values[i / step] += (ulong)((unsigned char)cbuffer[i + j]) << (8*j);\n    }\n  }\n  return values;\n}\n\n__host__ __device__\nunsigned my_abs ( int x )\n{\n  unsigned t = x >> 31;\n  return (x ^ t) - t;\n}\n\nunsigned FPCCompress(ulong *values, unsigned size )\n{\n  unsigned compressable = 0;\n  unsigned i;\n  for (i = 0; i < size; i++) {\n    \n\n    if(values[i] == 0){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFF){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFFFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if(((values[i]) & 0xFFFF) == 0 ){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if( my_abs((int)((values[i]) & 0xFFFF)) <= 0xFF\n        && my_abs((int)((values[i] >> 16) & 0xFFFF)) <= 0xFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    unsigned byte0 = (values[i]) & 0xFF;\n    unsigned byte1 = (values[i] >> 8) & 0xFF;\n    unsigned byte2 = (values[i] >> 16) & 0xFF;\n    unsigned byte3 = (values[i] >> 24) & 0xFF;\n    if(byte0 == byte1 && byte0 == byte2 && byte0 == byte3){\n      compressable += 1;\n      continue;\n    }\n    \n\n    compressable += 4;\n  }\n  return compressable;\n}\n\n__device__\nunsigned f1(ulong value, bool* mask) {\n  if (value == 0) {\n    *mask = 1;\n  } \n  return 1;\n}\n\n__device__\nunsigned f2(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFF) *mask = 1;\n  return 1;\n}\n\n__device__\nunsigned f3(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFFFF) *mask = 1;\n  return 2;\n}\n\n__device__\nunsigned f4(ulong value, bool* mask) {\n  if (((value) & 0xFFFF) == 0 ) *mask = 1;\n  return 2;\n}\n\n__device__\nunsigned f5(ulong value, bool* mask) {\n  if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF && \n      my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF) \n    *mask = 1;\n  return 2;\n}\n\n__device__\nunsigned f6(ulong value, bool* mask) {\n  unsigned byte0 = (value) & 0xFF;\n  unsigned byte1 = (value >> 8) & 0xFF;\n  unsigned byte2 = (value >> 16) & 0xFF;\n  unsigned byte3 = (value >> 24) & 0xFF;\n  if (byte0 == byte1 && byte0 == byte2 && byte0 == byte3) \n    *mask = 1;\n  return 1;\n}\n\n__device__\nunsigned f7(ulong value, bool* mask) {\n  *mask = 1;\n  return 4;\n}\n\n__global__ void\nfpc_kernel (const ulong* values, unsigned *cmp_size)\n{\n  __shared__ unsigned compressable;\n  int lid = threadIdx.x;\n  int WGS = blockDim.x;\n  int gid = blockIdx.x*WGS+lid;\n\n  ulong value = values[gid];\n  unsigned inc;\n\n  \n\n  if (value == 0){\n    inc = 1;\n  }\n  \n\n  else if ((my_abs((int)(value)) <= 0xFF)) {\n    inc = 1;\n  }\n  \n\n  else if ((my_abs((int)(value)) <= 0xFFFF)) {\n    inc = 2;\n  }\n  \n\n  else if ((((value) & 0xFFFF) == 0 )) {\n    inc = 2;\n  }\n  \n\n  else if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF\n      && my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF ) {\n    inc = 2;\n  }\n  \n\n  else if( (((value) & 0xFF) == ((value >> 8) & 0xFF)) &&\n      (((value) & 0xFF) == ((value >> 16) & 0xFF)) &&\n      (((value) & 0xFF) == ((value >> 24) & 0xFF)) ) {\n    inc = 1;\n  } else { \n    inc = 4;\n  }\n\n  if (lid == 0) compressable = 0;\n  __syncthreads();\n\n  atomicAdd(&compressable, inc);\n  __syncthreads();\n  if (lid == WGS-1) {\n    atomicAdd(cmp_size, compressable);\n  }\n}\n\n__global__ void\nfpc2_kernel (const ulong* values, unsigned *cmp_size)\n{\n  __shared__ unsigned compressable;\n  int lid = threadIdx.x;\n  int WGS = blockDim.x;\n  int gid = blockIdx.x*WGS+lid;\n\n  unsigned inc;\n\n  bool m1 = 0;\n  bool m2 = 0;\n  bool m3 = 0;\n  bool m4 = 0;\n  bool m5 = 0;\n  bool m6 = 0;\n  bool m7 = 0;\n\n  ulong value = values[gid];\n  unsigned inc1 = f1(value, &m1);\n  unsigned inc2 = f2(value, &m2);\n  unsigned inc3 = f3(value, &m3);\n  unsigned inc4 = f4(value, &m4);\n  unsigned inc5 = f5(value, &m5);\n  unsigned inc6 = f6(value, &m6);\n  unsigned inc7 = f7(value, &m7);\n\n  if (m1)\n    inc = inc1;\n  else if (m2)\n    inc = inc2;\n  else if (m3)\n    inc = inc3;\n  else if (m4)\n    inc = inc4;\n  else if (m5)\n    inc = inc5;\n  else if (m6)\n    inc = inc6;\n  else\n    inc = inc7;\n\n\n  if (lid == 0) compressable = 0;\n  __syncthreads();\n\n  atomicAdd(&compressable, inc);\n  __syncthreads();\n  if (lid == WGS-1) {\n    atomicAdd(cmp_size, compressable);\n  }\n}\n\nvoid fpc (const ulong* values, unsigned *cmp_size_hw, const int values_size, const int wgs)\n{\n  *cmp_size_hw = 0;\n  ulong* d_values;\n  unsigned* d_cmp_size;\n  cudaMalloc((void**)&d_values, values_size*sizeof(ulong));\n  cudaMemcpy(d_values, values, values_size*sizeof(ulong), cudaMemcpyHostToDevice);\n  cudaMalloc((void**)&d_cmp_size, sizeof(unsigned));\n  cudaMemcpy(d_cmp_size, cmp_size_hw, sizeof(unsigned), cudaMemcpyHostToDevice);\n\n  dim3 grids (values_size/wgs);\n  dim3 threads (wgs);\n\n  fpc_kernel<<<grids, threads>>>(d_values, d_cmp_size);\n\n  cudaMemcpy(cmp_size_hw, d_cmp_size, sizeof(unsigned), cudaMemcpyDeviceToHost);\n  cudaFree(d_values);\n  cudaFree(d_cmp_size);\n}\n\nvoid fpc2 (const ulong* values, unsigned *cmp_size_hw, const int values_size, const int wgs)\n{\n  *cmp_size_hw = 0;\n  ulong* d_values;\n  unsigned* d_cmp_size;\n  cudaMalloc((void**)&d_values, values_size*sizeof(ulong));\n  cudaMemcpy(d_values, values, values_size*sizeof(ulong), cudaMemcpyHostToDevice);\n  cudaMalloc((void**)&d_cmp_size, sizeof(unsigned));\n  cudaMemcpy(d_cmp_size, cmp_size_hw, sizeof(unsigned), cudaMemcpyHostToDevice);\n\n  dim3 grids (values_size/wgs);\n  dim3 threads (wgs);\n\n  fpc2_kernel<<<grids, threads>>>(d_values, d_cmp_size);\n\n  cudaMemcpy(cmp_size_hw, d_cmp_size, sizeof(unsigned), cudaMemcpyDeviceToHost);\n  cudaFree(d_values);\n  cudaFree(d_cmp_size);\n}\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <work-group size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int wgs = atoi(argv[1]); \n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int step = 4;\n  const size_t size = (size_t)wgs * wgs * wgs;\n  char* cbuffer = (char*) malloc (size * step);\n\n  srand(2);\n  for (size_t i = 0; i < size*step; i++) {\n    cbuffer[i] = 0xFF << (rand() % 256);\n  }\n\n  ulong *values = convertBuffer2Array (cbuffer, size, step);\n  unsigned values_size = size / step;\n\n  \n\n  unsigned cmp_size = FPCCompress(values, values_size);\n\n  \n\n  unsigned cmp_size_hw; \n\n  bool ok = true;\n\n  \n\n  fpc(values, &cmp_size_hw, values_size, wgs);\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc(values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  auto end = std::chrono::high_resolution_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  fpc2(values, &cmp_size_hw, values_size, wgs);\n\n  start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc2(values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc2 failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  end = std::chrono::high_resolution_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc2: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(values);\n  free(cbuffer);\n  return 0;\n}\n"}}
{"kernel_name": "fpc", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>      \n\n#include <stdlib.h> \n#include <chrono>\n#include <hip/hip_runtime.h>\n\ntypedef unsigned long ulong;\n\nulong * convertBuffer2Array (char *cbuffer, unsigned size, unsigned step)\n{\n  unsigned i,j; \n  ulong * values = NULL;\n  posix_memalign((void**)&values, 1024, sizeof(ulong)*size/step);\n  for (i = 0; i < size / step; i++) {\n    values[i] = 0;    \n\n  }\n  for (i = 0; i < size; i += step ){\n    for (j = 0; j < step; j++){\n      values[i / step] += (ulong)((unsigned char)cbuffer[i + j]) << (8*j);\n    }\n  }\n  return values;\n}\n\n__host__ __device__\nunsigned my_abs ( int x )\n{\n  unsigned t = x >> 31;\n  return (x ^ t) - t;\n}\n\nunsigned FPCCompress(ulong *values, unsigned size )\n{\n  unsigned compressable = 0;\n  unsigned i;\n  for (i = 0; i < size; i++) {\n    \n\n    if(values[i] == 0){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFF){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFFFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if(((values[i]) & 0xFFFF) == 0 ){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if( my_abs((int)((values[i]) & 0xFFFF)) <= 0xFF\n        && my_abs((int)((values[i] >> 16) & 0xFFFF)) <= 0xFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    unsigned byte0 = (values[i]) & 0xFF;\n    unsigned byte1 = (values[i] >> 8) & 0xFF;\n    unsigned byte2 = (values[i] >> 16) & 0xFF;\n    unsigned byte3 = (values[i] >> 24) & 0xFF;\n    if(byte0 == byte1 && byte0 == byte2 && byte0 == byte3){\n      compressable += 1;\n      continue;\n    }\n    \n\n    compressable += 4;\n  }\n  return compressable;\n}\n\n__device__\nunsigned f1(ulong value, bool* mask) {\n  if (value == 0) {\n    *mask = 1;\n  } \n  return 1;\n}\n\n__device__\nunsigned f2(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFF) *mask = 1;\n  return 1;\n}\n\n__device__\nunsigned f3(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFFFF) *mask = 1;\n  return 2;\n}\n\n__device__\nunsigned f4(ulong value, bool* mask) {\n  if (((value) & 0xFFFF) == 0 ) *mask = 1;\n  return 2;\n}\n\n__device__\nunsigned f5(ulong value, bool* mask) {\n  if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF && \n      my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF) \n    *mask = 1;\n  return 2;\n}\n\n__device__\nunsigned f6(ulong value, bool* mask) {\n  unsigned byte0 = (value) & 0xFF;\n  unsigned byte1 = (value >> 8) & 0xFF;\n  unsigned byte2 = (value >> 16) & 0xFF;\n  unsigned byte3 = (value >> 24) & 0xFF;\n  if (byte0 == byte1 && byte0 == byte2 && byte0 == byte3) \n    *mask = 1;\n  return 1;\n}\n\n__device__\nunsigned f7(ulong value, bool* mask) {\n  *mask = 1;\n  return 4;\n}\n\n__global__ void\nfpc_kernel (const ulong* values, unsigned *cmp_size)\n{\n  __shared__ unsigned compressable;\n  int lid = threadIdx.x;\n  int WGS = blockDim.x;\n  int gid = blockIdx.x*WGS+lid;\n\n  ulong value = values[gid];\n  unsigned inc;\n\n  \n\n  if (value == 0){\n    inc = 1;\n  }\n  \n\n  else if ((my_abs((int)(value)) <= 0xFF)) {\n    inc = 1;\n  }\n  \n\n  else if ((my_abs((int)(value)) <= 0xFFFF)) {\n    inc = 2;\n  }\n  \n\n  else if ((((value) & 0xFFFF) == 0 )) {\n    inc = 2;\n  }\n  \n\n  else if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF\n      && my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF ) {\n    inc = 2;\n  }\n  \n\n  else if( (((value) & 0xFF) == ((value >> 8) & 0xFF)) &&\n      (((value) & 0xFF) == ((value >> 16) & 0xFF)) &&\n      (((value) & 0xFF) == ((value >> 24) & 0xFF)) ) {\n    inc = 1;\n  } else { \n    inc = 4;\n  }\n\n  if (lid == 0) compressable = 0;\n  __syncthreads();\n\n  atomicAdd(&compressable, inc);\n  __syncthreads();\n  if (lid == WGS-1) {\n    atomicAdd(cmp_size, compressable);\n  }\n}\n\n__global__ void\nfpc2_kernel (const ulong* values, unsigned *cmp_size)\n{\n  __shared__ unsigned compressable;\n  int lid = threadIdx.x;\n  int WGS = blockDim.x;\n  int gid = blockIdx.x*WGS+lid;\n\n  unsigned inc;\n\n  bool m1 = 0;\n  bool m2 = 0;\n  bool m3 = 0;\n  bool m4 = 0;\n  bool m5 = 0;\n  bool m6 = 0;\n  bool m7 = 0;\n\n  ulong value = values[gid];\n  unsigned inc1 = f1(value, &m1);\n  unsigned inc2 = f2(value, &m2);\n  unsigned inc3 = f3(value, &m3);\n  unsigned inc4 = f4(value, &m4);\n  unsigned inc5 = f5(value, &m5);\n  unsigned inc6 = f6(value, &m6);\n  unsigned inc7 = f7(value, &m7);\n\n  if (m1)\n    inc = inc1;\n  else if (m2)\n    inc = inc2;\n  else if (m3)\n    inc = inc3;\n  else if (m4)\n    inc = inc4;\n  else if (m5)\n    inc = inc5;\n  else if (m6)\n    inc = inc6;\n  else\n    inc = inc7;\n\n\n  if (lid == 0) compressable = 0;\n  __syncthreads();\n\n  atomicAdd(&compressable, inc);\n  __syncthreads();\n  if (lid == WGS-1) {\n    atomicAdd(cmp_size, compressable);\n  }\n}\n\nvoid fpc (const ulong* values, unsigned *cmp_size_hw, const int values_size, const int wgs)\n{\n  *cmp_size_hw = 0;\n  ulong* d_values;\n  unsigned* d_cmp_size;\n  hipMalloc((void**)&d_values, values_size*sizeof(ulong));\n  hipMemcpy(d_values, values, values_size*sizeof(ulong), hipMemcpyHostToDevice);\n  hipMalloc((void**)&d_cmp_size, sizeof(unsigned));\n  hipMemcpy(d_cmp_size, cmp_size_hw, sizeof(unsigned), hipMemcpyHostToDevice);\n\n  dim3 grids (values_size/wgs);\n  dim3 threads (wgs);\n\n  hipLaunchKernelGGL(fpc_kernel, grids, threads, 0, 0, d_values, d_cmp_size);\n\n  hipMemcpy(cmp_size_hw, d_cmp_size, sizeof(unsigned), hipMemcpyDeviceToHost);\n  hipFree(d_values);\n  hipFree(d_cmp_size);\n}\n\nvoid fpc2 (const ulong* values, unsigned *cmp_size_hw, const int values_size, const int wgs)\n{\n  *cmp_size_hw = 0;\n  ulong* d_values;\n  unsigned* d_cmp_size;\n  hipMalloc((void**)&d_values, values_size*sizeof(ulong));\n  hipMemcpy(d_values, values, values_size*sizeof(ulong), hipMemcpyHostToDevice);\n  hipMalloc((void**)&d_cmp_size, sizeof(unsigned));\n  hipMemcpy(d_cmp_size, cmp_size_hw, sizeof(unsigned), hipMemcpyHostToDevice);\n\n  dim3 grids (values_size/wgs);\n  dim3 threads (wgs);\n\n  hipLaunchKernelGGL(fpc2_kernel, grids, threads, 0, 0, d_values, d_cmp_size);\n\n  hipMemcpy(cmp_size_hw, d_cmp_size, sizeof(unsigned), hipMemcpyDeviceToHost);\n  hipFree(d_values);\n  hipFree(d_cmp_size);\n}\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <work-group size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int wgs = atoi(argv[1]); \n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int step = 4;\n  const size_t size = (size_t)wgs * wgs * wgs;\n  char* cbuffer = (char*) malloc (size * step);\n\n  srand(2);\n  for (size_t i = 0; i < size*step; i++) {\n    cbuffer[i] = 0xFF << (rand() % 256);\n  }\n\n  ulong *values = convertBuffer2Array (cbuffer, size, step);\n  unsigned values_size = size / step;\n\n  \n\n  unsigned cmp_size = FPCCompress(values, values_size);\n\n  \n\n  unsigned cmp_size_hw; \n\n  bool ok = true;\n\n  \n\n  fpc(values, &cmp_size_hw, values_size, wgs);\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc(values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  auto end = std::chrono::high_resolution_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  fpc2(values, &cmp_size_hw, values_size, wgs);\n\n  start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc2(values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc2 failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  end = std::chrono::high_resolution_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc2: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(values);\n  free(cbuffer);\n  return 0;\n}\n"}}
{"kernel_name": "fpc", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h> \n#include <chrono>\n#include <omp.h>\n\ntypedef unsigned long ulong;\n\nulong * convertBuffer2Array (char *cbuffer, unsigned size, unsigned step)\n{\n  unsigned i,j; \n  ulong * values = NULL;\n  posix_memalign((void**)&values, 1024, sizeof(ulong)*size/step);\n  for (i = 0; i < size / step; i++) {\n    values[i] = 0;    \n\n  }\n  for (i = 0; i < size; i += step ){\n    for (j = 0; j < step; j++){\n      values[i / step] += (ulong)((unsigned char)cbuffer[i + j]) << (8*j);\n    }\n  }\n  return values;\n}\n\n#pragma omp declare target\nunsigned my_abs ( int x )\n{\n  unsigned t = x >> 31;\n  return (x ^ t) - t;\n}\n\nunsigned FPCCompress(ulong *values, unsigned size )\n{\n  unsigned compressable = 0;\n  unsigned i;\n  for (i = 0; i < size; i++) {\n    \n\n    if(values[i] == 0){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFF){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFFFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if(((values[i]) & 0xFFFF) == 0 ){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if( my_abs((int)((values[i]) & 0xFFFF)) <= 0xFF\n        && my_abs((int)((values[i] >> 16) & 0xFFFF)) <= 0xFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    unsigned byte0 = (values[i]) & 0xFF;\n    unsigned byte1 = (values[i] >> 8) & 0xFF;\n    unsigned byte2 = (values[i] >> 16) & 0xFF;\n    unsigned byte3 = (values[i] >> 24) & 0xFF;\n    if(byte0 == byte1 && byte0 == byte2 && byte0 == byte3){\n      compressable += 1;\n      continue;\n    }\n    \n\n    compressable += 4;\n  }\n  return compressable;\n}\n\nunsigned f1(ulong value, bool* mask) {\n  if (value == 0) {\n    *mask = 1;\n  } \n  return 1;\n}\n\nunsigned f2(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFF) *mask = 1;\n  return 1;\n}\n\nunsigned f3(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFFFF) *mask = 1;\n  return 2;\n}\n\nunsigned f4(ulong value, bool* mask) {\n  if (((value) & 0xFFFF) == 0 ) *mask = 1;\n  return 2;\n}\n\nunsigned f5(ulong value, bool* mask) {\n  if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF && \n      my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF) \n    *mask = 1;\n  return 2;\n}\n\nunsigned f6(ulong value, bool* mask) {\n  unsigned byte0 = (value) & 0xFF;\n  unsigned byte1 = (value >> 8) & 0xFF;\n  unsigned byte2 = (value >> 16) & 0xFF;\n  unsigned byte3 = (value >> 24) & 0xFF;\n  if (byte0 == byte1 && byte0 == byte2 && byte0 == byte3) \n    *mask = 1;\n  return 1;\n}\n\nunsigned f7(ulong value, bool* mask) {\n  *mask = 1;\n  return 4;\n}\n#pragma omp end declare target\n\nvoid fpc (const ulong* values, unsigned *cmp_size, const int values_size, const int wgs)\n{\n  *cmp_size= 0;\n  #pragma omp target data map(to: values[0:values_size]) map(tofrom: cmp_size[0:1])\n  {\n    #pragma omp target teams num_teams(values_size/wgs) thread_limit(wgs) \n    {\n      unsigned compressable;\n      #pragma omp parallel\n      {\n        int lid = omp_get_thread_num();\n        int WGS = omp_get_num_threads();\n        int gid = omp_get_team_num()*WGS+lid;\n\n        ulong value = values[gid];\n        unsigned inc;\n\n        \n\n        if (value == 0){\n          inc = 1;\n        }\n        \n\n        else if ((my_abs((int)(value)) <= 0xFF)) {\n          inc = 1;\n        }\n        \n\n        else if ((my_abs((int)(value)) <= 0xFFFF)) {\n          inc = 2;\n        }\n        \n\n        else if ((((value) & 0xFFFF) == 0 )) {\n          inc = 2;\n        }\n        \n\n        else if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF\n            && my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF ) {\n          inc = 2;\n        }\n        \n\n        else if( (((value) & 0xFF) == ((value >> 8) & 0xFF)) &&\n            (((value) & 0xFF) == ((value >> 16) & 0xFF)) &&\n            (((value) & 0xFF) == ((value >> 24) & 0xFF)) ) {\n          inc = 1;\n        } else { \n          inc = 4;\n        }\n\n        if (lid == 0) compressable = 0;\n        #pragma omp barrier\n\n        #pragma omp atomic update \n        compressable += inc;\n        #pragma omp barrier\n        if (lid == WGS-1) {\n        #pragma omp atomic update \n          cmp_size[0] += compressable;\n        }\n      }\n    }\n  }\n}\n\nvoid fpc2 (const ulong* values, unsigned *cmp_size, const int values_size, const int wgs)\n{\n  *cmp_size= 0;\n  #pragma omp target data map(to: values[0:values_size]) map(tofrom: cmp_size[0:1])\n  {\n    #pragma omp target teams num_teams(values_size/wgs) thread_limit(wgs)\n    {\n      unsigned compressable;\n      #pragma omp parallel\n      {\n        int lid = omp_get_thread_num();\n        int WGS = omp_get_num_threads();\n        int gid = omp_get_team_num()*WGS+lid;\n\n        ulong value = values[gid];\n\n        unsigned inc;\n\n        bool m1 = 0;\n        bool m2 = 0;\n        bool m3 = 0;\n        bool m4 = 0;\n        bool m5 = 0;\n        bool m6 = 0;\n        bool m7 = 0;\n\n        unsigned inc1 = f1(value, &m1);\n        unsigned inc2 = f2(value, &m2);\n        unsigned inc3 = f3(value, &m3);\n        unsigned inc4 = f4(value, &m4);\n        unsigned inc5 = f5(value, &m5);\n        unsigned inc6 = f6(value, &m6);\n        unsigned inc7 = f7(value, &m7);\n\n        if (m1)\n          inc = inc1;\n        else if (m2)\n          inc = inc2;\n        else if (m3)\n          inc = inc3;\n        else if (m4)\n          inc = inc4;\n        else if (m5)\n          inc = inc5;\n        else if (m6)\n          inc = inc6;\n        else\n          inc = inc7;\n\n        if (lid == 0) compressable = 0;\n        #pragma omp barrier\n\n        #pragma omp atomic update \n        compressable += inc;\n\n        #pragma omp barrier\n        if (lid == WGS-1) {\n          #pragma omp atomic update \n          cmp_size[0] += compressable;\n        }\n      }\n    }\n  }\n}\n\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <work-group size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int wgs = atoi(argv[1]); \n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int step = 4;\n  const size_t size = (size_t)wgs * wgs * wgs;\n  char* cbuffer = (char*) malloc (size * step);\n\n  srand(2);\n  for (int i = 0; i < size*step; i++) {\n    cbuffer[i] = 0xFF << (rand() % 256);\n  }\n\n  ulong *values = convertBuffer2Array (cbuffer, size, step);\n  unsigned values_size = size / step;\n\n  \n\n  unsigned cmp_size = FPCCompress(values, values_size);\n\n  \n\n  unsigned cmp_size_hw; \n\n  bool ok = true;\n\n  \n\n  fpc(values, &cmp_size_hw, values_size, wgs);\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc(values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  auto end = std::chrono::high_resolution_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  fpc2(values, &cmp_size_hw, values_size, wgs);\n\n  start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc2(values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc2 failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  end = std::chrono::high_resolution_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc2: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(values);\n  free(cbuffer);\n  return 0;\n}\n"}}
{"kernel_name": "fpc", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h> \n#include <chrono>\n\ntypedef unsigned long ulong;\n\nulong * convertBuffer2Array (char *cbuffer, unsigned size, unsigned step)\n{\n  unsigned i,j; \n  ulong * values = NULL;\n  posix_memalign((void**)&values, 1024, sizeof(ulong)*size/step);\n  for (i = 0; i < size / step; i++) {\n    values[i] = 0;    \n\n  }\n  for (i = 0; i < size; i += step ){\n    for (j = 0; j < step; j++){\n      values[i / step] += (ulong)((unsigned char)cbuffer[i + j]) << (8*j);\n    }\n  }\n  return values;\n}\n\nunsigned my_abs ( int x )\n{\n  unsigned t = x >> 31;\n  return (x ^ t) - t;\n}\n\nunsigned FPCCompress(ulong *values, unsigned size )\n{\n  unsigned compressable = 0;\n  unsigned i;\n  for (i = 0; i < size; i++) {\n    \n\n    if(values[i] == 0){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFF){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFFFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if(((values[i]) & 0xFFFF) == 0 ){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if( my_abs((int)((values[i]) & 0xFFFF)) <= 0xFF\n        && my_abs((int)((values[i] >> 16) & 0xFFFF)) <= 0xFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    unsigned byte0 = (values[i]) & 0xFF;\n    unsigned byte1 = (values[i] >> 8) & 0xFF;\n    unsigned byte2 = (values[i] >> 16) & 0xFF;\n    unsigned byte3 = (values[i] >> 24) & 0xFF;\n    if(byte0 == byte1 && byte0 == byte2 && byte0 == byte3){\n      compressable += 1;\n      continue;\n    }\n    \n\n    compressable += 4;\n  }\n  return compressable;\n}\n\nunsigned f1(ulong value, bool* mask) {\n  if (value == 0) {\n    *mask = 1;\n  } \n  return 1;\n}\n\nunsigned f2(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFF) *mask = 1;\n  return 1;\n}\n\nunsigned f3(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFFFF) *mask = 1;\n  return 2;\n}\n\nunsigned f4(ulong value, bool* mask) {\n  if (((value) & 0xFFFF) == 0 ) *mask = 1;\n  return 2;\n}\n\nunsigned f5(ulong value, bool* mask) {\n  if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF && \n      my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF) \n    *mask = 1;\n  return 2;\n}\n\nunsigned f6(ulong value, bool* mask) {\n  unsigned byte0 = (value) & 0xFF;\n  unsigned byte1 = (value >> 8) & 0xFF;\n  unsigned byte2 = (value >> 16) & 0xFF;\n  unsigned byte3 = (value >> 24) & 0xFF;\n  if (byte0 == byte1 && byte0 == byte2 && byte0 == byte3) \n    *mask = 1;\n  return 1;\n}\n\nunsigned f7(ulong value, bool* mask) {\n  *mask = 1;\n  return 4;\n}\n\nvoid fpc (const ulong* values, unsigned *cmp_size, const int values_size, const int wgs)\n{\n  *cmp_size= 0;\n    {\n        {\n      unsigned compressable;\n            {\n        int lid = omp_get_thread_num();\n        int WGS = omp_get_num_threads();\n        int gid = omp_get_team_num()*WGS+lid;\n\n        ulong value = values[gid];\n        unsigned inc;\n\n        \n\n        if (value == 0){\n          inc = 1;\n        }\n        \n\n        else if ((my_abs((int)(value)) <= 0xFF)) {\n          inc = 1;\n        }\n        \n\n        else if ((my_abs((int)(value)) <= 0xFFFF)) {\n          inc = 2;\n        }\n        \n\n        else if ((((value) & 0xFFFF) == 0 )) {\n          inc = 2;\n        }\n        \n\n        else if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF\n            && my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF ) {\n          inc = 2;\n        }\n        \n\n        else if( (((value) & 0xFF) == ((value >> 8) & 0xFF)) &&\n            (((value) & 0xFF) == ((value >> 16) & 0xFF)) &&\n            (((value) & 0xFF) == ((value >> 24) & 0xFF)) ) {\n          inc = 1;\n        } else { \n          inc = 4;\n        }\n\n        if (lid == 0) compressable = 0;\n        \n                compressable += inc;\n                if (lid == WGS-1) {\n                  cmp_size[0] += compressable;\n        }\n      }\n    }\n  }\n}\n\nvoid fpc2 (const ulong* values, unsigned *cmp_size, const int values_size, const int wgs)\n{\n  *cmp_size= 0;\n    {\n        {\n      unsigned compressable;\n            {\n        int lid = omp_get_thread_num();\n        int WGS = omp_get_num_threads();\n        int gid = omp_get_team_num()*WGS+lid;\n\n        ulong value = values[gid];\n\n        unsigned inc;\n\n        bool m1 = 0;\n        bool m2 = 0;\n        bool m3 = 0;\n        bool m4 = 0;\n        bool m5 = 0;\n        bool m6 = 0;\n        bool m7 = 0;\n\n        unsigned inc1 = f1(value, &m1);\n        unsigned inc2 = f2(value, &m2);\n        unsigned inc3 = f3(value, &m3);\n        unsigned inc4 = f4(value, &m4);\n        unsigned inc5 = f5(value, &m5);\n        unsigned inc6 = f6(value, &m6);\n        unsigned inc7 = f7(value, &m7);\n\n        if (m1)\n          inc = inc1;\n        else if (m2)\n          inc = inc2;\n        else if (m3)\n          inc = inc3;\n        else if (m4)\n          inc = inc4;\n        else if (m5)\n          inc = inc5;\n        else if (m6)\n          inc = inc6;\n        else\n          inc = inc7;\n\n        if (lid == 0) compressable = 0;\n        \n                compressable += inc;\n\n                if (lid == WGS-1) {\n                    cmp_size[0] += compressable;\n        }\n      }\n    }\n  }\n}\n\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <work-group size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int wgs = atoi(argv[1]); \n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int step = 4;\n  const size_t size = (size_t)wgs * wgs * wgs;\n  char* cbuffer = (char*) malloc (size * step);\n\n  srand(2);\n  for (int i = 0; i < size*step; i++) {\n    cbuffer[i] = 0xFF << (rand() % 256);\n  }\n\n  ulong *values = convertBuffer2Array (cbuffer, size, step);\n  unsigned values_size = size / step;\n\n  \n\n  unsigned cmp_size = FPCCompress(values, values_size);\n\n  \n\n  unsigned cmp_size_hw; \n\n  bool ok = true;\n\n  \n\n  fpc(values, &cmp_size_hw, values_size, wgs);\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc(values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  auto end = std::chrono::high_resolution_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  fpc2(values, &cmp_size_hw, values_size, wgs);\n\n  start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc2(values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc2 failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  end = std::chrono::high_resolution_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc2: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(values);\n  free(cbuffer);\n  return 0;\n}"}}
{"kernel_name": "fpc", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>      \n\n#include <stdlib.h> \n#include <chrono>\n#include <sycl/sycl.hpp>\n\ntypedef unsigned long ulong;\n\nulong * convertBuffer2Array (char *cbuffer, unsigned size, unsigned step)\n{\n  unsigned i,j; \n  ulong * values = NULL;\n  posix_memalign((void**)&values, 1024, sizeof(ulong)*size/step);\n  for (i = 0; i < size / step; i++) {\n    values[i] = 0;    \n\n  }\n  for (i = 0; i < size; i += step ){\n    for (j = 0; j < step; j++){\n      values[i / step] += (ulong)((unsigned char)cbuffer[i + j]) << (8*j);\n    }\n  }\n  return values;\n}\n\nunsigned my_abs ( int x )\n{\n  unsigned t = x >> 31;\n  return (x ^ t) - t;\n}\n\nunsigned FPCCompress(ulong *values, unsigned size )\n{\n  unsigned compressable = 0;\n  unsigned i;\n  for (i = 0; i < size; i++) {\n    \n\n    if(values[i] == 0){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFF){\n      compressable += 1;\n      continue;\n    }\n    \n\n    if(my_abs((int)(values[i])) <= 0xFFFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if(((values[i]) & 0xFFFF) == 0 ){\n      compressable += 2;\n      continue;\n    }\n    \n\n    if( my_abs((int)((values[i]) & 0xFFFF)) <= 0xFF\n        && my_abs((int)((values[i] >> 16) & 0xFFFF)) <= 0xFF){\n      compressable += 2;\n      continue;\n    }\n    \n\n    unsigned byte0 = (values[i]) & 0xFF;\n    unsigned byte1 = (values[i] >> 8) & 0xFF;\n    unsigned byte2 = (values[i] >> 16) & 0xFF;\n    unsigned byte3 = (values[i] >> 24) & 0xFF;\n    if(byte0 == byte1 && byte0 == byte2 && byte0 == byte3){\n      compressable += 1;\n      continue;\n    }\n    \n\n    compressable += 4;\n  }\n  return compressable;\n}\n\nunsigned f1(ulong value, bool* mask) {\n  if (value == 0) {\n    *mask = 1;\n  } \n  return 1;\n}\n\nunsigned f2(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFF) *mask = 1;\n  return 1;\n}\n\nunsigned f3(ulong value, bool* mask) {\n  if (my_abs((int)(value)) <= 0xFFFF) *mask = 1;\n  return 2;\n}\n\nunsigned f4(ulong value, bool* mask) {\n  if (((value) & 0xFFFF) == 0 ) *mask = 1;\n  return 2;\n}\n\nunsigned f5(ulong value, bool* mask) {\n  if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF && \n      my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF) \n    *mask = 1;\n  return 2;\n}\n\nunsigned f6(ulong value, bool* mask) {\n  unsigned byte0 = (value) & 0xFF;\n  unsigned byte1 = (value >> 8) & 0xFF;\n  unsigned byte2 = (value >> 16) & 0xFF;\n  unsigned byte3 = (value >> 24) & 0xFF;\n  if (byte0 == byte1 && byte0 == byte2 && byte0 == byte3) \n    *mask = 1;\n  return 1;\n}\n\nunsigned f7(ulong value, bool* mask) {\n  *mask = 1;\n  return 4;\n}\n\ntemplate<typename sycl::memory_scope MemoryScope = sycl::memory_scope::device>\nstatic inline void atomicAdd(unsigned& val, const unsigned delta)\n{\n  sycl::atomic_ref<unsigned, sycl::memory_order::relaxed, \n     MemoryScope, sycl::access::address_space::generic_space> ref(val);\n  ref.fetch_add(delta);\n}\n\nvoid fpc_kernel (sycl::nd_item<1> &item, unsigned &compressable,\n                 const ulong* values, unsigned *cmp_size)\n{\n  int gid = item.get_global_id(0);\n  int lid = item.get_local_id(0);\n  int WGS = item.get_local_range(0);\n\n  ulong value = values[gid];\n  unsigned inc;\n\n  \n\n  if (value == 0){\n    inc = 1;\n  }\n  \n\n  else if ((my_abs((int)(value)) <= 0xFF)) {\n    inc = 1;\n  }\n  \n\n  else if ((my_abs((int)(value)) <= 0xFFFF)) {\n    inc = 2;\n  }\n  \n\n  else if ((((value) & 0xFFFF) == 0 )) {\n    inc = 2;\n  }\n  \n\n  else if ((my_abs((int)((value) & 0xFFFF))) <= 0xFF\n      && my_abs((int)((value >> 16) & 0xFFFF)) <= 0xFF ) {\n    inc = 2;\n  }\n  \n\n  else if( (((value) & 0xFF) == ((value >> 8) & 0xFF)) &&\n      (((value) & 0xFF) == ((value >> 16) & 0xFF)) &&\n      (((value) & 0xFF) == ((value >> 24) & 0xFF)) ) {\n    inc = 1;\n  } else { \n    inc = 4;\n  }\n\n  if (lid == 0) compressable = 0;\n  item.barrier(sycl::access::fence_space::local_space);\n\n  atomicAdd<sycl::memory_scope::work_group>(compressable, inc);\n  item.barrier(sycl::access::fence_space::local_space);\n  if (lid == WGS-1) {\n    atomicAdd(cmp_size[0], compressable);\n  }\n}\n\nvoid fpc2_kernel (sycl::nd_item<1> &item, unsigned &compressable,\n                  const ulong* values, unsigned *cmp_size)\n{\n  int gid = item.get_global_id(0);\n  int lid = item.get_local_id(0);\n  int WGS = item.get_local_range(0);\n  unsigned inc;\n\n  bool m1 = 0;\n  bool m2 = 0;\n  bool m3 = 0;\n  bool m4 = 0;\n  bool m5 = 0;\n  bool m6 = 0;\n  bool m7 = 0;\n\n  ulong value = values[gid];\n  unsigned inc1 = f1(value, &m1);\n  unsigned inc2 = f2(value, &m2);\n  unsigned inc3 = f3(value, &m3);\n  unsigned inc4 = f4(value, &m4);\n  unsigned inc5 = f5(value, &m5);\n  unsigned inc6 = f6(value, &m6);\n  unsigned inc7 = f7(value, &m7);\n\n  if (m1)\n    inc = inc1;\n  else if (m2)\n    inc = inc2;\n  else if (m3)\n    inc = inc3;\n  else if (m4)\n    inc = inc4;\n  else if (m5)\n    inc = inc5;\n  else if (m6)\n    inc = inc6;\n  else\n    inc = inc7;\n\n  if (lid == 0) compressable = 0;\n  item.barrier(sycl::access::fence_space::local_space);\n\n  atomicAdd<sycl::memory_scope::work_group>(compressable, inc);\n  item.barrier(sycl::access::fence_space::local_space);\n  if (lid == WGS-1) {\n    atomicAdd(cmp_size[0], compressable);\n  }\n}\n\nvoid fpc (sycl::queue &q, const ulong* values, unsigned *cmp_size_hw,\n          const int values_size, const int wgs)\n{\n  *cmp_size_hw = 0;\n\n  ulong *d_values = sycl::malloc_device<ulong>(values_size, q);\n  q.memcpy(d_values, values, values_size * sizeof(ulong));\n\n  unsigned *d_cmp_size = sycl::malloc_device<unsigned>(1, q);\n  q.memset(d_cmp_size, 0, sizeof(unsigned));\n\n  sycl::range<1> gws (values_size);\n  sycl::range<1> lws (wgs);\n\n  q.submit([&](sycl::handler &h) {\n    sycl::local_accessor<unsigned, 0> compressable(h);\n    h.parallel_for<class test1>(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      fpc_kernel(item, compressable, d_values, d_cmp_size);\n    });\n  });\n\n  q.memcpy(cmp_size_hw, d_cmp_size, sizeof(unsigned)).wait();\n  sycl::free(d_values, q);\n  sycl::free(d_cmp_size, q);\n}\n\nvoid fpc2 (sycl::queue &q, const ulong* values, unsigned *cmp_size_hw,\n           const int values_size, const int wgs)\n{\n  *cmp_size_hw = 0;\n\n  ulong *d_values = sycl::malloc_device<ulong>(values_size, q);\n  q.memcpy(d_values, values, values_size * sizeof(ulong));\n\n  unsigned *d_cmp_size = sycl::malloc_device<unsigned>(1, q);\n  q.memset(d_cmp_size, 0, sizeof(unsigned));\n\n  sycl::range<1> gws (values_size);\n  sycl::range<1> lws (wgs);\n\n  q.submit([&](sycl::handler &h) {\n    sycl::local_accessor<unsigned, 0> compressable (h);\n    h.parallel_for<class test2>(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      fpc2_kernel(item, compressable, d_values, d_cmp_size);\n    });\n  });\n\n  q.memcpy(cmp_size_hw, d_cmp_size, sizeof(unsigned)).wait();\n  sycl::free(d_values, q);\n  sycl::free(d_cmp_size, q);\n}\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <work-group size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int wgs = atoi(argv[1]); \n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int step = 4;\n  const size_t size = (size_t)wgs * wgs * wgs;\n  char* cbuffer = (char*) malloc (size * step);\n\n  srand(2);\n  for (int i = 0; i < size*step; i++) {\n    cbuffer[i] = 0xFF << (rand() % 256);\n  }\n\n  ulong *values = convertBuffer2Array (cbuffer, size, step);\n  unsigned values_size = size / step;\n\n  \n\n  unsigned cmp_size = FPCCompress(values, values_size);\n\n  unsigned cmp_size_hw; \n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  bool ok = true;\n \n  \n\n  fpc(q, values, &cmp_size_hw, values_size, wgs);\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc(q, values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n  auto end = std::chrono::high_resolution_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  fpc2(q, values, &cmp_size_hw, values_size, wgs);\n\n  start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    fpc2(q, values, &cmp_size_hw, values_size, wgs);\n    if (cmp_size_hw != cmp_size) {\n      printf(\"fpc2 failed %u != %u\\n\", cmp_size_hw, cmp_size);\n      ok = false;\n      break;\n    }\n  }\n\n  end = std::chrono::high_resolution_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"fpc2: average device offload time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(values);\n  free(cbuffer);\n  return 0;\n}\n"}}
{"kernel_name": "histogram", "parallel_api": "cuda", "code": {"histogram_compare.cu": "\n\n\n#include <stdio.h>\n#include <map>\n#include <vector>\n#include <algorithm>\n#include <cstdio>\n#include <cstring>\n#include <fstream>\n#include \"test_util.h\"\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\n__device__ __forceinline__ void DecodePixel(float4 &pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float samples[4];\n    samples[0] = pixel.x;\n    samples[1] = pixel.y;\n    samples[2] = pixel.z;\n    samples[3] = pixel.w;\n\n    #pragma unroll\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\n__device__ __forceinline__ void DecodePixel(uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char samples[4];\n    samples[0] = pixel.x;\n    samples[1] = pixel.y;\n    samples[2] = pixel.z;\n    samples[3] = pixel.w;\n\n    #pragma unroll\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\n__device__ __forceinline__ void DecodePixel(uchar1 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel.x;\n}\n\n#include \"histogram_gmem_atomics.h\"\n#include \"histogram_smem_atomics.h\"\n\n\n\n\n\n\n\n\n\n\nbool                    g_verbose = false;  \n\nbool                    g_report = false;   \n\n\nstruct less_than_value\n{\n    inline bool operator()(\n        const std::pair<std::string, double> &a,\n        const std::pair<std::string, double> &b)\n    {\n        return a.second < b.second;\n    }\n};\n\n\n\n\n\n\n\n\n\n\n\nstruct TgaHeader\n{\n    char idlength;\n    char colormaptype;\n    char datatypecode;\n    short colormaporigin;\n    short colormaplength;\n    char colormapdepth;\n    short x_origin;\n    short y_origin;\n    short width;\n    short height;\n    char bitsperpixel;\n    char imagedescriptor;\n\n    void Parse (FILE *fptr)\n    {\n        idlength = fgetc(fptr);\n        colormaptype = fgetc(fptr);\n        datatypecode = fgetc(fptr);\n        fread(&colormaporigin, 2, 1, fptr);\n        fread(&colormaplength, 2, 1, fptr);\n        colormapdepth = fgetc(fptr);\n        fread(&x_origin, 2, 1, fptr);\n        fread(&y_origin, 2, 1, fptr);\n        fread(&width, 2, 1, fptr);\n        fread(&height, 2, 1, fptr);\n        bitsperpixel = fgetc(fptr);\n        imagedescriptor = fgetc(fptr);\n    }\n\n    void Display (FILE *fptr)\n    {\n        fprintf(fptr, \"ID length:           %d\\n\", idlength);\n        fprintf(fptr, \"Color map type:      %d\\n\", colormaptype);\n        fprintf(fptr, \"Image type:          %d\\n\", datatypecode);\n        fprintf(fptr, \"Color map offset:    %d\\n\", colormaporigin);\n        fprintf(fptr, \"Color map length:    %d\\n\", colormaplength);\n        fprintf(fptr, \"Color map depth:     %d\\n\", colormapdepth);\n        fprintf(fptr, \"X origin:            %d\\n\", x_origin);\n        fprintf(fptr, \"Y origin:            %d\\n\", y_origin);\n        fprintf(fptr, \"Width:               %d\\n\", width);\n        fprintf(fptr, \"Height:              %d\\n\", height);\n        fprintf(fptr, \"Bits per pixel:      %d\\n\", bitsperpixel);\n        fprintf(fptr, \"Descriptor:          %d\\n\", imagedescriptor);\n    }\n};\n\n\n\n\nvoid ParseTgaPixel(uchar4 &pixel, unsigned char *tga_pixel, int bytes)\n{\n    if (bytes == 4)\n    {\n        pixel.x = tga_pixel[2];\n        pixel.y = tga_pixel[1];\n        pixel.z = tga_pixel[0];\n        pixel.w = tga_pixel[3];\n    }\n    else if (bytes == 3)\n    {\n        pixel.x = tga_pixel[2];\n        pixel.y = tga_pixel[1];\n        pixel.z = tga_pixel[0];\n        pixel.w = 0;\n    }\n    else if (bytes == 2)\n    {\n        pixel.x = (tga_pixel[1] & 0x7c) << 1;\n        pixel.y = ((tga_pixel[1] & 0x03) << 6) | ((tga_pixel[0] & 0xe0) >> 2);\n        pixel.z = (tga_pixel[0] & 0x1f) << 3;\n        pixel.w = (tga_pixel[1] & 0x80);\n    }\n}\n\n\n\n\nvoid ReadTga(uchar4* &pixels, int &width, int &height, const char *filename)\n{\n    \n\n    FILE *fptr;\n    if ((fptr = fopen(filename, \"rb\")) == NULL)\n    {\n        fprintf(stderr, \"File open failed\\n\");\n        exit(-1);\n    }\n\n    \n\n    TgaHeader header;\n    header.Parse(fptr);\n\n\n    width = header.width;\n    height = header.height;\n\n    \n\n    if (header.datatypecode != 2 && header.datatypecode != 10)\n    {\n        fprintf(stderr, \"Can only handle image type 2 and 10\\n\");\n        exit(-1);\n    }\n    if (header.bitsperpixel != 16 && header.bitsperpixel != 24 && header.bitsperpixel != 32)\n    {\n        fprintf(stderr, \"Can only handle pixel depths of 16, 24, and 32\\n\");\n        exit(-1);\n    }\n    if (header.colormaptype != 0 && header.colormaptype != 1)\n    {\n        fprintf(stderr, \"Can only handle color map types of 0 and 1\\n\");\n        exit(-1);\n    }\n\n    \n\n    int skip_bytes = header.idlength + (header.colormaptype * header.colormaplength);\n    fseek(fptr, skip_bytes, SEEK_CUR);\n\n    \n\n    int pixel_bytes = header.bitsperpixel / 8;\n\n    \n\n    size_t image_bytes = width * height * sizeof(uchar4);\n    if ((pixels == NULL) && ((pixels = (uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n    memset(pixels, 0, image_bytes);\n\n    \n\n    unsigned char   tga_pixel[5];\n    int             current_pixel = 0;\n    while (current_pixel < header.width * header.height)\n    {\n        if (header.datatypecode == 2)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d  (uncompressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n            current_pixel++;\n        }\n        else if (header.datatypecode == 10)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes + 1, fptr) != pixel_bytes + 1)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d (compressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            int run_length = tga_pixel[0] & 0x7f;\n            ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n            current_pixel++;\n\n            if (tga_pixel[0] & 0x80)\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n                    current_pixel++;\n                }\n            }\n            else\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n                    {\n                        fprintf(stderr, \"Unexpected end of file at pixel %d (normal)\\n\", current_pixel);\n                        exit(-1);\n                    }\n                    ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n                    current_pixel++;\n                }\n            }\n        }\n    }\n\n    \n\n    fclose(fptr);\n}\n\n\n\n\n\n\n\n\n\n\n\n\nvoid GenerateRandomImage(uchar4* &pixels, int width, int height, int entropy_reduction)\n{\n    int num_pixels = width * height;\n    size_t image_bytes = num_pixels * sizeof(uchar4);\n    if ((pixels == NULL) && ((pixels = (uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n\n    for (int i = 0; i < num_pixels; ++i)\n    {\n        RandomBits(pixels[i].x, entropy_reduction);\n        RandomBits(pixels[i].y, entropy_reduction);\n        RandomBits(pixels[i].z, entropy_reduction);\n        RandomBits(pixels[i].w, entropy_reduction);\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(float4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float* samples = reinterpret_cast<float*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char* samples = reinterpret_cast<unsigned char*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(uchar1 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel.x;\n}\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid HistogramGold(PixelType *image, int width, int height, unsigned int* hist)\n{\n    memset(hist, 0, ACTIVE_CHANNELS * NUM_BINS * sizeof(unsigned int));\n\n    for (int i = 0; i < width; i++)\n    {\n        for (int j = 0; j < height; j++)\n        {\n            PixelType pixel = image[i + j * width];\n\n            unsigned int bins[ACTIVE_CHANNELS];\n            DecodePixelGold<NUM_BINS>(pixel, bins);\n\n            for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n            {\n                hist[(NUM_BINS * CHANNEL) + bins[CHANNEL]]++;\n            }\n        }\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid RunTest(\n    std::vector<std::pair<std::string, double> >&   timings,\n    PixelType*                                      d_pixels,\n    const int                                       width,\n    const int                                       height,\n    unsigned int *                                  d_hist,\n    unsigned int *                                  h_hist,\n    int                                             timing_iterations,\n    const char *                                    long_name,\n    const char *                                    short_name,\n    double (*f)(PixelType*, int, int, unsigned int*, bool))\n{\n    if (!g_report) printf(\"%s \", long_name); fflush(stdout);\n\n    \n\n    (*f)(d_pixels, width, height, d_hist, !g_report);\n\n    int compare = CompareDeviceResults(h_hist, d_hist, ACTIVE_CHANNELS * NUM_BINS, true, g_verbose);\n    if (!g_report) printf(\"\\t%s\\n\", compare ? \"FAIL\" : \"PASS\"); fflush(stdout);\n\n    double elapsed_ms = 0;\n    for (int i = 0; i < timing_iterations; i++)\n    {\n        elapsed_ms += (*f)(d_pixels, width, height, d_hist, false);\n    }\n    double avg_us = (elapsed_ms / timing_iterations) * 1000;    \n\n    timings.push_back(std::pair<std::string, double>(short_name, avg_us));\n\n    if (!g_report)\n    {\n        printf(\"Avg time %.3f us (%d iterations)\\n\", avg_us, timing_iterations); fflush(stdout);\n    }\n    else\n    {\n        printf(\"%.3f, \", avg_us); fflush(stdout);\n    }\n\n    AssertEquals(0, compare);\n}\n\n\n\n\ntemplate <\n    int         NUM_CHANNELS,\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid TestMethods(\n    PixelType*  h_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    \n\n    PixelType* d_pixels;\n    size_t pixel_bytes = width * height * sizeof(PixelType);\n    cudaMalloc((void**) &d_pixels, pixel_bytes);\n    cudaMemcpy(d_pixels, h_pixels, pixel_bytes, cudaMemcpyHostToDevice);\n\n    if (g_report) printf(\"%.3f, \", double(pixel_bytes) / bandwidth_GBs / 1000);\n\n    \n\n    unsigned int *h_hist;\n    unsigned int *d_hist;\n    size_t histogram_bytes = NUM_BINS * ACTIVE_CHANNELS * sizeof(unsigned int);\n    h_hist = (unsigned int *) malloc(histogram_bytes);\n    cudaMalloc((void **) &d_hist, histogram_bytes);\n\n    \n\n    HistogramGold<ACTIVE_CHANNELS, NUM_BINS>(h_pixels, width, height, h_hist);\n\n    \n\n    std::vector<std::pair<std::string, double> > timings;\n\n    \n\n    RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, d_pixels, width, height, d_hist, h_hist, timing_iterations,\n        \"Shared memory atomics\", \"smem atomics\", run_smem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n    RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, d_pixels, width, height, d_hist, h_hist, timing_iterations,\n        \"Global memory atomics\", \"gmem atomics\", run_gmem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n\n    \n\n    if (!g_report)\n    {\n        std::sort(timings.begin(), timings.end(), less_than_value());\n        printf(\"Timings (us):\\n\");\n        for (int i = 0; i < timings.size(); i++)\n        {\n            double bandwidth = height * width * sizeof(PixelType) / timings[i].second / 1000;\n            printf(\"\\t %.3f %s (%.3f GB/s, %.3f%% peak)\\n\", timings[i].second, timings[i].first.c_str(), bandwidth, bandwidth / bandwidth_GBs * 100);\n        }\n        printf(\"\\n\");\n    }\n\n    \n\n    cudaFree(d_pixels);\n    cudaFree(d_hist);\n    free(h_hist);\n}\n\n\n\n\nvoid TestGenres(\n    uchar4*     uchar4_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    int num_pixels = width * height;\n\n    {\n        if (!g_report) printf(\"1 channel uchar1 tests (256-bin):\\n\\n\"); fflush(stdout);\n\n        size_t      image_bytes     = num_pixels * sizeof(uchar1);\n        uchar1*     uchar1_pixels   = (uchar1*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            uchar1_pixels[i].x = (unsigned char)\n                (((unsigned int) uchar4_pixels[i].x +\n                  (unsigned int) uchar4_pixels[i].y +\n                  (unsigned int) uchar4_pixels[i].z) / 3);\n        }\n\n        TestMethods<1, 1, 256>(uchar1_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(uchar1_pixels);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel uchar4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        TestMethods<4, 3, 256>(uchar4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel float4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        size_t      image_bytes     = num_pixels * sizeof(float4);\n        float4*     float4_pixels   = (float4*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            float4_pixels[i].x = float(uchar4_pixels[i].x) / 256;\n            float4_pixels[i].y = float(uchar4_pixels[i].y) / 256;\n            float4_pixels[i].z = float(uchar4_pixels[i].z) / 256;\n            float4_pixels[i].w = float(uchar4_pixels[i].w) / 256;\n        }\n        TestMethods<4, 3, 256>(float4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(float4_pixels);\n        if (g_report) printf(\"\\n\");\n    }\n}\n\n\n\n\nint main(int argc, char **argv)\n{\n    \n\n    CommandLineArgs args(argc, argv);\n    if (args.CheckCmdLineFlag(\"help\"))\n    {\n        printf(\n            \"%s \"\n            \"[--device=<device-id>] \"\n            \"[--v] \"\n            \"[--i=<timing iterations>] \"\n            \"\\n\\t\"\n                \"--file=<.tga filename> \"\n            \"\\n\\t\"\n                \"--entropy=<-1 (0%%), 0 (100%%), 1 (81%%), 2 (54%%), 3 (34%%), 4 (20%%), ...\"\n                \"[--height=<default: 1080>] \"\n                \"[--width=<default: 1920>] \"\n            \"\\n\", argv[0]);\n        exit(0);\n    }\n\n    std::string         filename;\n    int                 timing_iterations   = 100;\n    int                 entropy_reduction   = 0;\n    int                 height              = 1080;\n    int                 width               = 1920;\n\n    g_verbose = args.CheckCmdLineFlag(\"v\");\n    g_report = args.CheckCmdLineFlag(\"report\");\n    args.GetCmdLineArgument(\"i\", timing_iterations);\n    args.GetCmdLineArgument(\"file\", filename);\n    args.GetCmdLineArgument(\"height\", height);\n    args.GetCmdLineArgument(\"width\", width);\n    args.GetCmdLineArgument(\"entropy\", entropy_reduction);\n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    double bandwidth_GBs = 41; \n\n\n    \n\n    uchar4* uchar4_pixels = NULL;\n    if (!g_report)\n    {\n        if (!filename.empty())\n        {\n            \n\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            printf(\"File %s: width(%d) height(%d)\\n\\n\", filename.c_str(), width, height); fflush(stdout);\n        }\n        else\n        {\n            \n\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            printf(\"Random image: entropy-reduction(%d) width(%d) height(%d)\\n\\n\", entropy_reduction, width, height); fflush(stdout);\n        }\n\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n    }\n    else\n    {\n        \n\n        printf(\"Test, MIN, RLE CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM\\n\");\n\n        \n\n        for (entropy_reduction = 0; entropy_reduction < 5; ++entropy_reduction)\n        {\n            printf(\"entropy reduction %d, \", entropy_reduction);\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n        printf(\"entropy reduction -1, \");\n        GenerateRandomImage(uchar4_pixels, width, height, -1);\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        printf(\"\\n\");\n\n        \n\n        std::vector<std::string> file_tests;\n        file_tests.push_back(\"animals\");\n        file_tests.push_back(\"apples\");\n        file_tests.push_back(\"sunset\");\n        file_tests.push_back(\"cheetah\");\n        file_tests.push_back(\"nature\");\n        file_tests.push_back(\"operahouse\");\n        file_tests.push_back(\"austin\");\n        file_tests.push_back(\"cityscape\");\n\n        for (int i = 0; i < file_tests.size(); ++i)\n        {\n            printf(\"%s, \", file_tests[i].c_str());\n            std::string filename = std::string(\"histogram/benchmark/\") + file_tests[i] + \".tga\";\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n    }\n\n    free(uchar4_pixels);\n\n    cudaDeviceSynchronize();\n    printf(\"\\n\\n\");\n\n    return 0;\n}\n"}}
{"kernel_name": "histogram", "parallel_api": "hip", "code": {"histogram_compare.cu": "\n\n\n#include <stdio.h>\n#include <map>\n#include <vector>\n#include <algorithm>\n#include <cstdio>\n#include <cstring>\n#include <fstream>\n#include \"test_util.h\"\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\n__device__ __forceinline__ void DecodePixel(float4 &pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float samples[4];\n    samples[0] = pixel.x;\n    samples[1] = pixel.y;\n    samples[2] = pixel.z;\n    samples[3] = pixel.w;\n\n    #pragma unroll\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * (float)NUM_BINS);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\n__device__ __forceinline__ void DecodePixel(uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char samples[4];\n    samples[0] = pixel.x;\n    samples[1] = pixel.y;\n    samples[2] = pixel.z;\n    samples[3] = pixel.w;\n\n    #pragma unroll\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\n__device__ __forceinline__ void DecodePixel(uchar1 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel.x;\n}\n\n#include \"histogram_gmem_atomics.h\"\n#include \"histogram_smem_atomics.h\"\n\n\n\n\n\n\n\n\n\n\nbool                    g_verbose = false;  \n\nbool                    g_report = false;   \n\n\nstruct less_than_value\n{\n    inline bool operator()(\n        const std::pair<std::string, double> &a,\n        const std::pair<std::string, double> &b)\n    {\n        return a.second < b.second;\n    }\n};\n\n\n\n\n\n\n\n\n\n\n\nstruct TgaHeader\n{\n    char idlength;\n    char colormaptype;\n    char datatypecode;\n    short colormaporigin;\n    short colormaplength;\n    char colormapdepth;\n    short x_origin;\n    short y_origin;\n    short width;\n    short height;\n    char bitsperpixel;\n    char imagedescriptor;\n\n    void Parse (FILE *fptr)\n    {\n        idlength = fgetc(fptr);\n        colormaptype = fgetc(fptr);\n        datatypecode = fgetc(fptr);\n        fread(&colormaporigin, 2, 1, fptr);\n        fread(&colormaplength, 2, 1, fptr);\n        colormapdepth = fgetc(fptr);\n        fread(&x_origin, 2, 1, fptr);\n        fread(&y_origin, 2, 1, fptr);\n        fread(&width, 2, 1, fptr);\n        fread(&height, 2, 1, fptr);\n        bitsperpixel = fgetc(fptr);\n        imagedescriptor = fgetc(fptr);\n    }\n\n    void Display (FILE *fptr)\n    {\n        fprintf(fptr, \"ID length:           %d\\n\", idlength);\n        fprintf(fptr, \"Color map type:      %d\\n\", colormaptype);\n        fprintf(fptr, \"Image type:          %d\\n\", datatypecode);\n        fprintf(fptr, \"Color map offset:    %d\\n\", colormaporigin);\n        fprintf(fptr, \"Color map length:    %d\\n\", colormaplength);\n        fprintf(fptr, \"Color map depth:     %d\\n\", colormapdepth);\n        fprintf(fptr, \"X origin:            %d\\n\", x_origin);\n        fprintf(fptr, \"Y origin:            %d\\n\", y_origin);\n        fprintf(fptr, \"Width:               %d\\n\", width);\n        fprintf(fptr, \"Height:              %d\\n\", height);\n        fprintf(fptr, \"Bits per pixel:      %d\\n\", bitsperpixel);\n        fprintf(fptr, \"Descriptor:          %d\\n\", imagedescriptor);\n    }\n};\n\n\n\n\nvoid ParseTgaPixel(uchar4 &pixel, unsigned char *tga_pixel, int bytes)\n{\n    if (bytes == 4)\n    {\n        pixel.x = tga_pixel[2];\n        pixel.y = tga_pixel[1];\n        pixel.z = tga_pixel[0];\n        pixel.w = tga_pixel[3];\n    }\n    else if (bytes == 3)\n    {\n        pixel.x = tga_pixel[2];\n        pixel.y = tga_pixel[1];\n        pixel.z = tga_pixel[0];\n        pixel.w = 0;\n    }\n    else if (bytes == 2)\n    {\n        pixel.x = (tga_pixel[1] & 0x7c) << 1;\n        pixel.y = ((tga_pixel[1] & 0x03) << 6) | ((tga_pixel[0] & 0xe0) >> 2);\n        pixel.z = (tga_pixel[0] & 0x1f) << 3;\n        pixel.w = (tga_pixel[1] & 0x80);\n    }\n}\n\n\n\n\nvoid ReadTga(uchar4* &pixels, int &width, int &height, const char *filename)\n{\n    \n\n    FILE *fptr;\n    if ((fptr = fopen(filename, \"rb\")) == NULL)\n    {\n        fprintf(stderr, \"File open failed\\n\");\n        exit(-1);\n    }\n\n    \n\n    TgaHeader header;\n    header.Parse(fptr);\n\n\n    width = header.width;\n    height = header.height;\n\n    \n\n    if (header.datatypecode != 2 && header.datatypecode != 10)\n    {\n        fprintf(stderr, \"Can only handle image type 2 and 10\\n\");\n        exit(-1);\n    }\n    if (header.bitsperpixel != 16 && header.bitsperpixel != 24 && header.bitsperpixel != 32)\n    {\n        fprintf(stderr, \"Can only handle pixel depths of 16, 24, and 32\\n\");\n        exit(-1);\n    }\n    if (header.colormaptype != 0 && header.colormaptype != 1)\n    {\n        fprintf(stderr, \"Can only handle color map types of 0 and 1\\n\");\n        exit(-1);\n    }\n\n    \n\n    int skip_bytes = header.idlength + (header.colormaptype * header.colormaplength);\n    fseek(fptr, skip_bytes, SEEK_CUR);\n\n    \n\n    int pixel_bytes = header.bitsperpixel / 8;\n\n    \n\n    size_t image_bytes = width * height * sizeof(uchar4);\n    if ((pixels == NULL) && ((pixels = (uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n    memset(pixels, 0, image_bytes);\n\n    \n\n    unsigned char   tga_pixel[5];\n    int             current_pixel = 0;\n    while (current_pixel < header.width * header.height)\n    {\n        if (header.datatypecode == 2)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d  (uncompressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n            current_pixel++;\n        }\n        else if (header.datatypecode == 10)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes + 1, fptr) != pixel_bytes + 1)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d (compressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            int run_length = tga_pixel[0] & 0x7f;\n            ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n            current_pixel++;\n\n            if (tga_pixel[0] & 0x80)\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n                    current_pixel++;\n                }\n            }\n            else\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n                    {\n                        fprintf(stderr, \"Unexpected end of file at pixel %d (normal)\\n\", current_pixel);\n                        exit(-1);\n                    }\n                    ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n                    current_pixel++;\n                }\n            }\n        }\n    }\n\n    \n\n    fclose(fptr);\n}\n\n\n\n\n\n\n\n\n\n\n\n\nvoid GenerateRandomImage(uchar4* &pixels, int width, int height, int entropy_reduction)\n{\n    int num_pixels = width * height;\n    size_t image_bytes = num_pixels * sizeof(uchar4);\n    if ((pixels == NULL) && ((pixels = (uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n\n    for (int i = 0; i < num_pixels; ++i)\n    {\n        RandomBits(pixels[i].x, entropy_reduction);\n        RandomBits(pixels[i].y, entropy_reduction);\n        RandomBits(pixels[i].z, entropy_reduction);\n        RandomBits(pixels[i].w, entropy_reduction);\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(float4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float* samples = reinterpret_cast<float*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char* samples = reinterpret_cast<unsigned char*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(uchar1 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel.x;\n}\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid HistogramGold(PixelType *image, int width, int height, unsigned int* hist)\n{\n    memset(hist, 0, ACTIVE_CHANNELS * NUM_BINS * sizeof(unsigned int));\n\n    for (int i = 0; i < width; i++)\n    {\n        for (int j = 0; j < height; j++)\n        {\n            PixelType pixel = image[i + j * width];\n\n            unsigned int bins[ACTIVE_CHANNELS];\n            DecodePixelGold<NUM_BINS>(pixel, bins);\n\n            for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n            {\n                hist[(NUM_BINS * CHANNEL) + bins[CHANNEL]]++;\n            }\n        }\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid RunTest(\n    std::vector<std::pair<std::string, double> >&   timings,\n    PixelType*                                      d_pixels,\n    const int                                       width,\n    const int                                       height,\n    unsigned int *                                  d_hist,\n    unsigned int *                                  h_hist,\n    int                                             timing_iterations,\n    const char *                                    long_name,\n    const char *                                    short_name,\n    double (*f)(PixelType*, int, int, unsigned int*, bool))\n{\n    if (!g_report) printf(\"%s \", long_name); fflush(stdout);\n\n    \n\n    (*f)(d_pixels, width, height, d_hist, !g_report);\n\n    int compare = CompareDeviceResults(h_hist, d_hist, ACTIVE_CHANNELS * NUM_BINS, true, g_verbose);\n    if (!g_report) printf(\"\\t%s\\n\", compare ? \"FAIL\" : \"PASS\"); fflush(stdout);\n\n    double elapsed_ms = 0;\n    for (int i = 0; i < timing_iterations; i++)\n    {\n        elapsed_ms += (*f)(d_pixels, width, height, d_hist, false);\n    }\n    double avg_us = (elapsed_ms / timing_iterations) * 1000;    \n\n    timings.push_back(std::pair<std::string, double>(short_name, avg_us));\n\n    if (!g_report)\n    {\n        printf(\"Avg time %.3f us (%d iterations)\\n\", avg_us, timing_iterations); fflush(stdout);\n    }\n    else\n    {\n        printf(\"%.3f, \", avg_us); fflush(stdout);\n    }\n\n    AssertEquals(0, compare);\n}\n\n\n\n\ntemplate <\n    int         NUM_CHANNELS,\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid TestMethods(\n    PixelType*  h_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    \n\n    PixelType* d_pixels;\n    size_t pixel_bytes = width * height * sizeof(PixelType);\n    hipMalloc((void**) &d_pixels, pixel_bytes);\n    hipMemcpy(d_pixels, h_pixels, pixel_bytes, hipMemcpyHostToDevice);\n\n    if (g_report) printf(\"%.3f, \", double(pixel_bytes) / bandwidth_GBs / 1000);\n\n    \n\n    unsigned int *h_hist;\n    unsigned int *d_hist;\n    size_t histogram_bytes = NUM_BINS * ACTIVE_CHANNELS * sizeof(unsigned int);\n    h_hist = (unsigned int *) malloc(histogram_bytes);\n    hipMalloc((void **) &d_hist, histogram_bytes);\n\n    \n\n    HistogramGold<ACTIVE_CHANNELS, NUM_BINS>(h_pixels, width, height, h_hist);\n\n    \n\n    std::vector<std::pair<std::string, double> > timings;\n\n    \n\n    RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, d_pixels, width, height, d_hist, h_hist, timing_iterations,\n        \"Shared memory atomics\", \"smem atomics\", run_smem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n    RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, d_pixels, width, height, d_hist, h_hist, timing_iterations,\n        \"Global memory atomics\", \"gmem atomics\", run_gmem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n\n    \n\n    if (!g_report)\n    {\n        std::sort(timings.begin(), timings.end(), less_than_value());\n        printf(\"Timings (us):\\n\");\n        for (int i = 0; i < timings.size(); i++)\n        {\n            double bandwidth = height * width * sizeof(PixelType) / timings[i].second / 1000;\n            printf(\"\\t %.3f %s (%.3f GB/s, %.3f%% peak)\\n\", timings[i].second, timings[i].first.c_str(), bandwidth, bandwidth / bandwidth_GBs * 100);\n        }\n        printf(\"\\n\");\n    }\n\n    \n\n    hipFree(d_pixels);\n    hipFree(d_hist);\n    free(h_hist);\n}\n\n\n\n\nvoid TestGenres(\n    uchar4*     uchar4_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    int num_pixels = width * height;\n\n    {\n        if (!g_report) printf(\"1 channel uchar1 tests (256-bin):\\n\\n\"); fflush(stdout);\n\n        size_t      image_bytes     = num_pixels * sizeof(uchar1);\n        uchar1*     uchar1_pixels   = (uchar1*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            uchar1_pixels[i].x = (unsigned char)\n                (((unsigned int) uchar4_pixels[i].x +\n                  (unsigned int) uchar4_pixels[i].y +\n                  (unsigned int) uchar4_pixels[i].z) / 3);\n        }\n\n        TestMethods<1, 1, 256>(uchar1_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(uchar1_pixels);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel uchar4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        TestMethods<4, 3, 256>(uchar4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel float4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        size_t      image_bytes     = num_pixels * sizeof(float4);\n        float4*     float4_pixels   = (float4*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            float4_pixels[i].x = float(uchar4_pixels[i].x) / 256;\n            float4_pixels[i].y = float(uchar4_pixels[i].y) / 256;\n            float4_pixels[i].z = float(uchar4_pixels[i].z) / 256;\n            float4_pixels[i].w = float(uchar4_pixels[i].w) / 256;\n        }\n        TestMethods<4, 3, 256>(float4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(float4_pixels);\n        if (g_report) printf(\"\\n\");\n    }\n}\n\n\n\n\nint main(int argc, char **argv)\n{\n    \n\n    CommandLineArgs args(argc, argv);\n    if (args.CheckCmdLineFlag(\"help\"))\n    {\n        printf(\n            \"%s \"\n            \"[--device=<device-id>] \"\n            \"[--v] \"\n            \"[--i=<timing iterations>] \"\n            \"\\n\\t\"\n                \"--file=<.tga filename> \"\n            \"\\n\\t\"\n                \"--entropy=<-1 (0%%), 0 (100%%), 1 (81%%), 2 (54%%), 3 (34%%), 4 (20%%), ...\"\n                \"[--height=<default: 1080>] \"\n                \"[--width=<default: 1920>] \"\n            \"\\n\", argv[0]);\n        exit(0);\n    }\n\n    std::string         filename;\n    int                 timing_iterations   = 100;\n    int                 entropy_reduction   = 0;\n    int                 height              = 1080;\n    int                 width               = 1920;\n\n    g_verbose = args.CheckCmdLineFlag(\"v\");\n    g_report = args.CheckCmdLineFlag(\"report\");\n    args.GetCmdLineArgument(\"i\", timing_iterations);\n    args.GetCmdLineArgument(\"file\", filename);\n    args.GetCmdLineArgument(\"height\", height);\n    args.GetCmdLineArgument(\"width\", width);\n    args.GetCmdLineArgument(\"entropy\", entropy_reduction);\n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    double bandwidth_GBs = 41; \n\n\n    \n\n    uchar4* uchar4_pixels = NULL;\n    if (!g_report)\n    {\n        if (!filename.empty())\n        {\n            \n\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            printf(\"File %s: width(%d) height(%d)\\n\\n\", filename.c_str(), width, height); fflush(stdout);\n        }\n        else\n        {\n            \n\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            printf(\"Random image: entropy-reduction(%d) width(%d) height(%d)\\n\\n\", entropy_reduction, width, height); fflush(stdout);\n        }\n\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n    }\n    else\n    {\n        \n\n        printf(\"Test, MIN, RLE CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM\\n\");\n\n        \n\n        for (entropy_reduction = 0; entropy_reduction < 5; ++entropy_reduction)\n        {\n            printf(\"entropy reduction %d, \", entropy_reduction);\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n        printf(\"entropy reduction -1, \");\n        GenerateRandomImage(uchar4_pixels, width, height, -1);\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        printf(\"\\n\");\n\n        \n\n        std::vector<std::string> file_tests;\n        file_tests.push_back(\"animals\");\n        file_tests.push_back(\"apples\");\n        file_tests.push_back(\"sunset\");\n        file_tests.push_back(\"cheetah\");\n        file_tests.push_back(\"nature\");\n        file_tests.push_back(\"operahouse\");\n        file_tests.push_back(\"austin\");\n        file_tests.push_back(\"cityscape\");\n\n        for (int i = 0; i < file_tests.size(); ++i)\n        {\n            printf(\"%s, \", file_tests[i].c_str());\n            std::string filename = std::string(\"histogram/benchmark/\") + file_tests[i] + \".tga\";\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n    }\n\n    free(uchar4_pixels);\n\n    hipDeviceSynchronize();\n    printf(\"\\n\\n\");\n\n    return 0;\n}\n"}}
{"kernel_name": "histogram", "parallel_api": "omp", "code": {"histogram_compare_base.cpp": "\n\n\n#include <stdio.h>\n#include <map>\n#include <vector>\n#include <algorithm>\n#include <cstdio>\n#include <cstring>\n#include <fstream>\n#include <omp.h>\n#include \"test_util.hpp\"\n\n\n\n\n\n\n\nbool                    g_verbose = false;  \n\nbool                    g_report = false;   \n\n\n\n\n\n\n\n\n\n#pragma omp declare target\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(float4 &pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float samples[4];\n    samples[0] = pixel.x;\n    samples[1] = pixel.y;\n    samples[2] = pixel.z;\n    samples[3] = pixel.w;\n\n    #pragma unroll\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char samples[4];\n    samples[0] = pixel.x;\n    samples[1] = pixel.y;\n    samples[2] = pixel.z;\n    samples[3] = pixel.w;\n\n\n    #pragma unroll\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(uchar1 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel;\n}\n#pragma omp end declare target\n\n#include \"histogram_gmem_atomics.hpp\"\n#include \"histogram_smem_atomics.hpp\"\n\nstruct less_than_value\n{\n    inline bool operator()(\n        const std::pair<std::string, double> &a,\n        const std::pair<std::string, double> &b)\n    {\n        return a.second < b.second;\n    }\n};\n\n\n\n\n\n\n\n\n\n\n\nstruct TgaHeader\n{\n    char idlength;\n    char colormaptype;\n    char datatypecode;\n    short colormaporigin;\n    short colormaplength;\n    char colormapdepth;\n    short x_origin;\n    short y_origin;\n    short width;\n    short height;\n    char bitsperpixel;\n    char imagedescriptor;\n\n    void Parse (FILE *fptr)\n    {\n        idlength = fgetc(fptr);\n        colormaptype = fgetc(fptr);\n        datatypecode = fgetc(fptr);\n        fread(&colormaporigin, 2, 1, fptr);\n        fread(&colormaplength, 2, 1, fptr);\n        colormapdepth = fgetc(fptr);\n        fread(&x_origin, 2, 1, fptr);\n        fread(&y_origin, 2, 1, fptr);\n        fread(&width, 2, 1, fptr);\n        fread(&height, 2, 1, fptr);\n        bitsperpixel = fgetc(fptr);\n        imagedescriptor = fgetc(fptr);\n    }\n\n    void Display (FILE *fptr)\n    {\n        fprintf(fptr, \"ID length:           %d\\n\", idlength);\n        fprintf(fptr, \"Color map type:      %d\\n\", colormaptype);\n        fprintf(fptr, \"Image type:          %d\\n\", datatypecode);\n        fprintf(fptr, \"Color map offset:    %d\\n\", colormaporigin);\n        fprintf(fptr, \"Color map length:    %d\\n\", colormaplength);\n        fprintf(fptr, \"Color map depth:     %d\\n\", colormapdepth);\n        fprintf(fptr, \"X origin:            %d\\n\", x_origin);\n        fprintf(fptr, \"Y origin:            %d\\n\", y_origin);\n        fprintf(fptr, \"Width:               %d\\n\", width);\n        fprintf(fptr, \"Height:              %d\\n\", height);\n        fprintf(fptr, \"Bits per pixel:      %d\\n\", bitsperpixel);\n        fprintf(fptr, \"Descriptor:          %d\\n\", imagedescriptor);\n    }\n};\n\n\n\n\nvoid ParseTgaPixel(uchar4 &pixel, unsigned char *tga_pixel, int bytes)\n{\n    if (bytes == 4)\n    {\n        pixel.x = tga_pixel[2];\n        pixel.y = tga_pixel[1];\n        pixel.z = tga_pixel[0];\n        pixel.w = tga_pixel[3];\n    }\n    else if (bytes == 3)\n    {\n        pixel.x = tga_pixel[2];\n        pixel.y = tga_pixel[1];\n        pixel.z = tga_pixel[0];\n        pixel.w = 0;\n    }\n    else if (bytes == 2)\n    {\n        pixel.x = (tga_pixel[1] & 0x7c) << 1;\n        pixel.y = ((tga_pixel[1] & 0x03) << 6) | ((tga_pixel[0] & 0xe0) >> 2);\n        pixel.z = (tga_pixel[0] & 0x1f) << 3;\n        pixel.w = (tga_pixel[1] & 0x80);\n    }\n}\n\n\n\n\nvoid ReadTga(uchar4* &pixels, int &width, int &height, const char *filename)\n{\n    \n\n    FILE *fptr;\n    if ((fptr = fopen(filename, \"rb\")) == NULL)\n    {\n        fprintf(stderr, \"File open failed\\n\");\n        exit(-1);\n    }\n\n    \n\n    TgaHeader header;\n    header.Parse(fptr);\n\n\n    width = header.width;\n    height = header.height;\n\n    \n\n    if (header.datatypecode != 2 && header.datatypecode != 10)\n    {\n        fprintf(stderr, \"Can only handle image type 2 and 10\\n\");\n        exit(-1);\n    }\n    if (header.bitsperpixel != 16 && header.bitsperpixel != 24 && header.bitsperpixel != 32)\n    {\n        fprintf(stderr, \"Can only handle pixel depths of 16, 24, and 32\\n\");\n        exit(-1);\n    }\n    if (header.colormaptype != 0 && header.colormaptype != 1)\n    {\n        fprintf(stderr, \"Can only handle color map types of 0 and 1\\n\");\n        exit(-1);\n    }\n\n    \n\n    int skip_bytes = header.idlength + (header.colormaptype * header.colormaplength);\n    fseek(fptr, skip_bytes, SEEK_CUR);\n\n    \n\n    int pixel_bytes = header.bitsperpixel / 8;\n\n    \n\n    size_t image_bytes = width * height * sizeof(uchar4);\n    if ((pixels == NULL) && ((pixels = (uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n    memset(pixels, 0, image_bytes);\n\n    \n\n    unsigned char   tga_pixel[5];\n    int             current_pixel = 0;\n    while (current_pixel < header.width * header.height)\n    {\n        if (header.datatypecode == 2)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d  (uncompressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n            current_pixel++;\n        }\n        else if (header.datatypecode == 10)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes + 1, fptr) != pixel_bytes + 1)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d (compressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            int run_length = tga_pixel[0] & 0x7f;\n            ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n            current_pixel++;\n\n            if (tga_pixel[0] & 0x80)\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n                    current_pixel++;\n                }\n            }\n            else\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n                    {\n                        fprintf(stderr, \"Unexpected end of file at pixel %d (normal)\\n\", current_pixel);\n                        exit(-1);\n                    }\n                    ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n                    current_pixel++;\n                }\n            }\n        }\n    }\n\n    \n\n    fclose(fptr);\n}\n\n\n\n\n\n\n\n\n\n\n\n\nvoid GenerateRandomImage(uchar4* &pixels, int width, int height, int entropy_reduction)\n{\n    int num_pixels = width * height;\n    size_t image_bytes = num_pixels * sizeof(uchar4);\n    if ((pixels == NULL) && ((pixels = (uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n\n    for (int i = 0; i < num_pixels; ++i)\n    {\n        RandomBits(pixels[i].x, entropy_reduction);\n        RandomBits(pixels[i].y, entropy_reduction);\n        RandomBits(pixels[i].z, entropy_reduction);\n        RandomBits(pixels[i].w, entropy_reduction);\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(float4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float* samples = reinterpret_cast<float*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char* samples = reinterpret_cast<unsigned char*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(uchar1 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel;\n}\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid HistogramGold(PixelType *image, int width, int height, unsigned int* hist)\n{\n    memset(hist, 0, ACTIVE_CHANNELS * NUM_BINS * sizeof(unsigned int));\n\n    for (int i = 0; i < width; i++)\n    {\n        for (int j = 0; j < height; j++)\n        {\n            PixelType pixel = image[i + j * width];\n\n            unsigned int bins[ACTIVE_CHANNELS];\n            DecodePixelGold<NUM_BINS>(pixel, bins);\n\n            for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n            {\n                hist[(NUM_BINS * CHANNEL) + bins[CHANNEL]]++;\n            }\n        }\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid RunTest(\n    std::vector<std::pair<std::string, double> >&   timings,\n    PixelType*                                      pixels,\n    const int                                       width,\n    const int                                       height,\n    unsigned int *                                  d_hist,\n    unsigned int *                                  h_hist,\n    int                                             timing_iterations,\n    const char *                                    long_name,\n    const char *                                    short_name,\n    double (*f)(PixelType*, \n                int,   \n\n                int,   \n\n                unsigned int*, \n                bool)\n    )\n{\n    if (!g_report) printf(\"%s \", long_name); fflush(stdout);\n\n    \n\n    (*f)(pixels, width, height, d_hist, !g_report);\n\n    int compare = CompareDeviceResults(h_hist, d_hist, ACTIVE_CHANNELS * NUM_BINS, true, g_verbose);\n    if (!g_report) printf(\"\\t%s\\n\", compare ? \"FAIL\" : \"PASS\"); fflush(stdout);\n\n    double elapsed_ms = 0;\n    for (int i = 0; i < timing_iterations; i++)\n    {\n        elapsed_ms += (*f)(pixels, width, height, d_hist, false);\n    }\n    double avg_us = (elapsed_ms / timing_iterations) * 1000;    \n\n    timings.push_back(std::pair<std::string, double>(short_name, avg_us));\n\n    if (!g_report)\n    {\n        printf(\"Avg time %.3f us (%d iterations)\\n\", avg_us, timing_iterations); fflush(stdout);\n    }\n    else\n    {\n        printf(\"%.3f, \", avg_us); fflush(stdout);\n    }\n\n    \n\n}\n\n\n\n\ntemplate <\n    int         NUM_CHANNELS,\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid TestMethods(\n    PixelType*  h_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    size_t pixel_bytes = width * height * sizeof(PixelType);\n    if (g_report) printf(\"%.3f, \", double(pixel_bytes) / bandwidth_GBs / 1000);\n\n    \n\n    size_t histogram_bytes = NUM_BINS * ACTIVE_CHANNELS * sizeof(unsigned int);\n    unsigned int *h_hist = (unsigned int *) malloc(histogram_bytes);\n    unsigned int *d_hist = (unsigned int *) malloc(histogram_bytes);\n\n\n    \n\n    HistogramGold<ACTIVE_CHANNELS, NUM_BINS>(h_pixels, width, height, h_hist);\n\n    \n\n    std::vector<std::pair<std::string, double> > timings;\n\n    \n\n    RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, h_pixels, width, height, d_hist, h_hist, timing_iterations,\n        \"Shared memory atomics\", \"smem atomics\", run_smem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n    RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, h_pixels, width, height, d_hist, h_hist, timing_iterations,\n        \"Global memory atomics\", \"gmem atomics\", run_gmem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n\n    \n\n    if (!g_report)\n    {\n        std::sort(timings.begin(), timings.end(), less_than_value());\n        printf(\"Timings (us):\\n\");\n        for (int i = 0; i < timings.size(); i++)\n        {\n            double bandwidth = height * width * sizeof(PixelType) / timings[i].second / 1000;\n            printf(\"\\t %.3f %s (%.3f GB/s, %.3f%% peak)\\n\", timings[i].second, timings[i].first.c_str(), bandwidth, bandwidth / bandwidth_GBs * 100);\n        }\n        printf(\"\\n\");\n    }\n\n    \n\n    free(h_hist);\n    free(d_hist);\n}\n\n\n\n\nvoid TestGenres(\n    uchar4*     uchar4_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    int num_pixels = width * height;\n\n    {\n        if (!g_report) printf(\"1 channel uchar1 tests (256-bin):\\n\\n\"); fflush(stdout);\n\n        size_t      image_bytes     = num_pixels * sizeof(uchar1);\n        uchar1*     uchar1_pixels   = (uchar1*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            uchar1_pixels[i] = (unsigned char)\n                (((unsigned int) uchar4_pixels[i].x +\n                  (unsigned int) uchar4_pixels[i].y +\n                  (unsigned int) uchar4_pixels[i].z) / 3);\n        }\n\n        TestMethods<1, 1, 256>(uchar1_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(uchar1_pixels);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel uchar4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        TestMethods<4, 3, 256>(uchar4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel float4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        size_t      image_bytes     = num_pixels * sizeof(float4);\n        float4*     float4_pixels   = (float4*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            float4_pixels[i].x = float(uchar4_pixels[i].x) / 256;\n            float4_pixels[i].y = float(uchar4_pixels[i].y) / 256;\n            float4_pixels[i].z = float(uchar4_pixels[i].z) / 256;\n            float4_pixels[i].w = float(uchar4_pixels[i].w) / 256;\n        }\n        TestMethods<4, 3, 256>(float4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(float4_pixels);\n        if (g_report) printf(\"\\n\");\n    }\n}\n\n\n\n\nint main(int argc, char **argv)\n{\n    \n\n    CommandLineArgs args(argc, argv);\n    if (args.CheckCmdLineFlag(\"help\"))\n    {\n        printf(\n            \"%s \"\n            \"[--v] \"\n            \"[--i=<timing iterations>] \"\n            \"\\n\\t\"\n                \"--file=<.tga filename> \"\n            \"\\n\\t\"\n                \"--entropy=<-1 (0%%), 0 (100%%), 1 (81%%), 2 (54%%), 3 (34%%), 4 (20%%), ...\"\n                \"[--height=<default: 1080>] \"\n                \"[--width=<default: 1920>] \"\n            \"\\n\", argv[0]);\n        exit(0);\n    }\n\n    std::string         filename;\n    int                 timing_iterations   = 100;\n    int                 entropy_reduction   = 0;\n    int                 height              = 1080;\n    int                 width               = 1920;\n\n    g_verbose = args.CheckCmdLineFlag(\"v\");\n    g_report = args.CheckCmdLineFlag(\"report\");\n    args.GetCmdLineArgument(\"i\", timing_iterations);\n    args.GetCmdLineArgument(\"file\", filename);\n    args.GetCmdLineArgument(\"height\", height);\n    args.GetCmdLineArgument(\"width\", width);\n    args.GetCmdLineArgument(\"entropy\", entropy_reduction);\n\n    \n\n    args.DeviceInit();\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n    double bandwidth_GBs = 41;  \n\n\n    \n\n    uchar4* uchar4_pixels = NULL;\n    if (!g_report)\n    {\n        if (!filename.empty())\n        {\n            \n\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            printf(\"File %s: width(%d) height(%d)\\n\\n\", filename.c_str(), width, height); fflush(stdout);\n        }\n        else\n        {\n            \n\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            printf(\"Random image: entropy-reduction(%d) width(%d) height(%d)\\n\\n\", entropy_reduction, width, height); fflush(stdout);\n        }\n\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n    }\n    else\n    {\n        \n\n        printf(\"Test, MIN, RLE CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM\\n\");\n\n        \n\n        for (entropy_reduction = 0; entropy_reduction < 5; ++entropy_reduction)\n        {\n            printf(\"entropy reduction %d, \", entropy_reduction);\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n        printf(\"entropy reduction -1, \");\n        GenerateRandomImage(uchar4_pixels, width, height, -1);\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        printf(\"\\n\");\n\n        \n\n        std::vector<std::string> file_tests;\n        file_tests.push_back(\"animals\");\n        file_tests.push_back(\"apples\");\n        file_tests.push_back(\"sunset\");\n        file_tests.push_back(\"cheetah\");\n        file_tests.push_back(\"nature\");\n        file_tests.push_back(\"operahouse\");\n        file_tests.push_back(\"austin\");\n        file_tests.push_back(\"cityscape\");\n\n        for (int i = 0; i < file_tests.size(); ++i)\n        {\n            printf(\"%s, \", file_tests[i].c_str());\n            std::string filename = std::string(\"histogram/benchmark/\") + file_tests[i] + \".tga\";\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n    }\n\n    free(uchar4_pixels);\n\n    printf(\"\\n\\n\");\n\n    return 0;\n}\n"}}
{"kernel_name": "histogram", "parallel_api": "serial", "code": {"histogram_compare_base.cpp": "\n\n\n#include <stdio.h>\n#include <map>\n#include <vector>\n#include <algorithm>\n#include <cstdio>\n#include <cstring>\n#include <fstream>\n#include \"test_util.hpp\"\n\n\n\n\n\n\n\nbool                    g_verbose = false;  \n\nbool                    g_report = false;   \n\n\n\n\n\n\n\n\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(float4 &pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float samples[4];\n    samples[0] = pixel.x;\n    samples[1] = pixel.y;\n    samples[2] = pixel.z;\n    samples[3] = pixel.w;\n\n        for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char samples[4];\n    samples[0] = pixel.x;\n    samples[1] = pixel.y;\n    samples[2] = pixel.z;\n    samples[3] = pixel.w;\n\n\n        for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(uchar1 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel;\n}\n\n#include \"histogram_gmem_atomics.hpp\"\n#include \"histogram_smem_atomics.hpp\"\n\nstruct less_than_value\n{\n    inline bool operator()(\n        const std::pair<std::string, double> &a,\n        const std::pair<std::string, double> &b)\n    {\n        return a.second < b.second;\n    }\n};\n\n\n\n\n\n\n\n\n\n\n\nstruct TgaHeader\n{\n    char idlength;\n    char colormaptype;\n    char datatypecode;\n    short colormaporigin;\n    short colormaplength;\n    char colormapdepth;\n    short x_origin;\n    short y_origin;\n    short width;\n    short height;\n    char bitsperpixel;\n    char imagedescriptor;\n\n    void Parse (FILE *fptr)\n    {\n        idlength = fgetc(fptr);\n        colormaptype = fgetc(fptr);\n        datatypecode = fgetc(fptr);\n        fread(&colormaporigin, 2, 1, fptr);\n        fread(&colormaplength, 2, 1, fptr);\n        colormapdepth = fgetc(fptr);\n        fread(&x_origin, 2, 1, fptr);\n        fread(&y_origin, 2, 1, fptr);\n        fread(&width, 2, 1, fptr);\n        fread(&height, 2, 1, fptr);\n        bitsperpixel = fgetc(fptr);\n        imagedescriptor = fgetc(fptr);\n    }\n\n    void Display (FILE *fptr)\n    {\n        fprintf(fptr, \"ID length:           %d\\n\", idlength);\n        fprintf(fptr, \"Color map type:      %d\\n\", colormaptype);\n        fprintf(fptr, \"Image type:          %d\\n\", datatypecode);\n        fprintf(fptr, \"Color map offset:    %d\\n\", colormaporigin);\n        fprintf(fptr, \"Color map length:    %d\\n\", colormaplength);\n        fprintf(fptr, \"Color map depth:     %d\\n\", colormapdepth);\n        fprintf(fptr, \"X origin:            %d\\n\", x_origin);\n        fprintf(fptr, \"Y origin:            %d\\n\", y_origin);\n        fprintf(fptr, \"Width:               %d\\n\", width);\n        fprintf(fptr, \"Height:              %d\\n\", height);\n        fprintf(fptr, \"Bits per pixel:      %d\\n\", bitsperpixel);\n        fprintf(fptr, \"Descriptor:          %d\\n\", imagedescriptor);\n    }\n};\n\n\n\n\nvoid ParseTgaPixel(uchar4 &pixel, unsigned char *tga_pixel, int bytes)\n{\n    if (bytes == 4)\n    {\n        pixel.x = tga_pixel[2];\n        pixel.y = tga_pixel[1];\n        pixel.z = tga_pixel[0];\n        pixel.w = tga_pixel[3];\n    }\n    else if (bytes == 3)\n    {\n        pixel.x = tga_pixel[2];\n        pixel.y = tga_pixel[1];\n        pixel.z = tga_pixel[0];\n        pixel.w = 0;\n    }\n    else if (bytes == 2)\n    {\n        pixel.x = (tga_pixel[1] & 0x7c) << 1;\n        pixel.y = ((tga_pixel[1] & 0x03) << 6) | ((tga_pixel[0] & 0xe0) >> 2);\n        pixel.z = (tga_pixel[0] & 0x1f) << 3;\n        pixel.w = (tga_pixel[1] & 0x80);\n    }\n}\n\n\n\n\nvoid ReadTga(uchar4* &pixels, int &width, int &height, const char *filename)\n{\n    \n\n    FILE *fptr;\n    if ((fptr = fopen(filename, \"rb\")) == NULL)\n    {\n        fprintf(stderr, \"File open failed\\n\");\n        exit(-1);\n    }\n\n    \n\n    TgaHeader header;\n    header.Parse(fptr);\n\n\n    width = header.width;\n    height = header.height;\n\n    \n\n    if (header.datatypecode != 2 && header.datatypecode != 10)\n    {\n        fprintf(stderr, \"Can only handle image type 2 and 10\\n\");\n        exit(-1);\n    }\n    if (header.bitsperpixel != 16 && header.bitsperpixel != 24 && header.bitsperpixel != 32)\n    {\n        fprintf(stderr, \"Can only handle pixel depths of 16, 24, and 32\\n\");\n        exit(-1);\n    }\n    if (header.colormaptype != 0 && header.colormaptype != 1)\n    {\n        fprintf(stderr, \"Can only handle color map types of 0 and 1\\n\");\n        exit(-1);\n    }\n\n    \n\n    int skip_bytes = header.idlength + (header.colormaptype * header.colormaplength);\n    fseek(fptr, skip_bytes, SEEK_CUR);\n\n    \n\n    int pixel_bytes = header.bitsperpixel / 8;\n\n    \n\n    size_t image_bytes = width * height * sizeof(uchar4);\n    if ((pixels == NULL) && ((pixels = (uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n    memset(pixels, 0, image_bytes);\n\n    \n\n    unsigned char   tga_pixel[5];\n    int             current_pixel = 0;\n    while (current_pixel < header.width * header.height)\n    {\n        if (header.datatypecode == 2)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d  (uncompressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n            current_pixel++;\n        }\n        else if (header.datatypecode == 10)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes + 1, fptr) != pixel_bytes + 1)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d (compressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            int run_length = tga_pixel[0] & 0x7f;\n            ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n            current_pixel++;\n\n            if (tga_pixel[0] & 0x80)\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n                    current_pixel++;\n                }\n            }\n            else\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n                    {\n                        fprintf(stderr, \"Unexpected end of file at pixel %d (normal)\\n\", current_pixel);\n                        exit(-1);\n                    }\n                    ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n                    current_pixel++;\n                }\n            }\n        }\n    }\n\n    \n\n    fclose(fptr);\n}\n\n\n\n\n\n\n\n\n\n\n\n\nvoid GenerateRandomImage(uchar4* &pixels, int width, int height, int entropy_reduction)\n{\n    int num_pixels = width * height;\n    size_t image_bytes = num_pixels * sizeof(uchar4);\n    if ((pixels == NULL) && ((pixels = (uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n\n    for (int i = 0; i < num_pixels; ++i)\n    {\n        RandomBits(pixels[i].x, entropy_reduction);\n        RandomBits(pixels[i].y, entropy_reduction);\n        RandomBits(pixels[i].z, entropy_reduction);\n        RandomBits(pixels[i].w, entropy_reduction);\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(float4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float* samples = reinterpret_cast<float*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char* samples = reinterpret_cast<unsigned char*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(uchar1 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel;\n}\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid HistogramGold(PixelType *image, int width, int height, unsigned int* hist)\n{\n    memset(hist, 0, ACTIVE_CHANNELS * NUM_BINS * sizeof(unsigned int));\n\n    for (int i = 0; i < width; i++)\n    {\n        for (int j = 0; j < height; j++)\n        {\n            PixelType pixel = image[i + j * width];\n\n            unsigned int bins[ACTIVE_CHANNELS];\n            DecodePixelGold<NUM_BINS>(pixel, bins);\n\n            for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n            {\n                hist[(NUM_BINS * CHANNEL) + bins[CHANNEL]]++;\n            }\n        }\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid RunTest(\n    std::vector<std::pair<std::string, double> >&   timings,\n    PixelType*                                      pixels,\n    const int                                       width,\n    const int                                       height,\n    unsigned int *                                  d_hist,\n    unsigned int *                                  h_hist,\n    int                                             timing_iterations,\n    const char *                                    long_name,\n    const char *                                    short_name,\n    double (*f)(PixelType*, \n                int,   \n\n                int,   \n\n                unsigned int*, \n                bool)\n    )\n{\n    if (!g_report) printf(\"%s \", long_name); fflush(stdout);\n\n    \n\n    (*f)(pixels, width, height, d_hist, !g_report);\n\n    int compare = CompareDeviceResults(h_hist, d_hist, ACTIVE_CHANNELS * NUM_BINS, true, g_verbose);\n    if (!g_report) printf(\"\\t%s\\n\", compare ? \"FAIL\" : \"PASS\"); fflush(stdout);\n\n    double elapsed_ms = 0;\n    for (int i = 0; i < timing_iterations; i++)\n    {\n        elapsed_ms += (*f)(pixels, width, height, d_hist, false);\n    }\n    double avg_us = (elapsed_ms / timing_iterations) * 1000;    \n\n    timings.push_back(std::pair<std::string, double>(short_name, avg_us));\n\n    if (!g_report)\n    {\n        printf(\"Avg time %.3f us (%d iterations)\\n\", avg_us, timing_iterations); fflush(stdout);\n    }\n    else\n    {\n        printf(\"%.3f, \", avg_us); fflush(stdout);\n    }\n\n    \n\n}\n\n\n\n\ntemplate <\n    int         NUM_CHANNELS,\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid TestMethods(\n    PixelType*  h_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    size_t pixel_bytes = width * height * sizeof(PixelType);\n    if (g_report) printf(\"%.3f, \", double(pixel_bytes) / bandwidth_GBs / 1000);\n\n    \n\n    size_t histogram_bytes = NUM_BINS * ACTIVE_CHANNELS * sizeof(unsigned int);\n    unsigned int *h_hist = (unsigned int *) malloc(histogram_bytes);\n    unsigned int *d_hist = (unsigned int *) malloc(histogram_bytes);\n\n\n    \n\n    HistogramGold<ACTIVE_CHANNELS, NUM_BINS>(h_pixels, width, height, h_hist);\n\n    \n\n    std::vector<std::pair<std::string, double> > timings;\n\n    \n\n    RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, h_pixels, width, height, d_hist, h_hist, timing_iterations,\n        \"Shared memory atomics\", \"smem atomics\", run_smem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n    RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, h_pixels, width, height, d_hist, h_hist, timing_iterations,\n        \"Global memory atomics\", \"gmem atomics\", run_gmem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n\n    \n\n    if (!g_report)\n    {\n        std::sort(timings.begin(), timings.end(), less_than_value());\n        printf(\"Timings (us):\\n\");\n        for (int i = 0; i < timings.size(); i++)\n        {\n            double bandwidth = height * width * sizeof(PixelType) / timings[i].second / 1000;\n            printf(\"\\t %.3f %s (%.3f GB/s, %.3f%% peak)\\n\", timings[i].second, timings[i].first.c_str(), bandwidth, bandwidth / bandwidth_GBs * 100);\n        }\n        printf(\"\\n\");\n    }\n\n    \n\n    free(h_hist);\n    free(d_hist);\n}\n\n\n\n\nvoid TestGenres(\n    uchar4*     uchar4_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    int num_pixels = width * height;\n\n    {\n        if (!g_report) printf(\"1 channel uchar1 tests (256-bin):\\n\\n\"); fflush(stdout);\n\n        size_t      image_bytes     = num_pixels * sizeof(uchar1);\n        uchar1*     uchar1_pixels   = (uchar1*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            uchar1_pixels[i] = (unsigned char)\n                (((unsigned int) uchar4_pixels[i].x +\n                  (unsigned int) uchar4_pixels[i].y +\n                  (unsigned int) uchar4_pixels[i].z) / 3);\n        }\n\n        TestMethods<1, 1, 256>(uchar1_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(uchar1_pixels);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel uchar4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        TestMethods<4, 3, 256>(uchar4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel float4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        size_t      image_bytes     = num_pixels * sizeof(float4);\n        float4*     float4_pixels   = (float4*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            float4_pixels[i].x = float(uchar4_pixels[i].x) / 256;\n            float4_pixels[i].y = float(uchar4_pixels[i].y) / 256;\n            float4_pixels[i].z = float(uchar4_pixels[i].z) / 256;\n            float4_pixels[i].w = float(uchar4_pixels[i].w) / 256;\n        }\n        TestMethods<4, 3, 256>(float4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(float4_pixels);\n        if (g_report) printf(\"\\n\");\n    }\n}\n\n\n\n\nint main(int argc, char **argv)\n{\n    \n\n    CommandLineArgs args(argc, argv);\n    if (args.CheckCmdLineFlag(\"help\"))\n    {\n        printf(\n            \"%s \"\n            \"[--v] \"\n            \"[--i=<timing iterations>] \"\n            \"\\n\\t\"\n                \"--file=<.tga filename> \"\n            \"\\n\\t\"\n                \"--entropy=<-1 (0%%), 0 (100%%), 1 (81%%), 2 (54%%), 3 (34%%), 4 (20%%), ...\"\n                \"[--height=<default: 1080>] \"\n                \"[--width=<default: 1920>] \"\n            \"\\n\", argv[0]);\n        exit(0);\n    }\n\n    std::string         filename;\n    int                 timing_iterations   = 100;\n    int                 entropy_reduction   = 0;\n    int                 height              = 1080;\n    int                 width               = 1920;\n\n    g_verbose = args.CheckCmdLineFlag(\"v\");\n    g_report = args.CheckCmdLineFlag(\"report\");\n    args.GetCmdLineArgument(\"i\", timing_iterations);\n    args.GetCmdLineArgument(\"file\", filename);\n    args.GetCmdLineArgument(\"height\", height);\n    args.GetCmdLineArgument(\"width\", width);\n    args.GetCmdLineArgument(\"entropy\", entropy_reduction);\n\n    \n\n    args.DeviceInit();\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n    double bandwidth_GBs = 41;  \n\n\n    \n\n    uchar4* uchar4_pixels = NULL;\n    if (!g_report)\n    {\n        if (!filename.empty())\n        {\n            \n\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            printf(\"File %s: width(%d) height(%d)\\n\\n\", filename.c_str(), width, height); fflush(stdout);\n        }\n        else\n        {\n            \n\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            printf(\"Random image: entropy-reduction(%d) width(%d) height(%d)\\n\\n\", entropy_reduction, width, height); fflush(stdout);\n        }\n\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n    }\n    else\n    {\n        \n\n        printf(\"Test, MIN, RLE CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM\\n\");\n\n        \n\n        for (entropy_reduction = 0; entropy_reduction < 5; ++entropy_reduction)\n        {\n            printf(\"entropy reduction %d, \", entropy_reduction);\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n        printf(\"entropy reduction -1, \");\n        GenerateRandomImage(uchar4_pixels, width, height, -1);\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        printf(\"\\n\");\n\n        \n\n        std::vector<std::string> file_tests;\n        file_tests.push_back(\"animals\");\n        file_tests.push_back(\"apples\");\n        file_tests.push_back(\"sunset\");\n        file_tests.push_back(\"cheetah\");\n        file_tests.push_back(\"nature\");\n        file_tests.push_back(\"operahouse\");\n        file_tests.push_back(\"austin\");\n        file_tests.push_back(\"cityscape\");\n\n        for (int i = 0; i < file_tests.size(); ++i)\n        {\n            printf(\"%s, \", file_tests[i].c_str());\n            std::string filename = std::string(\"histogram/benchmark/\") + file_tests[i] + \".tga\";\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n    }\n\n    free(uchar4_pixels);\n\n    printf(\"\\n\\n\");\n\n    return 0;\n}"}}
{"kernel_name": "histogram", "parallel_api": "sycl", "code": {"histogram_compare_base.cpp": "\n\n\n#include <stdio.h>\n#include <map>\n#include <vector>\n#include <algorithm>\n#include <cstdio>\n#include <cstring>\n#include <fstream>\n#include \"test_util.hpp\"\n\n\n\n\n\n\n\nbool                    g_verbose = false;  \n\nbool                    g_report = false;   \n\n\n\n\n\n\n\n\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(sycl::float4 &pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float samples[4];\n    samples[0] = pixel.x();\n    samples[1] = pixel.y();\n    samples[2] = pixel.z();\n    samples[3] = pixel.w();\n\n    #pragma unroll\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(sycl::uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char samples[4];\n    samples[0] = pixel.x();\n    samples[1] = pixel.y();\n    samples[2] = pixel.z();\n    samples[3] = pixel.w();\n\n    #pragma unroll\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\ninline void DecodePixel(unsigned char pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel;\n}\n\n\n\ntemplate <int ACTIVE_CHANNELS, int NUM_BINS, typename PixelType>\nclass hist_gmem_atomics;\n\ntemplate <int ACTIVE_CHANNELS, int NUM_BINS, typename PixelType>\nclass hist_smem_atomics;\n\ntemplate <int ACTIVE_CHANNELS, int NUM_BINS, typename PixelType>\nclass hist_gmem_accum;\n\ntemplate <int ACTIVE_CHANNELS, int NUM_BINS, typename PixelType>\nclass hist_smem_accum;\n\n#include \"histogram_gmem_atomics.hpp\"\n#include \"histogram_smem_atomics.hpp\"\n\nstruct less_than_value\n{\n    inline bool operator()(\n        const std::pair<std::string, double> &a,\n        const std::pair<std::string, double> &b)\n    {\n        return a.second < b.second;\n    }\n};\n\n\n\n\n\n\n\n\n\n\n\nstruct TgaHeader\n{\n    char idlength;\n    char colormaptype;\n    char datatypecode;\n    short colormaporigin;\n    short colormaplength;\n    char colormapdepth;\n    short x_origin;\n    short y_origin;\n    short width;\n    short height;\n    char bitsperpixel;\n    char imagedescriptor;\n\n    void Parse (FILE *fptr)\n    {\n        idlength = fgetc(fptr);\n        colormaptype = fgetc(fptr);\n        datatypecode = fgetc(fptr);\n        fread(&colormaporigin, 2, 1, fptr);\n        fread(&colormaplength, 2, 1, fptr);\n        colormapdepth = fgetc(fptr);\n        fread(&x_origin, 2, 1, fptr);\n        fread(&y_origin, 2, 1, fptr);\n        fread(&width, 2, 1, fptr);\n        fread(&height, 2, 1, fptr);\n        bitsperpixel = fgetc(fptr);\n        imagedescriptor = fgetc(fptr);\n    }\n\n    void Display (FILE *fptr)\n    {\n        fprintf(fptr, \"ID length:           %d\\n\", idlength);\n        fprintf(fptr, \"Color map type:      %d\\n\", colormaptype);\n        fprintf(fptr, \"Image type:          %d\\n\", datatypecode);\n        fprintf(fptr, \"Color map offset:    %d\\n\", colormaporigin);\n        fprintf(fptr, \"Color map length:    %d\\n\", colormaplength);\n        fprintf(fptr, \"Color map depth:     %d\\n\", colormapdepth);\n        fprintf(fptr, \"X origin:            %d\\n\", x_origin);\n        fprintf(fptr, \"Y origin:            %d\\n\", y_origin);\n        fprintf(fptr, \"Width:               %d\\n\", width);\n        fprintf(fptr, \"Height:              %d\\n\", height);\n        fprintf(fptr, \"Bits per pixel:      %d\\n\", bitsperpixel);\n        fprintf(fptr, \"Descriptor:          %d\\n\", imagedescriptor);\n    }\n};\n\n\n\n\nvoid ParseTgaPixel(sycl::uchar4 &pixel, unsigned char *tga_pixel, int bytes)\n{\n    if (bytes == 4)\n    {\n        pixel.x() = tga_pixel[2];\n        pixel.y() = tga_pixel[1];\n        pixel.z() = tga_pixel[0];\n        pixel.w() = tga_pixel[3];\n    }\n    else if (bytes == 3)\n    {\n        pixel.x() = tga_pixel[2];\n        pixel.y() = tga_pixel[1];\n        pixel.z() = tga_pixel[0];\n        pixel.w() = 0;\n    }\n    else if (bytes == 2)\n    {\n        pixel.x() = (tga_pixel[1] & 0x7c) << 1;\n        pixel.y() = ((tga_pixel[1] & 0x03) << 6) | ((tga_pixel[0] & 0xe0) >> 2);\n        pixel.z() = (tga_pixel[0] & 0x1f) << 3;\n        pixel.w() = (tga_pixel[1] & 0x80);\n    }\n}\n\n\n\n\nvoid ReadTga(sycl::uchar4* &pixels, int &width, int &height, const char *filename)\n{\n    \n\n    FILE *fptr;\n    if ((fptr = fopen(filename, \"rb\")) == NULL)\n    {\n        fprintf(stderr, \"File open failed\\n\");\n        exit(-1);\n    }\n\n    \n\n    TgaHeader header;\n    header.Parse(fptr);\n\n\n    width = header.width;\n    height = header.height;\n\n    \n\n    if (header.datatypecode != 2 && header.datatypecode != 10)\n    {\n        fprintf(stderr, \"Can only handle image type 2 and 10\\n\");\n        exit(-1);\n    }\n    if (header.bitsperpixel != 16 && header.bitsperpixel != 24 && header.bitsperpixel != 32)\n    {\n        fprintf(stderr, \"Can only handle pixel depths of 16, 24, and 32\\n\");\n        exit(-1);\n    }\n    if (header.colormaptype != 0 && header.colormaptype != 1)\n    {\n        fprintf(stderr, \"Can only handle color map types of 0 and 1\\n\");\n        exit(-1);\n    }\n\n    \n\n    int skip_bytes = header.idlength + (header.colormaptype * header.colormaplength);\n    fseek(fptr, skip_bytes, SEEK_CUR);\n\n    \n\n    int pixel_bytes = header.bitsperpixel / 8;\n\n    \n\n    size_t image_bytes = width * height * sizeof(sycl::uchar4);\n    if ((pixels == NULL) && ((pixels = (sycl::uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n    memset(pixels, 0, image_bytes);\n\n    \n\n    unsigned char   tga_pixel[5];\n    int             current_pixel = 0;\n    while (current_pixel < header.width * header.height)\n    {\n        if (header.datatypecode == 2)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d  (uncompressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n            current_pixel++;\n        }\n        else if (header.datatypecode == 10)\n        {\n            \n\n            if (fread(tga_pixel, 1, pixel_bytes + 1, fptr) != pixel_bytes + 1)\n            {\n                fprintf(stderr, \"Unexpected end of file at pixel %d (compressed)\\n\", current_pixel);\n                exit(-1);\n            }\n            int run_length = tga_pixel[0] & 0x7f;\n            ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n            current_pixel++;\n\n            if (tga_pixel[0] & 0x80)\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    ParseTgaPixel(pixels[current_pixel], &(tga_pixel[1]), pixel_bytes);\n                    current_pixel++;\n                }\n            }\n            else\n            {\n                \n\n                for (int i = 0; i < run_length; i++)\n                {\n                    if (fread(tga_pixel, 1, pixel_bytes, fptr) != pixel_bytes)\n                    {\n                        fprintf(stderr, \"Unexpected end of file at pixel %d (normal)\\n\", current_pixel);\n                        exit(-1);\n                    }\n                    ParseTgaPixel(pixels[current_pixel], tga_pixel, pixel_bytes);\n                    current_pixel++;\n                }\n            }\n        }\n    }\n\n    \n\n    fclose(fptr);\n}\n\n\n\n\n\n\n\n\n\n\n\n\nvoid GenerateRandomImage(sycl::uchar4* &pixels, int width, int height, int entropy_reduction)\n{\n    int num_pixels = width * height;\n    size_t image_bytes = num_pixels * sizeof(sycl::uchar4);\n    if ((pixels == NULL) && ((pixels = (sycl::uchar4*) malloc(image_bytes)) == NULL))\n    {\n        fprintf(stderr, \"malloc of image failed\\n\");\n        exit(-1);\n    }\n\n    for (int i = 0; i < num_pixels; ++i)\n    {\n        RandomBits(pixels[i].x(), entropy_reduction);\n        RandomBits(pixels[i].y(), entropy_reduction);\n        RandomBits(pixels[i].z(), entropy_reduction);\n        RandomBits(pixels[i].w(), entropy_reduction);\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(sycl::float4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    float* samples = reinterpret_cast<float*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL] * float(NUM_BINS));\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(sycl::uchar4 pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    unsigned char* samples = reinterpret_cast<unsigned char*>(&pixel);\n\n    for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n        bins[CHANNEL] = (unsigned int) (samples[CHANNEL]);\n}\n\n\n\ntemplate <int NUM_BINS, int ACTIVE_CHANNELS>\nvoid DecodePixelGold(unsigned char pixel, unsigned int (&bins)[ACTIVE_CHANNELS])\n{\n    bins[0] = (unsigned int) pixel;\n}\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid HistogramGold(PixelType *image, int width, int height, unsigned int* hist)\n{\n    memset(hist, 0, ACTIVE_CHANNELS * NUM_BINS * sizeof(unsigned int));\n\n    for (int i = 0; i < width; i++)\n    {\n        for (int j = 0; j < height; j++)\n        {\n            PixelType pixel = image[i + j * width];\n\n            unsigned int bins[ACTIVE_CHANNELS];\n            DecodePixelGold<NUM_BINS>(pixel, bins);\n\n            for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL)\n            {\n                hist[(NUM_BINS * CHANNEL) + bins[CHANNEL]]++;\n            }\n        }\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\ntemplate <\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid RunTest(\n    std::vector<std::pair<std::string, double> >&   timings,\n    sycl::queue                                     &q,\n    PixelType *                                     d_pixels,\n    const int                                       width,\n    const int                                       height,\n    unsigned int *                                  d_hist,\n    unsigned int *                                  h_hist,\n    int                                             timing_iterations,\n    const char *                                    long_name,\n    const char *                                    short_name,\n    double (*f)(sycl::queue&, \n                PixelType*,\n                int,   \n\n                int,   \n\n                unsigned int*,\n                bool)\n    )\n{\n    if (!g_report) printf(\"%s \", long_name); fflush(stdout);\n\n    \n\n    (*f)(q, d_pixels, width, height, d_hist, !g_report);\n\n    int compare = CompareDeviceResults(q, h_hist, d_hist, ACTIVE_CHANNELS * NUM_BINS, true, g_verbose);\n    if (!g_report) printf(\"\\t%s\\n\", compare ? \"FAIL\" : \"PASS\"); fflush(stdout);\n\n    double elapsed_ms = 0;\n    for (int i = 0; i < timing_iterations; i++)\n    {\n        elapsed_ms += (*f)(q, d_pixels, width, height, d_hist, false);\n    }\n    double avg_us = (elapsed_ms / timing_iterations) * 1000;    \n\n    timings.push_back(std::pair<std::string, double>(short_name, avg_us));\n\n    if (!g_report)\n    {\n        printf(\"Avg time %.3f us (%d iterations)\\n\", avg_us, timing_iterations); fflush(stdout);\n    }\n    else\n    {\n        printf(\"%.3f, \", avg_us); fflush(stdout);\n    }\n\n    \n\n}\n\n\n\n\ntemplate <\n    int         NUM_CHANNELS,\n    int         ACTIVE_CHANNELS,\n    int         NUM_BINS,\n    typename    PixelType>\nvoid TestMethods(\n    PixelType*  h_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  size_t pixel_bytes = width * height * sizeof(PixelType);\n  PixelType *d_pixels = sycl::malloc_device<PixelType>(width * height, q);\n  q.memcpy(d_pixels, h_pixels, pixel_bytes);\n\n  if (g_report) printf(\"%.3f, \", double(pixel_bytes) / bandwidth_GBs / 1000);\n\n  \n\n  unsigned int *h_hist;\n  \n\n  size_t histogram_bytes = NUM_BINS * ACTIVE_CHANNELS * sizeof(unsigned int);\n  h_hist = (unsigned int *) malloc(histogram_bytes);\n  unsigned int *d_hist = sycl::malloc_device<unsigned int>(NUM_BINS * ACTIVE_CHANNELS, q);\n\n  \n\n  HistogramGold<ACTIVE_CHANNELS, NUM_BINS>(h_pixels, width, height, h_hist);\n\n  \n\n  std::vector<std::pair<std::string, double> > timings;\n\n  \n\n  RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, q, d_pixels, width, height, d_hist, h_hist, timing_iterations,\n      \"Shared memory atomics\", \"smem atomics\", run_smem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n  RunTest<ACTIVE_CHANNELS, NUM_BINS>(timings, q, d_pixels, width, height, d_hist, h_hist, timing_iterations,\n      \"Global memory atomics\", \"gmem atomics\", run_gmem_atomics<ACTIVE_CHANNELS, NUM_BINS, PixelType>);\n\n  \n\n  if (!g_report)\n  {\n      std::sort(timings.begin(), timings.end(), less_than_value());\n      printf(\"Timings (us):\\n\");\n      for (int i = 0; i < timings.size(); i++)\n      {\n          double bandwidth = height * width * sizeof(PixelType) / timings[i].second / 1000;\n          printf(\"\\t %.3f %s (%.3f GB/s, %.3f%% peak)\\n\", timings[i].second, timings[i].first.c_str(), bandwidth, bandwidth / bandwidth_GBs * 100);\n      }\n      printf(\"\\n\");\n  }\n\n  \n\n  free(h_hist);\n  sycl::free(d_pixels, q);\n  sycl::free(d_hist, q);\n}\n\n\n\n\nvoid TestGenres(\n    sycl::uchar4*     uchar4_pixels,\n    int         height,\n    int         width,\n    int         timing_iterations,\n    double      bandwidth_GBs)\n{\n    int num_pixels = width * height;\n\n    {\n        if (!g_report) printf(\"1 channel unsigned char tests (256-bin):\\n\\n\"); fflush(stdout);\n\n        size_t image_bytes = num_pixels * sizeof(unsigned char);\n        unsigned char *uchar1_pixels = (unsigned char*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            uchar1_pixels[i] = (unsigned char)\n                (((unsigned int) uchar4_pixels[i].x() +\n                  (unsigned int) uchar4_pixels[i].y() +\n                  (unsigned int) uchar4_pixels[i].z()) / 3);\n        }\n\n        TestMethods<1, 1, 256>(uchar1_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(uchar1_pixels);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel uchar4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        TestMethods<4, 3, 256>(uchar4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        if (g_report) printf(\", \");\n    }\n\n    {\n        if (!g_report) printf(\"3/4 channel float4 tests (256-bin):\\n\\n\"); fflush(stdout);\n        size_t image_bytes = num_pixels * sizeof(sycl::float4);\n\tsycl::float4 *float4_pixels = (sycl::float4*) malloc(image_bytes);\n\n        \n\n        for (int i = 0; i < num_pixels; ++i)\n        {\n            float4_pixels[i].x() = float(uchar4_pixels[i].x()) / 256;\n            float4_pixels[i].y() = float(uchar4_pixels[i].y()) / 256;\n            float4_pixels[i].z() = float(uchar4_pixels[i].z()) / 256;\n            float4_pixels[i].w() = float(uchar4_pixels[i].w()) / 256;\n        }\n        TestMethods<4, 3, 256>(float4_pixels, width, height, timing_iterations, bandwidth_GBs);\n        free(float4_pixels);\n        if (g_report) printf(\"\\n\");\n    }\n}\n\n\n\n\nint main(int argc, char **argv)\n{\n    \n\n    CommandLineArgs args(argc, argv);\n    if (args.CheckCmdLineFlag(\"help\"))\n    {\n        printf(\n            \"%s \"\n            \"[--v] \"\n            \"[--i=<timing iterations>] \"\n            \"\\n\\t\"\n                \"--file=<.tga filename> \"\n            \"\\n\\t\"\n                \"--entropy=<-1 (0%%), 0 (100%%), 1 (81%%), 2 (54%%), 3 (34%%), 4 (20%%), ...\"\n                \"[--height=<default: 1080>] \"\n                \"[--width=<default: 1920>] \"\n            \"\\n\", argv[0]);\n        exit(0);\n    }\n\n    std::string         filename;\n    int                 timing_iterations   = 100;\n    int                 entropy_reduction   = 0;\n    int                 height              = 1080;\n    int                 width               = 1920;\n\n    g_verbose = args.CheckCmdLineFlag(\"v\");\n    g_report = args.CheckCmdLineFlag(\"report\");\n    args.GetCmdLineArgument(\"i\", timing_iterations);\n    args.GetCmdLineArgument(\"file\", filename);\n    args.GetCmdLineArgument(\"height\", height);\n    args.GetCmdLineArgument(\"width\", width);\n    args.GetCmdLineArgument(\"entropy\", entropy_reduction);\n\n    \n\n    args.DeviceInit();\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n    double bandwidth_GBs = 41;  \n\n\n    \n\n    sycl::uchar4* uchar4_pixels = NULL;\n    if (!g_report)\n    {\n        if (!filename.empty())\n        {\n            \n\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            printf(\"File %s: width(%d) height(%d)\\n\\n\", filename.c_str(), width, height); fflush(stdout);\n        }\n        else\n        {\n            \n\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            printf(\"Random image: entropy-reduction(%d) width(%d) height(%d)\\n\\n\", entropy_reduction, width, height); fflush(stdout);\n        }\n\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n    }\n    else\n    {\n        \n\n        printf(\"Test, MIN, RLE CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM, , MIN, RLE_CUB, SMEM, GMEM\\n\");\n\n        \n\n        for (entropy_reduction = 0; entropy_reduction < 5; ++entropy_reduction)\n        {\n            printf(\"entropy reduction %d, \", entropy_reduction);\n            GenerateRandomImage(uchar4_pixels, width, height, entropy_reduction);\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n        printf(\"entropy reduction -1, \");\n        GenerateRandomImage(uchar4_pixels, width, height, -1);\n        TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        printf(\"\\n\");\n\n        \n\n        std::vector<std::string> file_tests;\n        file_tests.push_back(\"animals\");\n        file_tests.push_back(\"apples\");\n        file_tests.push_back(\"sunset\");\n        file_tests.push_back(\"cheetah\");\n        file_tests.push_back(\"nature\");\n        file_tests.push_back(\"operahouse\");\n        file_tests.push_back(\"austin\");\n        file_tests.push_back(\"cityscape\");\n\n        for (int i = 0; i < file_tests.size(); ++i)\n        {\n            printf(\"%s, \", file_tests[i].c_str());\n            std::string filename = std::string(\"histogram/benchmark/\") + file_tests[i] + \".tga\";\n            ReadTga(uchar4_pixels, width, height, filename.c_str());\n            TestGenres(uchar4_pixels, height, width, timing_iterations, bandwidth_GBs);\n        }\n    }\n\n    free(uchar4_pixels);\n\n    printf(\"\\n\\n\");\n\n    return 0;\n}\n"}}
{"kernel_name": "scan", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n\ntemplate<typename T>\nvoid verify(const T* cpu_out, const T* gpu_out, int64_t n)\n{\n  int error = memcmp(cpu_out, gpu_out, n * sizeof(T));\n  if (error) {\n    for (int64_t i = 0; i < n; i++) {\n      if (cpu_out[i] != gpu_out[i]) {\n        printf(\"@%zu: %lf != %lf\\n\", i, (double)cpu_out[i], (double)gpu_out[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n}\n\n\n\n\n#define LOG_MEM_BANKS 5\n#define OFFSET(n) ((n) >> LOG_MEM_BANKS)\n\n\n\ntemplate<typename T, int N>\n__global__ void scan_bcao (\n  const int64_t nblocks,\n        T *__restrict__ g_odata,\n  const T *__restrict__ g_idata)\n{\n  __shared__ T temp[2*N];\n\n  for (int64_t bid = blockIdx.x; bid < nblocks; bid += gridDim.x)\n  {\n    auto gi = g_idata + bid * N;\n    auto go = g_odata + bid * N;\n\n    int thid = threadIdx.x;\n    int a = thid;\n    int b = a + (N/2);\n    int oa = OFFSET(a);\n    int ob = OFFSET(b);\n\n    temp[a + oa] = gi[a];\n    temp[b + ob] = gi[b];\n\n    int offset = 1;\n    for (int d = N >> 1; d > 0; d >>= 1)\n    {\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        ai += OFFSET(ai);\n        bi += OFFSET(bi);\n        temp[bi] += temp[ai];\n      }\n      offset *= 2;\n    }\n\n    if (thid == 0) temp[N-1+OFFSET(N-1)] = 0; \n\n    for (int d = 1; d < N; d *= 2) \n\n    {\n      offset >>= 1;\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        ai += OFFSET(ai);\n        bi += OFFSET(bi);\n        T t = temp[ai];\n        temp[ai] = temp[bi];\n        temp[bi] += t;\n      }\n    }\n    __syncthreads(); \n\n\n    go[a] = temp[a + oa];\n    go[b] = temp[b + ob];\n  }\n}\n\ntemplate<typename T, int N>\n__global__ void scan(\n  const int64_t nblocks,\n        T *__restrict__ g_odata,\n  const T *__restrict__ g_idata)\n{\n  __shared__ T temp[N];\n\n  for (int64_t bid = blockIdx.x; bid < nblocks; bid += gridDim.x)\n  {\n    auto gi = g_idata + bid * N;\n    auto go = g_odata + bid * N;\n\n    int thid = threadIdx.x;\n    int offset = 1;\n    temp[2*thid]   = gi[2*thid];\n    temp[2*thid+1] = gi[2*thid+1];\n    for (int d = N >> 1; d > 0; d >>= 1)\n    {\n      __syncthreads();\n      if (thid < d)\n      {\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        temp[bi] += temp[ai];\n      }\n      offset *= 2;\n    }\n\n    if (thid == 0) temp[N-1] = 0; \n\n    for (int d = 1; d < N; d *= 2) \n\n    {\n      offset >>= 1;\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        T t = temp[ai];\n        temp[ai] = temp[bi];\n        temp[bi] += t;\n      }\n    }\n    go[2*thid] = temp[2*thid];\n    go[2*thid+1] = temp[2*thid+1];\n  }\n}\n\ntemplate <typename T, int N>\nvoid runTest (const int64_t n, const int repeat, bool timing = false)\n{\n  int64_t num_blocks = (n + N - 1) / N;\n\n  int64_t nelems = num_blocks * N; \n\n\n  int64_t bytes = nelems * sizeof(T);\n\n  T *in = (T*) malloc (bytes);\n  T *cpu_out = (T*) malloc (bytes);\n  T *gpu_out = (T*) malloc (bytes);\n\n  srand(123);\n  for (int64_t n = 0; n < nelems; n++) in[n] = rand() % 5 + 1;\n\n  T *t_in = in;\n  T *t_out = cpu_out;\n  for (int64_t n = 0; n < num_blocks; n++) {\n    t_out[0] = 0;\n    for (int i = 1; i < N; i++)\n      t_out[i] = t_out[i-1] + t_in[i-1];\n    t_out += N;\n    t_in += N;\n  }\n\n  T *d_in, *d_out;\n\n  cudaMalloc((void**)&d_in, bytes);\n  cudaMemcpy(d_in, in, bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_out, bytes);\n\n  cudaDeviceProp prop;\n  cudaGetDeviceProperties(&prop, 0);\n  dim3 grids (16 * prop.multiProcessorCount);\n  dim3 blocks (N/2);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    scan<T, N><<<grids, blocks>>>(num_blocks, d_out, d_in);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  if (timing) {\n    printf(\"Element size in bytes is %zu. Average execution time of scan (w/  bank conflicts): %f (us)\\n\",\n           sizeof(T), (time * 1e-3f) / repeat);\n  }\n  cudaMemcpy(gpu_out, d_out, bytes, cudaMemcpyDeviceToHost);\n  if (!timing) verify(cpu_out, gpu_out, nelems);\n\n  \n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    scan_bcao<T, N><<<grids, blocks>>>(num_blocks, d_out, d_in);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  auto bcao_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  if (timing) {\n    printf(\"Element size in bytes is %zu. Average execution time of scan (w/o bank conflicts): %f (us). \",\n           sizeof(T), (bcao_time * 1e-3f) / repeat);\n    printf(\"Reduce the time by %.1f%%\\n\", (time - bcao_time) * 1.0 / time * 100);\n  }\n  cudaMemcpy(gpu_out, d_out, bytes, cudaMemcpyDeviceToHost);\n  if (!timing) verify(cpu_out, gpu_out, nelems);\n\n  cudaFree(d_in);\n  cudaFree(d_out);\n  free(in);\n  free(cpu_out);\n  free(gpu_out);\n}\n\ntemplate<int N>\nvoid run (const int64_t n, const int repeat) {\n  for (int i = 0; i < 2; i++) {\n    bool report_timing = i > 0;\n    printf(\"\\nThe number of elements to scan in a thread block: %d\\n\", N);\n    runTest< char, N>(n, repeat, report_timing);\n    runTest<short, N>(n, repeat, report_timing);\n    runTest<  int, N>(n, repeat, report_timing);\n    runTest< long, N>(n, repeat, report_timing);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int64_t n = atol(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  run< 128>(n, repeat);\n  run< 256>(n, repeat);\n  run< 512>(n, repeat);\n  run<1024>(n, repeat);\n  run<2048>(n, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "scan", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\ntemplate<typename T>\nvoid verify(const T* cpu_out, const T* gpu_out, int64_t n)\n{\n  int error = memcmp(cpu_out, gpu_out, n * sizeof(T));\n  if (error) {\n    for (int64_t i = 0; i < n; i++) {\n      if (cpu_out[i] != gpu_out[i]) {\n        printf(\"@%zu: %lf != %lf\\n\", i, (double)cpu_out[i], (double)gpu_out[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n}\n\n\n\n\n#define LOG_MEM_BANKS 5\n#define OFFSET(n) ((n) >> LOG_MEM_BANKS)\n\n\n\ntemplate<typename T, int N>\n__global__ void scan_bcao (\n  const int64_t nblocks,\n        T *__restrict__ g_odata,\n  const T *__restrict__ g_idata)\n{\n  __shared__ T temp[2*N];\n\n  for (int64_t bid = blockIdx.x; bid < nblocks; bid += gridDim.x)\n  {\n    auto gi = g_idata + bid * N;\n    auto go = g_odata + bid * N;\n\n    int thid = threadIdx.x;\n    int a = thid;\n    int b = a + (N/2);\n    int oa = OFFSET(a);\n    int ob = OFFSET(b);\n\n    temp[a + oa] = gi[a];\n    temp[b + ob] = gi[b];\n\n    int offset = 1;\n    for (int d = N >> 1; d > 0; d >>= 1)\n    {\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        ai += OFFSET(ai);\n        bi += OFFSET(bi);\n        temp[bi] += temp[ai];\n      }\n      offset *= 2;\n    }\n\n    if (thid == 0) temp[N-1+OFFSET(N-1)] = 0; \n\n    for (int d = 1; d < N; d *= 2) \n\n    {\n      offset >>= 1;\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        ai += OFFSET(ai);\n        bi += OFFSET(bi);\n        T t = temp[ai];\n        temp[ai] = temp[bi];\n        temp[bi] += t;\n      }\n    }\n    __syncthreads(); \n\n\n    go[a] = temp[a + oa];\n    go[b] = temp[b + ob];\n  }\n}\n\ntemplate<typename T, int N>\n__global__ void scan(\n  const int64_t nblocks,\n        T *__restrict__ g_odata,\n  const T *__restrict__ g_idata)\n{\n  __shared__ T temp[N];\n\n  for (int64_t bid = blockIdx.x; bid < nblocks; bid += gridDim.x)\n  {\n    auto gi = g_idata + bid * N;\n    auto go = g_odata + bid * N;\n\n    int thid = threadIdx.x;\n    int offset = 1;\n    temp[2*thid]   = gi[2*thid];\n    temp[2*thid+1] = gi[2*thid+1];\n    for (int d = N >> 1; d > 0; d >>= 1)\n    {\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        temp[bi] += temp[ai];\n      }\n      offset *= 2;\n    }\n\n    if (thid == 0) temp[N-1] = 0; \n\n    for (int d = 1; d < N; d *= 2) \n\n    {\n      offset >>= 1;\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        T t = temp[ai];\n        temp[ai] = temp[bi];\n        temp[bi] += t;\n      }\n    }\n    go[2*thid] = temp[2*thid];\n    go[2*thid+1] = temp[2*thid+1];\n  }\n}\n\ntemplate <typename T, int N>\nvoid runTest (const int64_t n, const int repeat, bool timing = false)\n{\n  int64_t num_blocks = (n + N - 1) / N;\n\n  int64_t nelems = num_blocks * N; \n\n\n  int64_t bytes = nelems * sizeof(T);\n\n  T *in = (T*) malloc (bytes);\n  T *cpu_out = (T*) malloc (bytes);\n  T *gpu_out = (T*) malloc (bytes);\n\n  srand(123);\n  for (int64_t n = 0; n < nelems; n++) in[n] = rand() % 5 + 1;\n\n  T *t_in = in;\n  T *t_out = cpu_out;\n  for (int64_t n = 0; n < num_blocks; n++) {\n    t_out[0] = 0;\n    for (int i = 1; i < N; i++)\n      t_out[i] = t_out[i-1] + t_in[i-1];\n    t_out += N;\n    t_in += N;\n  }\n\n  T *d_in, *d_out;\n\n  hipMalloc((void**)&d_in, bytes);\n  hipMemcpy(d_in, in, bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_out, bytes);\n\n  hipDeviceProp_t prop;\n  hipGetDeviceProperties(&prop, 0);\n  dim3 grids (16 * prop.multiProcessorCount);\n  dim3 blocks (N/2);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    scan<T, N><<<grids, blocks>>>(num_blocks, d_out, d_in);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  if (timing) {\n    printf(\"Element size in bytes is %zu. Average execution time of scan (w/  bank conflicts): %f (us)\\n\",\n           sizeof(T), (time * 1e-3f) / repeat);\n  }\n  hipMemcpy(gpu_out, d_out, bytes, hipMemcpyDeviceToHost);\n  if (!timing) verify(cpu_out, gpu_out, nelems);\n\n  \n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    scan_bcao<T, N><<<grids, blocks>>>(num_blocks, d_out, d_in);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  auto bcao_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  if (timing) {\n    printf(\"Element size in bytes is %zu. Average execution time of scan (w/o bank conflicts): %f (us). \",\n           sizeof(T), (bcao_time * 1e-3f) / repeat);\n    printf(\"Reduce the time by %.1f%%\\n\", (time - bcao_time) * 1.0 / time * 100);\n  }\n  hipMemcpy(gpu_out, d_out, bytes, hipMemcpyDeviceToHost);\n  if (!timing) verify(cpu_out, gpu_out, nelems);\n\n  hipFree(d_in);\n  hipFree(d_out);\n  free(in);\n  free(cpu_out);\n  free(gpu_out);\n}\n\ntemplate<int N>\nvoid run (const int64_t n, const int repeat) {\n  for (int i = 0; i < 2; i++) {\n    bool report_timing = i > 0;\n    printf(\"\\nThe number of elements to scan in a thread block: %d\\n\", N);\n    runTest< char, N>(n, repeat, report_timing);\n    runTest<short, N>(n, repeat, report_timing);\n    runTest<  int, N>(n, repeat, report_timing);\n    runTest< long, N>(n, repeat, report_timing);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int64_t n = atol(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  run< 128>(n, repeat);\n  run< 256>(n, repeat);\n  run< 512>(n, repeat);\n  run<1024>(n, repeat);\n  run<2048>(n, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "scan", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n\ntemplate<typename T>\nvoid verify(const T* ref_out, const T* out, int64_t n)\n{\n  int error = memcmp(ref_out, out, n * sizeof(T));\n  if (error) {\n    for (int64_t i = 0; i < n; i++) {\n      if (ref_out[i] != out[i]) {\n        printf(\"@%zu: %lf != %lf\\n\", i, (double)ref_out[i], (double)out[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n}\n\n\n\n#define LOG_MEM_BANKS 5\n#define OFFSET(n) ((n) >> LOG_MEM_BANKS)\n\ntemplate<typename T, int N>\nvoid runTest (const int64_t n, const int repeat, bool timing = false)\n{\n  int64_t num_blocks = (n + N - 1) / N;\n\n  int64_t nelems = num_blocks * N; \n\n\n  int64_t bytes = nelems * sizeof(T);\n\n  T *in = (T*) malloc (bytes);\n  T *out = (T*) malloc (bytes);\n  T *ref_out = (T*) malloc (bytes);\n\n  srand(123);\n  for (int64_t n = 0; n < nelems; n++) in[n] = rand() % 5 + 1;\n\n  T *t_in = in;\n  T *t_out = ref_out;\n  for (int64_t n = 0; n < num_blocks; n++) {\n    t_out[0] = 0;\n    for (int i = 1; i < N; i++)\n      t_out[i] = t_out[i-1] + t_in[i-1];\n    t_out += N;\n    t_in += N;\n  }\n\n  #pragma omp target data map(to: in[0:nelems]) map(alloc: out[0:nelems])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target teams num_teams(num_blocks) thread_limit(N/2)\n      {\n        T temp[N];\n        #pragma omp parallel\n        {\n          for (int64_t bid = omp_get_team_num(); bid < num_blocks; bid += omp_get_num_teams())\n          {\n            T *t_in  = in + bid * N;\n            T *t_out = out + bid * N;\n\n            int thid = omp_get_thread_num();\n            int offset = 1;\n\n            temp[2*thid]   = t_in[2*thid];\n            temp[2*thid+1] = t_in[2*thid+1];\n\n            for (int d = N >> 1; d > 0; d >>= 1)\n            {\n              #pragma omp barrier\n              if (thid < d)\n              {\n                int ai = offset*(2*thid+1)-1;\n                int bi = offset*(2*thid+2)-1;\n                temp[bi] += temp[ai];\n              }\n              offset *= 2;\n            }\n\n            if (thid == 0) temp[N-1] = 0; \n\n            for (int d = 1; d < N; d *= 2) \n\n            {\n              offset >>= 1;\n              #pragma omp barrier\n              if (thid < d)\n              {\n                int ai = offset*(2*thid+1)-1;\n                int bi = offset*(2*thid+2)-1;\n                T t = temp[ai];\n                temp[ai] = temp[bi];\n                temp[bi] += t;\n              }\n            }\n            t_out[2*thid] = temp[2*thid];\n            t_out[2*thid+1] = temp[2*thid+1];\n\t  }\n\t}\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    if (timing) {\n      printf(\"Element size in bytes is %zu. Average execution time of scan (w/  bank conflicts): %f (us)\\n\",\n             sizeof(T), (time * 1e-3f) / repeat);\n    }\n    #pragma omp target update from (out[0:nelems])\n    if (!timing) verify(ref_out, out, nelems);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target teams num_teams(num_blocks) thread_limit(N/2)\n      {\n        T temp[2*N];\n        #pragma omp parallel\n        {\n          for (int64_t bid = omp_get_team_num(); bid < num_blocks; bid += omp_get_num_teams())\n          {\n            T *t_in  = in + bid * N;\n            T *t_out = out + bid * N;\n\n            int thid = omp_get_thread_num();\n            int a = thid;\n            int b = a + (N/2);\n            int oa = OFFSET(a);\n            int ob = OFFSET(b);\n\n            temp[a + oa] = t_in[a];\n            temp[b + ob] = t_in[b];\n\n            int offset = 1;\n            for (int d = N >> 1; d > 0; d >>= 1)\n            {\n              #pragma omp barrier\n              if (thid < d)\n              {\n                int ai = offset*(2*thid+1)-1;\n                int bi = offset*(2*thid+2)-1;\n                ai += OFFSET(ai);\n                bi += OFFSET(bi);\n                temp[bi] += temp[ai];\n              }\n              offset *= 2;\n            }\n\n            if (thid == 0) temp[N-1+OFFSET(N-1)] = 0; \n\n            for (int d = 1; d < N; d *= 2) \n\n            {\n              offset >>= 1;\n              #pragma omp barrier\n              if (thid < d)\n              {\n                int ai = offset*(2*thid+1)-1;\n                int bi = offset*(2*thid+2)-1;\n                ai += OFFSET(ai);\n                bi += OFFSET(bi);\n                T t = temp[ai];\n                temp[ai] = temp[bi];\n                temp[bi] += t;\n              }\n            }\n            #pragma omp barrier \n\n\n            t_out[a] = temp[a + oa];\n            t_out[b] = temp[b + ob];\n          }\n        }\n      }\n    }\n\n    end = std::chrono::steady_clock::now();\n    auto bcao_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    if (timing) {\n      printf(\"Element size in bytes is %zu. Average execution time of scan (w/o bank conflicts): %f (us). \",\n             sizeof(T), (bcao_time * 1e-3f) / repeat);\n      printf(\"Reduce the time by %.1f%%\\n\", (time - bcao_time) * 1.0 / time * 100);\n    }\n\n    #pragma omp target update from (out[0:nelems])\n    if (!timing) verify(ref_out, out, nelems);\n  }\n}\n\ntemplate<int N>\nvoid run (const int n, const int repeat) {\n  for (int i = 0; i < 2; i++) {\n    bool report_timing = i > 0;\n    printf(\"\\nThe number of elements to scan in a thread block: %d\\n\", N);\n    runTest< char, N>(n, repeat, report_timing);\n    runTest<short, N>(n, repeat, report_timing);\n    runTest<  int, N>(n, repeat, report_timing);\n    runTest< long, N>(n, repeat, report_timing);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  run< 128>(n, repeat);\n  run< 256>(n, repeat);\n  run< 512>(n, repeat);\n  run<1024>(n, repeat);\n  run<2048>(n, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "scan", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n\ntemplate<typename T>\nvoid verify(const T* ref_out, const T* out, int64_t n)\n{\n  int error = memcmp(ref_out, out, n * sizeof(T));\n  if (error) {\n    for (int64_t i = 0; i < n; i++) {\n      if (ref_out[i] != out[i]) {\n        printf(\"@%zu: %lf != %lf\\n\", i, (double)ref_out[i], (double)out[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n}\n\n\n\n#define LOG_MEM_BANKS 5\n#define OFFSET(n) ((n) >> LOG_MEM_BANKS)\n\ntemplate<typename T, int N>\nvoid runTest (const int64_t n, const int repeat, bool timing = false)\n{\n  int64_t num_blocks = (n + N - 1) / N;\n\n  int64_t nelems = num_blocks * N; \n\n\n  int64_t bytes = nelems * sizeof(T);\n\n  T *in = (T*) malloc (bytes);\n  T *out = (T*) malloc (bytes);\n  T *ref_out = (T*) malloc (bytes);\n\n  srand(123);\n  for (int64_t n = 0; n < nelems; n++) in[n] = rand() % 5 + 1;\n\n  T *t_in = in;\n  T *t_out = ref_out;\n  for (int64_t n = 0; n < num_blocks; n++) {\n    t_out[0] = 0;\n    for (int i = 1; i < N; i++)\n      t_out[i] = t_out[i-1] + t_in[i-1];\n    t_out += N;\n    t_in += N;\n  }\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n            {\n        T temp[N];\n                {\n          for (int64_t bid = omp_get_team_num(); bid < num_blocks; bid += omp_get_num_teams())\n          {\n            T *t_in  = in + bid * N;\n            T *t_out = out + bid * N;\n\n            int thid = omp_get_thread_num();\n            int offset = 1;\n\n            temp[2*thid]   = t_in[2*thid];\n            temp[2*thid+1] = t_in[2*thid+1];\n\n            for (int d = N >> 1; d > 0; d >>= 1)\n            {\n                            if (thid < d)\n              {\n                int ai = offset*(2*thid+1)-1;\n                int bi = offset*(2*thid+2)-1;\n                temp[bi] += temp[ai];\n              }\n              offset *= 2;\n            }\n\n            if (thid == 0) temp[N-1] = 0; \n\n            for (int d = 1; d < N; d *= 2) \n\n            {\n              offset >>= 1;\n                            if (thid < d)\n              {\n                int ai = offset*(2*thid+1)-1;\n                int bi = offset*(2*thid+2)-1;\n                T t = temp[ai];\n                temp[ai] = temp[bi];\n                temp[bi] += t;\n              }\n            }\n            t_out[2*thid] = temp[2*thid];\n            t_out[2*thid+1] = temp[2*thid+1];\n\t  }\n\t}\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    if (timing) {\n      printf(\"Element size in bytes is %zu. Average execution time of scan (w/  bank conflicts): %f (us)\\n\",\n             sizeof(T), (time * 1e-3f) / repeat);\n    }\n        if (!timing) verify(ref_out, out, nelems);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n            {\n        T temp[2*N];\n                {\n          for (int64_t bid = omp_get_team_num(); bid < num_blocks; bid += omp_get_num_teams())\n          {\n            T *t_in  = in + bid * N;\n            T *t_out = out + bid * N;\n\n            int thid = omp_get_thread_num();\n            int a = thid;\n            int b = a + (N/2);\n            int oa = OFFSET(a);\n            int ob = OFFSET(b);\n\n            temp[a + oa] = t_in[a];\n            temp[b + ob] = t_in[b];\n\n            int offset = 1;\n            for (int d = N >> 1; d > 0; d >>= 1)\n            {\n                            if (thid < d)\n              {\n                int ai = offset*(2*thid+1)-1;\n                int bi = offset*(2*thid+2)-1;\n                ai += OFFSET(ai);\n                bi += OFFSET(bi);\n                temp[bi] += temp[ai];\n              }\n              offset *= 2;\n            }\n\n            if (thid == 0) temp[N-1+OFFSET(N-1)] = 0; \n\n            for (int d = 1; d < N; d *= 2) \n\n            {\n              offset >>= 1;\n                            if (thid < d)\n              {\n                int ai = offset*(2*thid+1)-1;\n                int bi = offset*(2*thid+2)-1;\n                ai += OFFSET(ai);\n                bi += OFFSET(bi);\n                T t = temp[ai];\n                temp[ai] = temp[bi];\n                temp[bi] += t;\n              }\n            }\n            \n\n            t_out[a] = temp[a + oa];\n            t_out[b] = temp[b + ob];\n          }\n        }\n      }\n    }\n\n    end = std::chrono::steady_clock::now();\n    auto bcao_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    if (timing) {\n      printf(\"Element size in bytes is %zu. Average execution time of scan (w/o bank conflicts): %f (us). \",\n             sizeof(T), (bcao_time * 1e-3f) / repeat);\n      printf(\"Reduce the time by %.1f%%\\n\", (time - bcao_time) * 1.0 / time * 100);\n    }\n\n        if (!timing) verify(ref_out, out, nelems);\n  }\n}\n\ntemplate<int N>\nvoid run (const int n, const int repeat) {\n  for (int i = 0; i < 2; i++) {\n    bool report_timing = i > 0;\n    printf(\"\\nThe number of elements to scan in a thread block: %d\\n\", N);\n    runTest< char, N>(n, repeat, report_timing);\n    runTest<short, N>(n, repeat, report_timing);\n    runTest<  int, N>(n, repeat, report_timing);\n    runTest< long, N>(n, repeat, report_timing);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  run< 128>(n, repeat);\n  run< 256>(n, repeat);\n  run< 512>(n, repeat);\n  run<1024>(n, repeat);\n  run<2048>(n, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "scan", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\ntemplate<typename T>\nvoid verify(const T* cpu_out, const T* gpu_out, int64_t n)\n{\n  int error = memcmp(cpu_out, gpu_out, n * sizeof(T));\n  if (error) {\n    for (int64_t i = 0; i < n; i++) {\n      if (cpu_out[i] != gpu_out[i]) {\n        printf(\"@%zu: %lf != %lf\\n\", i, (double)cpu_out[i], (double)gpu_out[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n}\n\n#define LOG_MEM_BANKS 5\n#define OFFSET(n) ((n) >> LOG_MEM_BANKS)\n#define __syncthreads() item.barrier(sycl::access::fence_space::local_space)\n\ntemplate<typename T, int N>\nclass opt;\n\ntemplate <typename T, int N>\nclass base;\n\n\n\ntemplate<typename T, int N>\nvoid scan_bcao (\n        sycl::nd_item<1> &item,\n        T *temp,\n  const int64_t nblocks,\n        T *__restrict g_odata,\n  const T *__restrict g_idata)\n{\n  for (int64_t bid = item.get_group(0); bid < nblocks; bid += item.get_group_range(0))\n  {\n    auto gi = g_idata + bid * N;\n    auto go = g_odata + bid * N;\n\n    int thid = item.get_local_id(0);\n    int a = thid;\n    int b = a + (N/2);\n    int oa = OFFSET(a);\n    int ob = OFFSET(b);\n\n    temp[a + oa] = gi[a];\n    temp[b + ob] = gi[b];\n\n    int offset = 1;\n    for (int d = N >> 1; d > 0; d >>= 1)\n    {\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        ai += OFFSET(ai);\n        bi += OFFSET(bi);\n        temp[bi] += temp[ai];\n      }\n      offset *= 2;\n    }\n\n    if (thid == 0) temp[N-1+OFFSET(N-1)] = 0; \n\n    for (int d = 1; d < N; d *= 2) \n\n    {\n      offset >>= 1;\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        ai += OFFSET(ai);\n        bi += OFFSET(bi);\n        T t = temp[ai];\n        temp[ai] = temp[bi];\n        temp[bi] += t;\n      }\n    }\n    __syncthreads(); \n\n\n    go[a] = temp[a + oa];\n    go[b] = temp[b + ob];\n  }\n}\n\ntemplate<typename T, int N>\nvoid scan (\n        sycl::nd_item<1> &item,\n        T *temp,\n  const int64_t nblocks,\n        T *__restrict g_odata,\n  const T *__restrict g_idata)\n{\n  for (int64_t bid = item.get_group(0); bid < nblocks; bid += item.get_group_range(0))\n  {\n    auto gi = g_idata + bid * N;\n    auto go = g_odata + bid * N;\n\n    int thid = item.get_local_id(0);\n    int offset = 1;\n    temp[2*thid]   = gi[2*thid];\n    temp[2*thid+1] = gi[2*thid+1];\n    for (int d = N >> 1; d > 0; d >>= 1)\n    {\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        temp[bi] += temp[ai];\n      }\n      offset *= 2;\n    }\n\n    if (thid == 0) temp[N-1] = 0; \n\n    for (int d = 1; d < N; d *= 2) \n\n    {\n      offset >>= 1;\n      __syncthreads();\n      if (thid < d)\n      {\n        int ai = offset*(2*thid+1)-1;\n        int bi = offset*(2*thid+2)-1;\n        T t = temp[ai];\n        temp[ai] = temp[bi];\n        temp[bi] += t;\n      }\n    }\n    go[2*thid] = temp[2*thid];\n    go[2*thid+1] = temp[2*thid+1];\n  }\n}\n\n\ntemplate <typename T, int N>\nvoid runTest (sycl::queue &q, const int64_t n, const int repeat, bool timing = false)\n{\n  int64_t num_blocks = (n + N - 1) / N;\n\n  int64_t nelems = num_blocks * N; \n\n\n  int64_t bytes = nelems * sizeof(T);\n\n  T *in = (T*) malloc (bytes);\n  T *cpu_out = (T*) malloc (bytes);\n  T *gpu_out = (T*) malloc (bytes);\n\n  srand(123);\n  for (int64_t n = 0; n < nelems; n++) in[n] = rand() % 5 + 1;\n\n  T *t_in = in;\n  T *t_out = cpu_out;\n  for (int64_t n = 0; n < num_blocks; n++) {\n    t_out[0] = 0;\n    for (int i = 1; i < N; i++)\n      t_out[i] = t_out[i-1] + t_in[i-1];\n    t_out += N;\n    t_in += N;\n  }\n\n  T *d_in = sycl::malloc_device<T>(nelems, q);\n  q.memcpy(d_in, in, bytes);\n\n  T *d_out = sycl::malloc_device<T>(nelems, q);\n\n  int cu = q.get_device().get_info<sycl::info::device::max_compute_units>();\n\n  sycl::range<1> gws (16 * cu * N/2);\n  sycl::range<1> lws (N/2);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> temp (sycl::range<1>(N), cgh);\n      cgh.parallel_for<class base<T, N>>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        scan<T, N>(item, temp.get_pointer(), num_blocks, d_out, d_in);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  if (timing) {\n    printf(\"Element size in bytes is %zu. Average execution time of scan (w/  bank conflicts): %f (us)\\n\",\n           sizeof(T), (time * 1e-3f) / repeat);\n  }\n  q.memcpy(gpu_out, d_out, bytes).wait();\n  if (!timing) verify(cpu_out, gpu_out, nelems);\n\n  \n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> temp (sycl::range<1>(N*2), cgh);\n      cgh.parallel_for<class opt<T, N>>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        scan_bcao<T, N>(item, temp.get_pointer(), num_blocks, d_out, d_in);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  auto bcao_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  if (timing) {\n    printf(\"Element size in bytes is %zu. Average execution time of scan (w/o bank conflicts): %f (us). \",\n           sizeof(T), (bcao_time * 1e-3f) / repeat);\n    printf(\"Reduce the time by %.1f%%\\n\", (time - bcao_time) * 1.0 / time * 100);\n  }\n  q.memcpy(gpu_out, d_out, bytes).wait();\n  if (!timing) verify(cpu_out, gpu_out, nelems);\n\n  sycl::free(d_in, q);\n  sycl::free(d_out, q);\n  free(in);\n  free(cpu_out);\n  free(gpu_out);\n}\n\ntemplate<int N>\nvoid run (sycl::queue &q, const int64_t n, const int repeat) {\n  for (int i = 0; i < 2; i++) {\n    bool report_timing = i > 0;\n    printf(\"\\nThe number of elements to scan in a thread block: %d\\n\", N);\n    runTest< char, N>(q, n, repeat, report_timing);\n    runTest<short, N>(q, n, repeat, report_timing);\n    runTest<  int, N>(q, n, repeat, report_timing);\n    runTest< long, N>(q, n, repeat, report_timing);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int64_t n = atol(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  run< 128>(q, n, repeat);\n  run< 256>(q, n, repeat);\n  run< 512>(q, n, repeat);\n  run<1024>(q, n, repeat);\n  run<2048>(q, n, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "scan2", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <chrono>\n#include <cuda.h>\n#include \"scan.h\"\n\n\n\n\n__global__\nvoid blockAddition(const float*__restrict__ input,\n                         float*__restrict__ output)\n{  \n  int bid = blockIdx.x;\n  int tid = threadIdx.x;\n  int gid = bid * blockDim.x + tid;\n\n  __shared__ float value;\n\n  \n\n  if(tid == 0)\n  {\n    value = input[bid];\n  }\n  __syncthreads();\n\n  output[gid] += value;\n}\n\n__global__\nvoid ScanLargeArrays(float *__restrict__ output,\n                     const float *__restrict__ input,\n                     const unsigned int block_size,   \n\n                     float *__restrict__ sumBuffer)  \n\n{\n  extern __shared__ float block[];   \n\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n  int gid = bid * blockDim.x + tid;\n\n  \n\n  block[2*tid]     = input[2*gid];\n  block[2*tid + 1] = input[2*gid + 1];\n  __syncthreads();\n\n  float cache0 = block[0];\n  float cache1 = cache0 + block[1];\n\n  \n\n  for(int stride = 1; stride < block_size; stride *=2)\n  {\n    if(2*tid>=stride)\n    {\n      cache0 = block[2*tid-stride]+block[2*tid];\n      cache1 = block[2*tid+1-stride]+block[2*tid+1];\n    }\n    __syncthreads();\n\n    block[2*tid] = cache0;\n    block[2*tid+1] = cache1;\n\n    __syncthreads();\n  }\n\n  \n   \n  sumBuffer[bid] = block[block_size-1];\n\n  \n\n  if(tid==0)\n  {\n    output[2*gid]     = 0;\n    output[2*gid+1]   = block[2*tid];\n  }\n  else\n  {\n    output[2*gid]     = block[2*tid-1];\n    output[2*gid + 1] = block[2*tid];\n  }\n}\n\n__global__ \nvoid prefixSum(float *__restrict__ output, \n               const float *__restrict__ input,\n               const unsigned int block_size)\n{\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n  int gid = bid * blockDim.x + tid;\n\n  extern __shared__ float block[];\n\n  \n\n  block[2*tid]     = input[2*gid];\n  block[2*tid + 1] = input[2*gid + 1];\n  __syncthreads();\n\n  float cache0 = block[0];\n  float cache1 = cache0 + block[1];\n\n  \n\n  for(int stride = 1; stride < block_size; stride *=2)\n  {\n\n    if(2*tid>=stride)\n    {\n      cache0 = block[2*tid-stride]+block[2*tid];\n      cache1 = block[2*tid+1-stride]+block[2*tid+1];\n    }\n    __syncthreads();\n\n    block[2*tid] = cache0;\n    block[2*tid+1] = cache1;\n\n    __syncthreads();\n  }\n\n  \n\n  if(tid==0)\n  {\n    output[2*gid]     = 0;\n    output[2*gid+1]   = block[2*tid];\n  }\n  else\n  {\n    output[2*gid]     = block[2*tid-1];\n    output[2*gid + 1] = block[2*tid];\n  }\n}\n\nvoid bScan(const unsigned int blockSize,\n           const unsigned int len,\n           const float *inputBuffer,\n           float *outputBuffer,\n           float *blockSumBuffer)\n{\n  \n\n  dim3 grid (len / blockSize);\n  dim3 block (blockSize / 2);\n\n  ScanLargeArrays<<<grid, block, sizeof(float)*blockSize>>>(\n      outputBuffer, inputBuffer, blockSize, blockSumBuffer);\n}\n\nvoid pScan(const unsigned int blockSize,\n           const unsigned int len,\n           const float *inputBuffer,\n           float *outputBuffer)\n{\n  dim3 grid (1);\n  dim3 block (len / 2);\n  prefixSum<<<grid, block, (len+1)*sizeof(float)>>>(outputBuffer, inputBuffer, blockSize);\n}\n\nvoid bAddition(const unsigned int blockSize,\n    const unsigned int len,\n    float *inputBuffer,\n    float *outputBuffer)\n{\n  \n\n  dim3 grid (len / blockSize);\n  dim3 block (blockSize);\n  blockAddition<<<grid, block>>>(inputBuffer, outputBuffer);\n}\n\n\n\n\nvoid scanLargeArraysCPUReference(\n    float * output,\n    float * input,\n    const unsigned int length)\n{\n  output[0] = 0;\n\n  for(unsigned int i = 1; i < length; ++i)\n  {\n    output[i] = input[i-1] + output[i-1];\n  }\n}\n\n\nint main(int argc, char * argv[])\n{\n  if (argc != 4) {\n    std::cout << \"Usage: \" << argv[0] << \" <repeat> <input length> <block size>\\n\";\n    return 1;\n  }\n  int iterations = atoi(argv[1]);\n  int length = atoi(argv[2]);\n  int blockSize = atoi(argv[3]);\n\n  if(iterations < 1)\n  {\n    std::cout << \"Error, iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n  if(!isPowerOf2(length))\n  {\n    length = roundToPowerOf2(length);\n  }\n\n  if((length/blockSize>GROUP_SIZE)&&(((length)&(length-1))!=0))\n  {\n    std::cout << \"Invalid length: \" << length << std::endl;\n    return -1;\n  }\n\n  \n\n  unsigned int sizeBytes = length * sizeof(float);\n\n  float* input = (float*) malloc (sizeBytes);\n\n  \n\n  float* output = (float*) malloc (sizeBytes);\n\n  \n\n  fillRandom<float>(input, length, 1, 0, 255);\n\n  blockSize = (blockSize < length/2) ? blockSize : length/2;\n\n  \n\n  float t = std::log((float)length) / std::log((float)blockSize);\n  unsigned int pass = (unsigned int)t;\n\n  \n\n  if(std::fabs(t - (float)pass) < 1e-7)\n  {\n    pass--;\n  }\n\n  \n\n  float* inputBuffer; \n  cudaMalloc((void**)&inputBuffer, sizeBytes);\n  cudaMemcpy(inputBuffer, input, sizeBytes, cudaMemcpyHostToDevice);\n\n  \n\n  std::vector<float*> outputBuffers(pass);\n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    int size = (int)(length / std::pow((float)blockSize,(float)i));\n    float* outputBuffer; \n    cudaMalloc((void**)&outputBuffer, size * sizeof(float));\n    outputBuffers[i] = outputBuffer;\n  }\n\n  \n\n  std::vector<float*> blockSumBuffers(pass);\n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    int size = (int)(length / std::pow((float)blockSize,(float)(i + 1)));\n    float* sum; \n    cudaMalloc((void**)&sum, size * sizeof(float));\n    blockSumBuffers[i] = sum;\n  }\n\n  \n\n  int tempLength = (int)(length / std::pow((float)blockSize, (float)pass));\n\n  float* tempBuffer; \n  cudaMalloc((void**)&tempBuffer, tempLength * sizeof(float));\n\n  std::cout << \"Executing kernel for \" << iterations << \" iterations\\n\";\n  std::cout << \"-------------------------------------------\\n\";\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    \n\n    bScan(blockSize, length, inputBuffer, outputBuffers[0], blockSumBuffers[0]);\n\n    for(int i = 1; i < (int)pass; i++)\n    {\n      int size = (int)(length / std::pow((float)blockSize,(float)i));\n      bScan(blockSize, size, blockSumBuffers[i - 1], outputBuffers[i], blockSumBuffers[i]);\n    }\n\n    \n\n    pScan(blockSize, tempLength, blockSumBuffers[pass - 1], tempBuffer);\n\n    \n\n    bAddition(blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(pass - 1))),\n        tempBuffer, outputBuffers[pass - 1]);\n\n    for(int i = pass - 1; i > 0; i--)\n    {\n      bAddition(blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(i - 1))),\n          outputBuffers[i], outputBuffers[i - 1]);\n    }\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of scan kernels: \" << time * 1e-3f / iterations\n            << \" (us)\\n\";\n\n  cudaMemcpy(output, outputBuffers[0], sizeBytes, cudaMemcpyDeviceToHost);\n\n  cudaFree(inputBuffer); \n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    cudaFree(outputBuffers[i]);\n    cudaFree(blockSumBuffers[i]);\n  }\n\n  cudaFree(tempBuffer);\n\n  \n\n  float* verificationOutput = (float*)malloc(sizeBytes);\n  memset(verificationOutput, 0, sizeBytes);\n\n  \n\n  scanLargeArraysCPUReference(verificationOutput, input, length);\n\n  \n\n  if (compare<float>(output, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  free(input);\n  free(output);\n  free(verificationOutput);\n  return 0;\n}\n"}}
{"kernel_name": "scan2", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"scan.h\"\n\n\n\n\n__global__\nvoid blockAddition(const float*__restrict__ input,\n                         float*__restrict__ output)\n{  \n  int bid = blockIdx.x;\n  int tid = threadIdx.x;\n  int gid = bid * blockDim.x + tid;\n\n  __shared__ float value;\n\n  \n\n  if(tid == 0)\n  {\n    value = input[bid];\n  }\n  __syncthreads();\n\n  output[gid] += value;\n}\n\n__global__\nvoid ScanLargeArrays(float *__restrict__ output,\n                     const float *__restrict__ input,\n                     const unsigned int block_size,   \n\n                     float *__restrict__ sumBuffer)  \n\n{\n  extern __shared__ float block[];   \n\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n  int gid = bid * blockDim.x + tid;\n\n  \n\n  block[2*tid]     = input[2*gid];\n  block[2*tid + 1] = input[2*gid + 1];\n  __syncthreads();\n\n  float cache0 = block[0];\n  float cache1 = cache0 + block[1];\n\n  \n\n  for(int stride = 1; stride < block_size; stride *=2)\n  {\n    if(2*tid>=stride)\n    {\n      cache0 = block[2*tid-stride]+block[2*tid];\n      cache1 = block[2*tid+1-stride]+block[2*tid+1];\n    }\n    __syncthreads();\n\n    block[2*tid] = cache0;\n    block[2*tid+1] = cache1;\n\n    __syncthreads();\n  }\n\n  \n   \n  sumBuffer[bid] = block[block_size-1];\n\n  \n\n  if(tid==0)\n  {\n    output[2*gid]     = 0;\n    output[2*gid+1]   = block[2*tid];\n  }\n  else\n  {\n    output[2*gid]     = block[2*tid-1];\n    output[2*gid + 1] = block[2*tid];\n  }\n}\n\n__global__ \nvoid prefixSum(float *__restrict__ output, \n               const float *__restrict__ input,\n               const unsigned int block_size)\n{\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n  int gid = bid * blockDim.x + tid;\n\n  extern __shared__ float block[];\n\n  \n\n  block[2*tid]     = input[2*gid];\n  block[2*tid + 1] = input[2*gid + 1];\n  __syncthreads();\n\n  float cache0 = block[0];\n  float cache1 = cache0 + block[1];\n\n  \n\n  for(int stride = 1; stride < block_size; stride *=2)\n  {\n\n    if(2*tid>=stride)\n    {\n      cache0 = block[2*tid-stride]+block[2*tid];\n      cache1 = block[2*tid+1-stride]+block[2*tid+1];\n    }\n    __syncthreads();\n\n    block[2*tid] = cache0;\n    block[2*tid+1] = cache1;\n\n    __syncthreads();\n  }\n\n  \n\n  if(tid==0)\n  {\n    output[2*gid]     = 0;\n    output[2*gid+1]   = block[2*tid];\n  }\n  else\n  {\n    output[2*gid]     = block[2*tid-1];\n    output[2*gid + 1] = block[2*tid];\n  }\n}\n\nvoid bScan(const unsigned int blockSize,\n           const unsigned int len,\n           const float *inputBuffer,\n           float *outputBuffer,\n           float *blockSumBuffer)\n{\n  \n\n  dim3 grid (len / blockSize);\n  dim3 block (blockSize / 2);\n\n  ScanLargeArrays<<<grid, block, sizeof(float)*blockSize>>>(\n      outputBuffer, inputBuffer, blockSize, blockSumBuffer);\n}\n\nvoid pScan(const unsigned int blockSize,\n           const unsigned int len,\n           const float *inputBuffer,\n           float *outputBuffer)\n{\n  dim3 grid (1);\n  dim3 block (len / 2);\n  hipLaunchKernelGGL(prefixSum, grid, block, (len+1)*sizeof(float), 0, outputBuffer, inputBuffer, blockSize);\n}\n\nvoid bAddition(const unsigned int blockSize,\n    const unsigned int len,\n    float *inputBuffer,\n    float *outputBuffer)\n{\n  \n\n  dim3 grid (len / blockSize);\n  dim3 block (blockSize);\n  hipLaunchKernelGGL(blockAddition, grid, block, 0, 0, inputBuffer, outputBuffer);\n}\n\n\n\n\nvoid scanLargeArraysCPUReference(\n    float * output,\n    float * input,\n    const unsigned int length)\n{\n  output[0] = 0;\n\n  for(unsigned int i = 1; i < length; ++i)\n  {\n    output[i] = input[i-1] + output[i-1];\n  }\n}\n\n\nint main(int argc, char * argv[])\n{\n  if (argc != 4) {\n    std::cout << \"Usage: \" << argv[0] << \" <repeat> <input length> <block size>\\n\";\n    return 1;\n  }\n  int iterations = atoi(argv[1]);\n  int length = atoi(argv[2]);\n  int blockSize = atoi(argv[3]);\n\n  if(iterations < 1)\n  {\n    std::cout << \"Error, iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n  if(!isPowerOf2(length))\n  {\n    length = roundToPowerOf2(length);\n  }\n\n  if((length/blockSize>GROUP_SIZE)&&(((length)&(length-1))!=0))\n  {\n    std::cout << \"Invalid length: \" << length << std::endl;\n    return -1;\n  }\n\n  \n\n  unsigned int sizeBytes = length * sizeof(float);\n\n  float* input = (float*) malloc (sizeBytes);\n\n  \n\n  float* output = (float*) malloc (sizeBytes);\n\n  \n\n  fillRandom<float>(input, length, 1, 0, 255);\n\n  blockSize = (blockSize < length/2) ? blockSize : length/2;\n\n  \n\n  float t = std::log((float)length) / std::log((float)blockSize);\n  unsigned int pass = (unsigned int)t;\n\n  \n\n  if(std::fabs(t - (float)pass) < 1e-7)\n  {\n    pass--;\n  }\n\n  \n\n  float* inputBuffer; \n  hipMalloc((void**)&inputBuffer, sizeBytes);\n  hipMemcpy(inputBuffer, input, sizeBytes, hipMemcpyHostToDevice);\n\n  \n\n  std::vector<float*> outputBuffers(pass);\n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    int size = (int)(length / std::pow((float)blockSize,(float)i));\n    float* outputBuffer; \n    hipMalloc((void**)&outputBuffer, size * sizeof(float));\n    outputBuffers[i] = outputBuffer;\n  }\n\n  \n\n  std::vector<float*> blockSumBuffers(pass);\n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    int size = (int)(length / std::pow((float)blockSize,(float)(i + 1)));\n    float* sum; \n    hipMalloc((void**)&sum, size * sizeof(float));\n    blockSumBuffers[i] = sum;\n  }\n\n  \n\n  int tempLength = (int)(length / std::pow((float)blockSize, (float)pass));\n\n  float* tempBuffer; \n  hipMalloc((void**)&tempBuffer, tempLength * sizeof(float));\n\n  std::cout << \"Executing kernel for \" << iterations << \" iterations\\n\";\n  std::cout << \"-------------------------------------------\\n\";\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    \n\n    bScan(blockSize, length, inputBuffer, outputBuffers[0], blockSumBuffers[0]);\n\n    for(int i = 1; i < (int)pass; i++)\n    {\n      int size = (int)(length / std::pow((float)blockSize,(float)i));\n      bScan(blockSize, size, blockSumBuffers[i - 1], outputBuffers[i], blockSumBuffers[i]);\n    }\n\n    \n\n    pScan(blockSize, tempLength, blockSumBuffers[pass - 1], tempBuffer);\n\n    \n\n    bAddition(blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(pass - 1))),\n        tempBuffer, outputBuffers[pass - 1]);\n\n    for(int i = pass - 1; i > 0; i--)\n    {\n      bAddition(blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(i - 1))),\n          outputBuffers[i], outputBuffers[i - 1]);\n    }\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of scan kernels: \" << time * 1e-3f / iterations\n            << \" (us)\\n\";\n\n  hipMemcpy(output, outputBuffers[0], sizeBytes, hipMemcpyDeviceToHost);\n\n  hipFree(inputBuffer); \n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    hipFree(outputBuffers[i]);\n    hipFree(blockSumBuffers[i]);\n  }\n\n  hipFree(tempBuffer);\n\n  \n\n  float* verificationOutput = (float*)malloc(sizeBytes);\n  memset(verificationOutput, 0, sizeBytes);\n\n  \n\n  scanLargeArraysCPUReference(verificationOutput, input, length);\n\n  \n\n  if (compare<float>(output, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  free(input);\n  free(output);\n  free(verificationOutput);\n  return 0;\n}\n"}}
{"kernel_name": "scan2", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <chrono>\n#include <omp.h>\n#include \"scan.h\"\n\nvoid bScan(const unsigned int blockSize,\n           const unsigned int len,\n           const float *input,\n           float *output,\n           float *sumBuffer)\n{\n  #pragma omp target teams num_teams(len/blockSize) thread_limit(blockSize/2)\n  {\n    float block[256];\n    #pragma omp parallel \n    {\n      int tid = omp_get_thread_num();\n      int bid = omp_get_team_num();\n      int gid = bid * blockSize/2 + tid;\n      \n      \n\n      block[2*tid]     = input[2*gid];\n      block[2*tid + 1] = input[2*gid + 1];\n      #pragma omp barrier\n      \n      float cache0 = block[0];\n      float cache1 = cache0 + block[1];\n      \n      \n\n      for(int stride = 1; stride < blockSize; stride *=2) {\n        if(2*tid>=stride) {\n          cache0 = block[2*tid-stride]+block[2*tid];\n          cache1 = block[2*tid+1-stride]+block[2*tid+1];\n        }\n        #pragma omp barrier\n      \n        block[2*tid] = cache0;\n        block[2*tid+1] = cache1;\n      \n        #pragma omp barrier\n      }\n      \n      \n   \n      sumBuffer[bid] = block[blockSize-1];\n      \n      \n\n      if(tid==0) {\n        output[2*gid]     = 0;\n        output[2*gid+1]   = block[2*tid];\n      } else {\n        output[2*gid]     = block[2*tid-1];\n        output[2*gid + 1] = block[2*tid];\n      }\n    }\n  }\n}\n\nvoid pScan(const unsigned int blockSize,\n           const unsigned int len,\n           const float *input,\n           float *output)\n{\n  #pragma omp target teams num_teams(1) thread_limit(len/2)\n  {\n    \n\n    float block[4];\n    #pragma omp parallel \n    {\n      int tid = omp_get_thread_num();\n      int bid = omp_get_team_num();\n      int gid = bid * len/2 + tid;\n\n      \n\n      block[2*tid]     = input[2*gid];\n      block[2*tid + 1] = input[2*gid + 1];\n      #pragma omp barrier\n\n      float cache0 = block[0];\n      float cache1 = cache0 + block[1];\n\n      \n\n      for(int stride = 1; stride < blockSize; stride *=2) {\n\n        if(2*tid>=stride) {\n          cache0 = block[2*tid-stride]+block[2*tid];\n          cache1 = block[2*tid+1-stride]+block[2*tid+1];\n        }\n        #pragma omp barrier\n\n        block[2*tid] = cache0;\n        block[2*tid+1] = cache1;\n\n        #pragma omp barrier\n      }\n\n      \n\n      if(tid==0) {\n        output[2*gid]     = 0;\n        output[2*gid+1]   = block[2*tid];\n      } else {\n        output[2*gid]     = block[2*tid-1];\n        output[2*gid + 1] = block[2*tid];\n      }\n    }\n  }\n}\n\nvoid bAddition(const unsigned int blockSize,\n               const unsigned int len,\n               const float *input,\n               float *output)\n{\n  #pragma omp target teams num_teams(len/blockSize) thread_limit(blockSize)\n  {\n    float value;\n    #pragma omp parallel \n    {\n      int tid = omp_get_thread_num();\n      int bid = omp_get_team_num();\n      int gid = bid * blockSize + tid;\n      \n\n      if(tid == 0) value = input[bid];\n      #pragma omp barrier\n\n      output[gid] += value;\n    }\n  }\n}\n\n\n\n\nvoid scanLargeArraysCPUReference(\n    float * output,\n    float * input,\n    const unsigned int length)\n{\n  output[0] = 0;\n\n  for(unsigned int i = 1; i < length; ++i)\n  {\n    output[i] = input[i-1] + output[i-1];\n  }\n}\n\n\nint main(int argc, char * argv[])\n{\n  if (argc != 4) {\n    std::cout << \"Usage: \" << argv[0] << \" <repeat> <input length> <block size>\\n\";\n    return 1;\n  }\n  int iterations = atoi(argv[1]);\n  int length = atoi(argv[2]);\n  int blockSize = atoi(argv[3]);\n\n  if(iterations < 1)\n  {\n    std::cout << \"Error, iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n  if(!isPowerOf2(length))\n  {\n    length = roundToPowerOf2(length);\n  }\n\n  if((length/blockSize>GROUP_SIZE)&&(((length)&(length-1))!=0))\n  {\n    std::cout << \"Invalid length: \" << length << std::endl;\n    return -1;\n  }\n\n  \n\n  unsigned int sizeBytes = length * sizeof(float);\n\n  float* inputBuffer = (float*) malloc (sizeBytes);\n\n  \n\n  fillRandom<float>(inputBuffer, length, 1, 0, 255);\n\n  blockSize = (blockSize < length/2) ? blockSize : length/2;\n\n  \n\n  float t = std::log((float)length) / std::log((float)blockSize);\n  unsigned int pass = (unsigned int)t;\n\n  \n\n  if(std::fabs(t - (float)pass) < 1e-7)\n  {\n    pass--;\n  }\n  \n  \n\n  int outputBufferSize = 0;\n  int* outputBufferSizeOffset = (int*) malloc (sizeof(int) * pass);\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    outputBufferSizeOffset[i] = outputBufferSize;\n    outputBufferSize += (int)(length / std::pow((float)blockSize,(float)i));\n  }\n\n  float* outputBuffer = (float*) malloc (sizeof(float) * outputBufferSize);\n\n  \n\n  int blockSumBufferSize = 0;\n  int* blockSumBufferSizeOffset = (int*) malloc (sizeof(int) * pass);\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    blockSumBufferSizeOffset[i] = blockSumBufferSize;\n    blockSumBufferSize += (int)(length / std::pow((float)blockSize,(float)(i + 1)));\n  }\n  float* blockSumBuffer = (float*) malloc (sizeof(float) * blockSumBufferSize);\n\n  \n\n  int tempLength = (int)(length / std::pow((float)blockSize, (float)pass));\n  float* tempBuffer = (float*) malloc (sizeof(float) * tempLength);\n\n  std::cout << \"Executing kernel for \" << iterations << \" iterations\\n\";\n  std::cout << \"-------------------------------------------\\n\";\n\n#pragma omp target data map(to: inputBuffer[0:length]) \\\n                        map(alloc: tempBuffer[0:tempLength], \\\n                                   blockSumBuffer[0:blockSumBufferSize], \\\n                                   outputBuffer[0:outputBufferSize])\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    \n\n    bScan(blockSize, length, inputBuffer, \n          outputBuffer + outputBufferSizeOffset[0], \n          blockSumBuffer + blockSumBufferSizeOffset[0]);\n\n    for(int i = 1; i < (int)pass; i++)\n    {\n      int size = (int)(length / std::pow((float)blockSize,(float)i));\n      bScan(blockSize, size, blockSumBuffer + blockSumBufferSizeOffset[i - 1], \n            outputBuffer + outputBufferSizeOffset[i], \n            blockSumBuffer + blockSumBufferSizeOffset[i]);\n    }\n\n    \n\n    pScan(blockSize, tempLength, \n          blockSumBuffer + blockSumBufferSizeOffset[pass - 1], tempBuffer);\n\n    \n\n    bAddition(blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(pass - 1))),\n          tempBuffer, \n          outputBuffer + outputBufferSizeOffset[pass - 1]);\n\n    for(int i = pass - 1; i > 0; i--)\n    {\n      bAddition(blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(i - 1))),\n            outputBuffer + outputBufferSizeOffset[i], \n            outputBuffer + outputBufferSizeOffset[i - 1]);\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of scan kernels: \" << time * 1e-3f / iterations\n            << \" (us)\\n\";\n\n  #pragma omp target update from (outputBuffer[0: \\\n     (pass==1) ? outputBufferSize : outputBufferSizeOffset[1]])\n}\n\n  \n\n  float* verificationOutput = (float*)malloc(sizeBytes);\n  memset(verificationOutput, 0, sizeBytes);\n\n  \n\n  scanLargeArraysCPUReference(verificationOutput, inputBuffer, length);\n\n  \n\n  if (compare<float>(outputBuffer, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  free(verificationOutput);\n  free(inputBuffer);\n  free(tempBuffer);\n  free(blockSumBuffer);\n  free(blockSumBufferSizeOffset);\n  free(outputBuffer);\n  free(outputBufferSizeOffset);\n  return 0;\n}\n"}}
{"kernel_name": "scan2", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <chrono>\n#include \"scan.h\"\n\nvoid bScan(const unsigned int blockSize,\n           const unsigned int len,\n           const float *input,\n           float *output,\n           float *sumBuffer)\n{\n    {\n    float block[256];\n        {\n      int tid = omp_get_thread_num();\n      int bid = omp_get_team_num();\n      int gid = bid * blockSize/2 + tid;\n      \n      \n\n      block[2*tid]     = input[2*gid];\n      block[2*tid + 1] = input[2*gid + 1];\n            \n      float cache0 = block[0];\n      float cache1 = cache0 + block[1];\n      \n      \n\n      for(int stride = 1; stride < blockSize; stride *=2) {\n        if(2*tid>=stride) {\n          cache0 = block[2*tid-stride]+block[2*tid];\n          cache1 = block[2*tid+1-stride]+block[2*tid+1];\n        }\n              \n        block[2*tid] = cache0;\n        block[2*tid+1] = cache1;\n      \n              }\n      \n      \n   \n      sumBuffer[bid] = block[blockSize-1];\n      \n      \n\n      if(tid==0) {\n        output[2*gid]     = 0;\n        output[2*gid+1]   = block[2*tid];\n      } else {\n        output[2*gid]     = block[2*tid-1];\n        output[2*gid + 1] = block[2*tid];\n      }\n    }\n  }\n}\n\nvoid pScan(const unsigned int blockSize,\n           const unsigned int len,\n           const float *input,\n           float *output)\n{\n    {\n    \n\n    float block[4];\n        {\n      int tid = omp_get_thread_num();\n      int bid = omp_get_team_num();\n      int gid = bid * len/2 + tid;\n\n      \n\n      block[2*tid]     = input[2*gid];\n      block[2*tid + 1] = input[2*gid + 1];\n      \n      float cache0 = block[0];\n      float cache1 = cache0 + block[1];\n\n      \n\n      for(int stride = 1; stride < blockSize; stride *=2) {\n\n        if(2*tid>=stride) {\n          cache0 = block[2*tid-stride]+block[2*tid];\n          cache1 = block[2*tid+1-stride]+block[2*tid+1];\n        }\n        \n        block[2*tid] = cache0;\n        block[2*tid+1] = cache1;\n\n              }\n\n      \n\n      if(tid==0) {\n        output[2*gid]     = 0;\n        output[2*gid+1]   = block[2*tid];\n      } else {\n        output[2*gid]     = block[2*tid-1];\n        output[2*gid + 1] = block[2*tid];\n      }\n    }\n  }\n}\n\nvoid bAddition(const unsigned int blockSize,\n               const unsigned int len,\n               const float *input,\n               float *output)\n{\n    {\n    float value;\n        {\n      int tid = omp_get_thread_num();\n      int bid = omp_get_team_num();\n      int gid = bid * blockSize + tid;\n      \n\n      if(tid == 0) value = input[bid];\n      \n      output[gid] += value;\n    }\n  }\n}\n\n\n\n\nvoid scanLargeArraysCPUReference(\n    float * output,\n    float * input,\n    const unsigned int length)\n{\n  output[0] = 0;\n\n  for(unsigned int i = 1; i < length; ++i)\n  {\n    output[i] = input[i-1] + output[i-1];\n  }\n}\n\n\nint main(int argc, char * argv[])\n{\n  if (argc != 4) {\n    std::cout << \"Usage: \" << argv[0] << \" <repeat> <input length> <block size>\\n\";\n    return 1;\n  }\n  int iterations = atoi(argv[1]);\n  int length = atoi(argv[2]);\n  int blockSize = atoi(argv[3]);\n\n  if(iterations < 1)\n  {\n    std::cout << \"Error, iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n  if(!isPowerOf2(length))\n  {\n    length = roundToPowerOf2(length);\n  }\n\n  if((length/blockSize>GROUP_SIZE)&&(((length)&(length-1))!=0))\n  {\n    std::cout << \"Invalid length: \" << length << std::endl;\n    return -1;\n  }\n\n  \n\n  unsigned int sizeBytes = length * sizeof(float);\n\n  float* inputBuffer = (float*) malloc (sizeBytes);\n\n  \n\n  fillRandom<float>(inputBuffer, length, 1, 0, 255);\n\n  blockSize = (blockSize < length/2) ? blockSize : length/2;\n\n  \n\n  float t = std::log((float)length) / std::log((float)blockSize);\n  unsigned int pass = (unsigned int)t;\n\n  \n\n  if(std::fabs(t - (float)pass) < 1e-7)\n  {\n    pass--;\n  }\n  \n  \n\n  int outputBufferSize = 0;\n  int* outputBufferSizeOffset = (int*) malloc (sizeof(int) * pass);\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    outputBufferSizeOffset[i] = outputBufferSize;\n    outputBufferSize += (int)(length / std::pow((float)blockSize,(float)i));\n  }\n\n  float* outputBuffer = (float*) malloc (sizeof(float) * outputBufferSize);\n\n  \n\n  int blockSumBufferSize = 0;\n  int* blockSumBufferSizeOffset = (int*) malloc (sizeof(int) * pass);\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    blockSumBufferSizeOffset[i] = blockSumBufferSize;\n    blockSumBufferSize += (int)(length / std::pow((float)blockSize,(float)(i + 1)));\n  }\n  float* blockSumBuffer = (float*) malloc (sizeof(float) * blockSumBufferSize);\n\n  \n\n  int tempLength = (int)(length / std::pow((float)blockSize, (float)pass));\n  float* tempBuffer = (float*) malloc (sizeof(float) * tempLength);\n\n  std::cout << \"Executing kernel for \" << iterations << \" iterations\\n\";\n  std::cout << \"-------------------------------------------\\n\";\n\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    \n\n    bScan(blockSize, length, inputBuffer, \n          outputBuffer + outputBufferSizeOffset[0], \n          blockSumBuffer + blockSumBufferSizeOffset[0]);\n\n    for(int i = 1; i < (int)pass; i++)\n    {\n      int size = (int)(length / std::pow((float)blockSize,(float)i));\n      bScan(blockSize, size, blockSumBuffer + blockSumBufferSizeOffset[i - 1], \n            outputBuffer + outputBufferSizeOffset[i], \n            blockSumBuffer + blockSumBufferSizeOffset[i]);\n    }\n\n    \n\n    pScan(blockSize, tempLength, \n          blockSumBuffer + blockSumBufferSizeOffset[pass - 1], tempBuffer);\n\n    \n\n    bAddition(blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(pass - 1))),\n          tempBuffer, \n          outputBuffer + outputBufferSizeOffset[pass - 1]);\n\n    for(int i = pass - 1; i > 0; i--)\n    {\n      bAddition(blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(i - 1))),\n            outputBuffer + outputBufferSizeOffset[i], \n            outputBuffer + outputBufferSizeOffset[i - 1]);\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of scan kernels: \" << time * 1e-3f / iterations\n            << \" (us)\\n\";\n\n  }\n\n  \n\n  float* verificationOutput = (float*)malloc(sizeBytes);\n  memset(verificationOutput, 0, sizeBytes);\n\n  \n\n  scanLargeArraysCPUReference(verificationOutput, inputBuffer, length);\n\n  \n\n  if (compare<float>(outputBuffer, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  free(verificationOutput);\n  free(inputBuffer);\n  free(tempBuffer);\n  free(blockSumBuffer);\n  free(blockSumBufferSizeOffset);\n  free(outputBuffer);\n  free(outputBufferSizeOffset);\n  return 0;\n}"}}
{"kernel_name": "scan2", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"scan.h\"\n\nvoid bScan(sycl::queue &q,\n           const unsigned int blockSize,\n           const unsigned int len,\n           float *input,\n           float *output,\n           float *blockSum)\n{\n  \n\n  sycl::range<1> gws (len / 2);\n  sycl::range<1> lws (blockSize / 2);\n\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<float, 1> block(sycl::range<1>(blockSize), cgh);\n    cgh.parallel_for<class lock_scan>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n\n      int tid = item.get_local_id(0);\n      int gid = item.get_global_id(0);\n      int bid = item.get_group(0);\n\n      \n\n      block[2*tid]     = input[2*gid];\n      block[2*tid + 1] = input[2*gid + 1];\n      item.barrier(sycl::access::fence_space::local_space);\n\n      float cache0 = block[0];\n      float cache1 = cache0 + block[1];\n\n      \n\n      for(int stride = 1; stride < blockSize; stride *=2) {\n        if(2*tid>=stride) {\n          cache0 = block[2*tid-stride]+block[2*tid];\n          cache1 = block[2*tid+1-stride]+block[2*tid+1];\n        }\n        item.barrier(sycl::access::fence_space::local_space);\n\n        block[2*tid] = cache0;\n        block[2*tid+1] = cache1;\n\n        item.barrier(sycl::access::fence_space::local_space);\n      }\n\n      \n\n      blockSum[bid] = block[blockSize-1];\n\n      \n\n      if(tid==0) {\n        output[2*gid]     = 0;\n        output[2*gid+1]   = block[2*tid];\n      } else {\n        output[2*gid]     = block[2*tid-1];\n        output[2*gid + 1] = block[2*tid];\n      }\n    });\n  });\n}\n\nvoid pScan(sycl::queue &q,\n           const unsigned int blockSize,\n           const unsigned int len,\n           float *input,\n           float *output)\n{\n  sycl::range<1> gws (len / 2);\n  sycl::range<1> lws (len / 2);\n\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<float, 1> block(sycl::range<1>(len+1), cgh);\n    cgh.parallel_for<class partial_scan>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n\n      int tid = item.get_local_id(0);\n      int gid = item.get_global_id(0);\n      \n\n\n      \n\n      block[2*tid]     = input[2*gid];\n      block[2*tid + 1] = input[2*gid + 1];\n      item.barrier(sycl::access::fence_space::local_space);\n\n      float cache0 = block[0];\n      float cache1 = cache0 + block[1];\n\n      \n\n      for(int stride = 1; stride < blockSize; stride *=2) {\n\n        if(2*tid>=stride) {\n          cache0 = block[2*tid-stride]+block[2*tid];\n          cache1 = block[2*tid+1-stride]+block[2*tid+1];\n        }\n        item.barrier(sycl::access::fence_space::local_space);\n\n        block[2*tid] = cache0;\n        block[2*tid+1] = cache1;\n\n        item.barrier(sycl::access::fence_space::local_space);\n      }\n\n      \n\n      if(tid==0) {\n        output[2*gid]     = 0;\n        output[2*gid+1]   = block[2*tid];\n      } else {\n        output[2*gid]     = block[2*tid-1];\n        output[2*gid + 1] = block[2*tid];\n      }\n    });\n  });\n}\n\nvoid bAddition(sycl::queue &q,\n               const unsigned int blockSize,\n               const unsigned int len,\n               float *input,\n               float *output)\n{\n  \n\n  sycl::range<1> gws (len);\n  sycl::range<1> lws (blockSize);\n\n  \n\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<float, 0> value(cgh);\n    cgh.parallel_for<class block_add>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      int globalId = item.get_global_id(0);\n      int groupId = item.get_group(0);\n      int localId = item.get_local_id(0);\n\n      \n\n      if(localId == 0) value = input[groupId];\n      item.barrier(sycl::access::fence_space::local_space);\n\n      output[globalId] += value;\n    });\n  });\n}\n\n\n\n\nvoid scanLargeArraysCPUReference(\n    float * output,\n    float * input,\n    const unsigned int length)\n{\n  output[0] = 0;\n\n  for(unsigned int i = 1; i < length; ++i)\n  {\n    output[i] = input[i-1] + output[i-1];\n  }\n}\n\n\nint main(int argc, char * argv[])\n{\n  if (argc != 4) {\n    std::cout << \"Usage: \" << argv[0] << \" <repeat> <input length> <block size>\\n\";\n    return 1;\n  }\n  int iterations = atoi(argv[1]);\n  int length = atoi(argv[2]);\n  int blockSize = atoi(argv[3]);\n\n  if(iterations < 1)\n  {\n    std::cout << \"Error, iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n  if(!isPowerOf2(length))\n  {\n    length = roundToPowerOf2(length);\n  }\n\n  if((length/blockSize>GROUP_SIZE)&&(((length)&(length-1))!=0))\n  {\n    std::cout << \"Invalid length: \" << length << std::endl;\n    return -1;\n  }\n\n  \n\n  unsigned int sizeBytes = length * sizeof(float);\n\n  float* input = (float*) malloc (sizeBytes);\n\n  \n\n  float* output = (float*) malloc (sizeBytes);\n\n  \n\n  fillRandom<float>(input, length, 1, 0, 255);\n\n  blockSize = (blockSize < length/2) ? blockSize : length/2;\n\n  \n\n  float t = std::log((float)length) / std::log((float)blockSize);\n  unsigned int pass = (unsigned int)t;\n\n  \n\n  if(std::fabs(t - (float)pass) < 1e-7)\n  {\n    pass--;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  float *inputBuffer = sycl::malloc_device<float>(length, q);\n  q.memcpy(inputBuffer, input, sizeBytes);\n\n  \n\n  std::vector<float*> outputBuffers(pass);\n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    int size = (int)(length / std::pow((float)blockSize,(float)i));\n    outputBuffers[i] = sycl::malloc_device<float>(size, q);\n  }\n\n  \n\n  std::vector<float*> blockSumBuffers(pass);\n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    int size = (int)(length / std::pow((float)blockSize,(float)(i + 1)));\n    blockSumBuffers[i] = sycl::malloc_device<float>(size, q);\n  }\n\n  \n\n  int tempLength = (int)(length / std::pow((float)blockSize, (float)pass));\n\n  float *tempBuffer = sycl::malloc_device<float>(tempLength, q);\n\n  std::cout << \"Executing kernel for \" << iterations << \" iterations\\n\";\n  std::cout << \"-------------------------------------------\\n\";\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    \n\n    bScan(q, blockSize, length, inputBuffer, outputBuffers[0], blockSumBuffers[0]);\n\n    for(int i = 1; i < (int)pass; i++)\n    {\n      int size = (int)(length / std::pow((float)blockSize,(float)i));\n      bScan(q, blockSize, size, blockSumBuffers[i - 1], outputBuffers[i], blockSumBuffers[i]);\n    }\n\n    \n\n    pScan(q, blockSize, tempLength, blockSumBuffers[pass - 1], tempBuffer);\n\n    \n\n    bAddition(q, blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(pass - 1))),\n          tempBuffer, outputBuffers[pass - 1]);\n\n    for(int i = pass - 1; i > 0; i--)\n    {\n      bAddition(q, blockSize, (unsigned int)(length / std::pow((float)blockSize, (float)(i - 1))),\n            outputBuffers[i], outputBuffers[i - 1]);\n    }\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of scan kernels: \" << time * 1e-3f / iterations\n            << \" (us)\\n\";\n\n  q.memcpy(output, outputBuffers[0], sizeBytes).wait();\n\n  sycl::free(inputBuffer, q);\n\n  for(unsigned int i = 0; i < pass; i++)\n  {\n    sycl::free(outputBuffers[i], q);\n    sycl::free(blockSumBuffers[i], q);\n  }\n\n  sycl::free(tempBuffer, q);\n\n  \n\n  float* verificationOutput = (float*)malloc(sizeBytes);\n  memset(verificationOutput, 0, sizeBytes);\n\n  \n\n  scanLargeArraysCPUReference(verificationOutput, input, length);\n\n  \n\n  if (compare<float>(output, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  free(input);\n  free(output);\n  free(verificationOutput);\n  return 0;\n}\n"}}
