{"kernel_name": "ace", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n\n\n#define DATAXSIZE 400\n#define DATAYSIZE 400\n#define DATAZSIZE 400\n\ntypedef double nRarray[DATAYSIZE][DATAXSIZE];\n\n\n\n#define SQ(x) ((x)*(x))\n\n#ifdef VERIFY\n#include <string.h>\n#include \"reference.h\"\n#endif\n\n__device__\ndouble dFphi(double phi, double u, double lambda)\n{\n  return (-phi*(1.0-phi*phi)+lambda*u*(1.0-phi*phi)*(1.0-phi*phi));\n}\n\n__device__\ndouble GradientX(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x+1][y][z] - phi[x-1][y][z]) / (2.0*dx);\n}\n\n__device__\ndouble GradientY(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y+1][z] - phi[x][y-1][z]) / (2.0*dy);\n}\n\n__device__\ndouble GradientZ(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y][z+1] - phi[x][y][z-1]) / (2.0*dz);\n}\n\n__device__\ndouble Divergence(double phix[][DATAYSIZE][DATAXSIZE], \n                  double phiy[][DATAYSIZE][DATAXSIZE],\n                  double phiz[][DATAYSIZE][DATAXSIZE], \n                  double dx, double dy, double dz, int x, int y, int z)\n{\n  return GradientX(phix,dx,dy,dz,x,y,z) + \n         GradientY(phiy,dx,dy,dz,x,y,z) +\n         GradientZ(phiz,dx,dy,dz,x,y,z);\n}\n\n__device__\ndouble Laplacian(double phi[][DATAYSIZE][DATAXSIZE],\n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  double phixx = (phi[x+1][y][z] + phi[x-1][y][z] - 2.0 * phi[x][y][z]) / SQ(dx);\n  double phiyy = (phi[x][y+1][z] + phi[x][y-1][z] - 2.0 * phi[x][y][z]) / SQ(dy);\n  double phizz = (phi[x][y][z+1] + phi[x][y][z-1] - 2.0 * phi[x][y][z]) / SQ(dz);\n  return phixx + phiyy + phizz;\n}\n\n__device__\ndouble An(double phix, double phiy, double phiz, double epsilon)\n{\n  if (phix != 0.0 || phiy != 0.0 || phiz != 0.0){\n    return ((1.0 - 3.0 * epsilon) * (1.0 + (((4.0 * epsilon) / (1.0-3.0*epsilon))*\n           ((SQ(phix)*SQ(phix)+SQ(phiy)*SQ(phiy)+SQ(phiz)*SQ(phiz)) /\n           ((SQ(phix)+SQ(phiy)+SQ(phiz))*(SQ(phix)+SQ(phiy)+SQ(phiz)))))));\n  }\n  else\n  {\n    return (1.0-((5.0/3.0)*epsilon));\n  }\n}\n\n__device__\ndouble Wn(double phix, double phiy, double phiz, double epsilon, double W0)\n{\n  return (W0*An(phix,phiy,phiz,epsilon));\n}\n\n__device__\ndouble taun(double phix, double phiy, double phiz, double epsilon, double tau0)\n{\n  return tau0 * SQ(An(phix,phiy,phiz,epsilon));\n}\n\n__device__\ndouble dFunc(double l, double m, double n)\n{\n  if (l != 0.0 || m != 0.0 || n != 0.0){\n    return (((l*l*l*(SQ(m)+SQ(n)))-(l*(SQ(m)*SQ(m)+SQ(n)*SQ(n)))) /\n            ((SQ(l)+SQ(m)+SQ(n))*(SQ(l)+SQ(m)+SQ(n))));\n  }\n  else\n  {\n    return 0.0;\n  }\n}\n\n__global__\nvoid calculateForce(double phi[][DATAYSIZE][DATAXSIZE], \n                    double Fx[][DATAYSIZE][DATAXSIZE],\n                    double Fy[][DATAYSIZE][DATAXSIZE],\n                    double Fz[][DATAYSIZE][DATAXSIZE],\n                    double dx, double dy, double dz,\n                    double epsilon, double W0, double tau0)\n{\n\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))) {\n\n    double phix = GradientX(phi,dx,dy,dz,ix,iy,iz);\n    double phiy = GradientY(phi,dx,dy,dz,ix,iy,iz);\n    double phiz = GradientZ(phi,dx,dy,dz,ix,iy,iz);\n    double sqGphi = SQ(phix) + SQ(phiy) + SQ(phiz);\n    double c = 16.0 * W0 * epsilon;\n    double w = Wn(phix,phiy,phiz,epsilon,W0);\n    double w2 = SQ(w);\n    \n\n    Fx[ix][iy][iz] = w2 * phix + sqGphi * w * c * dFunc(phix,phiy,phiz);\n    Fy[ix][iy][iz] = w2 * phiy + sqGphi * w * c * dFunc(phiy,phiz,phix);\n    Fz[ix][iy][iz] = w2 * phiz + sqGphi * w * c * dFunc(phiz,phix,phiy);\n  }\n  else\n  {\n    Fx[ix][iy][iz] = 0.0;\n    Fy[ix][iy][iz] = 0.0;\n    Fz[ix][iy][iz] = 0.0;\n  }\n\n}\n\n\n\n__global__\nvoid allenCahn(double phinew[][DATAYSIZE][DATAXSIZE], \n               double phiold[][DATAYSIZE][DATAXSIZE],\n               double uold[][DATAYSIZE][DATAXSIZE],\n               double Fx[][DATAYSIZE][DATAXSIZE],\n               double Fy[][DATAYSIZE][DATAXSIZE],\n               double Fz[][DATAYSIZE][DATAXSIZE],\n               double epsilon, double W0, double tau0, double lambda,\n               double dt, double dx, double dy, double dz)\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))) {\n\n    double phix = GradientX(phiold,dx,dy,dz,ix,iy,iz);\n    double phiy = GradientY(phiold,dx,dy,dz,ix,iy,iz);\n    double phiz = GradientZ(phiold,dx,dy,dz,ix,iy,iz); \n\n    phinew[ix][iy][iz] = phiold[ix][iy][iz] + \n     (dt / taun(phix,phiy,phiz,epsilon,tau0)) * \n     (Divergence(Fx,Fy,Fz,dx,dy,dz,ix,iy,iz) - \n      dFphi(phiold[ix][iy][iz], uold[ix][iy][iz],lambda));\n  }\n}\n\n__global__\nvoid boundaryConditionsPhi(double phinew[][DATAYSIZE][DATAXSIZE])\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if (ix == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (ix == DATAXSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iy == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iy == DATAYSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iz == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iz == DATAZSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n}\n\n__global__\nvoid thermalEquation(double unew[][DATAYSIZE][DATAXSIZE],\n                     double uold[][DATAYSIZE][DATAXSIZE],\n                     double phinew[][DATAYSIZE][DATAXSIZE],\n                     double phiold[][DATAYSIZE][DATAXSIZE],\n                     double D, double dt, double dx, double dy, double dz)\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))){\n    unew[ix][iy][iz] = uold[ix][iy][iz] + \n      0.5*(phinew[ix][iy][iz]- phiold[ix][iy][iz]) +\n      dt * D * Laplacian(uold,dx,dy,dz,ix,iy,iz);\n  }\n}\n\n__global__\nvoid boundaryConditionsU(double unew[][DATAYSIZE][DATAXSIZE], double delta)\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if (ix == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (ix == DATAXSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iy == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iy == DATAYSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iz == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iz == DATAZSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n}\n\n__global__\nvoid swapGrid(double cnew[][DATAYSIZE][DATAXSIZE],\n              double cold[][DATAYSIZE][DATAXSIZE])\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if ((ix < (DATAXSIZE)) && \n      (iy < (DATAYSIZE)) &&\n      (iz < (DATAZSIZE))) {\n    double tmp = cnew[ix][iy][iz];\n    cnew[ix][iy][iz] = cold[ix][iy][iz];\n    cold[ix][iy][iz] = tmp;\n  }\n}\n\nvoid initializationPhi(double phi[][DATAYSIZE][DATAXSIZE], double r0)\n{\n#ifdef _OPENMP\n  #pragma omp parallel for collapse(3)\n#endif\n  for (int idx = 0; idx < DATAXSIZE; idx++) {\n    for (int idy = 0; idy < DATAYSIZE; idy++) {\n      for (int idz = 0; idz < DATAZSIZE; idz++) {\n        double r = std::sqrt(SQ(idx-0.5*DATAXSIZE) + SQ(idy-0.5*DATAYSIZE) + SQ(idz-0.5*DATAZSIZE));\n        if (r < r0){\n          phi[idx][idy][idz] = 1.0;\n        }\n        else\n        {\n          phi[idx][idy][idz] = -1.0;\n        }\n      }\n    }\n  }\n}\n\nvoid initializationU(double u[][DATAYSIZE][DATAXSIZE], double r0, double delta)\n{\n#ifdef _OPENMP\n  #pragma omp parallel for collapse(3)\n#endif\n  for (int idx = 0; idx < DATAXSIZE; idx++) {\n    for (int idy = 0; idy < DATAYSIZE; idy++) {\n      for (int idz = 0; idz < DATAZSIZE; idz++) {\n        double r = std::sqrt(SQ(idx-0.5*DATAXSIZE) + SQ(idy-0.5*DATAYSIZE) + SQ(idz-0.5*DATAZSIZE));\n        if (r < r0) {\n          u[idx][idy][idz] = 0.0;\n        }\n        else\n        {\n          u[idx][idy][idz] = -delta * (1.0 - std::exp(-(r-r0)));\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  const int num_steps = atoi(argv[1]);  \n\n  const double dx = 0.4;\n  const double dy = 0.4;\n  const double dz = 0.4;\n  const double dt = 0.01;\n  const double delta = 0.8;\n  const double r0 = 5.0;\n  const double epsilon = 0.07;\n  const double W0 = 1.0;\n  const double beta0 = 0.0;\n  const double D = 2.0;\n  const double d0 = 0.5;\n  const double a1 = 1.25 / std::sqrt(2.0);\n  const double a2 = 0.64;\n  const double lambda = (W0*a1)/(d0);\n  const double tau0 = ((W0*W0*W0*a1*a2)/(d0*D)) + ((W0*W0*beta0)/(d0));\n\n  \n\n  const int nx = DATAXSIZE;\n  const int ny = DATAYSIZE;\n  const int nz = DATAZSIZE;\n  const int vol = nx * ny * nz;\n  const size_t vol_in_bytes = sizeof(double) * vol;\n\n  \n\n  nRarray *phi_host;\n  nRarray *d_phiold;\n  nRarray *u_host;\n  nRarray *d_phinew;\n  nRarray *d_uold;\n  nRarray *d_unew;\n  nRarray *d_Fx;\n  nRarray *d_Fy;\n  nRarray *d_Fz;\n\n  phi_host = (nRarray *)malloc(vol_in_bytes);\n  u_host = (nRarray *)malloc(vol_in_bytes);\n\n  initializationPhi(phi_host,r0);\n  initializationU(u_host,r0,delta);\n\n#ifdef VERIFY\n  nRarray *phi_ref = (nRarray *)malloc(vol_in_bytes);\n  nRarray *u_ref = (nRarray *)malloc(vol_in_bytes);\n  memcpy(phi_ref, phi_host, vol_in_bytes);\n  memcpy(u_ref, u_host, vol_in_bytes);\n  reference(phi_ref, u_ref, vol, num_steps);\n#endif \n\n  auto offload_start = std::chrono::steady_clock::now();\n\n  \n\n  dim3 grid ((DATAZSIZE+7)/8, (DATAYSIZE+7)/8, (DATAXSIZE+3)/4);\n  dim3 block (8, 8, 4);\n\n  \n\n  cudaMalloc((void **) &d_phiold, vol_in_bytes);\n  cudaMalloc((void **) &d_phinew, vol_in_bytes);\n  cudaMalloc((void **) &d_uold, vol_in_bytes);\n  cudaMalloc((void **) &d_unew, vol_in_bytes);\n  cudaMalloc((void **) &d_Fx, vol_in_bytes);\n  cudaMalloc((void **) &d_Fy, vol_in_bytes);\n  cudaMalloc((void **) &d_Fz, vol_in_bytes);\n\n  cudaMemcpy(d_phiold, phi_host, vol_in_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_uold, u_host, vol_in_bytes, cudaMemcpyHostToDevice);\n\n  int t = 0;\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  while (t <= num_steps) {\n\n    calculateForce<<<grid, block>>>(d_phiold,d_Fx,d_Fy,d_Fz,\n                                    dx,dy,dz,epsilon,W0,tau0);\n\n    allenCahn<<<grid, block>>>(d_phinew,d_phiold,d_uold,\n                               d_Fx,d_Fy,d_Fz,\n                               epsilon,W0,tau0,lambda,\n                               dt,dx,dy,dz);\n\n    boundaryConditionsPhi<<<grid, block>>>(d_phinew);\n\n    thermalEquation<<<grid, block>>>(d_unew,d_uold,d_phinew,d_phiold,\n                                     D,dt,dx,dy,dz);\n\n    boundaryConditionsU<<<grid, block>>>(d_unew,delta);\n\n    swapGrid<<<grid, block>>>(d_phinew, d_phiold);\n\n    swapGrid<<<grid, block>>>(d_unew, d_uold);\n\n    t++;\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %.3f (ms)\\n\", time * 1e-6f);\n\n  cudaMemcpy(phi_host, d_phiold, vol_in_bytes, cudaMemcpyDeviceToHost);\n  cudaMemcpy(u_host, d_uold, vol_in_bytes, cudaMemcpyDeviceToHost);\n\n  cudaFree(d_phiold);\n  cudaFree(d_phinew);\n  cudaFree(d_uold);\n  cudaFree(d_unew);\n  cudaFree(d_Fx);\n  cudaFree(d_Fy);\n  cudaFree(d_Fz);\n\n  auto offload_end = std::chrono::steady_clock::now();\n  auto offload_time = std::chrono::duration_cast<std::chrono::nanoseconds>(offload_end - offload_start).count();\n  printf(\"Offload time: %.3f (ms)\\n\", offload_time * 1e-6f);\n\n#ifdef VERIFY\n  bool ok = true;\n  for (int idx = 0; idx < nx; idx++)\n    for (int idy = 0; idy < ny; idy++)\n      for (int idz = 0; idz < nz; idz++) {\n        if (fabs(phi_ref[idx][idy][idz] - phi_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"phi: %lf %lf\\n\", phi_ref[idx][idy][idz], phi_host[idx][idy][idz]);\n\t}\n        if (fabs(u_ref[idx][idy][idz] - u_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"u: %lf %lf\\n\", u_ref[idx][idy][idz], u_host[idx][idy][idz]);\n        }\n      }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(phi_ref);\n  free(u_ref);\n#endif\n\n  free(phi_host);\n  free(u_host);\n  return 0;\n}\n"}}
{"kernel_name": "ace", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n\n\n#define DATAXSIZE 400\n#define DATAYSIZE 400\n#define DATAZSIZE 400\n\ntypedef double nRarray[DATAYSIZE][DATAXSIZE];\n\n\n\n#define SQ(x) ((x)*(x))\n\n#ifdef VERIFY\n#include <string.h>\n#include \"reference.h\"\n#endif\n\n__device__\ndouble dFphi(double phi, double u, double lambda)\n{\n  return (-phi*(1.0-phi*phi)+lambda*u*(1.0-phi*phi)*(1.0-phi*phi));\n}\n\n__device__\ndouble GradientX(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x+1][y][z] - phi[x-1][y][z]) / (2.0*dx);\n}\n\n__device__\ndouble GradientY(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y+1][z] - phi[x][y-1][z]) / (2.0*dy);\n}\n\n__device__\ndouble GradientZ(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y][z+1] - phi[x][y][z-1]) / (2.0*dz);\n}\n\n__device__\ndouble Divergence(double phix[][DATAYSIZE][DATAXSIZE], \n                  double phiy[][DATAYSIZE][DATAXSIZE],\n                  double phiz[][DATAYSIZE][DATAXSIZE], \n                  double dx, double dy, double dz, int x, int y, int z)\n{\n  return GradientX(phix,dx,dy,dz,x,y,z) + \n         GradientY(phiy,dx,dy,dz,x,y,z) +\n         GradientZ(phiz,dx,dy,dz,x,y,z);\n}\n\n__device__\ndouble Laplacian(double phi[][DATAYSIZE][DATAXSIZE],\n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  double phixx = (phi[x+1][y][z] + phi[x-1][y][z] - 2.0 * phi[x][y][z]) / SQ(dx);\n  double phiyy = (phi[x][y+1][z] + phi[x][y-1][z] - 2.0 * phi[x][y][z]) / SQ(dy);\n  double phizz = (phi[x][y][z+1] + phi[x][y][z-1] - 2.0 * phi[x][y][z]) / SQ(dz);\n  return phixx + phiyy + phizz;\n}\n\n__device__\ndouble An(double phix, double phiy, double phiz, double epsilon)\n{\n  if (phix != 0.0 || phiy != 0.0 || phiz != 0.0){\n    return ((1.0 - 3.0 * epsilon) * (1.0 + (((4.0 * epsilon) / (1.0-3.0*epsilon))*\n           ((SQ(phix)*SQ(phix)+SQ(phiy)*SQ(phiy)+SQ(phiz)*SQ(phiz)) /\n           ((SQ(phix)+SQ(phiy)+SQ(phiz))*(SQ(phix)+SQ(phiy)+SQ(phiz)))))));\n  }\n  else\n  {\n    return (1.0-((5.0/3.0)*epsilon));\n  }\n}\n\n__device__\ndouble Wn(double phix, double phiy, double phiz, double epsilon, double W0)\n{\n  return (W0*An(phix,phiy,phiz,epsilon));\n}\n\n__device__\ndouble taun(double phix, double phiy, double phiz, double epsilon, double tau0)\n{\n  return tau0 * SQ(An(phix,phiy,phiz,epsilon));\n}\n\n__device__\ndouble dFunc(double l, double m, double n)\n{\n  if (l != 0.0 || m != 0.0 || n != 0.0){\n    return (((l*l*l*(SQ(m)+SQ(n)))-(l*(SQ(m)*SQ(m)+SQ(n)*SQ(n)))) /\n            ((SQ(l)+SQ(m)+SQ(n))*(SQ(l)+SQ(m)+SQ(n))));\n  }\n  else\n  {\n    return 0.0;\n  }\n}\n\n__global__\nvoid calculateForce(double phi[][DATAYSIZE][DATAXSIZE], \n                    double Fx[][DATAYSIZE][DATAXSIZE],\n                    double Fy[][DATAYSIZE][DATAXSIZE],\n                    double Fz[][DATAYSIZE][DATAXSIZE],\n                    double dx, double dy, double dz,\n                    double epsilon, double W0, double tau0)\n{\n\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))) {\n\n    double phix = GradientX(phi,dx,dy,dz,ix,iy,iz);\n    double phiy = GradientY(phi,dx,dy,dz,ix,iy,iz);\n    double phiz = GradientZ(phi,dx,dy,dz,ix,iy,iz);\n    double sqGphi = SQ(phix) + SQ(phiy) + SQ(phiz);\n    double c = 16.0 * W0 * epsilon;\n    double w = Wn(phix,phiy,phiz,epsilon,W0);\n    double w2 = SQ(w);\n    \n\n    Fx[ix][iy][iz] = w2 * phix + sqGphi * w * c * dFunc(phix,phiy,phiz);\n    Fy[ix][iy][iz] = w2 * phiy + sqGphi * w * c * dFunc(phiy,phiz,phix);\n    Fz[ix][iy][iz] = w2 * phiz + sqGphi * w * c * dFunc(phiz,phix,phiy);\n  }\n  else\n  {\n    Fx[ix][iy][iz] = 0.0;\n    Fy[ix][iy][iz] = 0.0;\n    Fz[ix][iy][iz] = 0.0;\n  }\n\n}\n\n\n\n__global__\nvoid allenCahn(double phinew[][DATAYSIZE][DATAXSIZE], \n               double phiold[][DATAYSIZE][DATAXSIZE],\n               double uold[][DATAYSIZE][DATAXSIZE],\n               double Fx[][DATAYSIZE][DATAXSIZE],\n               double Fy[][DATAYSIZE][DATAXSIZE],\n               double Fz[][DATAYSIZE][DATAXSIZE],\n               double epsilon, double W0, double tau0, double lambda,\n               double dt, double dx, double dy, double dz)\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))) {\n\n    double phix = GradientX(phiold,dx,dy,dz,ix,iy,iz);\n    double phiy = GradientY(phiold,dx,dy,dz,ix,iy,iz);\n    double phiz = GradientZ(phiold,dx,dy,dz,ix,iy,iz); \n\n    phinew[ix][iy][iz] = phiold[ix][iy][iz] + \n     (dt / taun(phix,phiy,phiz,epsilon,tau0)) * \n     (Divergence(Fx,Fy,Fz,dx,dy,dz,ix,iy,iz) - \n      dFphi(phiold[ix][iy][iz], uold[ix][iy][iz],lambda));\n  }\n}\n\n__global__\nvoid boundaryConditionsPhi(double phinew[][DATAYSIZE][DATAXSIZE])\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if (ix == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (ix == DATAXSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iy == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iy == DATAYSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iz == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iz == DATAZSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n}\n\n__global__\nvoid thermalEquation(double unew[][DATAYSIZE][DATAXSIZE],\n                     double uold[][DATAYSIZE][DATAXSIZE],\n                     double phinew[][DATAYSIZE][DATAXSIZE],\n                     double phiold[][DATAYSIZE][DATAXSIZE],\n                     double D, double dt, double dx, double dy, double dz)\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))){\n    unew[ix][iy][iz] = uold[ix][iy][iz] + \n      0.5*(phinew[ix][iy][iz]- phiold[ix][iy][iz]) +\n      dt * D * Laplacian(uold,dx,dy,dz,ix,iy,iz);\n  }\n}\n\n__global__\nvoid boundaryConditionsU(double unew[][DATAYSIZE][DATAXSIZE], double delta)\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if (ix == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (ix == DATAXSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iy == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iy == DATAYSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iz == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iz == DATAZSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n}\n\n__global__\nvoid swapGrid(double cnew[][DATAYSIZE][DATAXSIZE],\n              double cold[][DATAYSIZE][DATAXSIZE])\n{\n  unsigned iz = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned iy = blockIdx.y*blockDim.y + threadIdx.y;\n  unsigned ix = blockIdx.z*blockDim.z + threadIdx.z;\n\n  if ((ix < (DATAXSIZE)) && \n      (iy < (DATAYSIZE)) &&\n      (iz < (DATAZSIZE))) {\n    double tmp = cnew[ix][iy][iz];\n    cnew[ix][iy][iz] = cold[ix][iy][iz];\n    cold[ix][iy][iz] = tmp;\n  }\n}\n\nvoid initializationPhi(double phi[][DATAYSIZE][DATAXSIZE], double r0)\n{\n#ifdef _OPENMP\n  #pragma omp parallel for collapse(3)\n#endif\n  for (int idx = 0; idx < DATAXSIZE; idx++) {\n    for (int idy = 0; idy < DATAYSIZE; idy++) {\n      for (int idz = 0; idz < DATAZSIZE; idz++) {\n        double r = std::sqrt(SQ(idx-0.5*DATAXSIZE) + SQ(idy-0.5*DATAYSIZE) + SQ(idz-0.5*DATAZSIZE));\n        if (r < r0){\n          phi[idx][idy][idz] = 1.0;\n        }\n        else\n        {\n          phi[idx][idy][idz] = -1.0;\n        }\n      }\n    }\n  }\n}\n\nvoid initializationU(double u[][DATAYSIZE][DATAXSIZE], double r0, double delta)\n{\n#ifdef _OPENMP\n  #pragma omp parallel for collapse(3)\n#endif\n  for (int idx = 0; idx < DATAXSIZE; idx++) {\n    for (int idy = 0; idy < DATAYSIZE; idy++) {\n      for (int idz = 0; idz < DATAZSIZE; idz++) {\n        double r = std::sqrt(SQ(idx-0.5*DATAXSIZE) + SQ(idy-0.5*DATAYSIZE) + SQ(idz-0.5*DATAZSIZE));\n        if (r < r0) {\n          u[idx][idy][idz] = 0.0;\n        }\n        else\n        {\n          u[idx][idy][idz] = -delta * (1.0 - std::exp(-(r-r0)));\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  const int num_steps = atoi(argv[1]);  \n\n  const double dx = 0.4;\n  const double dy = 0.4;\n  const double dz = 0.4;\n  const double dt = 0.01;\n  const double delta = 0.8;\n  const double r0 = 5.0;\n  const double epsilon = 0.07;\n  const double W0 = 1.0;\n  const double beta0 = 0.0;\n  const double D = 2.0;\n  const double d0 = 0.5;\n  const double a1 = 1.25 / std::sqrt(2.0);\n  const double a2 = 0.64;\n  const double lambda = (W0*a1)/(d0);\n  const double tau0 = ((W0*W0*W0*a1*a2)/(d0*D)) + ((W0*W0*beta0)/(d0));\n\n  \n\n  const int nx = DATAXSIZE;\n  const int ny = DATAYSIZE;\n  const int nz = DATAZSIZE;\n  const int vol = nx * ny * nz;\n  const size_t vol_in_bytes = sizeof(double) * vol;\n\n  \n\n  nRarray *phi_host;\n  nRarray *d_phiold;\n  nRarray *u_host;\n  nRarray *d_phinew;\n  nRarray *d_uold;\n  nRarray *d_unew;\n  nRarray *d_Fx;\n  nRarray *d_Fy;\n  nRarray *d_Fz;\n\n  phi_host = (nRarray *)malloc(vol_in_bytes);\n  u_host = (nRarray *)malloc(vol_in_bytes);\n\n  initializationPhi(phi_host,r0);\n  initializationU(u_host,r0,delta);\n\n#ifdef VERIFY\n  nRarray *phi_ref = (nRarray *)malloc(vol_in_bytes);\n  nRarray *u_ref = (nRarray *)malloc(vol_in_bytes);\n  memcpy(phi_ref, phi_host, vol_in_bytes);\n  memcpy(u_ref, u_host, vol_in_bytes);\n  reference(phi_ref, u_ref, vol, num_steps);\n#endif \n\n  auto offload_start = std::chrono::steady_clock::now();\n\n  \n\n  dim3 grid ((DATAZSIZE+7)/8, (DATAYSIZE+7)/8, (DATAXSIZE+3)/4);\n  dim3 block (8, 8, 4);\n\n  \n\n  hipMalloc((void **) &d_phiold, vol_in_bytes);\n  hipMalloc((void **) &d_phinew, vol_in_bytes);\n  hipMalloc((void **) &d_uold, vol_in_bytes);\n  hipMalloc((void **) &d_unew, vol_in_bytes);\n  hipMalloc((void **) &d_Fx, vol_in_bytes);\n  hipMalloc((void **) &d_Fy, vol_in_bytes);\n  hipMalloc((void **) &d_Fz, vol_in_bytes);\n\n  hipMemcpy(d_phiold, phi_host, vol_in_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_uold, u_host, vol_in_bytes, hipMemcpyHostToDevice);\n\n  int t = 0;\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  while (t <= num_steps) {\n\n    hipLaunchKernelGGL(calculateForce, grid, block, 0, 0, d_phiold,d_Fx,d_Fy,d_Fz,\n                                    dx,dy,dz,epsilon,W0,tau0);\n\n    hipLaunchKernelGGL(allenCahn, grid, block, 0, 0, d_phinew,d_phiold,d_uold,\n                               d_Fx,d_Fy,d_Fz,\n                               epsilon,W0,tau0,lambda,\n                               dt,dx,dy,dz);\n\n    hipLaunchKernelGGL(boundaryConditionsPhi, grid, block, 0, 0, d_phinew);\n\n    hipLaunchKernelGGL(thermalEquation, grid, block, 0, 0, d_unew,d_uold,d_phinew,d_phiold,\n                                     D,dt,dx,dy,dz);\n\n    hipLaunchKernelGGL(boundaryConditionsU, grid, block, 0, 0, d_unew,delta);\n\n    hipLaunchKernelGGL(swapGrid, grid, block, 0, 0, d_phinew, d_phiold);\n\n    hipLaunchKernelGGL(swapGrid, grid, block, 0, 0, d_unew, d_uold);\n\n    t++;\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %.3f (ms)\\n\", time * 1e-6f);\n\n  hipMemcpy(phi_host, d_phiold, vol_in_bytes, hipMemcpyDeviceToHost);\n  hipMemcpy(u_host, d_uold, vol_in_bytes, hipMemcpyDeviceToHost);\n\n  hipFree(d_phiold);\n  hipFree(d_phinew);\n  hipFree(d_uold);\n  hipFree(d_unew);\n  hipFree(d_Fx);\n  hipFree(d_Fy);\n  hipFree(d_Fz);\n\n  auto offload_end = std::chrono::steady_clock::now();\n  auto offload_time = std::chrono::duration_cast<std::chrono::nanoseconds>(offload_end - offload_start).count();\n  printf(\"Offload time: %.3f (ms)\\n\", offload_time * 1e-6f);\n\n#ifdef VERIFY\n  bool ok = true;\n  for (int idx = 0; idx < nx; idx++)\n    for (int idy = 0; idy < ny; idy++)\n      for (int idz = 0; idz < nz; idz++) {\n        if (fabs(phi_ref[idx][idy][idz] - phi_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"phi: %lf %lf\\n\", phi_ref[idx][idy][idz], phi_host[idx][idy][idz]);\n\t}\n        if (fabs(u_ref[idx][idy][idz] - u_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"u: %lf %lf\\n\", u_ref[idx][idy][idz], u_host[idx][idy][idz]);\n        }\n      }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(phi_ref);\n  free(u_ref);\n#endif\n\n  free(phi_host);\n  free(u_host);\n  return 0;\n}\n"}}
{"kernel_name": "ace", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n\n\n#define DATAXSIZE 400\n#define DATAYSIZE 400\n#define DATAZSIZE 400\n\n#define SQ(x) ((x)*(x))\n\ntypedef double nRarray[DATAYSIZE][DATAXSIZE];\n\n#ifdef VERIFY\n#include <string.h>\n#include \"reference.h\"\n#endif\n\n#pragma omp declare target\ndouble dFphi(double phi, double u, double lambda)\n{\n  return (-phi*(1.0-phi*phi)+lambda*u*(1.0-phi*phi)*(1.0-phi*phi));\n}\n\n\ndouble GradientX(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x+1][y][z] - phi[x-1][y][z]) / (2.0*dx);\n}\n\n\ndouble GradientY(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y+1][z] - phi[x][y-1][z]) / (2.0*dy);\n}\n\n\ndouble GradientZ(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y][z+1] - phi[x][y][z-1]) / (2.0*dz);\n}\n\n\ndouble Divergence(double phix[][DATAYSIZE][DATAXSIZE], \n                  double phiy[][DATAYSIZE][DATAXSIZE],\n                  double phiz[][DATAYSIZE][DATAXSIZE], \n                  double dx, double dy, double dz, int x, int y, int z)\n{\n  return GradientX(phix,dx,dy,dz,x,y,z) + \n         GradientY(phiy,dx,dy,dz,x,y,z) +\n         GradientZ(phiz,dx,dy,dz,x,y,z);\n}\n\n\ndouble Laplacian(double phi[][DATAYSIZE][DATAXSIZE],\n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  double phixx = (phi[x+1][y][z] + phi[x-1][y][z] - 2.0 * phi[x][y][z]) / SQ(dx);\n  double phiyy = (phi[x][y+1][z] + phi[x][y-1][z] - 2.0 * phi[x][y][z]) / SQ(dy);\n  double phizz = (phi[x][y][z+1] + phi[x][y][z-1] - 2.0 * phi[x][y][z]) / SQ(dz);\n  return phixx + phiyy + phizz;\n}\n\n\ndouble An(double phix, double phiy, double phiz, double epsilon)\n{\n  if (phix != 0.0 || phiy != 0.0 || phiz != 0.0){\n    return ((1.0 - 3.0 * epsilon) * (1.0 + (((4.0 * epsilon) / (1.0-3.0*epsilon))*\n           ((SQ(phix)*SQ(phix)+SQ(phiy)*SQ(phiy)+SQ(phiz)*SQ(phiz)) /\n           ((SQ(phix)+SQ(phiy)+SQ(phiz))*(SQ(phix)+SQ(phiy)+SQ(phiz)))))));\n  }\n  else\n  {\n    return (1.0-((5.0/3.0)*epsilon));\n  }\n}\n\n\ndouble Wn(double phix, double phiy, double phiz, double epsilon, double W0)\n{\n  return (W0*An(phix,phiy,phiz,epsilon));\n}\n\n\ndouble taun(double phix, double phiy, double phiz, double epsilon, double tau0)\n{\n  return tau0 * SQ(An(phix,phiy,phiz,epsilon));\n}\n\n\ndouble dFunc(double l, double m, double n)\n{\n  if (l != 0.0 || m != 0.0 || n != 0.0){\n    return (((l*l*l*(SQ(m)+SQ(n)))-(l*(SQ(m)*SQ(m)+SQ(n)*SQ(n)))) /\n            ((SQ(l)+SQ(m)+SQ(n))*(SQ(l)+SQ(m)+SQ(n))));\n  }\n  else\n  {\n    return 0.0;\n  }\n}\n#pragma omp end declare target\n\nvoid calculateForce(double phi[][DATAYSIZE][DATAXSIZE], \n                    double Fx[][DATAYSIZE][DATAXSIZE],\n                    double Fy[][DATAYSIZE][DATAXSIZE],\n                    double Fz[][DATAYSIZE][DATAXSIZE],\n                    double dx, double dy, double dz,\n                    double epsilon, double W0, double tau0)\n{\n  #pragma omp target teams distribute parallel for collapse(3) thread_limit(256)\n  for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n\n        if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n            (iz < (DATAZSIZE-1)) && (ix > (0)) && \n            (iy > (0)) && (iz > (0))) {\n\n          double phix = GradientX(phi,dx,dy,dz,ix,iy,iz);\n          double phiy = GradientY(phi,dx,dy,dz,ix,iy,iz);\n          double phiz = GradientZ(phi,dx,dy,dz,ix,iy,iz);\n          double sqGphi = SQ(phix) + SQ(phiy) + SQ(phiz);\n          double c = 16.0 * W0 * epsilon;\n          double w = Wn(phix,phiy,phiz,epsilon,W0);\n          double w2 = SQ(w);\n          \n\n          Fx[ix][iy][iz] = w2 * phix + sqGphi * w * c * dFunc(phix,phiy,phiz);\n          Fy[ix][iy][iz] = w2 * phiy + sqGphi * w * c * dFunc(phiy,phiz,phix);\n          Fz[ix][iy][iz] = w2 * phiz + sqGphi * w * c * dFunc(phiz,phix,phiy);\n        }\n        else\n        {\n          Fx[ix][iy][iz] = 0.0;\n          Fy[ix][iy][iz] = 0.0;\n          Fz[ix][iy][iz] = 0.0;\n        }\n      }\n    }\n  }\n}\n\n\n\nvoid allenCahn(double phinew[][DATAYSIZE][DATAXSIZE], \n               double phiold[][DATAYSIZE][DATAXSIZE],\n               double uold[][DATAYSIZE][DATAXSIZE],\n               double Fx[][DATAYSIZE][DATAXSIZE],\n               double Fy[][DATAYSIZE][DATAXSIZE],\n               double Fz[][DATAYSIZE][DATAXSIZE],\n               double epsilon, double W0, double tau0, double lambda,\n               double dt, double dx, double dy, double dz)\n{\n  #pragma omp target teams distribute parallel for collapse(3) thread_limit(256)\n  for (int ix = 1; ix < DATAXSIZE-1; ix++) {\n    for (int iy = 1; iy < DATAYSIZE-1; iy++) {\n      for (int iz = 1; iz < DATAZSIZE-1; iz++) {\n\n        double phix = GradientX(phiold,dx,dy,dz,ix,iy,iz);\n        double phiy = GradientY(phiold,dx,dy,dz,ix,iy,iz);\n        double phiz = GradientZ(phiold,dx,dy,dz,ix,iy,iz); \n\n        phinew[ix][iy][iz] = phiold[ix][iy][iz] + \n         (dt / taun(phix,phiy,phiz,epsilon,tau0)) * \n         (Divergence(Fx,Fy,Fz,dx,dy,dz,ix,iy,iz) - \n          dFphi(phiold[ix][iy][iz], uold[ix][iy][iz],lambda));\n      }\n    }\n  }\n}\n\nvoid boundaryConditionsPhi(double phinew[][DATAYSIZE][DATAXSIZE])\n{\n  #pragma omp target teams distribute parallel for collapse(3) thread_limit(256)\n  for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n\n        if (ix == 0){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (ix == DATAXSIZE-1){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (iy == 0){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (iy == DATAYSIZE-1){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (iz == 0){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (iz == DATAZSIZE-1){\n          phinew[ix][iy][iz] = -1.0;\n        }\n      }\n    }\n  }\n}\n\nvoid thermalEquation(double unew[][DATAYSIZE][DATAXSIZE],\n                     double uold[][DATAYSIZE][DATAXSIZE],\n                     double phinew[][DATAYSIZE][DATAXSIZE],\n                     double phiold[][DATAYSIZE][DATAXSIZE],\n                     double D, double dt, double dx, double dy, double dz)\n{\n  #pragma omp target teams distribute parallel for collapse(3) thread_limit(256)\n  for (int ix = 1; ix < DATAXSIZE-1; ix++) {\n    for (int iy = 1; iy < DATAYSIZE-1; iy++) {\n      for (int iz = 1; iz < DATAZSIZE-1; iz++) {\n\n        unew[ix][iy][iz] = uold[ix][iy][iz] + \n          0.5*(phinew[ix][iy][iz]-\n               phiold[ix][iy][iz]) +\n          dt * D * Laplacian(uold,dx,dy,dz,ix,iy,iz);\n      }\n    }\n  }\n}\n\nvoid boundaryConditionsU(double unew[][DATAYSIZE][DATAXSIZE], double delta)\n{\n  #pragma omp target teams distribute parallel for collapse(3) thread_limit(256)\n  for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n\n        if (ix == 0){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (ix == DATAXSIZE-1){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (iy == 0){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (iy == DATAYSIZE-1){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (iz == 0){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (iz == DATAZSIZE-1){\n          unew[ix][iy][iz] =  -delta;\n        }\n      }\n    }\n  }\n}\n\nvoid swapGrid(double cnew[][DATAYSIZE][DATAXSIZE],\n              double cold[][DATAYSIZE][DATAXSIZE])\n{\n  #pragma omp target teams distribute parallel for collapse(3) thread_limit(256)\n  for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n        double tmp = cnew[ix][iy][iz];\n        cnew[ix][iy][iz] = cold[ix][iy][iz];\n        cold[ix][iy][iz] = tmp;\n      }\n    }\n  }\n}\n\nvoid initializationPhi(double phi[][DATAYSIZE][DATAXSIZE], double r0)\n{\n  #pragma omp parallel for collapse(3)\n  for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n        double r = std::sqrt(SQ(ix-0.5*DATAXSIZE) + SQ(iy-0.5*DATAYSIZE) + SQ(iz-0.5*DATAZSIZE));\n        if (r < r0){\n          phi[ix][iy][iz] = 1.0;\n        }\n        else\n        {\n          phi[ix][iy][iz] = -1.0;\n        }\n      }\n    }\n  }\n}\n\nvoid initializationU(double u[][DATAYSIZE][DATAXSIZE], double r0, double delta)\n{\n  #pragma omp parallel for collapse(3)\n  for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n        double r = std::sqrt(SQ(ix-0.5*DATAXSIZE) + SQ(iy-0.5*DATAYSIZE) + SQ(iz-0.5*DATAZSIZE));\n        if (r < r0) {\n          u[ix][iy][iz] = 0.0;\n        }\n        else\n        {\n          u[ix][iy][iz] = -delta * (1.0 - std::exp(-(r-r0)));\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  const int num_steps = atoi(argv[1]);  \n\n  const double dx = 0.4;\n  const double dy = 0.4;\n  const double dz = 0.4;\n  const double dt = 0.01;\n  const double delta = 0.8;\n  const double r0 = 5.0;\n  const double epsilon = 0.07;\n  const double W0 = 1.0;\n  const double beta0 = 0.0;\n  const double D = 2.0;\n  const double d0 = 0.5;\n  const double a1 = 1.25 / std::sqrt(2.0);\n  const double a2 = 0.64;\n  const double lambda = (W0*a1)/(d0);\n  const double tau0 = ((W0*W0*W0*a1*a2)/(d0*D)) + ((W0*W0*beta0)/(d0));\n\n  \n\n  const int nx = DATAXSIZE;\n  const int ny = DATAYSIZE;\n  const int nz = DATAZSIZE;\n  const int vol = nx * ny * nz;\n  const size_t vol_in_bytes = sizeof(double) * vol;\n\n  \n\n  nRarray *phi_host = (nRarray *)malloc(vol_in_bytes);\n  nRarray *u_host = (nRarray *)malloc(vol_in_bytes);\n  initializationPhi(phi_host,r0);\n  initializationU(u_host,r0,delta);\n\n#ifdef VERIFY\n  nRarray *phi_ref = (nRarray *)malloc(vol_in_bytes);\n  nRarray *u_ref = (nRarray *)malloc(vol_in_bytes);\n  memcpy(phi_ref, phi_host, vol_in_bytes);\n  memcpy(u_ref, u_host, vol_in_bytes);\n  reference(phi_ref, u_ref, vol, num_steps);\n#endif \n\n  auto offload_start = std::chrono::steady_clock::now();\n\n  \n\n  double *d_phiold = (double*)phi_host;\n  double *d_uold = (double*)u_host;\n  double *d_phinew = (double*) malloc (vol_in_bytes);\n  double *d_unew = (double*) malloc (vol_in_bytes);\n  double *d_Fx = (double*) malloc (vol_in_bytes);\n  double *d_Fy = (double*) malloc (vol_in_bytes);\n  double *d_Fz = (double*) malloc (vol_in_bytes);\n\n  #pragma omp target data map(tofrom: d_phiold[0:vol], \\\n                                      d_uold[0:vol]) \\\n                          map(alloc: d_phinew[0:vol], \\\n                                     d_unew[0:vol], \\\n                                     d_Fx[0:vol],\\\n                                     d_Fy[0:vol],\\\n                                     d_Fz[0:vol])\n  {\n    int t = 0;\n\n    auto start = std::chrono::steady_clock::now();\n  \n    while (t <= num_steps) {\n  \n      calculateForce((nRarray*)d_phiold, (nRarray*)d_Fx,(nRarray*)d_Fy,(nRarray*)d_Fz,\n                     dx,dy,dz,epsilon,W0,tau0);\n  \n      allenCahn((nRarray*)d_phinew,(nRarray*)d_phiold,(nRarray*)d_uold,\n                (nRarray*)d_Fx,(nRarray*)d_Fy,(nRarray*)d_Fz,\n                epsilon,W0,tau0,lambda, dt,dx,dy,dz);\n  \n      boundaryConditionsPhi((nRarray*)d_phinew);\n  \n      thermalEquation((nRarray*)d_unew,(nRarray*)d_uold,(nRarray*)d_phinew,(nRarray*)d_phiold,\n                      D,dt,dx,dy,dz);\n  \n      boundaryConditionsU((nRarray*)d_unew,delta);\n  \n      swapGrid((nRarray*)d_phinew, (nRarray*)d_phiold);\n  \n      swapGrid((nRarray*)d_unew, (nRarray*)d_uold);\n  \n      t++;\n    }\n  \n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Total kernel execution time: %.3f (ms)\\n\", time * 1e-6f);\n  }\n\n  auto offload_end = std::chrono::steady_clock::now();\n  auto offload_time = std::chrono::duration_cast<std::chrono::nanoseconds>(offload_end - offload_start).count();\n  printf(\"Offload time: %.3f (ms)\\n\", offload_time * 1e-6f);\n\n#ifdef VERIFY\n  bool ok = true;\n  for (int idx = 0; idx < nx; idx++)\n    for (int idy = 0; idy < ny; idy++)\n      for (int idz = 0; idz < nz; idz++) {\n        if (fabs(phi_ref[idx][idy][idz] - phi_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"phi: %lf %lf\\n\", phi_ref[idx][idy][idz], phi_host[idx][idy][idz]);\n\t}\n        if (fabs(u_ref[idx][idy][idz] - u_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"u: %lf %lf\\n\", u_ref[idx][idy][idz], u_host[idx][idy][idz]);\n        }\n      }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(phi_ref);\n  free(u_ref);\n#endif\n\n  free(phi_host);\n  free(u_host);\n  free(d_phinew);\n  free(d_unew);\n  free(d_Fx);\n  free(d_Fy);\n  free(d_Fz);\n  return 0;\n}\n"}}
{"kernel_name": "ace", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n\n\n\n#define DATAXSIZE 400\n#define DATAYSIZE 400\n#define DATAZSIZE 400\n\n#define SQ(x) ((x)*(x))\n\ntypedef double nRarray[DATAYSIZE][DATAXSIZE];\n\n#ifdef VERIFY\n#include <string.h>\n#include \"reference.h\"\n#endif\n\ndouble dFphi(double phi, double u, double lambda)\n{\n  return (-phi*(1.0-phi*phi)+lambda*u*(1.0-phi*phi)*(1.0-phi*phi));\n}\n\n\ndouble GradientX(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x+1][y][z] - phi[x-1][y][z]) / (2.0*dx);\n}\n\n\ndouble GradientY(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y+1][z] - phi[x][y-1][z]) / (2.0*dy);\n}\n\n\ndouble GradientZ(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y][z+1] - phi[x][y][z-1]) / (2.0*dz);\n}\n\n\ndouble Divergence(double phix[][DATAYSIZE][DATAXSIZE], \n                  double phiy[][DATAYSIZE][DATAXSIZE],\n                  double phiz[][DATAYSIZE][DATAXSIZE], \n                  double dx, double dy, double dz, int x, int y, int z)\n{\n  return GradientX(phix,dx,dy,dz,x,y,z) + \n         GradientY(phiy,dx,dy,dz,x,y,z) +\n         GradientZ(phiz,dx,dy,dz,x,y,z);\n}\n\n\ndouble Laplacian(double phi[][DATAYSIZE][DATAXSIZE],\n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  double phixx = (phi[x+1][y][z] + phi[x-1][y][z] - 2.0 * phi[x][y][z]) / SQ(dx);\n  double phiyy = (phi[x][y+1][z] + phi[x][y-1][z] - 2.0 * phi[x][y][z]) / SQ(dy);\n  double phizz = (phi[x][y][z+1] + phi[x][y][z-1] - 2.0 * phi[x][y][z]) / SQ(dz);\n  return phixx + phiyy + phizz;\n}\n\n\ndouble An(double phix, double phiy, double phiz, double epsilon)\n{\n  if (phix != 0.0 || phiy != 0.0 || phiz != 0.0){\n    return ((1.0 - 3.0 * epsilon) * (1.0 + (((4.0 * epsilon) / (1.0-3.0*epsilon))*\n           ((SQ(phix)*SQ(phix)+SQ(phiy)*SQ(phiy)+SQ(phiz)*SQ(phiz)) /\n           ((SQ(phix)+SQ(phiy)+SQ(phiz))*(SQ(phix)+SQ(phiy)+SQ(phiz)))))));\n  }\n  else\n  {\n    return (1.0-((5.0/3.0)*epsilon));\n  }\n}\n\n\ndouble Wn(double phix, double phiy, double phiz, double epsilon, double W0)\n{\n  return (W0*An(phix,phiy,phiz,epsilon));\n}\n\n\ndouble taun(double phix, double phiy, double phiz, double epsilon, double tau0)\n{\n  return tau0 * SQ(An(phix,phiy,phiz,epsilon));\n}\n\n\ndouble dFunc(double l, double m, double n)\n{\n  if (l != 0.0 || m != 0.0 || n != 0.0){\n    return (((l*l*l*(SQ(m)+SQ(n)))-(l*(SQ(m)*SQ(m)+SQ(n)*SQ(n)))) /\n            ((SQ(l)+SQ(m)+SQ(n))*(SQ(l)+SQ(m)+SQ(n))));\n  }\n  else\n  {\n    return 0.0;\n  }\n}\n\nvoid calculateForce(double phi[][DATAYSIZE][DATAXSIZE], \n                    double Fx[][DATAYSIZE][DATAXSIZE],\n                    double Fy[][DATAYSIZE][DATAXSIZE],\n                    double Fz[][DATAYSIZE][DATAXSIZE],\n                    double dx, double dy, double dz,\n                    double epsilon, double W0, double tau0)\n{\n    for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n\n        if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n            (iz < (DATAZSIZE-1)) && (ix > (0)) && \n            (iy > (0)) && (iz > (0))) {\n\n          double phix = GradientX(phi,dx,dy,dz,ix,iy,iz);\n          double phiy = GradientY(phi,dx,dy,dz,ix,iy,iz);\n          double phiz = GradientZ(phi,dx,dy,dz,ix,iy,iz);\n          double sqGphi = SQ(phix) + SQ(phiy) + SQ(phiz);\n          double c = 16.0 * W0 * epsilon;\n          double w = Wn(phix,phiy,phiz,epsilon,W0);\n          double w2 = SQ(w);\n          \n\n          Fx[ix][iy][iz] = w2 * phix + sqGphi * w * c * dFunc(phix,phiy,phiz);\n          Fy[ix][iy][iz] = w2 * phiy + sqGphi * w * c * dFunc(phiy,phiz,phix);\n          Fz[ix][iy][iz] = w2 * phiz + sqGphi * w * c * dFunc(phiz,phix,phiy);\n        }\n        else\n        {\n          Fx[ix][iy][iz] = 0.0;\n          Fy[ix][iy][iz] = 0.0;\n          Fz[ix][iy][iz] = 0.0;\n        }\n      }\n    }\n  }\n}\n\n\n\nvoid allenCahn(double phinew[][DATAYSIZE][DATAXSIZE], \n               double phiold[][DATAYSIZE][DATAXSIZE],\n               double uold[][DATAYSIZE][DATAXSIZE],\n               double Fx[][DATAYSIZE][DATAXSIZE],\n               double Fy[][DATAYSIZE][DATAXSIZE],\n               double Fz[][DATAYSIZE][DATAXSIZE],\n               double epsilon, double W0, double tau0, double lambda,\n               double dt, double dx, double dy, double dz)\n{\n    for (int ix = 1; ix < DATAXSIZE-1; ix++) {\n    for (int iy = 1; iy < DATAYSIZE-1; iy++) {\n      for (int iz = 1; iz < DATAZSIZE-1; iz++) {\n\n        double phix = GradientX(phiold,dx,dy,dz,ix,iy,iz);\n        double phiy = GradientY(phiold,dx,dy,dz,ix,iy,iz);\n        double phiz = GradientZ(phiold,dx,dy,dz,ix,iy,iz); \n\n        phinew[ix][iy][iz] = phiold[ix][iy][iz] + \n         (dt / taun(phix,phiy,phiz,epsilon,tau0)) * \n         (Divergence(Fx,Fy,Fz,dx,dy,dz,ix,iy,iz) - \n          dFphi(phiold[ix][iy][iz], uold[ix][iy][iz],lambda));\n      }\n    }\n  }\n}\n\nvoid boundaryConditionsPhi(double phinew[][DATAYSIZE][DATAXSIZE])\n{\n    for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n\n        if (ix == 0){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (ix == DATAXSIZE-1){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (iy == 0){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (iy == DATAYSIZE-1){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (iz == 0){\n          phinew[ix][iy][iz] = -1.0;\n        }\n        else if (iz == DATAZSIZE-1){\n          phinew[ix][iy][iz] = -1.0;\n        }\n      }\n    }\n  }\n}\n\nvoid thermalEquation(double unew[][DATAYSIZE][DATAXSIZE],\n                     double uold[][DATAYSIZE][DATAXSIZE],\n                     double phinew[][DATAYSIZE][DATAXSIZE],\n                     double phiold[][DATAYSIZE][DATAXSIZE],\n                     double D, double dt, double dx, double dy, double dz)\n{\n    for (int ix = 1; ix < DATAXSIZE-1; ix++) {\n    for (int iy = 1; iy < DATAYSIZE-1; iy++) {\n      for (int iz = 1; iz < DATAZSIZE-1; iz++) {\n\n        unew[ix][iy][iz] = uold[ix][iy][iz] + \n          0.5*(phinew[ix][iy][iz]-\n               phiold[ix][iy][iz]) +\n          dt * D * Laplacian(uold,dx,dy,dz,ix,iy,iz);\n      }\n    }\n  }\n}\n\nvoid boundaryConditionsU(double unew[][DATAYSIZE][DATAXSIZE], double delta)\n{\n    for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n\n        if (ix == 0){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (ix == DATAXSIZE-1){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (iy == 0){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (iy == DATAYSIZE-1){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (iz == 0){\n          unew[ix][iy][iz] =  -delta;\n        }\n        else if (iz == DATAZSIZE-1){\n          unew[ix][iy][iz] =  -delta;\n        }\n      }\n    }\n  }\n}\n\nvoid swapGrid(double cnew[][DATAYSIZE][DATAXSIZE],\n              double cold[][DATAYSIZE][DATAXSIZE])\n{\n    for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n        double tmp = cnew[ix][iy][iz];\n        cnew[ix][iy][iz] = cold[ix][iy][iz];\n        cold[ix][iy][iz] = tmp;\n      }\n    }\n  }\n}\n\nvoid initializationPhi(double phi[][DATAYSIZE][DATAXSIZE], double r0)\n{\n    for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n        double r = std::sqrt(SQ(ix-0.5*DATAXSIZE) + SQ(iy-0.5*DATAYSIZE) + SQ(iz-0.5*DATAZSIZE));\n        if (r < r0){\n          phi[ix][iy][iz] = 1.0;\n        }\n        else\n        {\n          phi[ix][iy][iz] = -1.0;\n        }\n      }\n    }\n  }\n}\n\nvoid initializationU(double u[][DATAYSIZE][DATAXSIZE], double r0, double delta)\n{\n    for (int ix = 0; ix < DATAXSIZE; ix++) {\n    for (int iy = 0; iy < DATAYSIZE; iy++) {\n      for (int iz = 0; iz < DATAZSIZE; iz++) {\n        double r = std::sqrt(SQ(ix-0.5*DATAXSIZE) + SQ(iy-0.5*DATAYSIZE) + SQ(iz-0.5*DATAZSIZE));\n        if (r < r0) {\n          u[ix][iy][iz] = 0.0;\n        }\n        else\n        {\n          u[ix][iy][iz] = -delta * (1.0 - std::exp(-(r-r0)));\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  const int num_steps = atoi(argv[1]);  \n\n  const double dx = 0.4;\n  const double dy = 0.4;\n  const double dz = 0.4;\n  const double dt = 0.01;\n  const double delta = 0.8;\n  const double r0 = 5.0;\n  const double epsilon = 0.07;\n  const double W0 = 1.0;\n  const double beta0 = 0.0;\n  const double D = 2.0;\n  const double d0 = 0.5;\n  const double a1 = 1.25 / std::sqrt(2.0);\n  const double a2 = 0.64;\n  const double lambda = (W0*a1)/(d0);\n  const double tau0 = ((W0*W0*W0*a1*a2)/(d0*D)) + ((W0*W0*beta0)/(d0));\n\n  \n\n  const int nx = DATAXSIZE;\n  const int ny = DATAYSIZE;\n  const int nz = DATAZSIZE;\n  const int vol = nx * ny * nz;\n  const size_t vol_in_bytes = sizeof(double) * vol;\n\n  \n\n  nRarray *phi_host = (nRarray *)malloc(vol_in_bytes);\n  nRarray *u_host = (nRarray *)malloc(vol_in_bytes);\n  initializationPhi(phi_host,r0);\n  initializationU(u_host,r0,delta);\n\n#ifdef VERIFY\n  nRarray *phi_ref = (nRarray *)malloc(vol_in_bytes);\n  nRarray *u_ref = (nRarray *)malloc(vol_in_bytes);\n  memcpy(phi_ref, phi_host, vol_in_bytes);\n  memcpy(u_ref, u_host, vol_in_bytes);\n  reference(phi_ref, u_ref, vol, num_steps);\n#endif \n\n  auto offload_start = std::chrono::steady_clock::now();\n\n  \n\n  double *d_phiold = (double*)phi_host;\n  double *d_uold = (double*)u_host;\n  double *d_phinew = (double*) malloc (vol_in_bytes);\n  double *d_unew = (double*) malloc (vol_in_bytes);\n  double *d_Fx = (double*) malloc (vol_in_bytes);\n  double *d_Fy = (double*) malloc (vol_in_bytes);\n  double *d_Fz = (double*) malloc (vol_in_bytes);\n\n    {\n    int t = 0;\n\n    auto start = std::chrono::steady_clock::now();\n  \n    while (t <= num_steps) {\n  \n      calculateForce((nRarray*)d_phiold, (nRarray*)d_Fx,(nRarray*)d_Fy,(nRarray*)d_Fz,\n                     dx,dy,dz,epsilon,W0,tau0);\n  \n      allenCahn((nRarray*)d_phinew,(nRarray*)d_phiold,(nRarray*)d_uold,\n                (nRarray*)d_Fx,(nRarray*)d_Fy,(nRarray*)d_Fz,\n                epsilon,W0,tau0,lambda, dt,dx,dy,dz);\n  \n      boundaryConditionsPhi((nRarray*)d_phinew);\n  \n      thermalEquation((nRarray*)d_unew,(nRarray*)d_uold,(nRarray*)d_phinew,(nRarray*)d_phiold,\n                      D,dt,dx,dy,dz);\n  \n      boundaryConditionsU((nRarray*)d_unew,delta);\n  \n      swapGrid((nRarray*)d_phinew, (nRarray*)d_phiold);\n  \n      swapGrid((nRarray*)d_unew, (nRarray*)d_uold);\n  \n      t++;\n    }\n  \n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Total kernel execution time: %.3f (ms)\\n\", time * 1e-6f);\n  }\n\n  auto offload_end = std::chrono::steady_clock::now();\n  auto offload_time = std::chrono::duration_cast<std::chrono::nanoseconds>(offload_end - offload_start).count();\n  printf(\"Offload time: %.3f (ms)\\n\", offload_time * 1e-6f);\n\n#ifdef VERIFY\n  bool ok = true;\n  for (int idx = 0; idx < nx; idx++)\n    for (int idy = 0; idy < ny; idy++)\n      for (int idz = 0; idz < nz; idz++) {\n        if (fabs(phi_ref[idx][idy][idz] - phi_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"phi: %lf %lf\\n\", phi_ref[idx][idy][idz], phi_host[idx][idy][idz]);\n\t}\n        if (fabs(u_ref[idx][idy][idz] - u_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"u: %lf %lf\\n\", u_ref[idx][idy][idz], u_host[idx][idy][idz]);\n        }\n      }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(phi_ref);\n  free(u_ref);\n#endif\n\n  free(phi_host);\n  free(u_host);\n  free(d_phinew);\n  free(d_unew);\n  free(d_Fx);\n  free(d_Fy);\n  free(d_Fz);\n  return 0;\n}"}}
{"kernel_name": "ace", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n\n\n#define DATAXSIZE 400\n#define DATAYSIZE 400\n#define DATAZSIZE 400\n\ntypedef double nRarray[DATAYSIZE][DATAXSIZE];\n\n\n\n#define SQ(x) ((x)*(x))\n\n#ifdef VERIFY\n#include <string.h>\n#include \"reference.h\"\n#endif\n\ndouble dFphi(double phi, double u, double lambda)\n{\n  return (-phi*(1.0-phi*phi)+lambda*u*(1.0-phi*phi)*(1.0-phi*phi));\n}\n\n\ndouble GradientX(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x+1][y][z] - phi[x-1][y][z]) / (2.0*dx);\n}\n\n\ndouble GradientY(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y+1][z] - phi[x][y-1][z]) / (2.0*dy);\n}\n\n\ndouble GradientZ(double phi[][DATAYSIZE][DATAXSIZE], \n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  return (phi[x][y][z+1] - phi[x][y][z-1]) / (2.0*dz);\n}\n\n\ndouble Divergence(double phix[][DATAYSIZE][DATAXSIZE], \n                  double phiy[][DATAYSIZE][DATAXSIZE],\n                  double phiz[][DATAYSIZE][DATAXSIZE], \n                  double dx, double dy, double dz, int x, int y, int z)\n{\n  return GradientX(phix,dx,dy,dz,x,y,z) + \n         GradientY(phiy,dx,dy,dz,x,y,z) +\n         GradientZ(phiz,dx,dy,dz,x,y,z);\n}\n\n\ndouble Laplacian(double phi[][DATAYSIZE][DATAXSIZE],\n                 double dx, double dy, double dz, int x, int y, int z)\n{\n  double phixx = (phi[x+1][y][z] + phi[x-1][y][z] - 2.0 * phi[x][y][z]) / SQ(dx);\n  double phiyy = (phi[x][y+1][z] + phi[x][y-1][z] - 2.0 * phi[x][y][z]) / SQ(dy);\n  double phizz = (phi[x][y][z+1] + phi[x][y][z-1] - 2.0 * phi[x][y][z]) / SQ(dz);\n  return phixx + phiyy + phizz;\n}\n\n\ndouble An(double phix, double phiy, double phiz, double epsilon)\n{\n  if (phix != 0.0 || phiy != 0.0 || phiz != 0.0){\n    return ((1.0 - 3.0 * epsilon) * (1.0 + (((4.0 * epsilon) / (1.0-3.0*epsilon))*\n           ((SQ(phix)*SQ(phix)+SQ(phiy)*SQ(phiy)+SQ(phiz)*SQ(phiz)) /\n           ((SQ(phix)+SQ(phiy)+SQ(phiz))*(SQ(phix)+SQ(phiy)+SQ(phiz)))))));\n  }\n  else\n  {\n    return (1.0-((5.0/3.0)*epsilon));\n  }\n}\n\n\ndouble Wn(double phix, double phiy, double phiz, double epsilon, double W0)\n{\n  return (W0*An(phix,phiy,phiz,epsilon));\n}\n\n\ndouble taun(double phix, double phiy, double phiz, double epsilon, double tau0)\n{\n  return tau0 * SQ(An(phix,phiy,phiz,epsilon));\n}\n\n\ndouble dFunc(double l, double m, double n)\n{\n  if (l != 0.0 || m != 0.0 || n != 0.0){\n    return (((l*l*l*(SQ(m)+SQ(n)))-(l*(SQ(m)*SQ(m)+SQ(n)*SQ(n)))) /\n            ((SQ(l)+SQ(m)+SQ(n))*(SQ(l)+SQ(m)+SQ(n))));\n  }\n  else\n  {\n    return 0.0;\n  }\n}\n\nvoid calculateForce(double phi[][DATAYSIZE][DATAXSIZE], \n                    double Fx[][DATAYSIZE][DATAXSIZE],\n                    double Fy[][DATAYSIZE][DATAXSIZE],\n                    double Fz[][DATAYSIZE][DATAXSIZE],\n                    double dx, double dy, double dz,\n                    double epsilon, double W0, double tau0,\n                    sycl::nd_item<3> &item)\n{\n\n  unsigned iz = item.get_global_id(2);\n  unsigned iy = item.get_global_id(1);\n  unsigned ix = item.get_global_id(0);\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))) {\n\n    double phix = GradientX(phi,dx,dy,dz,ix,iy,iz);\n    double phiy = GradientY(phi,dx,dy,dz,ix,iy,iz);\n    double phiz = GradientZ(phi,dx,dy,dz,ix,iy,iz);\n    double sqGphi = SQ(phix) + SQ(phiy) + SQ(phiz);\n    double c = 16.0 * W0 * epsilon;\n    double w = Wn(phix,phiy,phiz,epsilon,W0);\n    double w2 = SQ(w);\n    \n\n    Fx[ix][iy][iz] = w2 * phix + sqGphi * w * c * dFunc(phix,phiy,phiz);\n    Fy[ix][iy][iz] = w2 * phiy + sqGphi * w * c * dFunc(phiy,phiz,phix);\n    Fz[ix][iy][iz] = w2 * phiz + sqGphi * w * c * dFunc(phiz,phix,phiy);\n  }\n  else\n  {\n    Fx[ix][iy][iz] = 0.0;\n    Fy[ix][iy][iz] = 0.0;\n    Fz[ix][iy][iz] = 0.0;\n  }\n\n}\n\n\n\nvoid allenCahn(double phinew[][DATAYSIZE][DATAXSIZE], \n               double phiold[][DATAYSIZE][DATAXSIZE],\n               double uold[][DATAYSIZE][DATAXSIZE],\n               double Fx[][DATAYSIZE][DATAXSIZE],\n               double Fy[][DATAYSIZE][DATAXSIZE],\n               double Fz[][DATAYSIZE][DATAXSIZE],\n               double epsilon, double W0, double tau0, double lambda,\n               double dt, double dx, double dy, double dz,\n               sycl::nd_item<3> &item)\n{\n  unsigned iz = item.get_global_id(2);\n  unsigned iy = item.get_global_id(1);\n  unsigned ix = item.get_global_id(0);\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))) {\n\n    double phix = GradientX(phiold,dx,dy,dz,ix,iy,iz);\n    double phiy = GradientY(phiold,dx,dy,dz,ix,iy,iz);\n    double phiz = GradientZ(phiold,dx,dy,dz,ix,iy,iz); \n\n    phinew[ix][iy][iz] = phiold[ix][iy][iz] + \n     (dt / taun(phix,phiy,phiz,epsilon,tau0)) * \n     (Divergence(Fx,Fy,Fz,dx,dy,dz,ix,iy,iz) - \n      dFphi(phiold[ix][iy][iz], uold[ix][iy][iz],lambda));\n  }\n}\n\n\nvoid boundaryConditionsPhi(double phinew[][DATAYSIZE][DATAXSIZE],\n                           sycl::nd_item<3> &item)\n{\n  unsigned iz = item.get_global_id(2);\n  unsigned iy = item.get_global_id(1);\n  unsigned ix = item.get_global_id(0);\n\n  if (ix == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (ix == DATAXSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iy == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iy == DATAYSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iz == 0){\n    phinew[ix][iy][iz] = -1.0;\n  }\n  else if (iz == DATAZSIZE-1){\n    phinew[ix][iy][iz] = -1.0;\n  }\n}\n\n\nvoid thermalEquation(double unew[][DATAYSIZE][DATAXSIZE],\n                     double uold[][DATAYSIZE][DATAXSIZE],\n                     double phinew[][DATAYSIZE][DATAXSIZE],\n                     double phiold[][DATAYSIZE][DATAXSIZE],\n                     double D, double dt, double dx, double dy, double dz,\n                     sycl::nd_item<3> &item)\n{\n  unsigned iz = item.get_global_id(2);\n  unsigned iy = item.get_global_id(1);\n  unsigned ix = item.get_global_id(0);\n\n  if ((ix < (DATAXSIZE-1)) && (iy < (DATAYSIZE-1)) && \n      (iz < (DATAZSIZE-1)) && (ix > (0)) && \n      (iy > (0)) && (iz > (0))){\n    unew[ix][iy][iz] = uold[ix][iy][iz] + \n      0.5*(phinew[ix][iy][iz]- phiold[ix][iy][iz]) +\n      dt * D * Laplacian(uold,dx,dy,dz,ix,iy,iz);\n  }\n}\n\n\nvoid boundaryConditionsU(double unew[][DATAYSIZE][DATAXSIZE], double delta,\n                         sycl::nd_item<3> &item)\n{\n  unsigned iz = item.get_global_id(2);\n  unsigned iy = item.get_global_id(1);\n  unsigned ix = item.get_global_id(0);\n\n  if (ix == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (ix == DATAXSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iy == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iy == DATAYSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iz == 0){\n    unew[ix][iy][iz] =  -delta;\n  }\n  else if (iz == DATAZSIZE-1){\n    unew[ix][iy][iz] =  -delta;\n  }\n}\n\n\nvoid swapGrid(double cnew[][DATAYSIZE][DATAXSIZE],\n              double cold[][DATAYSIZE][DATAXSIZE],\n              sycl::nd_item<3> &item)\n{\n  unsigned iz = item.get_global_id(2);\n  unsigned iy = item.get_global_id(1);\n  unsigned ix = item.get_global_id(0);\n\n  if ((ix < (DATAXSIZE)) && \n      (iy < (DATAYSIZE)) &&\n      (iz < (DATAZSIZE))) {\n    double tmp = cnew[ix][iy][iz];\n    cnew[ix][iy][iz] = cold[ix][iy][iz];\n    cold[ix][iy][iz] = tmp;\n  }\n}\n\nvoid initializationPhi(double phi[][DATAYSIZE][DATAXSIZE], double r0)\n{\n#ifdef _OPENMP\n  #pragma omp parallel for collapse(3)\n#endif\n  for (int idx = 0; idx < DATAXSIZE; idx++) {\n    for (int idy = 0; idy < DATAYSIZE; idy++) {\n      for (int idz = 0; idz < DATAZSIZE; idz++) {\n        double r = std::sqrt(SQ(idx-0.5*DATAXSIZE) + SQ(idy-0.5*DATAYSIZE) + SQ(idz-0.5*DATAZSIZE));\n        if (r < r0){\n          phi[idx][idy][idz] = 1.0;\n        }\n        else\n        {\n          phi[idx][idy][idz] = -1.0;\n        }\n      }\n    }\n  }\n}\n\nvoid initializationU(double u[][DATAYSIZE][DATAXSIZE], double r0, double delta)\n{\n#ifdef _OPENMP\n  #pragma omp parallel for collapse(3)\n#endif\n  for (int idx = 0; idx < DATAXSIZE; idx++) {\n    for (int idy = 0; idy < DATAYSIZE; idy++) {\n      for (int idz = 0; idz < DATAZSIZE; idz++) {\n        double r = std::sqrt(SQ(idx-0.5*DATAXSIZE) + SQ(idy-0.5*DATAYSIZE) + SQ(idz-0.5*DATAZSIZE));\n        if (r < r0) {\n          u[idx][idy][idz] = 0.0;\n        }\n        else\n        {\n          u[idx][idy][idz] = -delta * (1.0 - std::exp(-(r-r0)));\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  const int num_steps = atoi(argv[1]);  \n\n  const double dx = 0.4;\n  const double dy = 0.4;\n  const double dz = 0.4;\n  const double dt = 0.01;\n  const double delta = 0.8;\n  const double r0 = 5.0;\n  const double epsilon = 0.07;\n  const double W0 = 1.0;\n  const double beta0 = 0.0;\n  const double D = 2.0;\n  const double d0 = 0.5;\n  const double a1 = 1.25 / std::sqrt(2.0);\n  const double a2 = 0.64;\n  const double lambda = (W0*a1)/(d0);\n  const double tau0 = ((W0*W0*W0*a1*a2)/(d0*D)) + ((W0*W0*beta0)/(d0));\n\n  \n\n  const int nx = DATAXSIZE;\n  const int ny = DATAYSIZE;\n  const int nz = DATAZSIZE;\n  const int vol = nx * ny * nz;\n  const size_t vol_in_bytes = sizeof(double) * vol;\n\n  \n\n  nRarray *phi_host;\n  nRarray *u_host;\n\n  phi_host = (nRarray *)malloc(vol_in_bytes);\n  u_host = (nRarray *)malloc(vol_in_bytes);\n\n  initializationPhi(phi_host,r0);\n  initializationU(u_host,r0,delta);\n\n#ifdef VERIFY\n  nRarray *phi_ref = (nRarray *)malloc(vol_in_bytes);\n  nRarray *u_ref = (nRarray *)malloc(vol_in_bytes);\n  memcpy(phi_ref, phi_host, vol_in_bytes);\n  memcpy(u_ref, u_host, vol_in_bytes);\n  reference(phi_ref, u_ref, vol, num_steps);\n#endif \n\n  auto offload_start = std::chrono::steady_clock::now();\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  nRarray *d_phiold = (nRarray*) sycl::malloc_device(vol_in_bytes, q);\n  nRarray *d_uold = (nRarray*) sycl::malloc_device(vol_in_bytes, q);\n  nRarray *d_phinew = (nRarray*) sycl::malloc_device(vol_in_bytes, q);\n  nRarray *d_unew = (nRarray*) sycl::malloc_device(vol_in_bytes, q);\n  nRarray *d_Fx = (nRarray*) sycl::malloc_device(vol_in_bytes, q);\n  nRarray *d_Fy = (nRarray*) sycl::malloc_device(vol_in_bytes, q);\n  nRarray *d_Fz = (nRarray*) sycl::malloc_device(vol_in_bytes, q);\n\n  q.memcpy(d_phiold, phi_host, vol_in_bytes);\n  q.memcpy(d_uold, u_host, vol_in_bytes);\n\n  \n\n  sycl::range<3> gws ((DATAXSIZE+3)/4*4, (DATAYSIZE+7)/8*8, (DATAZSIZE+7)/8*8);\n  sycl::range<3> lws (4, 8, 8);\n\n  int t = 0;\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  while (t <= num_steps) {\n    \n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class calc_force>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        calculateForce(d_phiold,\n                       d_Fx,\n                       d_Fy,\n                       d_Fz,\n                       dx,dy,dz,epsilon,W0,tau0,\n                       item);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class allen_cahn>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        allenCahn(d_phinew,\n                  d_phiold,\n                  d_uold,\n                  d_Fx,\n                  d_Fy,\n                  d_Fz,\n                  epsilon,W0,tau0,lambda,\n                  dt,dx,dy,dz,\n                  item);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class bc_phi>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        boundaryConditionsPhi(d_phinew, item);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class thermal_equation>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        thermalEquation(d_unew,\n                        d_uold,\n                        d_phinew,\n                        d_phiold,\n                        D,dt,dx,dy,dz,\n                        item);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class bc_u>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        boundaryConditionsU(d_unew, delta, item);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class swap_phi>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        swapGrid(d_phinew, d_phiold, item);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class swap_u>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        swapGrid(d_unew, d_uold, item);\n      });\n    });\n\n    t++;\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %.3f (ms)\\n\", time * 1e-6f);\n\n  q.memcpy(phi_host, d_phiold, vol_in_bytes);\n  q.memcpy(u_host, d_uold, vol_in_bytes);\n  q.wait();\n\n  sycl::free(d_phiold, q);\n  sycl::free(d_phinew, q);\n  sycl::free(d_uold, q);\n  sycl::free(d_unew, q);\n  sycl::free(d_Fx, q);\n  sycl::free(d_Fy, q);\n  sycl::free(d_Fz, q);\n\n  auto offload_end = std::chrono::steady_clock::now();\n  auto offload_time = std::chrono::duration_cast<std::chrono::nanoseconds>(offload_end - offload_start).count();\n  printf(\"Offload time: %.3f (ms)\\n\", offload_time * 1e-6f);\n\n#ifdef VERIFY\n  bool ok = true;\n  for (int idx = 0; idx < nx; idx++)\n    for (int idy = 0; idy < ny; idy++)\n      for (int idz = 0; idz < nz; idz++) {\n        if (fabs(phi_ref[idx][idy][idz] - phi_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"phi: %lf %lf\\n\", phi_ref[idx][idy][idz], phi_host[idx][idy][idz]);\n\t}\n        if (fabs(u_ref[idx][idy][idz] - u_host[idx][idy][idz]) > 1e-3) {\n          ok = false; printf(\"u: %lf %lf\\n\", u_ref[idx][idy][idz], u_host[idx][idy][idz]);\n        }\n      }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(phi_ref);\n  free(u_ref);\n#endif\n\n  free(phi_host);\n  free(u_host);\n\n  return 0;\n}\n"}}
{"kernel_name": "addBiasResidualLayerNorm", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include <cuda_fp16.h>\n#include <cuda_bf16.h>\n#include \"kernels.h\"\n\n\n\ntemplate<typename T, int V>\nvoid invokeAddBiasResidualLayerNorm(\n          T*     out,\n    const T*     input,\n    const T*     bias,\n    const T*     gamma,\n    const T*     beta,\n    const float  layernorm_eps,\n    int          m,\n    int          n)\n{\n  dim3 grid(m);\n  dim3 block(std::min(n, 256));\n\n  if (V == 2) { \n\n    addBiasResidualPostLayerNormV2<T><<<grid, n / 8>>>(out, input, bias, gamma, beta, layernorm_eps, n);\n  }\n  else {\n    int num_trips = (n + block.x - 1) / block.x;\n    if (num_trips == 1) {\n      addBiasResidualPostLayerNorm<T, 1>\n        <<<grid, block>>>(out, input, bias, gamma, beta, layernorm_eps, n);\n    }\n    else if (num_trips == 2) {\n      addBiasResidualPostLayerNorm<T, 2>\n        <<<grid, block>>>(out, input, bias, gamma, beta, layernorm_eps, n);\n    }\n    else {\n      generalAddBiasResidualPostLayerNorm<T>\n        <<<grid, block>>>(out, input, bias, gamma, beta, layernorm_eps, n);\n    }\n  }\n}\n\ntemplate<typename T, int V>\nvoid layer(int repeat) {\n\n  const int m = 4096;  \n\n\n  int dim[] = {256, 512, 768, 1024, 2048, 4096, 8192};\n\n  for (int i = 0; i < sizeof(dim) / sizeof(int); i++) {\n\n    std::mt19937 gen (19937);\n    std::uniform_real_distribution<float> dis(0.f, 1.f);\n\n    \n\n    const int n = dim[i]; \n    const int input_size = m * n;\n    const int output_size = m * n;\n    const int input_size_bytes = input_size * sizeof(T);\n    const int output_size_bytes = output_size * sizeof(T);\n    const int bias_size_bytes = n * sizeof(T);\n    const int beta_size_bytes = n * sizeof(T);\n    const int gamma_size_bytes = n * sizeof(T);\n\n    T *h_input = (T*) malloc (input_size_bytes);\n    T *h_output = (T*) malloc (output_size_bytes);\n    T *h_bias = (T*) malloc (bias_size_bytes);\n    T *h_gamma = (T*) malloc (gamma_size_bytes);\n    T *h_beta = (T*) malloc (beta_size_bytes);\n\n    for (int i = 0; i < input_size; i++) {\n      h_input[i] = (T) dis(gen);\n    }\n    for (int i = 0; i < n; i++) {\n      h_bias[i] = (T) dis(gen);\n      h_gamma[i] = (T) dis(gen);\n      h_beta[i] = (T) dis(gen);\n    }\n\n    float layernorm_eps = 1e-6;\n    T *d_input, *d_output, *d_bias, *d_gamma, *d_beta;\n    cudaMalloc((void**)&d_input, input_size_bytes);\n    cudaMemcpy(d_input, h_input, input_size_bytes, cudaMemcpyHostToDevice);\n\n    cudaMalloc((void**)&d_output,  output_size_bytes);\n    cudaMemset(d_output,  0, output_size_bytes); \n\n\n    cudaMalloc((void**)&d_bias,  bias_size_bytes);\n    cudaMemcpy(d_bias, h_bias, bias_size_bytes, cudaMemcpyHostToDevice);\n\n    cudaMalloc((void**)&d_gamma,  gamma_size_bytes);\n    cudaMemcpy(d_gamma, h_gamma, gamma_size_bytes, cudaMemcpyHostToDevice);\n\n    cudaMalloc((void**)&d_beta,  beta_size_bytes);\n    cudaMemcpy(d_beta, h_beta, beta_size_bytes, cudaMemcpyHostToDevice);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      invokeAddBiasResidualLayerNorm<T, V>\n          (d_output, d_input, d_bias, d_gamma, d_beta, layernorm_eps, m, n);\n    }\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of AddBiasResidualLayerNorm (%d x %d): %f (us)\\n\",\n           m, n, (time * 1e-3f) / repeat);\n\n    cudaMemcpy(h_output, d_output, output_size_bytes, cudaMemcpyDeviceToHost);\n\n    float s = 0;\n    for (int i = 0; i < output_size; i++)\n      s += float(h_output[i]);\n\n    printf(\"Checksum = %f\\n\", s / (n * n));\n    \n    cudaFree(d_input);\n    cudaFree(d_output);\n    cudaFree(d_bias);\n    cudaFree(d_gamma);\n    cudaFree(d_beta);\n\n    free(h_input);\n    free(h_output);\n    free(h_bias);\n    free(h_gamma);\n    free(h_beta);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  printf(\"---------------- float16 (version 1) -------------\\n\");\n  layer<half, 1>(repeat);\n  printf(\"---------------- float16 (version 2) -------------\\n\");\n  layer<half, 2>(repeat);\n\n  printf(\"---------------- bfloat16 (version 1) -------------\\n\");\n  layer<__nv_bfloat16, 1>(repeat);\n  printf(\"---------------- bfloat16 (version 2) -------------\\n\");\n  layer<__nv_bfloat16, 2>(repeat);\n  return 0;\n}\n"}}
{"kernel_name": "addBiasResidualLayerNorm", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include <hip/hip_fp16.h>\n#include <hip/hip_bf16.h>\n#include \"kernels.h\"\n\ntemplate<typename T, int V>\nvoid invokeAddBiasResidualLayerNorm(\n          T*     out,\n    const T*     input,\n    const T*     bias,\n    const T*     gamma,\n    const T*     beta,\n    const float  layernorm_eps,\n    int          m,\n    int          n)\n{\n  dim3 grid(m);\n  dim3 block(std::min(n, 256));\n\n  if (V == 2) { \n\n    addBiasResidualPostLayerNormV2<T><<<grid, n / 8>>>(out, input, bias, gamma, beta, layernorm_eps, n);\n  }\n  else {\n    int num_trips = (n + block.x - 1) / block.x;\n    if (num_trips == 1) {\n      addBiasResidualPostLayerNorm<T, 1>\n        <<<grid, block>>>(out, input, bias, gamma, beta, layernorm_eps, n);\n    }\n    else if (num_trips == 2) {\n      addBiasResidualPostLayerNorm<T, 2>\n        <<<grid, block>>>(out, input, bias, gamma, beta, layernorm_eps, n);\n    }\n    else {\n      generalAddBiasResidualPostLayerNorm<T>\n        <<<grid, block>>>(out, input, bias, gamma, beta, layernorm_eps, n);\n    }\n  }\n}\n\ntemplate<typename T, int V>\nvoid layer(int repeat) {\n\n  const int m = 4096;  \n\n\n  int dim[] = {256, 512, 768, 1024, 2048, 4096, 8192};\n\n  for (int i = 0; i < sizeof(dim) / sizeof(int); i++) {\n\n    std::mt19937 gen (19937);\n    std::uniform_real_distribution<float> dis(0.f, 1.f);\n\n    \n\n    const int n = dim[i]; \n    const int input_size = m * n;\n    const int output_size = m * n;\n    const int input_size_bytes = input_size * sizeof(T);\n    const int output_size_bytes = output_size * sizeof(T);\n    const int bias_size_bytes = n * sizeof(T);\n    const int beta_size_bytes = n * sizeof(T);\n    const int gamma_size_bytes = n * sizeof(T);\n\n    T *h_input = (T*) malloc (input_size_bytes);\n    T *h_output = (T*) malloc (output_size_bytes);\n    T *h_bias = (T*) malloc (bias_size_bytes);\n    T *h_gamma = (T*) malloc (gamma_size_bytes);\n    T *h_beta = (T*) malloc (beta_size_bytes);\n\n    for (int i = 0; i < input_size; i++) {\n      h_input[i] = floatToType<T>(dis(gen));\n    }\n    for (int i = 0; i < n; i++) {\n      h_bias[i] = floatToType<T>(dis(gen));\n      h_gamma[i] = floatToType<T>(dis(gen));\n      h_beta[i] = floatToType<T>(dis(gen));\n    }\n\n    float layernorm_eps = 1e-6;\n    T *d_input, *d_output, *d_bias, *d_gamma, *d_beta;\n    hipMalloc((void**)&d_input, input_size_bytes);\n    hipMemcpy(d_input, h_input, input_size_bytes, hipMemcpyHostToDevice);\n\n    hipMalloc((void**)&d_output,  output_size_bytes);\n    hipMemset(d_output,  0, output_size_bytes); \n\n\n    hipMalloc((void**)&d_bias,  bias_size_bytes);\n    hipMemcpy(d_bias, h_bias, bias_size_bytes, hipMemcpyHostToDevice);\n\n    hipMalloc((void**)&d_gamma,  gamma_size_bytes);\n    hipMemcpy(d_gamma, h_gamma, gamma_size_bytes, hipMemcpyHostToDevice);\n\n    hipMalloc((void**)&d_beta,  beta_size_bytes);\n    hipMemcpy(d_beta, h_beta, beta_size_bytes, hipMemcpyHostToDevice);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      invokeAddBiasResidualLayerNorm<T, V>\n          (d_output, d_input, d_bias, d_gamma, d_beta, layernorm_eps, m, n);\n    }\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of AddBiasResidualLayerNorm (%d x %d): %f (us)\\n\",\n           m, n, (time * 1e-3f) / repeat);\n\n    hipMemcpy(h_output, d_output, output_size_bytes, hipMemcpyDeviceToHost);\n\n    float s = 0;\n    for (int i = 0; i < output_size; i++)\n      s += typeToFloat(h_output[i]);\n\n    printf(\"Checksum = %f\\n\", s / (n * n));\n    \n    hipFree(d_input);\n    hipFree(d_output);\n    hipFree(d_bias);\n    hipFree(d_gamma);\n    hipFree(d_beta);\n\n    free(h_input);\n    free(h_output);\n    free(h_bias);\n    free(h_gamma);\n    free(h_beta);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  printf(\"---------------- float16 (version 1) -------------\\n\");\n  layer<half, 1>(repeat);\n  printf(\"---------------- float16 (version 2) -------------\\n\");\n  layer<half, 2>(repeat);\n\n  printf(\"---------------- bfloat16 (version 1) -------------\\n\");\n  layer<__hip_bfloat16, 1>(repeat);\n  printf(\"---------------- bfloat16 (version 2) -------------\\n\");\n  layer<__hip_bfloat16, 2>(repeat);\n  return 0;\n}\n"}}
{"kernel_name": "addBiasResidualLayerNorm", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n\ntemplate<typename T, int V>\nvoid invokeAddBiasResidualLayerNorm(\n    sycl::queue &q,\n          T*     out,\n    const T*     input,\n    const T*     bias,\n    const T*     gamma,\n    const T*     beta,\n    const float  layernorm_eps,\n    int          m,\n    int          n)\n{\n  if (V == 2) {\n\n    sycl::range<1> gws (m * n / 8);\n    sycl::range<1> lws (n / 8);\n\n    q.submit([&](sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> shared(sycl::range<1>(32), cgh);\n      sycl::local_accessor<float, 0> s_mean(cgh);\n      sycl::local_accessor<float, 0> s_variance(cgh);\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n        [[intel::reqd_sub_group_size(32)]] {\n        addBiasResidualPostLayerNormV2<T>(\n          out, input, bias, gamma, beta, layernorm_eps,\n          n, item, shared.get_pointer(),\n          s_mean, s_variance);\n      });\n    });\n  }\n  else {\n    sycl::range<1> gws (m * std::min(n, 256));\n    sycl::range<1> lws (std::min(n, 256));\n\n    int num_trips = (n + lws[0] - 1) / lws[0];\n    if (num_trips == 1) {\n      q.submit([&](sycl::handler &cgh) {\n        sycl::local_accessor<float, 1> shared(sycl::range<1>(32), cgh);\n        sycl::local_accessor<float, 0> s_mean(cgh);\n        sycl::local_accessor<float, 0> s_variance(cgh);\n\n        cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n          [[intel::reqd_sub_group_size(32)]] {\n          addBiasResidualPostLayerNorm<T, 1>(\n            out, input, bias, gamma, beta, layernorm_eps,\n            n, item, shared.get_pointer(),\n            s_mean, s_variance);\n        });\n      });\n    }\n    else if (num_trips == 2) {\n      q.submit([&](sycl::handler &cgh) {\n        sycl::local_accessor<float, 1> shared(sycl::range<1>(32), cgh);\n        sycl::local_accessor<float, 0> s_mean(cgh);\n        sycl::local_accessor<float, 0> s_variance(cgh);\n\n        cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n          [[intel::reqd_sub_group_size(32)]] {\n          addBiasResidualPostLayerNorm<T, 2>(\n            out, input, bias, gamma, beta, layernorm_eps,\n            n, item, shared.get_pointer(),\n            s_mean, s_variance);\n        });\n      });\n    }\n    else {\n      q.submit([&](sycl::handler &cgh) {\n        sycl::local_accessor<float, 1> shared(sycl::range<1>(32), cgh);\n        sycl::local_accessor<float, 0> s_mean(cgh);\n        sycl::local_accessor<float, 0> s_variance(cgh);\n\n        cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n          [[intel::reqd_sub_group_size(32)]] {\n          generalAddBiasResidualPostLayerNorm<T>(\n            out, input, bias, gamma, beta, layernorm_eps,\n            n, item, shared.get_pointer(),\n            s_mean, s_variance);\n        });\n      });\n    }\n  }\n}\n\ntemplate<typename T, int V>\nvoid layer(int repeat) {\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  const int m = 4096;  \n\n\n  int dim[] = {256, 512, 768, 1024, 2048, 4096, 8192};\n\n  for (int i = 0; i < sizeof(dim) / sizeof(int); i++) {\n\n    std::mt19937 gen (19937);\n    std::uniform_real_distribution<float> dis(0.f, 1.f);\n\n    \n\n    const int n = dim[i]; \n    const int input_size = m * n;\n    const int output_size = m * n;\n    const int input_size_bytes = input_size * sizeof(T);\n    const int output_size_bytes = output_size * sizeof(T);\n    const int bias_size_bytes = n * sizeof(T);\n    const int beta_size_bytes = n * sizeof(T);\n    const int gamma_size_bytes = n * sizeof(T);\n\n    T *h_input = (T*) malloc (input_size_bytes);\n    T *h_output = (T*) malloc (output_size_bytes);\n    T *h_bias = (T*) malloc (bias_size_bytes);\n    T *h_gamma = (T*) malloc (gamma_size_bytes);\n    T *h_beta = (T*) malloc (beta_size_bytes);\n\n    for (int i = 0; i < input_size; i++) {\n      h_input[i] = (T) dis(gen);\n    }\n    for (int i = 0; i < n; i++) {\n      h_bias[i] = (T) dis(gen);\n      h_gamma[i] = (T) dis(gen);\n      h_beta[i] = (T) dis(gen);\n    }\n\n    float layernorm_eps = 1e-6;\n    T *d_input, *d_output, *d_bias, *d_gamma, *d_beta;\n    d_input = (T *)sycl::malloc_device(input_size_bytes, q);\n    q.memcpy(d_input, h_input, input_size_bytes);\n\n    d_output = (T *)sycl::malloc_device(output_size_bytes, q);\n    q.memset(d_output, 0, output_size_bytes);\n\n    d_bias = (T *)sycl::malloc_device(bias_size_bytes, q);\n    q.memcpy(d_bias, h_bias, bias_size_bytes);\n\n    d_gamma = (T *)sycl::malloc_device(gamma_size_bytes, q);\n    q.memcpy(d_gamma, h_gamma, gamma_size_bytes);\n\n    d_beta = (T *)sycl::malloc_device(beta_size_bytes, q);\n    q.memcpy(d_beta, h_beta, beta_size_bytes);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      invokeAddBiasResidualLayerNorm<T, V>(\n        q, d_output, d_input, d_bias, d_gamma, d_beta, layernorm_eps, m, n);\n    }\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of AddBiasResidualLayerNorm (%d x %d): %f (us)\\n\",\n           m, n, (time * 1e-3f) / repeat);\n\n    q.memcpy(h_output, d_output, output_size_bytes).wait();\n\n    float s = 0;\n    for (int i = 0; i < output_size; i++)\n      s += float(h_output[i]);\n\n    printf(\"Checksum = %f\\n\", s / (n * n));\n\n    sycl::free(d_input, q);\n    sycl::free(d_output, q);\n    sycl::free(d_bias, q);\n    sycl::free(d_gamma, q);\n    sycl::free(d_beta, q);\n\n    free(h_input);\n    free(h_output);\n    free(h_bias);\n    free(h_gamma);\n    free(h_beta);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  printf(\"---------------- float16 (version 1) -------------\\n\");\n  layer<sycl::half, 1>(repeat);\n  printf(\"---------------- float16 (version 2) -------------\\n\");\n  layer<sycl::half, 2>(repeat);\n\n  printf(\"---------------- bfloat16 (version 1) -------------\\n\");\n  layer<sycl::ext::oneapi::bfloat16, 1>(repeat);\n  printf(\"---------------- bfloat16 (version 2) -------------\\n\");\n  layer<sycl::ext::oneapi::bfloat16, 2>(repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "atomicIntrinsics", "parallel_api": "cuda", "code": {"main-um.cu": "\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"kernel.h\"\n#include \"reference.h\"\n\ntemplate <class T>\nvoid testcase(const int repeat)\n{\n  unsigned int len = 1 << 27;\n  unsigned int numThreads = 256;\n  unsigned int numBlocks = (len + numThreads - 1) / numThreads;\n  T gpuData[] = {0, 0, (T)-256, 256, 255, 0, 255, 0, 0};\n  unsigned int memSize = sizeof(gpuData);\n\n  \n\n  T *dOData;\n  cudaMallocManaged((void **) &dOData, memSize);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    cudaMemcpy(dOData, gpuData, memSize, cudaMemcpyHostToDevice);\n\n    \n\n    testKernel<T><<<numBlocks, numThreads>>>(dOData);\n  }\n  cudaDeviceSynchronize();\n\n  computeGold<T>(dOData, numThreads * numBlocks);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    testKernel<T><<<numBlocks, numThreads>>>(dOData);\n  }\n  cudaDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaFree(dOData);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  testcase<int>(repeat);\n  testcase<unsigned int>(repeat);\n  return 0;\n}\n", "main.cu": "\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"kernel.h\"\n#include \"reference.h\"\n\ntemplate <class T>\nvoid testcase(const int repeat)\n{\n  unsigned int len = 1 << 27;\n  unsigned int numThreads = 256;\n  unsigned int numBlocks = (len + numThreads - 1) / numThreads;\n  T gpuData[] = {0, 0, (T)-256, 256, 255, 0, 255, 0, 0};\n  unsigned int memSize = sizeof(gpuData);\n\n  \n\n  T *dOData;\n  cudaMalloc((void **) &dOData, memSize);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    cudaMemcpy(dOData, gpuData, memSize, cudaMemcpyHostToDevice);\n\n    \n\n    testKernel<T><<<numBlocks, numThreads>>>(dOData);\n  }\n\n  \n\n  cudaMemcpy(gpuData, dOData, memSize, cudaMemcpyDeviceToHost);\n\n  computeGold<T>(gpuData, numThreads * numBlocks);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    testKernel<T><<<numBlocks, numThreads>>>(dOData);\n  }\n  cudaDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaFree(dOData);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  testcase<int>(repeat);\n  testcase<unsigned int>(repeat);\n  return 0;\n}\n"}}
{"kernel_name": "atomicIntrinsics", "parallel_api": "hip", "code": {"main-um.cu": "\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"kernel.h\"\n#include \"reference.h\"\n\ntemplate <class T>\nvoid testcase(const int repeat)\n{\n  unsigned int len = 1 << 27;\n  unsigned int numThreads = 256;\n  unsigned int numBlocks = (len + numThreads - 1) / numThreads;\n  T gpuData[] = {0, 0, (T)-256, 256, 255, 0, 255, 0, 0};\n  unsigned int memSize = sizeof(gpuData);\n\n  \n\n  T *dOData;\n  hipMallocManaged((void **) &dOData, memSize);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    hipMemcpy(dOData, gpuData, memSize, hipMemcpyHostToDevice);\n\n    \n\n    testKernel<T><<<numBlocks, numThreads>>>(dOData);\n  }\n  hipDeviceSynchronize();\n\n  computeGold<T>(dOData, numThreads * numBlocks);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    testKernel<T><<<numBlocks, numThreads>>>(dOData);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipFree(dOData);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  testcase<int>(repeat);\n  testcase<unsigned int>(repeat);\n  return 0;\n}\n", "main.cu": "\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <hip/hip_runtime.h>\n#include \"kernel.h\"\n#include \"reference.h\"\n\ntemplate <class T>\nvoid testcase(const int repeat)\n{\n  unsigned int len = 1 << 27;\n  unsigned int numThreads = 256;\n  unsigned int numBlocks = (len + numThreads - 1) / numThreads;\n  T gpuData[] = {0, 0, (T)-256, 256, 255, 0, 255, 0, 0};\n  unsigned int memSize = sizeof(gpuData);\n\n  \n\n  T *dOData;\n  hipMalloc((void **) &dOData, memSize);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    hipMemcpy(dOData, gpuData, memSize, hipMemcpyHostToDevice);\n\n    \n\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(testKernel<T>), numBlocks, numThreads, 0, 0, dOData);\n  }\n\n  \n\n  hipMemcpy(gpuData, dOData, memSize, hipMemcpyDeviceToHost);\n\n  computeGold<T>(gpuData, numThreads * numBlocks);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(testKernel<T>), numBlocks, numThreads, 0, 0, dOData);\n  }\n  hipDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipFree(dOData);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  testcase<int>(repeat);\n  testcase<unsigned int>(repeat);\n  return 0;\n}\n"}}
{"kernel_name": "atomicIntrinsics", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n\n#include <omp.h>\n#include \"reference.h\"\n\ntemplate <class T>\nvoid testcase(const int repeat)\n{\n  const int len = 1 << 10;\n  unsigned int numThreads = 256;\n  unsigned int numData = 7;\n  unsigned int memSize = sizeof(T) * numData;\n  const T data[] = {0, 0, (T)-256, 256, 255, 0, 255};\n  T gpuData[7];\n\n  #pragma omp target data map(alloc: gpuData[0:7])\n  {\n    for (int n = 0; n < repeat; n++) {\n      memcpy(gpuData, data, memSize);\n      #pragma omp target update to (gpuData[0:7])\n\n      #pragma omp target teams distribute parallel for thread_limit(numThreads)\n      for (int i = 0; i < len; ++i)\n      {\n         #pragma omp atomic update\n          gpuData[0] += (T)10;\n         #pragma omp atomic update\n          gpuData[1] -= (T)10;\n         \n\n         \n\n         \n\n         \n\n         #pragma omp atomic update\n          gpuData[4] &= (T)(2*i+7);\n         #pragma omp atomic update\n          gpuData[5] |= (T)(1 << i);\n         #pragma omp atomic update\n          gpuData[6] ^= (T)i;\n      }\n\n      #pragma omp target teams distribute parallel for thread_limit(256) reduction(max: gpuData[2])\n      for (int i = 0; i < len; ++i)\n         gpuData[2] = max(gpuData[2], (T)i);\n\n      #pragma omp target teams distribute parallel for thread_limit(256) reduction(min: gpuData[3])\n      for (int i = 0; i < len; ++i)\n         gpuData[3] = min(gpuData[3], (T)i);\n    }\n\n    #pragma omp target update from (gpuData[0:7])\n    computeGold<T>(gpuData, len);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      \n\n      #pragma omp target teams distribute parallel for thread_limit(numThreads)\n      for (int i = 0; i < len; ++i)\n      {\n         #pragma omp atomic update\n          gpuData[0] += (T)10;\n         #pragma omp atomic update\n          gpuData[1] -= (T)10;\n         \n\n         \n\n         \n\n         \n\n         #pragma omp atomic update\n          gpuData[4] &= (T)(2*i+7);\n         #pragma omp atomic update\n          gpuData[5] |= (T)(1 << i);\n         #pragma omp atomic update\n          gpuData[6] ^= (T)i;\n      }\n\n      #pragma omp target teams distribute parallel for thread_limit(256) reduction(max: gpuData[2])\n      for (int i = 0; i < len; ++i)\n         gpuData[2] = max(gpuData[2], (T)i);\n\n      #pragma omp target teams distribute parallel for thread_limit(256) reduction(min: gpuData[3])\n      for (int i = 0; i < len; ++i)\n         gpuData[3] = min(gpuData[3], (T)i);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  testcase<int>(repeat);\n  testcase<unsigned int>(repeat);\n  return 0;\n}\n"}}
{"kernel_name": "atomicIntrinsics", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n\n#include \"reference.h\"\n\ntemplate <class T>\nvoid testcase(const int repeat)\n{\n  const int len = 1 << 10;\n  unsigned int numThreads = 256;\n  unsigned int numData = 7;\n  unsigned int memSize = sizeof(T) * numData;\n  const T data[] = {0, 0, (T)-256, 256, 255, 0, 255};\n  T gpuData[7];\n\n    {\n    for (int n = 0; n < repeat; n++) {\n      memcpy(gpuData, data, memSize);\n      \n            for (int i = 0; i < len; ++i)\n      {\n                   gpuData[0] += (T)10;\n                   gpuData[1] -= (T)10;\n         \n\n         \n\n         \n\n         \n\n                   gpuData[4] &= (T)(2*i+7);\n                   gpuData[5] |= (T)(1 << i);\n                   gpuData[6] ^= (T)i;\n      }\n\n            for (int i = 0; i < len; ++i)\n         gpuData[2] = max(gpuData[2], (T)i);\n\n            for (int i = 0; i < len; ++i)\n         gpuData[3] = min(gpuData[3], (T)i);\n    }\n\n        computeGold<T>(gpuData, len);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      \n\n            for (int i = 0; i < len; ++i)\n      {\n                   gpuData[0] += (T)10;\n                   gpuData[1] -= (T)10;\n         \n\n         \n\n         \n\n         \n\n                   gpuData[4] &= (T)(2*i+7);\n                   gpuData[5] |= (T)(1 << i);\n                   gpuData[6] ^= (T)i;\n      }\n\n            for (int i = 0; i < len; ++i)\n         gpuData[2] = max(gpuData[2], (T)i);\n\n            for (int i = 0; i < len; ++i)\n         gpuData[3] = min(gpuData[3], (T)i);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  testcase<int>(repeat);\n  testcase<unsigned int>(repeat);\n  return 0;\n}"}}
{"kernel_name": "bitpacking", "parallel_api": "cuda", "code": {"main.cu": "#include \"utils.h\"\n\ntemplate <typename T>\nvoid toGPU(T* const output, T const* const input, size_t const num)\n{\n  CUDA_RT_CALL(\n      cudaMemcpy(output, input, num * sizeof(T), cudaMemcpyHostToDevice));\n}\n\ntemplate <typename T>\nvoid fromGPU(T* const output, T const* const input, size_t const num)\n{\n  CUDA_RT_CALL(\n      cudaMemcpy(output, input, num * sizeof(T), cudaMemcpyDeviceToHost));\n}\n\ntemplate <>\nvoid fromGPU<void>(void* const output, void const* const input, size_t const num)\n{\n  CUDA_RT_CALL(cudaMemcpy(output, input, num, cudaMemcpyDeviceToHost));\n}\n\ntemplate <typename T>\nvoid runBitPackingOnGPU(\n    T const* const inputHost,\n    void* const outputHost,\n    int const numBitsMax,\n    size_t const n,\n    int* const numBitsOut,\n    T* const minValOut)\n{\n  T* input;\n\n  CUDA_RT_CALL(cudaMalloc((void**)&input, n * sizeof(T)));\n  toGPU(input, inputHost, n);\n\n  void* output;\n  size_t const packedSize = (((numBitsMax * n) / 64U) + 1U) * 8U;\n\n  size_t* numDevice;\n  CUDA_RT_CALL(cudaMalloc((void**)&numDevice, sizeof(numDevice)));\n  toGPU(numDevice, &n, 1);\n\n  CUDA_RT_CALL(cudaMalloc(&output, packedSize));\n  CUDA_RT_CALL(cudaMemset(output, 0, packedSize));\n\n  T* minValueDevice;\n  CUDA_RT_CALL(cudaMalloc((void**)&minValueDevice, sizeof(*minValueDevice)));\n  unsigned char* numBitsDevice;\n  CUDA_RT_CALL(cudaMalloc((void**)&numBitsDevice, sizeof(*numBitsDevice)));\n\n  void* workspace;\n  size_t workspaceBytes = requiredWorkspaceSize(n, TypeOf<T>());\n  CUDA_RT_CALL(cudaMalloc(&workspace, workspaceBytes));\n\n  const nvcompType_t inType = TypeOf<T>();\n\n  compress(\n      workspace,\n      workspaceBytes,\n      inType,\n      output,\n      input,\n      numDevice,\n      n,\n      minValueDevice,\n      numBitsDevice);\n\n  fromGPU(minValOut, minValueDevice, 1);\n\n  unsigned char numBits;\n  fromGPU(&numBits, numBitsDevice, 1);\n  *numBitsOut = numBits;\n\n  fromGPU(outputHost, output, std::min(packedSize, n * sizeof(T)));\n\n  CUDA_RT_CALL(cudaFree(input));\n  CUDA_RT_CALL(cudaFree(output));\n  CUDA_RT_CALL(cudaFree(workspace));\n  CUDA_RT_CALL(cudaFree(minValueDevice));\n  CUDA_RT_CALL(cudaFree(numBitsDevice));\n}\n\nint main() {\n int const offset = 87231;\n  int const numBits = 13;\n\n  \n\n  std::vector<size_t> const sizes{2, 123, 3411, 83621, 872163, 100000001};\n\n  using T = int32_t;\n\n  \n\n  std::vector<T> source(sizes.back());\n  std::srand(0);\n  for (T& v : source) {\n    v = std::abs(static_cast<T>(std::rand())) % std::numeric_limits<T>::max();\n  }\n\n  size_t const numBytes = sizes.back() * sizeof(T);\n  T* inputHost = (T*) aligned_alloc (1024, numBytes);\n  void* outputHost = aligned_alloc (1024, numBytes);\n\n  for (size_t const n : sizes) {\n    for (size_t i = 0; i < n; ++i) {\n      inputHost[i] = (source[i] & ((1U << numBits) - 1)) + offset;\n    }\n\n    T minValue;\n    int numBitsAct;\n\n    printf(\"Size = %10zu\\n\", n);\n    auto start = std::chrono::steady_clock::now();\n\n    runBitPackingOnGPU(\n        inputHost, outputHost, numBits, n, &numBitsAct, &minValue);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Device offload time = %f (s)\\n\", time * 1e-9f);\n\n    assert(numBitsAct <= numBits);\n\n    \n\n    std::vector<T> unpackedHost;\n    for (size_t i = 0; i < n; ++i) {\n      unpackedHost.emplace_back(unpackBytes(\n          outputHost, static_cast<uint8_t>(numBitsAct), minValue, i));\n    }\n\n    \n\n    assert(unpackedHost.size() == n);\n\n    bool ok = true;\n    \n\n    size_t const numSamples = static_cast<size_t>(std::sqrt(n)) + 1;\n    for (size_t i = 0; i < numSamples; ++i) {\n      \n\n      size_t const idx = static_cast<uint32_t>(source[i]) % n;\n      if (unpackedHost[idx] != inputHost[idx]) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");  \n  }\n\n  free(inputHost);\n  free(outputHost);\n}\n", "kernels.cu": "#include \"utils.h\"\n\n\n\n\n__device__ int clamp(size_t const val, int const max)\n{\n  return static_cast<int>(min(static_cast<size_t>(max), val));\n}\n\ntemplate <typename T>\n__device__ void readMinAndMax(\n    T const* const inMin,\n    T const* const inMax,\n    T* const minBuffer,\n    T* const maxBuffer,\n    int const blockOffset,\n    int const blockEnd)\n{\n  static_assert(\n      BLOCK_SIZE <= BLOCK_WIDTH,\n      \"BLOCK_SIZE must be less than or equal to BLOCK_WIDTH\");\n\n  if (threadIdx.x < blockEnd) {\n    T localMin = inMin[blockOffset + threadIdx.x];\n    T localMax = inMax[blockOffset + threadIdx.x];\n    for (int i = threadIdx.x + BLOCK_SIZE; i < BLOCK_WIDTH && i < blockEnd;\n         i += BLOCK_SIZE) {\n      int const readIdx = blockOffset + i;\n      localMin = min(inMin[readIdx], localMin);\n      localMax = max(inMax[readIdx], localMax);\n    }\n    minBuffer[threadIdx.x] = localMin;\n    maxBuffer[threadIdx.x] = localMax;\n  }\n}\n\ntemplate <typename T>\n__device__ void\nreduceMinAndMax(T* const minBuffer, T* const maxBuffer, int const blockEnd)\n{\n  \n\n  for (int d = BLOCK_SIZE / 2; d > 0; d >>= 1) {\n    if (threadIdx.x < BLOCK_SIZE / 2) {\n      int const idx = threadIdx.x;\n      if (idx < d && idx + d < blockEnd) {\n        minBuffer[idx] = min(minBuffer[idx], minBuffer[d + idx]);\n      }\n    } else {\n      int const idx = threadIdx.x - (BLOCK_SIZE / 2);\n      if (idx < d && idx + d < blockEnd) {\n        maxBuffer[idx] = max(maxBuffer[idx], maxBuffer[d + idx]);\n      }\n    }\n    __syncthreads();\n  }\n}\n\n\n\n\n\ntemplate <typename LIMIT, typename INPUT>\n__global__ void bitPackConfigScanKernel(\n    LIMIT* const minValue,\n    LIMIT* const maxValue,\n    INPUT const* const in,\n    const size_t* const numDevice)\n{\n  static_assert(BLOCK_SIZE % 64 == 0, \"BLOCK_SIZE must a multiple of 64\");\n\n  \n\n\n  const size_t num = *numDevice;\n  const int numBlocks = roundUpDiv(num, BLOCK_SIZE);\n\n  \n\n  \n\n\n  if (blockIdx.x < numBlocks) {\n    \n\n    __shared__ LIMIT minBuffer[BLOCK_SIZE];\n    __shared__ LIMIT maxBuffer[BLOCK_SIZE];\n\n    LIMIT localMin = 0;\n    LIMIT localMax = 0;\n\n    int lastThread = 0;\n    for (int block = blockIdx.x; block < numBlocks; block += gridDim.x) {\n\n      int const blockOffset = BLOCK_SIZE * block;\n      int const blockEnd = min(static_cast<int>(num) - blockOffset, BLOCK_SIZE);\n\n      lastThread = max(lastThread, blockEnd);\n\n      if (threadIdx.x < blockEnd) {\n        LIMIT const val = in[blockOffset + threadIdx.x];\n        if (block == blockIdx.x) {\n          \n\n          localMax = val;\n          localMin = val;\n        } else {\n          localMin = min(val, localMin);\n          localMax = max(val, localMax);\n        }\n      }\n    }\n\n    minBuffer[threadIdx.x] = localMin;\n    maxBuffer[threadIdx.x] = localMax;\n\n    __syncthreads();\n\n    \n\n    reduceMinAndMax(minBuffer, maxBuffer, lastThread);\n\n    if (threadIdx.x == 0) {\n      minValue[blockIdx.x] = minBuffer[0];\n      maxValue[blockIdx.x] = maxBuffer[0];\n    }\n  }\n}\n\ntemplate <typename LIMIT, typename INPUT>\n__global__ void bitPackConfigFinalizeKernel(\n    LIMIT const* const inMin,\n    LIMIT const* const inMax,\n    unsigned char* const numBitsPtr,\n    INPUT* const outMinValPtr,\n    const size_t* const numDevice)\n{\n  static_assert(\n      BLOCK_SIZE <= BLOCK_WIDTH,\n      \"BLOCK_SIZE must be less than or equal to BLOCK_WIDTH\");\n  static_assert(\n      BLOCK_WIDTH % BLOCK_SIZE == 0,\n      \"BLOCK_WIDTH must be a multiple of BLOCK_SIZE\");\n  static_assert(BLOCK_SIZE % 64 == 0, \"BLOCK_SIZE must a multiple of 64\");\n\n  \n\n\n  const size_t num = min(\n      roundUpDiv(*numDevice, BLOCK_SIZE), static_cast<size_t>(BLOCK_WIDTH));\n\n  \n\n\n  \n\n  \n\n  __shared__ LIMIT minBuffer[BLOCK_SIZE];\n  __shared__ LIMIT maxBuffer[BLOCK_SIZE];\n\n  \n\n  readMinAndMax(inMin, inMax, minBuffer, maxBuffer, 0, num);\n\n  __syncthreads();\n\n  \n\n  reduceMinAndMax(minBuffer, maxBuffer, min(BLOCK_SIZE, (int)num));\n\n  if (threadIdx.x == 0) {\n    *outMinValPtr = static_cast<INPUT>(minBuffer[0]);\n    \n\n    if (sizeof(LIMIT) > sizeof(int)) {\n      const uint64_t range = static_cast<uint64_t>(maxBuffer[0]) - static_cast<uint64_t>(minBuffer[0]);\n      \n\n      *numBitsPtr = sizeof(uint64_t) * 8 - __clzll(range);\n    } else {\n      const uint32_t range = static_cast<uint32_t>(maxBuffer[0]) - static_cast<uint32_t>(minBuffer[0]);\n      \n\n      *numBitsPtr = sizeof(uint32_t) * 8 - __clz(range);\n    }\n  }\n}\n\ntemplate <typename INPUT, typename OUTPUT>\n__global__ void bitPackKernel(\n    unsigned char const* const numBitsPtr,\n    INPUT const* const valueOffsetPtr,\n    OUTPUT* const outPtr,\n    INPUT const* const in,\n    const size_t* const numDevice)\n{\n  using UINPUT = typename std::make_unsigned<INPUT>::type;\n\n  const size_t num = *numDevice;\n\n  const int numBlocks = roundUpDiv(num, BLOCK_SIZE);\n\n  OUTPUT* const out = outPtr;\n  int const numBits = *numBitsPtr;\n  INPUT const valueOffset = *valueOffsetPtr;\n\n  __shared__ UINPUT inBuffer[BLOCK_SIZE];\n\n  for (int blockId = blockIdx.x; blockId < numBlocks; blockId += gridDim.x) {\n    \n\n    \n\n    \n\n    \n\n    int const outputIdx = threadIdx.x + blockId * BLOCK_SIZE;\n    \n\n    \n\n\n    size_t const bitStart = outputIdx * sizeof(*out) * 8U;\n    size_t const bitEnd = bitStart + (sizeof(*out) * 8U);\n\n    int const startIdx = clamp(bitStart / static_cast<size_t>(numBits), num);\n    int const endIdx = clamp(roundUpDiv(bitEnd, numBits), num);\n    \n\n\n    size_t const blockStartBit = blockId * BLOCK_SIZE * sizeof(*out) * 8U;\n    size_t const blockEndBit = (blockId + 1) * BLOCK_SIZE * sizeof(*out) * 8U;\n    \n\n\n    int const blockStartIdx = clamp(\n        roundDownTo(blockStartBit / static_cast<size_t>(numBits), BLOCK_SIZE),\n        num);\n    int const blockEndIdx\n        = clamp(roundUpTo(roundUpDiv(blockEndBit, numBits), BLOCK_SIZE), num);\n    \n\n    \n\n\n    OUTPUT val = 0;\n    for (int bufferStart = blockStartIdx; bufferStart < blockEndIdx;\n         bufferStart += BLOCK_SIZE) {\n      __syncthreads();\n\n      \n\n      int const inputIdx = bufferStart + threadIdx.x;\n      if (inputIdx < num) {\n        inBuffer[threadIdx.x] = in[inputIdx] - valueOffset;\n      }\n\n      __syncthreads();\n\n      int const currentStartIdx = max(startIdx, bufferStart);\n      int const currentEndIdx = min(endIdx, bufferStart + BLOCK_SIZE);\n\n      for (int idx = currentStartIdx; idx < currentEndIdx; ++idx) {\n        int const localIdx = idx - bufferStart;\n\n        \n\n        OUTPUT bits = static_cast<OUTPUT>(inBuffer[localIdx]);\n        int const offset = static_cast<int>(\n            static_cast<ssize_t>(idx * numBits)\n            - static_cast<ssize_t>(bitStart));\n        \n\n\n        if (offset > 0) {\n          bits <<= offset;\n        } else {\n          bits >>= -offset;\n        }\n\n        \n\n        val |= bits;\n      }\n    }\n\n    if (startIdx < num) {\n      out[outputIdx] = val;\n    }\n  }\n}\n\n\n\n\ntemplate <typename LIMIT, typename INPUT>\nvoid bitPackConfigLaunch(\n    LIMIT* const minValueScratch,\n    LIMIT* const maxValueScratch,\n    INPUT* const minValOutPtr,\n    unsigned char* const numBitsPtr,\n    INPUT const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum)\n{\n  const dim3 grid(\n      min(BLOCK_WIDTH, static_cast<int>(roundUpDiv(maxNum, BLOCK_SIZE))));\n  const dim3 block(BLOCK_SIZE);\n\n  \n\n  bitPackConfigScanKernel<<<grid, block>>>(\n      minValueScratch, maxValueScratch, in, numDevice);\n#ifdef DEBUG\n  cudaError_t err;\n  err = cudaGetLastError();\n  if (err != cudaSuccess) {\n    throw std::runtime_error(\n        \"Failed to launch bitPackConfigScanKernel \"\n        \"kernel: \"\n        + std::to_string(err));\n  }\n#endif\n\n  \n\n  bitPackConfigFinalizeKernel<<<dim3(1), block>>>(\n      minValueScratch, maxValueScratch, numBitsPtr, minValOutPtr, numDevice);\n#ifdef DEBUG\n  err = cudaGetLastError();\n  if (err != cudaSuccess) {\n    throw std::runtime_error(\n        \"Failed to launch bitPackConfigFinalizeKernel \"\n        \"kernel: \"\n        + std::to_string(err));\n  }\n#endif\n}\n\ntemplate <typename INPUT, typename OUTPUT>\nvoid bitPackLaunch(\n    const INPUT * const minValueDevicePtr,\n    unsigned char const* const numBitsDevicePtr,\n    OUTPUT* const outPtr,\n    INPUT const* const in,\n    const size_t* const numDevice,\n    const size_t maxNum)\n{\n  static_assert(\n      BLOCK_SIZE % (sizeof(OUTPUT) * 8U) == 0,\n      \"Block size must be a multiple of output word size.\");\n\n  dim3 const grid(\n      std::min(4096, static_cast<int>(roundUpDiv(maxNum, BLOCK_SIZE))));\n  dim3 const block(BLOCK_SIZE);\n\n  bitPackKernel<<<grid, block>>>(\n      numBitsDevicePtr, minValueDevicePtr, outPtr, in, numDevice);\n\n#ifdef DEBUG\n  cudaError_t err = cudaGetLastError();\n  if (err != cudaSuccess) {\n    throw std::runtime_error(\n        \"Failed to launch bitPackKernel kernel: \" + std::to_string(err));\n  }\n#endif\n}\n\ntemplate <typename IN, typename OUT, typename LIMIT>\nvoid bitPackFixedBitAndMinInternal(\n    void const* const minValueDevicePtr,\n    unsigned char const* const numBitsDevicePtr,\n    void* const \n,\n    void* const outPtr,\n    void const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum)\n{\n  \n\n  OUT* const outputTypedPtr = reinterpret_cast<OUT*>(outPtr);\n  IN const* const inputTyped = static_cast<IN const*>(in);\n\n  bitPackLaunch(\n      reinterpret_cast<const IN*>(minValueDevicePtr),\n      numBitsDevicePtr,\n      outputTypedPtr,\n      inputTyped,\n      numDevice,\n      maxNum);\n}\n\ntemplate <typename IN, typename OUT, typename LIMIT>\nvoid bitPackInternal(\n    void* const workspace,\n    void* const outPtr,\n    void const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum,\n    void* const minValueDevicePtr,\n    unsigned char* const numBitsDevicePtr)\n{\n  \n\n  LIMIT* const maxValueTyped = static_cast<LIMIT*>(workspace);\n  LIMIT* const minValueTyped = maxValueTyped + getReduceScratchSpaceSize(maxNum);\n  IN const* const inputTyped = static_cast<IN const*>(in);\n\n  \n\n  bitPackConfigLaunch(\n      minValueTyped,\n      maxValueTyped,\n      reinterpret_cast<IN*>(minValueDevicePtr),\n      numBitsDevicePtr,\n      inputTyped,\n      numDevice,\n      maxNum);\n\n  bitPackFixedBitAndMinInternal<IN, OUT, LIMIT>(\n      minValueDevicePtr,\n      numBitsDevicePtr,\n      workspace,\n      outPtr,\n      in,\n      numDevice,\n      maxNum);\n}\n\n\nvoid compress(\n    void* const workspace,\n    const size_t workspaceSize,\n    const nvcompType_t inType,\n    void* const outPtr,\n    const void* const in,\n    const size_t* const numPtr,\n    const size_t maxNum,\n    void* const minValueDevicePtr,\n    unsigned char* const numBitsDevicePtr)\n{\n  const size_t reqWorkSize = requiredWorkspaceSize(maxNum, inType);\n  if (workspaceSize < reqWorkSize) {\n    throw std::runtime_error(\n        \"Insufficient workspace size: \" + std::to_string(workspaceSize)\n        + \", need \" + std::to_string(reqWorkSize));\n  }\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < 1000; n++)\n    NVCOMP_TYPE_SWITCH(\n      inType,\n      bitPackInternal,\n      workspace,\n      outPtr,\n      in,\n      numPtr,\n      maxNum,\n      minValueDevicePtr,\n      numBitsDevicePtr);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time (1000 iterations) = %f (s)\\n\", time * 1e-9f);\n}\n\n"}}
{"kernel_name": "bitpacking", "parallel_api": "hip", "code": {"main.cu": "#include \"utils.h\"\n\ntemplate <typename T>\nvoid toGPU(T* const output, T const* const input, size_t const num)\n{\n  CUDA_RT_CALL(\n      hipMemcpy(output, input, num * sizeof(T), hipMemcpyHostToDevice));\n}\n\ntemplate <typename T>\nvoid fromGPU(T* const output, T const* const input, size_t const num)\n{\n  CUDA_RT_CALL(\n      hipMemcpy(output, input, num * sizeof(T), hipMemcpyDeviceToHost));\n}\n\ntemplate <>\nvoid fromGPU<void>(void* const output, void const* const input, size_t const num)\n{\n  CUDA_RT_CALL(hipMemcpy(output, input, num, hipMemcpyDeviceToHost));\n}\n\ntemplate <typename T>\nvoid runBitPackingOnGPU(\n    T const* const inputHost,\n    void* const outputHost,\n    int const numBitsMax,\n    size_t const n,\n    int* const numBitsOut,\n    T* const minValOut)\n{\n  T* input;\n\n  CUDA_RT_CALL(hipMalloc((void**)&input, n * sizeof(T)));\n  toGPU(input, inputHost, n);\n\n  void* output;\n  size_t const packedSize = (((numBitsMax * n) / 64U) + 1U) * 8U;\n\n  size_t* numDevice;\n  CUDA_RT_CALL(hipMalloc((void**)&numDevice, sizeof(numDevice)));\n  toGPU(numDevice, &n, 1);\n\n  CUDA_RT_CALL(hipMalloc(&output, packedSize));\n  CUDA_RT_CALL(hipMemset(output, 0, packedSize));\n\n  T* minValueDevice;\n  CUDA_RT_CALL(hipMalloc((void**)&minValueDevice, sizeof(*minValueDevice)));\n  unsigned char* numBitsDevice;\n  CUDA_RT_CALL(hipMalloc((void**)&numBitsDevice, sizeof(*numBitsDevice)));\n\n\n  void* workspace;\n  size_t workspaceBytes = requiredWorkspaceSize(n, TypeOf<T>());\n  CUDA_RT_CALL(hipMalloc(&workspace, workspaceBytes));\n\n  const nvcompType_t inType = TypeOf<T>();\n\n  compress(\n      workspace,\n      workspaceBytes,\n      inType,\n      output,\n      input,\n      numDevice,\n      n,\n      minValueDevice,\n      numBitsDevice);\n\n  fromGPU(minValOut, minValueDevice, 1);\n\n  unsigned char numBits;\n  fromGPU(&numBits, numBitsDevice, 1);\n  *numBitsOut = numBits;\n\n  fromGPU(outputHost, output, std::min(packedSize, n * sizeof(T)));\n\n  CUDA_RT_CALL(hipFree(input));\n  CUDA_RT_CALL(hipFree(output));\n  CUDA_RT_CALL(hipFree(workspace));\n  CUDA_RT_CALL(hipFree(minValueDevice));\n  CUDA_RT_CALL(hipFree(numBitsDevice));\n}\n\nint main() {\n int const offset = 87231;\n  int const numBits = 13;\n\n  \n\n  std::vector<size_t> const sizes{2, 123, 3411, 83621, 872163, 100000001};\n\n  using T = int32_t;\n\n  \n\n  std::vector<T> source(sizes.back());\n  std::srand(0);\n  for (T& v : source) {\n    v = std::abs(static_cast<T>(std::rand())) % std::numeric_limits<T>::max();\n  }\n\n  size_t const numBytes = sizes.back() * sizeof(T);\n  T* inputHost = (T*) aligned_alloc (1024, numBytes);\n  void* outputHost = aligned_alloc (1024, numBytes);\n\n  for (size_t const n : sizes) {\n    for (size_t i = 0; i < n; ++i) {\n      inputHost[i] = (source[i] & ((1U << numBits) - 1)) + offset;\n    }\n\n    T minValue;\n    int numBitsAct;\n\n    printf(\"Size = %10zu\\n\", n);\n    auto start = std::chrono::steady_clock::now();\n\n    runBitPackingOnGPU(\n        inputHost, outputHost, numBits, n, &numBitsAct, &minValue);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Device offload time = %f (s)\\n\", time * 1e-9f);\n\n    assert(numBitsAct <= numBits);\n\n    \n\n    std::vector<T> unpackedHost;\n    for (size_t i = 0; i < n; ++i) {\n      unpackedHost.emplace_back(unpackBytes(\n          outputHost, static_cast<uint8_t>(numBitsAct), minValue, i));\n    }\n\n    \n\n    assert(unpackedHost.size() == n);\n\n    bool ok = true;\n    \n\n    size_t const numSamples = static_cast<size_t>(std::sqrt(n)) + 1;\n    for (size_t i = 0; i < numSamples; ++i) {\n      \n\n      size_t const idx = static_cast<uint32_t>(source[i]) % n;\n      if (unpackedHost[idx] != inputHost[idx]) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");  \n  }\n\n  free(inputHost);\n  free(outputHost);\n}\n", "kernels.cu": "#include <hip/hip_runtime.h>\n#include \"utils.h\"\n\n\n\n\n__device__ int clamp(size_t const val, int const max)\n{\n  return static_cast<int>(min(static_cast<size_t>(max), val));\n}\n\ntemplate <typename T>\n__device__ void readMinAndMax(\n    T const* const inMin,\n    T const* const inMax,\n    T* const minBuffer,\n    T* const maxBuffer,\n    int const blockOffset,\n    int const blockEnd)\n{\n  static_assert(\n      BLOCK_SIZE <= BLOCK_WIDTH,\n      \"BLOCK_SIZE must be less than or equal to BLOCK_WIDTH\");\n\n  if (threadIdx.x < blockEnd) {\n    T localMin = inMin[blockOffset + threadIdx.x];\n    T localMax = inMax[blockOffset + threadIdx.x];\n    for (int i = threadIdx.x + BLOCK_SIZE; i < BLOCK_WIDTH && i < blockEnd;\n         i += BLOCK_SIZE) {\n      int const readIdx = blockOffset + i;\n      localMin = min(inMin[readIdx], localMin);\n      localMax = max(inMax[readIdx], localMax);\n    }\n    minBuffer[threadIdx.x] = localMin;\n    maxBuffer[threadIdx.x] = localMax;\n  }\n}\n\ntemplate <typename T>\n__device__ void\nreduceMinAndMax(T* const minBuffer, T* const maxBuffer, int const blockEnd)\n{\n  \n\n  for (int d = BLOCK_SIZE / 2; d > 0; d >>= 1) {\n    if (threadIdx.x < BLOCK_SIZE / 2) {\n      int const idx = threadIdx.x;\n      if (idx < d && idx + d < blockEnd) {\n        minBuffer[idx] = min(minBuffer[idx], minBuffer[d + idx]);\n      }\n    } else {\n      int const idx = threadIdx.x - (BLOCK_SIZE / 2);\n      if (idx < d && idx + d < blockEnd) {\n        maxBuffer[idx] = max(maxBuffer[idx], maxBuffer[d + idx]);\n      }\n    }\n    __syncthreads();\n  }\n}\n\n\n\n\n\ntemplate <typename LIMIT, typename INPUT>\n__global__ void bitPackConfigScanKernel(\n    LIMIT* const minValue,\n    LIMIT* const maxValue,\n    INPUT const* const in,\n    const size_t* const numDevice)\n{\n  static_assert(BLOCK_SIZE % 64 == 0, \"BLOCK_SIZE must a multiple of 64\");\n\n  \n\n\n  const size_t num = *numDevice;\n  const int numBlocks = roundUpDiv(num, BLOCK_SIZE);\n\n  \n\n  \n\n\n  if (blockIdx.x < numBlocks) {\n    \n\n    __shared__ LIMIT minBuffer[BLOCK_SIZE];\n    __shared__ LIMIT maxBuffer[BLOCK_SIZE];\n\n    LIMIT localMin = 0;\n    LIMIT localMax = 0;\n\n    int lastThread = 0;\n    for (int block = blockIdx.x; block < numBlocks; block += gridDim.x) {\n\n      int const blockOffset = BLOCK_SIZE * block;\n      int const blockEnd = min(static_cast<int>(num) - blockOffset, BLOCK_SIZE);\n\n      lastThread = max(lastThread, blockEnd);\n\n      if (threadIdx.x < blockEnd) {\n        LIMIT const val = in[blockOffset + threadIdx.x];\n        if (block == blockIdx.x) {\n          \n\n          localMax = val;\n          localMin = val;\n        } else {\n          localMin = min(val, localMin);\n          localMax = max(val, localMax);\n        }\n      }\n    }\n\n    minBuffer[threadIdx.x] = localMin;\n    maxBuffer[threadIdx.x] = localMax;\n\n    __syncthreads();\n\n    \n\n    reduceMinAndMax(minBuffer, maxBuffer, lastThread);\n\n    if (threadIdx.x == 0) {\n      minValue[blockIdx.x] = minBuffer[0];\n      maxValue[blockIdx.x] = maxBuffer[0];\n    }\n  }\n}\n\ntemplate <typename LIMIT, typename INPUT>\n__global__ void bitPackConfigFinalizeKernel(\n    LIMIT const* const inMin,\n    LIMIT const* const inMax,\n    unsigned char* const numBitsPtr,\n    INPUT* const outMinValPtr,\n    const size_t* const numDevice)\n{\n  static_assert(\n      BLOCK_SIZE <= BLOCK_WIDTH,\n      \"BLOCK_SIZE must be less than or equal to BLOCK_WIDTH\");\n  static_assert(\n      BLOCK_WIDTH % BLOCK_SIZE == 0,\n      \"BLOCK_WIDTH must be a multiple of BLOCK_SIZE\");\n  static_assert(BLOCK_SIZE % 64 == 0, \"BLOCK_SIZE must a multiple of 64\");\n\n  \n\n\n  const size_t num = min(\n      roundUpDiv(*numDevice, BLOCK_SIZE), static_cast<size_t>(BLOCK_WIDTH));\n\n  \n\n\n  \n\n  \n\n  __shared__ LIMIT minBuffer[BLOCK_SIZE];\n  __shared__ LIMIT maxBuffer[BLOCK_SIZE];\n\n  \n\n  readMinAndMax(inMin, inMax, minBuffer, maxBuffer, 0, num);\n\n  __syncthreads();\n\n  \n\n  reduceMinAndMax(minBuffer, maxBuffer, min(BLOCK_SIZE, (int)num));\n\n  if (threadIdx.x == 0) {\n    *outMinValPtr = static_cast<INPUT>(minBuffer[0]);\n    \n\n    if (sizeof(LIMIT) > sizeof(int)) {\n      const uint64_t range = static_cast<uint64_t>(maxBuffer[0]) - static_cast<uint64_t>(minBuffer[0]);\n      \n\n      *numBitsPtr = sizeof(uint64_t)  * 8 - __clzll(range);\n    } else {\n      const uint32_t range = static_cast<uint32_t>(maxBuffer[0]) - static_cast<uint32_t>(minBuffer[0]);\n      \n\n      *numBitsPtr = sizeof(uint32_t) * 8 - __clz(range);\n    }\n  }\n}\n\ntemplate <typename INPUT, typename OUTPUT>\n__global__ void bitPackKernel(\n    unsigned char const* const numBitsPtr,\n    INPUT const* const valueOffsetPtr,\n    OUTPUT* const outPtr,\n    INPUT const* const in,\n    const size_t* const numDevice)\n{\n  using UINPUT = typename std::make_unsigned<INPUT>::type;\n\n  const size_t num = *numDevice;\n\n  const int numBlocks = roundUpDiv(num, BLOCK_SIZE);\n\n  OUTPUT* const out = outPtr;\n  int const numBits = *numBitsPtr;\n  INPUT const valueOffset = *valueOffsetPtr;\n\n  __shared__ UINPUT inBuffer[BLOCK_SIZE];\n\n  for (int blockId = blockIdx.x; blockId < numBlocks; blockId += gridDim.x) {\n    \n\n    \n\n    \n\n    \n\n    int const outputIdx = threadIdx.x + blockId * BLOCK_SIZE;\n    \n\n    \n\n\n    size_t const bitStart = outputIdx * sizeof(*out) * 8U;\n    size_t const bitEnd = bitStart + (sizeof(*out) * 8U);\n\n    int const startIdx = clamp(bitStart / static_cast<size_t>(numBits), num);\n    int const endIdx = clamp(roundUpDiv(bitEnd, numBits), num);\n    \n\n\n    size_t const blockStartBit = blockId * BLOCK_SIZE * sizeof(*out) * 8U;\n    size_t const blockEndBit = (blockId + 1) * BLOCK_SIZE * sizeof(*out) * 8U;\n    \n\n\n    int const blockStartIdx = clamp(\n        roundDownTo(blockStartBit / static_cast<size_t>(numBits), BLOCK_SIZE),\n        num);\n    int const blockEndIdx\n        = clamp(roundUpTo(roundUpDiv(blockEndBit, numBits), BLOCK_SIZE), num);\n    \n\n    \n\n\n    OUTPUT val = 0;\n    for (int bufferStart = blockStartIdx; bufferStart < blockEndIdx;\n         bufferStart += BLOCK_SIZE) {\n      __syncthreads();\n\n      \n\n      int const inputIdx = bufferStart + threadIdx.x;\n      if (inputIdx < num) {\n        inBuffer[threadIdx.x] = in[inputIdx] - valueOffset;\n      }\n\n      __syncthreads();\n\n      int const currentStartIdx = max(startIdx, bufferStart);\n      int const currentEndIdx = min(endIdx, bufferStart + BLOCK_SIZE);\n\n      for (int idx = currentStartIdx; idx < currentEndIdx; ++idx) {\n        int const localIdx = idx - bufferStart;\n\n        \n\n        OUTPUT bits = static_cast<OUTPUT>(inBuffer[localIdx]);\n        int const offset = static_cast<int>(\n            static_cast<ssize_t>(idx * numBits)\n            - static_cast<ssize_t>(bitStart));\n        \n\n\n        if (offset > 0) {\n          bits <<= offset;\n        } else {\n          bits >>= -offset;\n        }\n\n        \n\n        val |= bits;\n      }\n    }\n\n    if (startIdx < num) {\n      out[outputIdx] = val;\n    }\n  }\n}\n\n\n\n\ntemplate <typename LIMIT, typename INPUT>\nvoid bitPackConfigLaunch(\n    LIMIT* const minValueScratch,\n    LIMIT* const maxValueScratch,\n    INPUT* const minValOutPtr,\n    unsigned char* const numBitsPtr,\n    INPUT const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum)\n{\n  const dim3 grid(\n      min(BLOCK_WIDTH, static_cast<int>(roundUpDiv(maxNum, BLOCK_SIZE))));\n  const dim3 block(BLOCK_SIZE);\n\n  \n\n  hipLaunchKernelGGL(bitPackConfigScanKernel, grid, block, 0, 0, \n      minValueScratch, maxValueScratch, in, numDevice);\n#ifdef DEBUG\n  hipError_t err;\n  err = hipGetLastError();\n  if (err != hipSuccess) {\n    throw std::runtime_error(\n        \"Failed to launch bitPackConfigScanKernel \"\n        \"kernel: \"\n        + std::to_string(err));\n  }\n#endif\n\n  \n\n  hipLaunchKernelGGL(bitPackConfigFinalizeKernel, dim3(dim3(1)), block, 0, 0, \n      minValueScratch, maxValueScratch, numBitsPtr, minValOutPtr, numDevice);\n#ifdef DEBUG\n  err = hipGetLastError();\n  if (err != hipSuccess) {\n    throw std::runtime_error(\n        \"Failed to launch bitPackConfigFinalizeKernel \"\n        \"kernel: \"\n        + std::to_string(err));\n  }\n#endif\n}\n\ntemplate <typename INPUT, typename OUTPUT>\nvoid bitPackLaunch(\n    const INPUT * const minValueDevicePtr,\n    unsigned char const* const numBitsDevicePtr,\n    OUTPUT* const outPtr,\n    INPUT const* const in,\n    const size_t* const numDevice,\n    const size_t maxNum)\n{\n  static_assert(\n      BLOCK_SIZE % (sizeof(OUTPUT) * 8U) == 0,\n      \"Block size must be a multiple of output word size.\");\n\n  dim3 const grid(\n      std::min(4096, static_cast<int>(roundUpDiv(maxNum, BLOCK_SIZE))));\n  dim3 const block(BLOCK_SIZE);\n\n  hipLaunchKernelGGL(bitPackKernel, grid, block, 0, 0, \n      numBitsDevicePtr, minValueDevicePtr, outPtr, in, numDevice);\n\n#ifdef DEBUG\n  hipError_t err = hipGetLastError();\n  if (err != hipSuccess) {\n    throw std::runtime_error(\n        \"Failed to launch bitPackKernel kernel: \" + std::to_string(err));\n  }\n#endif\n}\n\ntemplate <typename IN, typename OUT, typename LIMIT>\nvoid bitPackFixedBitAndMinInternal(\n    void const* const minValueDevicePtr,\n    unsigned char const* const numBitsDevicePtr,\n    void* const \n,\n    void* const outPtr,\n    void const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum)\n{\n  \n\n  OUT* const outputTypedPtr = reinterpret_cast<OUT*>(outPtr);\n  IN const* const inputTyped = static_cast<IN const*>(in);\n\n  bitPackLaunch(\n      reinterpret_cast<const IN*>(minValueDevicePtr),\n      numBitsDevicePtr,\n      outputTypedPtr,\n      inputTyped,\n      numDevice,\n      maxNum);\n}\n\ntemplate <typename IN, typename OUT, typename LIMIT>\nvoid bitPackInternal(\n    void* const workspace,\n    void* const outPtr,\n    void const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum,\n    void* const minValueDevicePtr,\n    unsigned char* const numBitsDevicePtr)\n{\n  \n\n  LIMIT* const maxValueTyped = static_cast<LIMIT*>(workspace);\n  LIMIT* const minValueTyped = maxValueTyped + getReduceScratchSpaceSize(maxNum);\n  IN const* const inputTyped = static_cast<IN const*>(in);\n\n  \n\n  bitPackConfigLaunch(\n      minValueTyped,\n      maxValueTyped,\n      reinterpret_cast<IN*>(minValueDevicePtr),\n      numBitsDevicePtr,\n      inputTyped,\n      numDevice,\n      maxNum);\n\n  bitPackFixedBitAndMinInternal<IN, OUT, LIMIT>(\n      minValueDevicePtr,\n      numBitsDevicePtr,\n      workspace,\n      outPtr,\n      in,\n      numDevice,\n      maxNum);\n}\n\n\nvoid compress(\n    void* const workspace,\n    const size_t workspaceSize,\n    const nvcompType_t inType,\n    void* const outPtr,\n    const void* const in,\n    const size_t* const numPtr,\n    const size_t maxNum,\n    void* const minValueDevicePtr,\n    unsigned char* const numBitsDevicePtr)\n{\n  const size_t reqWorkSize = requiredWorkspaceSize(maxNum, inType);\n  if (workspaceSize < reqWorkSize) {\n    throw std::runtime_error(\n        \"Insufficient workspace size: \" + std::to_string(workspaceSize)\n        + \", need \" + std::to_string(reqWorkSize));\n  }\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < 1000; n++)\n    NVCOMP_TYPE_SWITCH(\n      inType,\n      bitPackInternal,\n      workspace,\n      outPtr,\n      in,\n      numPtr,\n      maxNum,\n      minValueDevicePtr,\n      numBitsDevicePtr);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time (1000 iterations) = %f (s)\\n\", time * 1e-9f);\n}\n\n"}}
{"kernel_name": "bitpacking", "parallel_api": "sycl", "code": {"main.cpp": "#include \"utils.h\"\n\ntemplate <typename T>\nvoid toGPU(sycl::queue &q, T* const output, T const* const input, size_t const num)\n{\n  q.memcpy(output, input, num * sizeof(T)).wait();\n}\n\ntemplate <typename T>\nvoid fromGPU(sycl::queue &q, T* const output, T const* const input, size_t const num)\n{\n  q.memcpy(output, input, num * sizeof(T)).wait();\n}\n\ntemplate <>\nvoid fromGPU<void>(sycl::queue &q, void* const output, void const* const input, size_t const num)\n{\n  q.memcpy(output, input, num).wait();\n}\n\ntemplate <typename T>\nvoid runBitPackingOnGPU(\n    T const* const inputHost,\n    void* const outputHost,\n    int const numBitsMax,\n    size_t const n,\n    int* const numBitsOut,\n    T* const minValOut)\n{\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  T* input;\n\n  input = (T *)sycl::malloc_device(n * sizeof(T), q);\n  toGPU(q, input, inputHost, n);\n\n  void* output;\n  size_t const packedSize = (((numBitsMax * n) / 64U) + 1U) * 8U;\n\n  size_t* numDevice;\n  numDevice = (size_t *)sycl::malloc_device(sizeof(numDevice), q);\n  toGPU(q, numDevice, &n, 1);\n\n  output = (void *)sycl::malloc_device(packedSize, q);\n  q.memset(output, 0, packedSize).wait();\n\n  T* minValueDevice;\n  minValueDevice = (T *)sycl::malloc_device(sizeof(T), q);\n\n  unsigned char* numBitsDevice;\n  numBitsDevice = (unsigned char *)sycl::malloc_device(sizeof(unsigned char), q);\n\n  void* workspace;\n  size_t workspaceBytes = requiredWorkspaceSize(n, TypeOf<T>());\n  workspace = (void *)sycl::malloc_device(workspaceBytes, q);\n\n  const nvcompType_t inType = TypeOf<T>();\n\n  compress(\n      q,\n      workspace,\n      workspaceBytes,\n      inType,\n      output,\n      input,\n      numDevice,\n      n,\n      minValueDevice,\n      numBitsDevice);\n\n  fromGPU(q, minValOut, minValueDevice, 1);\n\n  unsigned char numBits;\n  fromGPU(q, &numBits, numBitsDevice, 1);\n  *numBitsOut = numBits;\n\n  fromGPU(q, outputHost, output, std::min(packedSize, n * sizeof(T)));\n\n  sycl::free(input, q);\n  sycl::free(output, q);\n  sycl::free(workspace, q);\n  sycl::free(minValueDevice, q);\n  sycl::free(numBitsDevice, q);\n}\n\nint main() {\n  int const offset = 87231;\n  int const numBits = 13;\n\n  \n\n  std::vector<size_t> const sizes{2, 123, 3411, 83621, 872163, 100000001};\n\n  using T = int32_t;\n\n  \n\n  std::vector<T> source(sizes.back());\n  std::srand(0);\n  for (T& v : source) {\n    v = std::abs(static_cast<T>(std::rand())) % std::numeric_limits<T>::max();\n  }\n\n  size_t const numBytes = sizes.back() * sizeof(T);\n  T* inputHost = (T*) aligned_alloc (1024, numBytes);\n  void* outputHost = aligned_alloc (1024, numBytes);\n\n  for (size_t const n : sizes) {\n    for (size_t i = 0; i < n; ++i) {\n      inputHost[i] = (source[i] & ((1U << numBits) - 1)) + offset;\n    }\n\n    T minValue;\n    int numBitsAct;\n\n    printf(\"Size = %10zu\\n\", n);\n    auto start = std::chrono::steady_clock::now();\n\n    runBitPackingOnGPU(\n        inputHost, outputHost, numBits, n, &numBitsAct, &minValue);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Device offload time = %f (s)\\n\", time * 1e-9f);\n\n    assert(numBitsAct <= numBits);\n\n    \n\n    std::vector<T> unpackedHost;\n    for (size_t i = 0; i < n; ++i) {\n      unpackedHost.emplace_back(unpackBytes(\n            outputHost, static_cast<uint8_t>(numBitsAct), minValue, i));\n    }\n\n    \n\n    assert(unpackedHost.size() == n);\n\n    bool ok = true;\n    \n\n    size_t const numSamples = static_cast<size_t>(std::sqrt(n)) + 1;\n    for (size_t i = 0; i < numSamples; ++i) {\n      \n\n      size_t const idx = static_cast<uint32_t>(source[i]) % n;\n      if (unpackedHost[idx] != inputHost[idx]) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");  \n  }\n\n  free(inputHost);\n  free(outputHost);\n}\n", "kernels.cpp": "#include <cmath>\n#include <algorithm>\n#include \"utils.h\"\n\n\n\n\nint clamp(size_t const val, int const max)\n{\n  return static_cast<int>(\n      sycl::min((unsigned long)static_cast<size_t>(max), (unsigned long)val));\n}\n\ntemplate <typename T>\nvoid readMinAndMax(\n    T const* const inMin,\n    T const* const inMax,\n    T* const minBuffer,\n    T* const maxBuffer,\n    int const blockOffset,\n    int const blockEnd,\n    sycl::nd_item<1> &item)\n{\n  static_assert(\n      BLOCK_SIZE <= BLOCK_WIDTH,\n      \"BLOCK_SIZE must be less than or equal to BLOCK_WIDTH\");\n\n  int lid = item.get_local_id(0);\n\n  if (lid < blockEnd) {\n    T localMin = inMin[blockOffset + lid];\n    T localMax = inMax[blockOffset + lid];\n    for (int i = lid + BLOCK_SIZE;\n         i < BLOCK_WIDTH && i < blockEnd; i += BLOCK_SIZE) {\n      int const readIdx = blockOffset + i;\n      localMin = sycl::min(inMin[readIdx], localMin);\n      localMax = sycl::max(inMax[readIdx], localMax);\n    }\n    minBuffer[lid] = localMin;\n    maxBuffer[lid] = localMax;\n  }\n}\n\ntemplate <typename T>\nvoid\nreduceMinAndMax(T* const minBuffer, T* const maxBuffer, int const blockEnd,\n                sycl::nd_item<1> &item)\n{\n  int lid = item.get_local_id(0);\n\n  \n\n  for (int d = BLOCK_SIZE / 2; d > 0; d >>= 1) {\n    if (lid < BLOCK_SIZE / 2) {\n      int const idx = lid;\n      if (idx < d && idx + d < blockEnd) {\n        minBuffer[idx] = sycl::min(minBuffer[idx], minBuffer[d + idx]);\n      }\n    } else {\n      int const idx = lid - (BLOCK_SIZE / 2);\n      if (idx < d && idx + d < blockEnd) {\n        maxBuffer[idx] = sycl::max(maxBuffer[idx], maxBuffer[d + idx]);\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n}\n\n\n\n\n\ntemplate <typename LIMIT, typename INPUT>\nvoid bitPackConfigScanKernel(\n    LIMIT* const minValue,\n    LIMIT* const maxValue,\n    INPUT const* const in,\n    const size_t* const numDevice,\n    sycl::nd_item<1> &item,\n    LIMIT *minBuffer,\n    LIMIT *maxBuffer)\n{\n  static_assert(BLOCK_SIZE % 64 == 0, \"BLOCK_SIZE must a multiple of 64\");\n\n  \n\n\n  const size_t num = *numDevice;\n  const int numBlocks = roundUpDiv(num, BLOCK_SIZE);\n\n  \n\n\n  int lid = item.get_local_id(0);\n  \n\n\n  int bid = item.get_group(0);\n\n  if (bid < numBlocks) {\n    \n\n\n    LIMIT localMin = 0;\n    LIMIT localMax = 0;\n\n    int lastThread = 0;\n    for (int block = bid; block < numBlocks;\n         block += item.get_group_range(0)) {\n\n      int const blockOffset = BLOCK_SIZE * block;\n      int const blockEnd =\n          sycl::min((int)(static_cast<int>(num) - blockOffset), BLOCK_SIZE);\n\n      lastThread = sycl::max(lastThread, blockEnd);\n\n      if (lid < blockEnd) {\n        LIMIT const val = in[blockOffset + lid];\n        if (block == bid) {\n          \n\n          localMax = val;\n          localMin = val;\n        } else {\n          localMin = sycl::min(val, localMin);\n          localMax = sycl::max(val, localMax);\n        }\n      }\n    }\n\n    minBuffer[lid] = localMin;\n    maxBuffer[lid] = localMax;\n\n    item.barrier(sycl::access::fence_space::local_space);\n\n    \n\n    reduceMinAndMax(minBuffer, maxBuffer, lastThread, item);\n\n    if (lid == 0) {\n      minValue[bid] = minBuffer[0];\n      maxValue[bid] = maxBuffer[0];\n    }\n  }\n}\n\ntemplate <typename LIMIT, typename INPUT>\nvoid bitPackConfigFinalizeKernel(\n    LIMIT const* const inMin,\n    LIMIT const* const inMax,\n    unsigned char* const numBitsPtr,\n    INPUT* const outMinValPtr,\n    const size_t* const numDevice,\n    sycl::nd_item<1> &item,\n    LIMIT *minBuffer,\n    LIMIT *maxBuffer)\n{\n  static_assert(\n      BLOCK_SIZE <= BLOCK_WIDTH,\n      \"BLOCK_SIZE must be less than or equal to BLOCK_WIDTH\");\n  static_assert(\n      BLOCK_WIDTH % BLOCK_SIZE == 0,\n      \"BLOCK_WIDTH must be a multiple of BLOCK_SIZE\");\n  static_assert(BLOCK_SIZE % 64 == 0, \"BLOCK_SIZE must a multiple of 64\");\n\n  \n\n  \n\n\n  const size_t num = sycl::min(roundUpDiv(*numDevice, BLOCK_SIZE),\n                               static_cast<size_t>(BLOCK_WIDTH));\n\n  \n\n\n  int lid = item.get_local_id(0);\n\n  \n\n  \n\n\n  \n\n  readMinAndMax(inMin, inMax, minBuffer, maxBuffer, 0, num, item);\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  reduceMinAndMax(minBuffer, maxBuffer, sycl::min(BLOCK_SIZE, (int)num), item);\n\n  if (lid == 0) {\n    *outMinValPtr = static_cast<INPUT>(minBuffer[0]);\n    \n\n    if (sizeof(LIMIT) > sizeof(int)) {\n      const uint64_t range = static_cast<uint64_t>(maxBuffer[0]) - static_cast<uint64_t>(minBuffer[0]);\n      \n\n      *numBitsPtr = sizeof(uint64_t) * 8 - sycl::clz(range);\n    } else {\n      const uint32_t range = static_cast<uint32_t>(maxBuffer[0]) - static_cast<uint32_t>(minBuffer[0]);\n      \n\n      *numBitsPtr = sizeof(uint32_t) * 8 - sycl::clz(range);\n    }\n  }\n}\n\ntemplate <typename INPUT, typename OUTPUT>\nvoid bitPackKernel(\n    unsigned char const* const numBitsPtr,\n    INPUT const* const valueOffsetPtr,\n    OUTPUT* const outPtr,\n    INPUT const* const in,\n    const size_t* const numDevice,\n    sycl::nd_item<1> &item,\n    typename std::make_unsigned<INPUT>::type *inBuffer)\n{\n  const size_t num = *numDevice;\n\n  const int numBlocks = roundUpDiv(num, BLOCK_SIZE);\n\n  OUTPUT* const out = outPtr;\n  int const numBits = *numBitsPtr;\n  INPUT const valueOffset = *valueOffsetPtr;\n\n  int lid = item.get_local_id(0);\n\n  for (int blockId = item.get_group(0); blockId < numBlocks;\n       blockId += item.get_group_range(0)) {\n    \n\n    \n\n    \n\n    \n\n    int const outputIdx = lid + blockId * BLOCK_SIZE;\n    \n\n    \n\n\n    size_t const bitStart = outputIdx * sizeof(*out) * 8U;\n    size_t const bitEnd = bitStart + (sizeof(*out) * 8U);\n\n    int const startIdx = clamp(bitStart / static_cast<size_t>(numBits), num);\n    int const endIdx = clamp(roundUpDiv(bitEnd, numBits), num);\n    \n\n\n    size_t const blockStartBit = blockId * BLOCK_SIZE * sizeof(*out) * 8U;\n    size_t const blockEndBit = (blockId + 1) * BLOCK_SIZE * sizeof(*out) * 8U;\n    \n\n\n    int const blockStartIdx = clamp(\n        roundDownTo(blockStartBit / static_cast<size_t>(numBits), BLOCK_SIZE),\n        num);\n    int const blockEndIdx\n        = clamp(roundUpTo(roundUpDiv(blockEndBit, numBits), BLOCK_SIZE), num);\n    \n\n    \n\n\n    OUTPUT val = 0;\n    for (int bufferStart = blockStartIdx; bufferStart < blockEndIdx;\n         bufferStart += BLOCK_SIZE) {\n      item.barrier(sycl::access::fence_space::local_space);\n\n      \n\n      int const inputIdx = bufferStart + lid;\n      if (inputIdx < num) {\n        inBuffer[lid] = in[inputIdx] - valueOffset;\n      }\n\n      item.barrier(sycl::access::fence_space::local_space);\n\n      int const currentStartIdx = sycl::max(startIdx, bufferStart);\n      int const currentEndIdx =\n          sycl::min(endIdx, (int)(bufferStart + BLOCK_SIZE));\n\n      for (int idx = currentStartIdx; idx < currentEndIdx; ++idx) {\n        int const localIdx = idx - bufferStart;\n\n        \n\n        OUTPUT bits = static_cast<OUTPUT>(inBuffer[localIdx]);\n        int const offset = static_cast<int>(\n            static_cast<ssize_t>(idx * numBits)\n            - static_cast<ssize_t>(bitStart));\n        \n\n\n        if (offset > 0) {\n          bits <<= offset;\n        } else {\n          bits >>= -offset;\n        }\n\n        \n\n        val |= bits;\n      }\n    }\n\n    if (startIdx < num) {\n      out[outputIdx] = val;\n    }\n  }\n}\n\n\n\n\ntemplate <typename LIMIT, typename INPUT>\nvoid bitPackConfigLaunch(\n    sycl::queue &q,\n    LIMIT* const minValueScratch,\n    LIMIT* const maxValueScratch,\n    INPUT* const minValOutPtr,\n    unsigned char* const numBitsPtr,\n    INPUT const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum)\n{\n  const sycl::range<1> grid(std::min(BLOCK_WIDTH, static_cast<int>(roundUpDiv(maxNum, BLOCK_SIZE))));\n  const sycl::range<1> block(BLOCK_SIZE);\n\n  \n\n  q.submit([&](sycl::handler &cgh) {\n    sycl::local_accessor<LIMIT, 1> minBuffer(sycl::range<1>(BLOCK_SIZE), cgh);\n    sycl::local_accessor<LIMIT, 1> maxBuffer(sycl::range<1>(BLOCK_SIZE), cgh);\n    cgh.parallel_for(sycl::nd_range<1>(grid * block, block), [=](sycl::nd_item<1> item) {\n      bitPackConfigScanKernel(minValueScratch, maxValueScratch, in, numDevice, item,\n                              (LIMIT *)minBuffer.get_pointer(),\n                              (LIMIT *)maxBuffer.get_pointer());\n      });\n  });\n\n  \n\n  q.submit([&](sycl::handler &cgh) {\n    sycl::local_accessor<LIMIT, 1> minBuffer(sycl::range<1>(BLOCK_SIZE), cgh);\n    sycl::local_accessor<LIMIT, 1> maxBuffer(sycl::range<1>(BLOCK_SIZE), cgh);\n    cgh.parallel_for(sycl::nd_range<1>(block, block), [=](sycl::nd_item<1> item) {\n      bitPackConfigFinalizeKernel(\n         minValueScratch, maxValueScratch, numBitsPtr, minValOutPtr,\n         numDevice, item, (LIMIT *)minBuffer.get_pointer(),\n         (LIMIT *)maxBuffer.get_pointer());\n    });\n  });\n}\n\ntemplate <typename INPUT, typename OUTPUT>\nvoid bitPackLaunch(\n    sycl::queue &q,\n    const INPUT * const minValueDevicePtr,\n    unsigned char const* const numBitsDevicePtr,\n    OUTPUT* const outPtr,\n    INPUT const* const in,\n    const size_t* const numDevice,\n    const size_t maxNum)\n{\n  static_assert(BLOCK_SIZE % (sizeof(OUTPUT) * 8U) == 0,\n      \"Block size must be a multiple of output word size.\");\n\n  sycl::range<1> const gws (std::min(4096, static_cast<int>(roundUpDiv(maxNum, BLOCK_SIZE))) * BLOCK_SIZE);\n  sycl::range<1> const lws (BLOCK_SIZE);\n\n  using UINPUT = typename std::make_unsigned<INPUT>::type;\n  q.submit([&](sycl::handler &cgh) {\n    sycl::local_accessor<UINPUT, 1> inBuffer(sycl::range<1>(256), cgh);\n    cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      bitPackKernel(numBitsDevicePtr, minValueDevicePtr, outPtr, in,\n                    numDevice, item, inBuffer.get_pointer());\n    });\n  });\n}\n\ntemplate <typename IN, typename OUT, typename LIMIT>\nvoid bitPackFixedBitAndMinInternal(\n    sycl::queue &q,\n    void const* const minValueDevicePtr,\n    unsigned char const* const numBitsDevicePtr,\n    void* const \n,\n    void* const outPtr,\n    void const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum)\n{\n  \n\n  OUT* const outputTypedPtr = reinterpret_cast<OUT*>(outPtr);\n  IN const* const inputTyped = static_cast<IN const*>(in);\n\n  bitPackLaunch(\n      q,  \n      reinterpret_cast<const IN*>(minValueDevicePtr),\n      numBitsDevicePtr,\n      outputTypedPtr,\n      inputTyped,\n      numDevice,\n      maxNum);\n}\n\ntemplate <typename IN, typename OUT, typename LIMIT>\nvoid bitPackInternal(\n    sycl::queue &q,\n    void* const workspace,\n    void* const outPtr,\n    void const* const in,\n    const size_t* const numDevice,\n    size_t const maxNum,\n    void* const minValueDevicePtr,\n    unsigned char* const numBitsDevicePtr)\n{\n  \n\n  LIMIT* const maxValueTyped = static_cast<LIMIT*>(workspace);\n  LIMIT* const minValueTyped = maxValueTyped + getReduceScratchSpaceSize(maxNum);\n  IN const* const inputTyped = static_cast<IN const*>(in);\n\n  \n\n  bitPackConfigLaunch(\n      q,\n      minValueTyped,\n      maxValueTyped,\n      reinterpret_cast<IN*>(minValueDevicePtr),\n      numBitsDevicePtr,\n      inputTyped,\n      numDevice,\n      maxNum);\n\n  bitPackFixedBitAndMinInternal<IN, OUT, LIMIT>(\n      q,\n      minValueDevicePtr,\n      numBitsDevicePtr,\n      workspace,\n      outPtr,\n      in,\n      numDevice,\n      maxNum);\n}\n\n\nvoid compress(\n    sycl::queue &q,\n    void* const workspace,\n    const size_t workspaceSize,\n    const nvcompType_t inType,\n    void* const outPtr,\n    const void* const in,\n    const size_t* const numPtr,\n    const size_t maxNum,\n    void* const minValueDevicePtr,\n    unsigned char* const numBitsDevicePtr)\n{\n  const size_t reqWorkSize = requiredWorkspaceSize(maxNum, inType);\n  if (workspaceSize < reqWorkSize) {\n    throw std::runtime_error(\n        \"Insufficient workspace size: \" + std::to_string(workspaceSize)\n        + \", need \" + std::to_string(reqWorkSize));\n  }\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < 1000; n++)\n    NVCOMP_TYPE_SWITCH(\n      inType,\n      bitPackInternal,\n      q,\n      workspace,\n      outPtr,\n      in,\n      numPtr,\n      maxNum,\n      minValueDevicePtr,\n      numBitsDevicePtr);\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time (1000 iterations) = %f (s)\\n\", time * 1e-9f);\n}\n"}}
{"kernel_name": "blas-dot", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cmath>\n#include <cuda.h>\n#include <cuda_fp16.h>\n#include <cuda_bf16.h>\n#include <cublas_v2.h>\n\ntemplate <typename T>\nvoid dot (const size_t iNumElements, const int iNumIterations)\n{\n  const size_t src_size = iNumElements;\n  const size_t src_size_bytes = src_size * sizeof(T);\n\n  \n\n  T* srcA = (T*) malloc (src_size_bytes);\n  T* srcB = (T*) malloc (src_size_bytes);\n  T  dst;\n\n  size_t i;\n  double sum = 0.0;\n  for (i = 0; i < iNumElements ; ++i)\n  {\n    srcA[i] = (T)(sqrt(65504.0 / iNumElements));\n    srcB[i] = (T)(sqrt(65504.0 / iNumElements));\n    sum += (float)srcA[i] * (float)srcB[i];\n  }\n\n  T *d_srcA;\n  T *d_srcB;\n  T *d_dst;\n\n  cudaMalloc((void**)&d_srcA, src_size_bytes);\n  cudaMemcpy(d_srcA, srcA, src_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_srcB, src_size_bytes);\n  cudaMemcpy(d_srcB, srcB, src_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_dst, sizeof(T));\n\n\n  cublasHandle_t h;\n  cublasCreate(&h);\n  cublasSetPointerMode(h, CUBLAS_POINTER_MODE_DEVICE);\n\n  cudaDataType xType, yType, rType, eType;\n  if constexpr (std::is_same<T, double>::value) {\n    xType = yType = rType = eType = CUDA_R_64F;\n  } else if constexpr (std::is_same<T, float>::value) {\n    xType = yType = rType = eType = CUDA_R_32F;\n  } else if constexpr (std::is_same<T, __half>::value) {\n    xType = yType = rType = CUDA_R_16F;\n    eType = CUDA_R_32F;\n  } else if constexpr (std::is_same<T, __nv_bfloat16>::value) {\n    xType = yType = rType = CUDA_R_16BF;\n    eType = CUDA_R_32F;\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (i = 0; i < (size_t)iNumIterations; i++) {\n    cublasDotEx(h, iNumElements, d_srcA, xType, 1, d_srcB,\n                yType, 1, d_dst, rType, eType);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average cublasDotEx execution time %f (ms)\\n\", (time * 1e-6f) / iNumIterations);\n\n  cudaMemcpy(&dst, d_dst, sizeof(T), cudaMemcpyDeviceToHost);\n  printf(\"Host: %lf  Device: %lf\\n\", sum, double(dst));\n  printf(\"%s\\n\\n\", (fabs(double(dst) - sum) < 1e-1) ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_dst);\n  cudaFree(d_srcA);\n  cudaFree(d_srcB);\n  cublasDestroy(h);\n\n  free(srcA);\n  free(srcB);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const size_t iNumElements = atol(argv[1]);\n  const int iNumIterations = atoi(argv[2]);\n\n  printf(\"\\nFP64 Dot\\n\");\n  dot<double>(iNumElements, iNumIterations);\n  printf(\"\\nFP32 Dot\\n\");\n  dot<float>(iNumElements, iNumIterations);\n  printf(\"\\nFP16 Dot\\n\");\n  dot<__half>(iNumElements, iNumIterations);\n  printf(\"\\nBF16 Dot\\n\");\n  dot<__nv_bfloat16>(iNumElements, iNumIterations);\n\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "blas-dot", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cmath>\n#include <hip/hip_runtime.h>\n#include <hip/hip_fp16.h>\n#include <hip/hip_bf16.h>\n#include <hipblas/hipblas.h>\n\ntemplate <typename T>\nvoid dot (const size_t iNumElements, const int iNumIterations)\n{\n  const size_t src_size = iNumElements;\n  const size_t src_size_bytes = src_size * sizeof(T);\n\n  \n\n  T* srcA = (T*) malloc (src_size_bytes);\n  T* srcB = (T*) malloc (src_size_bytes);\n  T  dst;\n\n  size_t i;\n  double sum = 0.0;\n  for (i = 0; i < iNumElements ; ++i)\n  {\n    srcA[i] = (T)(sqrt(65504.0 / iNumElements));\n    srcB[i] = (T)(sqrt(65504.0 / iNumElements));\n    sum += (float)srcA[i] * (float)srcB[i];\n  }\n\n  T *d_srcA;\n  T *d_srcB;\n  T *d_dst;\n\n  hipMalloc((void**)&d_srcA, src_size_bytes);\n  hipMemcpy(d_srcA, srcA, src_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_srcB, src_size_bytes);\n  hipMemcpy(d_srcB, srcB, src_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_dst, sizeof(T));\n\n\n  hipblasHandle_t h;\n  hipblasCreate(&h);\n  hipblasSetPointerMode(h, HIPBLAS_POINTER_MODE_DEVICE);\n\n  hipDataType xType, yType, rType, eType;\n  if constexpr (std::is_same<T, double>::value) {\n    xType = yType = rType = eType = HIP_R_64F;\n  } else if constexpr (std::is_same<T, float>::value) {\n    xType = yType = rType = eType = HIP_R_32F;\n  } else if constexpr (std::is_same<T, __half>::value) {\n    xType = yType = rType = HIP_R_16F;\n    eType = HIP_R_32F;\n  } else if constexpr (std::is_same<T, __hip_bfloat16>::value) {\n    xType = yType = rType = HIP_R_16BF;\n    eType = HIP_R_32F;\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (i = 0; i < (size_t)iNumIterations; i++) {\n    hipblasDotEx_v2(h, iNumElements, d_srcA, xType, 1, d_srcB,\n                    yType, 1, d_dst, rType, eType);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average hipblasDotEx_v2 execution time %f (ms)\\n\", (time * 1e-6f) / iNumIterations);\n\n  hipMemcpy(&dst, d_dst, sizeof(T), hipMemcpyDeviceToHost);\n  printf(\"Host: %lf  Device: %lf\\n\", sum, double(dst));\n  printf(\"%s\\n\\n\", (fabs(double(dst) - sum) < 1e-1) ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_dst);\n  hipFree(d_srcA);\n  hipFree(d_srcB);\n  hipblasDestroy(h);\n\n  free(srcA);\n  free(srcB);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const size_t iNumElements = atol(argv[1]);\n  const int iNumIterations = atoi(argv[2]);\n\n  printf(\"\\nFP64 Dot\\n\");\n  dot<double>(iNumElements, iNumIterations);\n  printf(\"\\nFP32 Dot\\n\");\n  dot<float>(iNumElements, iNumIterations);\n  printf(\"\\nFP16 Dot\\n\");\n  dot<__half>(iNumElements, iNumIterations);\n  printf(\"\\nBF16 Dot\\n\");\n  dot<__hip_bfloat16>(iNumElements, iNumIterations);\n\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "blas-dot", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cmath>\n#include <sycl/sycl.hpp>\n#include <oneapi/mkl.hpp>\n\ntemplate <typename T>\nvoid dot (const size_t iNumElements, const int iNumIterations)\n{\n  const size_t src_size = iNumElements;\n  const size_t src_size_bytes = src_size * sizeof(T);\n\n  \n\n  T* srcA = (T*) malloc (src_size_bytes);\n  T* srcB = (T*) malloc (src_size_bytes);\n  T  dst;\n\n  size_t i;\n  double sum = 0.0;\n  for (i = 0; i < iNumElements ; ++i)\n  {\n    srcA[i] = (T)(sqrt(65504.0 / iNumElements));\n    srcB[i] = (T)(sqrt(65504.0 / iNumElements));\n    sum += (float)srcA[i] * (float)srcB[i];\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  T *d_srcA = sycl::malloc_device<T>(src_size, q);\n  q.memcpy(d_srcA, srcA, src_size_bytes);\n\n  T *d_srcB = sycl::malloc_device<T>(src_size, q);\n  q.memcpy(d_srcB, srcB, src_size_bytes);\n\n  T *d_dst = sycl::malloc_device<T>(1, q);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iNumIterations; i++) {\n    oneapi::mkl::blas::dot(q, iNumElements, d_srcA, 1, d_srcB, 1, d_dst);\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average oneMKL::dot execution time %f (ms)\\n\", (time * 1e-6f) / iNumIterations);\n  q.memcpy(&dst, d_dst, sizeof(T)).wait();\n  printf(\"Host: %lf  Device: %lf\\n\", sum, double(dst));\n  printf(\"%s\\n\\n\", (fabs(double(dst) - sum) < 1e-1) ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_dst, q);\n  sycl::free(d_srcA, q);\n  sycl::free(d_srcB, q);\n\n  free(srcA);\n  free(srcB);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const size_t iNumElements = atol(argv[1]);\n  const int iNumIterations = atoi(argv[2]);\n\n  printf(\"\\nFP64 Dot\\n\");\n  dot<double>(iNumElements, iNumIterations);\n  printf(\"\\nFP32 Dot\\n\");\n  dot<float>(iNumElements, iNumIterations);\n  printf(\"\\nFP16 Dot\\n\");\n  dot<sycl::half>(iNumElements, iNumIterations);\n  printf(\"\\nBF16 Dot\\n\");\n  dot<sycl::ext::oneapi::bfloat16>(iNumElements, iNumIterations);\n\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "blas-gemmBatched", "parallel_api": "cuda", "code": {"main.cu": "#include <assert.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <chrono>\n#include <cmath>\n#include <iostream>\n#include <type_traits> \n\n#include <cuda_fp16.h>\n#include <cuda_runtime.h>\n#include <cublas_v2.h>\n#include \"reference.h\"\n\nusing namespace std;\n\ntemplate <typename T>\nvoid gemmBatched(\n  int lower,\n  int upper,\n  int num,\n  int reps,\n  int verbose) \n{\n  if(verbose) cout << \"initializing inputs\" << endl;\n  size_t matrices_size = upper * upper * num * sizeof(T);\n  size_t vectors_size = upper * num * sizeof(T);\n\n  T *matrices = (T*)malloc(matrices_size);\n  assert(matrices);\n\n  T *vectors = (T*)malloc(vectors_size);\n  assert(vectors);\n\n  T *result = (T*)malloc(vectors_size);\n  assert(result);\n\n  T *result_ref = (T*)malloc(vectors_size);\n  assert(result_ref);\n\n  srand48(48);\n  for(int i = 0; i < num * upper * upper; i++)\n    matrices[i] = static_cast<T>(drand48());\n\n  for(int i = 0; i < num * upper; i++)\n    vectors[i] = static_cast<T>(drand48());\n\n  cudaError_t cudaStat;\n  cublasStatus_t stat;\n  cublasHandle_t handle;\n\n  stat = cublasCreate(&handle);\n  if(stat != CUBLAS_STATUS_SUCCESS){\n    cerr << \"cublas init failed\" << endl;\n    exit(1);\n  }\n\n  if(verbose) cout << \"allocating device variables\" << endl;\n\n  \n\n  T *devMatrices;\n  cudaStat = cudaMalloc((void**)&devMatrices, matrices_size);\n  assert(!cudaStat);\n\n  T *devVectors;\n  cudaStat = cudaMalloc((void**)&devVectors, vectors_size);\n  assert(!cudaStat);\n\n  \n\n  T *devResult;\n  cudaStat = cudaMalloc((void**)&devResult, vectors_size);\n\n  assert(!cudaStat);\n\n  if(verbose) cout << \"copying data to device\" << endl;\n  \n\n  cudaStat = \n    cudaMemcpy(devMatrices, matrices, matrices_size, cudaMemcpyHostToDevice);\n\n  assert(!cudaStat);\n  \n  cudaStat = \n    cudaMemcpy(devVectors, vectors, vectors_size, cudaMemcpyHostToDevice);\n\n  assert(!cudaStat);\n\n  \n\n  T **AList = 0, **BList = 0, **CList = 0;\n\n  AList = (T**)malloc(num * sizeof(T*));\n  BList = (T**)malloc(num * sizeof(T*));\n  CList = (T**)malloc(num * sizeof(T*));\n\n  int lda = upper, \n\n      ldb = upper, \n\n      ldc = upper; \n\n\n  const T alpha = 1.0f, beta = 0.0f;\n  for(int i = 0; i < num; i++){\n    \n\n    AList[i] = devMatrices + upper * upper * i;\n    \n\n    BList[i] = devVectors + upper * i;\n    \n\n    CList[i] = devResult + upper * i;\n  }\n\n  \n\n  T **devAList, **devBList, **devCList;\n  cudaStat = cudaMalloc((void**)&devAList, num * sizeof(T*));\n  assert(!cudaStat);\n\n  cudaStat = cudaMalloc((void**)&devBList, num * sizeof(T*));\n  assert(!cudaStat);\n\n  cudaStat = cudaMalloc((void**)&devCList, num * sizeof(T*));\n  assert(!cudaStat);\n\n  cudaStat = cudaMemcpy(devAList, AList, num * sizeof(T*), cudaMemcpyHostToDevice);\n  assert(!cudaStat);\n  \n  cudaStat = cudaMemcpy(devBList, BList, num * sizeof(T*), cudaMemcpyHostToDevice);\n  assert(!cudaStat);\n\n  cudaStat = cudaMemcpy(devCList, CList, num * sizeof(T*), cudaMemcpyHostToDevice);\n  assert(!cudaStat);\n\n\n  \n\n#define GEMM_BATCHED_PARAMETERS handle,              \\\n                                CUBLAS_OP_N,         \\\n                                CUBLAS_OP_N,         \\\n                                m, n, k,             \\\n                                &alpha,              \\\n                                (const T**)devAList, \\\n                                lda,                 \\\n                                (const T**)devBList, \\\n                                ldb,                 \\\n                                &beta,               \\\n                                devCList,            \\\n                                ldc,                 \\\n                                num\n\n  for(int size = lower; size <= upper; size++){\n    if(verbose) cout << \"running with <size x size> x <size x 1> \" << size << endl;\n    double sum = 0.0;\n    const int m = size, n = 1, k = size;\n    for(int rep = 0; rep <= reps; rep++){\n      auto start = std::chrono::steady_clock::now();\n\n      if constexpr (std::is_same_v<T, double>)\n        stat = cublasDgemmBatched(GEMM_BATCHED_PARAMETERS);\n      else if constexpr (std::is_same_v<T, float>)\n        stat = cublasSgemmBatched(GEMM_BATCHED_PARAMETERS);\n      else if constexpr (std::is_same_v<T, __half>)\n        stat = cublasHgemmBatched(GEMM_BATCHED_PARAMETERS);\n\n      cudaDeviceSynchronize();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      auto elapsed = time * 1e-3;\n\n      if(stat != CUBLAS_STATUS_SUCCESS){\n        cerr << \"cublasXgemmBatched failed\" << endl;\n        break;\n      }\n\n      if (rep != 0) sum += elapsed;\n      \n      if(verbose)\n\tcout << \"size \" << size << \": \" << elapsed << \" us; \" \n\t     << elapsed / num << \" us per operation\" << endl;\n    }\n    cout << \"size \" << size << \" average execution time: \" << sum/reps << \" us; \"\n\t << sum / reps / num << \" us per operation; \"\n         << \"floating-point operations per second: \";\n    performance(m, n, k, 1e3 * (sum / reps / num));\n\n    \n\n    if constexpr (std::is_same_v<T, double>) {\n      cudaMemcpy(result, devResult, vectors_size, cudaMemcpyDeviceToHost);\n      gemmBatched_ref (num, upper, upper, 1, m, k, n, alpha, beta,\n                       matrices, lda, vectors, ldb, result_ref, ldc);\n\n      for (int i = 0; i < num; i++) {\n      for (int j = 0; j < m; j++) {\n        if (abs(result[i*upper+j] - result_ref[i*upper+j]) > 1e-6) {\n          cout << \"Mismatch at batch index \" << i << \": \" << result[i*upper+j] << \"!=\"\n               << result_ref[i*upper+j] << endl;\n          break;\n        }\n      }}\n    }\n  }\n\n  cudaFree(devMatrices);\n  cudaFree(devVectors);\n  cudaFree(devResult);\n  cudaFree(devAList);\n  cudaFree(devBList);\n  cudaFree(devCList);\n  cublasDestroy(handle);\n\n  free(matrices);\n  free(vectors);\n  free(result);\n  free(result_ref);\n  free(AList);\n  free(BList);\n  free(CList);\n}\n\nint main(int argc, char ** argv){\n\n  int status;\n  int lower = 2;    \n\n  int upper = 100;  \n\n  int num = 25000;  \n\n  int reps = 10;\n  int verbose = 0;\n  \n  while((status = getopt(argc, argv, \"l:u:n:r:v\")) != -1){\n    switch(status){\n    case 'l':\n      lower = strtoul(optarg, 0, 0);\n      break;\n    case 'u':\n      upper = strtoul(optarg, 0, 0);\n      break;\n    case 'n':\n      num = strtoul(optarg, 0, 0);  \n\n      break;\n    case 'r':\n      reps = strtoul(optarg, 0, 0);\n      break;\n    case 'v':\n      verbose = 1;\n      break;\n    default:\n      cerr << \"invalid argument: \" << status << endl;\n      exit(1);\n    }\n  }\n\n  cout << \"running with\" << \" lower: \" << lower << \" upper: \" << upper\n       << \" num: \" << num << \" reps: \" << reps << endl;\n\n  cout << \">>>>>>>>>>>>>>> Half precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<__half>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Single precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<float>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Double precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<double>(lower, upper, num, reps, verbose);\n      \n  return 0;\n}\n"}}
{"kernel_name": "blas-gemmBatched", "parallel_api": "hip", "code": {"main.cu": "#include <assert.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <chrono>\n#include <cmath>\n#include <iostream>\n#include <type_traits> \n\n#include <hip/hip_fp16.h>\n#include <hip/hip_runtime.h>\n#include <hipblas/hipblas.h>\n#include \"reference.h\"\n\nusing namespace std;\n\n\ntemplate <typename T>\nvoid gemmBatched(\n  int lower,\n  int upper,\n  int num,\n  int reps,\n  int verbose) \n{\n  if(verbose) cout << \"initializing inputs\" << endl;\n  size_t matrices_size = upper * upper * num * sizeof(T);\n  size_t vectors_size = upper * num * sizeof(T);\n\n  T *matrices = (T*)malloc(matrices_size);\n  assert(matrices);\n\n  T *vectors = (T*)malloc(vectors_size);\n  assert(vectors);\n\n  T *result = (T*)malloc(vectors_size);\n  assert(result);\n\n  T *result_ref = (T*)malloc(vectors_size);\n  assert(result_ref);\n\n  srand48(48);\n  for(int i = 0; i < num * upper * upper; i++)\n    matrices[i] = static_cast<T>(drand48());\n\n  for(int i = 0; i < num * upper; i++)\n    vectors[i] = static_cast<T>(drand48());\n\n  hipError_t hipStat;\n  hipblasStatus_t stat;\n  hipblasHandle_t handle;\n\n  stat = hipblasCreate(&handle);\n  if(stat != HIPBLAS_STATUS_SUCCESS){\n    cerr << \"hipblas init failed\" << endl;\n    exit(1);\n  }\n\n  if(verbose) cout << \"allocating device variables\" << endl;\n\n  \n\n  T *devMatrices;\n  hipStat = hipMalloc((void**)&devMatrices, matrices_size);\n  assert(!hipStat);\n\n  T *devVectors;\n  hipStat = hipMalloc((void**)&devVectors, vectors_size);\n  assert(!hipStat);\n\n  \n\n  T *devResult;\n  hipStat = hipMalloc((void**)&devResult, vectors_size);\n\n  assert(!hipStat);\n\n  if(verbose) cout << \"copying data to device\" << endl;\n  \n\n  hipStat = \n    hipMemcpy(devMatrices, matrices, matrices_size, hipMemcpyHostToDevice);\n\n  assert(!hipStat);\n  \n  hipStat = \n    hipMemcpy(devVectors, vectors, vectors_size, hipMemcpyHostToDevice);\n\n  assert(!hipStat);\n\n  \n\n  T **AList = 0, **BList = 0, **CList = 0;\n\n  AList = (T**)malloc(num * sizeof(T*));\n  BList = (T**)malloc(num * sizeof(T*));\n  CList = (T**)malloc(num * sizeof(T*));\n\n  int lda = upper, \n\n      ldb = upper, \n\n      ldc = upper; \n\n\n  const T alpha = 1.0f, beta = 0.0f;\n  for(int i = 0; i < num; i++){\n    \n\n    AList[i] = devMatrices + upper * upper * i;\n    \n\n    BList[i] = devVectors + upper * i;\n    \n\n    CList[i] = devResult + upper * i;\n  }\n\n  \n\n  T **devAList, **devBList, **devCList;\n  hipStat = hipMalloc((void**)&devAList, num * sizeof(T*));\n  assert(!hipStat);\n\n  hipStat = hipMalloc((void**)&devBList, num * sizeof(T*));\n  assert(!hipStat);\n\n  hipStat = hipMalloc((void**)&devCList, num * sizeof(T*));\n  assert(!hipStat);\n\n  hipStat = hipMemcpy(devAList, AList, num * sizeof(T*), hipMemcpyHostToDevice);\n  assert(!hipStat);\n  \n  hipStat = hipMemcpy(devBList, BList, num * sizeof(T*), hipMemcpyHostToDevice);\n  assert(!hipStat);\n\n  hipStat = hipMemcpy(devCList, CList, num * sizeof(T*), hipMemcpyHostToDevice);\n  assert(!hipStat);\n\n\n  \n\n#define GEMM_BATCHED_PARAMETERS handle,              \\\n                                HIPBLAS_OP_N,        \\\n                                HIPBLAS_OP_N,        \\\n                                m, n, k,             \\\n                                &alpha,              \\\n                                (const T**)devAList, \\\n                                lda,                 \\\n                                (const T**)devBList, \\\n                                ldb,                 \\\n                                &beta,               \\\n                                devCList,            \\\n                                ldc,                 \\\n                                num\n\n  for(int size = lower; size <= upper; size++){\n    if(verbose) cout << \"running with <size x size> x <size x 1> \" << size << endl;\n    double sum = 0.0;\n    const int m = size, n = 1, k = size;\n    for(int rep = 0; rep <= reps; rep++){\n      auto start = std::chrono::steady_clock::now();\n\n      if constexpr (std::is_same_v<T, double>)\n        stat = hipblasDgemmBatched(GEMM_BATCHED_PARAMETERS);\n      else if constexpr (std::is_same_v<T, float>)\n        stat = hipblasSgemmBatched(GEMM_BATCHED_PARAMETERS);\n      else if constexpr (std::is_same_v<T, hipblasHalf>)\n        stat = hipblasHgemmBatched(GEMM_BATCHED_PARAMETERS);\n\n      hipDeviceSynchronize();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      auto elapsed = time * 1e-3;\n\n      if(stat != HIPBLAS_STATUS_SUCCESS){\n\tcerr << \"hipblasSgemmBatched failed\" << endl;\n        break;\n      }\n\n      if (rep != 0) sum += elapsed;\n      \n      if(verbose)\n\tcout << \"size \" << size << \": \" << elapsed << \" us; \" \n\t     << elapsed / num << \" us per operation\" << endl;\n    }\n    cout << \"size \" << size << \" average execution time: \" << sum/reps << \" us; \"\n\t << sum / reps / num << \" us per operation; \"\n         << \"floating-point operations per second: \";\n    performance(m, n, k, 1e3 * (sum / reps / num));\n\n    \n\n    if constexpr (std::is_same_v<T, double>) {\n      hipMemcpy(result, devResult, vectors_size, hipMemcpyDeviceToHost);\n      gemmBatched_ref (num, upper, upper, 1, m, k, n, alpha, beta,\n                       matrices, lda, vectors, ldb, result_ref, ldc);\n\n      for (int i = 0; i < num; i++) {\n      for (int j = 0; j < m; j++) {\n        if (abs(result[i*upper+j] - result_ref[i*upper+j]) > 1e-6) {\n          cout << \"Mismatch at batch index \" << i << \": \" << result[i*upper+j] << \"!=\"\n               << result_ref[i*upper+j] << endl;\n          break;\n        }\n      }}\n    }\n  }\n\n  hipFree(devMatrices);\n  hipFree(devVectors);\n  hipFree(devResult);\n  hipFree(devAList);\n  hipFree(devBList);\n  hipFree(devCList);\n  hipblasDestroy(handle);\n\n  free(matrices);\n  free(vectors);\n  free(result);\n  free(result_ref);\n  free(AList);\n  free(BList);\n  free(CList);\n}\n\nint main(int argc, char ** argv){\n\n  int status;\n  int lower = 2;    \n\n  int upper = 100;  \n\n  int num = 25000;  \n\n  int reps = 10;\n  int verbose = 0;\n  \n  while((status = getopt(argc, argv, \"l:u:n:r:v\")) != -1){\n    switch(status){\n    case 'l':\n      lower = strtoul(optarg, 0, 0);\n      break;\n    case 'u':\n      upper = strtoul(optarg, 0, 0);\n      break;\n    case 'n':\n      num = strtoul(optarg, 0, 0);  \n\n      break;\n    case 'r':\n      reps = strtoul(optarg, 0, 0);\n      break;\n    case 'v':\n      verbose = 1;\n      break;\n    default:\n      cerr << \"invalid argument: \" << status << endl;\n      exit(1);\n    }\n  }\n\n  cout << \"running with\" << \" lower: \" << lower << \" upper: \" << upper\n       << \" num: \" << num << \" reps: \" << reps << endl;\n\n  cout << \">>>>>>>>>>>>>>> Half precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<hipblasHalf>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Single precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<float>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Double precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<double>(lower, upper, num, reps, verbose);\n      \n  return 0;\n}\n"}}
{"kernel_name": "blas-gemmBatched", "parallel_api": "sycl", "code": {"main.cpp": "#include <assert.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <chrono>\n#include <cmath>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include <oneapi/mkl.hpp>\n#include \"reference.h\"\n\nusing namespace std;\n\ntemplate <typename T>\nvoid gemmBatched(\n  int lower,\n  int upper,\n  int num,\n  int reps,\n  int verbose) try \n{\n  if(verbose) cout << \"initializing inputs\" << endl;\n  size_t matrices_size = upper * upper * num * sizeof(T);\n  size_t vectors_size = upper * num * sizeof(T);\n\n  T *matrices = (T*)malloc(matrices_size);\n  assert(matrices);\n\n  T *vectors = (T*)malloc(vectors_size);\n  assert(vectors);\n\n  T *result = (T*)malloc(vectors_size);\n  assert(result);\n\n  T *result_ref = (T*)malloc(vectors_size);\n  assert(result_ref);\n\n  srand48(48);\n  for(int i = 0; i < num * upper * upper; i++)\n    matrices[i] = static_cast<T>(drand48());\n\n  for(int i = 0; i < num * upper; i++)\n    vectors[i] = static_cast<T>(drand48());\n\n  if(verbose) cout << \"allocating device variables\" << endl;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  T *devMatrices = (T *)sycl::malloc_device(matrices_size, q);\n  assert(devMatrices != nullptr);\n\n  T *devVectors = (T *)sycl::malloc_device(vectors_size, q);\n  assert(devVectors != nullptr);\n\n  \n\n  T *devResult = (T *)sycl::malloc_device(vectors_size, q);\n  assert(devResult != nullptr);\n\n  if(verbose) cout << \"copying data to device\" << endl;\n  \n\n  q.memcpy(devMatrices, matrices, matrices_size).wait();\n  q.memcpy(devVectors, vectors, vectors_size).wait();\n\n  \n\n  T **AList = 0, **BList = 0, **CList = 0;\n\n  AList = (T**)malloc(num * sizeof(T*));\n  BList = (T**)malloc(num * sizeof(T*));\n  CList = (T**)malloc(num * sizeof(T*));\n\n  int lda = upper, \n\n      ldb = upper, \n\n      ldc = upper; \n\n\n  const T alpha = 1.0f, beta = 0.0f;\n  for(int i = 0; i < num; i++){\n    \n\n    AList[i] = devMatrices + upper * upper * i;\n    \n\n    BList[i] = devVectors + upper * i;\n    \n\n    CList[i] = devResult + upper * i;\n  }\n\n  \n\n  T **devAList, **devBList, **devCList;\n  devAList = sycl::malloc_device<T *>(num, q);\n  assert(devAList != nullptr);\n\n  devBList = sycl::malloc_device<T *>(num, q);\n  assert(devBList != nullptr);\n\n  devCList = sycl::malloc_device<T *>(num, q);\n  assert(devCList != nullptr);\n\n  q.memcpy(devAList, AList, num * sizeof(T *)).wait();\n  q.memcpy(devBList, BList, num * sizeof(T *)).wait();\n  q.memcpy(devCList, CList, num * sizeof(T *)).wait();\n\n\n  \n\n  struct param_t {\n    oneapi::mkl::transpose transpose_info[2];\n    T value_info[2];\n    std::int64_t size_info[3];\n    std::int64_t ld_info[3];\n    std::int64_t groupsize_info;\n  };\n\n  param_t *p = (param_t *)std::malloc(sizeof(param_t));\n  p->transpose_info[0] = oneapi::mkl::transpose::nontrans;\n  p->transpose_info[1] = oneapi::mkl::transpose::nontrans;\n  p->value_info[0] = alpha;\n  p->value_info[1] = beta;\n  p->ld_info[0] = lda;\n  p->ld_info[1] = ldb;\n  p->ld_info[2] = ldc;\n  p->groupsize_info = num;\n\n  for(int size = lower; size <= upper; size++){\n    if(verbose) cout << \"running with <size x size> x <size x 1> \" << size << endl;\n    double sum = 0.0;\n    const int m = size, n = 1, k = size;\n    p->size_info[0] = m;\n    p->size_info[1] = n;\n    p->size_info[2] = k;\n    for(int rep = 0; rep <= reps; rep++){\n      auto start = std::chrono::steady_clock::now();\n\n      oneapi::mkl::blas::column_major::gemm_batch(\n        q, p->transpose_info, p->transpose_info + 1,\n        p->size_info, p->size_info + 1,\n        p->size_info + 2, p->value_info,\n        const_cast<const T**>(devAList), p->ld_info,\n        const_cast<const T**>(devBList), p->ld_info + 1,\n        p->value_info + 1, devCList,\n        p->ld_info + 2, 1, &(p->groupsize_info)).wait();\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      auto elapsed = time * 1e-3;\n\n      if (rep != 0) sum += elapsed;\n      \n      if(verbose)\n\tcout << \"size \" << size << \": \" << elapsed << \" us; \" \n\t     << elapsed / num << \" us per operation\" << endl;\n    }\n    cout << \"size \" << size << \" average execution time: \" << sum/reps << \" us; \"\n\t << sum / reps / num << \" us per operation; \"\n         << \"floating-point operations per second: \";\n    performance(m, n, k, 1e3 * (sum / reps / num));\n\n    \n\n    if constexpr (std::is_same_v<T, double>) {\n      q.memcpy(result, devResult, vectors_size).wait();\n      gemmBatched_ref (num, upper, upper, 1, m, k, n, alpha, beta,\n                       matrices, lda, vectors, ldb, result_ref, ldc);\n\n      for (int i = 0; i < num; i++) {\n      for (int j = 0; j < m; j++) {\n        if (abs(result[i*upper+j] - result_ref[i*upper+j]) > 1e-6) {\n          cout << \"Mismatch at batch index \" << i << \": \" << result[i*upper+j] << \"!=\"\n               << result_ref[i*upper+j] << endl;\n          break;\n        }\n      }}\n    }\n  }\n\n  sycl::free(devMatrices, q);\n  sycl::free(devVectors, q);\n  sycl::free(devResult, q);\n  sycl::free(devAList, q);\n  sycl::free(devBList, q);\n  sycl::free(devCList, q);\n\n  free(p);\n  free(matrices);\n  free(vectors);\n  free(result);\n  free(result_ref);\n  free(AList);\n  free(BList);\n  free(CList);\n}\ncatch (sycl::exception const &exc) {\n  std::cerr << exc.what() << \"Exception caught at file:\" << __FILE__\n            << \", line:\" << __LINE__ << std::endl;\n  std::exit(1);\n}\n\nint main(int argc, char **argv) {\n\n  int status;\n  int lower = 2;    \n\n  int upper = 100;  \n\n  int num = 25000;  \n\n  int reps = 10;\n  int verbose = 0;\n  \n  while((status = getopt(argc, argv, \"l:u:n:r:v\")) != -1){\n    switch(status){\n    case 'l':\n      lower = strtoul(optarg, 0, 0);\n      break;\n    case 'u':\n      upper = strtoul(optarg, 0, 0);\n      break;\n    case 'n':\n      num = strtoul(optarg, 0, 0);\n      break;\n    case 'r':\n      reps = strtoul(optarg, 0, 0);\n      break;\n    case 'v':\n      verbose = 1;\n      break;\n    default:\n      cerr << \"invalid argument: \" << status << endl;\n      exit(1);\n    }\n  }\n\n  cout << \"running with\" << \" lower: \" << lower << \" upper: \" << upper\n       << \" num: \" << num << \" reps: \" << reps << endl;\n\n  cout << \">>>>>>>>>>>>>>> Half precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<sycl::half>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Single precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<float>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Double precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<double>(lower, upper, num, reps, verbose);\n      \n  return 0;\n}\n"}}
{"kernel_name": "clock", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <stdio.h>\n#include <stdint.h>\n#include <assert.h>\n\n\n\n#include <cuda.h>\n\n\n\n\n\n\n\n\n__global__ static void timedReduction(const float *input, float *output, clock_t *timer)\n{\n    \n\n    extern __shared__ float shared[];\n\n    const int tid = threadIdx.x;\n    const int bid = blockIdx.x;\n\n    if (tid == 0) timer[bid] = clock();\n\n    \n\n    shared[tid] = input[tid];\n    shared[tid + blockDim.x] = input[tid + blockDim.x];\n\n    \n\n    for (int d = blockDim.x; d > 0; d /= 2)\n    {\n        __syncthreads();\n\n        if (tid < d)\n        {\n            float f0 = shared[tid];\n            float f1 = shared[tid + d];\n\n            if (f1 < f0)\n            {\n                shared[tid] = f1;\n            }\n        }\n    }\n\n    \n\n    if (tid == 0) output[bid] = shared[0];\n\n    __syncthreads();\n\n    if (tid == 0) timer[bid+gridDim.x] = clock();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef NUM_BLOCKS\n#define NUM_BLOCKS    32\n#endif\n\n#define NUM_THREADS   256\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char **argv)\n{\n    printf(\"CUDA Clock sample\\n\");\n\n    float *dinput = NULL;\n    float *doutput = NULL;\n    clock_t *dtimer = NULL;\n\n    clock_t timer[NUM_BLOCKS * 2];\n    float input[NUM_THREADS * 2];\n\n    for (int i = 0; i < NUM_THREADS * 2; i++)\n    {\n        input[i] = (float)i;\n    }\n\n    cudaMalloc((void **)&dinput, sizeof(float) * NUM_THREADS * 2);\n    cudaMalloc((void **)&doutput, sizeof(float) * NUM_BLOCKS);\n    cudaMalloc((void **)&dtimer, sizeof(clock_t) * NUM_BLOCKS * 2);\n\n    cudaMemcpy(dinput, input, sizeof(float) * NUM_THREADS * 2, cudaMemcpyHostToDevice);\n\n    timedReduction<<<NUM_BLOCKS, NUM_THREADS, sizeof(float) * 2 *NUM_THREADS>>>(dinput, doutput, dtimer);\n\n    cudaMemcpy(timer, dtimer, sizeof(clock_t) * NUM_BLOCKS * 2, cudaMemcpyDeviceToHost);\n\n    cudaFree(dinput);\n    cudaFree(doutput);\n    cudaFree(dtimer);\n\n    long double totalBlockTime = 0;\n    for (int i = 0; i < NUM_BLOCKS; i++)\n    {\n        \n\n        totalBlockTime += timer[NUM_BLOCKS+i] - timer[i];\n    }\n\n    \n\n    clock_t minStart = timer[0];\n    clock_t maxEnd = timer[NUM_BLOCKS];\n\n    for (int i = 1; i < NUM_BLOCKS; i++)\n    {\n        minStart = timer[i] < minStart ? timer[i] : minStart;\n        maxEnd = timer[NUM_BLOCKS+i] > maxEnd ? timer[NUM_BLOCKS+i] : maxEnd;\n    }\n\n    printf(\"Total clocks = %lu\\n\", (maxEnd - minStart));\n    printf(\"Execution efficiency = %Lf\\n\", 100 * totalBlockTime / (long double)(maxEnd - minStart));\n\n    return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "clock", "parallel_api": "hip", "code": {"main.cu": "#include \"hip/hip_runtime.h\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <stdio.h>\n#include <stdint.h>\n#include <assert.h>\n\n\n\n#include <hip/hip_runtime.h>\n\n\n\n\n\n\n\n\n__global__ static void timedReduction(const float *input, float *output, clock_t *timer)\n{\n    \n\n    HIP_DYNAMIC_SHARED( float, shared)\n\n    const int tid = threadIdx.x;\n    const int bid = blockIdx.x;\n\n    if (tid == 0) timer[bid] = clock();\n\n    \n\n    shared[tid] = input[tid];\n    shared[tid + blockDim.x] = input[tid + blockDim.x];\n\n    \n\n    for (int d = blockDim.x; d > 0; d /= 2)\n    {\n        __syncthreads();\n\n        if (tid < d)\n        {\n            float f0 = shared[tid];\n            float f1 = shared[tid + d];\n\n            if (f1 < f0)\n            {\n                shared[tid] = f1;\n            }\n        }\n    }\n\n    \n\n    if (tid == 0) output[bid] = shared[0];\n\n    __syncthreads();\n\n    if (tid == 0) timer[bid+gridDim.x] = clock();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef NUM_BLOCKS\n#define NUM_BLOCKS    32\n#endif\n\n#define NUM_THREADS   256\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char **argv)\n{\n    printf(\"CUDA Clock sample\\n\");\n\n    float *dinput = NULL;\n    float *doutput = NULL;\n    clock_t *dtimer = NULL;\n\n    clock_t timer[NUM_BLOCKS * 2];\n    float input[NUM_THREADS * 2];\n\n    for (int i = 0; i < NUM_THREADS * 2; i++)\n    {\n        input[i] = (float)i;\n    }\n\n    hipMalloc((void **)&dinput, sizeof(float) * NUM_THREADS * 2);\n    hipMalloc((void **)&doutput, sizeof(float) * NUM_BLOCKS);\n    hipMalloc((void **)&dtimer, sizeof(clock_t) * NUM_BLOCKS * 2);\n\n    hipMemcpy(dinput, input, sizeof(float) * NUM_THREADS * 2, hipMemcpyHostToDevice);\n\n    hipLaunchKernelGGL(timedReduction, dim3(NUM_BLOCKS), dim3(NUM_THREADS), sizeof(float) * 2 *NUM_THREADS, 0, dinput, doutput, dtimer);\n\n    hipMemcpy(timer, dtimer, sizeof(clock_t) * NUM_BLOCKS * 2, hipMemcpyDeviceToHost);\n\n    hipFree(dinput);\n    hipFree(doutput);\n    hipFree(dtimer);\n\n    long double totalBlockTime = 0;\n    for (int i = 0; i < NUM_BLOCKS; i++)\n    {\n        \n\n        totalBlockTime += timer[NUM_BLOCKS+i] - timer[i];\n    }\n\n    \n\n    clock_t minStart = timer[0];\n    clock_t maxEnd = timer[NUM_BLOCKS];\n\n    for (int i = 1; i < NUM_BLOCKS; i++)\n    {\n        minStart = timer[i] < minStart ? timer[i] : minStart;\n        maxEnd = timer[NUM_BLOCKS+i] > maxEnd ? timer[NUM_BLOCKS+i] : maxEnd;\n    }\n\n    printf(\"Total clocks = %lu\\n\", (maxEnd - minStart));\n    printf(\"Execution efficiency = %Lf\\n\", 100 * totalBlockTime / (long double)(maxEnd - minStart));\n\n    return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "columnarSolver", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n\n#define B ((int)32)\n#define T ((int)32)\n#define THREADS ((int)B*T)\n#define CLIMBINGS 150000\n#define ALPHABET 26\n#define totalBigrams ((int)ALPHABET*ALPHABET)\n#define CAP ((float)999999.0)\n\n#define ENCRYPTED_T \"tteohtedanisroudesereguwocubsoitoabbofeiaiutsdheeisatsarsturesuaastniersrotnesctrctxdiwmhcusyenorndasmhaipnnptmaeecspegdeislwoheoiymreeotbsspiatoanihrelhwctftrhpuunhoianunreetrioettatlsnehtbaecpvgtltcirottonesnobeeeireaymrtohaawnwtesssvassirsrhabapnsynntitsittchitoosbtelmlaouitrehhwfeiaandeitciegfreoridhdcsheucrnoihdeoswobaceeaorgndlstigeearsotoetduedininttpedststntefoeaheoesuetvmmiorftuuhsurof\"\n#define ENCRYPTEDLEN ((int)sizeof(ENCRYPTED_T)-1)\n\n#define DECRYPTED_T \"thedistinctionbetweentherouteciphertranspositionandthesubstitutioncipherwherewholewordsaresubstitutedforlettersoftheoriginaltextmustbemadeonthebasisofthewordsactuallyuseditisbettertoconsidersuchamessageasaroutecipherwhenthewordsusedappeartohavesomeconsecutivemeaningbearingonthesituationathandasubstitutioncipherofthisvarietywouldonlybeusedfortransmissionofashortmessageofgreatimportanceandsecrecy\"\n\n#define KEY_LENGTH 30\n#define SECTION_CONSTANT ENCRYPTEDLEN/KEY_LENGTH\n\n#define HEUR_THRESHOLD_OP1 50\n#define HEUR_THRESHOLD_OP2 70\n\n#define OP1_HOP 4\n#define OP2_HOP 2\n\n\n#include \"kernels.cu\"\n\nbool extractBigrams(float *scores, const char* filename) {\n  FILE* bigramsFile = fopen(filename, \"r\");\n  if (bigramsFile == NULL) {\n    fprintf(stderr, \"Failed to open file %s. Exit\\n\", filename);\n    return true;\n  }\n  while(1){\n    char tempBigram[2];\n    float tempBigramScore = 0.0;\n    if (fscanf(bigramsFile, \"%s %f\", tempBigram, &tempBigramScore) < 2)\n    { break; } \n    scores[(tempBigram[0]-'a')*ALPHABET + tempBigram[1]-'a'] = tempBigramScore; \n  }\n  fclose(bigramsFile);\n  return false;\n}\n\nbool verify(int* encrMap) {\n  bool pass = true;\n  const char *expect = DECRYPTED_T;\n  for (int j=0; j<ENCRYPTEDLEN; ++j) {\n    if (encrMap[j] + 'a' != expect[j]) {\n       pass = false; break;\n    }\n  }\n  return pass;\n}\n\nfloat candidateScore(int* decrMsg, float* scores) {\n  float total = 0.0;\n  for (int j=0; j<ENCRYPTEDLEN-1; ++j) \n    total += scores[ALPHABET*decrMsg[j] + decrMsg[j+1]];  \n  return total;\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <path to file>\\n\", argv[0]);\n    return 1;\n  }\n  const char* filename = argv[1];\n\n  int encryptedMap[ENCRYPTEDLEN];\n\n  for (int j=0; j<ENCRYPTEDLEN; ++j)\n    encryptedMap[j] = ENCRYPTED_T[j] - 'a';\n\n  float scores[totalBigrams];  \n  bool fail = extractBigrams(scores, filename);\n  if (fail) return 1;\n\n  float *d_scores;\n  int *d_encrypted, *d_decrypted;\n  int* decrypted = new int[ENCRYPTEDLEN*THREADS];\n\n  cudaMalloc((void **)&d_scores, sizeof(float)*totalBigrams);\n  cudaMalloc((void **)&d_encrypted, sizeof(int)*ENCRYPTEDLEN);\n  cudaMalloc((void **)&d_decrypted, sizeof(int)*ENCRYPTEDLEN*THREADS);\n\n  cudaMemcpy(d_scores, scores, sizeof(float)*totalBigrams, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_encrypted, encryptedMap, sizeof(int)*ENCRYPTEDLEN, cudaMemcpyHostToDevice);\n\n  unsigned int* devStates;\n  cudaMalloc(&devStates, THREADS*sizeof(unsigned int));\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  setupKernel<<<B,T>>>(devStates);\n\n  decode<<<B,T>>>(d_scores, d_encrypted, devStates, d_decrypted);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Kernel execution time %f (s)\\n\", time * 1e-9f);\n\n  cudaMemcpy(decrypted, d_decrypted, sizeof(int)*ENCRYPTEDLEN*THREADS, cudaMemcpyDeviceToHost);\n\n  int bestCandidate = 0;\n  float bestScore = CAP;\n  float* scoreHistory = new float[B*T];\n\n  \n\n  for (int j=0; j<THREADS; ++j)  {\n    float currentScore = candidateScore(&decrypted[ENCRYPTEDLEN*j], scores);\n    scoreHistory[j] = currentScore;\n    if (currentScore < bestScore) {\n      bestScore = currentScore;\n      bestCandidate = j;\n    }    \n  }  \n\n  \n\n  bool pass = verify(&decrypted[ENCRYPTEDLEN*bestCandidate]);\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_scores);\n  cudaFree(d_encrypted);\n  cudaFree(d_decrypted);\n  cudaFree(devStates);\n  delete[] decrypted;\n  delete[] scoreHistory;\n  return 0;\n}\n", "kernels.cu": "__device__\nfloat LCG_random_float(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n__device__\nvoid LCG_random_init(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n}\n\n__global__\nvoid setupKernel(unsigned int* state) {\n  int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  state[idx] = idx;\n  for (int i = 0; i < idx; i++)\n    LCG_random_init(&state[idx]);\n}\n\n__device__\nvoid decrypt(const int* encrypted, const int* key, int* decrypted) {\n\n  int columns[KEY_LENGTH][SECTION_CONSTANT+1];\n  int offset = 0;\n  int colLength[KEY_LENGTH];\n\n  for (int j=0; j<KEY_LENGTH; ++j) {\n    colLength[j] = ENCRYPTEDLEN / KEY_LENGTH;\n    if (j < ENCRYPTEDLEN % KEY_LENGTH)\n      colLength[j]++;\n  }\n\n  for (int keyPos=0; keyPos < KEY_LENGTH; ++keyPos) {\n    offset = 0;\n    for (int i=0; i<KEY_LENGTH; ++i)\n      if (key[i] < key[keyPos])\n        offset += colLength[i];\n\n    for (int j=0; j<colLength[keyPos]; ++j)   \n      columns[key[keyPos]][j] = encrypted[offset+j];          \n  } \n\n  for (int j=0; j<ENCRYPTEDLEN; ++j) \n    decrypted[j] = columns[key[j % KEY_LENGTH]][j / KEY_LENGTH];  \n} \n\n__device__\nvoid swapElements(int *key, int posLeft, int posRight) {\n  if (posLeft != posRight)\n  {\n    key[posLeft] -= key[posRight];\n    key[posRight] += key[posLeft];\n    key[posLeft] = key[posRight] - key[posLeft];\n  }\n}\n\n__device__ \nvoid swapBlock(int *key, int posLeft, int posRight, int length) {  \n  for (int i=0; i<length; i++) \n    swapElements(key, (posLeft+i)%KEY_LENGTH, (posRight+i)%KEY_LENGTH);\n}\n\n__global__ \nvoid decode(const float *__restrict d_scores, \n            const int *__restrict d_encrypted,\n            const unsigned int*__restrict  globalState, \n            int *__restrict d_decrypted) {\n\n  __shared__ float shared_scores[ALPHABET*ALPHABET];\n\n  int key[KEY_LENGTH];\n  int localDecrypted[ENCRYPTEDLEN];  \n  int bestLocalDecrypted[ENCRYPTEDLEN];  \n  int leftLetter = 0;\n  int rightLetter = 0;\n  int backupKey[KEY_LENGTH];\n  int shiftHelper[KEY_LENGTH];\n  int blockStart, blockEnd;\n  int l,f,t,t0,n,ff,tt;\n  float tempScore = 0.f;\n  float bestScore = CAP;\n  int j = 0, jj = 0;\n\n  int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned int localState = globalState[idx];\n\n  if (threadIdx.x == 0) {\n    for (j=0; j<ALPHABET;++j)\n      for (jj=0; jj<ALPHABET; ++jj)\n        shared_scores[j*ALPHABET + jj] = d_scores[j*ALPHABET + jj];\n  }\n\n  __syncthreads();\n\n  for (j=0; j<KEY_LENGTH; ++j) \n    key[j]=j;\n\n  for (j=0; j<KEY_LENGTH; ++j) {\n    swapElements(key, j, LCG_random_float(&localState)*KEY_LENGTH);\n  }\n\n  for (int cycles=0; cycles<CLIMBINGS; ++cycles) {  \n\n    for (j=0; j<KEY_LENGTH;j++)\n      backupKey[j] = key[j];\n\n    tempScore = 0.f;\n\n    int branch = LCG_random_float(&localState)*100; \n\n    if (branch < HEUR_THRESHOLD_OP1)\n    {\n      for (j=0; j<1+LCG_random_float(&localState)*OP1_HOP; j++) \n      {\n        leftLetter = LCG_random_float(&localState)*KEY_LENGTH;   \n        rightLetter = LCG_random_float(&localState)*KEY_LENGTH; \n        swapElements(key, leftLetter, rightLetter);\n      }            \n    }\n\n    else if (branch < HEUR_THRESHOLD_OP2)\n    {\n      for (j=0; j< 1+LCG_random_float(&localState)*OP2_HOP;j++)\n      {\n        blockStart = LCG_random_float(&localState)*KEY_LENGTH;\n        blockEnd = LCG_random_float(&localState)*KEY_LENGTH;\n        swapBlock(key, blockStart, blockEnd, 1+LCG_random_float(&localState)*(abs((blockStart-blockEnd))-1));\n      }\n    }\n\n    else \n    {\n      l = 1 + LCG_random_float(&localState)*(KEY_LENGTH-2);\n      f = LCG_random_float(&localState)*(KEY_LENGTH-1);\n      t = (f+1+(LCG_random_float(&localState)*(KEY_LENGTH-2)));\n      t = t % KEY_LENGTH;\n\n      for (j=0; j< KEY_LENGTH;j++)\n        shiftHelper[j] = key[j];\n\n      t0 = (t-f+KEY_LENGTH) % KEY_LENGTH;\n      n = (t0+l) % KEY_LENGTH;\n\n      for (j=0; j<n;j++) \n      {\n        ff = (f+j) % KEY_LENGTH;\n        tt = (((t0+j)%n)+f)%KEY_LENGTH;\n        key[tt] = shiftHelper[ff];\n      }        \n    }      \n\n    decrypt(d_encrypted, key, localDecrypted);    \n\n    for (j=0; j<ENCRYPTEDLEN-1; ++j) {\n      tempScore += shared_scores[ALPHABET*localDecrypted[j] + localDecrypted[j+1]];\n    }\n\n    if (tempScore < bestScore) {\n      bestScore = tempScore;\n      for (j=0; j<ENCRYPTEDLEN; ++j) {\n        bestLocalDecrypted[j] = localDecrypted[j];\n      }\n    }    \n\n    else \n    {\n      for (j=0; j<KEY_LENGTH;j++)\n        key[j] = backupKey[j];      \n    }\n  }\n\n  for (j=0; j<ENCRYPTEDLEN; ++j)\n    d_decrypted[idx*ENCRYPTEDLEN+j] = bestLocalDecrypted[j];\n}\n\n"}}
{"kernel_name": "columnarSolver", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define B ((int)32)\n#define T ((int)32)\n#define THREADS ((int)B*T)\n#define CLIMBINGS 150000\n#define ALPHABET 26\n#define totalBigrams ((int)ALPHABET*ALPHABET)\n#define CAP ((float)999999.0)\n\n#define ENCRYPTED_T \"tteohtedanisroudesereguwocubsoitoabbofeiaiutsdheeisatsarsturesuaastniersrotnesctrctxdiwmhcusyenorndasmhaipnnptmaeecspegdeislwoheoiymreeotbsspiatoanihrelhwctftrhpuunhoianunreetrioettatlsnehtbaecpvgtltcirottonesnobeeeireaymrtohaawnwtesssvassirsrhabapnsynntitsittchitoosbtelmlaouitrehhwfeiaandeitciegfreoridhdcsheucrnoihdeoswobaceeaorgndlstigeearsotoetduedininttpedststntefoeaheoesuetvmmiorftuuhsurof\"\n#define ENCRYPTEDLEN ((int)sizeof(ENCRYPTED_T)-1)\n\n#define DECRYPTED_T \"thedistinctionbetweentherouteciphertranspositionandthesubstitutioncipherwherewholewordsaresubstitutedforlettersoftheoriginaltextmustbemadeonthebasisofthewordsactuallyuseditisbettertoconsidersuchamessageasaroutecipherwhenthewordsusedappeartohavesomeconsecutivemeaningbearingonthesituationathandasubstitutioncipherofthisvarietywouldonlybeusedfortransmissionofashortmessageofgreatimportanceandsecrecy\"\n\n#define KEY_LENGTH 30\n#define SECTION_CONSTANT ENCRYPTEDLEN/KEY_LENGTH\n\n#define HEUR_THRESHOLD_OP1 50\n#define HEUR_THRESHOLD_OP2 70\n\n#define OP1_HOP 4\n#define OP2_HOP 2\n\n\n#include \"kernels.cu\"\n\nbool extractBigrams(float *scores, const char* filename) {\n  FILE* bigramsFile = fopen(filename, \"r\");\n  if (bigramsFile == NULL) {\n    fprintf(stderr, \"Failed to open file %s. Exit\\n\", filename);\n    return true;\n  }\n  while(1){\n    char tempBigram[2];\n    float tempBigramScore = 0.0;\n    if (fscanf(bigramsFile, \"%s %f\", tempBigram, &tempBigramScore) < 2)\n    { break; } \n    scores[(tempBigram[0]-'a')*ALPHABET + tempBigram[1]-'a'] = tempBigramScore; \n  }\n  fclose(bigramsFile);\n  return false;\n}\n\nbool verify(int* encrMap) {\n  bool pass = true;\n  const char *expect = DECRYPTED_T;\n  for (int j=0; j<ENCRYPTEDLEN; ++j) {\n    if (encrMap[j] + 'a' != expect[j]) {\n       pass = false; break;\n    }\n  }\n  return pass;\n}\n\nfloat candidateScore(int* decrMsg, float* scores) {\n  float total = 0.0;\n  for (int j=0; j<ENCRYPTEDLEN-1; ++j) \n    total += scores[ALPHABET*decrMsg[j] + decrMsg[j+1]];  \n  return total;\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <path to file>\\n\", argv[0]);\n    return 1;\n  }\n  const char* filename = argv[1];\n\n  int encryptedMap[ENCRYPTEDLEN];\n\n  for (int j=0; j<ENCRYPTEDLEN; ++j)\n    encryptedMap[j] = ENCRYPTED_T[j] - 'a';\n\n  float scores[totalBigrams];  \n  bool fail = extractBigrams(scores, filename);\n  if (fail) return 1;\n\n  float *d_scores;\n  int *d_encrypted, *d_decrypted;\n  int* decrypted = new int[ENCRYPTEDLEN*THREADS];\n\n  hipMalloc((void **)&d_scores, sizeof(float)*totalBigrams);\n  hipMalloc((void **)&d_encrypted, sizeof(int)*ENCRYPTEDLEN);\n  hipMalloc((void **)&d_decrypted, sizeof(int)*ENCRYPTEDLEN*THREADS);\n\n  hipMemcpy(d_scores, scores, sizeof(float)*totalBigrams, hipMemcpyHostToDevice);\n  hipMemcpy(d_encrypted, encryptedMap, sizeof(int)*ENCRYPTEDLEN, hipMemcpyHostToDevice);\n\n  unsigned int* devStates;\n  hipMalloc(&devStates, THREADS*sizeof(unsigned int));\n  \n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  hipLaunchKernelGGL(setupKernel, dim3(B), dim3(T), 0, 0, devStates);\n\n  hipLaunchKernelGGL(decode, dim3(B), dim3(T), 0, 0, d_scores, d_encrypted, devStates, d_decrypted);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Kernel execution time %f (s)\\n\", time * 1e-9f);\n\n  hipMemcpy(decrypted, d_decrypted, sizeof(int)*ENCRYPTEDLEN*THREADS, hipMemcpyDeviceToHost);\n\n  int bestCandidate = 0;\n  float bestScore = CAP;\n  float* scoreHistory = new float[B*T];\n\n  \n\n  for (int j=0; j<THREADS; ++j)  {\n    float currentScore = candidateScore(&decrypted[ENCRYPTEDLEN*j], scores);\n    scoreHistory[j] = currentScore;\n    if (currentScore < bestScore) {\n      bestScore = currentScore;\n      bestCandidate = j;\n    }    \n  }  \n\n  \n\n  bool pass = verify(&decrypted[ENCRYPTEDLEN*bestCandidate]);\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_scores);\n  hipFree(d_encrypted);\n  hipFree(d_decrypted);\n  hipFree(devStates);\n  delete[] decrypted;\n  delete[] scoreHistory;\n  return 0;\n}\n", "kernels.cu": "__device__\nfloat LCG_random_float(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n__device__\nvoid LCG_random_init(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n}\n\n__global__\nvoid setupKernel(unsigned int* state) {\n  int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  state[idx] = idx;\n  for (int i = 0; i < idx; i++)\n    LCG_random_init(&state[idx]);\n}\n\n__device__\nvoid decrypt(const int* encrypted, const int* key, int* decrypted) {\n\n  int columns[KEY_LENGTH][SECTION_CONSTANT+1];\n  int offset = 0;\n  int colLength[KEY_LENGTH];\n\n  for (int j=0; j<KEY_LENGTH; ++j) {\n    colLength[j] = ENCRYPTEDLEN / KEY_LENGTH;\n    if (j < ENCRYPTEDLEN % KEY_LENGTH)\n      colLength[j]++;\n  }\n\n  for (int keyPos=0; keyPos < KEY_LENGTH; ++keyPos) {\n    offset = 0;\n    for (int i=0; i<KEY_LENGTH; ++i)\n      if (key[i] < key[keyPos])\n        offset += colLength[i];\n\n    for (int j=0; j<colLength[keyPos]; ++j)   \n      columns[key[keyPos]][j] = encrypted[offset+j];          \n  } \n\n  for (int j=0; j<ENCRYPTEDLEN; ++j) \n    decrypted[j] = columns[key[j % KEY_LENGTH]][j / KEY_LENGTH];  \n} \n\n__device__\nvoid swapElements(int *key, int posLeft, int posRight) {\n  if (posLeft != posRight)\n  {\n    key[posLeft] -= key[posRight];\n    key[posRight] += key[posLeft];\n    key[posLeft] = key[posRight] - key[posLeft];\n  }\n}\n\n__device__ \nvoid swapBlock(int *key, int posLeft, int posRight, int length) {  \n  for (int i=0; i<length; i++) \n    swapElements(key, (posLeft+i)%KEY_LENGTH, (posRight+i)%KEY_LENGTH);\n}\n\n__global__ \nvoid decode(const float *__restrict d_scores, \n            const int *__restrict d_encrypted,\n            const unsigned int*__restrict  globalState, \n            int *__restrict d_decrypted) {\n\n  __shared__ float shared_scores[ALPHABET*ALPHABET];\n\n  int key[KEY_LENGTH];\n  int localDecrypted[ENCRYPTEDLEN];  \n  int bestLocalDecrypted[ENCRYPTEDLEN];  \n  int leftLetter = 0;\n  int rightLetter = 0;\n  int backupKey[KEY_LENGTH];\n  int shiftHelper[KEY_LENGTH];\n  int blockStart, blockEnd;\n  int l,f,t,t0,n,ff,tt;\n  float tempScore = 0.f;\n  float bestScore = CAP;\n  int j = 0, jj = 0;\n\n  int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned int localState = globalState[idx];\n\n  if (threadIdx.x == 0) {\n    for (j=0; j<ALPHABET;++j)\n      for (jj=0; jj<ALPHABET; ++jj)\n        shared_scores[j*ALPHABET + jj] = d_scores[j*ALPHABET + jj];\n  }\n\n  __syncthreads();\n\n  for (j=0; j<KEY_LENGTH; ++j) \n    key[j]=j;\n\n  for (j=0; j<KEY_LENGTH; ++j) {\n    swapElements(key, j, LCG_random_float(&localState)*KEY_LENGTH);\n  }\n\n  for (int cycles=0; cycles<CLIMBINGS; ++cycles) {  \n\n    for (j=0; j<KEY_LENGTH;j++)\n      backupKey[j] = key[j];\n\n    tempScore = 0.f;\n\n    int branch = LCG_random_float(&localState)*100; \n\n    if (branch < HEUR_THRESHOLD_OP1)\n    {\n      for (j=0; j<1+LCG_random_float(&localState)*OP1_HOP; j++) \n      {\n        leftLetter = LCG_random_float(&localState)*KEY_LENGTH;   \n        rightLetter = LCG_random_float(&localState)*KEY_LENGTH; \n        swapElements(key, leftLetter, rightLetter);\n      }            \n    }\n\n    else if (branch < HEUR_THRESHOLD_OP2)\n    {\n      for (j=0; j< 1+LCG_random_float(&localState)*OP2_HOP;j++)\n      {\n        blockStart = LCG_random_float(&localState)*KEY_LENGTH;\n        blockEnd = LCG_random_float(&localState)*KEY_LENGTH;\n        swapBlock(key, blockStart, blockEnd, 1+LCG_random_float(&localState)*(abs((blockStart-blockEnd))-1));\n      }\n    }\n\n    else \n    {\n      l = 1 + LCG_random_float(&localState)*(KEY_LENGTH-2);\n      f = LCG_random_float(&localState)*(KEY_LENGTH-1);\n      t = (f+1+(LCG_random_float(&localState)*(KEY_LENGTH-2)));\n      t = t % KEY_LENGTH;\n\n      for (j=0; j< KEY_LENGTH;j++)\n        shiftHelper[j] = key[j];\n\n      t0 = (t-f+KEY_LENGTH) % KEY_LENGTH;\n      n = (t0+l) % KEY_LENGTH;\n\n      for (j=0; j<n;j++) \n      {\n        ff = (f+j) % KEY_LENGTH;\n        tt = (((t0+j)%n)+f)%KEY_LENGTH;\n        key[tt] = shiftHelper[ff];\n      }        \n    }      \n\n    decrypt(d_encrypted, key, localDecrypted);    \n\n    for (j=0; j<ENCRYPTEDLEN-1; ++j) {\n      tempScore += shared_scores[ALPHABET*localDecrypted[j] + localDecrypted[j+1]];\n    }\n\n    if (tempScore < bestScore) {\n      bestScore = tempScore;\n      for (j=0; j<ENCRYPTEDLEN; ++j) {\n        bestLocalDecrypted[j] = localDecrypted[j];\n      }\n    }    \n\n    else \n    {\n      for (j=0; j<KEY_LENGTH;j++)\n        key[j] = backupKey[j];      \n    }\n  }\n\n  for (j=0; j<ENCRYPTEDLEN; ++j)\n    d_decrypted[idx*ENCRYPTEDLEN+j] = bestLocalDecrypted[j];\n}\n\n"}}
{"kernel_name": "columnarSolver", "parallel_api": "omp", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#define B ((int)32)\n#define T ((int)32)\n#define THREADS ((int)B*T)\n#define CLIMBINGS 150000\n#define ALPHABET 26\n#define totalBigrams ((int)ALPHABET*ALPHABET)\n#define CAP ((float)999999.0)\n\n#define ENCRYPTED_T \"tteohtedanisroudesereguwocubsoitoabbofeiaiutsdheeisatsarsturesuaastniersrotnesctrctxdiwmhcusyenorndasmhaipnnptmaeecspegdeislwoheoiymreeotbsspiatoanihrelhwctftrhpuunhoianunreetrioettatlsnehtbaecpvgtltcirottonesnobeeeireaymrtohaawnwtesssvassirsrhabapnsynntitsittchitoosbtelmlaouitrehhwfeiaandeitciegfreoridhdcsheucrnoihdeoswobaceeaorgndlstigeearsotoetduedininttpedststntefoeaheoesuetvmmiorftuuhsurof\"\n#define ENCRYPTEDLEN ((int)sizeof(ENCRYPTED_T)-1)\n\n#define DECRYPTED_T \"thedistinctionbetweentherouteciphertranspositionandthesubstitutioncipherwherewholewordsaresubstitutedforlettersoftheoriginaltextmustbemadeonthebasisofthewordsactuallyuseditisbettertoconsidersuchamessageasaroutecipherwhenthewordsusedappeartohavesomeconsecutivemeaningbearingonthesituationathandasubstitutioncipherofthisvarietywouldonlybeusedfortransmissionofashortmessageofgreatimportanceandsecrecy\"\n\n#define KEY_LENGTH 30\n#define SECTION_CONSTANT ENCRYPTEDLEN/KEY_LENGTH\n\n#define HEUR_THRESHOLD_OP1 50\n#define HEUR_THRESHOLD_OP2 70\n\n#define OP1_HOP 4\n#define OP2_HOP 2\n\n\n#include \"kernels.cpp\"\n\nbool extractBigrams(float *scores, const char* filename) {\n  FILE* bigramsFile = fopen(filename, \"r\");\n  if (bigramsFile == NULL) {\n    fprintf(stderr, \"Failed to open file %s. Exit\\n\", filename);\n    return true;\n  }\n  while(1){\n    char tempBigram[2];\n    float tempBigramScore = 0.0;\n    if (fscanf(bigramsFile, \"%s %f\", tempBigram, &tempBigramScore) < 2)\n    { break; } \n    scores[(tempBigram[0]-'a')*ALPHABET + tempBigram[1]-'a'] = tempBigramScore; \n  }\n  fclose(bigramsFile);\n  return false;\n}\n\nbool verify(int* encrMap) {\n  bool pass = true;\n  const char *expect = DECRYPTED_T;\n  for (int j=0; j<ENCRYPTEDLEN; ++j) {\n    if (encrMap[j] + 'a' != expect[j]) {\n       pass = false; break;\n    }\n  }\n  return pass;\n}\n\nfloat candidateScore(int* decrMsg, float* scores) {\n  float total = 0.0;\n  for (int j=0; j<ENCRYPTEDLEN-1; ++j) \n    total += scores[ALPHABET*decrMsg[j] + decrMsg[j+1]];  \n  return total;\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <path to file>\\n\", argv[0]);\n    return 1;\n  }\n  const char* filename = argv[1];\n\n  int encryptedMap[ENCRYPTEDLEN];\n\n  for (int j=0; j<ENCRYPTEDLEN; ++j)\n    encryptedMap[j] = ENCRYPTED_T[j] - 'a';\n\n  float scores[totalBigrams];  \n  bool fail = extractBigrams(scores, filename);\n  if (fail) return 1;\n\n  int* decrypted = new int[ENCRYPTEDLEN*THREADS];\n  unsigned int state[THREADS];\n\n#pragma omp target data map(to: scores[0:totalBigrams], \\\n                                encryptedMap[0:ENCRYPTEDLEN]) \\\n                        map(from: decrypted[0:ENCRYPTEDLEN * THREADS]) \\\n                        map(alloc: state[0:THREADS])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    #pragma omp target teams distribute parallel for thread_limit(T)\n    for (int idx = 0; idx < THREADS; idx++) {\n      state[idx] = idx;\n      for (int i = 0; i < idx; i++)\n        LCG_random_init(&state[idx]);\n    }\n\n    #pragma omp target teams num_teams(B) thread_limit(T)\n    {\n      float shared_scores[ALPHABET*ALPHABET];\n      #pragma omp parallel \n      {\n        decodeKernel(scores, encryptedMap, state, decrypted, shared_scores);\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Kernel execution time %f (s)\\n\", time * 1e-9f);\n  }\n\n  int bestCandidate = 0;\n  float bestScore = CAP;\n  float* scoreHistory = new float[B*T];\n\n  \n\n  for (int j=0; j<THREADS; ++j)  {\n    float currentScore = candidateScore(&decrypted[ENCRYPTEDLEN*j], scores);\n    scoreHistory[j] = currentScore;\n    if (currentScore < bestScore) {\n      bestScore = currentScore;\n      bestCandidate = j;\n    }\n  }\n\n  \n\n  bool pass = verify(&decrypted[ENCRYPTEDLEN*bestCandidate]);\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  delete[] decrypted;\n  delete[] scoreHistory;\n  return 0;\n}\n", "kernels.cpp": "#pragma omp declare target\nfloat LCG_random_float(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\nvoid LCG_random_init(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n}\n\nvoid decrypt(const int* encrypted, const int* key, int* decrypted) {\n\n  int columns[KEY_LENGTH][SECTION_CONSTANT+1];\n  int offset = 0;\n  int colLength[KEY_LENGTH];\n\n  for (int j=0; j<KEY_LENGTH; ++j) {\n    colLength[j] = ENCRYPTEDLEN / KEY_LENGTH;\n    if (j < ENCRYPTEDLEN % KEY_LENGTH)\n      colLength[j]++;\n  }\n\n  for (int keyPos=0; keyPos < KEY_LENGTH; ++keyPos) {\n    offset = 0;\n    for (int i=0; i<KEY_LENGTH; ++i)\n      if (key[i] < key[keyPos])\n        offset += colLength[i];\n\n    for (int j=0; j<colLength[keyPos]; ++j)   \n      columns[key[keyPos]][j] = encrypted[offset+j];          \n  } \n\n  for (int j=0; j<ENCRYPTEDLEN; ++j) \n    decrypted[j] = columns[key[j % KEY_LENGTH]][j / KEY_LENGTH];  \n} \n\nvoid swapElements(int *key, int posLeft, int posRight) {\n  if (posLeft != posRight)\n  {\n    key[posLeft] -= key[posRight];\n    key[posRight] += key[posLeft];\n    key[posLeft] = key[posRight] - key[posLeft];\n  }\n}\n\nvoid swapBlock(int *key, int posLeft, int posRight, int length) {  \n  for (int i=0; i<length; i++) \n    swapElements(key, (posLeft+i)%KEY_LENGTH, (posRight+i)%KEY_LENGTH);\n}\n\nvoid decodeKernel(\n  const float *__restrict d_scores, \n    const int *__restrict d_encrypted,\n  const unsigned int*__restrict globalState, \n          int *__restrict d_decrypted,\n        float *__restrict shared_scores) {\n\n  int key[KEY_LENGTH];\n  int localDecrypted[ENCRYPTEDLEN];  \n  int bestLocalDecrypted[ENCRYPTEDLEN];  \n  int leftLetter = 0;\n  int rightLetter = 0;\n  int backupKey[KEY_LENGTH];\n  int shiftHelper[KEY_LENGTH];\n  int blockStart, blockEnd;\n  int l,f,t,t0,n,ff,tt;\n  float tempScore = 0.f;\n  float bestScore = CAP;\n  int j = 0, jj = 0;\n\n  int lid = omp_get_thread_num();\n  int idx = omp_get_team_num() * T + lid;\n  unsigned int localState = globalState[idx];\n\n  if (lid == 0) {\n    for (j=0; j<ALPHABET;++j)\n      for (jj=0; jj<ALPHABET; ++jj)\n        shared_scores[j*ALPHABET + jj] = d_scores[j*ALPHABET + jj];\n  }\n\n  #pragma omp barrier\n\n  for (j=0; j<KEY_LENGTH; ++j) \n    key[j]=j;\n\n  for (j=0; j<KEY_LENGTH; ++j) {\n    swapElements(key, j, LCG_random_float(&localState)*KEY_LENGTH);\n  }\n\n  for (int cycles=0; cycles<CLIMBINGS; ++cycles) {  \n\n    for (j=0; j<KEY_LENGTH;j++)\n      backupKey[j] = key[j];\n\n    tempScore = 0.f;\n\n    int branch = LCG_random_float(&localState)*100; \n\n    if (branch < HEUR_THRESHOLD_OP1)\n    {\n      for (j=0; j<1+LCG_random_float(&localState)*OP1_HOP; j++) \n      {\n        leftLetter = LCG_random_float(&localState)*KEY_LENGTH;   \n        rightLetter = LCG_random_float(&localState)*KEY_LENGTH; \n        swapElements(key, leftLetter, rightLetter);\n      }            \n    }\n\n    else if (branch < HEUR_THRESHOLD_OP2)\n    {\n      for (j=0; j< 1+LCG_random_float(&localState)*OP2_HOP;j++)\n      {\n        blockStart = LCG_random_float(&localState)*KEY_LENGTH;\n        blockEnd = LCG_random_float(&localState)*KEY_LENGTH;\n        swapBlock(key, blockStart, blockEnd, 1+LCG_random_float(&localState)*(abs((blockStart-blockEnd))-1));\n      }\n    }\n\n    else \n    {\n      l = 1 + LCG_random_float(&localState)*(KEY_LENGTH-2);\n      f = LCG_random_float(&localState)*(KEY_LENGTH-1);\n      t = (f+1+(LCG_random_float(&localState)*(KEY_LENGTH-2)));\n      t = t % KEY_LENGTH;\n\n      for (j=0; j< KEY_LENGTH;j++)\n        shiftHelper[j] = key[j];\n\n      t0 = (t-f+KEY_LENGTH) % KEY_LENGTH;\n      n = (t0+l) % KEY_LENGTH;\n\n      for (j=0; j<n;j++) \n      {\n        ff = (f+j) % KEY_LENGTH;\n        tt = (((t0+j)%n)+f)%KEY_LENGTH;\n        key[tt] = shiftHelper[ff];\n      }        \n    }      \n\n    decrypt(d_encrypted, key, localDecrypted);    \n\n    for (j=0; j<ENCRYPTEDLEN-1; ++j) {\n      tempScore += shared_scores[ALPHABET*localDecrypted[j] + localDecrypted[j+1]];\n    }\n\n    if (tempScore < bestScore) {\n      bestScore = tempScore;\n      for (j=0; j<ENCRYPTEDLEN; ++j) {\n        bestLocalDecrypted[j] = localDecrypted[j];\n      }\n    }    \n\n    else \n    {\n      for (j=0; j<KEY_LENGTH;j++)\n        key[j] = backupKey[j];      \n    }\n  }\n\n  for (j=0; j<ENCRYPTEDLEN; ++j)\n    d_decrypted[idx*ENCRYPTEDLEN+j] = bestLocalDecrypted[j];\n}\n\n#pragma omp end declare target\n"}}
{"kernel_name": "columnarSolver", "parallel_api": "serial", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n\n#define B ((int)32)\n#define T ((int)32)\n#define THREADS ((int)B*T)\n#define CLIMBINGS 150000\n#define ALPHABET 26\n#define totalBigrams ((int)ALPHABET*ALPHABET)\n#define CAP ((float)999999.0)\n\n#define ENCRYPTED_T \"tteohtedanisroudesereguwocubsoitoabbofeiaiutsdheeisatsarsturesuaastniersrotnesctrctxdiwmhcusyenorndasmhaipnnptmaeecspegdeislwoheoiymreeotbsspiatoanihrelhwctftrhpuunhoianunreetrioettatlsnehtbaecpvgtltcirottonesnobeeeireaymrtohaawnwtesssvassirsrhabapnsynntitsittchitoosbtelmlaouitrehhwfeiaandeitciegfreoridhdcsheucrnoihdeoswobaceeaorgndlstigeearsotoetduedininttpedststntefoeaheoesuetvmmiorftuuhsurof\"\n#define ENCRYPTEDLEN ((int)sizeof(ENCRYPTED_T)-1)\n\n#define DECRYPTED_T \"thedistinctionbetweentherouteciphertranspositionandthesubstitutioncipherwherewholewordsaresubstitutedforlettersoftheoriginaltextmustbemadeonthebasisofthewordsactuallyuseditisbettertoconsidersuchamessageasaroutecipherwhenthewordsusedappeartohavesomeconsecutivemeaningbearingonthesituationathandasubstitutioncipherofthisvarietywouldonlybeusedfortransmissionofashortmessageofgreatimportanceandsecrecy\"\n\n#define KEY_LENGTH 30\n#define SECTION_CONSTANT ENCRYPTEDLEN/KEY_LENGTH\n\n#define HEUR_THRESHOLD_OP1 50\n#define HEUR_THRESHOLD_OP2 70\n\n#define OP1_HOP 4\n#define OP2_HOP 2\n\n\n#include \"kernels.cpp\"\n\nbool extractBigrams(float *scores, const char* filename) {\n  FILE* bigramsFile = fopen(filename, \"r\");\n  if (bigramsFile == NULL) {\n    fprintf(stderr, \"Failed to open file %s. Exit\\n\", filename);\n    return true;\n  }\n  while(1){\n    char tempBigram[2];\n    float tempBigramScore = 0.0;\n    if (fscanf(bigramsFile, \"%s %f\", tempBigram, &tempBigramScore) < 2)\n    { break; } \n    scores[(tempBigram[0]-'a')*ALPHABET + tempBigram[1]-'a'] = tempBigramScore; \n  }\n  fclose(bigramsFile);\n  return false;\n}\n\nbool verify(int* encrMap) {\n  bool pass = true;\n  const char *expect = DECRYPTED_T;\n  for (int j=0; j<ENCRYPTEDLEN; ++j) {\n    if (encrMap[j] + 'a' != expect[j]) {\n       pass = false; break;\n    }\n  }\n  return pass;\n}\n\nfloat candidateScore(int* decrMsg, float* scores) {\n  float total = 0.0;\n  for (int j=0; j<ENCRYPTEDLEN-1; ++j) \n    total += scores[ALPHABET*decrMsg[j] + decrMsg[j+1]];  \n  return total;\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <path to file>\\n\", argv[0]);\n    return 1;\n  }\n  const char* filename = argv[1];\n\n  int encryptedMap[ENCRYPTEDLEN];\n\n  for (int j=0; j<ENCRYPTEDLEN; ++j)\n    encryptedMap[j] = ENCRYPTED_T[j] - 'a';\n\n  float scores[totalBigrams];  \n  bool fail = extractBigrams(scores, filename);\n  if (fail) return 1;\n\n  int* decrypted = new int[ENCRYPTEDLEN*THREADS];\n  unsigned int state[THREADS];\n\n  {\n    auto start = std::chrono::steady_clock::now();\n\n        for (int idx = 0; idx < THREADS; idx++) {\n      state[idx] = idx;\n      for (int i = 0; i < idx; i++)\n        LCG_random_init(&state[idx]);\n    }\n\n        {\n      float shared_scores[ALPHABET*ALPHABET];\n            {\n        decodeKernel(scores, encryptedMap, state, decrypted, shared_scores);\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Kernel execution time %f (s)\\n\", time * 1e-9f);\n  }\n\n  int bestCandidate = 0;\n  float bestScore = CAP;\n  float* scoreHistory = new float[B*T];\n\n  \n\n  for (int j=0; j<THREADS; ++j)  {\n    float currentScore = candidateScore(&decrypted[ENCRYPTEDLEN*j], scores);\n    scoreHistory[j] = currentScore;\n    if (currentScore < bestScore) {\n      bestScore = currentScore;\n      bestCandidate = j;\n    }\n  }\n\n  \n\n  bool pass = verify(&decrypted[ENCRYPTEDLEN*bestCandidate]);\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  delete[] decrypted;\n  delete[] scoreHistory;\n  return 0;\n}", "kernels.cpp": "float LCG_random_float(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\nvoid LCG_random_init(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n}\n\nvoid decrypt(const int* encrypted, const int* key, int* decrypted) {\n\n  int columns[KEY_LENGTH][SECTION_CONSTANT+1];\n  int offset = 0;\n  int colLength[KEY_LENGTH];\n\n  for (int j=0; j<KEY_LENGTH; ++j) {\n    colLength[j] = ENCRYPTEDLEN / KEY_LENGTH;\n    if (j < ENCRYPTEDLEN % KEY_LENGTH)\n      colLength[j]++;\n  }\n\n  for (int keyPos=0; keyPos < KEY_LENGTH; ++keyPos) {\n    offset = 0;\n    for (int i=0; i<KEY_LENGTH; ++i)\n      if (key[i] < key[keyPos])\n        offset += colLength[i];\n\n    for (int j=0; j<colLength[keyPos]; ++j)   \n      columns[key[keyPos]][j] = encrypted[offset+j];          \n  } \n\n  for (int j=0; j<ENCRYPTEDLEN; ++j) \n    decrypted[j] = columns[key[j % KEY_LENGTH]][j / KEY_LENGTH];  \n} \n\nvoid swapElements(int *key, int posLeft, int posRight) {\n  if (posLeft != posRight)\n  {\n    key[posLeft] -= key[posRight];\n    key[posRight] += key[posLeft];\n    key[posLeft] = key[posRight] - key[posLeft];\n  }\n}\n\nvoid swapBlock(int *key, int posLeft, int posRight, int length) {  \n  for (int i=0; i<length; i++) \n    swapElements(key, (posLeft+i)%KEY_LENGTH, (posRight+i)%KEY_LENGTH);\n}\n\nvoid decodeKernel(\n  const float *__restrict d_scores, \n    const int *__restrict d_encrypted,\n  const unsigned int*__restrict globalState, \n          int *__restrict d_decrypted,\n        float *__restrict shared_scores) {\n\n  int key[KEY_LENGTH];\n  int localDecrypted[ENCRYPTEDLEN];  \n  int bestLocalDecrypted[ENCRYPTEDLEN];  \n  int leftLetter = 0;\n  int rightLetter = 0;\n  int backupKey[KEY_LENGTH];\n  int shiftHelper[KEY_LENGTH];\n  int blockStart, blockEnd;\n  int l,f,t,t0,n,ff,tt;\n  float tempScore = 0.f;\n  float bestScore = CAP;\n  int j = 0, jj = 0;\n\n  int lid = omp_get_thread_num();\n  int idx = omp_get_team_num() * T + lid;\n  unsigned int localState = globalState[idx];\n\n  if (lid == 0) {\n    for (j=0; j<ALPHABET;++j)\n      for (jj=0; jj<ALPHABET; ++jj)\n        shared_scores[j*ALPHABET + jj] = d_scores[j*ALPHABET + jj];\n  }\n\n  \n  for (j=0; j<KEY_LENGTH; ++j) \n    key[j]=j;\n\n  for (j=0; j<KEY_LENGTH; ++j) {\n    swapElements(key, j, LCG_random_float(&localState)*KEY_LENGTH);\n  }\n\n  for (int cycles=0; cycles<CLIMBINGS; ++cycles) {  \n\n    for (j=0; j<KEY_LENGTH;j++)\n      backupKey[j] = key[j];\n\n    tempScore = 0.f;\n\n    int branch = LCG_random_float(&localState)*100; \n\n    if (branch < HEUR_THRESHOLD_OP1)\n    {\n      for (j=0; j<1+LCG_random_float(&localState)*OP1_HOP; j++) \n      {\n        leftLetter = LCG_random_float(&localState)*KEY_LENGTH;   \n        rightLetter = LCG_random_float(&localState)*KEY_LENGTH; \n        swapElements(key, leftLetter, rightLetter);\n      }            \n    }\n\n    else if (branch < HEUR_THRESHOLD_OP2)\n    {\n      for (j=0; j< 1+LCG_random_float(&localState)*OP2_HOP;j++)\n      {\n        blockStart = LCG_random_float(&localState)*KEY_LENGTH;\n        blockEnd = LCG_random_float(&localState)*KEY_LENGTH;\n        swapBlock(key, blockStart, blockEnd, 1+LCG_random_float(&localState)*(abs((blockStart-blockEnd))-1));\n      }\n    }\n\n    else \n    {\n      l = 1 + LCG_random_float(&localState)*(KEY_LENGTH-2);\n      f = LCG_random_float(&localState)*(KEY_LENGTH-1);\n      t = (f+1+(LCG_random_float(&localState)*(KEY_LENGTH-2)));\n      t = t % KEY_LENGTH;\n\n      for (j=0; j< KEY_LENGTH;j++)\n        shiftHelper[j] = key[j];\n\n      t0 = (t-f+KEY_LENGTH) % KEY_LENGTH;\n      n = (t0+l) % KEY_LENGTH;\n\n      for (j=0; j<n;j++) \n      {\n        ff = (f+j) % KEY_LENGTH;\n        tt = (((t0+j)%n)+f)%KEY_LENGTH;\n        key[tt] = shiftHelper[ff];\n      }        \n    }      \n\n    decrypt(d_encrypted, key, localDecrypted);    \n\n    for (j=0; j<ENCRYPTEDLEN-1; ++j) {\n      tempScore += shared_scores[ALPHABET*localDecrypted[j] + localDecrypted[j+1]];\n    }\n\n    if (tempScore < bestScore) {\n      bestScore = tempScore;\n      for (j=0; j<ENCRYPTEDLEN; ++j) {\n        bestLocalDecrypted[j] = localDecrypted[j];\n      }\n    }    \n\n    else \n    {\n      for (j=0; j<KEY_LENGTH;j++)\n        key[j] = backupKey[j];      \n    }\n  }\n\n  for (j=0; j<ENCRYPTEDLEN; ++j)\n    d_decrypted[idx*ENCRYPTEDLEN+j] = bestLocalDecrypted[j];\n}\n"}}
{"kernel_name": "columnarSolver", "parallel_api": "sycl", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define B ((int)32)\n#define T ((int)32)\n#define THREADS ((int)B*T)\n#define CLIMBINGS 150000\n#define ALPHABET 26\n#define totalBigrams ((int)ALPHABET*ALPHABET)\n#define CAP ((float)999999.0)\n\n#define ENCRYPTED_T \"tteohtedanisroudesereguwocubsoitoabbofeiaiutsdheeisatsarsturesuaastniersrotnesctrctxdiwmhcusyenorndasmhaipnnptmaeecspegdeislwoheoiymreeotbsspiatoanihrelhwctftrhpuunhoianunreetrioettatlsnehtbaecpvgtltcirottonesnobeeeireaymrtohaawnwtesssvassirsrhabapnsynntitsittchitoosbtelmlaouitrehhwfeiaandeitciegfreoridhdcsheucrnoihdeoswobaceeaorgndlstigeearsotoetduedininttpedststntefoeaheoesuetvmmiorftuuhsurof\"\n#define ENCRYPTEDLEN ((int)sizeof(ENCRYPTED_T)-1)\n\n#define DECRYPTED_T \"thedistinctionbetweentherouteciphertranspositionandthesubstitutioncipherwherewholewordsaresubstitutedforlettersoftheoriginaltextmustbemadeonthebasisofthewordsactuallyuseditisbettertoconsidersuchamessageasaroutecipherwhenthewordsusedappeartohavesomeconsecutivemeaningbearingonthesituationathandasubstitutioncipherofthisvarietywouldonlybeusedfortransmissionofashortmessageofgreatimportanceandsecrecy\"\n\n#define KEY_LENGTH 30\n#define SECTION_CONSTANT ENCRYPTEDLEN/KEY_LENGTH\n\n#define HEUR_THRESHOLD_OP1 50\n#define HEUR_THRESHOLD_OP2 70\n\n#define OP1_HOP 4\n#define OP2_HOP 2\n\n\n#include \"kernels.cpp\"\n\nbool extractBigrams(float *scores, const char* filename) {\n  FILE* bigramsFile = fopen(filename, \"r\");\n  if (bigramsFile == NULL) {\n    fprintf(stderr, \"Failed to open file %s. Exit\\n\", filename);\n    return true;\n  }\n  while(1){\n    char tempBigram[2];\n    float tempBigramScore = 0.0;\n    if (fscanf(bigramsFile, \"%s %f\", tempBigram, &tempBigramScore) < 2)\n    { break; } \n    scores[(tempBigram[0]-'a')*ALPHABET + tempBigram[1]-'a'] = tempBigramScore; \n  }\n  fclose(bigramsFile);\n  return false;\n}\n\nbool verify(int* encrMap) {\n  bool pass = true;\n  const char *expect = DECRYPTED_T;\n  for (int j=0; j<ENCRYPTEDLEN; ++j) {\n    if (encrMap[j] + 'a' != expect[j]) {\n       pass = false; break;\n    }\n  }\n  return pass;\n}\n\nfloat candidateScore(int* decrMsg, float* scores) {\n  float total = 0.0;\n  for (int j=0; j<ENCRYPTEDLEN-1; ++j) \n    total += scores[ALPHABET*decrMsg[j] + decrMsg[j+1]];  \n  return total;\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <path to file>\\n\", argv[0]);\n    return 1;\n  }\n  const char* filename = argv[1];\n\n  int encryptedMap[ENCRYPTEDLEN];\n\n  for (int j=0; j<ENCRYPTEDLEN; ++j)\n    encryptedMap[j] = ENCRYPTED_T[j] - 'a';\n\n  float scores[totalBigrams];  \n  bool fail = extractBigrams(scores, filename);\n  if (fail) return 1;\n\n  int* decrypted = new int[ENCRYPTEDLEN*THREADS];\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_scores = sycl::malloc_device<float>(totalBigrams, q);\n  q.memcpy(d_scores, scores, totalBigrams * sizeof(float));\n\n  int *d_encrypted = sycl::malloc_device<int>(ENCRYPTEDLEN, q); \n  q.memcpy(d_encrypted, encryptedMap, ENCRYPTEDLEN * sizeof(int));\n\n  int *d_decrypted = sycl::malloc_device<int>(ENCRYPTEDLEN * THREADS, q);\n\n  unsigned int *d_states = sycl::malloc_device<unsigned int>(THREADS, q);\n\n  sycl::range<1> gws(THREADS);\n  sycl::range<1> lws(T);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class setup>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      setupKernel(item, d_states);\n    });\n  });\n\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<float, 1> lscores (sycl::range<1>(ALPHABET*ALPHABET), cgh);\n    cgh.parallel_for<class decode>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      decodeKernel(item, \n                   d_scores,\n                   d_encrypted,\n                   d_states,\n                   d_decrypted,\n                   lscores.get_pointer());\n    });\n  });\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Kernel execution time %f (s)\\n\", time * 1e-9f);\n\n  q.memcpy(decrypted, d_decrypted, ENCRYPTEDLEN * THREADS * sizeof(int)).wait();\n\n  int bestCandidate = 0;\n  float bestScore = CAP;\n  float* scoreHistory = new float[B*T];\n\n  \n\n  for (int j=0; j<THREADS; ++j)  {\n    float currentScore = candidateScore(&decrypted[ENCRYPTEDLEN*j], scores);\n    scoreHistory[j] = currentScore;\n    if (currentScore < bestScore) {\n      bestScore = currentScore;\n      bestCandidate = j;\n    }    \n  }  \n\n  \n\n  bool pass = verify(&decrypted[ENCRYPTEDLEN*bestCandidate]);\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_scores, q);\n  sycl::free(d_encrypted, q);\n  sycl::free(d_decrypted, q);\n  sycl::free(d_states, q);\n  delete[] decrypted;\n  delete[] scoreHistory;\n  return 0;\n}\n", "kernels.cpp": "float LCG_random_float(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\nvoid LCG_random_init(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n}\n\nvoid setupKernel(sycl::nd_item<1> &item, unsigned int* state) {\n  int idx = item.get_global_id(0);\n  state[idx] = idx;\n  for (int i = 0; i < idx; i++) {\n    LCG_random_init(&state[idx]);\n  }\n}\n\nvoid decrypt(const int* encrypted, const int* key, int* decrypted) {\n\n  int columns[KEY_LENGTH][SECTION_CONSTANT+1];\n  int offset = 0;\n  int colLength[KEY_LENGTH];\n\n  for (int j=0; j<KEY_LENGTH; ++j) {\n    colLength[j] = ENCRYPTEDLEN / KEY_LENGTH;\n    if (j < ENCRYPTEDLEN % KEY_LENGTH)\n      colLength[j]++;\n  }\n\n  for (int keyPos=0; keyPos < KEY_LENGTH; ++keyPos) {\n    offset = 0;\n    for (int i=0; i<KEY_LENGTH; ++i)\n      if (key[i] < key[keyPos])\n        offset += colLength[i];\n\n    for (int j=0; j<colLength[keyPos]; ++j)   \n      columns[key[keyPos]][j] = encrypted[offset+j];          \n  } \n\n  for (int j=0; j<ENCRYPTEDLEN; ++j) \n    decrypted[j] = columns[key[j % KEY_LENGTH]][j / KEY_LENGTH];  \n} \n\nvoid swapElements(int *key, int posLeft, int posRight) {\n  if (posLeft != posRight)\n  {\n    key[posLeft] -= key[posRight];\n    key[posRight] += key[posLeft];\n    key[posLeft] = key[posRight] - key[posLeft];\n  }\n}\n\nvoid swapBlock(int *key, int posLeft, int posRight, int length) {  \n  for (int i=0; i<length; i++) \n    swapElements(key, (posLeft+i)%KEY_LENGTH, (posRight+i)%KEY_LENGTH);\n}\n\nvoid decodeKernel(\n  sycl::nd_item<1> &item,\n  const float *__restrict d_scores, \n    const int *__restrict d_encrypted,\n  const unsigned int*__restrict globalState, \n          int *__restrict d_decrypted,\n        float *__restrict shared_scores) {\n\n  int key[KEY_LENGTH];\n  int localDecrypted[ENCRYPTEDLEN];  \n  int bestLocalDecrypted[ENCRYPTEDLEN];  \n  int leftLetter = 0;\n  int rightLetter = 0;\n  int backupKey[KEY_LENGTH];\n  int shiftHelper[KEY_LENGTH];\n  int blockStart, blockEnd;\n  int l,f,t,t0,n,ff,tt;\n  float tempScore = 0.f;\n  float bestScore = CAP;\n  int j = 0, jj = 0;\n\n  int idx = item.get_global_id(0);\n  unsigned int localState = globalState[idx];\n\n  if (item.get_local_id(0) == 0) {\n    for (j=0; j<ALPHABET;++j)\n      for (jj=0; jj<ALPHABET; ++jj)\n        shared_scores[j*ALPHABET + jj] = d_scores[j*ALPHABET + jj];\n  }\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  for (j=0; j<KEY_LENGTH; ++j) \n    key[j]=j;\n\n  for (j=0; j<KEY_LENGTH; ++j) {\n    swapElements(key, j, LCG_random_float(&localState)*KEY_LENGTH);\n  }\n\n  for (int cycles=0; cycles<CLIMBINGS; ++cycles) {  \n\n    for (j=0; j<KEY_LENGTH;j++)\n      backupKey[j] = key[j];\n\n    tempScore = 0.f;\n\n    int branch = LCG_random_float(&localState)*100; \n\n    if (branch < HEUR_THRESHOLD_OP1)\n    {\n      for (j=0; j<1+LCG_random_float(&localState)*OP1_HOP; j++) \n      {\n        leftLetter = LCG_random_float(&localState)*KEY_LENGTH;   \n        rightLetter = LCG_random_float(&localState)*KEY_LENGTH; \n        swapElements(key, leftLetter, rightLetter);\n      }            \n    }\n\n    else if (branch < HEUR_THRESHOLD_OP2)\n    {\n      for (j=0; j< 1+LCG_random_float(&localState)*OP2_HOP;j++)\n      {\n        blockStart = LCG_random_float(&localState)*KEY_LENGTH;\n        blockEnd = LCG_random_float(&localState)*KEY_LENGTH;\n        swapBlock(key, blockStart, blockEnd, \n                  1+LCG_random_float(&localState)*(sycl::abs((blockStart-blockEnd))-1));\n      }\n    }\n\n    else \n    {\n      l = 1 + LCG_random_float(&localState)*(KEY_LENGTH-2);\n      f = LCG_random_float(&localState)*(KEY_LENGTH-1);\n      t = (f+1+(LCG_random_float(&localState)*(KEY_LENGTH-2)));\n      t = t % KEY_LENGTH;\n\n      for (j=0; j< KEY_LENGTH;j++)\n        shiftHelper[j] = key[j];\n\n      t0 = (t-f+KEY_LENGTH) % KEY_LENGTH;\n      n = (t0+l) % KEY_LENGTH;\n\n      for (j=0; j<n;j++) \n      {\n        ff = (f+j) % KEY_LENGTH;\n        tt = (((t0+j)%n)+f)%KEY_LENGTH;\n        key[tt] = shiftHelper[ff];\n      }        \n    }      \n\n    decrypt(d_encrypted, key, localDecrypted);    \n\n    for (j=0; j<ENCRYPTEDLEN-1; ++j) {\n      tempScore += shared_scores[ALPHABET*localDecrypted[j] + localDecrypted[j+1]];\n    }\n\n    if (tempScore < bestScore) {\n      bestScore = tempScore;\n      for (j=0; j<ENCRYPTEDLEN; ++j) {\n        bestLocalDecrypted[j] = localDecrypted[j];\n      }\n    }    \n\n    else \n    {\n      for (j=0; j<KEY_LENGTH;j++)\n        key[j] = backupKey[j];      \n    }\n  }\n\n  for (j=0; j<ENCRYPTEDLEN; ++j)\n    d_decrypted[idx*ENCRYPTEDLEN+j] = bestLocalDecrypted[j];\n}\n"}}
{"kernel_name": "convolution1D", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\n__constant__ T mask [MAX_MASK_WIDTH];\n\ntemplate<typename T>\n__global__\nvoid conv1d(const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  T s = 0;\n  int start = i - mask_width / 2;\n  for (int j = 0; j < mask_width; j++) {\n    if (start + j >= 0 && start + j < input_width) {\n      s += in[start + j] * mask<T>[j];\n    }\n  }\n  out[i] = s;\n}\n\ntemplate<typename T>\n__global__\nvoid conv1d_tiled(const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n  __shared__ T tile[TILE_SIZE + MAX_MASK_WIDTH - 1];\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n  int n = mask_width / 2;  \n\n\n  \n\n  int halo_left = (blockIdx.x - 1) * blockDim.x + threadIdx.x;\n  if (threadIdx.x >= blockDim.x - n)\n     tile[threadIdx.x - (blockDim.x - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n  \n\n  tile[n + threadIdx.x] = in[blockIdx.x * blockDim.x + threadIdx.x];\n\n  \n\n  int halo_right = (blockIdx.x + 1) * blockDim.x + threadIdx.x;\n  if (threadIdx.x < n)\n     tile[threadIdx.x + blockDim.x + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n  __syncthreads();\n\n  T s = 0;\n  for (int j = 0; j < mask_width; j++)\n    s += tile[threadIdx.x + j] * mask<T>[j];\n\n  out[i] = s;\n}\n\ntemplate<typename T>\n__global__\nvoid conv1d_tiled_caching(const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n  __shared__ T tile[TILE_SIZE];\n\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  tile[threadIdx.x] = in[i];\n  __syncthreads();\n\n  int this_tile_start = blockIdx.x * blockDim.x;\n  int next_tile_start = (blockIdx.x + 1) * blockDim.x;\n  int start = i - (mask_width / 2);\n  T s = 0;\n  for (int j = 0; j < mask_width; j++) {\n    int in_index = start + j;\n    if (in_index >= 0 && in_index < input_width) {\n      if (in_index >= this_tile_start && in_index < next_tile_start) {\n        \n\n        \n\n        s += tile[threadIdx.x + j - (mask_width / 2)] * mask<T>[j];\n      } else {\n        s += in[in_index] * mask<T>[j];\n      }\n    }\n  }\n  out[i] = s;\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T h_mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) h_mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n  T *d_a, *d_b;\n  cudaMalloc((void **)&d_a, size_bytes);\n  cudaMalloc((void **)&d_b, size_bytes);\n\n  cudaMemcpy(d_a, a, size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpyToSymbol(mask<T>, h_mask, mask_width * sizeof(T));\n\n  dim3 grids (input_width / BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  cudaDeviceSynchronize();\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  cudaMemcpy(b, d_b, size_bytes, cudaMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d_tiled <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  cudaMemcpy(b, d_b, size_bytes, cudaMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d_tiled_caching <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  cudaMemcpy(b, d_b, size_bytes, cudaMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  free(a);\n  free(b);\n  cudaFree(d_a);\n  cudaFree(d_b);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(input_width, mask_width, repeat);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "convolution1D", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\n__constant__ T mask [MAX_MASK_WIDTH];\n\ntemplate<typename T>\n__global__\nvoid conv1d(const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  T s = 0;\n  int start = i - mask_width / 2;\n  for (int j = 0; j < mask_width; j++) {\n    if (start + j >= 0 && start + j < input_width) {\n      s += in[start + j] * mask<T>[j];\n    }\n  }\n  out[i] = s;\n}\n\ntemplate<typename T>\n__global__\nvoid conv1d_tiled(const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n  __shared__ T tile[TILE_SIZE + MAX_MASK_WIDTH - 1];\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n  int n = mask_width / 2;  \n\n\n  \n\n  int halo_left = (blockIdx.x - 1) * blockDim.x + threadIdx.x;\n  if (threadIdx.x >= blockDim.x - n)\n     tile[threadIdx.x - (blockDim.x - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n  \n\n  tile[n + threadIdx.x] = in[blockIdx.x * blockDim.x + threadIdx.x];\n\n  \n\n  int halo_right = (blockIdx.x + 1) * blockDim.x + threadIdx.x;\n  if (threadIdx.x < n)\n     tile[threadIdx.x + blockDim.x + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n  __syncthreads();\n\n  T s = 0;\n  for (int j = 0; j < mask_width; j++)\n    s += tile[threadIdx.x + j] * mask<T>[j];\n\n  out[i] = s;\n}\n\ntemplate<typename T>\n__global__\nvoid conv1d_tiled_caching(const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n  __shared__ T tile[TILE_SIZE];\n\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  tile[threadIdx.x] = in[i];\n  __syncthreads();\n\n  int this_tile_start = blockIdx.x * blockDim.x;\n  int next_tile_start = (blockIdx.x + 1) * blockDim.x;\n  int start = i - (mask_width / 2);\n  T s = 0;\n  for (int j = 0; j < mask_width; j++) {\n    int in_index = start + j;\n    if (in_index >= 0 && in_index < input_width) {\n      if (in_index >= this_tile_start && in_index < next_tile_start) {\n        \n\n        \n\n        s += tile[threadIdx.x + j - (mask_width / 2)] * mask<T>[j];\n      } else {\n        s += in[in_index] * mask<T>[j];\n      }\n    }\n  }\n  out[i] = s;\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T h_mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) h_mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n  T *d_a, *d_b;\n  hipMalloc((void **)&d_a, size_bytes);\n  hipMalloc((void **)&d_b, size_bytes);\n\n  hipMemcpy(d_a, a, size_bytes, hipMemcpyHostToDevice);\n  hipMemcpyToSymbol(mask<T>, h_mask, mask_width * sizeof(T));\n\n  dim3 grids (input_width / BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  hipDeviceSynchronize();\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  hipMemcpy(b, d_b, size_bytes, hipMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d_tiled <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  hipMemcpy(b, d_b, size_bytes, hipMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d_tiled_caching <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  hipMemcpy(b, d_b, size_bytes, hipMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  free(a);\n  free(b);\n  hipFree(d_a);\n  hipFree(d_b);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(input_width, mask_width, repeat);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "convolution1D", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\nvoid conv1d(const T * __restrict__ mask,\n            const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n  #pragma omp target teams distribute parallel for num_threads(BLOCK_SIZE)\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += in[start + j] * mask[j];\n      }\n    }\n    out[i] = s;\n  }\n}\n\ntemplate<typename T>\nvoid conv1d_tiled(const T *__restrict__ mask,\n                  const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n  #pragma omp target teams num_teams(input_width/BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T tile[TILE_SIZE + MAX_MASK_WIDTH - 1];\n    #pragma omp parallel \n    {\n      int bid = omp_get_team_num();\n      int lid = omp_get_thread_num();\n      int dim = omp_get_num_threads();\n      int i = bid * dim + lid;\n\n      int n = mask_width / 2;  \n\n\n      \n\n      int halo_left = (bid - 1) * dim + lid;\n      if (lid >= dim - n)\n         tile[lid - (dim - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n      \n\n      tile[n + lid] = in[bid * dim + lid];\n\n      \n\n      int halo_right = (bid + 1) * dim + lid;\n      if (lid < n)\n         tile[lid + dim + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n      #pragma omp barrier\n\n      T s = 0;\n      for (int j = 0; j < mask_width; j++)\n        s += tile[lid + j] * mask[j];\n\n      out[i] = s;\n    }\n  }\n}\n\ntemplate<typename T>\nvoid conv1d_tiled_caching(const T *__restrict__ mask,\n                          const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n  #pragma omp target teams num_teams(input_width/BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T tile[TILE_SIZE];\n    #pragma omp parallel \n    {\n      int bid = omp_get_team_num();\n      int lid = omp_get_thread_num();\n      int dim = omp_get_num_threads();\n      int i = bid * dim + lid;\n      tile[lid] = in[i];\n      #pragma omp barrier\n\n      int this_tile_start = bid * dim;\n      int next_tile_start = (bid + 1) * dim;\n      int start = i - (mask_width / 2);\n      T s = 0;\n      for (int j = 0; j < mask_width; j++) {\n        int in_index = start + j;\n        if (in_index >= 0 && in_index < input_width) {\n          if (in_index >= this_tile_start && in_index < next_tile_start) {\n            \n\n            \n\n            s += tile[lid + j - (mask_width / 2)] * mask[j];\n          } else {\n            s += in[in_index] * mask[j];\n          }\n        }\n      }\n      out[i] = s;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n  #pragma omp target data map(to: a[0:input_width], \\\n                                  mask[0:mask_width]) \\\n                          map(alloc: b[0:input_width])\n  {\n    \n\n    auto start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d(mask, a, b, input_width, mask_width);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    #pragma omp target update from (b[0:input_width])\n    reference(a, b, mask, input_width, mask_width);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d_tiled(mask, a, b, input_width, mask_width);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    #pragma omp target update from (b[0:input_width])\n    reference(a, b, mask, input_width, mask_width);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d_tiled_caching(mask, a, b, input_width, mask_width);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    #pragma omp target update from (b[0:input_width])\n    reference(a, b, mask, input_width, mask_width);\n  }\n\n  free(a);\n  free(b);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(input_width, mask_width, repeat);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "convolution1D", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\nvoid conv1d(const T * __restrict__ mask,\n            const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n    for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += in[start + j] * mask[j];\n      }\n    }\n    out[i] = s;\n  }\n}\n\ntemplate<typename T>\nvoid conv1d_tiled(const T *__restrict__ mask,\n                  const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n    {\n    T tile[TILE_SIZE + MAX_MASK_WIDTH - 1];\n        {\n      int bid = omp_get_team_num();\n      int lid = omp_get_thread_num();\n      int dim = omp_get_num_threads();\n      int i = bid * dim + lid;\n\n      int n = mask_width / 2;  \n\n\n      \n\n      int halo_left = (bid - 1) * dim + lid;\n      if (lid >= dim - n)\n         tile[lid - (dim - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n      \n\n      tile[n + lid] = in[bid * dim + lid];\n\n      \n\n      int halo_right = (bid + 1) * dim + lid;\n      if (lid < n)\n         tile[lid + dim + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n      \n      T s = 0;\n      for (int j = 0; j < mask_width; j++)\n        s += tile[lid + j] * mask[j];\n\n      out[i] = s;\n    }\n  }\n}\n\ntemplate<typename T>\nvoid conv1d_tiled_caching(const T *__restrict__ mask,\n                          const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n    {\n    T tile[TILE_SIZE];\n        {\n      int bid = omp_get_team_num();\n      int lid = omp_get_thread_num();\n      int dim = omp_get_num_threads();\n      int i = bid * dim + lid;\n      tile[lid] = in[i];\n      \n      int this_tile_start = bid * dim;\n      int next_tile_start = (bid + 1) * dim;\n      int start = i - (mask_width / 2);\n      T s = 0;\n      for (int j = 0; j < mask_width; j++) {\n        int in_index = start + j;\n        if (in_index >= 0 && in_index < input_width) {\n          if (in_index >= this_tile_start && in_index < next_tile_start) {\n            \n\n            \n\n            s += tile[lid + j - (mask_width / 2)] * mask[j];\n          } else {\n            s += in[in_index] * mask[j];\n          }\n        }\n      }\n      out[i] = s;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n    {\n    \n\n    auto start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d(mask, a, b, input_width, mask_width);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n        reference(a, b, mask, input_width, mask_width);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d_tiled(mask, a, b, input_width, mask_width);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n        reference(a, b, mask, input_width, mask_width);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d_tiled_caching(mask, a, b, input_width, mask_width);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n        reference(a, b, mask, input_width, mask_width);\n  }\n\n  free(a);\n  free(b);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(input_width, mask_width, repeat);\n  }\n\n  return 0;\n}"}}
{"kernel_name": "convolution1D", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#ifdef __NVPTX__\n  #include <sycl/ext/oneapi/experimental/cuda/builtins.hpp>\n  using namespace sycl::ext::oneapi::experimental::cuda;\n#else\n  #define ldg(a) (*(a))\n#endif\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\nclass k1;\n\ntemplate<typename T>\nclass k2;\n\ntemplate<typename T>\nclass k3;\n\ntemplate<typename T>\nvoid conv1d(sycl::nd_item<1> &item,\n            const T * __restrict__ mask,\n            const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n  int i = item.get_global_id(0);\n  T s = 0;\n  int start = i - mask_width / 2;\n  for (int j = 0; j < mask_width; j++) {\n    if (start + j >= 0 && start + j < input_width) {\n      s += in[start + j] * ldg(&mask[j]);\n    }\n  }\n  out[i] = s;\n}\n\ntemplate<typename T>\nvoid conv1d_tiled(sycl::nd_item<1> &item,\n                  sycl::local_ptr<T> tile,\n                  const T * __restrict__ mask,\n                  const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n  int lid = item.get_local_id(0);\n  int bid = item.get_group(0);\n  int dim = item.get_local_range(0);\n  int i = bid * dim + lid;\n\n  int n = mask_width / 2;  \n\n\n  \n\n  int halo_left = (bid - 1) * dim + lid;\n  if (lid >= dim - n)\n     tile[lid - (dim - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n  \n\n  tile[n + lid] = in[bid * dim + lid];\n\n  \n\n  int halo_right = (bid + 1) * dim + lid;\n  if (lid < n)\n     tile[lid + dim + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  T s = 0;\n  for (int j = 0; j < mask_width; j++)\n    s += tile[lid + j] * ldg(&mask[j]);\n\n  out[i] = s;\n}\n\ntemplate<typename T>\nvoid conv1d_tiled_caching(sycl::nd_item<1> &item,\n                          sycl::local_ptr<T> tile,\n                          const T *__restrict__ mask,\n                          const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n  int lid = item.get_local_id(0);\n  int bid = item.get_group(0);\n  int dim = item.get_local_range(0);\n  int i = bid * dim + lid;\n  tile[lid] = in[i];\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  int this_tile_start = bid * dim;\n  int next_tile_start = (bid + 1) * dim;\n  int start = i - (mask_width / 2);\n  T s = 0;\n  for (int j = 0; j < mask_width; j++) {\n    int in_index = start + j;\n    if (in_index >= 0 && in_index < input_width) {\n      if (in_index >= this_tile_start && in_index < next_tile_start) {\n        \n\n        \n\n        s += tile[lid + j - (mask_width / 2)] * ldg(&mask[j]);\n      } else {\n        s += in[in_index] * ldg(&mask[j]);\n      }\n    }\n  }\n  out[i] = s;\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(sycl::queue &q, const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T h_mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) h_mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n  T *mask, *d_a, *d_b;\n  mask = sycl::malloc_device<T>(MAX_MASK_WIDTH, q);\n  d_a = sycl::malloc_device<T>(input_width, q);\n  d_b = sycl::malloc_device<T>(input_width, q);\n\n  q.memcpy(d_a, a, size_bytes);\n  q.memcpy(mask, h_mask, mask_width * sizeof(T));\n\n  sycl::range<1> gws (input_width);\n  sycl::range<1> lws (BLOCK_SIZE);\n\n  q.wait();\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k1<T>>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        conv1d(item, mask, d_a, d_b, input_width, mask_width);\n      });\n    });\n  }\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  q.memcpy(b, d_b, size_bytes).wait();\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> tile (sycl::range<1>(TILE_SIZE + MAX_MASK_WIDTH - 1), cgh);\n      cgh.parallel_for<class k2<T>>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        conv1d_tiled(item, tile.get_pointer(), mask, d_a, d_b, input_width, mask_width);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  q.memcpy(b, d_b, size_bytes).wait();\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> tile (sycl::range<1>(TILE_SIZE), cgh);\n      cgh.parallel_for<class k3<T>>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        conv1d_tiled_caching(item, tile.get_pointer(), mask, d_a, d_b, input_width, mask_width);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  q.memcpy(b, d_b, size_bytes).wait();\n  reference(a, b, h_mask, input_width, mask_width);\n\n  free(a);\n  free(b);\n  sycl::free(mask, q);\n  sycl::free(d_a, q);\n  sycl::free(d_b, q);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(q, input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(q, input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(q, input_width, mask_width, repeat);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "crc64", "parallel_api": "cuda", "code": {"CRC64.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef __STDC_CONSTANT_MACROS\n#define __STDC_CONSTANT_MACROS\n#endif\n\n#ifdef HAVE_CONFIG_H\n#include <config.h>\n#endif\n\n#include <stdbool.h>\n\n#include <cuda.h>\n#include \"CRC64.h\"\n\n\n\nstatic const uint64_t crc64_poly = UINT64_C(0xc96c5795d7870f42);\n\nstatic const uint64_t crc64_table[4][256] = {\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x1dee8a5e222ca1dc),\n    UINT64_C(0x3bdd14bc445943b8), UINT64_C(0x26339ee26675e264),\n    UINT64_C(0x77ba297888b28770), UINT64_C(0x6a54a326aa9e26ac),\n    UINT64_C(0x4c673dc4ccebc4c8), UINT64_C(0x5189b79aeec76514),\n    UINT64_C(0xef7452f111650ee0), UINT64_C(0xf29ad8af3349af3c),\n    UINT64_C(0xd4a9464d553c4d58), UINT64_C(0xc947cc137710ec84),\n    UINT64_C(0x98ce7b8999d78990), UINT64_C(0x8520f1d7bbfb284c),\n    UINT64_C(0xa3136f35dd8eca28), UINT64_C(0xbefde56bffa26bf4),\n    UINT64_C(0x4c300ac98dc40345), UINT64_C(0x51de8097afe8a299),\n    UINT64_C(0x77ed1e75c99d40fd), UINT64_C(0x6a03942bebb1e121),\n    UINT64_C(0x3b8a23b105768435), UINT64_C(0x2664a9ef275a25e9),\n    UINT64_C(0x0057370d412fc78d), UINT64_C(0x1db9bd5363036651),\n    UINT64_C(0xa34458389ca10da5), UINT64_C(0xbeaad266be8dac79),\n    UINT64_C(0x98994c84d8f84e1d), UINT64_C(0x8577c6dafad4efc1),\n    UINT64_C(0xd4fe714014138ad5), UINT64_C(0xc910fb1e363f2b09),\n    UINT64_C(0xef2365fc504ac96d), UINT64_C(0xf2cdefa2726668b1),\n    UINT64_C(0x986015931b88068a), UINT64_C(0x858e9fcd39a4a756),\n    UINT64_C(0xa3bd012f5fd14532), UINT64_C(0xbe538b717dfde4ee),\n    UINT64_C(0xefda3ceb933a81fa), UINT64_C(0xf234b6b5b1162026),\n    UINT64_C(0xd4072857d763c242), UINT64_C(0xc9e9a209f54f639e),\n    UINT64_C(0x771447620aed086a), UINT64_C(0x6afacd3c28c1a9b6),\n    UINT64_C(0x4cc953de4eb44bd2), UINT64_C(0x5127d9806c98ea0e),\n    UINT64_C(0x00ae6e1a825f8f1a), UINT64_C(0x1d40e444a0732ec6),\n    UINT64_C(0x3b737aa6c606cca2), UINT64_C(0x269df0f8e42a6d7e),\n    UINT64_C(0xd4501f5a964c05cf), UINT64_C(0xc9be9504b460a413),\n    UINT64_C(0xef8d0be6d2154677), UINT64_C(0xf26381b8f039e7ab),\n    UINT64_C(0xa3ea36221efe82bf), UINT64_C(0xbe04bc7c3cd22363),\n    UINT64_C(0x9837229e5aa7c107), UINT64_C(0x85d9a8c0788b60db),\n    UINT64_C(0x3b244dab87290b2f), UINT64_C(0x26cac7f5a505aaf3),\n    UINT64_C(0x00f95917c3704897), UINT64_C(0x1d17d349e15ce94b),\n    UINT64_C(0x4c9e64d30f9b8c5f), UINT64_C(0x5170ee8d2db72d83),\n    UINT64_C(0x7743706f4bc2cfe7), UINT64_C(0x6aadfa3169ee6e3b),\n    UINT64_C(0xa218840d981e1391), UINT64_C(0xbff60e53ba32b24d),\n    UINT64_C(0x99c590b1dc475029), UINT64_C(0x842b1aeffe6bf1f5),\n    UINT64_C(0xd5a2ad7510ac94e1), UINT64_C(0xc84c272b3280353d),\n    UINT64_C(0xee7fb9c954f5d759), UINT64_C(0xf391339776d97685),\n    UINT64_C(0x4d6cd6fc897b1d71), UINT64_C(0x50825ca2ab57bcad),\n    UINT64_C(0x76b1c240cd225ec9), UINT64_C(0x6b5f481eef0eff15),\n    UINT64_C(0x3ad6ff8401c99a01), UINT64_C(0x273875da23e53bdd),\n    UINT64_C(0x010beb384590d9b9), UINT64_C(0x1ce5616667bc7865),\n    UINT64_C(0xee288ec415da10d4), UINT64_C(0xf3c6049a37f6b108),\n    UINT64_C(0xd5f59a785183536c), UINT64_C(0xc81b102673aff2b0),\n    UINT64_C(0x9992a7bc9d6897a4), UINT64_C(0x847c2de2bf443678),\n    UINT64_C(0xa24fb300d931d41c), UINT64_C(0xbfa1395efb1d75c0),\n    UINT64_C(0x015cdc3504bf1e34), UINT64_C(0x1cb2566b2693bfe8),\n    UINT64_C(0x3a81c88940e65d8c), UINT64_C(0x276f42d762cafc50),\n    UINT64_C(0x76e6f54d8c0d9944), UINT64_C(0x6b087f13ae213898),\n    UINT64_C(0x4d3be1f1c854dafc), UINT64_C(0x50d56bafea787b20),\n    UINT64_C(0x3a78919e8396151b), UINT64_C(0x27961bc0a1bab4c7),\n    UINT64_C(0x01a58522c7cf56a3), UINT64_C(0x1c4b0f7ce5e3f77f),\n    UINT64_C(0x4dc2b8e60b24926b), UINT64_C(0x502c32b8290833b7),\n    UINT64_C(0x761fac5a4f7dd1d3), UINT64_C(0x6bf126046d51700f),\n    UINT64_C(0xd50cc36f92f31bfb), UINT64_C(0xc8e24931b0dfba27),\n    UINT64_C(0xeed1d7d3d6aa5843), UINT64_C(0xf33f5d8df486f99f),\n    UINT64_C(0xa2b6ea171a419c8b), UINT64_C(0xbf586049386d3d57),\n    UINT64_C(0x996bfeab5e18df33), UINT64_C(0x848574f57c347eef),\n    UINT64_C(0x76489b570e52165e), UINT64_C(0x6ba611092c7eb782),\n    UINT64_C(0x4d958feb4a0b55e6), UINT64_C(0x507b05b56827f43a),\n    UINT64_C(0x01f2b22f86e0912e), UINT64_C(0x1c1c3871a4cc30f2),\n    UINT64_C(0x3a2fa693c2b9d296), UINT64_C(0x27c12ccde095734a),\n    UINT64_C(0x993cc9a61f3718be), UINT64_C(0x84d243f83d1bb962),\n    UINT64_C(0xa2e1dd1a5b6e5b06), UINT64_C(0xbf0f57447942fada),\n    UINT64_C(0xee86e0de97859fce), UINT64_C(0xf3686a80b5a93e12),\n    UINT64_C(0xd55bf462d3dcdc76), UINT64_C(0xc8b57e3cf1f07daa),\n    UINT64_C(0xd6e9a7309f3239a7), UINT64_C(0xcb072d6ebd1e987b),\n    UINT64_C(0xed34b38cdb6b7a1f), UINT64_C(0xf0da39d2f947dbc3),\n    UINT64_C(0xa1538e481780bed7), UINT64_C(0xbcbd041635ac1f0b),\n    UINT64_C(0x9a8e9af453d9fd6f), UINT64_C(0x876010aa71f55cb3),\n    UINT64_C(0x399df5c18e573747), UINT64_C(0x24737f9fac7b969b),\n    UINT64_C(0x0240e17dca0e74ff), UINT64_C(0x1fae6b23e822d523),\n    UINT64_C(0x4e27dcb906e5b037), UINT64_C(0x53c956e724c911eb),\n    UINT64_C(0x75fac80542bcf38f), UINT64_C(0x6814425b60905253),\n    UINT64_C(0x9ad9adf912f63ae2), UINT64_C(0x873727a730da9b3e),\n    UINT64_C(0xa104b94556af795a), UINT64_C(0xbcea331b7483d886),\n    UINT64_C(0xed6384819a44bd92), UINT64_C(0xf08d0edfb8681c4e),\n    UINT64_C(0xd6be903dde1dfe2a), UINT64_C(0xcb501a63fc315ff6),\n    UINT64_C(0x75adff0803933402), UINT64_C(0x6843755621bf95de),\n    UINT64_C(0x4e70ebb447ca77ba), UINT64_C(0x539e61ea65e6d666),\n    UINT64_C(0x0217d6708b21b372), UINT64_C(0x1ff95c2ea90d12ae),\n    UINT64_C(0x39cac2cccf78f0ca), UINT64_C(0x24244892ed545116),\n    UINT64_C(0x4e89b2a384ba3f2d), UINT64_C(0x536738fda6969ef1),\n    UINT64_C(0x7554a61fc0e37c95), UINT64_C(0x68ba2c41e2cfdd49),\n    UINT64_C(0x39339bdb0c08b85d), UINT64_C(0x24dd11852e241981),\n    UINT64_C(0x02ee8f674851fbe5), UINT64_C(0x1f0005396a7d5a39),\n    UINT64_C(0xa1fde05295df31cd), UINT64_C(0xbc136a0cb7f39011),\n    UINT64_C(0x9a20f4eed1867275), UINT64_C(0x87ce7eb0f3aad3a9),\n    UINT64_C(0xd647c92a1d6db6bd), UINT64_C(0xcba943743f411761),\n    UINT64_C(0xed9add965934f505), UINT64_C(0xf07457c87b1854d9),\n    UINT64_C(0x02b9b86a097e3c68), UINT64_C(0x1f5732342b529db4),\n    UINT64_C(0x3964acd64d277fd0), UINT64_C(0x248a26886f0bde0c),\n    UINT64_C(0x7503911281ccbb18), UINT64_C(0x68ed1b4ca3e01ac4),\n    UINT64_C(0x4ede85aec595f8a0), UINT64_C(0x53300ff0e7b9597c),\n    UINT64_C(0xedcdea9b181b3288), UINT64_C(0xf02360c53a379354),\n    UINT64_C(0xd610fe275c427130), UINT64_C(0xcbfe74797e6ed0ec),\n    UINT64_C(0x9a77c3e390a9b5f8), UINT64_C(0x879949bdb2851424),\n    UINT64_C(0xa1aad75fd4f0f640), UINT64_C(0xbc445d01f6dc579c),\n    UINT64_C(0x74f1233d072c2a36), UINT64_C(0x691fa96325008bea),\n    UINT64_C(0x4f2c37814375698e), UINT64_C(0x52c2bddf6159c852),\n    UINT64_C(0x034b0a458f9ead46), UINT64_C(0x1ea5801badb20c9a),\n    UINT64_C(0x38961ef9cbc7eefe), UINT64_C(0x257894a7e9eb4f22),\n    UINT64_C(0x9b8571cc164924d6), UINT64_C(0x866bfb923465850a),\n    UINT64_C(0xa05865705210676e), UINT64_C(0xbdb6ef2e703cc6b2),\n    UINT64_C(0xec3f58b49efba3a6), UINT64_C(0xf1d1d2eabcd7027a),\n    UINT64_C(0xd7e24c08daa2e01e), UINT64_C(0xca0cc656f88e41c2),\n    UINT64_C(0x38c129f48ae82973), UINT64_C(0x252fa3aaa8c488af),\n    UINT64_C(0x031c3d48ceb16acb), UINT64_C(0x1ef2b716ec9dcb17),\n    UINT64_C(0x4f7b008c025aae03), UINT64_C(0x52958ad220760fdf),\n    UINT64_C(0x74a614304603edbb), UINT64_C(0x69489e6e642f4c67),\n    UINT64_C(0xd7b57b059b8d2793), UINT64_C(0xca5bf15bb9a1864f),\n    UINT64_C(0xec686fb9dfd4642b), UINT64_C(0xf186e5e7fdf8c5f7),\n    UINT64_C(0xa00f527d133fa0e3), UINT64_C(0xbde1d8233113013f),\n    UINT64_C(0x9bd246c15766e35b), UINT64_C(0x863ccc9f754a4287),\n    UINT64_C(0xec9136ae1ca42cbc), UINT64_C(0xf17fbcf03e888d60),\n    UINT64_C(0xd74c221258fd6f04), UINT64_C(0xcaa2a84c7ad1ced8),\n    UINT64_C(0x9b2b1fd69416abcc), UINT64_C(0x86c59588b63a0a10),\n    UINT64_C(0xa0f60b6ad04fe874), UINT64_C(0xbd188134f26349a8),\n    UINT64_C(0x03e5645f0dc1225c), UINT64_C(0x1e0bee012fed8380),\n    UINT64_C(0x383870e3499861e4), UINT64_C(0x25d6fabd6bb4c038),\n    UINT64_C(0x745f4d278573a52c), UINT64_C(0x69b1c779a75f04f0),\n    UINT64_C(0x4f82599bc12ae694), UINT64_C(0x526cd3c5e3064748),\n    UINT64_C(0xa0a13c6791602ff9), UINT64_C(0xbd4fb639b34c8e25),\n    UINT64_C(0x9b7c28dbd5396c41), UINT64_C(0x8692a285f715cd9d),\n    UINT64_C(0xd71b151f19d2a889), UINT64_C(0xcaf59f413bfe0955),\n    UINT64_C(0xecc601a35d8beb31), UINT64_C(0xf1288bfd7fa74aed),\n    UINT64_C(0x4fd56e9680052119), UINT64_C(0x523be4c8a22980c5),\n    UINT64_C(0x74087a2ac45c62a1), UINT64_C(0x69e6f074e670c37d),\n    UINT64_C(0x386f47ee08b7a669), UINT64_C(0x2581cdb02a9b07b5),\n    UINT64_C(0x03b253524ceee5d1), UINT64_C(0x1e5cd90c6ec2440d)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x3f0be14a916a6dcb),\n    UINT64_C(0x7e17c29522d4db96), UINT64_C(0x411c23dfb3beb65d),\n    UINT64_C(0xfc2f852a45a9b72c), UINT64_C(0xc3246460d4c3dae7),\n    UINT64_C(0x823847bf677d6cba), UINT64_C(0xbd33a6f5f6170171),\n    UINT64_C(0x6a87a57f245d70dd), UINT64_C(0x558c4435b5371d16),\n    UINT64_C(0x149067ea0689ab4b), UINT64_C(0x2b9b86a097e3c680),\n    UINT64_C(0x96a8205561f4c7f1), UINT64_C(0xa9a3c11ff09eaa3a),\n    UINT64_C(0xe8bfe2c043201c67), UINT64_C(0xd7b4038ad24a71ac),\n    UINT64_C(0xd50f4afe48bae1ba), UINT64_C(0xea04abb4d9d08c71),\n    UINT64_C(0xab18886b6a6e3a2c), UINT64_C(0x94136921fb0457e7),\n    UINT64_C(0x2920cfd40d135696), UINT64_C(0x162b2e9e9c793b5d),\n    UINT64_C(0x57370d412fc78d00), UINT64_C(0x683cec0bbeade0cb),\n    UINT64_C(0xbf88ef816ce79167), UINT64_C(0x80830ecbfd8dfcac),\n    UINT64_C(0xc19f2d144e334af1), UINT64_C(0xfe94cc5edf59273a),\n    UINT64_C(0x43a76aab294e264b), UINT64_C(0x7cac8be1b8244b80),\n    UINT64_C(0x3db0a83e0b9afddd), UINT64_C(0x02bb49749af09016),\n    UINT64_C(0x38c63ad73e7bddf1), UINT64_C(0x07cddb9daf11b03a),\n    UINT64_C(0x46d1f8421caf0667), UINT64_C(0x79da19088dc56bac),\n    UINT64_C(0xc4e9bffd7bd26add), UINT64_C(0xfbe25eb7eab80716),\n    UINT64_C(0xbafe7d685906b14b), UINT64_C(0x85f59c22c86cdc80),\n    UINT64_C(0x52419fa81a26ad2c), UINT64_C(0x6d4a7ee28b4cc0e7),\n    UINT64_C(0x2c565d3d38f276ba), UINT64_C(0x135dbc77a9981b71),\n    UINT64_C(0xae6e1a825f8f1a00), UINT64_C(0x9165fbc8cee577cb),\n    UINT64_C(0xd079d8177d5bc196), UINT64_C(0xef72395dec31ac5d),\n    UINT64_C(0xedc9702976c13c4b), UINT64_C(0xd2c29163e7ab5180),\n    UINT64_C(0x93deb2bc5415e7dd), UINT64_C(0xacd553f6c57f8a16),\n    UINT64_C(0x11e6f50333688b67), UINT64_C(0x2eed1449a202e6ac),\n    UINT64_C(0x6ff1379611bc50f1), UINT64_C(0x50fad6dc80d63d3a),\n    UINT64_C(0x874ed556529c4c96), UINT64_C(0xb845341cc3f6215d),\n    UINT64_C(0xf95917c370489700), UINT64_C(0xc652f689e122facb),\n    UINT64_C(0x7b61507c1735fbba), UINT64_C(0x446ab136865f9671),\n    UINT64_C(0x057692e935e1202c), UINT64_C(0x3a7d73a3a48b4de7),\n    UINT64_C(0x718c75ae7cf7bbe2), UINT64_C(0x4e8794e4ed9dd629),\n    UINT64_C(0x0f9bb73b5e236074), UINT64_C(0x30905671cf490dbf),\n    UINT64_C(0x8da3f084395e0cce), UINT64_C(0xb2a811cea8346105),\n    UINT64_C(0xf3b432111b8ad758), UINT64_C(0xccbfd35b8ae0ba93),\n    UINT64_C(0x1b0bd0d158aacb3f), UINT64_C(0x2400319bc9c0a6f4),\n    UINT64_C(0x651c12447a7e10a9), UINT64_C(0x5a17f30eeb147d62),\n    UINT64_C(0xe72455fb1d037c13), UINT64_C(0xd82fb4b18c6911d8),\n    UINT64_C(0x9933976e3fd7a785), UINT64_C(0xa6387624aebdca4e),\n    UINT64_C(0xa4833f50344d5a58), UINT64_C(0x9b88de1aa5273793),\n    UINT64_C(0xda94fdc5169981ce), UINT64_C(0xe59f1c8f87f3ec05),\n    UINT64_C(0x58acba7a71e4ed74), UINT64_C(0x67a75b30e08e80bf),\n    UINT64_C(0x26bb78ef533036e2), UINT64_C(0x19b099a5c25a5b29),\n    UINT64_C(0xce049a2f10102a85), UINT64_C(0xf10f7b65817a474e),\n    UINT64_C(0xb01358ba32c4f113), UINT64_C(0x8f18b9f0a3ae9cd8),\n    UINT64_C(0x322b1f0555b99da9), UINT64_C(0x0d20fe4fc4d3f062),\n    UINT64_C(0x4c3cdd90776d463f), UINT64_C(0x73373cdae6072bf4),\n    UINT64_C(0x494a4f79428c6613), UINT64_C(0x7641ae33d3e60bd8),\n    UINT64_C(0x375d8dec6058bd85), UINT64_C(0x08566ca6f132d04e),\n    UINT64_C(0xb565ca530725d13f), UINT64_C(0x8a6e2b19964fbcf4),\n    UINT64_C(0xcb7208c625f10aa9), UINT64_C(0xf479e98cb49b6762),\n    UINT64_C(0x23cdea0666d116ce), UINT64_C(0x1cc60b4cf7bb7b05),\n    UINT64_C(0x5dda28934405cd58), UINT64_C(0x62d1c9d9d56fa093),\n    UINT64_C(0xdfe26f2c2378a1e2), UINT64_C(0xe0e98e66b212cc29),\n    UINT64_C(0xa1f5adb901ac7a74), UINT64_C(0x9efe4cf390c617bf),\n    UINT64_C(0x9c4505870a3687a9), UINT64_C(0xa34ee4cd9b5cea62),\n    UINT64_C(0xe252c71228e25c3f), UINT64_C(0xdd592658b98831f4),\n    UINT64_C(0x606a80ad4f9f3085), UINT64_C(0x5f6161e7def55d4e),\n    UINT64_C(0x1e7d42386d4beb13), UINT64_C(0x2176a372fc2186d8),\n    UINT64_C(0xf6c2a0f82e6bf774), UINT64_C(0xc9c941b2bf019abf),\n    UINT64_C(0x88d5626d0cbf2ce2), UINT64_C(0xb7de83279dd54129),\n    UINT64_C(0x0aed25d26bc24058), UINT64_C(0x35e6c498faa82d93),\n    UINT64_C(0x74fae74749169bce), UINT64_C(0x4bf1060dd87cf605),\n    UINT64_C(0xe318eb5cf9ef77c4), UINT64_C(0xdc130a1668851a0f),\n    UINT64_C(0x9d0f29c9db3bac52), UINT64_C(0xa204c8834a51c199),\n    UINT64_C(0x1f376e76bc46c0e8), UINT64_C(0x203c8f3c2d2cad23),\n    UINT64_C(0x6120ace39e921b7e), UINT64_C(0x5e2b4da90ff876b5),\n    UINT64_C(0x899f4e23ddb20719), UINT64_C(0xb694af694cd86ad2),\n    UINT64_C(0xf7888cb6ff66dc8f), UINT64_C(0xc8836dfc6e0cb144),\n    UINT64_C(0x75b0cb09981bb035), UINT64_C(0x4abb2a430971ddfe),\n    UINT64_C(0x0ba7099cbacf6ba3), UINT64_C(0x34ace8d62ba50668),\n    UINT64_C(0x3617a1a2b155967e), UINT64_C(0x091c40e8203ffbb5),\n    UINT64_C(0x4800633793814de8), UINT64_C(0x770b827d02eb2023),\n    UINT64_C(0xca382488f4fc2152), UINT64_C(0xf533c5c265964c99),\n    UINT64_C(0xb42fe61dd628fac4), UINT64_C(0x8b2407574742970f),\n    UINT64_C(0x5c9004dd9508e6a3), UINT64_C(0x639be59704628b68),\n    UINT64_C(0x2287c648b7dc3d35), UINT64_C(0x1d8c270226b650fe),\n    UINT64_C(0xa0bf81f7d0a1518f), UINT64_C(0x9fb460bd41cb3c44),\n    UINT64_C(0xdea84362f2758a19), UINT64_C(0xe1a3a228631fe7d2),\n    UINT64_C(0xdbded18bc794aa35), UINT64_C(0xe4d530c156fec7fe),\n    UINT64_C(0xa5c9131ee54071a3), UINT64_C(0x9ac2f254742a1c68),\n    UINT64_C(0x27f154a1823d1d19), UINT64_C(0x18fab5eb135770d2),\n    UINT64_C(0x59e69634a0e9c68f), UINT64_C(0x66ed777e3183ab44),\n    UINT64_C(0xb15974f4e3c9dae8), UINT64_C(0x8e5295be72a3b723),\n    UINT64_C(0xcf4eb661c11d017e), UINT64_C(0xf045572b50776cb5),\n    UINT64_C(0x4d76f1dea6606dc4), UINT64_C(0x727d1094370a000f),\n    UINT64_C(0x3361334b84b4b652), UINT64_C(0x0c6ad20115dedb99),\n    UINT64_C(0x0ed19b758f2e4b8f), UINT64_C(0x31da7a3f1e442644),\n    UINT64_C(0x70c659e0adfa9019), UINT64_C(0x4fcdb8aa3c90fdd2),\n    UINT64_C(0xf2fe1e5fca87fca3), UINT64_C(0xcdf5ff155bed9168),\n    UINT64_C(0x8ce9dccae8532735), UINT64_C(0xb3e23d8079394afe),\n    UINT64_C(0x64563e0aab733b52), UINT64_C(0x5b5ddf403a195699),\n    UINT64_C(0x1a41fc9f89a7e0c4), UINT64_C(0x254a1dd518cd8d0f),\n    UINT64_C(0x9879bb20eeda8c7e), UINT64_C(0xa7725a6a7fb0e1b5),\n    UINT64_C(0xe66e79b5cc0e57e8), UINT64_C(0xd96598ff5d643a23),\n    UINT64_C(0x92949ef28518cc26), UINT64_C(0xad9f7fb81472a1ed),\n    UINT64_C(0xec835c67a7cc17b0), UINT64_C(0xd388bd2d36a67a7b),\n    UINT64_C(0x6ebb1bd8c0b17b0a), UINT64_C(0x51b0fa9251db16c1),\n    UINT64_C(0x10acd94de265a09c), UINT64_C(0x2fa73807730fcd57),\n    UINT64_C(0xf8133b8da145bcfb), UINT64_C(0xc718dac7302fd130),\n    UINT64_C(0x8604f9188391676d), UINT64_C(0xb90f185212fb0aa6),\n    UINT64_C(0x043cbea7e4ec0bd7), UINT64_C(0x3b375fed7586661c),\n    UINT64_C(0x7a2b7c32c638d041), UINT64_C(0x45209d785752bd8a),\n    UINT64_C(0x479bd40ccda22d9c), UINT64_C(0x789035465cc84057),\n    UINT64_C(0x398c1699ef76f60a), UINT64_C(0x0687f7d37e1c9bc1),\n    UINT64_C(0xbbb45126880b9ab0), UINT64_C(0x84bfb06c1961f77b),\n    UINT64_C(0xc5a393b3aadf4126), UINT64_C(0xfaa872f93bb52ced),\n    UINT64_C(0x2d1c7173e9ff5d41), UINT64_C(0x121790397895308a),\n    UINT64_C(0x530bb3e6cb2b86d7), UINT64_C(0x6c0052ac5a41eb1c),\n    UINT64_C(0xd133f459ac56ea6d), UINT64_C(0xee3815133d3c87a6),\n    UINT64_C(0xaf2436cc8e8231fb), UINT64_C(0x902fd7861fe85c30),\n    UINT64_C(0xaa52a425bb6311d7), UINT64_C(0x9559456f2a097c1c),\n    UINT64_C(0xd44566b099b7ca41), UINT64_C(0xeb4e87fa08dda78a),\n    UINT64_C(0x567d210ffecaa6fb), UINT64_C(0x6976c0456fa0cb30),\n    UINT64_C(0x286ae39adc1e7d6d), UINT64_C(0x176102d04d7410a6),\n    UINT64_C(0xc0d5015a9f3e610a), UINT64_C(0xffdee0100e540cc1),\n    UINT64_C(0xbec2c3cfbdeaba9c), UINT64_C(0x81c922852c80d757),\n    UINT64_C(0x3cfa8470da97d626), UINT64_C(0x03f1653a4bfdbbed),\n    UINT64_C(0x42ed46e5f8430db0), UINT64_C(0x7de6a7af6929607b),\n    UINT64_C(0x7f5deedbf3d9f06d), UINT64_C(0x40560f9162b39da6),\n    UINT64_C(0x014a2c4ed10d2bfb), UINT64_C(0x3e41cd0440674630),\n    UINT64_C(0x83726bf1b6704741), UINT64_C(0xbc798abb271a2a8a),\n    UINT64_C(0xfd65a96494a49cd7), UINT64_C(0xc26e482e05cef11c),\n    UINT64_C(0x15da4ba4d78480b0), UINT64_C(0x2ad1aaee46eeed7b),\n    UINT64_C(0x6bcd8931f5505b26), UINT64_C(0x54c6687b643a36ed),\n    UINT64_C(0xe9f5ce8e922d379c), UINT64_C(0xd6fe2fc403475a57),\n    UINT64_C(0x97e20c1bb0f9ec0a), UINT64_C(0xa8e9ed51219381c1)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x54e979925cd0f10d),\n    UINT64_C(0xa9d2f324b9a1e21a), UINT64_C(0xfd3b8ab6e5711317),\n    UINT64_C(0xc17d4962dc4ddab1), UINT64_C(0x959430f0809d2bbc),\n    UINT64_C(0x68afba4665ec38ab), UINT64_C(0x3c46c3d4393cc9a6),\n    UINT64_C(0x10223dee1795abe7), UINT64_C(0x44cb447c4b455aea),\n    UINT64_C(0xb9f0cecaae3449fd), UINT64_C(0xed19b758f2e4b8f0),\n    UINT64_C(0xd15f748ccbd87156), UINT64_C(0x85b60d1e9708805b),\n    UINT64_C(0x788d87a87279934c), UINT64_C(0x2c64fe3a2ea96241),\n    UINT64_C(0x20447bdc2f2b57ce), UINT64_C(0x74ad024e73fba6c3),\n    UINT64_C(0x899688f8968ab5d4), UINT64_C(0xdd7ff16aca5a44d9),\n    UINT64_C(0xe13932bef3668d7f), UINT64_C(0xb5d04b2cafb67c72),\n    UINT64_C(0x48ebc19a4ac76f65), UINT64_C(0x1c02b80816179e68),\n    UINT64_C(0x3066463238befc29), UINT64_C(0x648f3fa0646e0d24),\n    UINT64_C(0x99b4b516811f1e33), UINT64_C(0xcd5dcc84ddcfef3e),\n    UINT64_C(0xf11b0f50e4f32698), UINT64_C(0xa5f276c2b823d795),\n    UINT64_C(0x58c9fc745d52c482), UINT64_C(0x0c2085e60182358f),\n    UINT64_C(0x4088f7b85e56af9c), UINT64_C(0x14618e2a02865e91),\n    UINT64_C(0xe95a049ce7f74d86), UINT64_C(0xbdb37d0ebb27bc8b),\n    UINT64_C(0x81f5beda821b752d), UINT64_C(0xd51cc748decb8420),\n    UINT64_C(0x28274dfe3bba9737), UINT64_C(0x7cce346c676a663a),\n    UINT64_C(0x50aaca5649c3047b), UINT64_C(0x0443b3c41513f576),\n    UINT64_C(0xf9783972f062e661), UINT64_C(0xad9140e0acb2176c),\n    UINT64_C(0x91d78334958edeca), UINT64_C(0xc53efaa6c95e2fc7),\n    UINT64_C(0x380570102c2f3cd0), UINT64_C(0x6cec098270ffcddd),\n    UINT64_C(0x60cc8c64717df852), UINT64_C(0x3425f5f62dad095f),\n    UINT64_C(0xc91e7f40c8dc1a48), UINT64_C(0x9df706d2940ceb45),\n    UINT64_C(0xa1b1c506ad3022e3), UINT64_C(0xf558bc94f1e0d3ee),\n    UINT64_C(0x086336221491c0f9), UINT64_C(0x5c8a4fb0484131f4),\n    UINT64_C(0x70eeb18a66e853b5), UINT64_C(0x2407c8183a38a2b8),\n    UINT64_C(0xd93c42aedf49b1af), UINT64_C(0x8dd53b3c839940a2),\n    UINT64_C(0xb193f8e8baa58904), UINT64_C(0xe57a817ae6757809),\n    UINT64_C(0x18410bcc03046b1e), UINT64_C(0x4ca8725e5fd49a13),\n    UINT64_C(0x8111ef70bcad5f38), UINT64_C(0xd5f896e2e07dae35),\n    UINT64_C(0x28c31c54050cbd22), UINT64_C(0x7c2a65c659dc4c2f),\n    UINT64_C(0x406ca61260e08589), UINT64_C(0x1485df803c307484),\n    UINT64_C(0xe9be5536d9416793), UINT64_C(0xbd572ca48591969e),\n    UINT64_C(0x9133d29eab38f4df), UINT64_C(0xc5daab0cf7e805d2),\n    UINT64_C(0x38e121ba129916c5), UINT64_C(0x6c0858284e49e7c8),\n    UINT64_C(0x504e9bfc77752e6e), UINT64_C(0x04a7e26e2ba5df63),\n    UINT64_C(0xf99c68d8ced4cc74), UINT64_C(0xad75114a92043d79),\n    UINT64_C(0xa15594ac938608f6), UINT64_C(0xf5bced3ecf56f9fb),\n    UINT64_C(0x088767882a27eaec), UINT64_C(0x5c6e1e1a76f71be1),\n    UINT64_C(0x6028ddce4fcbd247), UINT64_C(0x34c1a45c131b234a),\n    UINT64_C(0xc9fa2eeaf66a305d), UINT64_C(0x9d135778aabac150),\n    UINT64_C(0xb177a9428413a311), UINT64_C(0xe59ed0d0d8c3521c),\n    UINT64_C(0x18a55a663db2410b), UINT64_C(0x4c4c23f46162b006),\n    UINT64_C(0x700ae020585e79a0), UINT64_C(0x24e399b2048e88ad),\n    UINT64_C(0xd9d81304e1ff9bba), UINT64_C(0x8d316a96bd2f6ab7),\n    UINT64_C(0xc19918c8e2fbf0a4), UINT64_C(0x9570615abe2b01a9),\n    UINT64_C(0x684bebec5b5a12be), UINT64_C(0x3ca2927e078ae3b3),\n    UINT64_C(0x00e451aa3eb62a15), UINT64_C(0x540d28386266db18),\n    UINT64_C(0xa936a28e8717c80f), UINT64_C(0xfddfdb1cdbc73902),\n    UINT64_C(0xd1bb2526f56e5b43), UINT64_C(0x85525cb4a9beaa4e),\n    UINT64_C(0x7869d6024ccfb959), UINT64_C(0x2c80af90101f4854),\n    UINT64_C(0x10c66c44292381f2), UINT64_C(0x442f15d675f370ff),\n    UINT64_C(0xb9149f60908263e8), UINT64_C(0xedfde6f2cc5292e5),\n    UINT64_C(0xe1dd6314cdd0a76a), UINT64_C(0xb5341a8691005667),\n    UINT64_C(0x480f903074714570), UINT64_C(0x1ce6e9a228a1b47d),\n    UINT64_C(0x20a02a76119d7ddb), UINT64_C(0x744953e44d4d8cd6),\n    UINT64_C(0x8972d952a83c9fc1), UINT64_C(0xdd9ba0c0f4ec6ecc),\n    UINT64_C(0xf1ff5efada450c8d), UINT64_C(0xa51627688695fd80),\n    UINT64_C(0x582dadde63e4ee97), UINT64_C(0x0cc4d44c3f341f9a),\n    UINT64_C(0x308217980608d63c), UINT64_C(0x646b6e0a5ad82731),\n    UINT64_C(0x9950e4bcbfa93426), UINT64_C(0xcdb99d2ee379c52b),\n    UINT64_C(0x90fb71cad654a0f5), UINT64_C(0xc41208588a8451f8),\n    UINT64_C(0x392982ee6ff542ef), UINT64_C(0x6dc0fb7c3325b3e2),\n    UINT64_C(0x518638a80a197a44), UINT64_C(0x056f413a56c98b49),\n    UINT64_C(0xf854cb8cb3b8985e), UINT64_C(0xacbdb21eef686953),\n    UINT64_C(0x80d94c24c1c10b12), UINT64_C(0xd43035b69d11fa1f),\n    UINT64_C(0x290bbf007860e908), UINT64_C(0x7de2c69224b01805),\n    UINT64_C(0x41a405461d8cd1a3), UINT64_C(0x154d7cd4415c20ae),\n    UINT64_C(0xe876f662a42d33b9), UINT64_C(0xbc9f8ff0f8fdc2b4),\n    UINT64_C(0xb0bf0a16f97ff73b), UINT64_C(0xe4567384a5af0636),\n    UINT64_C(0x196df93240de1521), UINT64_C(0x4d8480a01c0ee42c),\n    UINT64_C(0x71c2437425322d8a), UINT64_C(0x252b3ae679e2dc87),\n    UINT64_C(0xd810b0509c93cf90), UINT64_C(0x8cf9c9c2c0433e9d),\n    UINT64_C(0xa09d37f8eeea5cdc), UINT64_C(0xf4744e6ab23aadd1),\n    UINT64_C(0x094fc4dc574bbec6), UINT64_C(0x5da6bd4e0b9b4fcb),\n    UINT64_C(0x61e07e9a32a7866d), UINT64_C(0x350907086e777760),\n    UINT64_C(0xc8328dbe8b066477), UINT64_C(0x9cdbf42cd7d6957a),\n    UINT64_C(0xd073867288020f69), UINT64_C(0x849affe0d4d2fe64),\n    UINT64_C(0x79a1755631a3ed73), UINT64_C(0x2d480cc46d731c7e),\n    UINT64_C(0x110ecf10544fd5d8), UINT64_C(0x45e7b682089f24d5),\n    UINT64_C(0xb8dc3c34edee37c2), UINT64_C(0xec3545a6b13ec6cf),\n    UINT64_C(0xc051bb9c9f97a48e), UINT64_C(0x94b8c20ec3475583),\n    UINT64_C(0x698348b826364694), UINT64_C(0x3d6a312a7ae6b799),\n    UINT64_C(0x012cf2fe43da7e3f), UINT64_C(0x55c58b6c1f0a8f32),\n    UINT64_C(0xa8fe01dafa7b9c25), UINT64_C(0xfc177848a6ab6d28),\n    UINT64_C(0xf037fdaea72958a7), UINT64_C(0xa4de843cfbf9a9aa),\n    UINT64_C(0x59e50e8a1e88babd), UINT64_C(0x0d0c771842584bb0),\n    UINT64_C(0x314ab4cc7b648216), UINT64_C(0x65a3cd5e27b4731b),\n    UINT64_C(0x989847e8c2c5600c), UINT64_C(0xcc713e7a9e159101),\n    UINT64_C(0xe015c040b0bcf340), UINT64_C(0xb4fcb9d2ec6c024d),\n    UINT64_C(0x49c73364091d115a), UINT64_C(0x1d2e4af655cde057),\n    UINT64_C(0x216889226cf129f1), UINT64_C(0x7581f0b03021d8fc),\n    UINT64_C(0x88ba7a06d550cbeb), UINT64_C(0xdc53039489803ae6),\n    UINT64_C(0x11ea9eba6af9ffcd), UINT64_C(0x4503e72836290ec0),\n    UINT64_C(0xb8386d9ed3581dd7), UINT64_C(0xecd1140c8f88ecda),\n    UINT64_C(0xd097d7d8b6b4257c), UINT64_C(0x847eae4aea64d471),\n    UINT64_C(0x794524fc0f15c766), UINT64_C(0x2dac5d6e53c5366b),\n    UINT64_C(0x01c8a3547d6c542a), UINT64_C(0x5521dac621bca527),\n    UINT64_C(0xa81a5070c4cdb630), UINT64_C(0xfcf329e2981d473d),\n    UINT64_C(0xc0b5ea36a1218e9b), UINT64_C(0x945c93a4fdf17f96),\n    UINT64_C(0x6967191218806c81), UINT64_C(0x3d8e608044509d8c),\n    UINT64_C(0x31aee56645d2a803), UINT64_C(0x65479cf41902590e),\n    UINT64_C(0x987c1642fc734a19), UINT64_C(0xcc956fd0a0a3bb14),\n    UINT64_C(0xf0d3ac04999f72b2), UINT64_C(0xa43ad596c54f83bf),\n    UINT64_C(0x59015f20203e90a8), UINT64_C(0x0de826b27cee61a5),\n    UINT64_C(0x218cd888524703e4), UINT64_C(0x7565a11a0e97f2e9),\n    UINT64_C(0x885e2bacebe6e1fe), UINT64_C(0xdcb7523eb73610f3),\n    UINT64_C(0xe0f191ea8e0ad955), UINT64_C(0xb418e878d2da2858),\n    UINT64_C(0x492362ce37ab3b4f), UINT64_C(0x1dca1b5c6b7bca42),\n    UINT64_C(0x5162690234af5051), UINT64_C(0x058b1090687fa15c),\n    UINT64_C(0xf8b09a268d0eb24b), UINT64_C(0xac59e3b4d1de4346),\n    UINT64_C(0x901f2060e8e28ae0), UINT64_C(0xc4f659f2b4327bed),\n    UINT64_C(0x39cdd344514368fa), UINT64_C(0x6d24aad60d9399f7),\n    UINT64_C(0x414054ec233afbb6), UINT64_C(0x15a92d7e7fea0abb),\n    UINT64_C(0xe892a7c89a9b19ac), UINT64_C(0xbc7bde5ac64be8a1),\n    UINT64_C(0x803d1d8eff772107), UINT64_C(0xd4d4641ca3a7d00a),\n    UINT64_C(0x29efeeaa46d6c31d), UINT64_C(0x7d0697381a063210),\n    UINT64_C(0x712612de1b84079f), UINT64_C(0x25cf6b4c4754f692),\n    UINT64_C(0xd8f4e1faa225e585), UINT64_C(0x8c1d9868fef51488),\n    UINT64_C(0xb05b5bbcc7c9dd2e), UINT64_C(0xe4b2222e9b192c23),\n    UINT64_C(0x1989a8987e683f34), UINT64_C(0x4d60d10a22b8ce39),\n    UINT64_C(0x61042f300c11ac78), UINT64_C(0x35ed56a250c15d75),\n    UINT64_C(0xc8d6dc14b5b04e62), UINT64_C(0x9c3fa586e960bf6f),\n    UINT64_C(0xa0796652d05c76c9), UINT64_C(0xf4901fc08c8c87c4),\n    UINT64_C(0x09ab957669fd94d3), UINT64_C(0x5d42ece4352d65de)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0xb32e4cbe03a75f6f),\n    UINT64_C(0xf4843657a840a05b), UINT64_C(0x47aa7ae9abe7ff34),\n    UINT64_C(0x7bd0c384ff8f5e33), UINT64_C(0xc8fe8f3afc28015c),\n    UINT64_C(0x8f54f5d357cffe68), UINT64_C(0x3c7ab96d5468a107),\n    UINT64_C(0xf7a18709ff1ebc66), UINT64_C(0x448fcbb7fcb9e309),\n    UINT64_C(0x0325b15e575e1c3d), UINT64_C(0xb00bfde054f94352),\n    UINT64_C(0x8c71448d0091e255), UINT64_C(0x3f5f08330336bd3a),\n    UINT64_C(0x78f572daa8d1420e), UINT64_C(0xcbdb3e64ab761d61),\n    UINT64_C(0x7d9ba13851336649), UINT64_C(0xceb5ed8652943926),\n    UINT64_C(0x891f976ff973c612), UINT64_C(0x3a31dbd1fad4997d),\n    UINT64_C(0x064b62bcaebc387a), UINT64_C(0xb5652e02ad1b6715),\n    UINT64_C(0xf2cf54eb06fc9821), UINT64_C(0x41e11855055bc74e),\n    UINT64_C(0x8a3a2631ae2dda2f), UINT64_C(0x39146a8fad8a8540),\n    UINT64_C(0x7ebe1066066d7a74), UINT64_C(0xcd905cd805ca251b),\n    UINT64_C(0xf1eae5b551a2841c), UINT64_C(0x42c4a90b5205db73),\n    UINT64_C(0x056ed3e2f9e22447), UINT64_C(0xb6409f5cfa457b28),\n    UINT64_C(0xfb374270a266cc92), UINT64_C(0x48190ecea1c193fd),\n    UINT64_C(0x0fb374270a266cc9), UINT64_C(0xbc9d3899098133a6),\n    UINT64_C(0x80e781f45de992a1), UINT64_C(0x33c9cd4a5e4ecdce),\n    UINT64_C(0x7463b7a3f5a932fa), UINT64_C(0xc74dfb1df60e6d95),\n    UINT64_C(0x0c96c5795d7870f4), UINT64_C(0xbfb889c75edf2f9b),\n    UINT64_C(0xf812f32ef538d0af), UINT64_C(0x4b3cbf90f69f8fc0),\n    UINT64_C(0x774606fda2f72ec7), UINT64_C(0xc4684a43a15071a8),\n    UINT64_C(0x83c230aa0ab78e9c), UINT64_C(0x30ec7c140910d1f3),\n    UINT64_C(0x86ace348f355aadb), UINT64_C(0x3582aff6f0f2f5b4),\n    UINT64_C(0x7228d51f5b150a80), UINT64_C(0xc10699a158b255ef),\n    UINT64_C(0xfd7c20cc0cdaf4e8), UINT64_C(0x4e526c720f7dab87),\n    UINT64_C(0x09f8169ba49a54b3), UINT64_C(0xbad65a25a73d0bdc),\n    UINT64_C(0x710d64410c4b16bd), UINT64_C(0xc22328ff0fec49d2),\n    UINT64_C(0x85895216a40bb6e6), UINT64_C(0x36a71ea8a7ace989),\n    UINT64_C(0x0adda7c5f3c4488e), UINT64_C(0xb9f3eb7bf06317e1),\n    UINT64_C(0xfe5991925b84e8d5), UINT64_C(0x4d77dd2c5823b7ba),\n    UINT64_C(0x64b62bcaebc387a1), UINT64_C(0xd7986774e864d8ce),\n    UINT64_C(0x90321d9d438327fa), UINT64_C(0x231c512340247895),\n    UINT64_C(0x1f66e84e144cd992), UINT64_C(0xac48a4f017eb86fd),\n    UINT64_C(0xebe2de19bc0c79c9), UINT64_C(0x58cc92a7bfab26a6),\n    UINT64_C(0x9317acc314dd3bc7), UINT64_C(0x2039e07d177a64a8),\n    UINT64_C(0x67939a94bc9d9b9c), UINT64_C(0xd4bdd62abf3ac4f3),\n    UINT64_C(0xe8c76f47eb5265f4), UINT64_C(0x5be923f9e8f53a9b),\n    UINT64_C(0x1c4359104312c5af), UINT64_C(0xaf6d15ae40b59ac0),\n    UINT64_C(0x192d8af2baf0e1e8), UINT64_C(0xaa03c64cb957be87),\n    UINT64_C(0xeda9bca512b041b3), UINT64_C(0x5e87f01b11171edc),\n    UINT64_C(0x62fd4976457fbfdb), UINT64_C(0xd1d305c846d8e0b4),\n    UINT64_C(0x96797f21ed3f1f80), UINT64_C(0x2557339fee9840ef),\n    UINT64_C(0xee8c0dfb45ee5d8e), UINT64_C(0x5da24145464902e1),\n    UINT64_C(0x1a083bacedaefdd5), UINT64_C(0xa9267712ee09a2ba),\n    UINT64_C(0x955cce7fba6103bd), UINT64_C(0x267282c1b9c65cd2),\n    UINT64_C(0x61d8f8281221a3e6), UINT64_C(0xd2f6b4961186fc89),\n    UINT64_C(0x9f8169ba49a54b33), UINT64_C(0x2caf25044a02145c),\n    UINT64_C(0x6b055fede1e5eb68), UINT64_C(0xd82b1353e242b407),\n    UINT64_C(0xe451aa3eb62a1500), UINT64_C(0x577fe680b58d4a6f),\n    UINT64_C(0x10d59c691e6ab55b), UINT64_C(0xa3fbd0d71dcdea34),\n    UINT64_C(0x6820eeb3b6bbf755), UINT64_C(0xdb0ea20db51ca83a),\n    UINT64_C(0x9ca4d8e41efb570e), UINT64_C(0x2f8a945a1d5c0861),\n    UINT64_C(0x13f02d374934a966), UINT64_C(0xa0de61894a93f609),\n    UINT64_C(0xe7741b60e174093d), UINT64_C(0x545a57dee2d35652),\n    UINT64_C(0xe21ac88218962d7a), UINT64_C(0x5134843c1b317215),\n    UINT64_C(0x169efed5b0d68d21), UINT64_C(0xa5b0b26bb371d24e),\n    UINT64_C(0x99ca0b06e7197349), UINT64_C(0x2ae447b8e4be2c26),\n    UINT64_C(0x6d4e3d514f59d312), UINT64_C(0xde6071ef4cfe8c7d),\n    UINT64_C(0x15bb4f8be788911c), UINT64_C(0xa6950335e42fce73),\n    UINT64_C(0xe13f79dc4fc83147), UINT64_C(0x521135624c6f6e28),\n    UINT64_C(0x6e6b8c0f1807cf2f), UINT64_C(0xdd45c0b11ba09040),\n    UINT64_C(0x9aefba58b0476f74), UINT64_C(0x29c1f6e6b3e0301b),\n    UINT64_C(0xc96c5795d7870f42), UINT64_C(0x7a421b2bd420502d),\n    UINT64_C(0x3de861c27fc7af19), UINT64_C(0x8ec62d7c7c60f076),\n    UINT64_C(0xb2bc941128085171), UINT64_C(0x0192d8af2baf0e1e),\n    UINT64_C(0x4638a2468048f12a), UINT64_C(0xf516eef883efae45),\n    UINT64_C(0x3ecdd09c2899b324), UINT64_C(0x8de39c222b3eec4b),\n    UINT64_C(0xca49e6cb80d9137f), UINT64_C(0x7967aa75837e4c10),\n    UINT64_C(0x451d1318d716ed17), UINT64_C(0xf6335fa6d4b1b278),\n    UINT64_C(0xb199254f7f564d4c), UINT64_C(0x02b769f17cf11223),\n    UINT64_C(0xb4f7f6ad86b4690b), UINT64_C(0x07d9ba1385133664),\n    UINT64_C(0x4073c0fa2ef4c950), UINT64_C(0xf35d8c442d53963f),\n    UINT64_C(0xcf273529793b3738), UINT64_C(0x7c0979977a9c6857),\n    UINT64_C(0x3ba3037ed17b9763), UINT64_C(0x888d4fc0d2dcc80c),\n    UINT64_C(0x435671a479aad56d), UINT64_C(0xf0783d1a7a0d8a02),\n    UINT64_C(0xb7d247f3d1ea7536), UINT64_C(0x04fc0b4dd24d2a59),\n    UINT64_C(0x3886b22086258b5e), UINT64_C(0x8ba8fe9e8582d431),\n    UINT64_C(0xcc0284772e652b05), UINT64_C(0x7f2cc8c92dc2746a),\n    UINT64_C(0x325b15e575e1c3d0), UINT64_C(0x8175595b76469cbf),\n    UINT64_C(0xc6df23b2dda1638b), UINT64_C(0x75f16f0cde063ce4),\n    UINT64_C(0x498bd6618a6e9de3), UINT64_C(0xfaa59adf89c9c28c),\n    UINT64_C(0xbd0fe036222e3db8), UINT64_C(0x0e21ac88218962d7),\n    UINT64_C(0xc5fa92ec8aff7fb6), UINT64_C(0x76d4de52895820d9),\n    UINT64_C(0x317ea4bb22bfdfed), UINT64_C(0x8250e80521188082),\n    UINT64_C(0xbe2a516875702185), UINT64_C(0x0d041dd676d77eea),\n    UINT64_C(0x4aae673fdd3081de), UINT64_C(0xf9802b81de97deb1),\n    UINT64_C(0x4fc0b4dd24d2a599), UINT64_C(0xfceef8632775faf6),\n    UINT64_C(0xbb44828a8c9205c2), UINT64_C(0x086ace348f355aad),\n    UINT64_C(0x34107759db5dfbaa), UINT64_C(0x873e3be7d8faa4c5),\n    UINT64_C(0xc094410e731d5bf1), UINT64_C(0x73ba0db070ba049e),\n    UINT64_C(0xb86133d4dbcc19ff), UINT64_C(0x0b4f7f6ad86b4690),\n    UINT64_C(0x4ce50583738cb9a4), UINT64_C(0xffcb493d702be6cb),\n    UINT64_C(0xc3b1f050244347cc), UINT64_C(0x709fbcee27e418a3),\n    UINT64_C(0x3735c6078c03e797), UINT64_C(0x841b8ab98fa4b8f8),\n    UINT64_C(0xadda7c5f3c4488e3), UINT64_C(0x1ef430e13fe3d78c),\n    UINT64_C(0x595e4a08940428b8), UINT64_C(0xea7006b697a377d7),\n    UINT64_C(0xd60abfdbc3cbd6d0), UINT64_C(0x6524f365c06c89bf),\n    UINT64_C(0x228e898c6b8b768b), UINT64_C(0x91a0c532682c29e4),\n    UINT64_C(0x5a7bfb56c35a3485), UINT64_C(0xe955b7e8c0fd6bea),\n    UINT64_C(0xaeffcd016b1a94de), UINT64_C(0x1dd181bf68bdcbb1),\n    UINT64_C(0x21ab38d23cd56ab6), UINT64_C(0x9285746c3f7235d9),\n    UINT64_C(0xd52f0e859495caed), UINT64_C(0x6601423b97329582),\n    UINT64_C(0xd041dd676d77eeaa), UINT64_C(0x636f91d96ed0b1c5),\n    UINT64_C(0x24c5eb30c5374ef1), UINT64_C(0x97eba78ec690119e),\n    UINT64_C(0xab911ee392f8b099), UINT64_C(0x18bf525d915feff6),\n    UINT64_C(0x5f1528b43ab810c2), UINT64_C(0xec3b640a391f4fad),\n    UINT64_C(0x27e05a6e926952cc), UINT64_C(0x94ce16d091ce0da3),\n    UINT64_C(0xd3646c393a29f297), UINT64_C(0x604a2087398eadf8),\n    UINT64_C(0x5c3099ea6de60cff), UINT64_C(0xef1ed5546e415390),\n    UINT64_C(0xa8b4afbdc5a6aca4), UINT64_C(0x1b9ae303c601f3cb),\n    UINT64_C(0x56ed3e2f9e224471), UINT64_C(0xe5c372919d851b1e),\n    UINT64_C(0xa26908783662e42a), UINT64_C(0x114744c635c5bb45),\n    UINT64_C(0x2d3dfdab61ad1a42), UINT64_C(0x9e13b115620a452d),\n    UINT64_C(0xd9b9cbfcc9edba19), UINT64_C(0x6a978742ca4ae576),\n    UINT64_C(0xa14cb926613cf817), UINT64_C(0x1262f598629ba778),\n    UINT64_C(0x55c88f71c97c584c), UINT64_C(0xe6e6c3cfcadb0723),\n    UINT64_C(0xda9c7aa29eb3a624), UINT64_C(0x69b2361c9d14f94b),\n    UINT64_C(0x2e184cf536f3067f), UINT64_C(0x9d36004b35545910),\n    UINT64_C(0x2b769f17cf112238), UINT64_C(0x9858d3a9ccb67d57),\n    UINT64_C(0xdff2a94067518263), UINT64_C(0x6cdce5fe64f6dd0c),\n    UINT64_C(0x50a65c93309e7c0b), UINT64_C(0xe388102d33392364),\n    UINT64_C(0xa4226ac498dedc50), UINT64_C(0x170c267a9b79833f),\n    UINT64_C(0xdcd7181e300f9e5e), UINT64_C(0x6ff954a033a8c131),\n    UINT64_C(0x28532e49984f3e05), UINT64_C(0x9b7d62f79be8616a),\n    UINT64_C(0xa707db9acf80c06d), UINT64_C(0x14299724cc279f02),\n    UINT64_C(0x5383edcd67c06036), UINT64_C(0xe0ada17364673f59)\n  }\n};\n\nstatic const uint64_t crc64_interleaved_table[4][256] = {\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0xe88a0d0c5521de3d),\n    UINT64_C(0x43ccb533054da2ff), UINT64_C(0xab46b83f506c7cc2),\n    UINT64_C(0x87996a660a9b45fe), UINT64_C(0x6f13676a5fba9bc3),\n    UINT64_C(0xc455df550fd6e701), UINT64_C(0x2cdfd2595af7393c),\n    UINT64_C(0x9dea7be7ba389579), UINT64_C(0x756076ebef194b44),\n    UINT64_C(0xde26ced4bf753786), UINT64_C(0x36acc3d8ea54e9bb),\n    UINT64_C(0x1a731181b0a3d087), UINT64_C(0xf2f91c8de5820eba),\n    UINT64_C(0x59bfa4b2b5ee7278), UINT64_C(0xb135a9bee0cfac45),\n    UINT64_C(0xa90c58e4db7f3477), UINT64_C(0x418655e88e5eea4a),\n    UINT64_C(0xeac0edd7de329688), UINT64_C(0x024ae0db8b1348b5),\n    UINT64_C(0x2e953282d1e47189), UINT64_C(0xc61f3f8e84c5afb4),\n    UINT64_C(0x6d5987b1d4a9d376), UINT64_C(0x85d38abd81880d4b),\n    UINT64_C(0x34e623036147a10e), UINT64_C(0xdc6c2e0f34667f33),\n    UINT64_C(0x772a9630640a03f1), UINT64_C(0x9fa09b3c312bddcc),\n    UINT64_C(0xb37f49656bdce4f0), UINT64_C(0x5bf544693efd3acd),\n    UINT64_C(0xf0b3fc566e91460f), UINT64_C(0x1839f15a3bb09832),\n    UINT64_C(0xc0c01ee219f0766b), UINT64_C(0x284a13ee4cd1a856),\n    UINT64_C(0x830cabd11cbdd494), UINT64_C(0x6b86a6dd499c0aa9),\n    UINT64_C(0x47597484136b3395), UINT64_C(0xafd37988464aeda8),\n    UINT64_C(0x0495c1b71626916a), UINT64_C(0xec1fccbb43074f57),\n    UINT64_C(0x5d2a6505a3c8e312), UINT64_C(0xb5a06809f6e93d2f),\n    UINT64_C(0x1ee6d036a68541ed), UINT64_C(0xf66cdd3af3a49fd0),\n    UINT64_C(0xdab30f63a953a6ec), UINT64_C(0x3239026ffc7278d1),\n    UINT64_C(0x997fba50ac1e0413), UINT64_C(0x71f5b75cf93fda2e),\n    UINT64_C(0x69cc4606c28f421c), UINT64_C(0x81464b0a97ae9c21),\n    UINT64_C(0x2a00f335c7c2e0e3), UINT64_C(0xc28afe3992e33ede),\n    UINT64_C(0xee552c60c81407e2), UINT64_C(0x06df216c9d35d9df),\n    UINT64_C(0xad999953cd59a51d), UINT64_C(0x4513945f98787b20),\n    UINT64_C(0xf4263de178b7d765), UINT64_C(0x1cac30ed2d960958),\n    UINT64_C(0xb7ea88d27dfa759a), UINT64_C(0x5f6085de28dbaba7),\n    UINT64_C(0x73bf5787722c929b), UINT64_C(0x9b355a8b270d4ca6),\n    UINT64_C(0x3073e2b477613064), UINT64_C(0xd8f9efb82240ee59),\n    UINT64_C(0x135892ef9ceef253), UINT64_C(0xfbd29fe3c9cf2c6e),\n    UINT64_C(0x509427dc99a350ac), UINT64_C(0xb81e2ad0cc828e91),\n    UINT64_C(0x94c1f8899675b7ad), UINT64_C(0x7c4bf585c3546990),\n    UINT64_C(0xd70d4dba93381552), UINT64_C(0x3f8740b6c619cb6f),\n    UINT64_C(0x8eb2e90826d6672a), UINT64_C(0x6638e40473f7b917),\n    UINT64_C(0xcd7e5c3b239bc5d5), UINT64_C(0x25f4513776ba1be8),\n    UINT64_C(0x092b836e2c4d22d4), UINT64_C(0xe1a18e62796cfce9),\n    UINT64_C(0x4ae7365d2900802b), UINT64_C(0xa26d3b517c215e16),\n    UINT64_C(0xba54ca0b4791c624), UINT64_C(0x52dec70712b01819),\n    UINT64_C(0xf9987f3842dc64db), UINT64_C(0x1112723417fdbae6),\n    UINT64_C(0x3dcda06d4d0a83da), UINT64_C(0xd547ad61182b5de7),\n    UINT64_C(0x7e01155e48472125), UINT64_C(0x968b18521d66ff18),\n    UINT64_C(0x27beb1ecfda9535d), UINT64_C(0xcf34bce0a8888d60),\n    UINT64_C(0x647204dff8e4f1a2), UINT64_C(0x8cf809d3adc52f9f),\n    UINT64_C(0xa027db8af73216a3), UINT64_C(0x48add686a213c89e),\n    UINT64_C(0xe3eb6eb9f27fb45c), UINT64_C(0x0b6163b5a75e6a61),\n    UINT64_C(0xd3988c0d851e8438), UINT64_C(0x3b128101d03f5a05),\n    UINT64_C(0x9054393e805326c7), UINT64_C(0x78de3432d572f8fa),\n    UINT64_C(0x5401e66b8f85c1c6), UINT64_C(0xbc8beb67daa41ffb),\n    UINT64_C(0x17cd53588ac86339), UINT64_C(0xff475e54dfe9bd04),\n    UINT64_C(0x4e72f7ea3f261141), UINT64_C(0xa6f8fae66a07cf7c),\n    UINT64_C(0x0dbe42d93a6bb3be), UINT64_C(0xe5344fd56f4a6d83),\n    UINT64_C(0xc9eb9d8c35bd54bf), UINT64_C(0x21619080609c8a82),\n    UINT64_C(0x8a2728bf30f0f640), UINT64_C(0x62ad25b365d1287d),\n    UINT64_C(0x7a94d4e95e61b04f), UINT64_C(0x921ed9e50b406e72),\n    UINT64_C(0x395861da5b2c12b0), UINT64_C(0xd1d26cd60e0dcc8d),\n    UINT64_C(0xfd0dbe8f54faf5b1), UINT64_C(0x1587b38301db2b8c),\n    UINT64_C(0xbec10bbc51b7574e), UINT64_C(0x564b06b004968973),\n    UINT64_C(0xe77eaf0ee4592536), UINT64_C(0x0ff4a202b178fb0b),\n    UINT64_C(0xa4b21a3de11487c9), UINT64_C(0x4c381731b43559f4),\n    UINT64_C(0x60e7c568eec260c8), UINT64_C(0x886dc864bbe3bef5),\n    UINT64_C(0x232b705beb8fc237), UINT64_C(0xcba17d57beae1c0a),\n    UINT64_C(0x26b125df39dde4a6), UINT64_C(0xce3b28d36cfc3a9b),\n    UINT64_C(0x657d90ec3c904659), UINT64_C(0x8df79de069b19864),\n    UINT64_C(0xa1284fb93346a158), UINT64_C(0x49a242b566677f65),\n    UINT64_C(0xe2e4fa8a360b03a7), UINT64_C(0x0a6ef786632add9a),\n    UINT64_C(0xbb5b5e3883e571df), UINT64_C(0x53d15334d6c4afe2),\n    UINT64_C(0xf897eb0b86a8d320), UINT64_C(0x101de607d3890d1d),\n    UINT64_C(0x3cc2345e897e3421), UINT64_C(0xd4483952dc5fea1c),\n    UINT64_C(0x7f0e816d8c3396de), UINT64_C(0x97848c61d91248e3),\n    UINT64_C(0x8fbd7d3be2a2d0d1), UINT64_C(0x67377037b7830eec),\n    UINT64_C(0xcc71c808e7ef722e), UINT64_C(0x24fbc504b2ceac13),\n    UINT64_C(0x0824175de839952f), UINT64_C(0xe0ae1a51bd184b12),\n    UINT64_C(0x4be8a26eed7437d0), UINT64_C(0xa362af62b855e9ed),\n    UINT64_C(0x125706dc589a45a8), UINT64_C(0xfadd0bd00dbb9b95),\n    UINT64_C(0x519bb3ef5dd7e757), UINT64_C(0xb911bee308f6396a),\n    UINT64_C(0x95ce6cba52010056), UINT64_C(0x7d4461b60720de6b),\n    UINT64_C(0xd602d989574ca2a9), UINT64_C(0x3e88d485026d7c94),\n    UINT64_C(0xe6713b3d202d92cd), UINT64_C(0x0efb3631750c4cf0),\n    UINT64_C(0xa5bd8e0e25603032), UINT64_C(0x4d3783027041ee0f),\n    UINT64_C(0x61e8515b2ab6d733), UINT64_C(0x89625c577f97090e),\n    UINT64_C(0x2224e4682ffb75cc), UINT64_C(0xcaaee9647adaabf1),\n    UINT64_C(0x7b9b40da9a1507b4), UINT64_C(0x93114dd6cf34d989),\n    UINT64_C(0x3857f5e99f58a54b), UINT64_C(0xd0ddf8e5ca797b76),\n    UINT64_C(0xfc022abc908e424a), UINT64_C(0x148827b0c5af9c77),\n    UINT64_C(0xbfce9f8f95c3e0b5), UINT64_C(0x57449283c0e23e88),\n    UINT64_C(0x4f7d63d9fb52a6ba), UINT64_C(0xa7f76ed5ae737887),\n    UINT64_C(0x0cb1d6eafe1f0445), UINT64_C(0xe43bdbe6ab3eda78),\n    UINT64_C(0xc8e409bff1c9e344), UINT64_C(0x206e04b3a4e83d79),\n    UINT64_C(0x8b28bc8cf48441bb), UINT64_C(0x63a2b180a1a59f86),\n    UINT64_C(0xd297183e416a33c3), UINT64_C(0x3a1d1532144bedfe),\n    UINT64_C(0x915bad0d4427913c), UINT64_C(0x79d1a00111064f01),\n    UINT64_C(0x550e72584bf1763d), UINT64_C(0xbd847f541ed0a800),\n    UINT64_C(0x16c2c76b4ebcd4c2), UINT64_C(0xfe48ca671b9d0aff),\n    UINT64_C(0x35e9b730a53316f5), UINT64_C(0xdd63ba3cf012c8c8),\n    UINT64_C(0x76250203a07eb40a), UINT64_C(0x9eaf0f0ff55f6a37),\n    UINT64_C(0xb270dd56afa8530b), UINT64_C(0x5afad05afa898d36),\n    UINT64_C(0xf1bc6865aae5f1f4), UINT64_C(0x19366569ffc42fc9),\n    UINT64_C(0xa803ccd71f0b838c), UINT64_C(0x4089c1db4a2a5db1),\n    UINT64_C(0xebcf79e41a462173), UINT64_C(0x034574e84f67ff4e),\n    UINT64_C(0x2f9aa6b11590c672), UINT64_C(0xc710abbd40b1184f),\n    UINT64_C(0x6c56138210dd648d), UINT64_C(0x84dc1e8e45fcbab0),\n    UINT64_C(0x9ce5efd47e4c2282), UINT64_C(0x746fe2d82b6dfcbf),\n    UINT64_C(0xdf295ae77b01807d), UINT64_C(0x37a357eb2e205e40),\n    UINT64_C(0x1b7c85b274d7677c), UINT64_C(0xf3f688be21f6b941),\n    UINT64_C(0x58b03081719ac583), UINT64_C(0xb03a3d8d24bb1bbe),\n    UINT64_C(0x010f9433c474b7fb), UINT64_C(0xe985993f915569c6),\n    UINT64_C(0x42c32100c1391504), UINT64_C(0xaa492c0c9418cb39),\n    UINT64_C(0x8696fe55ceeff205), UINT64_C(0x6e1cf3599bce2c38),\n    UINT64_C(0xc55a4b66cba250fa), UINT64_C(0x2dd0466a9e838ec7),\n    UINT64_C(0xf529a9d2bcc3609e), UINT64_C(0x1da3a4dee9e2bea3),\n    UINT64_C(0xb6e51ce1b98ec261), UINT64_C(0x5e6f11edecaf1c5c),\n    UINT64_C(0x72b0c3b4b6582560), UINT64_C(0x9a3aceb8e379fb5d),\n    UINT64_C(0x317c7687b315879f), UINT64_C(0xd9f67b8be63459a2),\n    UINT64_C(0x68c3d23506fbf5e7), UINT64_C(0x8049df3953da2bda),\n    UINT64_C(0x2b0f670603b65718), UINT64_C(0xc3856a0a56978925),\n    UINT64_C(0xef5ab8530c60b019), UINT64_C(0x07d0b55f59416e24),\n    UINT64_C(0xac960d60092d12e6), UINT64_C(0x441c006c5c0cccdb),\n    UINT64_C(0x5c25f13667bc54e9), UINT64_C(0xb4affc3a329d8ad4),\n    UINT64_C(0x1fe9440562f1f616), UINT64_C(0xf763490937d0282b),\n    UINT64_C(0xdbbc9b506d271117), UINT64_C(0x3336965c3806cf2a),\n    UINT64_C(0x98702e63686ab3e8), UINT64_C(0x70fa236f3d4b6dd5),\n    UINT64_C(0xc1cf8ad1dd84c190), UINT64_C(0x294587dd88a51fad),\n    UINT64_C(0x82033fe2d8c9636f), UINT64_C(0x6a8932ee8de8bd52),\n    UINT64_C(0x4656e0b7d71f846e), UINT64_C(0xaedcedbb823e5a53),\n    UINT64_C(0x059a5584d2522691), UINT64_C(0xed1058888773f8ac)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x4d624bbe73bbc94c),\n    UINT64_C(0x9ac4977ce7779298), UINT64_C(0xd7a6dcc294cc5bd4),\n    UINT64_C(0xa75181d261e13bb5), UINT64_C(0xea33ca6c125af2f9),\n    UINT64_C(0x3d9516ae8696a92d), UINT64_C(0x70f75d10f52d6061),\n    UINT64_C(0xdc7bac8f6ccc69ef), UINT64_C(0x9119e7311f77a0a3),\n    UINT64_C(0x46bf3bf38bbbfb77), UINT64_C(0x0bdd704df800323b),\n    UINT64_C(0x7b2a2d5d0d2d525a), UINT64_C(0x364866e37e969b16),\n    UINT64_C(0xe1eeba21ea5ac0c2), UINT64_C(0xac8cf19f99e1098e),\n    UINT64_C(0x2a2ff6357696cd5b), UINT64_C(0x674dbd8b052d0417),\n    UINT64_C(0xb0eb614991e15fc3), UINT64_C(0xfd892af7e25a968f),\n    UINT64_C(0x8d7e77e71777f6ee), UINT64_C(0xc01c3c5964cc3fa2),\n    UINT64_C(0x17bae09bf0006476), UINT64_C(0x5ad8ab2583bbad3a),\n    UINT64_C(0xf6545aba1a5aa4b4), UINT64_C(0xbb36110469e16df8),\n    UINT64_C(0x6c90cdc6fd2d362c), UINT64_C(0x21f286788e96ff60),\n    UINT64_C(0x5105db687bbb9f01), UINT64_C(0x1c6790d60800564d),\n    UINT64_C(0xcbc14c149ccc0d99), UINT64_C(0x86a307aaef77c4d5),\n    UINT64_C(0x545fec6aed2d9ab6), UINT64_C(0x193da7d49e9653fa),\n    UINT64_C(0xce9b7b160a5a082e), UINT64_C(0x83f930a879e1c162),\n    UINT64_C(0xf30e6db88ccca103), UINT64_C(0xbe6c2606ff77684f),\n    UINT64_C(0x69cafac46bbb339b), UINT64_C(0x24a8b17a1800fad7),\n    UINT64_C(0x882440e581e1f359), UINT64_C(0xc5460b5bf25a3a15),\n    UINT64_C(0x12e0d799669661c1), UINT64_C(0x5f829c27152da88d),\n    UINT64_C(0x2f75c137e000c8ec), UINT64_C(0x62178a8993bb01a0),\n    UINT64_C(0xb5b1564b07775a74), UINT64_C(0xf8d31df574cc9338),\n    UINT64_C(0x7e701a5f9bbb57ed), UINT64_C(0x331251e1e8009ea1),\n    UINT64_C(0xe4b48d237cccc575), UINT64_C(0xa9d6c69d0f770c39),\n    UINT64_C(0xd9219b8dfa5a6c58), UINT64_C(0x9443d03389e1a514),\n    UINT64_C(0x43e50cf11d2dfec0), UINT64_C(0x0e87474f6e96378c),\n    UINT64_C(0xa20bb6d0f7773e02), UINT64_C(0xef69fd6e84ccf74e),\n    UINT64_C(0x38cf21ac1000ac9a), UINT64_C(0x75ad6a1263bb65d6),\n    UINT64_C(0x055a3702969605b7), UINT64_C(0x48387cbce52dccfb),\n    UINT64_C(0x9f9ea07e71e1972f), UINT64_C(0xd2fcebc0025a5e63),\n    UINT64_C(0xa8bfd8d5da5b356c), UINT64_C(0xe5dd936ba9e0fc20),\n    UINT64_C(0x327b4fa93d2ca7f4), UINT64_C(0x7f1904174e976eb8),\n    UINT64_C(0x0fee5907bbba0ed9), UINT64_C(0x428c12b9c801c795),\n    UINT64_C(0x952ace7b5ccd9c41), UINT64_C(0xd84885c52f76550d),\n    UINT64_C(0x74c4745ab6975c83), UINT64_C(0x39a63fe4c52c95cf),\n    UINT64_C(0xee00e32651e0ce1b), UINT64_C(0xa362a898225b0757),\n    UINT64_C(0xd395f588d7766736), UINT64_C(0x9ef7be36a4cdae7a),\n    UINT64_C(0x495162f43001f5ae), UINT64_C(0x0433294a43ba3ce2),\n    UINT64_C(0x82902ee0accdf837), UINT64_C(0xcff2655edf76317b),\n    UINT64_C(0x1854b99c4bba6aaf), UINT64_C(0x5536f2223801a3e3),\n    UINT64_C(0x25c1af32cd2cc382), UINT64_C(0x68a3e48cbe970ace),\n    UINT64_C(0xbf05384e2a5b511a), UINT64_C(0xf26773f059e09856),\n    UINT64_C(0x5eeb826fc00191d8), UINT64_C(0x1389c9d1b3ba5894),\n    UINT64_C(0xc42f151327760340), UINT64_C(0x894d5ead54cdca0c),\n    UINT64_C(0xf9ba03bda1e0aa6d), UINT64_C(0xb4d84803d25b6321),\n    UINT64_C(0x637e94c1469738f5), UINT64_C(0x2e1cdf7f352cf1b9),\n    UINT64_C(0xfce034bf3776afda), UINT64_C(0xb1827f0144cd6696),\n    UINT64_C(0x6624a3c3d0013d42), UINT64_C(0x2b46e87da3baf40e),\n    UINT64_C(0x5bb1b56d5697946f), UINT64_C(0x16d3fed3252c5d23),\n    UINT64_C(0xc1752211b1e006f7), UINT64_C(0x8c1769afc25bcfbb),\n    UINT64_C(0x209b98305bbac635), UINT64_C(0x6df9d38e28010f79),\n    UINT64_C(0xba5f0f4cbccd54ad), UINT64_C(0xf73d44f2cf769de1),\n    UINT64_C(0x87ca19e23a5bfd80), UINT64_C(0xcaa8525c49e034cc),\n    UINT64_C(0x1d0e8e9edd2c6f18), UINT64_C(0x506cc520ae97a654),\n    UINT64_C(0xd6cfc28a41e06281), UINT64_C(0x9bad8934325babcd),\n    UINT64_C(0x4c0b55f6a697f019), UINT64_C(0x01691e48d52c3955),\n    UINT64_C(0x719e435820015934), UINT64_C(0x3cfc08e653ba9078),\n    UINT64_C(0xeb5ad424c776cbac), UINT64_C(0xa6389f9ab4cd02e0),\n    UINT64_C(0x0ab46e052d2c0b6e), UINT64_C(0x47d625bb5e97c222),\n    UINT64_C(0x9070f979ca5b99f6), UINT64_C(0xdd12b2c7b9e050ba),\n    UINT64_C(0xade5efd74ccd30db), UINT64_C(0xe087a4693f76f997),\n    UINT64_C(0x372178ababbaa243), UINT64_C(0x7a433315d8016b0f),\n    UINT64_C(0xc3a71e801bb8745d), UINT64_C(0x8ec5553e6803bd11),\n    UINT64_C(0x596389fcfccfe6c5), UINT64_C(0x1401c2428f742f89),\n    UINT64_C(0x64f69f527a594fe8), UINT64_C(0x2994d4ec09e286a4),\n    UINT64_C(0xfe32082e9d2edd70), UINT64_C(0xb3504390ee95143c),\n    UINT64_C(0x1fdcb20f77741db2), UINT64_C(0x52bef9b104cfd4fe),\n    UINT64_C(0x8518257390038f2a), UINT64_C(0xc87a6ecde3b84666),\n    UINT64_C(0xb88d33dd16952607), UINT64_C(0xf5ef7863652eef4b),\n    UINT64_C(0x2249a4a1f1e2b49f), UINT64_C(0x6f2bef1f82597dd3),\n    UINT64_C(0xe988e8b56d2eb906), UINT64_C(0xa4eaa30b1e95704a),\n    UINT64_C(0x734c7fc98a592b9e), UINT64_C(0x3e2e3477f9e2e2d2),\n    UINT64_C(0x4ed969670ccf82b3), UINT64_C(0x03bb22d97f744bff),\n    UINT64_C(0xd41dfe1bebb8102b), UINT64_C(0x997fb5a59803d967),\n    UINT64_C(0x35f3443a01e2d0e9), UINT64_C(0x78910f84725919a5),\n    UINT64_C(0xaf37d346e6954271), UINT64_C(0xe25598f8952e8b3d),\n    UINT64_C(0x92a2c5e86003eb5c), UINT64_C(0xdfc08e5613b82210),\n    UINT64_C(0x08665294877479c4), UINT64_C(0x4504192af4cfb088),\n    UINT64_C(0x97f8f2eaf695eeeb), UINT64_C(0xda9ab954852e27a7),\n    UINT64_C(0x0d3c659611e27c73), UINT64_C(0x405e2e286259b53f),\n    UINT64_C(0x30a973389774d55e), UINT64_C(0x7dcb3886e4cf1c12),\n    UINT64_C(0xaa6de444700347c6), UINT64_C(0xe70faffa03b88e8a),\n    UINT64_C(0x4b835e659a598704), UINT64_C(0x06e115dbe9e24e48),\n    UINT64_C(0xd147c9197d2e159c), UINT64_C(0x9c2582a70e95dcd0),\n    UINT64_C(0xecd2dfb7fbb8bcb1), UINT64_C(0xa1b09409880375fd),\n    UINT64_C(0x761648cb1ccf2e29), UINT64_C(0x3b7403756f74e765),\n    UINT64_C(0xbdd704df800323b0), UINT64_C(0xf0b54f61f3b8eafc),\n    UINT64_C(0x271393a36774b128), UINT64_C(0x6a71d81d14cf7864),\n    UINT64_C(0x1a86850de1e21805), UINT64_C(0x57e4ceb39259d149),\n    UINT64_C(0x8042127106958a9d), UINT64_C(0xcd2059cf752e43d1),\n    UINT64_C(0x61aca850eccf4a5f), UINT64_C(0x2ccee3ee9f748313),\n    UINT64_C(0xfb683f2c0bb8d8c7), UINT64_C(0xb60a74927803118b),\n    UINT64_C(0xc6fd29828d2e71ea), UINT64_C(0x8b9f623cfe95b8a6),\n    UINT64_C(0x5c39befe6a59e372), UINT64_C(0x115bf54019e22a3e),\n    UINT64_C(0x6b18c655c1e34131), UINT64_C(0x267a8debb258887d),\n    UINT64_C(0xf1dc51292694d3a9), UINT64_C(0xbcbe1a97552f1ae5),\n    UINT64_C(0xcc494787a0027a84), UINT64_C(0x812b0c39d3b9b3c8),\n    UINT64_C(0x568dd0fb4775e81c), UINT64_C(0x1bef9b4534ce2150),\n    UINT64_C(0xb7636adaad2f28de), UINT64_C(0xfa012164de94e192),\n    UINT64_C(0x2da7fda64a58ba46), UINT64_C(0x60c5b61839e3730a),\n    UINT64_C(0x1032eb08ccce136b), UINT64_C(0x5d50a0b6bf75da27),\n    UINT64_C(0x8af67c742bb981f3), UINT64_C(0xc79437ca580248bf),\n    UINT64_C(0x41373060b7758c6a), UINT64_C(0x0c557bdec4ce4526),\n    UINT64_C(0xdbf3a71c50021ef2), UINT64_C(0x9691eca223b9d7be),\n    UINT64_C(0xe666b1b2d694b7df), UINT64_C(0xab04fa0ca52f7e93),\n    UINT64_C(0x7ca226ce31e32547), UINT64_C(0x31c06d704258ec0b),\n    UINT64_C(0x9d4c9cefdbb9e585), UINT64_C(0xd02ed751a8022cc9),\n    UINT64_C(0x07880b933cce771d), UINT64_C(0x4aea402d4f75be51),\n    UINT64_C(0x3a1d1d3dba58de30), UINT64_C(0x777f5683c9e3177c),\n    UINT64_C(0xa0d98a415d2f4ca8), UINT64_C(0xedbbc1ff2e9485e4),\n    UINT64_C(0x3f472a3f2ccedb87), UINT64_C(0x722561815f7512cb),\n    UINT64_C(0xa583bd43cbb9491f), UINT64_C(0xe8e1f6fdb8028053),\n    UINT64_C(0x9816abed4d2fe032), UINT64_C(0xd574e0533e94297e),\n    UINT64_C(0x02d23c91aa5872aa), UINT64_C(0x4fb0772fd9e3bbe6),\n    UINT64_C(0xe33c86b04002b268), UINT64_C(0xae5ecd0e33b97b24),\n    UINT64_C(0x79f811cca77520f0), UINT64_C(0x349a5a72d4cee9bc),\n    UINT64_C(0x446d076221e389dd), UINT64_C(0x090f4cdc52584091),\n    UINT64_C(0xdea9901ec6941b45), UINT64_C(0x93cbdba0b52fd209),\n    UINT64_C(0x1568dc0a5a5816dc), UINT64_C(0x580a97b429e3df90),\n    UINT64_C(0x8fac4b76bd2f8444), UINT64_C(0xc2ce00c8ce944d08),\n    UINT64_C(0xb2395dd83bb92d69), UINT64_C(0xff5b16664802e425),\n    UINT64_C(0x28fdcaa4dccebff1), UINT64_C(0x659f811aaf7576bd),\n    UINT64_C(0xc913708536947f33), UINT64_C(0x84713b3b452fb67f),\n    UINT64_C(0x53d7e7f9d1e3edab), UINT64_C(0x1eb5ac47a25824e7),\n    UINT64_C(0x6e42f15757754486), UINT64_C(0x2320bae924ce8dca),\n    UINT64_C(0xf486662bb002d61e), UINT64_C(0xb9e42d95c3b91f52)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x1596922b987ef63f),\n    UINT64_C(0x2b2d245730fdec7e), UINT64_C(0x3ebbb67ca8831a41),\n    UINT64_C(0x565a48ae61fbd8fc), UINT64_C(0x43ccda85f9852ec3),\n    UINT64_C(0x7d776cf951063482), UINT64_C(0x68e1fed2c978c2bd),\n    UINT64_C(0xacb4915cc3f7b1f8), UINT64_C(0xb92203775b8947c7),\n    UINT64_C(0x8799b50bf30a5d86), UINT64_C(0x920f27206b74abb9),\n    UINT64_C(0xfaeed9f2a20c6904), UINT64_C(0xef784bd93a729f3b),\n    UINT64_C(0xd1c3fda592f1857a), UINT64_C(0xc4556f8e0a8f7345),\n    UINT64_C(0xcbb18d9228e17d75), UINT64_C(0xde271fb9b09f8b4a),\n    UINT64_C(0xe09ca9c5181c910b), UINT64_C(0xf50a3bee80626734),\n    UINT64_C(0x9debc53c491aa589), UINT64_C(0x887d5717d16453b6),\n    UINT64_C(0xb6c6e16b79e749f7), UINT64_C(0xa3507340e199bfc8),\n    UINT64_C(0x67051cceeb16cc8d), UINT64_C(0x72938ee573683ab2),\n    UINT64_C(0x4c283899dbeb20f3), UINT64_C(0x59beaab24395d6cc),\n    UINT64_C(0x315f54608aed1471), UINT64_C(0x24c9c64b1293e24e),\n    UINT64_C(0x1a727037ba10f80f), UINT64_C(0x0fe4e21c226e0e30),\n    UINT64_C(0x05bbb40ffecce46f), UINT64_C(0x102d262466b21250),\n    UINT64_C(0x2e969058ce310811), UINT64_C(0x3b000273564ffe2e),\n    UINT64_C(0x53e1fca19f373c93), UINT64_C(0x46776e8a0749caac),\n    UINT64_C(0x78ccd8f6afcad0ed), UINT64_C(0x6d5a4add37b426d2),\n    UINT64_C(0xa90f25533d3b5597), UINT64_C(0xbc99b778a545a3a8),\n    UINT64_C(0x822201040dc6b9e9), UINT64_C(0x97b4932f95b84fd6),\n    UINT64_C(0xff556dfd5cc08d6b), UINT64_C(0xeac3ffd6c4be7b54),\n    UINT64_C(0xd47849aa6c3d6115), UINT64_C(0xc1eedb81f443972a),\n    UINT64_C(0xce0a399dd62d991a), UINT64_C(0xdb9cabb64e536f25),\n    UINT64_C(0xe5271dcae6d07564), UINT64_C(0xf0b18fe17eae835b),\n    UINT64_C(0x98507133b7d641e6), UINT64_C(0x8dc6e3182fa8b7d9),\n    UINT64_C(0xb37d5564872bad98), UINT64_C(0xa6ebc74f1f555ba7),\n    UINT64_C(0x62bea8c115da28e2), UINT64_C(0x77283aea8da4dedd),\n    UINT64_C(0x49938c962527c49c), UINT64_C(0x5c051ebdbd5932a3),\n    UINT64_C(0x34e4e06f7421f01e), UINT64_C(0x21727244ec5f0621),\n    UINT64_C(0x1fc9c43844dc1c60), UINT64_C(0x0a5f5613dca2ea5f),\n    UINT64_C(0x0b77681ffd99c8de), UINT64_C(0x1ee1fa3465e73ee1),\n    UINT64_C(0x205a4c48cd6424a0), UINT64_C(0x35ccde63551ad29f),\n    UINT64_C(0x5d2d20b19c621022), UINT64_C(0x48bbb29a041ce61d),\n    UINT64_C(0x760004e6ac9ffc5c), UINT64_C(0x639696cd34e10a63),\n    UINT64_C(0xa7c3f9433e6e7926), UINT64_C(0xb2556b68a6108f19),\n    UINT64_C(0x8ceedd140e939558), UINT64_C(0x99784f3f96ed6367),\n    UINT64_C(0xf199b1ed5f95a1da), UINT64_C(0xe40f23c6c7eb57e5),\n    UINT64_C(0xdab495ba6f684da4), UINT64_C(0xcf220791f716bb9b),\n    UINT64_C(0xc0c6e58dd578b5ab), UINT64_C(0xd55077a64d064394),\n    UINT64_C(0xebebc1dae58559d5), UINT64_C(0xfe7d53f17dfbafea),\n    UINT64_C(0x969cad23b4836d57), UINT64_C(0x830a3f082cfd9b68),\n    UINT64_C(0xbdb18974847e8129), UINT64_C(0xa8271b5f1c007716),\n    UINT64_C(0x6c7274d1168f0453), UINT64_C(0x79e4e6fa8ef1f26c),\n    UINT64_C(0x475f50862672e82d), UINT64_C(0x52c9c2adbe0c1e12),\n    UINT64_C(0x3a283c7f7774dcaf), UINT64_C(0x2fbeae54ef0a2a90),\n    UINT64_C(0x11051828478930d1), UINT64_C(0x04938a03dff7c6ee),\n    UINT64_C(0x0eccdc1003552cb1), UINT64_C(0x1b5a4e3b9b2bda8e),\n    UINT64_C(0x25e1f84733a8c0cf), UINT64_C(0x30776a6cabd636f0),\n    UINT64_C(0x589694be62aef44d), UINT64_C(0x4d000695fad00272),\n    UINT64_C(0x73bbb0e952531833), UINT64_C(0x662d22c2ca2dee0c),\n    UINT64_C(0xa2784d4cc0a29d49), UINT64_C(0xb7eedf6758dc6b76),\n    UINT64_C(0x8955691bf05f7137), UINT64_C(0x9cc3fb3068218708),\n    UINT64_C(0xf42205e2a15945b5), UINT64_C(0xe1b497c93927b38a),\n    UINT64_C(0xdf0f21b591a4a9cb), UINT64_C(0xca99b39e09da5ff4),\n    UINT64_C(0xc57d51822bb451c4), UINT64_C(0xd0ebc3a9b3caa7fb),\n    UINT64_C(0xee5075d51b49bdba), UINT64_C(0xfbc6e7fe83374b85),\n    UINT64_C(0x9327192c4a4f8938), UINT64_C(0x86b18b07d2317f07),\n    UINT64_C(0xb80a3d7b7ab26546), UINT64_C(0xad9caf50e2cc9379),\n    UINT64_C(0x69c9c0dee843e03c), UINT64_C(0x7c5f52f5703d1603),\n    UINT64_C(0x42e4e489d8be0c42), UINT64_C(0x577276a240c0fa7d),\n    UINT64_C(0x3f93887089b838c0), UINT64_C(0x2a051a5b11c6ceff),\n    UINT64_C(0x14beac27b945d4be), UINT64_C(0x01283e0c213b2281),\n    UINT64_C(0x16eed03ffb3391bc), UINT64_C(0x03784214634d6783),\n    UINT64_C(0x3dc3f468cbce7dc2), UINT64_C(0x2855664353b08bfd),\n    UINT64_C(0x40b498919ac84940), UINT64_C(0x55220aba02b6bf7f),\n    UINT64_C(0x6b99bcc6aa35a53e), UINT64_C(0x7e0f2eed324b5301),\n    UINT64_C(0xba5a416338c42044), UINT64_C(0xafccd348a0bad67b),\n    UINT64_C(0x917765340839cc3a), UINT64_C(0x84e1f71f90473a05),\n    UINT64_C(0xec0009cd593ff8b8), UINT64_C(0xf9969be6c1410e87),\n    UINT64_C(0xc72d2d9a69c214c6), UINT64_C(0xd2bbbfb1f1bce2f9),\n    UINT64_C(0xdd5f5dadd3d2ecc9), UINT64_C(0xc8c9cf864bac1af6),\n    UINT64_C(0xf67279fae32f00b7), UINT64_C(0xe3e4ebd17b51f688),\n    UINT64_C(0x8b051503b2293435), UINT64_C(0x9e9387282a57c20a),\n    UINT64_C(0xa028315482d4d84b), UINT64_C(0xb5bea37f1aaa2e74),\n    UINT64_C(0x71ebccf110255d31), UINT64_C(0x647d5eda885bab0e),\n    UINT64_C(0x5ac6e8a620d8b14f), UINT64_C(0x4f507a8db8a64770),\n    UINT64_C(0x27b1845f71de85cd), UINT64_C(0x32271674e9a073f2),\n    UINT64_C(0x0c9ca008412369b3), UINT64_C(0x190a3223d95d9f8c),\n    UINT64_C(0x1355643005ff75d3), UINT64_C(0x06c3f61b9d8183ec),\n    UINT64_C(0x38784067350299ad), UINT64_C(0x2deed24cad7c6f92),\n    UINT64_C(0x450f2c9e6404ad2f), UINT64_C(0x5099beb5fc7a5b10),\n    UINT64_C(0x6e2208c954f94151), UINT64_C(0x7bb49ae2cc87b76e),\n    UINT64_C(0xbfe1f56cc608c42b), UINT64_C(0xaa7767475e763214),\n    UINT64_C(0x94ccd13bf6f52855), UINT64_C(0x815a43106e8bde6a),\n    UINT64_C(0xe9bbbdc2a7f31cd7), UINT64_C(0xfc2d2fe93f8deae8),\n    UINT64_C(0xc2969995970ef0a9), UINT64_C(0xd7000bbe0f700696),\n    UINT64_C(0xd8e4e9a22d1e08a6), UINT64_C(0xcd727b89b560fe99),\n    UINT64_C(0xf3c9cdf51de3e4d8), UINT64_C(0xe65f5fde859d12e7),\n    UINT64_C(0x8ebea10c4ce5d05a), UINT64_C(0x9b283327d49b2665),\n    UINT64_C(0xa593855b7c183c24), UINT64_C(0xb0051770e466ca1b),\n    UINT64_C(0x745078feeee9b95e), UINT64_C(0x61c6ead576974f61),\n    UINT64_C(0x5f7d5ca9de145520), UINT64_C(0x4aebce82466aa31f),\n    UINT64_C(0x220a30508f1261a2), UINT64_C(0x379ca27b176c979d),\n    UINT64_C(0x09271407bfef8ddc), UINT64_C(0x1cb1862c27917be3),\n    UINT64_C(0x1d99b82006aa5962), UINT64_C(0x080f2a0b9ed4af5d),\n    UINT64_C(0x36b49c773657b51c), UINT64_C(0x23220e5cae294323),\n    UINT64_C(0x4bc3f08e6751819e), UINT64_C(0x5e5562a5ff2f77a1),\n    UINT64_C(0x60eed4d957ac6de0), UINT64_C(0x757846f2cfd29bdf),\n    UINT64_C(0xb12d297cc55de89a), UINT64_C(0xa4bbbb575d231ea5),\n    UINT64_C(0x9a000d2bf5a004e4), UINT64_C(0x8f969f006ddef2db),\n    UINT64_C(0xe77761d2a4a63066), UINT64_C(0xf2e1f3f93cd8c659),\n    UINT64_C(0xcc5a4585945bdc18), UINT64_C(0xd9ccd7ae0c252a27),\n    UINT64_C(0xd62835b22e4b2417), UINT64_C(0xc3bea799b635d228),\n    UINT64_C(0xfd0511e51eb6c869), UINT64_C(0xe89383ce86c83e56),\n    UINT64_C(0x80727d1c4fb0fceb), UINT64_C(0x95e4ef37d7ce0ad4),\n    UINT64_C(0xab5f594b7f4d1095), UINT64_C(0xbec9cb60e733e6aa),\n    UINT64_C(0x7a9ca4eeedbc95ef), UINT64_C(0x6f0a36c575c263d0),\n    UINT64_C(0x51b180b9dd417991), UINT64_C(0x44271292453f8fae),\n    UINT64_C(0x2cc6ec408c474d13), UINT64_C(0x39507e6b1439bb2c),\n    UINT64_C(0x07ebc817bcbaa16d), UINT64_C(0x127d5a3c24c45752),\n    UINT64_C(0x18220c2ff866bd0d), UINT64_C(0x0db49e0460184b32),\n    UINT64_C(0x330f2878c89b5173), UINT64_C(0x2699ba5350e5a74c),\n    UINT64_C(0x4e784481999d65f1), UINT64_C(0x5beed6aa01e393ce),\n    UINT64_C(0x655560d6a960898f), UINT64_C(0x70c3f2fd311e7fb0),\n    UINT64_C(0xb4969d733b910cf5), UINT64_C(0xa1000f58a3effaca),\n    UINT64_C(0x9fbbb9240b6ce08b), UINT64_C(0x8a2d2b0f931216b4),\n    UINT64_C(0xe2ccd5dd5a6ad409), UINT64_C(0xf75a47f6c2142236),\n    UINT64_C(0xc9e1f18a6a973877), UINT64_C(0xdc7763a1f2e9ce48),\n    UINT64_C(0xd39381bdd087c078), UINT64_C(0xc605139648f93647),\n    UINT64_C(0xf8bea5eae07a2c06), UINT64_C(0xed2837c17804da39),\n    UINT64_C(0x85c9c913b17c1884), UINT64_C(0x905f5b382902eebb),\n    UINT64_C(0xaee4ed448181f4fa), UINT64_C(0xbb727f6f19ff02c5),\n    UINT64_C(0x7f2710e113707180), UINT64_C(0x6ab182ca8b0e87bf),\n    UINT64_C(0x540a34b6238d9dfe), UINT64_C(0x419ca69dbbf36bc1),\n    UINT64_C(0x297d584f728ba97c), UINT64_C(0x3cebca64eaf55f43),\n    UINT64_C(0x02507c1842764502), UINT64_C(0x17c6ee33da08b33d)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x2ddda07ff6672378),\n    UINT64_C(0x5bbb40ffecce46f0), UINT64_C(0x7666e0801aa96588),\n    UINT64_C(0xb77681ffd99c8de0), UINT64_C(0x9aab21802ffbae98),\n    UINT64_C(0xeccdc1003552cb10), UINT64_C(0xc110617fc335e868),\n    UINT64_C(0xfc35acd41c370545), UINT64_C(0xd1e80cabea50263d),\n    UINT64_C(0xa78eec2bf0f943b5), UINT64_C(0x8a534c54069e60cd),\n    UINT64_C(0x4b432d2bc5ab88a5), UINT64_C(0x669e8d5433ccabdd),\n    UINT64_C(0x10f86dd42965ce55), UINT64_C(0x3d25cdabdf02ed2d),\n    UINT64_C(0x6ab3f6839760140f), UINT64_C(0x476e56fc61073777),\n    UINT64_C(0x3108b67c7bae52ff), UINT64_C(0x1cd516038dc97187),\n    UINT64_C(0xddc5777c4efc99ef), UINT64_C(0xf018d703b89bba97),\n    UINT64_C(0x867e3783a232df1f), UINT64_C(0xaba397fc5455fc67),\n    UINT64_C(0x96865a578b57114a), UINT64_C(0xbb5bfa287d303232),\n    UINT64_C(0xcd3d1aa8679957ba), UINT64_C(0xe0e0bad791fe74c2),\n    UINT64_C(0x21f0dba852cb9caa), UINT64_C(0x0c2d7bd7a4acbfd2),\n    UINT64_C(0x7a4b9b57be05da5a), UINT64_C(0x57963b284862f922),\n    UINT64_C(0xd567ed072ec0281e), UINT64_C(0xf8ba4d78d8a70b66),\n    UINT64_C(0x8edcadf8c20e6eee), UINT64_C(0xa3010d8734694d96),\n    UINT64_C(0x62116cf8f75ca5fe), UINT64_C(0x4fcccc87013b8686),\n    UINT64_C(0x39aa2c071b92e30e), UINT64_C(0x14778c78edf5c076),\n    UINT64_C(0x295241d332f72d5b), UINT64_C(0x048fe1acc4900e23),\n    UINT64_C(0x72e9012cde396bab), UINT64_C(0x5f34a153285e48d3),\n    UINT64_C(0x9e24c02ceb6ba0bb), UINT64_C(0xb3f960531d0c83c3),\n    UINT64_C(0xc59f80d307a5e64b), UINT64_C(0xe84220acf1c2c533),\n    UINT64_C(0xbfd41b84b9a03c11), UINT64_C(0x9209bbfb4fc71f69),\n    UINT64_C(0xe46f5b7b556e7ae1), UINT64_C(0xc9b2fb04a3095999),\n    UINT64_C(0x08a29a7b603cb1f1), UINT64_C(0x257f3a04965b9289),\n    UINT64_C(0x5319da848cf2f701), UINT64_C(0x7ec47afb7a95d479),\n    UINT64_C(0x43e1b750a5973954), UINT64_C(0x6e3c172f53f01a2c),\n    UINT64_C(0x185af7af49597fa4), UINT64_C(0x358757d0bf3e5cdc),\n    UINT64_C(0xf49736af7c0bb4b4), UINT64_C(0xd94a96d08a6c97cc),\n    UINT64_C(0xaf2c765090c5f244), UINT64_C(0x82f1d62f66a2d13c),\n    UINT64_C(0x38177525f28e4eb9), UINT64_C(0x15cad55a04e96dc1),\n    UINT64_C(0x63ac35da1e400849), UINT64_C(0x4e7195a5e8272b31),\n    UINT64_C(0x8f61f4da2b12c359), UINT64_C(0xa2bc54a5dd75e021),\n    UINT64_C(0xd4dab425c7dc85a9), UINT64_C(0xf907145a31bba6d1),\n    UINT64_C(0xc422d9f1eeb94bfc), UINT64_C(0xe9ff798e18de6884),\n    UINT64_C(0x9f99990e02770d0c), UINT64_C(0xb2443971f4102e74),\n    UINT64_C(0x7354580e3725c61c), UINT64_C(0x5e89f871c142e564),\n    UINT64_C(0x28ef18f1dbeb80ec), UINT64_C(0x0532b88e2d8ca394),\n    UINT64_C(0x52a483a665ee5ab6), UINT64_C(0x7f7923d9938979ce),\n    UINT64_C(0x091fc35989201c46), UINT64_C(0x24c263267f473f3e),\n    UINT64_C(0xe5d20259bc72d756), UINT64_C(0xc80fa2264a15f42e),\n    UINT64_C(0xbe6942a650bc91a6), UINT64_C(0x93b4e2d9a6dbb2de),\n    UINT64_C(0xae912f7279d95ff3), UINT64_C(0x834c8f0d8fbe7c8b),\n    UINT64_C(0xf52a6f8d95171903), UINT64_C(0xd8f7cff263703a7b),\n    UINT64_C(0x19e7ae8da045d213), UINT64_C(0x343a0ef25622f16b),\n    UINT64_C(0x425cee724c8b94e3), UINT64_C(0x6f814e0dbaecb79b),\n    UINT64_C(0xed709822dc4e66a7), UINT64_C(0xc0ad385d2a2945df),\n    UINT64_C(0xb6cbd8dd30802057), UINT64_C(0x9b1678a2c6e7032f),\n    UINT64_C(0x5a0619dd05d2eb47), UINT64_C(0x77dbb9a2f3b5c83f),\n    UINT64_C(0x01bd5922e91cadb7), UINT64_C(0x2c60f95d1f7b8ecf),\n    UINT64_C(0x114534f6c07963e2), UINT64_C(0x3c989489361e409a),\n    UINT64_C(0x4afe74092cb72512), UINT64_C(0x6723d476dad0066a),\n    UINT64_C(0xa633b50919e5ee02), UINT64_C(0x8bee1576ef82cd7a),\n    UINT64_C(0xfd88f5f6f52ba8f2), UINT64_C(0xd0555589034c8b8a),\n    UINT64_C(0x87c36ea14b2e72a8), UINT64_C(0xaa1ecedebd4951d0),\n    UINT64_C(0xdc782e5ea7e03458), UINT64_C(0xf1a58e2151871720),\n    UINT64_C(0x30b5ef5e92b2ff48), UINT64_C(0x1d684f2164d5dc30),\n    UINT64_C(0x6b0eafa17e7cb9b8), UINT64_C(0x46d30fde881b9ac0),\n    UINT64_C(0x7bf6c275571977ed), UINT64_C(0x562b620aa17e5495),\n    UINT64_C(0x204d828abbd7311d), UINT64_C(0x0d9022f54db01265),\n    UINT64_C(0xcc80438a8e85fa0d), UINT64_C(0xe15de3f578e2d975),\n    UINT64_C(0x973b0375624bbcfd), UINT64_C(0xbae6a30a942c9f85),\n    UINT64_C(0x702eea4be51c9d72), UINT64_C(0x5df34a34137bbe0a),\n    UINT64_C(0x2b95aab409d2db82), UINT64_C(0x06480acbffb5f8fa),\n    UINT64_C(0xc7586bb43c801092), UINT64_C(0xea85cbcbcae733ea),\n    UINT64_C(0x9ce32b4bd04e5662), UINT64_C(0xb13e8b342629751a),\n    UINT64_C(0x8c1b469ff92b9837), UINT64_C(0xa1c6e6e00f4cbb4f),\n    UINT64_C(0xd7a0066015e5dec7), UINT64_C(0xfa7da61fe382fdbf),\n    UINT64_C(0x3b6dc76020b715d7), UINT64_C(0x16b0671fd6d036af),\n    UINT64_C(0x60d6879fcc795327), UINT64_C(0x4d0b27e03a1e705f),\n    UINT64_C(0x1a9d1cc8727c897d), UINT64_C(0x3740bcb7841baa05),\n    UINT64_C(0x41265c379eb2cf8d), UINT64_C(0x6cfbfc4868d5ecf5),\n    UINT64_C(0xadeb9d37abe0049d), UINT64_C(0x80363d485d8727e5),\n    UINT64_C(0xf650ddc8472e426d), UINT64_C(0xdb8d7db7b1496115),\n    UINT64_C(0xe6a8b01c6e4b8c38), UINT64_C(0xcb751063982caf40),\n    UINT64_C(0xbd13f0e38285cac8), UINT64_C(0x90ce509c74e2e9b0),\n    UINT64_C(0x51de31e3b7d701d8), UINT64_C(0x7c03919c41b022a0),\n    UINT64_C(0x0a65711c5b194728), UINT64_C(0x27b8d163ad7e6450),\n    UINT64_C(0xa549074ccbdcb56c), UINT64_C(0x8894a7333dbb9614),\n    UINT64_C(0xfef247b32712f39c), UINT64_C(0xd32fe7ccd175d0e4),\n    UINT64_C(0x123f86b31240388c), UINT64_C(0x3fe226cce4271bf4),\n    UINT64_C(0x4984c64cfe8e7e7c), UINT64_C(0x6459663308e95d04),\n    UINT64_C(0x597cab98d7ebb029), UINT64_C(0x74a10be7218c9351),\n    UINT64_C(0x02c7eb673b25f6d9), UINT64_C(0x2f1a4b18cd42d5a1),\n    UINT64_C(0xee0a2a670e773dc9), UINT64_C(0xc3d78a18f8101eb1),\n    UINT64_C(0xb5b16a98e2b97b39), UINT64_C(0x986ccae714de5841),\n    UINT64_C(0xcffaf1cf5cbca163), UINT64_C(0xe22751b0aadb821b),\n    UINT64_C(0x9441b130b072e793), UINT64_C(0xb99c114f4615c4eb),\n    UINT64_C(0x788c703085202c83), UINT64_C(0x5551d04f73470ffb),\n    UINT64_C(0x233730cf69ee6a73), UINT64_C(0x0eea90b09f89490b),\n    UINT64_C(0x33cf5d1b408ba426), UINT64_C(0x1e12fd64b6ec875e),\n    UINT64_C(0x68741de4ac45e2d6), UINT64_C(0x45a9bd9b5a22c1ae),\n    UINT64_C(0x84b9dce4991729c6), UINT64_C(0xa9647c9b6f700abe),\n    UINT64_C(0xdf029c1b75d96f36), UINT64_C(0xf2df3c6483be4c4e),\n    UINT64_C(0x48399f6e1792d3cb), UINT64_C(0x65e43f11e1f5f0b3),\n    UINT64_C(0x1382df91fb5c953b), UINT64_C(0x3e5f7fee0d3bb643),\n    UINT64_C(0xff4f1e91ce0e5e2b), UINT64_C(0xd292beee38697d53),\n    UINT64_C(0xa4f45e6e22c018db), UINT64_C(0x8929fe11d4a73ba3),\n    UINT64_C(0xb40c33ba0ba5d68e), UINT64_C(0x99d193c5fdc2f5f6),\n    UINT64_C(0xefb77345e76b907e), UINT64_C(0xc26ad33a110cb306),\n    UINT64_C(0x037ab245d2395b6e), UINT64_C(0x2ea7123a245e7816),\n    UINT64_C(0x58c1f2ba3ef71d9e), UINT64_C(0x751c52c5c8903ee6),\n    UINT64_C(0x228a69ed80f2c7c4), UINT64_C(0x0f57c9927695e4bc),\n    UINT64_C(0x793129126c3c8134), UINT64_C(0x54ec896d9a5ba24c),\n    UINT64_C(0x95fce812596e4a24), UINT64_C(0xb821486daf09695c),\n    UINT64_C(0xce47a8edb5a00cd4), UINT64_C(0xe39a089243c72fac),\n    UINT64_C(0xdebfc5399cc5c281), UINT64_C(0xf36265466aa2e1f9),\n    UINT64_C(0x850485c6700b8471), UINT64_C(0xa8d925b9866ca709),\n    UINT64_C(0x69c944c645594f61), UINT64_C(0x4414e4b9b33e6c19),\n    UINT64_C(0x32720439a9970991), UINT64_C(0x1fafa4465ff02ae9),\n    UINT64_C(0x9d5e72693952fbd5), UINT64_C(0xb083d216cf35d8ad),\n    UINT64_C(0xc6e53296d59cbd25), UINT64_C(0xeb3892e923fb9e5d),\n    UINT64_C(0x2a28f396e0ce7635), UINT64_C(0x07f553e916a9554d),\n    UINT64_C(0x7193b3690c0030c5), UINT64_C(0x5c4e1316fa6713bd),\n    UINT64_C(0x616bdebd2565fe90), UINT64_C(0x4cb67ec2d302dde8),\n    UINT64_C(0x3ad09e42c9abb860), UINT64_C(0x170d3e3d3fcc9b18),\n    UINT64_C(0xd61d5f42fcf97370), UINT64_C(0xfbc0ff3d0a9e5008),\n    UINT64_C(0x8da61fbd10373580), UINT64_C(0xa07bbfc2e65016f8),\n    UINT64_C(0xf7ed84eaae32efda), UINT64_C(0xda3024955855cca2),\n    UINT64_C(0xac56c41542fca92a), UINT64_C(0x818b646ab49b8a52),\n    UINT64_C(0x409b051577ae623a), UINT64_C(0x6d46a56a81c94142),\n    UINT64_C(0x1b2045ea9b6024ca), UINT64_C(0x36fde5956d0707b2),\n    UINT64_C(0x0bd8283eb205ea9f), UINT64_C(0x260588414462c9e7),\n    UINT64_C(0x506368c15ecbac6f), UINT64_C(0x7dbec8bea8ac8f17),\n    UINT64_C(0xbcaea9c16b99677f), UINT64_C(0x917309be9dfe4407),\n    UINT64_C(0xe715e93e8757218f), UINT64_C(0xcac84941713002f7)\n  }\n};\n\nuint64_t crc64_slow(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  uint64_t cs = UINT64_C(0xffffffffffffffff);\n\n  while (nbytes--) {\n    uint32_t idx = ((uint32_t) (cs ^ *data++)) & 0xff;\n    cs = crc64_table[3][idx] ^ (cs >> 8);\n  }\n\n  return cs ^ UINT64_C(0xffffffffffffffff);\n}\n\n\n\n__host__ __device__\nstatic inline uint32_t crc64_load_le32_(const uint32_t *p) {\n  uint32_t w = *p;\n  return  ((((w) & 0xff000000) >> 24)\n         | (((w) & 0x00ff0000) >>  8)\n         | (((w) & 0x0000ff00) <<  8)\n         | (((w) & 0x000000ff) << 24));\n}\n\n\n\n\n\nuint64_t crc64(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  const unsigned char *end = data + nbytes;\n  uint64_t cs[5] = { UINT64_C(0xffffffffffffffff), 0, 0, 0, 0 };\n\n  \n\n  \n\n  \n\n  \n\n  while (data < end && ((((size_t) data) & 3) || (end - data < 20))) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  if (data == end)\n    return cs[0] ^ UINT64_C(0xffffffffffffffff);\n\n  const uint32_t one = 1;\n  bool big_endian = !(*((char *)(&one)));\n\n  uint64_t cry = 0;\n  uint32_t in[5];\n\n  if (!big_endian) {\n    for (unsigned i = 0; i < 5; ++i)\n      in[i] = ((const uint32_t*) data)[i];\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = ((const uint32_t*) data)[0];\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = ((const uint32_t*) data)[1];\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = ((const uint32_t*) data)[2];\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = ((const uint32_t*) data)[3];\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = ((const uint32_t*) data)[4];\n    }\n  } else {\n    for (unsigned i = 0; i < 5; ++i) {\n      in[i] = crc64_load_le32_(&((const uint32_t*) data)[i]);\n    }\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = crc64_load_le32_(&((const uint32_t*) data)[0]);\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = crc64_load_le32_(&((const uint32_t*) data)[1]);\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = crc64_load_le32_(&((const uint32_t*) data)[2]);\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = crc64_load_le32_(&((const uint32_t*) data)[3]);\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = crc64_load_le32_(&((const uint32_t*) data)[4]);\n    }\n  }\n\n  cs[0] ^= cry;\n\n  for (unsigned i = 0; i < 5; ++i) {\n    if (i > 0)\n      cs[0] ^= cs[i];\n    in[i] ^= (uint32_t) cs[0];\n    cs[0] = cs[0] >> 32;\n\n    for (unsigned b = 0; b < 3; ++b) {\n      cs[0] ^= crc64_table[b][in[i] & 0xff];\n      in[i] >>= 8;\n    }\n\n    cs[0] ^= crc64_table[3][in[i] & 0xff];\n  }\n\n  while (data < end) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  return cs[0] ^ UINT64_C(0xffffffffffffffff);\n}\n\n__device__\nuint64_t crc64_device(const unsigned char *input, size_t nbytes, \n\t\tconst uint64_t *d_crc64_table, \n\t\tconst uint64_t *d_crc64_interleaved_table) {\n  const unsigned char *data = input;\n  const unsigned char *end = data + nbytes;\n  uint64_t cs[5] = { UINT64_C(0xffffffffffffffff), 0, 0, 0, 0 };\n\n  \n\n  \n\n  \n\n  \n\n  while (data < end && ((((size_t) data) & 3) || (end - data < 20))) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = d_crc64_table[3*256+idx] ^ (cs[0] >> 8);\n  }\n\n  if (data == end)\n    return cs[0] ^ UINT64_C(0xffffffffffffffff);\n\n  const uint32_t one = 1;\n  bool big_endian = !(*((char *)(&one)));\n\n  uint64_t cry = 0;\n  uint32_t in[5];\n\n  if (!big_endian) {\n    for (unsigned i = 0; i < 5; ++i)\n      in[i] = ((const uint32_t*) data)[i];\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = d_crc64_interleaved_table[in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = d_crc64_interleaved_table[in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = d_crc64_interleaved_table[in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = d_crc64_interleaved_table[in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = d_crc64_interleaved_table[in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= d_crc64_interleaved_table[b*256+(in[0] & 0xff)];\n        in[0] >>= 8;\n\n        cs[1] ^= d_crc64_interleaved_table[b*256+(in[1] & 0xff)];\n        in[1] >>= 8;\n\n        cs[2] ^= d_crc64_interleaved_table[b*256+(in[2] & 0xff)];\n        in[2] >>= 8;\n\n        cs[3] ^= d_crc64_interleaved_table[b*256+(in[3] & 0xff)];\n        in[3] >>= 8;\n\n        cs[4] ^= d_crc64_interleaved_table[b*256+(in[4] & 0xff)];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= d_crc64_interleaved_table[3*256+(in[0] & 0xff)];\n      in[0] = ((const uint32_t*) data)[0];\n\n      cs[1] ^= d_crc64_interleaved_table[3*256+(in[1] & 0xff)];\n      in[1] = ((const uint32_t*) data)[1];\n\n      cs[2] ^= d_crc64_interleaved_table[3*256+(in[2] & 0xff)];\n      in[2] = ((const uint32_t*) data)[2];\n\n      cs[3] ^= d_crc64_interleaved_table[3*256+(in[3] & 0xff)];\n      in[3] = ((const uint32_t*) data)[3];\n\n      cs[4] ^= d_crc64_interleaved_table[3*256+(in[4] & 0xff)];\n      in[4] = ((const uint32_t*) data)[4];\n    }\n  } else {\n    for (unsigned i = 0; i < 5; ++i) {\n      in[i] = crc64_load_le32_(&((const uint32_t*) data)[i]);\n    }\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = d_crc64_interleaved_table[in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = d_crc64_interleaved_table[in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = d_crc64_interleaved_table[in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = d_crc64_interleaved_table[in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = d_crc64_interleaved_table[in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= d_crc64_interleaved_table[b*256+(in[0] & 0xff)];\n        in[0] >>= 8;\n\n        cs[1] ^= d_crc64_interleaved_table[b*256+(in[1] & 0xff)];\n        in[1] >>= 8;\n\n        cs[2] ^= d_crc64_interleaved_table[b*256+(in[2] & 0xff)];\n        in[2] >>= 8;\n\n        cs[3] ^= d_crc64_interleaved_table[b*256+(in[3] & 0xff)];\n        in[3] >>= 8;\n\n        cs[4] ^= d_crc64_interleaved_table[b*256+(in[4] & 0xff)];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= d_crc64_interleaved_table[3*256+(in[0] & 0xff)];\n      in[0] = crc64_load_le32_(&((const uint32_t*) data)[0]);\n\n      cs[1] ^= d_crc64_interleaved_table[3*256+(in[1] & 0xff)];\n      in[1] = crc64_load_le32_(&((const uint32_t*) data)[1]);\n\n      cs[2] ^= d_crc64_interleaved_table[3*256+(in[2] & 0xff)];\n      in[2] = crc64_load_le32_(&((const uint32_t*) data)[2]);\n\n      cs[3] ^= d_crc64_interleaved_table[3*256+(in[3] & 0xff)];\n      in[3] = crc64_load_le32_(&((const uint32_t*) data)[3]);\n\n      cs[4] ^= d_crc64_interleaved_table[3*256+(in[4] & 0xff)];\n      in[4] = crc64_load_le32_(&((const uint32_t*) data)[4]);\n    }\n  }\n\n  cs[0] ^= cry;\n\n  for (unsigned i = 0; i < 5; ++i) {\n    if (i > 0)\n      cs[0] ^= cs[i];\n    in[i] ^= (uint32_t) cs[0];\n    cs[0] = cs[0] >> 32;\n\n    for (unsigned b = 0; b < 3; ++b) {\n      cs[0] ^= d_crc64_table[b*256+(in[i] & 0xff)];\n      in[i] >>= 8;\n    }\n\n    cs[0] ^= d_crc64_table[3*256+(in[i] & 0xff)];\n  }\n\n  while (data < end) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = d_crc64_table[3*256+idx] ^ (cs[0] >> 8);\n  }\n\n  return cs[0] ^ UINT64_C(0xffffffffffffffff);\n}\n\n\n\n\n\nvoid crc64_invert(uint64_t cs, void *check_bytes) {\n  unsigned char *bytes = (unsigned char *) check_bytes;\n  cs ^= UINT64_C(0xffffffffffffffff);\n\n  \n\n  \n\n  bytes[7] = (cs >> 56) & 0xff;\n  bytes[6] = (cs >> 48) & 0xff;\n  bytes[5] = (cs >> 40) & 0xff;\n  bytes[4] = (cs >> 32) & 0xff;\n  bytes[3] = (cs >> 24) & 0xff;\n  bytes[2] = (cs >> 16) & 0xff;\n  bytes[1] = (cs >>  8) & 0xff;\n  bytes[0] =  cs        & 0xff;\n}\n\nstatic const uint64_t crc64_x_pow_2n[64] = {\n  UINT64_C(0x4000000000000000), UINT64_C(0x2000000000000000),\n  UINT64_C(0x0800000000000000), UINT64_C(0x0080000000000000),\n  UINT64_C(0x0000800000000000), UINT64_C(0x0000000080000000),\n  UINT64_C(0xc96c5795d7870f42), UINT64_C(0x6d5f4ad7e3c3afa0),\n  UINT64_C(0xd49f7e445077d8ea), UINT64_C(0x040fb02a53c216fa),\n  UINT64_C(0x6bec35957b9ef3a0), UINT64_C(0xb0e3bb0658964afe),\n  UINT64_C(0x218578c7a2dff638), UINT64_C(0x6dbb920f24dd5cf2),\n  UINT64_C(0x7a140cfcdb4d5eb5), UINT64_C(0x41b3705ecbc4057b),\n  UINT64_C(0xd46ab656accac1ea), UINT64_C(0x329beda6fc34fb73),\n  UINT64_C(0x51a4fcd4350b9797), UINT64_C(0x314fa85637efae9d),\n  UINT64_C(0xacf27e9a1518d512), UINT64_C(0xffe2a3388a4d8ce7),\n  UINT64_C(0x48b9697e60cc2e4e), UINT64_C(0xada73cb78dd62460),\n  UINT64_C(0x3ea5454d8ce5c1bb), UINT64_C(0x5e84e3a6c70feaf1),\n  UINT64_C(0x90fd49b66cbd81d1), UINT64_C(0xe2943e0c1db254e8),\n  UINT64_C(0xecfa6adeca8834a1), UINT64_C(0xf513e212593ee321),\n  UINT64_C(0xf36ae57331040916), UINT64_C(0x63fbd333b87b6717),\n  UINT64_C(0xbd60f8e152f50b8b), UINT64_C(0xa5ce4a8299c1567d),\n  UINT64_C(0x0bd445f0cbdb55ee), UINT64_C(0xfdd6824e20134285),\n  UINT64_C(0xcead8b6ebda2227a), UINT64_C(0xe44b17e4f5d4fb5c),\n  UINT64_C(0x9b29c81ad01ca7c5), UINT64_C(0x1b4366e40fea4055),\n  UINT64_C(0x27bca1551aae167b), UINT64_C(0xaa57bcd1b39a5690),\n  UINT64_C(0xd7fce83fa1234db9), UINT64_C(0xcce4986efea3ff8e),\n  UINT64_C(0x3602a4d9e65341f1), UINT64_C(0x722b1da2df516145),\n  UINT64_C(0xecfc3ddd3a08da83), UINT64_C(0x0fb96dcca83507e6),\n  UINT64_C(0x125f2fe78d70f080), UINT64_C(0x842f50b7651aa516),\n  UINT64_C(0x09bc34188cd9836f), UINT64_C(0xf43666c84196d909),\n  UINT64_C(0xb56feb30c0df6ccb), UINT64_C(0xaa66e04ce7f30958),\n  UINT64_C(0xb7b1187e9af29547), UINT64_C(0x113255f8476495de),\n  UINT64_C(0x8fb19f783095d77e), UINT64_C(0xaec4aacc7c82b133),\n  UINT64_C(0xf64e6d09218428cf), UINT64_C(0x036a72ea5ac258a0),\n  UINT64_C(0x5235ef12eb7aaa6a), UINT64_C(0x2fed7b1685657853),\n  UINT64_C(0x8ef8951d46606fb5), UINT64_C(0x9d58c1090f034d14)\n};\n\n\n\n\n\nstatic inline uint64_t crc64_multiply_(uint64_t a, uint64_t b) {\n  if ((a ^ (a-1)) < (b ^ (b-1))) {\n    uint64_t t = a;\n    a = b;\n    b = t;\n  }\n\n  if (a == 0)\n    return 0;\n\n  uint64_t r = 0, h = UINT64_C(1) << 63;\n  for (; a != 0; a <<= 1) {\n    if (a & h) {\n      r ^= b;\n      a ^= h;\n    }\n\n    b = (b >> 1) ^ ((b & 1) ? crc64_poly : 0);\n  }\n\n  return r;\n}\n\n\n\nstatic inline uint64_t crc64_x_pow_n_(uint64_t n) {\n  uint64_t r = UINT64_C(1) << 63;\n  for (size_t i = 0; n != 0; n >>= 1, ++i) {\n    if (n & 1)\n      r = crc64_multiply_(r, crc64_x_pow_2n[i]);\n  }\n\n  return r;\n}\n\nuint64_t crc64_combine(uint64_t cs1, uint64_t cs2, size_t nbytes2) {\n  \n\n  \n\n  return cs2 ^ crc64_multiply_(cs1, crc64_x_pow_n_(8*nbytes2));\n}\n\nstatic const size_t crc64_min_thread_bytes = 1024;\n\n__global__ void \ncrc64_kernel(\n  size_t *__restrict__ d_thread_sz, \n  uint64_t *__restrict__ d_thread_cs, \n  const unsigned char*__restrict__  d_data, \n  const uint64_t *__restrict__ d_crc64_table, \n  const uint64_t *__restrict__ d_crc64_interleaved_table, \n  size_t nbytes, int nthreads) \n{\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  size_t bpt = nbytes/nthreads;\n  const unsigned char *start = d_data + bpt*tid;\n  const unsigned char *end;\n  if (tid != nthreads - 1)\n    end = start + bpt;\n  else\n    end = d_data + nbytes;\n    \n  size_t sz = end - start;\n  d_thread_sz[tid] = sz;\n  d_thread_cs[tid] = crc64_device(start, sz, d_crc64_table, d_crc64_interleaved_table);\n}\n\nuint64_t crc64_parallel(const void *input, size_t nbytes) {\n\n  if (nbytes > 2*crc64_min_thread_bytes) {\n    int nthreads = 96*8*32; \n\n    if (nbytes < nthreads*crc64_min_thread_bytes)\n      nthreads = nbytes/crc64_min_thread_bytes;\n\n    uint64_t thread_cs[nthreads];\n    size_t thread_sz[nthreads];\n\n    const unsigned char *data = (const unsigned char*) input;\n\n    uint64_t *d_thread_cs;\n    uint64_t *d_crc64_table;\n    uint64_t *d_crc64_interleaved_table;\n    size_t *d_thread_sz;\n    unsigned char *d_data;\n\n    cudaMalloc((void**)&d_thread_sz, nthreads * sizeof(size_t));\n    cudaMalloc((void**)&d_thread_cs, nthreads * sizeof(uint64_t));\n    cudaMalloc((void**)&d_data, nbytes);\n    cudaMalloc((void**)&d_crc64_table, 4*256*sizeof(uint64_t));\n    cudaMalloc((void**)&d_crc64_interleaved_table, 4*256*sizeof(uint64_t));\n\n    cudaMemcpy(d_data, data, nbytes , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_crc64_table, crc64_table, 4*256*sizeof(uint64_t) , cudaMemcpyHostToDevice);\n    cudaMemcpy(d_crc64_interleaved_table, crc64_interleaved_table, \n\t\t    4*256*sizeof(uint64_t) , cudaMemcpyHostToDevice);\n\n    crc64_kernel<<<nthreads/64, 64>>>(d_thread_sz, d_thread_cs, d_data, \n\t\t    d_crc64_table, d_crc64_interleaved_table, nbytes, nthreads);\n\n    cudaMemcpy(thread_sz, d_thread_sz, nthreads * sizeof(size_t), cudaMemcpyDeviceToHost);\n    cudaMemcpy(thread_cs, d_thread_cs, nthreads * sizeof(uint64_t), cudaMemcpyDeviceToHost);\n\n    uint64_t cs = thread_cs[0];\n    for (int i = 1; i < nthreads; ++i) {\n      cs = crc64_combine(cs, thread_cs[i], thread_sz[i]);\n    }\n    cudaFree(d_thread_sz); \n    cudaFree(d_thread_cs);\n    cudaFree(d_data);\n    cudaFree(d_crc64_table);\n    cudaFree(d_crc64_interleaved_table);\n    return cs;\n  }\n\n  return crc64(input, nbytes);\n}\n", "CRC64Test.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <ctime>\n#include <vector>\n#include <iostream>\n#include \"CRC64.h\"\n\nint main(int argc, char *argv[]) {\n  int ntests = 10;\n  if (argc > 1) ntests = atoi(argv[1]);\n\n  int seed = 5;\n  if (argc > 2) seed = atoi(argv[2]);\n\n  int max_test_length = 2097152;\n  if (argc > 3) max_test_length = atoi(argv[3]);\n\n  std::cout << \"Running \" << ntests << \" tests with seed \" << seed << std::endl;\n\n  srand48(seed);\n\n#ifdef __bgp__\n#define THE_CLOCK CLOCK_REALTIME\n#else\n#define THE_CLOCK CLOCK_THREAD_CPUTIME_ID\n#endif\n\n  double tot_time = 0, tot_bytes = 0;\n\n  int ntest = 0;\n  while (++ntest <= ntests) {\n    std::cout << ntest << \" \";\n\n    size_t test_length = (size_t) (max_test_length*(drand48()+1));\n    std::cout << test_length << \" \";\n\n    std::vector<unsigned char> input_buffer(test_length);\n\n    for (size_t i = 0; i < test_length; ++i) {\n      input_buffer[i] = (unsigned char) (255*drand48());\n    }\n\n    timespec b_start, b_end;\n    clock_gettime(THE_CLOCK, &b_start);\n\n    uint64_t cs = crc64_parallel(&input_buffer[0], test_length);\n\n    clock_gettime(THE_CLOCK, &b_end);\n    double b_time = (b_end.tv_sec - b_start.tv_sec);\n    b_time += 1e-9*(b_end.tv_nsec - b_start.tv_nsec);\n\n    if (ntest > 1) {\n      tot_time += b_time;\n      tot_bytes += test_length;\n    }\n\n    \n\n    size_t tlend = 8;\n    input_buffer.resize(test_length + tlend, 0);\n    crc64_invert(cs, &input_buffer[test_length]);\n\n    std::string pass(\"pass\"), fail(\"fail\");\n    uint64_t csc = crc64(&input_buffer[0], test_length+tlend);\n    std::cout << ((csc == (uint64_t) -1) ? pass : fail) << \" \";\n\n    size_t div_pt = (size_t) (test_length*drand48());\n    uint64_t cs1 = crc64(&input_buffer[0], div_pt);\n    uint64_t cs2 = crc64(&input_buffer[div_pt], test_length - div_pt);\n    csc = crc64_combine(cs1, cs2, test_length - div_pt);\n    std::cout << ((csc == cs) ? pass : fail);\n\n    std::cout << std::endl;\n  }\n\n  std::cout << (tot_bytes/(1024*1024))/tot_time << \" MB/s\" << std::endl;\n\n  return 0;\n}\n"}}
{"kernel_name": "crc64", "parallel_api": "hip", "code": {"CRC64.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef __STDC_CONSTANT_MACROS\n#define __STDC_CONSTANT_MACROS\n#endif\n\n\n#ifdef HAVE_CONFIG_H\n#include <config.h>\n#endif\n\n\n#include <stdbool.h>\n\n#include <hip/hip_runtime.h>\n#include \"CRC64.h\"\n\n\n\nstatic const uint64_t crc64_poly = UINT64_C(0xc96c5795d7870f42);\n\nstatic const uint64_t crc64_table[4][256] = {\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x1dee8a5e222ca1dc),\n    UINT64_C(0x3bdd14bc445943b8), UINT64_C(0x26339ee26675e264),\n    UINT64_C(0x77ba297888b28770), UINT64_C(0x6a54a326aa9e26ac),\n    UINT64_C(0x4c673dc4ccebc4c8), UINT64_C(0x5189b79aeec76514),\n    UINT64_C(0xef7452f111650ee0), UINT64_C(0xf29ad8af3349af3c),\n    UINT64_C(0xd4a9464d553c4d58), UINT64_C(0xc947cc137710ec84),\n    UINT64_C(0x98ce7b8999d78990), UINT64_C(0x8520f1d7bbfb284c),\n    UINT64_C(0xa3136f35dd8eca28), UINT64_C(0xbefde56bffa26bf4),\n    UINT64_C(0x4c300ac98dc40345), UINT64_C(0x51de8097afe8a299),\n    UINT64_C(0x77ed1e75c99d40fd), UINT64_C(0x6a03942bebb1e121),\n    UINT64_C(0x3b8a23b105768435), UINT64_C(0x2664a9ef275a25e9),\n    UINT64_C(0x0057370d412fc78d), UINT64_C(0x1db9bd5363036651),\n    UINT64_C(0xa34458389ca10da5), UINT64_C(0xbeaad266be8dac79),\n    UINT64_C(0x98994c84d8f84e1d), UINT64_C(0x8577c6dafad4efc1),\n    UINT64_C(0xd4fe714014138ad5), UINT64_C(0xc910fb1e363f2b09),\n    UINT64_C(0xef2365fc504ac96d), UINT64_C(0xf2cdefa2726668b1),\n    UINT64_C(0x986015931b88068a), UINT64_C(0x858e9fcd39a4a756),\n    UINT64_C(0xa3bd012f5fd14532), UINT64_C(0xbe538b717dfde4ee),\n    UINT64_C(0xefda3ceb933a81fa), UINT64_C(0xf234b6b5b1162026),\n    UINT64_C(0xd4072857d763c242), UINT64_C(0xc9e9a209f54f639e),\n    UINT64_C(0x771447620aed086a), UINT64_C(0x6afacd3c28c1a9b6),\n    UINT64_C(0x4cc953de4eb44bd2), UINT64_C(0x5127d9806c98ea0e),\n    UINT64_C(0x00ae6e1a825f8f1a), UINT64_C(0x1d40e444a0732ec6),\n    UINT64_C(0x3b737aa6c606cca2), UINT64_C(0x269df0f8e42a6d7e),\n    UINT64_C(0xd4501f5a964c05cf), UINT64_C(0xc9be9504b460a413),\n    UINT64_C(0xef8d0be6d2154677), UINT64_C(0xf26381b8f039e7ab),\n    UINT64_C(0xa3ea36221efe82bf), UINT64_C(0xbe04bc7c3cd22363),\n    UINT64_C(0x9837229e5aa7c107), UINT64_C(0x85d9a8c0788b60db),\n    UINT64_C(0x3b244dab87290b2f), UINT64_C(0x26cac7f5a505aaf3),\n    UINT64_C(0x00f95917c3704897), UINT64_C(0x1d17d349e15ce94b),\n    UINT64_C(0x4c9e64d30f9b8c5f), UINT64_C(0x5170ee8d2db72d83),\n    UINT64_C(0x7743706f4bc2cfe7), UINT64_C(0x6aadfa3169ee6e3b),\n    UINT64_C(0xa218840d981e1391), UINT64_C(0xbff60e53ba32b24d),\n    UINT64_C(0x99c590b1dc475029), UINT64_C(0x842b1aeffe6bf1f5),\n    UINT64_C(0xd5a2ad7510ac94e1), UINT64_C(0xc84c272b3280353d),\n    UINT64_C(0xee7fb9c954f5d759), UINT64_C(0xf391339776d97685),\n    UINT64_C(0x4d6cd6fc897b1d71), UINT64_C(0x50825ca2ab57bcad),\n    UINT64_C(0x76b1c240cd225ec9), UINT64_C(0x6b5f481eef0eff15),\n    UINT64_C(0x3ad6ff8401c99a01), UINT64_C(0x273875da23e53bdd),\n    UINT64_C(0x010beb384590d9b9), UINT64_C(0x1ce5616667bc7865),\n    UINT64_C(0xee288ec415da10d4), UINT64_C(0xf3c6049a37f6b108),\n    UINT64_C(0xd5f59a785183536c), UINT64_C(0xc81b102673aff2b0),\n    UINT64_C(0x9992a7bc9d6897a4), UINT64_C(0x847c2de2bf443678),\n    UINT64_C(0xa24fb300d931d41c), UINT64_C(0xbfa1395efb1d75c0),\n    UINT64_C(0x015cdc3504bf1e34), UINT64_C(0x1cb2566b2693bfe8),\n    UINT64_C(0x3a81c88940e65d8c), UINT64_C(0x276f42d762cafc50),\n    UINT64_C(0x76e6f54d8c0d9944), UINT64_C(0x6b087f13ae213898),\n    UINT64_C(0x4d3be1f1c854dafc), UINT64_C(0x50d56bafea787b20),\n    UINT64_C(0x3a78919e8396151b), UINT64_C(0x27961bc0a1bab4c7),\n    UINT64_C(0x01a58522c7cf56a3), UINT64_C(0x1c4b0f7ce5e3f77f),\n    UINT64_C(0x4dc2b8e60b24926b), UINT64_C(0x502c32b8290833b7),\n    UINT64_C(0x761fac5a4f7dd1d3), UINT64_C(0x6bf126046d51700f),\n    UINT64_C(0xd50cc36f92f31bfb), UINT64_C(0xc8e24931b0dfba27),\n    UINT64_C(0xeed1d7d3d6aa5843), UINT64_C(0xf33f5d8df486f99f),\n    UINT64_C(0xa2b6ea171a419c8b), UINT64_C(0xbf586049386d3d57),\n    UINT64_C(0x996bfeab5e18df33), UINT64_C(0x848574f57c347eef),\n    UINT64_C(0x76489b570e52165e), UINT64_C(0x6ba611092c7eb782),\n    UINT64_C(0x4d958feb4a0b55e6), UINT64_C(0x507b05b56827f43a),\n    UINT64_C(0x01f2b22f86e0912e), UINT64_C(0x1c1c3871a4cc30f2),\n    UINT64_C(0x3a2fa693c2b9d296), UINT64_C(0x27c12ccde095734a),\n    UINT64_C(0x993cc9a61f3718be), UINT64_C(0x84d243f83d1bb962),\n    UINT64_C(0xa2e1dd1a5b6e5b06), UINT64_C(0xbf0f57447942fada),\n    UINT64_C(0xee86e0de97859fce), UINT64_C(0xf3686a80b5a93e12),\n    UINT64_C(0xd55bf462d3dcdc76), UINT64_C(0xc8b57e3cf1f07daa),\n    UINT64_C(0xd6e9a7309f3239a7), UINT64_C(0xcb072d6ebd1e987b),\n    UINT64_C(0xed34b38cdb6b7a1f), UINT64_C(0xf0da39d2f947dbc3),\n    UINT64_C(0xa1538e481780bed7), UINT64_C(0xbcbd041635ac1f0b),\n    UINT64_C(0x9a8e9af453d9fd6f), UINT64_C(0x876010aa71f55cb3),\n    UINT64_C(0x399df5c18e573747), UINT64_C(0x24737f9fac7b969b),\n    UINT64_C(0x0240e17dca0e74ff), UINT64_C(0x1fae6b23e822d523),\n    UINT64_C(0x4e27dcb906e5b037), UINT64_C(0x53c956e724c911eb),\n    UINT64_C(0x75fac80542bcf38f), UINT64_C(0x6814425b60905253),\n    UINT64_C(0x9ad9adf912f63ae2), UINT64_C(0x873727a730da9b3e),\n    UINT64_C(0xa104b94556af795a), UINT64_C(0xbcea331b7483d886),\n    UINT64_C(0xed6384819a44bd92), UINT64_C(0xf08d0edfb8681c4e),\n    UINT64_C(0xd6be903dde1dfe2a), UINT64_C(0xcb501a63fc315ff6),\n    UINT64_C(0x75adff0803933402), UINT64_C(0x6843755621bf95de),\n    UINT64_C(0x4e70ebb447ca77ba), UINT64_C(0x539e61ea65e6d666),\n    UINT64_C(0x0217d6708b21b372), UINT64_C(0x1ff95c2ea90d12ae),\n    UINT64_C(0x39cac2cccf78f0ca), UINT64_C(0x24244892ed545116),\n    UINT64_C(0x4e89b2a384ba3f2d), UINT64_C(0x536738fda6969ef1),\n    UINT64_C(0x7554a61fc0e37c95), UINT64_C(0x68ba2c41e2cfdd49),\n    UINT64_C(0x39339bdb0c08b85d), UINT64_C(0x24dd11852e241981),\n    UINT64_C(0x02ee8f674851fbe5), UINT64_C(0x1f0005396a7d5a39),\n    UINT64_C(0xa1fde05295df31cd), UINT64_C(0xbc136a0cb7f39011),\n    UINT64_C(0x9a20f4eed1867275), UINT64_C(0x87ce7eb0f3aad3a9),\n    UINT64_C(0xd647c92a1d6db6bd), UINT64_C(0xcba943743f411761),\n    UINT64_C(0xed9add965934f505), UINT64_C(0xf07457c87b1854d9),\n    UINT64_C(0x02b9b86a097e3c68), UINT64_C(0x1f5732342b529db4),\n    UINT64_C(0x3964acd64d277fd0), UINT64_C(0x248a26886f0bde0c),\n    UINT64_C(0x7503911281ccbb18), UINT64_C(0x68ed1b4ca3e01ac4),\n    UINT64_C(0x4ede85aec595f8a0), UINT64_C(0x53300ff0e7b9597c),\n    UINT64_C(0xedcdea9b181b3288), UINT64_C(0xf02360c53a379354),\n    UINT64_C(0xd610fe275c427130), UINT64_C(0xcbfe74797e6ed0ec),\n    UINT64_C(0x9a77c3e390a9b5f8), UINT64_C(0x879949bdb2851424),\n    UINT64_C(0xa1aad75fd4f0f640), UINT64_C(0xbc445d01f6dc579c),\n    UINT64_C(0x74f1233d072c2a36), UINT64_C(0x691fa96325008bea),\n    UINT64_C(0x4f2c37814375698e), UINT64_C(0x52c2bddf6159c852),\n    UINT64_C(0x034b0a458f9ead46), UINT64_C(0x1ea5801badb20c9a),\n    UINT64_C(0x38961ef9cbc7eefe), UINT64_C(0x257894a7e9eb4f22),\n    UINT64_C(0x9b8571cc164924d6), UINT64_C(0x866bfb923465850a),\n    UINT64_C(0xa05865705210676e), UINT64_C(0xbdb6ef2e703cc6b2),\n    UINT64_C(0xec3f58b49efba3a6), UINT64_C(0xf1d1d2eabcd7027a),\n    UINT64_C(0xd7e24c08daa2e01e), UINT64_C(0xca0cc656f88e41c2),\n    UINT64_C(0x38c129f48ae82973), UINT64_C(0x252fa3aaa8c488af),\n    UINT64_C(0x031c3d48ceb16acb), UINT64_C(0x1ef2b716ec9dcb17),\n    UINT64_C(0x4f7b008c025aae03), UINT64_C(0x52958ad220760fdf),\n    UINT64_C(0x74a614304603edbb), UINT64_C(0x69489e6e642f4c67),\n    UINT64_C(0xd7b57b059b8d2793), UINT64_C(0xca5bf15bb9a1864f),\n    UINT64_C(0xec686fb9dfd4642b), UINT64_C(0xf186e5e7fdf8c5f7),\n    UINT64_C(0xa00f527d133fa0e3), UINT64_C(0xbde1d8233113013f),\n    UINT64_C(0x9bd246c15766e35b), UINT64_C(0x863ccc9f754a4287),\n    UINT64_C(0xec9136ae1ca42cbc), UINT64_C(0xf17fbcf03e888d60),\n    UINT64_C(0xd74c221258fd6f04), UINT64_C(0xcaa2a84c7ad1ced8),\n    UINT64_C(0x9b2b1fd69416abcc), UINT64_C(0x86c59588b63a0a10),\n    UINT64_C(0xa0f60b6ad04fe874), UINT64_C(0xbd188134f26349a8),\n    UINT64_C(0x03e5645f0dc1225c), UINT64_C(0x1e0bee012fed8380),\n    UINT64_C(0x383870e3499861e4), UINT64_C(0x25d6fabd6bb4c038),\n    UINT64_C(0x745f4d278573a52c), UINT64_C(0x69b1c779a75f04f0),\n    UINT64_C(0x4f82599bc12ae694), UINT64_C(0x526cd3c5e3064748),\n    UINT64_C(0xa0a13c6791602ff9), UINT64_C(0xbd4fb639b34c8e25),\n    UINT64_C(0x9b7c28dbd5396c41), UINT64_C(0x8692a285f715cd9d),\n    UINT64_C(0xd71b151f19d2a889), UINT64_C(0xcaf59f413bfe0955),\n    UINT64_C(0xecc601a35d8beb31), UINT64_C(0xf1288bfd7fa74aed),\n    UINT64_C(0x4fd56e9680052119), UINT64_C(0x523be4c8a22980c5),\n    UINT64_C(0x74087a2ac45c62a1), UINT64_C(0x69e6f074e670c37d),\n    UINT64_C(0x386f47ee08b7a669), UINT64_C(0x2581cdb02a9b07b5),\n    UINT64_C(0x03b253524ceee5d1), UINT64_C(0x1e5cd90c6ec2440d)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x3f0be14a916a6dcb),\n    UINT64_C(0x7e17c29522d4db96), UINT64_C(0x411c23dfb3beb65d),\n    UINT64_C(0xfc2f852a45a9b72c), UINT64_C(0xc3246460d4c3dae7),\n    UINT64_C(0x823847bf677d6cba), UINT64_C(0xbd33a6f5f6170171),\n    UINT64_C(0x6a87a57f245d70dd), UINT64_C(0x558c4435b5371d16),\n    UINT64_C(0x149067ea0689ab4b), UINT64_C(0x2b9b86a097e3c680),\n    UINT64_C(0x96a8205561f4c7f1), UINT64_C(0xa9a3c11ff09eaa3a),\n    UINT64_C(0xe8bfe2c043201c67), UINT64_C(0xd7b4038ad24a71ac),\n    UINT64_C(0xd50f4afe48bae1ba), UINT64_C(0xea04abb4d9d08c71),\n    UINT64_C(0xab18886b6a6e3a2c), UINT64_C(0x94136921fb0457e7),\n    UINT64_C(0x2920cfd40d135696), UINT64_C(0x162b2e9e9c793b5d),\n    UINT64_C(0x57370d412fc78d00), UINT64_C(0x683cec0bbeade0cb),\n    UINT64_C(0xbf88ef816ce79167), UINT64_C(0x80830ecbfd8dfcac),\n    UINT64_C(0xc19f2d144e334af1), UINT64_C(0xfe94cc5edf59273a),\n    UINT64_C(0x43a76aab294e264b), UINT64_C(0x7cac8be1b8244b80),\n    UINT64_C(0x3db0a83e0b9afddd), UINT64_C(0x02bb49749af09016),\n    UINT64_C(0x38c63ad73e7bddf1), UINT64_C(0x07cddb9daf11b03a),\n    UINT64_C(0x46d1f8421caf0667), UINT64_C(0x79da19088dc56bac),\n    UINT64_C(0xc4e9bffd7bd26add), UINT64_C(0xfbe25eb7eab80716),\n    UINT64_C(0xbafe7d685906b14b), UINT64_C(0x85f59c22c86cdc80),\n    UINT64_C(0x52419fa81a26ad2c), UINT64_C(0x6d4a7ee28b4cc0e7),\n    UINT64_C(0x2c565d3d38f276ba), UINT64_C(0x135dbc77a9981b71),\n    UINT64_C(0xae6e1a825f8f1a00), UINT64_C(0x9165fbc8cee577cb),\n    UINT64_C(0xd079d8177d5bc196), UINT64_C(0xef72395dec31ac5d),\n    UINT64_C(0xedc9702976c13c4b), UINT64_C(0xd2c29163e7ab5180),\n    UINT64_C(0x93deb2bc5415e7dd), UINT64_C(0xacd553f6c57f8a16),\n    UINT64_C(0x11e6f50333688b67), UINT64_C(0x2eed1449a202e6ac),\n    UINT64_C(0x6ff1379611bc50f1), UINT64_C(0x50fad6dc80d63d3a),\n    UINT64_C(0x874ed556529c4c96), UINT64_C(0xb845341cc3f6215d),\n    UINT64_C(0xf95917c370489700), UINT64_C(0xc652f689e122facb),\n    UINT64_C(0x7b61507c1735fbba), UINT64_C(0x446ab136865f9671),\n    UINT64_C(0x057692e935e1202c), UINT64_C(0x3a7d73a3a48b4de7),\n    UINT64_C(0x718c75ae7cf7bbe2), UINT64_C(0x4e8794e4ed9dd629),\n    UINT64_C(0x0f9bb73b5e236074), UINT64_C(0x30905671cf490dbf),\n    UINT64_C(0x8da3f084395e0cce), UINT64_C(0xb2a811cea8346105),\n    UINT64_C(0xf3b432111b8ad758), UINT64_C(0xccbfd35b8ae0ba93),\n    UINT64_C(0x1b0bd0d158aacb3f), UINT64_C(0x2400319bc9c0a6f4),\n    UINT64_C(0x651c12447a7e10a9), UINT64_C(0x5a17f30eeb147d62),\n    UINT64_C(0xe72455fb1d037c13), UINT64_C(0xd82fb4b18c6911d8),\n    UINT64_C(0x9933976e3fd7a785), UINT64_C(0xa6387624aebdca4e),\n    UINT64_C(0xa4833f50344d5a58), UINT64_C(0x9b88de1aa5273793),\n    UINT64_C(0xda94fdc5169981ce), UINT64_C(0xe59f1c8f87f3ec05),\n    UINT64_C(0x58acba7a71e4ed74), UINT64_C(0x67a75b30e08e80bf),\n    UINT64_C(0x26bb78ef533036e2), UINT64_C(0x19b099a5c25a5b29),\n    UINT64_C(0xce049a2f10102a85), UINT64_C(0xf10f7b65817a474e),\n    UINT64_C(0xb01358ba32c4f113), UINT64_C(0x8f18b9f0a3ae9cd8),\n    UINT64_C(0x322b1f0555b99da9), UINT64_C(0x0d20fe4fc4d3f062),\n    UINT64_C(0x4c3cdd90776d463f), UINT64_C(0x73373cdae6072bf4),\n    UINT64_C(0x494a4f79428c6613), UINT64_C(0x7641ae33d3e60bd8),\n    UINT64_C(0x375d8dec6058bd85), UINT64_C(0x08566ca6f132d04e),\n    UINT64_C(0xb565ca530725d13f), UINT64_C(0x8a6e2b19964fbcf4),\n    UINT64_C(0xcb7208c625f10aa9), UINT64_C(0xf479e98cb49b6762),\n    UINT64_C(0x23cdea0666d116ce), UINT64_C(0x1cc60b4cf7bb7b05),\n    UINT64_C(0x5dda28934405cd58), UINT64_C(0x62d1c9d9d56fa093),\n    UINT64_C(0xdfe26f2c2378a1e2), UINT64_C(0xe0e98e66b212cc29),\n    UINT64_C(0xa1f5adb901ac7a74), UINT64_C(0x9efe4cf390c617bf),\n    UINT64_C(0x9c4505870a3687a9), UINT64_C(0xa34ee4cd9b5cea62),\n    UINT64_C(0xe252c71228e25c3f), UINT64_C(0xdd592658b98831f4),\n    UINT64_C(0x606a80ad4f9f3085), UINT64_C(0x5f6161e7def55d4e),\n    UINT64_C(0x1e7d42386d4beb13), UINT64_C(0x2176a372fc2186d8),\n    UINT64_C(0xf6c2a0f82e6bf774), UINT64_C(0xc9c941b2bf019abf),\n    UINT64_C(0x88d5626d0cbf2ce2), UINT64_C(0xb7de83279dd54129),\n    UINT64_C(0x0aed25d26bc24058), UINT64_C(0x35e6c498faa82d93),\n    UINT64_C(0x74fae74749169bce), UINT64_C(0x4bf1060dd87cf605),\n    UINT64_C(0xe318eb5cf9ef77c4), UINT64_C(0xdc130a1668851a0f),\n    UINT64_C(0x9d0f29c9db3bac52), UINT64_C(0xa204c8834a51c199),\n    UINT64_C(0x1f376e76bc46c0e8), UINT64_C(0x203c8f3c2d2cad23),\n    UINT64_C(0x6120ace39e921b7e), UINT64_C(0x5e2b4da90ff876b5),\n    UINT64_C(0x899f4e23ddb20719), UINT64_C(0xb694af694cd86ad2),\n    UINT64_C(0xf7888cb6ff66dc8f), UINT64_C(0xc8836dfc6e0cb144),\n    UINT64_C(0x75b0cb09981bb035), UINT64_C(0x4abb2a430971ddfe),\n    UINT64_C(0x0ba7099cbacf6ba3), UINT64_C(0x34ace8d62ba50668),\n    UINT64_C(0x3617a1a2b155967e), UINT64_C(0x091c40e8203ffbb5),\n    UINT64_C(0x4800633793814de8), UINT64_C(0x770b827d02eb2023),\n    UINT64_C(0xca382488f4fc2152), UINT64_C(0xf533c5c265964c99),\n    UINT64_C(0xb42fe61dd628fac4), UINT64_C(0x8b2407574742970f),\n    UINT64_C(0x5c9004dd9508e6a3), UINT64_C(0x639be59704628b68),\n    UINT64_C(0x2287c648b7dc3d35), UINT64_C(0x1d8c270226b650fe),\n    UINT64_C(0xa0bf81f7d0a1518f), UINT64_C(0x9fb460bd41cb3c44),\n    UINT64_C(0xdea84362f2758a19), UINT64_C(0xe1a3a228631fe7d2),\n    UINT64_C(0xdbded18bc794aa35), UINT64_C(0xe4d530c156fec7fe),\n    UINT64_C(0xa5c9131ee54071a3), UINT64_C(0x9ac2f254742a1c68),\n    UINT64_C(0x27f154a1823d1d19), UINT64_C(0x18fab5eb135770d2),\n    UINT64_C(0x59e69634a0e9c68f), UINT64_C(0x66ed777e3183ab44),\n    UINT64_C(0xb15974f4e3c9dae8), UINT64_C(0x8e5295be72a3b723),\n    UINT64_C(0xcf4eb661c11d017e), UINT64_C(0xf045572b50776cb5),\n    UINT64_C(0x4d76f1dea6606dc4), UINT64_C(0x727d1094370a000f),\n    UINT64_C(0x3361334b84b4b652), UINT64_C(0x0c6ad20115dedb99),\n    UINT64_C(0x0ed19b758f2e4b8f), UINT64_C(0x31da7a3f1e442644),\n    UINT64_C(0x70c659e0adfa9019), UINT64_C(0x4fcdb8aa3c90fdd2),\n    UINT64_C(0xf2fe1e5fca87fca3), UINT64_C(0xcdf5ff155bed9168),\n    UINT64_C(0x8ce9dccae8532735), UINT64_C(0xb3e23d8079394afe),\n    UINT64_C(0x64563e0aab733b52), UINT64_C(0x5b5ddf403a195699),\n    UINT64_C(0x1a41fc9f89a7e0c4), UINT64_C(0x254a1dd518cd8d0f),\n    UINT64_C(0x9879bb20eeda8c7e), UINT64_C(0xa7725a6a7fb0e1b5),\n    UINT64_C(0xe66e79b5cc0e57e8), UINT64_C(0xd96598ff5d643a23),\n    UINT64_C(0x92949ef28518cc26), UINT64_C(0xad9f7fb81472a1ed),\n    UINT64_C(0xec835c67a7cc17b0), UINT64_C(0xd388bd2d36a67a7b),\n    UINT64_C(0x6ebb1bd8c0b17b0a), UINT64_C(0x51b0fa9251db16c1),\n    UINT64_C(0x10acd94de265a09c), UINT64_C(0x2fa73807730fcd57),\n    UINT64_C(0xf8133b8da145bcfb), UINT64_C(0xc718dac7302fd130),\n    UINT64_C(0x8604f9188391676d), UINT64_C(0xb90f185212fb0aa6),\n    UINT64_C(0x043cbea7e4ec0bd7), UINT64_C(0x3b375fed7586661c),\n    UINT64_C(0x7a2b7c32c638d041), UINT64_C(0x45209d785752bd8a),\n    UINT64_C(0x479bd40ccda22d9c), UINT64_C(0x789035465cc84057),\n    UINT64_C(0x398c1699ef76f60a), UINT64_C(0x0687f7d37e1c9bc1),\n    UINT64_C(0xbbb45126880b9ab0), UINT64_C(0x84bfb06c1961f77b),\n    UINT64_C(0xc5a393b3aadf4126), UINT64_C(0xfaa872f93bb52ced),\n    UINT64_C(0x2d1c7173e9ff5d41), UINT64_C(0x121790397895308a),\n    UINT64_C(0x530bb3e6cb2b86d7), UINT64_C(0x6c0052ac5a41eb1c),\n    UINT64_C(0xd133f459ac56ea6d), UINT64_C(0xee3815133d3c87a6),\n    UINT64_C(0xaf2436cc8e8231fb), UINT64_C(0x902fd7861fe85c30),\n    UINT64_C(0xaa52a425bb6311d7), UINT64_C(0x9559456f2a097c1c),\n    UINT64_C(0xd44566b099b7ca41), UINT64_C(0xeb4e87fa08dda78a),\n    UINT64_C(0x567d210ffecaa6fb), UINT64_C(0x6976c0456fa0cb30),\n    UINT64_C(0x286ae39adc1e7d6d), UINT64_C(0x176102d04d7410a6),\n    UINT64_C(0xc0d5015a9f3e610a), UINT64_C(0xffdee0100e540cc1),\n    UINT64_C(0xbec2c3cfbdeaba9c), UINT64_C(0x81c922852c80d757),\n    UINT64_C(0x3cfa8470da97d626), UINT64_C(0x03f1653a4bfdbbed),\n    UINT64_C(0x42ed46e5f8430db0), UINT64_C(0x7de6a7af6929607b),\n    UINT64_C(0x7f5deedbf3d9f06d), UINT64_C(0x40560f9162b39da6),\n    UINT64_C(0x014a2c4ed10d2bfb), UINT64_C(0x3e41cd0440674630),\n    UINT64_C(0x83726bf1b6704741), UINT64_C(0xbc798abb271a2a8a),\n    UINT64_C(0xfd65a96494a49cd7), UINT64_C(0xc26e482e05cef11c),\n    UINT64_C(0x15da4ba4d78480b0), UINT64_C(0x2ad1aaee46eeed7b),\n    UINT64_C(0x6bcd8931f5505b26), UINT64_C(0x54c6687b643a36ed),\n    UINT64_C(0xe9f5ce8e922d379c), UINT64_C(0xd6fe2fc403475a57),\n    UINT64_C(0x97e20c1bb0f9ec0a), UINT64_C(0xa8e9ed51219381c1)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x54e979925cd0f10d),\n    UINT64_C(0xa9d2f324b9a1e21a), UINT64_C(0xfd3b8ab6e5711317),\n    UINT64_C(0xc17d4962dc4ddab1), UINT64_C(0x959430f0809d2bbc),\n    UINT64_C(0x68afba4665ec38ab), UINT64_C(0x3c46c3d4393cc9a6),\n    UINT64_C(0x10223dee1795abe7), UINT64_C(0x44cb447c4b455aea),\n    UINT64_C(0xb9f0cecaae3449fd), UINT64_C(0xed19b758f2e4b8f0),\n    UINT64_C(0xd15f748ccbd87156), UINT64_C(0x85b60d1e9708805b),\n    UINT64_C(0x788d87a87279934c), UINT64_C(0x2c64fe3a2ea96241),\n    UINT64_C(0x20447bdc2f2b57ce), UINT64_C(0x74ad024e73fba6c3),\n    UINT64_C(0x899688f8968ab5d4), UINT64_C(0xdd7ff16aca5a44d9),\n    UINT64_C(0xe13932bef3668d7f), UINT64_C(0xb5d04b2cafb67c72),\n    UINT64_C(0x48ebc19a4ac76f65), UINT64_C(0x1c02b80816179e68),\n    UINT64_C(0x3066463238befc29), UINT64_C(0x648f3fa0646e0d24),\n    UINT64_C(0x99b4b516811f1e33), UINT64_C(0xcd5dcc84ddcfef3e),\n    UINT64_C(0xf11b0f50e4f32698), UINT64_C(0xa5f276c2b823d795),\n    UINT64_C(0x58c9fc745d52c482), UINT64_C(0x0c2085e60182358f),\n    UINT64_C(0x4088f7b85e56af9c), UINT64_C(0x14618e2a02865e91),\n    UINT64_C(0xe95a049ce7f74d86), UINT64_C(0xbdb37d0ebb27bc8b),\n    UINT64_C(0x81f5beda821b752d), UINT64_C(0xd51cc748decb8420),\n    UINT64_C(0x28274dfe3bba9737), UINT64_C(0x7cce346c676a663a),\n    UINT64_C(0x50aaca5649c3047b), UINT64_C(0x0443b3c41513f576),\n    UINT64_C(0xf9783972f062e661), UINT64_C(0xad9140e0acb2176c),\n    UINT64_C(0x91d78334958edeca), UINT64_C(0xc53efaa6c95e2fc7),\n    UINT64_C(0x380570102c2f3cd0), UINT64_C(0x6cec098270ffcddd),\n    UINT64_C(0x60cc8c64717df852), UINT64_C(0x3425f5f62dad095f),\n    UINT64_C(0xc91e7f40c8dc1a48), UINT64_C(0x9df706d2940ceb45),\n    UINT64_C(0xa1b1c506ad3022e3), UINT64_C(0xf558bc94f1e0d3ee),\n    UINT64_C(0x086336221491c0f9), UINT64_C(0x5c8a4fb0484131f4),\n    UINT64_C(0x70eeb18a66e853b5), UINT64_C(0x2407c8183a38a2b8),\n    UINT64_C(0xd93c42aedf49b1af), UINT64_C(0x8dd53b3c839940a2),\n    UINT64_C(0xb193f8e8baa58904), UINT64_C(0xe57a817ae6757809),\n    UINT64_C(0x18410bcc03046b1e), UINT64_C(0x4ca8725e5fd49a13),\n    UINT64_C(0x8111ef70bcad5f38), UINT64_C(0xd5f896e2e07dae35),\n    UINT64_C(0x28c31c54050cbd22), UINT64_C(0x7c2a65c659dc4c2f),\n    UINT64_C(0x406ca61260e08589), UINT64_C(0x1485df803c307484),\n    UINT64_C(0xe9be5536d9416793), UINT64_C(0xbd572ca48591969e),\n    UINT64_C(0x9133d29eab38f4df), UINT64_C(0xc5daab0cf7e805d2),\n    UINT64_C(0x38e121ba129916c5), UINT64_C(0x6c0858284e49e7c8),\n    UINT64_C(0x504e9bfc77752e6e), UINT64_C(0x04a7e26e2ba5df63),\n    UINT64_C(0xf99c68d8ced4cc74), UINT64_C(0xad75114a92043d79),\n    UINT64_C(0xa15594ac938608f6), UINT64_C(0xf5bced3ecf56f9fb),\n    UINT64_C(0x088767882a27eaec), UINT64_C(0x5c6e1e1a76f71be1),\n    UINT64_C(0x6028ddce4fcbd247), UINT64_C(0x34c1a45c131b234a),\n    UINT64_C(0xc9fa2eeaf66a305d), UINT64_C(0x9d135778aabac150),\n    UINT64_C(0xb177a9428413a311), UINT64_C(0xe59ed0d0d8c3521c),\n    UINT64_C(0x18a55a663db2410b), UINT64_C(0x4c4c23f46162b006),\n    UINT64_C(0x700ae020585e79a0), UINT64_C(0x24e399b2048e88ad),\n    UINT64_C(0xd9d81304e1ff9bba), UINT64_C(0x8d316a96bd2f6ab7),\n    UINT64_C(0xc19918c8e2fbf0a4), UINT64_C(0x9570615abe2b01a9),\n    UINT64_C(0x684bebec5b5a12be), UINT64_C(0x3ca2927e078ae3b3),\n    UINT64_C(0x00e451aa3eb62a15), UINT64_C(0x540d28386266db18),\n    UINT64_C(0xa936a28e8717c80f), UINT64_C(0xfddfdb1cdbc73902),\n    UINT64_C(0xd1bb2526f56e5b43), UINT64_C(0x85525cb4a9beaa4e),\n    UINT64_C(0x7869d6024ccfb959), UINT64_C(0x2c80af90101f4854),\n    UINT64_C(0x10c66c44292381f2), UINT64_C(0x442f15d675f370ff),\n    UINT64_C(0xb9149f60908263e8), UINT64_C(0xedfde6f2cc5292e5),\n    UINT64_C(0xe1dd6314cdd0a76a), UINT64_C(0xb5341a8691005667),\n    UINT64_C(0x480f903074714570), UINT64_C(0x1ce6e9a228a1b47d),\n    UINT64_C(0x20a02a76119d7ddb), UINT64_C(0x744953e44d4d8cd6),\n    UINT64_C(0x8972d952a83c9fc1), UINT64_C(0xdd9ba0c0f4ec6ecc),\n    UINT64_C(0xf1ff5efada450c8d), UINT64_C(0xa51627688695fd80),\n    UINT64_C(0x582dadde63e4ee97), UINT64_C(0x0cc4d44c3f341f9a),\n    UINT64_C(0x308217980608d63c), UINT64_C(0x646b6e0a5ad82731),\n    UINT64_C(0x9950e4bcbfa93426), UINT64_C(0xcdb99d2ee379c52b),\n    UINT64_C(0x90fb71cad654a0f5), UINT64_C(0xc41208588a8451f8),\n    UINT64_C(0x392982ee6ff542ef), UINT64_C(0x6dc0fb7c3325b3e2),\n    UINT64_C(0x518638a80a197a44), UINT64_C(0x056f413a56c98b49),\n    UINT64_C(0xf854cb8cb3b8985e), UINT64_C(0xacbdb21eef686953),\n    UINT64_C(0x80d94c24c1c10b12), UINT64_C(0xd43035b69d11fa1f),\n    UINT64_C(0x290bbf007860e908), UINT64_C(0x7de2c69224b01805),\n    UINT64_C(0x41a405461d8cd1a3), UINT64_C(0x154d7cd4415c20ae),\n    UINT64_C(0xe876f662a42d33b9), UINT64_C(0xbc9f8ff0f8fdc2b4),\n    UINT64_C(0xb0bf0a16f97ff73b), UINT64_C(0xe4567384a5af0636),\n    UINT64_C(0x196df93240de1521), UINT64_C(0x4d8480a01c0ee42c),\n    UINT64_C(0x71c2437425322d8a), UINT64_C(0x252b3ae679e2dc87),\n    UINT64_C(0xd810b0509c93cf90), UINT64_C(0x8cf9c9c2c0433e9d),\n    UINT64_C(0xa09d37f8eeea5cdc), UINT64_C(0xf4744e6ab23aadd1),\n    UINT64_C(0x094fc4dc574bbec6), UINT64_C(0x5da6bd4e0b9b4fcb),\n    UINT64_C(0x61e07e9a32a7866d), UINT64_C(0x350907086e777760),\n    UINT64_C(0xc8328dbe8b066477), UINT64_C(0x9cdbf42cd7d6957a),\n    UINT64_C(0xd073867288020f69), UINT64_C(0x849affe0d4d2fe64),\n    UINT64_C(0x79a1755631a3ed73), UINT64_C(0x2d480cc46d731c7e),\n    UINT64_C(0x110ecf10544fd5d8), UINT64_C(0x45e7b682089f24d5),\n    UINT64_C(0xb8dc3c34edee37c2), UINT64_C(0xec3545a6b13ec6cf),\n    UINT64_C(0xc051bb9c9f97a48e), UINT64_C(0x94b8c20ec3475583),\n    UINT64_C(0x698348b826364694), UINT64_C(0x3d6a312a7ae6b799),\n    UINT64_C(0x012cf2fe43da7e3f), UINT64_C(0x55c58b6c1f0a8f32),\n    UINT64_C(0xa8fe01dafa7b9c25), UINT64_C(0xfc177848a6ab6d28),\n    UINT64_C(0xf037fdaea72958a7), UINT64_C(0xa4de843cfbf9a9aa),\n    UINT64_C(0x59e50e8a1e88babd), UINT64_C(0x0d0c771842584bb0),\n    UINT64_C(0x314ab4cc7b648216), UINT64_C(0x65a3cd5e27b4731b),\n    UINT64_C(0x989847e8c2c5600c), UINT64_C(0xcc713e7a9e159101),\n    UINT64_C(0xe015c040b0bcf340), UINT64_C(0xb4fcb9d2ec6c024d),\n    UINT64_C(0x49c73364091d115a), UINT64_C(0x1d2e4af655cde057),\n    UINT64_C(0x216889226cf129f1), UINT64_C(0x7581f0b03021d8fc),\n    UINT64_C(0x88ba7a06d550cbeb), UINT64_C(0xdc53039489803ae6),\n    UINT64_C(0x11ea9eba6af9ffcd), UINT64_C(0x4503e72836290ec0),\n    UINT64_C(0xb8386d9ed3581dd7), UINT64_C(0xecd1140c8f88ecda),\n    UINT64_C(0xd097d7d8b6b4257c), UINT64_C(0x847eae4aea64d471),\n    UINT64_C(0x794524fc0f15c766), UINT64_C(0x2dac5d6e53c5366b),\n    UINT64_C(0x01c8a3547d6c542a), UINT64_C(0x5521dac621bca527),\n    UINT64_C(0xa81a5070c4cdb630), UINT64_C(0xfcf329e2981d473d),\n    UINT64_C(0xc0b5ea36a1218e9b), UINT64_C(0x945c93a4fdf17f96),\n    UINT64_C(0x6967191218806c81), UINT64_C(0x3d8e608044509d8c),\n    UINT64_C(0x31aee56645d2a803), UINT64_C(0x65479cf41902590e),\n    UINT64_C(0x987c1642fc734a19), UINT64_C(0xcc956fd0a0a3bb14),\n    UINT64_C(0xf0d3ac04999f72b2), UINT64_C(0xa43ad596c54f83bf),\n    UINT64_C(0x59015f20203e90a8), UINT64_C(0x0de826b27cee61a5),\n    UINT64_C(0x218cd888524703e4), UINT64_C(0x7565a11a0e97f2e9),\n    UINT64_C(0x885e2bacebe6e1fe), UINT64_C(0xdcb7523eb73610f3),\n    UINT64_C(0xe0f191ea8e0ad955), UINT64_C(0xb418e878d2da2858),\n    UINT64_C(0x492362ce37ab3b4f), UINT64_C(0x1dca1b5c6b7bca42),\n    UINT64_C(0x5162690234af5051), UINT64_C(0x058b1090687fa15c),\n    UINT64_C(0xf8b09a268d0eb24b), UINT64_C(0xac59e3b4d1de4346),\n    UINT64_C(0x901f2060e8e28ae0), UINT64_C(0xc4f659f2b4327bed),\n    UINT64_C(0x39cdd344514368fa), UINT64_C(0x6d24aad60d9399f7),\n    UINT64_C(0x414054ec233afbb6), UINT64_C(0x15a92d7e7fea0abb),\n    UINT64_C(0xe892a7c89a9b19ac), UINT64_C(0xbc7bde5ac64be8a1),\n    UINT64_C(0x803d1d8eff772107), UINT64_C(0xd4d4641ca3a7d00a),\n    UINT64_C(0x29efeeaa46d6c31d), UINT64_C(0x7d0697381a063210),\n    UINT64_C(0x712612de1b84079f), UINT64_C(0x25cf6b4c4754f692),\n    UINT64_C(0xd8f4e1faa225e585), UINT64_C(0x8c1d9868fef51488),\n    UINT64_C(0xb05b5bbcc7c9dd2e), UINT64_C(0xe4b2222e9b192c23),\n    UINT64_C(0x1989a8987e683f34), UINT64_C(0x4d60d10a22b8ce39),\n    UINT64_C(0x61042f300c11ac78), UINT64_C(0x35ed56a250c15d75),\n    UINT64_C(0xc8d6dc14b5b04e62), UINT64_C(0x9c3fa586e960bf6f),\n    UINT64_C(0xa0796652d05c76c9), UINT64_C(0xf4901fc08c8c87c4),\n    UINT64_C(0x09ab957669fd94d3), UINT64_C(0x5d42ece4352d65de)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0xb32e4cbe03a75f6f),\n    UINT64_C(0xf4843657a840a05b), UINT64_C(0x47aa7ae9abe7ff34),\n    UINT64_C(0x7bd0c384ff8f5e33), UINT64_C(0xc8fe8f3afc28015c),\n    UINT64_C(0x8f54f5d357cffe68), UINT64_C(0x3c7ab96d5468a107),\n    UINT64_C(0xf7a18709ff1ebc66), UINT64_C(0x448fcbb7fcb9e309),\n    UINT64_C(0x0325b15e575e1c3d), UINT64_C(0xb00bfde054f94352),\n    UINT64_C(0x8c71448d0091e255), UINT64_C(0x3f5f08330336bd3a),\n    UINT64_C(0x78f572daa8d1420e), UINT64_C(0xcbdb3e64ab761d61),\n    UINT64_C(0x7d9ba13851336649), UINT64_C(0xceb5ed8652943926),\n    UINT64_C(0x891f976ff973c612), UINT64_C(0x3a31dbd1fad4997d),\n    UINT64_C(0x064b62bcaebc387a), UINT64_C(0xb5652e02ad1b6715),\n    UINT64_C(0xf2cf54eb06fc9821), UINT64_C(0x41e11855055bc74e),\n    UINT64_C(0x8a3a2631ae2dda2f), UINT64_C(0x39146a8fad8a8540),\n    UINT64_C(0x7ebe1066066d7a74), UINT64_C(0xcd905cd805ca251b),\n    UINT64_C(0xf1eae5b551a2841c), UINT64_C(0x42c4a90b5205db73),\n    UINT64_C(0x056ed3e2f9e22447), UINT64_C(0xb6409f5cfa457b28),\n    UINT64_C(0xfb374270a266cc92), UINT64_C(0x48190ecea1c193fd),\n    UINT64_C(0x0fb374270a266cc9), UINT64_C(0xbc9d3899098133a6),\n    UINT64_C(0x80e781f45de992a1), UINT64_C(0x33c9cd4a5e4ecdce),\n    UINT64_C(0x7463b7a3f5a932fa), UINT64_C(0xc74dfb1df60e6d95),\n    UINT64_C(0x0c96c5795d7870f4), UINT64_C(0xbfb889c75edf2f9b),\n    UINT64_C(0xf812f32ef538d0af), UINT64_C(0x4b3cbf90f69f8fc0),\n    UINT64_C(0x774606fda2f72ec7), UINT64_C(0xc4684a43a15071a8),\n    UINT64_C(0x83c230aa0ab78e9c), UINT64_C(0x30ec7c140910d1f3),\n    UINT64_C(0x86ace348f355aadb), UINT64_C(0x3582aff6f0f2f5b4),\n    UINT64_C(0x7228d51f5b150a80), UINT64_C(0xc10699a158b255ef),\n    UINT64_C(0xfd7c20cc0cdaf4e8), UINT64_C(0x4e526c720f7dab87),\n    UINT64_C(0x09f8169ba49a54b3), UINT64_C(0xbad65a25a73d0bdc),\n    UINT64_C(0x710d64410c4b16bd), UINT64_C(0xc22328ff0fec49d2),\n    UINT64_C(0x85895216a40bb6e6), UINT64_C(0x36a71ea8a7ace989),\n    UINT64_C(0x0adda7c5f3c4488e), UINT64_C(0xb9f3eb7bf06317e1),\n    UINT64_C(0xfe5991925b84e8d5), UINT64_C(0x4d77dd2c5823b7ba),\n    UINT64_C(0x64b62bcaebc387a1), UINT64_C(0xd7986774e864d8ce),\n    UINT64_C(0x90321d9d438327fa), UINT64_C(0x231c512340247895),\n    UINT64_C(0x1f66e84e144cd992), UINT64_C(0xac48a4f017eb86fd),\n    UINT64_C(0xebe2de19bc0c79c9), UINT64_C(0x58cc92a7bfab26a6),\n    UINT64_C(0x9317acc314dd3bc7), UINT64_C(0x2039e07d177a64a8),\n    UINT64_C(0x67939a94bc9d9b9c), UINT64_C(0xd4bdd62abf3ac4f3),\n    UINT64_C(0xe8c76f47eb5265f4), UINT64_C(0x5be923f9e8f53a9b),\n    UINT64_C(0x1c4359104312c5af), UINT64_C(0xaf6d15ae40b59ac0),\n    UINT64_C(0x192d8af2baf0e1e8), UINT64_C(0xaa03c64cb957be87),\n    UINT64_C(0xeda9bca512b041b3), UINT64_C(0x5e87f01b11171edc),\n    UINT64_C(0x62fd4976457fbfdb), UINT64_C(0xd1d305c846d8e0b4),\n    UINT64_C(0x96797f21ed3f1f80), UINT64_C(0x2557339fee9840ef),\n    UINT64_C(0xee8c0dfb45ee5d8e), UINT64_C(0x5da24145464902e1),\n    UINT64_C(0x1a083bacedaefdd5), UINT64_C(0xa9267712ee09a2ba),\n    UINT64_C(0x955cce7fba6103bd), UINT64_C(0x267282c1b9c65cd2),\n    UINT64_C(0x61d8f8281221a3e6), UINT64_C(0xd2f6b4961186fc89),\n    UINT64_C(0x9f8169ba49a54b33), UINT64_C(0x2caf25044a02145c),\n    UINT64_C(0x6b055fede1e5eb68), UINT64_C(0xd82b1353e242b407),\n    UINT64_C(0xe451aa3eb62a1500), UINT64_C(0x577fe680b58d4a6f),\n    UINT64_C(0x10d59c691e6ab55b), UINT64_C(0xa3fbd0d71dcdea34),\n    UINT64_C(0x6820eeb3b6bbf755), UINT64_C(0xdb0ea20db51ca83a),\n    UINT64_C(0x9ca4d8e41efb570e), UINT64_C(0x2f8a945a1d5c0861),\n    UINT64_C(0x13f02d374934a966), UINT64_C(0xa0de61894a93f609),\n    UINT64_C(0xe7741b60e174093d), UINT64_C(0x545a57dee2d35652),\n    UINT64_C(0xe21ac88218962d7a), UINT64_C(0x5134843c1b317215),\n    UINT64_C(0x169efed5b0d68d21), UINT64_C(0xa5b0b26bb371d24e),\n    UINT64_C(0x99ca0b06e7197349), UINT64_C(0x2ae447b8e4be2c26),\n    UINT64_C(0x6d4e3d514f59d312), UINT64_C(0xde6071ef4cfe8c7d),\n    UINT64_C(0x15bb4f8be788911c), UINT64_C(0xa6950335e42fce73),\n    UINT64_C(0xe13f79dc4fc83147), UINT64_C(0x521135624c6f6e28),\n    UINT64_C(0x6e6b8c0f1807cf2f), UINT64_C(0xdd45c0b11ba09040),\n    UINT64_C(0x9aefba58b0476f74), UINT64_C(0x29c1f6e6b3e0301b),\n    UINT64_C(0xc96c5795d7870f42), UINT64_C(0x7a421b2bd420502d),\n    UINT64_C(0x3de861c27fc7af19), UINT64_C(0x8ec62d7c7c60f076),\n    UINT64_C(0xb2bc941128085171), UINT64_C(0x0192d8af2baf0e1e),\n    UINT64_C(0x4638a2468048f12a), UINT64_C(0xf516eef883efae45),\n    UINT64_C(0x3ecdd09c2899b324), UINT64_C(0x8de39c222b3eec4b),\n    UINT64_C(0xca49e6cb80d9137f), UINT64_C(0x7967aa75837e4c10),\n    UINT64_C(0x451d1318d716ed17), UINT64_C(0xf6335fa6d4b1b278),\n    UINT64_C(0xb199254f7f564d4c), UINT64_C(0x02b769f17cf11223),\n    UINT64_C(0xb4f7f6ad86b4690b), UINT64_C(0x07d9ba1385133664),\n    UINT64_C(0x4073c0fa2ef4c950), UINT64_C(0xf35d8c442d53963f),\n    UINT64_C(0xcf273529793b3738), UINT64_C(0x7c0979977a9c6857),\n    UINT64_C(0x3ba3037ed17b9763), UINT64_C(0x888d4fc0d2dcc80c),\n    UINT64_C(0x435671a479aad56d), UINT64_C(0xf0783d1a7a0d8a02),\n    UINT64_C(0xb7d247f3d1ea7536), UINT64_C(0x04fc0b4dd24d2a59),\n    UINT64_C(0x3886b22086258b5e), UINT64_C(0x8ba8fe9e8582d431),\n    UINT64_C(0xcc0284772e652b05), UINT64_C(0x7f2cc8c92dc2746a),\n    UINT64_C(0x325b15e575e1c3d0), UINT64_C(0x8175595b76469cbf),\n    UINT64_C(0xc6df23b2dda1638b), UINT64_C(0x75f16f0cde063ce4),\n    UINT64_C(0x498bd6618a6e9de3), UINT64_C(0xfaa59adf89c9c28c),\n    UINT64_C(0xbd0fe036222e3db8), UINT64_C(0x0e21ac88218962d7),\n    UINT64_C(0xc5fa92ec8aff7fb6), UINT64_C(0x76d4de52895820d9),\n    UINT64_C(0x317ea4bb22bfdfed), UINT64_C(0x8250e80521188082),\n    UINT64_C(0xbe2a516875702185), UINT64_C(0x0d041dd676d77eea),\n    UINT64_C(0x4aae673fdd3081de), UINT64_C(0xf9802b81de97deb1),\n    UINT64_C(0x4fc0b4dd24d2a599), UINT64_C(0xfceef8632775faf6),\n    UINT64_C(0xbb44828a8c9205c2), UINT64_C(0x086ace348f355aad),\n    UINT64_C(0x34107759db5dfbaa), UINT64_C(0x873e3be7d8faa4c5),\n    UINT64_C(0xc094410e731d5bf1), UINT64_C(0x73ba0db070ba049e),\n    UINT64_C(0xb86133d4dbcc19ff), UINT64_C(0x0b4f7f6ad86b4690),\n    UINT64_C(0x4ce50583738cb9a4), UINT64_C(0xffcb493d702be6cb),\n    UINT64_C(0xc3b1f050244347cc), UINT64_C(0x709fbcee27e418a3),\n    UINT64_C(0x3735c6078c03e797), UINT64_C(0x841b8ab98fa4b8f8),\n    UINT64_C(0xadda7c5f3c4488e3), UINT64_C(0x1ef430e13fe3d78c),\n    UINT64_C(0x595e4a08940428b8), UINT64_C(0xea7006b697a377d7),\n    UINT64_C(0xd60abfdbc3cbd6d0), UINT64_C(0x6524f365c06c89bf),\n    UINT64_C(0x228e898c6b8b768b), UINT64_C(0x91a0c532682c29e4),\n    UINT64_C(0x5a7bfb56c35a3485), UINT64_C(0xe955b7e8c0fd6bea),\n    UINT64_C(0xaeffcd016b1a94de), UINT64_C(0x1dd181bf68bdcbb1),\n    UINT64_C(0x21ab38d23cd56ab6), UINT64_C(0x9285746c3f7235d9),\n    UINT64_C(0xd52f0e859495caed), UINT64_C(0x6601423b97329582),\n    UINT64_C(0xd041dd676d77eeaa), UINT64_C(0x636f91d96ed0b1c5),\n    UINT64_C(0x24c5eb30c5374ef1), UINT64_C(0x97eba78ec690119e),\n    UINT64_C(0xab911ee392f8b099), UINT64_C(0x18bf525d915feff6),\n    UINT64_C(0x5f1528b43ab810c2), UINT64_C(0xec3b640a391f4fad),\n    UINT64_C(0x27e05a6e926952cc), UINT64_C(0x94ce16d091ce0da3),\n    UINT64_C(0xd3646c393a29f297), UINT64_C(0x604a2087398eadf8),\n    UINT64_C(0x5c3099ea6de60cff), UINT64_C(0xef1ed5546e415390),\n    UINT64_C(0xa8b4afbdc5a6aca4), UINT64_C(0x1b9ae303c601f3cb),\n    UINT64_C(0x56ed3e2f9e224471), UINT64_C(0xe5c372919d851b1e),\n    UINT64_C(0xa26908783662e42a), UINT64_C(0x114744c635c5bb45),\n    UINT64_C(0x2d3dfdab61ad1a42), UINT64_C(0x9e13b115620a452d),\n    UINT64_C(0xd9b9cbfcc9edba19), UINT64_C(0x6a978742ca4ae576),\n    UINT64_C(0xa14cb926613cf817), UINT64_C(0x1262f598629ba778),\n    UINT64_C(0x55c88f71c97c584c), UINT64_C(0xe6e6c3cfcadb0723),\n    UINT64_C(0xda9c7aa29eb3a624), UINT64_C(0x69b2361c9d14f94b),\n    UINT64_C(0x2e184cf536f3067f), UINT64_C(0x9d36004b35545910),\n    UINT64_C(0x2b769f17cf112238), UINT64_C(0x9858d3a9ccb67d57),\n    UINT64_C(0xdff2a94067518263), UINT64_C(0x6cdce5fe64f6dd0c),\n    UINT64_C(0x50a65c93309e7c0b), UINT64_C(0xe388102d33392364),\n    UINT64_C(0xa4226ac498dedc50), UINT64_C(0x170c267a9b79833f),\n    UINT64_C(0xdcd7181e300f9e5e), UINT64_C(0x6ff954a033a8c131),\n    UINT64_C(0x28532e49984f3e05), UINT64_C(0x9b7d62f79be8616a),\n    UINT64_C(0xa707db9acf80c06d), UINT64_C(0x14299724cc279f02),\n    UINT64_C(0x5383edcd67c06036), UINT64_C(0xe0ada17364673f59)\n  }\n};\n\nstatic const uint64_t crc64_interleaved_table[4][256] = {\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0xe88a0d0c5521de3d),\n    UINT64_C(0x43ccb533054da2ff), UINT64_C(0xab46b83f506c7cc2),\n    UINT64_C(0x87996a660a9b45fe), UINT64_C(0x6f13676a5fba9bc3),\n    UINT64_C(0xc455df550fd6e701), UINT64_C(0x2cdfd2595af7393c),\n    UINT64_C(0x9dea7be7ba389579), UINT64_C(0x756076ebef194b44),\n    UINT64_C(0xde26ced4bf753786), UINT64_C(0x36acc3d8ea54e9bb),\n    UINT64_C(0x1a731181b0a3d087), UINT64_C(0xf2f91c8de5820eba),\n    UINT64_C(0x59bfa4b2b5ee7278), UINT64_C(0xb135a9bee0cfac45),\n    UINT64_C(0xa90c58e4db7f3477), UINT64_C(0x418655e88e5eea4a),\n    UINT64_C(0xeac0edd7de329688), UINT64_C(0x024ae0db8b1348b5),\n    UINT64_C(0x2e953282d1e47189), UINT64_C(0xc61f3f8e84c5afb4),\n    UINT64_C(0x6d5987b1d4a9d376), UINT64_C(0x85d38abd81880d4b),\n    UINT64_C(0x34e623036147a10e), UINT64_C(0xdc6c2e0f34667f33),\n    UINT64_C(0x772a9630640a03f1), UINT64_C(0x9fa09b3c312bddcc),\n    UINT64_C(0xb37f49656bdce4f0), UINT64_C(0x5bf544693efd3acd),\n    UINT64_C(0xf0b3fc566e91460f), UINT64_C(0x1839f15a3bb09832),\n    UINT64_C(0xc0c01ee219f0766b), UINT64_C(0x284a13ee4cd1a856),\n    UINT64_C(0x830cabd11cbdd494), UINT64_C(0x6b86a6dd499c0aa9),\n    UINT64_C(0x47597484136b3395), UINT64_C(0xafd37988464aeda8),\n    UINT64_C(0x0495c1b71626916a), UINT64_C(0xec1fccbb43074f57),\n    UINT64_C(0x5d2a6505a3c8e312), UINT64_C(0xb5a06809f6e93d2f),\n    UINT64_C(0x1ee6d036a68541ed), UINT64_C(0xf66cdd3af3a49fd0),\n    UINT64_C(0xdab30f63a953a6ec), UINT64_C(0x3239026ffc7278d1),\n    UINT64_C(0x997fba50ac1e0413), UINT64_C(0x71f5b75cf93fda2e),\n    UINT64_C(0x69cc4606c28f421c), UINT64_C(0x81464b0a97ae9c21),\n    UINT64_C(0x2a00f335c7c2e0e3), UINT64_C(0xc28afe3992e33ede),\n    UINT64_C(0xee552c60c81407e2), UINT64_C(0x06df216c9d35d9df),\n    UINT64_C(0xad999953cd59a51d), UINT64_C(0x4513945f98787b20),\n    UINT64_C(0xf4263de178b7d765), UINT64_C(0x1cac30ed2d960958),\n    UINT64_C(0xb7ea88d27dfa759a), UINT64_C(0x5f6085de28dbaba7),\n    UINT64_C(0x73bf5787722c929b), UINT64_C(0x9b355a8b270d4ca6),\n    UINT64_C(0x3073e2b477613064), UINT64_C(0xd8f9efb82240ee59),\n    UINT64_C(0x135892ef9ceef253), UINT64_C(0xfbd29fe3c9cf2c6e),\n    UINT64_C(0x509427dc99a350ac), UINT64_C(0xb81e2ad0cc828e91),\n    UINT64_C(0x94c1f8899675b7ad), UINT64_C(0x7c4bf585c3546990),\n    UINT64_C(0xd70d4dba93381552), UINT64_C(0x3f8740b6c619cb6f),\n    UINT64_C(0x8eb2e90826d6672a), UINT64_C(0x6638e40473f7b917),\n    UINT64_C(0xcd7e5c3b239bc5d5), UINT64_C(0x25f4513776ba1be8),\n    UINT64_C(0x092b836e2c4d22d4), UINT64_C(0xe1a18e62796cfce9),\n    UINT64_C(0x4ae7365d2900802b), UINT64_C(0xa26d3b517c215e16),\n    UINT64_C(0xba54ca0b4791c624), UINT64_C(0x52dec70712b01819),\n    UINT64_C(0xf9987f3842dc64db), UINT64_C(0x1112723417fdbae6),\n    UINT64_C(0x3dcda06d4d0a83da), UINT64_C(0xd547ad61182b5de7),\n    UINT64_C(0x7e01155e48472125), UINT64_C(0x968b18521d66ff18),\n    UINT64_C(0x27beb1ecfda9535d), UINT64_C(0xcf34bce0a8888d60),\n    UINT64_C(0x647204dff8e4f1a2), UINT64_C(0x8cf809d3adc52f9f),\n    UINT64_C(0xa027db8af73216a3), UINT64_C(0x48add686a213c89e),\n    UINT64_C(0xe3eb6eb9f27fb45c), UINT64_C(0x0b6163b5a75e6a61),\n    UINT64_C(0xd3988c0d851e8438), UINT64_C(0x3b128101d03f5a05),\n    UINT64_C(0x9054393e805326c7), UINT64_C(0x78de3432d572f8fa),\n    UINT64_C(0x5401e66b8f85c1c6), UINT64_C(0xbc8beb67daa41ffb),\n    UINT64_C(0x17cd53588ac86339), UINT64_C(0xff475e54dfe9bd04),\n    UINT64_C(0x4e72f7ea3f261141), UINT64_C(0xa6f8fae66a07cf7c),\n    UINT64_C(0x0dbe42d93a6bb3be), UINT64_C(0xe5344fd56f4a6d83),\n    UINT64_C(0xc9eb9d8c35bd54bf), UINT64_C(0x21619080609c8a82),\n    UINT64_C(0x8a2728bf30f0f640), UINT64_C(0x62ad25b365d1287d),\n    UINT64_C(0x7a94d4e95e61b04f), UINT64_C(0x921ed9e50b406e72),\n    UINT64_C(0x395861da5b2c12b0), UINT64_C(0xd1d26cd60e0dcc8d),\n    UINT64_C(0xfd0dbe8f54faf5b1), UINT64_C(0x1587b38301db2b8c),\n    UINT64_C(0xbec10bbc51b7574e), UINT64_C(0x564b06b004968973),\n    UINT64_C(0xe77eaf0ee4592536), UINT64_C(0x0ff4a202b178fb0b),\n    UINT64_C(0xa4b21a3de11487c9), UINT64_C(0x4c381731b43559f4),\n    UINT64_C(0x60e7c568eec260c8), UINT64_C(0x886dc864bbe3bef5),\n    UINT64_C(0x232b705beb8fc237), UINT64_C(0xcba17d57beae1c0a),\n    UINT64_C(0x26b125df39dde4a6), UINT64_C(0xce3b28d36cfc3a9b),\n    UINT64_C(0x657d90ec3c904659), UINT64_C(0x8df79de069b19864),\n    UINT64_C(0xa1284fb93346a158), UINT64_C(0x49a242b566677f65),\n    UINT64_C(0xe2e4fa8a360b03a7), UINT64_C(0x0a6ef786632add9a),\n    UINT64_C(0xbb5b5e3883e571df), UINT64_C(0x53d15334d6c4afe2),\n    UINT64_C(0xf897eb0b86a8d320), UINT64_C(0x101de607d3890d1d),\n    UINT64_C(0x3cc2345e897e3421), UINT64_C(0xd4483952dc5fea1c),\n    UINT64_C(0x7f0e816d8c3396de), UINT64_C(0x97848c61d91248e3),\n    UINT64_C(0x8fbd7d3be2a2d0d1), UINT64_C(0x67377037b7830eec),\n    UINT64_C(0xcc71c808e7ef722e), UINT64_C(0x24fbc504b2ceac13),\n    UINT64_C(0x0824175de839952f), UINT64_C(0xe0ae1a51bd184b12),\n    UINT64_C(0x4be8a26eed7437d0), UINT64_C(0xa362af62b855e9ed),\n    UINT64_C(0x125706dc589a45a8), UINT64_C(0xfadd0bd00dbb9b95),\n    UINT64_C(0x519bb3ef5dd7e757), UINT64_C(0xb911bee308f6396a),\n    UINT64_C(0x95ce6cba52010056), UINT64_C(0x7d4461b60720de6b),\n    UINT64_C(0xd602d989574ca2a9), UINT64_C(0x3e88d485026d7c94),\n    UINT64_C(0xe6713b3d202d92cd), UINT64_C(0x0efb3631750c4cf0),\n    UINT64_C(0xa5bd8e0e25603032), UINT64_C(0x4d3783027041ee0f),\n    UINT64_C(0x61e8515b2ab6d733), UINT64_C(0x89625c577f97090e),\n    UINT64_C(0x2224e4682ffb75cc), UINT64_C(0xcaaee9647adaabf1),\n    UINT64_C(0x7b9b40da9a1507b4), UINT64_C(0x93114dd6cf34d989),\n    UINT64_C(0x3857f5e99f58a54b), UINT64_C(0xd0ddf8e5ca797b76),\n    UINT64_C(0xfc022abc908e424a), UINT64_C(0x148827b0c5af9c77),\n    UINT64_C(0xbfce9f8f95c3e0b5), UINT64_C(0x57449283c0e23e88),\n    UINT64_C(0x4f7d63d9fb52a6ba), UINT64_C(0xa7f76ed5ae737887),\n    UINT64_C(0x0cb1d6eafe1f0445), UINT64_C(0xe43bdbe6ab3eda78),\n    UINT64_C(0xc8e409bff1c9e344), UINT64_C(0x206e04b3a4e83d79),\n    UINT64_C(0x8b28bc8cf48441bb), UINT64_C(0x63a2b180a1a59f86),\n    UINT64_C(0xd297183e416a33c3), UINT64_C(0x3a1d1532144bedfe),\n    UINT64_C(0x915bad0d4427913c), UINT64_C(0x79d1a00111064f01),\n    UINT64_C(0x550e72584bf1763d), UINT64_C(0xbd847f541ed0a800),\n    UINT64_C(0x16c2c76b4ebcd4c2), UINT64_C(0xfe48ca671b9d0aff),\n    UINT64_C(0x35e9b730a53316f5), UINT64_C(0xdd63ba3cf012c8c8),\n    UINT64_C(0x76250203a07eb40a), UINT64_C(0x9eaf0f0ff55f6a37),\n    UINT64_C(0xb270dd56afa8530b), UINT64_C(0x5afad05afa898d36),\n    UINT64_C(0xf1bc6865aae5f1f4), UINT64_C(0x19366569ffc42fc9),\n    UINT64_C(0xa803ccd71f0b838c), UINT64_C(0x4089c1db4a2a5db1),\n    UINT64_C(0xebcf79e41a462173), UINT64_C(0x034574e84f67ff4e),\n    UINT64_C(0x2f9aa6b11590c672), UINT64_C(0xc710abbd40b1184f),\n    UINT64_C(0x6c56138210dd648d), UINT64_C(0x84dc1e8e45fcbab0),\n    UINT64_C(0x9ce5efd47e4c2282), UINT64_C(0x746fe2d82b6dfcbf),\n    UINT64_C(0xdf295ae77b01807d), UINT64_C(0x37a357eb2e205e40),\n    UINT64_C(0x1b7c85b274d7677c), UINT64_C(0xf3f688be21f6b941),\n    UINT64_C(0x58b03081719ac583), UINT64_C(0xb03a3d8d24bb1bbe),\n    UINT64_C(0x010f9433c474b7fb), UINT64_C(0xe985993f915569c6),\n    UINT64_C(0x42c32100c1391504), UINT64_C(0xaa492c0c9418cb39),\n    UINT64_C(0x8696fe55ceeff205), UINT64_C(0x6e1cf3599bce2c38),\n    UINT64_C(0xc55a4b66cba250fa), UINT64_C(0x2dd0466a9e838ec7),\n    UINT64_C(0xf529a9d2bcc3609e), UINT64_C(0x1da3a4dee9e2bea3),\n    UINT64_C(0xb6e51ce1b98ec261), UINT64_C(0x5e6f11edecaf1c5c),\n    UINT64_C(0x72b0c3b4b6582560), UINT64_C(0x9a3aceb8e379fb5d),\n    UINT64_C(0x317c7687b315879f), UINT64_C(0xd9f67b8be63459a2),\n    UINT64_C(0x68c3d23506fbf5e7), UINT64_C(0x8049df3953da2bda),\n    UINT64_C(0x2b0f670603b65718), UINT64_C(0xc3856a0a56978925),\n    UINT64_C(0xef5ab8530c60b019), UINT64_C(0x07d0b55f59416e24),\n    UINT64_C(0xac960d60092d12e6), UINT64_C(0x441c006c5c0cccdb),\n    UINT64_C(0x5c25f13667bc54e9), UINT64_C(0xb4affc3a329d8ad4),\n    UINT64_C(0x1fe9440562f1f616), UINT64_C(0xf763490937d0282b),\n    UINT64_C(0xdbbc9b506d271117), UINT64_C(0x3336965c3806cf2a),\n    UINT64_C(0x98702e63686ab3e8), UINT64_C(0x70fa236f3d4b6dd5),\n    UINT64_C(0xc1cf8ad1dd84c190), UINT64_C(0x294587dd88a51fad),\n    UINT64_C(0x82033fe2d8c9636f), UINT64_C(0x6a8932ee8de8bd52),\n    UINT64_C(0x4656e0b7d71f846e), UINT64_C(0xaedcedbb823e5a53),\n    UINT64_C(0x059a5584d2522691), UINT64_C(0xed1058888773f8ac)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x4d624bbe73bbc94c),\n    UINT64_C(0x9ac4977ce7779298), UINT64_C(0xd7a6dcc294cc5bd4),\n    UINT64_C(0xa75181d261e13bb5), UINT64_C(0xea33ca6c125af2f9),\n    UINT64_C(0x3d9516ae8696a92d), UINT64_C(0x70f75d10f52d6061),\n    UINT64_C(0xdc7bac8f6ccc69ef), UINT64_C(0x9119e7311f77a0a3),\n    UINT64_C(0x46bf3bf38bbbfb77), UINT64_C(0x0bdd704df800323b),\n    UINT64_C(0x7b2a2d5d0d2d525a), UINT64_C(0x364866e37e969b16),\n    UINT64_C(0xe1eeba21ea5ac0c2), UINT64_C(0xac8cf19f99e1098e),\n    UINT64_C(0x2a2ff6357696cd5b), UINT64_C(0x674dbd8b052d0417),\n    UINT64_C(0xb0eb614991e15fc3), UINT64_C(0xfd892af7e25a968f),\n    UINT64_C(0x8d7e77e71777f6ee), UINT64_C(0xc01c3c5964cc3fa2),\n    UINT64_C(0x17bae09bf0006476), UINT64_C(0x5ad8ab2583bbad3a),\n    UINT64_C(0xf6545aba1a5aa4b4), UINT64_C(0xbb36110469e16df8),\n    UINT64_C(0x6c90cdc6fd2d362c), UINT64_C(0x21f286788e96ff60),\n    UINT64_C(0x5105db687bbb9f01), UINT64_C(0x1c6790d60800564d),\n    UINT64_C(0xcbc14c149ccc0d99), UINT64_C(0x86a307aaef77c4d5),\n    UINT64_C(0x545fec6aed2d9ab6), UINT64_C(0x193da7d49e9653fa),\n    UINT64_C(0xce9b7b160a5a082e), UINT64_C(0x83f930a879e1c162),\n    UINT64_C(0xf30e6db88ccca103), UINT64_C(0xbe6c2606ff77684f),\n    UINT64_C(0x69cafac46bbb339b), UINT64_C(0x24a8b17a1800fad7),\n    UINT64_C(0x882440e581e1f359), UINT64_C(0xc5460b5bf25a3a15),\n    UINT64_C(0x12e0d799669661c1), UINT64_C(0x5f829c27152da88d),\n    UINT64_C(0x2f75c137e000c8ec), UINT64_C(0x62178a8993bb01a0),\n    UINT64_C(0xb5b1564b07775a74), UINT64_C(0xf8d31df574cc9338),\n    UINT64_C(0x7e701a5f9bbb57ed), UINT64_C(0x331251e1e8009ea1),\n    UINT64_C(0xe4b48d237cccc575), UINT64_C(0xa9d6c69d0f770c39),\n    UINT64_C(0xd9219b8dfa5a6c58), UINT64_C(0x9443d03389e1a514),\n    UINT64_C(0x43e50cf11d2dfec0), UINT64_C(0x0e87474f6e96378c),\n    UINT64_C(0xa20bb6d0f7773e02), UINT64_C(0xef69fd6e84ccf74e),\n    UINT64_C(0x38cf21ac1000ac9a), UINT64_C(0x75ad6a1263bb65d6),\n    UINT64_C(0x055a3702969605b7), UINT64_C(0x48387cbce52dccfb),\n    UINT64_C(0x9f9ea07e71e1972f), UINT64_C(0xd2fcebc0025a5e63),\n    UINT64_C(0xa8bfd8d5da5b356c), UINT64_C(0xe5dd936ba9e0fc20),\n    UINT64_C(0x327b4fa93d2ca7f4), UINT64_C(0x7f1904174e976eb8),\n    UINT64_C(0x0fee5907bbba0ed9), UINT64_C(0x428c12b9c801c795),\n    UINT64_C(0x952ace7b5ccd9c41), UINT64_C(0xd84885c52f76550d),\n    UINT64_C(0x74c4745ab6975c83), UINT64_C(0x39a63fe4c52c95cf),\n    UINT64_C(0xee00e32651e0ce1b), UINT64_C(0xa362a898225b0757),\n    UINT64_C(0xd395f588d7766736), UINT64_C(0x9ef7be36a4cdae7a),\n    UINT64_C(0x495162f43001f5ae), UINT64_C(0x0433294a43ba3ce2),\n    UINT64_C(0x82902ee0accdf837), UINT64_C(0xcff2655edf76317b),\n    UINT64_C(0x1854b99c4bba6aaf), UINT64_C(0x5536f2223801a3e3),\n    UINT64_C(0x25c1af32cd2cc382), UINT64_C(0x68a3e48cbe970ace),\n    UINT64_C(0xbf05384e2a5b511a), UINT64_C(0xf26773f059e09856),\n    UINT64_C(0x5eeb826fc00191d8), UINT64_C(0x1389c9d1b3ba5894),\n    UINT64_C(0xc42f151327760340), UINT64_C(0x894d5ead54cdca0c),\n    UINT64_C(0xf9ba03bda1e0aa6d), UINT64_C(0xb4d84803d25b6321),\n    UINT64_C(0x637e94c1469738f5), UINT64_C(0x2e1cdf7f352cf1b9),\n    UINT64_C(0xfce034bf3776afda), UINT64_C(0xb1827f0144cd6696),\n    UINT64_C(0x6624a3c3d0013d42), UINT64_C(0x2b46e87da3baf40e),\n    UINT64_C(0x5bb1b56d5697946f), UINT64_C(0x16d3fed3252c5d23),\n    UINT64_C(0xc1752211b1e006f7), UINT64_C(0x8c1769afc25bcfbb),\n    UINT64_C(0x209b98305bbac635), UINT64_C(0x6df9d38e28010f79),\n    UINT64_C(0xba5f0f4cbccd54ad), UINT64_C(0xf73d44f2cf769de1),\n    UINT64_C(0x87ca19e23a5bfd80), UINT64_C(0xcaa8525c49e034cc),\n    UINT64_C(0x1d0e8e9edd2c6f18), UINT64_C(0x506cc520ae97a654),\n    UINT64_C(0xd6cfc28a41e06281), UINT64_C(0x9bad8934325babcd),\n    UINT64_C(0x4c0b55f6a697f019), UINT64_C(0x01691e48d52c3955),\n    UINT64_C(0x719e435820015934), UINT64_C(0x3cfc08e653ba9078),\n    UINT64_C(0xeb5ad424c776cbac), UINT64_C(0xa6389f9ab4cd02e0),\n    UINT64_C(0x0ab46e052d2c0b6e), UINT64_C(0x47d625bb5e97c222),\n    UINT64_C(0x9070f979ca5b99f6), UINT64_C(0xdd12b2c7b9e050ba),\n    UINT64_C(0xade5efd74ccd30db), UINT64_C(0xe087a4693f76f997),\n    UINT64_C(0x372178ababbaa243), UINT64_C(0x7a433315d8016b0f),\n    UINT64_C(0xc3a71e801bb8745d), UINT64_C(0x8ec5553e6803bd11),\n    UINT64_C(0x596389fcfccfe6c5), UINT64_C(0x1401c2428f742f89),\n    UINT64_C(0x64f69f527a594fe8), UINT64_C(0x2994d4ec09e286a4),\n    UINT64_C(0xfe32082e9d2edd70), UINT64_C(0xb3504390ee95143c),\n    UINT64_C(0x1fdcb20f77741db2), UINT64_C(0x52bef9b104cfd4fe),\n    UINT64_C(0x8518257390038f2a), UINT64_C(0xc87a6ecde3b84666),\n    UINT64_C(0xb88d33dd16952607), UINT64_C(0xf5ef7863652eef4b),\n    UINT64_C(0x2249a4a1f1e2b49f), UINT64_C(0x6f2bef1f82597dd3),\n    UINT64_C(0xe988e8b56d2eb906), UINT64_C(0xa4eaa30b1e95704a),\n    UINT64_C(0x734c7fc98a592b9e), UINT64_C(0x3e2e3477f9e2e2d2),\n    UINT64_C(0x4ed969670ccf82b3), UINT64_C(0x03bb22d97f744bff),\n    UINT64_C(0xd41dfe1bebb8102b), UINT64_C(0x997fb5a59803d967),\n    UINT64_C(0x35f3443a01e2d0e9), UINT64_C(0x78910f84725919a5),\n    UINT64_C(0xaf37d346e6954271), UINT64_C(0xe25598f8952e8b3d),\n    UINT64_C(0x92a2c5e86003eb5c), UINT64_C(0xdfc08e5613b82210),\n    UINT64_C(0x08665294877479c4), UINT64_C(0x4504192af4cfb088),\n    UINT64_C(0x97f8f2eaf695eeeb), UINT64_C(0xda9ab954852e27a7),\n    UINT64_C(0x0d3c659611e27c73), UINT64_C(0x405e2e286259b53f),\n    UINT64_C(0x30a973389774d55e), UINT64_C(0x7dcb3886e4cf1c12),\n    UINT64_C(0xaa6de444700347c6), UINT64_C(0xe70faffa03b88e8a),\n    UINT64_C(0x4b835e659a598704), UINT64_C(0x06e115dbe9e24e48),\n    UINT64_C(0xd147c9197d2e159c), UINT64_C(0x9c2582a70e95dcd0),\n    UINT64_C(0xecd2dfb7fbb8bcb1), UINT64_C(0xa1b09409880375fd),\n    UINT64_C(0x761648cb1ccf2e29), UINT64_C(0x3b7403756f74e765),\n    UINT64_C(0xbdd704df800323b0), UINT64_C(0xf0b54f61f3b8eafc),\n    UINT64_C(0x271393a36774b128), UINT64_C(0x6a71d81d14cf7864),\n    UINT64_C(0x1a86850de1e21805), UINT64_C(0x57e4ceb39259d149),\n    UINT64_C(0x8042127106958a9d), UINT64_C(0xcd2059cf752e43d1),\n    UINT64_C(0x61aca850eccf4a5f), UINT64_C(0x2ccee3ee9f748313),\n    UINT64_C(0xfb683f2c0bb8d8c7), UINT64_C(0xb60a74927803118b),\n    UINT64_C(0xc6fd29828d2e71ea), UINT64_C(0x8b9f623cfe95b8a6),\n    UINT64_C(0x5c39befe6a59e372), UINT64_C(0x115bf54019e22a3e),\n    UINT64_C(0x6b18c655c1e34131), UINT64_C(0x267a8debb258887d),\n    UINT64_C(0xf1dc51292694d3a9), UINT64_C(0xbcbe1a97552f1ae5),\n    UINT64_C(0xcc494787a0027a84), UINT64_C(0x812b0c39d3b9b3c8),\n    UINT64_C(0x568dd0fb4775e81c), UINT64_C(0x1bef9b4534ce2150),\n    UINT64_C(0xb7636adaad2f28de), UINT64_C(0xfa012164de94e192),\n    UINT64_C(0x2da7fda64a58ba46), UINT64_C(0x60c5b61839e3730a),\n    UINT64_C(0x1032eb08ccce136b), UINT64_C(0x5d50a0b6bf75da27),\n    UINT64_C(0x8af67c742bb981f3), UINT64_C(0xc79437ca580248bf),\n    UINT64_C(0x41373060b7758c6a), UINT64_C(0x0c557bdec4ce4526),\n    UINT64_C(0xdbf3a71c50021ef2), UINT64_C(0x9691eca223b9d7be),\n    UINT64_C(0xe666b1b2d694b7df), UINT64_C(0xab04fa0ca52f7e93),\n    UINT64_C(0x7ca226ce31e32547), UINT64_C(0x31c06d704258ec0b),\n    UINT64_C(0x9d4c9cefdbb9e585), UINT64_C(0xd02ed751a8022cc9),\n    UINT64_C(0x07880b933cce771d), UINT64_C(0x4aea402d4f75be51),\n    UINT64_C(0x3a1d1d3dba58de30), UINT64_C(0x777f5683c9e3177c),\n    UINT64_C(0xa0d98a415d2f4ca8), UINT64_C(0xedbbc1ff2e9485e4),\n    UINT64_C(0x3f472a3f2ccedb87), UINT64_C(0x722561815f7512cb),\n    UINT64_C(0xa583bd43cbb9491f), UINT64_C(0xe8e1f6fdb8028053),\n    UINT64_C(0x9816abed4d2fe032), UINT64_C(0xd574e0533e94297e),\n    UINT64_C(0x02d23c91aa5872aa), UINT64_C(0x4fb0772fd9e3bbe6),\n    UINT64_C(0xe33c86b04002b268), UINT64_C(0xae5ecd0e33b97b24),\n    UINT64_C(0x79f811cca77520f0), UINT64_C(0x349a5a72d4cee9bc),\n    UINT64_C(0x446d076221e389dd), UINT64_C(0x090f4cdc52584091),\n    UINT64_C(0xdea9901ec6941b45), UINT64_C(0x93cbdba0b52fd209),\n    UINT64_C(0x1568dc0a5a5816dc), UINT64_C(0x580a97b429e3df90),\n    UINT64_C(0x8fac4b76bd2f8444), UINT64_C(0xc2ce00c8ce944d08),\n    UINT64_C(0xb2395dd83bb92d69), UINT64_C(0xff5b16664802e425),\n    UINT64_C(0x28fdcaa4dccebff1), UINT64_C(0x659f811aaf7576bd),\n    UINT64_C(0xc913708536947f33), UINT64_C(0x84713b3b452fb67f),\n    UINT64_C(0x53d7e7f9d1e3edab), UINT64_C(0x1eb5ac47a25824e7),\n    UINT64_C(0x6e42f15757754486), UINT64_C(0x2320bae924ce8dca),\n    UINT64_C(0xf486662bb002d61e), UINT64_C(0xb9e42d95c3b91f52)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x1596922b987ef63f),\n    UINT64_C(0x2b2d245730fdec7e), UINT64_C(0x3ebbb67ca8831a41),\n    UINT64_C(0x565a48ae61fbd8fc), UINT64_C(0x43ccda85f9852ec3),\n    UINT64_C(0x7d776cf951063482), UINT64_C(0x68e1fed2c978c2bd),\n    UINT64_C(0xacb4915cc3f7b1f8), UINT64_C(0xb92203775b8947c7),\n    UINT64_C(0x8799b50bf30a5d86), UINT64_C(0x920f27206b74abb9),\n    UINT64_C(0xfaeed9f2a20c6904), UINT64_C(0xef784bd93a729f3b),\n    UINT64_C(0xd1c3fda592f1857a), UINT64_C(0xc4556f8e0a8f7345),\n    UINT64_C(0xcbb18d9228e17d75), UINT64_C(0xde271fb9b09f8b4a),\n    UINT64_C(0xe09ca9c5181c910b), UINT64_C(0xf50a3bee80626734),\n    UINT64_C(0x9debc53c491aa589), UINT64_C(0x887d5717d16453b6),\n    UINT64_C(0xb6c6e16b79e749f7), UINT64_C(0xa3507340e199bfc8),\n    UINT64_C(0x67051cceeb16cc8d), UINT64_C(0x72938ee573683ab2),\n    UINT64_C(0x4c283899dbeb20f3), UINT64_C(0x59beaab24395d6cc),\n    UINT64_C(0x315f54608aed1471), UINT64_C(0x24c9c64b1293e24e),\n    UINT64_C(0x1a727037ba10f80f), UINT64_C(0x0fe4e21c226e0e30),\n    UINT64_C(0x05bbb40ffecce46f), UINT64_C(0x102d262466b21250),\n    UINT64_C(0x2e969058ce310811), UINT64_C(0x3b000273564ffe2e),\n    UINT64_C(0x53e1fca19f373c93), UINT64_C(0x46776e8a0749caac),\n    UINT64_C(0x78ccd8f6afcad0ed), UINT64_C(0x6d5a4add37b426d2),\n    UINT64_C(0xa90f25533d3b5597), UINT64_C(0xbc99b778a545a3a8),\n    UINT64_C(0x822201040dc6b9e9), UINT64_C(0x97b4932f95b84fd6),\n    UINT64_C(0xff556dfd5cc08d6b), UINT64_C(0xeac3ffd6c4be7b54),\n    UINT64_C(0xd47849aa6c3d6115), UINT64_C(0xc1eedb81f443972a),\n    UINT64_C(0xce0a399dd62d991a), UINT64_C(0xdb9cabb64e536f25),\n    UINT64_C(0xe5271dcae6d07564), UINT64_C(0xf0b18fe17eae835b),\n    UINT64_C(0x98507133b7d641e6), UINT64_C(0x8dc6e3182fa8b7d9),\n    UINT64_C(0xb37d5564872bad98), UINT64_C(0xa6ebc74f1f555ba7),\n    UINT64_C(0x62bea8c115da28e2), UINT64_C(0x77283aea8da4dedd),\n    UINT64_C(0x49938c962527c49c), UINT64_C(0x5c051ebdbd5932a3),\n    UINT64_C(0x34e4e06f7421f01e), UINT64_C(0x21727244ec5f0621),\n    UINT64_C(0x1fc9c43844dc1c60), UINT64_C(0x0a5f5613dca2ea5f),\n    UINT64_C(0x0b77681ffd99c8de), UINT64_C(0x1ee1fa3465e73ee1),\n    UINT64_C(0x205a4c48cd6424a0), UINT64_C(0x35ccde63551ad29f),\n    UINT64_C(0x5d2d20b19c621022), UINT64_C(0x48bbb29a041ce61d),\n    UINT64_C(0x760004e6ac9ffc5c), UINT64_C(0x639696cd34e10a63),\n    UINT64_C(0xa7c3f9433e6e7926), UINT64_C(0xb2556b68a6108f19),\n    UINT64_C(0x8ceedd140e939558), UINT64_C(0x99784f3f96ed6367),\n    UINT64_C(0xf199b1ed5f95a1da), UINT64_C(0xe40f23c6c7eb57e5),\n    UINT64_C(0xdab495ba6f684da4), UINT64_C(0xcf220791f716bb9b),\n    UINT64_C(0xc0c6e58dd578b5ab), UINT64_C(0xd55077a64d064394),\n    UINT64_C(0xebebc1dae58559d5), UINT64_C(0xfe7d53f17dfbafea),\n    UINT64_C(0x969cad23b4836d57), UINT64_C(0x830a3f082cfd9b68),\n    UINT64_C(0xbdb18974847e8129), UINT64_C(0xa8271b5f1c007716),\n    UINT64_C(0x6c7274d1168f0453), UINT64_C(0x79e4e6fa8ef1f26c),\n    UINT64_C(0x475f50862672e82d), UINT64_C(0x52c9c2adbe0c1e12),\n    UINT64_C(0x3a283c7f7774dcaf), UINT64_C(0x2fbeae54ef0a2a90),\n    UINT64_C(0x11051828478930d1), UINT64_C(0x04938a03dff7c6ee),\n    UINT64_C(0x0eccdc1003552cb1), UINT64_C(0x1b5a4e3b9b2bda8e),\n    UINT64_C(0x25e1f84733a8c0cf), UINT64_C(0x30776a6cabd636f0),\n    UINT64_C(0x589694be62aef44d), UINT64_C(0x4d000695fad00272),\n    UINT64_C(0x73bbb0e952531833), UINT64_C(0x662d22c2ca2dee0c),\n    UINT64_C(0xa2784d4cc0a29d49), UINT64_C(0xb7eedf6758dc6b76),\n    UINT64_C(0x8955691bf05f7137), UINT64_C(0x9cc3fb3068218708),\n    UINT64_C(0xf42205e2a15945b5), UINT64_C(0xe1b497c93927b38a),\n    UINT64_C(0xdf0f21b591a4a9cb), UINT64_C(0xca99b39e09da5ff4),\n    UINT64_C(0xc57d51822bb451c4), UINT64_C(0xd0ebc3a9b3caa7fb),\n    UINT64_C(0xee5075d51b49bdba), UINT64_C(0xfbc6e7fe83374b85),\n    UINT64_C(0x9327192c4a4f8938), UINT64_C(0x86b18b07d2317f07),\n    UINT64_C(0xb80a3d7b7ab26546), UINT64_C(0xad9caf50e2cc9379),\n    UINT64_C(0x69c9c0dee843e03c), UINT64_C(0x7c5f52f5703d1603),\n    UINT64_C(0x42e4e489d8be0c42), UINT64_C(0x577276a240c0fa7d),\n    UINT64_C(0x3f93887089b838c0), UINT64_C(0x2a051a5b11c6ceff),\n    UINT64_C(0x14beac27b945d4be), UINT64_C(0x01283e0c213b2281),\n    UINT64_C(0x16eed03ffb3391bc), UINT64_C(0x03784214634d6783),\n    UINT64_C(0x3dc3f468cbce7dc2), UINT64_C(0x2855664353b08bfd),\n    UINT64_C(0x40b498919ac84940), UINT64_C(0x55220aba02b6bf7f),\n    UINT64_C(0x6b99bcc6aa35a53e), UINT64_C(0x7e0f2eed324b5301),\n    UINT64_C(0xba5a416338c42044), UINT64_C(0xafccd348a0bad67b),\n    UINT64_C(0x917765340839cc3a), UINT64_C(0x84e1f71f90473a05),\n    UINT64_C(0xec0009cd593ff8b8), UINT64_C(0xf9969be6c1410e87),\n    UINT64_C(0xc72d2d9a69c214c6), UINT64_C(0xd2bbbfb1f1bce2f9),\n    UINT64_C(0xdd5f5dadd3d2ecc9), UINT64_C(0xc8c9cf864bac1af6),\n    UINT64_C(0xf67279fae32f00b7), UINT64_C(0xe3e4ebd17b51f688),\n    UINT64_C(0x8b051503b2293435), UINT64_C(0x9e9387282a57c20a),\n    UINT64_C(0xa028315482d4d84b), UINT64_C(0xb5bea37f1aaa2e74),\n    UINT64_C(0x71ebccf110255d31), UINT64_C(0x647d5eda885bab0e),\n    UINT64_C(0x5ac6e8a620d8b14f), UINT64_C(0x4f507a8db8a64770),\n    UINT64_C(0x27b1845f71de85cd), UINT64_C(0x32271674e9a073f2),\n    UINT64_C(0x0c9ca008412369b3), UINT64_C(0x190a3223d95d9f8c),\n    UINT64_C(0x1355643005ff75d3), UINT64_C(0x06c3f61b9d8183ec),\n    UINT64_C(0x38784067350299ad), UINT64_C(0x2deed24cad7c6f92),\n    UINT64_C(0x450f2c9e6404ad2f), UINT64_C(0x5099beb5fc7a5b10),\n    UINT64_C(0x6e2208c954f94151), UINT64_C(0x7bb49ae2cc87b76e),\n    UINT64_C(0xbfe1f56cc608c42b), UINT64_C(0xaa7767475e763214),\n    UINT64_C(0x94ccd13bf6f52855), UINT64_C(0x815a43106e8bde6a),\n    UINT64_C(0xe9bbbdc2a7f31cd7), UINT64_C(0xfc2d2fe93f8deae8),\n    UINT64_C(0xc2969995970ef0a9), UINT64_C(0xd7000bbe0f700696),\n    UINT64_C(0xd8e4e9a22d1e08a6), UINT64_C(0xcd727b89b560fe99),\n    UINT64_C(0xf3c9cdf51de3e4d8), UINT64_C(0xe65f5fde859d12e7),\n    UINT64_C(0x8ebea10c4ce5d05a), UINT64_C(0x9b283327d49b2665),\n    UINT64_C(0xa593855b7c183c24), UINT64_C(0xb0051770e466ca1b),\n    UINT64_C(0x745078feeee9b95e), UINT64_C(0x61c6ead576974f61),\n    UINT64_C(0x5f7d5ca9de145520), UINT64_C(0x4aebce82466aa31f),\n    UINT64_C(0x220a30508f1261a2), UINT64_C(0x379ca27b176c979d),\n    UINT64_C(0x09271407bfef8ddc), UINT64_C(0x1cb1862c27917be3),\n    UINT64_C(0x1d99b82006aa5962), UINT64_C(0x080f2a0b9ed4af5d),\n    UINT64_C(0x36b49c773657b51c), UINT64_C(0x23220e5cae294323),\n    UINT64_C(0x4bc3f08e6751819e), UINT64_C(0x5e5562a5ff2f77a1),\n    UINT64_C(0x60eed4d957ac6de0), UINT64_C(0x757846f2cfd29bdf),\n    UINT64_C(0xb12d297cc55de89a), UINT64_C(0xa4bbbb575d231ea5),\n    UINT64_C(0x9a000d2bf5a004e4), UINT64_C(0x8f969f006ddef2db),\n    UINT64_C(0xe77761d2a4a63066), UINT64_C(0xf2e1f3f93cd8c659),\n    UINT64_C(0xcc5a4585945bdc18), UINT64_C(0xd9ccd7ae0c252a27),\n    UINT64_C(0xd62835b22e4b2417), UINT64_C(0xc3bea799b635d228),\n    UINT64_C(0xfd0511e51eb6c869), UINT64_C(0xe89383ce86c83e56),\n    UINT64_C(0x80727d1c4fb0fceb), UINT64_C(0x95e4ef37d7ce0ad4),\n    UINT64_C(0xab5f594b7f4d1095), UINT64_C(0xbec9cb60e733e6aa),\n    UINT64_C(0x7a9ca4eeedbc95ef), UINT64_C(0x6f0a36c575c263d0),\n    UINT64_C(0x51b180b9dd417991), UINT64_C(0x44271292453f8fae),\n    UINT64_C(0x2cc6ec408c474d13), UINT64_C(0x39507e6b1439bb2c),\n    UINT64_C(0x07ebc817bcbaa16d), UINT64_C(0x127d5a3c24c45752),\n    UINT64_C(0x18220c2ff866bd0d), UINT64_C(0x0db49e0460184b32),\n    UINT64_C(0x330f2878c89b5173), UINT64_C(0x2699ba5350e5a74c),\n    UINT64_C(0x4e784481999d65f1), UINT64_C(0x5beed6aa01e393ce),\n    UINT64_C(0x655560d6a960898f), UINT64_C(0x70c3f2fd311e7fb0),\n    UINT64_C(0xb4969d733b910cf5), UINT64_C(0xa1000f58a3effaca),\n    UINT64_C(0x9fbbb9240b6ce08b), UINT64_C(0x8a2d2b0f931216b4),\n    UINT64_C(0xe2ccd5dd5a6ad409), UINT64_C(0xf75a47f6c2142236),\n    UINT64_C(0xc9e1f18a6a973877), UINT64_C(0xdc7763a1f2e9ce48),\n    UINT64_C(0xd39381bdd087c078), UINT64_C(0xc605139648f93647),\n    UINT64_C(0xf8bea5eae07a2c06), UINT64_C(0xed2837c17804da39),\n    UINT64_C(0x85c9c913b17c1884), UINT64_C(0x905f5b382902eebb),\n    UINT64_C(0xaee4ed448181f4fa), UINT64_C(0xbb727f6f19ff02c5),\n    UINT64_C(0x7f2710e113707180), UINT64_C(0x6ab182ca8b0e87bf),\n    UINT64_C(0x540a34b6238d9dfe), UINT64_C(0x419ca69dbbf36bc1),\n    UINT64_C(0x297d584f728ba97c), UINT64_C(0x3cebca64eaf55f43),\n    UINT64_C(0x02507c1842764502), UINT64_C(0x17c6ee33da08b33d)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x2ddda07ff6672378),\n    UINT64_C(0x5bbb40ffecce46f0), UINT64_C(0x7666e0801aa96588),\n    UINT64_C(0xb77681ffd99c8de0), UINT64_C(0x9aab21802ffbae98),\n    UINT64_C(0xeccdc1003552cb10), UINT64_C(0xc110617fc335e868),\n    UINT64_C(0xfc35acd41c370545), UINT64_C(0xd1e80cabea50263d),\n    UINT64_C(0xa78eec2bf0f943b5), UINT64_C(0x8a534c54069e60cd),\n    UINT64_C(0x4b432d2bc5ab88a5), UINT64_C(0x669e8d5433ccabdd),\n    UINT64_C(0x10f86dd42965ce55), UINT64_C(0x3d25cdabdf02ed2d),\n    UINT64_C(0x6ab3f6839760140f), UINT64_C(0x476e56fc61073777),\n    UINT64_C(0x3108b67c7bae52ff), UINT64_C(0x1cd516038dc97187),\n    UINT64_C(0xddc5777c4efc99ef), UINT64_C(0xf018d703b89bba97),\n    UINT64_C(0x867e3783a232df1f), UINT64_C(0xaba397fc5455fc67),\n    UINT64_C(0x96865a578b57114a), UINT64_C(0xbb5bfa287d303232),\n    UINT64_C(0xcd3d1aa8679957ba), UINT64_C(0xe0e0bad791fe74c2),\n    UINT64_C(0x21f0dba852cb9caa), UINT64_C(0x0c2d7bd7a4acbfd2),\n    UINT64_C(0x7a4b9b57be05da5a), UINT64_C(0x57963b284862f922),\n    UINT64_C(0xd567ed072ec0281e), UINT64_C(0xf8ba4d78d8a70b66),\n    UINT64_C(0x8edcadf8c20e6eee), UINT64_C(0xa3010d8734694d96),\n    UINT64_C(0x62116cf8f75ca5fe), UINT64_C(0x4fcccc87013b8686),\n    UINT64_C(0x39aa2c071b92e30e), UINT64_C(0x14778c78edf5c076),\n    UINT64_C(0x295241d332f72d5b), UINT64_C(0x048fe1acc4900e23),\n    UINT64_C(0x72e9012cde396bab), UINT64_C(0x5f34a153285e48d3),\n    UINT64_C(0x9e24c02ceb6ba0bb), UINT64_C(0xb3f960531d0c83c3),\n    UINT64_C(0xc59f80d307a5e64b), UINT64_C(0xe84220acf1c2c533),\n    UINT64_C(0xbfd41b84b9a03c11), UINT64_C(0x9209bbfb4fc71f69),\n    UINT64_C(0xe46f5b7b556e7ae1), UINT64_C(0xc9b2fb04a3095999),\n    UINT64_C(0x08a29a7b603cb1f1), UINT64_C(0x257f3a04965b9289),\n    UINT64_C(0x5319da848cf2f701), UINT64_C(0x7ec47afb7a95d479),\n    UINT64_C(0x43e1b750a5973954), UINT64_C(0x6e3c172f53f01a2c),\n    UINT64_C(0x185af7af49597fa4), UINT64_C(0x358757d0bf3e5cdc),\n    UINT64_C(0xf49736af7c0bb4b4), UINT64_C(0xd94a96d08a6c97cc),\n    UINT64_C(0xaf2c765090c5f244), UINT64_C(0x82f1d62f66a2d13c),\n    UINT64_C(0x38177525f28e4eb9), UINT64_C(0x15cad55a04e96dc1),\n    UINT64_C(0x63ac35da1e400849), UINT64_C(0x4e7195a5e8272b31),\n    UINT64_C(0x8f61f4da2b12c359), UINT64_C(0xa2bc54a5dd75e021),\n    UINT64_C(0xd4dab425c7dc85a9), UINT64_C(0xf907145a31bba6d1),\n    UINT64_C(0xc422d9f1eeb94bfc), UINT64_C(0xe9ff798e18de6884),\n    UINT64_C(0x9f99990e02770d0c), UINT64_C(0xb2443971f4102e74),\n    UINT64_C(0x7354580e3725c61c), UINT64_C(0x5e89f871c142e564),\n    UINT64_C(0x28ef18f1dbeb80ec), UINT64_C(0x0532b88e2d8ca394),\n    UINT64_C(0x52a483a665ee5ab6), UINT64_C(0x7f7923d9938979ce),\n    UINT64_C(0x091fc35989201c46), UINT64_C(0x24c263267f473f3e),\n    UINT64_C(0xe5d20259bc72d756), UINT64_C(0xc80fa2264a15f42e),\n    UINT64_C(0xbe6942a650bc91a6), UINT64_C(0x93b4e2d9a6dbb2de),\n    UINT64_C(0xae912f7279d95ff3), UINT64_C(0x834c8f0d8fbe7c8b),\n    UINT64_C(0xf52a6f8d95171903), UINT64_C(0xd8f7cff263703a7b),\n    UINT64_C(0x19e7ae8da045d213), UINT64_C(0x343a0ef25622f16b),\n    UINT64_C(0x425cee724c8b94e3), UINT64_C(0x6f814e0dbaecb79b),\n    UINT64_C(0xed709822dc4e66a7), UINT64_C(0xc0ad385d2a2945df),\n    UINT64_C(0xb6cbd8dd30802057), UINT64_C(0x9b1678a2c6e7032f),\n    UINT64_C(0x5a0619dd05d2eb47), UINT64_C(0x77dbb9a2f3b5c83f),\n    UINT64_C(0x01bd5922e91cadb7), UINT64_C(0x2c60f95d1f7b8ecf),\n    UINT64_C(0x114534f6c07963e2), UINT64_C(0x3c989489361e409a),\n    UINT64_C(0x4afe74092cb72512), UINT64_C(0x6723d476dad0066a),\n    UINT64_C(0xa633b50919e5ee02), UINT64_C(0x8bee1576ef82cd7a),\n    UINT64_C(0xfd88f5f6f52ba8f2), UINT64_C(0xd0555589034c8b8a),\n    UINT64_C(0x87c36ea14b2e72a8), UINT64_C(0xaa1ecedebd4951d0),\n    UINT64_C(0xdc782e5ea7e03458), UINT64_C(0xf1a58e2151871720),\n    UINT64_C(0x30b5ef5e92b2ff48), UINT64_C(0x1d684f2164d5dc30),\n    UINT64_C(0x6b0eafa17e7cb9b8), UINT64_C(0x46d30fde881b9ac0),\n    UINT64_C(0x7bf6c275571977ed), UINT64_C(0x562b620aa17e5495),\n    UINT64_C(0x204d828abbd7311d), UINT64_C(0x0d9022f54db01265),\n    UINT64_C(0xcc80438a8e85fa0d), UINT64_C(0xe15de3f578e2d975),\n    UINT64_C(0x973b0375624bbcfd), UINT64_C(0xbae6a30a942c9f85),\n    UINT64_C(0x702eea4be51c9d72), UINT64_C(0x5df34a34137bbe0a),\n    UINT64_C(0x2b95aab409d2db82), UINT64_C(0x06480acbffb5f8fa),\n    UINT64_C(0xc7586bb43c801092), UINT64_C(0xea85cbcbcae733ea),\n    UINT64_C(0x9ce32b4bd04e5662), UINT64_C(0xb13e8b342629751a),\n    UINT64_C(0x8c1b469ff92b9837), UINT64_C(0xa1c6e6e00f4cbb4f),\n    UINT64_C(0xd7a0066015e5dec7), UINT64_C(0xfa7da61fe382fdbf),\n    UINT64_C(0x3b6dc76020b715d7), UINT64_C(0x16b0671fd6d036af),\n    UINT64_C(0x60d6879fcc795327), UINT64_C(0x4d0b27e03a1e705f),\n    UINT64_C(0x1a9d1cc8727c897d), UINT64_C(0x3740bcb7841baa05),\n    UINT64_C(0x41265c379eb2cf8d), UINT64_C(0x6cfbfc4868d5ecf5),\n    UINT64_C(0xadeb9d37abe0049d), UINT64_C(0x80363d485d8727e5),\n    UINT64_C(0xf650ddc8472e426d), UINT64_C(0xdb8d7db7b1496115),\n    UINT64_C(0xe6a8b01c6e4b8c38), UINT64_C(0xcb751063982caf40),\n    UINT64_C(0xbd13f0e38285cac8), UINT64_C(0x90ce509c74e2e9b0),\n    UINT64_C(0x51de31e3b7d701d8), UINT64_C(0x7c03919c41b022a0),\n    UINT64_C(0x0a65711c5b194728), UINT64_C(0x27b8d163ad7e6450),\n    UINT64_C(0xa549074ccbdcb56c), UINT64_C(0x8894a7333dbb9614),\n    UINT64_C(0xfef247b32712f39c), UINT64_C(0xd32fe7ccd175d0e4),\n    UINT64_C(0x123f86b31240388c), UINT64_C(0x3fe226cce4271bf4),\n    UINT64_C(0x4984c64cfe8e7e7c), UINT64_C(0x6459663308e95d04),\n    UINT64_C(0x597cab98d7ebb029), UINT64_C(0x74a10be7218c9351),\n    UINT64_C(0x02c7eb673b25f6d9), UINT64_C(0x2f1a4b18cd42d5a1),\n    UINT64_C(0xee0a2a670e773dc9), UINT64_C(0xc3d78a18f8101eb1),\n    UINT64_C(0xb5b16a98e2b97b39), UINT64_C(0x986ccae714de5841),\n    UINT64_C(0xcffaf1cf5cbca163), UINT64_C(0xe22751b0aadb821b),\n    UINT64_C(0x9441b130b072e793), UINT64_C(0xb99c114f4615c4eb),\n    UINT64_C(0x788c703085202c83), UINT64_C(0x5551d04f73470ffb),\n    UINT64_C(0x233730cf69ee6a73), UINT64_C(0x0eea90b09f89490b),\n    UINT64_C(0x33cf5d1b408ba426), UINT64_C(0x1e12fd64b6ec875e),\n    UINT64_C(0x68741de4ac45e2d6), UINT64_C(0x45a9bd9b5a22c1ae),\n    UINT64_C(0x84b9dce4991729c6), UINT64_C(0xa9647c9b6f700abe),\n    UINT64_C(0xdf029c1b75d96f36), UINT64_C(0xf2df3c6483be4c4e),\n    UINT64_C(0x48399f6e1792d3cb), UINT64_C(0x65e43f11e1f5f0b3),\n    UINT64_C(0x1382df91fb5c953b), UINT64_C(0x3e5f7fee0d3bb643),\n    UINT64_C(0xff4f1e91ce0e5e2b), UINT64_C(0xd292beee38697d53),\n    UINT64_C(0xa4f45e6e22c018db), UINT64_C(0x8929fe11d4a73ba3),\n    UINT64_C(0xb40c33ba0ba5d68e), UINT64_C(0x99d193c5fdc2f5f6),\n    UINT64_C(0xefb77345e76b907e), UINT64_C(0xc26ad33a110cb306),\n    UINT64_C(0x037ab245d2395b6e), UINT64_C(0x2ea7123a245e7816),\n    UINT64_C(0x58c1f2ba3ef71d9e), UINT64_C(0x751c52c5c8903ee6),\n    UINT64_C(0x228a69ed80f2c7c4), UINT64_C(0x0f57c9927695e4bc),\n    UINT64_C(0x793129126c3c8134), UINT64_C(0x54ec896d9a5ba24c),\n    UINT64_C(0x95fce812596e4a24), UINT64_C(0xb821486daf09695c),\n    UINT64_C(0xce47a8edb5a00cd4), UINT64_C(0xe39a089243c72fac),\n    UINT64_C(0xdebfc5399cc5c281), UINT64_C(0xf36265466aa2e1f9),\n    UINT64_C(0x850485c6700b8471), UINT64_C(0xa8d925b9866ca709),\n    UINT64_C(0x69c944c645594f61), UINT64_C(0x4414e4b9b33e6c19),\n    UINT64_C(0x32720439a9970991), UINT64_C(0x1fafa4465ff02ae9),\n    UINT64_C(0x9d5e72693952fbd5), UINT64_C(0xb083d216cf35d8ad),\n    UINT64_C(0xc6e53296d59cbd25), UINT64_C(0xeb3892e923fb9e5d),\n    UINT64_C(0x2a28f396e0ce7635), UINT64_C(0x07f553e916a9554d),\n    UINT64_C(0x7193b3690c0030c5), UINT64_C(0x5c4e1316fa6713bd),\n    UINT64_C(0x616bdebd2565fe90), UINT64_C(0x4cb67ec2d302dde8),\n    UINT64_C(0x3ad09e42c9abb860), UINT64_C(0x170d3e3d3fcc9b18),\n    UINT64_C(0xd61d5f42fcf97370), UINT64_C(0xfbc0ff3d0a9e5008),\n    UINT64_C(0x8da61fbd10373580), UINT64_C(0xa07bbfc2e65016f8),\n    UINT64_C(0xf7ed84eaae32efda), UINT64_C(0xda3024955855cca2),\n    UINT64_C(0xac56c41542fca92a), UINT64_C(0x818b646ab49b8a52),\n    UINT64_C(0x409b051577ae623a), UINT64_C(0x6d46a56a81c94142),\n    UINT64_C(0x1b2045ea9b6024ca), UINT64_C(0x36fde5956d0707b2),\n    UINT64_C(0x0bd8283eb205ea9f), UINT64_C(0x260588414462c9e7),\n    UINT64_C(0x506368c15ecbac6f), UINT64_C(0x7dbec8bea8ac8f17),\n    UINT64_C(0xbcaea9c16b99677f), UINT64_C(0x917309be9dfe4407),\n    UINT64_C(0xe715e93e8757218f), UINT64_C(0xcac84941713002f7)\n  }\n};\n\nuint64_t crc64_slow(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  uint64_t cs = UINT64_C(0xffffffffffffffff);\n\n  while (nbytes--) {\n    uint32_t idx = ((uint32_t) (cs ^ *data++)) & 0xff;\n    cs = crc64_table[3][idx] ^ (cs >> 8);\n  }\n\n  return cs ^ UINT64_C(0xffffffffffffffff);\n}\n\n\n\n__host__ __device__\nstatic inline uint32_t crc64_load_le32_(const uint32_t *p) {\n  uint32_t w = *p;\n  return  ((((w) & 0xff000000) >> 24)\n         | (((w) & 0x00ff0000) >>  8)\n         | (((w) & 0x0000ff00) <<  8)\n         | (((w) & 0x000000ff) << 24));\n}\n\n\n\n\n\nuint64_t crc64(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  const unsigned char *end = data + nbytes;\n  uint64_t cs[5] = { UINT64_C(0xffffffffffffffff), 0, 0, 0, 0 };\n\n  \n\n  \n\n  \n\n  \n\n  while (data < end && ((((size_t) data) & 3) || (end - data < 20))) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  if (data == end)\n    return cs[0] ^ UINT64_C(0xffffffffffffffff);\n\n  const uint32_t one = 1;\n  bool big_endian = !(*((char *)(&one)));\n\n  uint64_t cry = 0;\n  uint32_t in[5];\n\n  if (!big_endian) {\n    for (unsigned i = 0; i < 5; ++i)\n      in[i] = ((const uint32_t*) data)[i];\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = ((const uint32_t*) data)[0];\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = ((const uint32_t*) data)[1];\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = ((const uint32_t*) data)[2];\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = ((const uint32_t*) data)[3];\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = ((const uint32_t*) data)[4];\n    }\n  } else {\n    for (unsigned i = 0; i < 5; ++i) {\n      in[i] = crc64_load_le32_(&((const uint32_t*) data)[i]);\n    }\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = crc64_load_le32_(&((const uint32_t*) data)[0]);\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = crc64_load_le32_(&((const uint32_t*) data)[1]);\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = crc64_load_le32_(&((const uint32_t*) data)[2]);\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = crc64_load_le32_(&((const uint32_t*) data)[3]);\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = crc64_load_le32_(&((const uint32_t*) data)[4]);\n    }\n  }\n\n  cs[0] ^= cry;\n\n  for (unsigned i = 0; i < 5; ++i) {\n    if (i > 0)\n      cs[0] ^= cs[i];\n    in[i] ^= (uint32_t) cs[0];\n    cs[0] = cs[0] >> 32;\n\n    for (unsigned b = 0; b < 3; ++b) {\n      cs[0] ^= crc64_table[b][in[i] & 0xff];\n      in[i] >>= 8;\n    }\n\n    cs[0] ^= crc64_table[3][in[i] & 0xff];\n  }\n\n  while (data < end) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  return cs[0] ^ UINT64_C(0xffffffffffffffff);\n}\n\n__device__\nuint64_t crc64_device(const unsigned char *input, size_t nbytes, \n\t\tconst uint64_t *d_crc64_table, \n\t\tconst uint64_t *d_crc64_interleaved_table) {\n  const unsigned char *data = input;\n  const unsigned char *end = data + nbytes;\n  uint64_t cs[5] = { UINT64_C(0xffffffffffffffff), 0, 0, 0, 0 };\n\n  \n\n  \n\n  \n\n  \n\n  while (data < end && ((((size_t) data) & 3) || (end - data < 20))) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = d_crc64_table[3*256+idx] ^ (cs[0] >> 8);\n  }\n\n  if (data == end)\n    return cs[0] ^ UINT64_C(0xffffffffffffffff);\n\n  const uint32_t one = 1;\n  bool big_endian = !(*((char *)(&one)));\n\n  uint64_t cry = 0;\n  uint32_t in[5];\n\n  if (!big_endian) {\n    for (unsigned i = 0; i < 5; ++i)\n      in[i] = ((const uint32_t*) data)[i];\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = d_crc64_interleaved_table[in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = d_crc64_interleaved_table[in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = d_crc64_interleaved_table[in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = d_crc64_interleaved_table[in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = d_crc64_interleaved_table[in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= d_crc64_interleaved_table[b*256+(in[0] & 0xff)];\n        in[0] >>= 8;\n\n        cs[1] ^= d_crc64_interleaved_table[b*256+(in[1] & 0xff)];\n        in[1] >>= 8;\n\n        cs[2] ^= d_crc64_interleaved_table[b*256+(in[2] & 0xff)];\n        in[2] >>= 8;\n\n        cs[3] ^= d_crc64_interleaved_table[b*256+(in[3] & 0xff)];\n        in[3] >>= 8;\n\n        cs[4] ^= d_crc64_interleaved_table[b*256+(in[4] & 0xff)];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= d_crc64_interleaved_table[3*256+(in[0] & 0xff)];\n      in[0] = ((const uint32_t*) data)[0];\n\n      cs[1] ^= d_crc64_interleaved_table[3*256+(in[1] & 0xff)];\n      in[1] = ((const uint32_t*) data)[1];\n\n      cs[2] ^= d_crc64_interleaved_table[3*256+(in[2] & 0xff)];\n      in[2] = ((const uint32_t*) data)[2];\n\n      cs[3] ^= d_crc64_interleaved_table[3*256+(in[3] & 0xff)];\n      in[3] = ((const uint32_t*) data)[3];\n\n      cs[4] ^= d_crc64_interleaved_table[3*256+(in[4] & 0xff)];\n      in[4] = ((const uint32_t*) data)[4];\n    }\n  } else {\n    for (unsigned i = 0; i < 5; ++i) {\n      in[i] = crc64_load_le32_(&((const uint32_t*) data)[i]);\n    }\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = d_crc64_interleaved_table[in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = d_crc64_interleaved_table[in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = d_crc64_interleaved_table[in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = d_crc64_interleaved_table[in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = d_crc64_interleaved_table[in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= d_crc64_interleaved_table[b*256+(in[0] & 0xff)];\n        in[0] >>= 8;\n\n        cs[1] ^= d_crc64_interleaved_table[b*256+(in[1] & 0xff)];\n        in[1] >>= 8;\n\n        cs[2] ^= d_crc64_interleaved_table[b*256+(in[2] & 0xff)];\n        in[2] >>= 8;\n\n        cs[3] ^= d_crc64_interleaved_table[b*256+(in[3] & 0xff)];\n        in[3] >>= 8;\n\n        cs[4] ^= d_crc64_interleaved_table[b*256+(in[4] & 0xff)];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= d_crc64_interleaved_table[3*256+(in[0] & 0xff)];\n      in[0] = crc64_load_le32_(&((const uint32_t*) data)[0]);\n\n      cs[1] ^= d_crc64_interleaved_table[3*256+(in[1] & 0xff)];\n      in[1] = crc64_load_le32_(&((const uint32_t*) data)[1]);\n\n      cs[2] ^= d_crc64_interleaved_table[3*256+(in[2] & 0xff)];\n      in[2] = crc64_load_le32_(&((const uint32_t*) data)[2]);\n\n      cs[3] ^= d_crc64_interleaved_table[3*256+(in[3] & 0xff)];\n      in[3] = crc64_load_le32_(&((const uint32_t*) data)[3]);\n\n      cs[4] ^= d_crc64_interleaved_table[3*256+(in[4] & 0xff)];\n      in[4] = crc64_load_le32_(&((const uint32_t*) data)[4]);\n    }\n  }\n\n  cs[0] ^= cry;\n\n  for (unsigned i = 0; i < 5; ++i) {\n    if (i > 0)\n      cs[0] ^= cs[i];\n    in[i] ^= (uint32_t) cs[0];\n    cs[0] = cs[0] >> 32;\n\n    for (unsigned b = 0; b < 3; ++b) {\n      cs[0] ^= d_crc64_table[b*256+(in[i] & 0xff)];\n      in[i] >>= 8;\n    }\n\n    cs[0] ^= d_crc64_table[3*256+(in[i] & 0xff)];\n  }\n\n  while (data < end) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = d_crc64_table[3*256+idx] ^ (cs[0] >> 8);\n  }\n\n  return cs[0] ^ UINT64_C(0xffffffffffffffff);\n}\n\n\n\n\n\nvoid crc64_invert(uint64_t cs, void *check_bytes) {\n  unsigned char *bytes = (unsigned char *) check_bytes;\n  cs ^= UINT64_C(0xffffffffffffffff);\n\n  \n\n  \n\n  bytes[7] = (cs >> 56) & 0xff;\n  bytes[6] = (cs >> 48) & 0xff;\n  bytes[5] = (cs >> 40) & 0xff;\n  bytes[4] = (cs >> 32) & 0xff;\n  bytes[3] = (cs >> 24) & 0xff;\n  bytes[2] = (cs >> 16) & 0xff;\n  bytes[1] = (cs >>  8) & 0xff;\n  bytes[0] =  cs        & 0xff;\n}\n\nstatic const uint64_t crc64_x_pow_2n[64] = {\n  UINT64_C(0x4000000000000000), UINT64_C(0x2000000000000000),\n  UINT64_C(0x0800000000000000), UINT64_C(0x0080000000000000),\n  UINT64_C(0x0000800000000000), UINT64_C(0x0000000080000000),\n  UINT64_C(0xc96c5795d7870f42), UINT64_C(0x6d5f4ad7e3c3afa0),\n  UINT64_C(0xd49f7e445077d8ea), UINT64_C(0x040fb02a53c216fa),\n  UINT64_C(0x6bec35957b9ef3a0), UINT64_C(0xb0e3bb0658964afe),\n  UINT64_C(0x218578c7a2dff638), UINT64_C(0x6dbb920f24dd5cf2),\n  UINT64_C(0x7a140cfcdb4d5eb5), UINT64_C(0x41b3705ecbc4057b),\n  UINT64_C(0xd46ab656accac1ea), UINT64_C(0x329beda6fc34fb73),\n  UINT64_C(0x51a4fcd4350b9797), UINT64_C(0x314fa85637efae9d),\n  UINT64_C(0xacf27e9a1518d512), UINT64_C(0xffe2a3388a4d8ce7),\n  UINT64_C(0x48b9697e60cc2e4e), UINT64_C(0xada73cb78dd62460),\n  UINT64_C(0x3ea5454d8ce5c1bb), UINT64_C(0x5e84e3a6c70feaf1),\n  UINT64_C(0x90fd49b66cbd81d1), UINT64_C(0xe2943e0c1db254e8),\n  UINT64_C(0xecfa6adeca8834a1), UINT64_C(0xf513e212593ee321),\n  UINT64_C(0xf36ae57331040916), UINT64_C(0x63fbd333b87b6717),\n  UINT64_C(0xbd60f8e152f50b8b), UINT64_C(0xa5ce4a8299c1567d),\n  UINT64_C(0x0bd445f0cbdb55ee), UINT64_C(0xfdd6824e20134285),\n  UINT64_C(0xcead8b6ebda2227a), UINT64_C(0xe44b17e4f5d4fb5c),\n  UINT64_C(0x9b29c81ad01ca7c5), UINT64_C(0x1b4366e40fea4055),\n  UINT64_C(0x27bca1551aae167b), UINT64_C(0xaa57bcd1b39a5690),\n  UINT64_C(0xd7fce83fa1234db9), UINT64_C(0xcce4986efea3ff8e),\n  UINT64_C(0x3602a4d9e65341f1), UINT64_C(0x722b1da2df516145),\n  UINT64_C(0xecfc3ddd3a08da83), UINT64_C(0x0fb96dcca83507e6),\n  UINT64_C(0x125f2fe78d70f080), UINT64_C(0x842f50b7651aa516),\n  UINT64_C(0x09bc34188cd9836f), UINT64_C(0xf43666c84196d909),\n  UINT64_C(0xb56feb30c0df6ccb), UINT64_C(0xaa66e04ce7f30958),\n  UINT64_C(0xb7b1187e9af29547), UINT64_C(0x113255f8476495de),\n  UINT64_C(0x8fb19f783095d77e), UINT64_C(0xaec4aacc7c82b133),\n  UINT64_C(0xf64e6d09218428cf), UINT64_C(0x036a72ea5ac258a0),\n  UINT64_C(0x5235ef12eb7aaa6a), UINT64_C(0x2fed7b1685657853),\n  UINT64_C(0x8ef8951d46606fb5), UINT64_C(0x9d58c1090f034d14)\n};\n\n\n\n\n\n\nstatic inline uint64_t crc64_multiply_(uint64_t a, uint64_t b) {\n  if ((a ^ (a-1)) < (b ^ (b-1))) {\n    uint64_t t = a;\n    a = b;\n    b = t;\n  }\n\n  if (a == 0)\n    return 0;\n\n  uint64_t r = 0, h = UINT64_C(1) << 63;\n  for (; a != 0; a <<= 1) {\n    if (a & h) {\n      r ^= b;\n      a ^= h;\n    }\n\n    b = (b >> 1) ^ ((b & 1) ? crc64_poly : 0);\n  }\n\n  return r;\n}\n\n\n\nstatic inline uint64_t crc64_x_pow_n_(uint64_t n) {\n  uint64_t r = UINT64_C(1) << 63;\n  for (size_t i = 0; n != 0; n >>= 1, ++i) {\n    if (n & 1)\n      r = crc64_multiply_(r, crc64_x_pow_2n[i]);\n  }\n\n  return r;\n}\n\nuint64_t crc64_combine(uint64_t cs1, uint64_t cs2, size_t nbytes2) {\n  \n\n  \n\n  return cs2 ^ crc64_multiply_(cs1, crc64_x_pow_n_(8*nbytes2));\n}\n\nstatic const size_t crc64_min_thread_bytes = 1024;\n\n__global__ void \ncrc64_kernel(size_t *d_thread_sz, \n\t\tuint64_t *d_thread_cs, \n\t\tconst unsigned char* d_data, \n\t\tconst uint64_t *d_crc64_table, \n\t\tconst uint64_t *d_crc64_interleaved_table, \n\t\tsize_t nbytes, int nthreads) \n{\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  size_t bpt = nbytes/nthreads;\n  const unsigned char *start = d_data + bpt*tid;\n  const unsigned char *end;\n  if (tid != nthreads - 1)\n    end = start + bpt;\n  else\n    end = d_data + nbytes;\n    \n  size_t sz = end - start;\n  d_thread_sz[tid] = sz;\n  d_thread_cs[tid] = crc64_device(start, sz, d_crc64_table, d_crc64_interleaved_table);\n}\n\nuint64_t crc64_parallel(const void *input, size_t nbytes) {\n\n  if (nbytes > 2*crc64_min_thread_bytes) {\n    int nthreads = 96*8*32; \n\n    if (nbytes < nthreads*crc64_min_thread_bytes)\n      nthreads = nbytes/crc64_min_thread_bytes;\n\n    uint64_t thread_cs[nthreads];\n    size_t thread_sz[nthreads];\n\n    const unsigned char *data = (const unsigned char*) input;\n\n    uint64_t *d_thread_cs;\n    uint64_t *d_crc64_table;\n    uint64_t *d_crc64_interleaved_table;\n    size_t *d_thread_sz;\n    unsigned char *d_data;\n\n    hipMalloc((void**)&d_thread_sz, nthreads * sizeof(size_t));\n    hipMalloc((void**)&d_thread_cs, nthreads * sizeof(uint64_t));\n    hipMalloc((void**)&d_data, nbytes);\n    hipMalloc((void**)&d_crc64_table, 4*256*sizeof(uint64_t));\n    hipMalloc((void**)&d_crc64_interleaved_table, 4*256*sizeof(uint64_t));\n\n    hipMemcpy(d_data, data, nbytes , hipMemcpyHostToDevice);\n    hipMemcpy(d_crc64_table, crc64_table, 4*256*sizeof(uint64_t) , hipMemcpyHostToDevice);\n    hipMemcpy(d_crc64_interleaved_table, crc64_interleaved_table, \n\t\t    4*256*sizeof(uint64_t) , hipMemcpyHostToDevice);\n\n    hipLaunchKernelGGL(crc64_kernel, nthreads/64, 64, 0, 0, d_thread_sz, d_thread_cs, d_data, \n\t\t    d_crc64_table, d_crc64_interleaved_table, nbytes, nthreads);\n\n    hipMemcpy(thread_sz, d_thread_sz, nthreads * sizeof(size_t), hipMemcpyDeviceToHost);\n    hipMemcpy(thread_cs, d_thread_cs, nthreads * sizeof(uint64_t), hipMemcpyDeviceToHost);\n\n    uint64_t cs = thread_cs[0];\n    for (int i = 1; i < nthreads; ++i) {\n      cs = crc64_combine(cs, thread_cs[i], thread_sz[i]);\n    }\n    hipFree(d_thread_sz); \n    hipFree(d_thread_cs);\n    hipFree(d_data);\n    hipFree(d_crc64_table);\n    hipFree(d_crc64_interleaved_table);\n    return cs;\n  }\n\n  return crc64(input, nbytes);\n}\n\n\n", "CRC64Test.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <ctime>\n#include <vector>\n#include <iostream>\n#include \"CRC64.h\"\n\n\n\nint main(int argc, char *argv[]) {\n  int ntests = 10;\n  if (argc > 1) ntests = atoi(argv[1]);\n\n  int seed = 5;\n  if (argc > 2) seed = atoi(argv[2]);\n\n  int max_test_length = 2097152;\n  if (argc > 3) max_test_length = atoi(argv[3]);\n\n  std::cout << \"Running \" << ntests << \" tests with seed \" << seed << std::endl;\n\n  srand48(seed);\n\n#ifdef __bgp__\n#define THE_CLOCK CLOCK_REALTIME\n#else\n#define THE_CLOCK CLOCK_THREAD_CPUTIME_ID\n#endif\n\n  double tot_time = 0, tot_bytes = 0;\n\n  int ntest = 0;\n  while (++ntest <= ntests) {\n    std::cout << ntest << \" \";\n\n    size_t test_length = (size_t) (max_test_length*(drand48()+1));\n    std::cout << test_length << \" \";\n\n    std::vector<unsigned char> input_buffer(test_length);\n\n    for (size_t i = 0; i < test_length; ++i) {\n      input_buffer[i] = (unsigned char) (255*drand48());\n    }\n\n    timespec b_start, b_end;\n    clock_gettime(THE_CLOCK, &b_start);\n\n    uint64_t cs = crc64_parallel(&input_buffer[0], test_length);\n\n    clock_gettime(THE_CLOCK, &b_end);\n    double b_time = (b_end.tv_sec - b_start.tv_sec);\n    b_time += 1e-9*(b_end.tv_nsec - b_start.tv_nsec);\n\n    if (ntest > 1) {\n      tot_time += b_time;\n      tot_bytes += test_length;\n    }\n\n    \n\n    size_t tlend = 8;\n    input_buffer.resize(test_length + tlend, 0);\n    crc64_invert(cs, &input_buffer[test_length]);\n\n    std::string pass(\"pass\"), fail(\"fail\");\n    uint64_t csc = crc64(&input_buffer[0], test_length+tlend);\n    std::cout << ((csc == (uint64_t) -1) ? pass : fail) << \" \";\n\n    size_t div_pt = (size_t) (test_length*drand48());\n    uint64_t cs1 = crc64(&input_buffer[0], div_pt);\n    uint64_t cs2 = crc64(&input_buffer[div_pt], test_length - div_pt);\n    csc = crc64_combine(cs1, cs2, test_length - div_pt);\n    std::cout << ((csc == cs) ? pass : fail);\n\n    std::cout << std::endl;\n  }\n\n  std::cout << (tot_bytes/(1024*1024))/tot_time << \" MB/s\" << std::endl;\n\n  return 0;\n}\n"}}
{"kernel_name": "crc64", "parallel_api": "omp", "code": {"CRC64.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef __STDC_CONSTANT_MACROS\n#define __STDC_CONSTANT_MACROS\n#endif\n\n#include \"CRC64.h\"\n\n#ifdef HAVE_CONFIG_H\n#include <config.h>\n#endif\n\n#ifdef _OPENMP\n#include <omp.h>\n#endif\n\n#include <stdbool.h>\n\n\n\nstatic const uint64_t crc64_poly = UINT64_C(0xc96c5795d7870f42);\n\n#pragma omp declare target\nstatic const uint64_t crc64_table[4][256] = {\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x1dee8a5e222ca1dc),\n    UINT64_C(0x3bdd14bc445943b8), UINT64_C(0x26339ee26675e264),\n    UINT64_C(0x77ba297888b28770), UINT64_C(0x6a54a326aa9e26ac),\n    UINT64_C(0x4c673dc4ccebc4c8), UINT64_C(0x5189b79aeec76514),\n    UINT64_C(0xef7452f111650ee0), UINT64_C(0xf29ad8af3349af3c),\n    UINT64_C(0xd4a9464d553c4d58), UINT64_C(0xc947cc137710ec84),\n    UINT64_C(0x98ce7b8999d78990), UINT64_C(0x8520f1d7bbfb284c),\n    UINT64_C(0xa3136f35dd8eca28), UINT64_C(0xbefde56bffa26bf4),\n    UINT64_C(0x4c300ac98dc40345), UINT64_C(0x51de8097afe8a299),\n    UINT64_C(0x77ed1e75c99d40fd), UINT64_C(0x6a03942bebb1e121),\n    UINT64_C(0x3b8a23b105768435), UINT64_C(0x2664a9ef275a25e9),\n    UINT64_C(0x0057370d412fc78d), UINT64_C(0x1db9bd5363036651),\n    UINT64_C(0xa34458389ca10da5), UINT64_C(0xbeaad266be8dac79),\n    UINT64_C(0x98994c84d8f84e1d), UINT64_C(0x8577c6dafad4efc1),\n    UINT64_C(0xd4fe714014138ad5), UINT64_C(0xc910fb1e363f2b09),\n    UINT64_C(0xef2365fc504ac96d), UINT64_C(0xf2cdefa2726668b1),\n    UINT64_C(0x986015931b88068a), UINT64_C(0x858e9fcd39a4a756),\n    UINT64_C(0xa3bd012f5fd14532), UINT64_C(0xbe538b717dfde4ee),\n    UINT64_C(0xefda3ceb933a81fa), UINT64_C(0xf234b6b5b1162026),\n    UINT64_C(0xd4072857d763c242), UINT64_C(0xc9e9a209f54f639e),\n    UINT64_C(0x771447620aed086a), UINT64_C(0x6afacd3c28c1a9b6),\n    UINT64_C(0x4cc953de4eb44bd2), UINT64_C(0x5127d9806c98ea0e),\n    UINT64_C(0x00ae6e1a825f8f1a), UINT64_C(0x1d40e444a0732ec6),\n    UINT64_C(0x3b737aa6c606cca2), UINT64_C(0x269df0f8e42a6d7e),\n    UINT64_C(0xd4501f5a964c05cf), UINT64_C(0xc9be9504b460a413),\n    UINT64_C(0xef8d0be6d2154677), UINT64_C(0xf26381b8f039e7ab),\n    UINT64_C(0xa3ea36221efe82bf), UINT64_C(0xbe04bc7c3cd22363),\n    UINT64_C(0x9837229e5aa7c107), UINT64_C(0x85d9a8c0788b60db),\n    UINT64_C(0x3b244dab87290b2f), UINT64_C(0x26cac7f5a505aaf3),\n    UINT64_C(0x00f95917c3704897), UINT64_C(0x1d17d349e15ce94b),\n    UINT64_C(0x4c9e64d30f9b8c5f), UINT64_C(0x5170ee8d2db72d83),\n    UINT64_C(0x7743706f4bc2cfe7), UINT64_C(0x6aadfa3169ee6e3b),\n    UINT64_C(0xa218840d981e1391), UINT64_C(0xbff60e53ba32b24d),\n    UINT64_C(0x99c590b1dc475029), UINT64_C(0x842b1aeffe6bf1f5),\n    UINT64_C(0xd5a2ad7510ac94e1), UINT64_C(0xc84c272b3280353d),\n    UINT64_C(0xee7fb9c954f5d759), UINT64_C(0xf391339776d97685),\n    UINT64_C(0x4d6cd6fc897b1d71), UINT64_C(0x50825ca2ab57bcad),\n    UINT64_C(0x76b1c240cd225ec9), UINT64_C(0x6b5f481eef0eff15),\n    UINT64_C(0x3ad6ff8401c99a01), UINT64_C(0x273875da23e53bdd),\n    UINT64_C(0x010beb384590d9b9), UINT64_C(0x1ce5616667bc7865),\n    UINT64_C(0xee288ec415da10d4), UINT64_C(0xf3c6049a37f6b108),\n    UINT64_C(0xd5f59a785183536c), UINT64_C(0xc81b102673aff2b0),\n    UINT64_C(0x9992a7bc9d6897a4), UINT64_C(0x847c2de2bf443678),\n    UINT64_C(0xa24fb300d931d41c), UINT64_C(0xbfa1395efb1d75c0),\n    UINT64_C(0x015cdc3504bf1e34), UINT64_C(0x1cb2566b2693bfe8),\n    UINT64_C(0x3a81c88940e65d8c), UINT64_C(0x276f42d762cafc50),\n    UINT64_C(0x76e6f54d8c0d9944), UINT64_C(0x6b087f13ae213898),\n    UINT64_C(0x4d3be1f1c854dafc), UINT64_C(0x50d56bafea787b20),\n    UINT64_C(0x3a78919e8396151b), UINT64_C(0x27961bc0a1bab4c7),\n    UINT64_C(0x01a58522c7cf56a3), UINT64_C(0x1c4b0f7ce5e3f77f),\n    UINT64_C(0x4dc2b8e60b24926b), UINT64_C(0x502c32b8290833b7),\n    UINT64_C(0x761fac5a4f7dd1d3), UINT64_C(0x6bf126046d51700f),\n    UINT64_C(0xd50cc36f92f31bfb), UINT64_C(0xc8e24931b0dfba27),\n    UINT64_C(0xeed1d7d3d6aa5843), UINT64_C(0xf33f5d8df486f99f),\n    UINT64_C(0xa2b6ea171a419c8b), UINT64_C(0xbf586049386d3d57),\n    UINT64_C(0x996bfeab5e18df33), UINT64_C(0x848574f57c347eef),\n    UINT64_C(0x76489b570e52165e), UINT64_C(0x6ba611092c7eb782),\n    UINT64_C(0x4d958feb4a0b55e6), UINT64_C(0x507b05b56827f43a),\n    UINT64_C(0x01f2b22f86e0912e), UINT64_C(0x1c1c3871a4cc30f2),\n    UINT64_C(0x3a2fa693c2b9d296), UINT64_C(0x27c12ccde095734a),\n    UINT64_C(0x993cc9a61f3718be), UINT64_C(0x84d243f83d1bb962),\n    UINT64_C(0xa2e1dd1a5b6e5b06), UINT64_C(0xbf0f57447942fada),\n    UINT64_C(0xee86e0de97859fce), UINT64_C(0xf3686a80b5a93e12),\n    UINT64_C(0xd55bf462d3dcdc76), UINT64_C(0xc8b57e3cf1f07daa),\n    UINT64_C(0xd6e9a7309f3239a7), UINT64_C(0xcb072d6ebd1e987b),\n    UINT64_C(0xed34b38cdb6b7a1f), UINT64_C(0xf0da39d2f947dbc3),\n    UINT64_C(0xa1538e481780bed7), UINT64_C(0xbcbd041635ac1f0b),\n    UINT64_C(0x9a8e9af453d9fd6f), UINT64_C(0x876010aa71f55cb3),\n    UINT64_C(0x399df5c18e573747), UINT64_C(0x24737f9fac7b969b),\n    UINT64_C(0x0240e17dca0e74ff), UINT64_C(0x1fae6b23e822d523),\n    UINT64_C(0x4e27dcb906e5b037), UINT64_C(0x53c956e724c911eb),\n    UINT64_C(0x75fac80542bcf38f), UINT64_C(0x6814425b60905253),\n    UINT64_C(0x9ad9adf912f63ae2), UINT64_C(0x873727a730da9b3e),\n    UINT64_C(0xa104b94556af795a), UINT64_C(0xbcea331b7483d886),\n    UINT64_C(0xed6384819a44bd92), UINT64_C(0xf08d0edfb8681c4e),\n    UINT64_C(0xd6be903dde1dfe2a), UINT64_C(0xcb501a63fc315ff6),\n    UINT64_C(0x75adff0803933402), UINT64_C(0x6843755621bf95de),\n    UINT64_C(0x4e70ebb447ca77ba), UINT64_C(0x539e61ea65e6d666),\n    UINT64_C(0x0217d6708b21b372), UINT64_C(0x1ff95c2ea90d12ae),\n    UINT64_C(0x39cac2cccf78f0ca), UINT64_C(0x24244892ed545116),\n    UINT64_C(0x4e89b2a384ba3f2d), UINT64_C(0x536738fda6969ef1),\n    UINT64_C(0x7554a61fc0e37c95), UINT64_C(0x68ba2c41e2cfdd49),\n    UINT64_C(0x39339bdb0c08b85d), UINT64_C(0x24dd11852e241981),\n    UINT64_C(0x02ee8f674851fbe5), UINT64_C(0x1f0005396a7d5a39),\n    UINT64_C(0xa1fde05295df31cd), UINT64_C(0xbc136a0cb7f39011),\n    UINT64_C(0x9a20f4eed1867275), UINT64_C(0x87ce7eb0f3aad3a9),\n    UINT64_C(0xd647c92a1d6db6bd), UINT64_C(0xcba943743f411761),\n    UINT64_C(0xed9add965934f505), UINT64_C(0xf07457c87b1854d9),\n    UINT64_C(0x02b9b86a097e3c68), UINT64_C(0x1f5732342b529db4),\n    UINT64_C(0x3964acd64d277fd0), UINT64_C(0x248a26886f0bde0c),\n    UINT64_C(0x7503911281ccbb18), UINT64_C(0x68ed1b4ca3e01ac4),\n    UINT64_C(0x4ede85aec595f8a0), UINT64_C(0x53300ff0e7b9597c),\n    UINT64_C(0xedcdea9b181b3288), UINT64_C(0xf02360c53a379354),\n    UINT64_C(0xd610fe275c427130), UINT64_C(0xcbfe74797e6ed0ec),\n    UINT64_C(0x9a77c3e390a9b5f8), UINT64_C(0x879949bdb2851424),\n    UINT64_C(0xa1aad75fd4f0f640), UINT64_C(0xbc445d01f6dc579c),\n    UINT64_C(0x74f1233d072c2a36), UINT64_C(0x691fa96325008bea),\n    UINT64_C(0x4f2c37814375698e), UINT64_C(0x52c2bddf6159c852),\n    UINT64_C(0x034b0a458f9ead46), UINT64_C(0x1ea5801badb20c9a),\n    UINT64_C(0x38961ef9cbc7eefe), UINT64_C(0x257894a7e9eb4f22),\n    UINT64_C(0x9b8571cc164924d6), UINT64_C(0x866bfb923465850a),\n    UINT64_C(0xa05865705210676e), UINT64_C(0xbdb6ef2e703cc6b2),\n    UINT64_C(0xec3f58b49efba3a6), UINT64_C(0xf1d1d2eabcd7027a),\n    UINT64_C(0xd7e24c08daa2e01e), UINT64_C(0xca0cc656f88e41c2),\n    UINT64_C(0x38c129f48ae82973), UINT64_C(0x252fa3aaa8c488af),\n    UINT64_C(0x031c3d48ceb16acb), UINT64_C(0x1ef2b716ec9dcb17),\n    UINT64_C(0x4f7b008c025aae03), UINT64_C(0x52958ad220760fdf),\n    UINT64_C(0x74a614304603edbb), UINT64_C(0x69489e6e642f4c67),\n    UINT64_C(0xd7b57b059b8d2793), UINT64_C(0xca5bf15bb9a1864f),\n    UINT64_C(0xec686fb9dfd4642b), UINT64_C(0xf186e5e7fdf8c5f7),\n    UINT64_C(0xa00f527d133fa0e3), UINT64_C(0xbde1d8233113013f),\n    UINT64_C(0x9bd246c15766e35b), UINT64_C(0x863ccc9f754a4287),\n    UINT64_C(0xec9136ae1ca42cbc), UINT64_C(0xf17fbcf03e888d60),\n    UINT64_C(0xd74c221258fd6f04), UINT64_C(0xcaa2a84c7ad1ced8),\n    UINT64_C(0x9b2b1fd69416abcc), UINT64_C(0x86c59588b63a0a10),\n    UINT64_C(0xa0f60b6ad04fe874), UINT64_C(0xbd188134f26349a8),\n    UINT64_C(0x03e5645f0dc1225c), UINT64_C(0x1e0bee012fed8380),\n    UINT64_C(0x383870e3499861e4), UINT64_C(0x25d6fabd6bb4c038),\n    UINT64_C(0x745f4d278573a52c), UINT64_C(0x69b1c779a75f04f0),\n    UINT64_C(0x4f82599bc12ae694), UINT64_C(0x526cd3c5e3064748),\n    UINT64_C(0xa0a13c6791602ff9), UINT64_C(0xbd4fb639b34c8e25),\n    UINT64_C(0x9b7c28dbd5396c41), UINT64_C(0x8692a285f715cd9d),\n    UINT64_C(0xd71b151f19d2a889), UINT64_C(0xcaf59f413bfe0955),\n    UINT64_C(0xecc601a35d8beb31), UINT64_C(0xf1288bfd7fa74aed),\n    UINT64_C(0x4fd56e9680052119), UINT64_C(0x523be4c8a22980c5),\n    UINT64_C(0x74087a2ac45c62a1), UINT64_C(0x69e6f074e670c37d),\n    UINT64_C(0x386f47ee08b7a669), UINT64_C(0x2581cdb02a9b07b5),\n    UINT64_C(0x03b253524ceee5d1), UINT64_C(0x1e5cd90c6ec2440d)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x3f0be14a916a6dcb),\n    UINT64_C(0x7e17c29522d4db96), UINT64_C(0x411c23dfb3beb65d),\n    UINT64_C(0xfc2f852a45a9b72c), UINT64_C(0xc3246460d4c3dae7),\n    UINT64_C(0x823847bf677d6cba), UINT64_C(0xbd33a6f5f6170171),\n    UINT64_C(0x6a87a57f245d70dd), UINT64_C(0x558c4435b5371d16),\n    UINT64_C(0x149067ea0689ab4b), UINT64_C(0x2b9b86a097e3c680),\n    UINT64_C(0x96a8205561f4c7f1), UINT64_C(0xa9a3c11ff09eaa3a),\n    UINT64_C(0xe8bfe2c043201c67), UINT64_C(0xd7b4038ad24a71ac),\n    UINT64_C(0xd50f4afe48bae1ba), UINT64_C(0xea04abb4d9d08c71),\n    UINT64_C(0xab18886b6a6e3a2c), UINT64_C(0x94136921fb0457e7),\n    UINT64_C(0x2920cfd40d135696), UINT64_C(0x162b2e9e9c793b5d),\n    UINT64_C(0x57370d412fc78d00), UINT64_C(0x683cec0bbeade0cb),\n    UINT64_C(0xbf88ef816ce79167), UINT64_C(0x80830ecbfd8dfcac),\n    UINT64_C(0xc19f2d144e334af1), UINT64_C(0xfe94cc5edf59273a),\n    UINT64_C(0x43a76aab294e264b), UINT64_C(0x7cac8be1b8244b80),\n    UINT64_C(0x3db0a83e0b9afddd), UINT64_C(0x02bb49749af09016),\n    UINT64_C(0x38c63ad73e7bddf1), UINT64_C(0x07cddb9daf11b03a),\n    UINT64_C(0x46d1f8421caf0667), UINT64_C(0x79da19088dc56bac),\n    UINT64_C(0xc4e9bffd7bd26add), UINT64_C(0xfbe25eb7eab80716),\n    UINT64_C(0xbafe7d685906b14b), UINT64_C(0x85f59c22c86cdc80),\n    UINT64_C(0x52419fa81a26ad2c), UINT64_C(0x6d4a7ee28b4cc0e7),\n    UINT64_C(0x2c565d3d38f276ba), UINT64_C(0x135dbc77a9981b71),\n    UINT64_C(0xae6e1a825f8f1a00), UINT64_C(0x9165fbc8cee577cb),\n    UINT64_C(0xd079d8177d5bc196), UINT64_C(0xef72395dec31ac5d),\n    UINT64_C(0xedc9702976c13c4b), UINT64_C(0xd2c29163e7ab5180),\n    UINT64_C(0x93deb2bc5415e7dd), UINT64_C(0xacd553f6c57f8a16),\n    UINT64_C(0x11e6f50333688b67), UINT64_C(0x2eed1449a202e6ac),\n    UINT64_C(0x6ff1379611bc50f1), UINT64_C(0x50fad6dc80d63d3a),\n    UINT64_C(0x874ed556529c4c96), UINT64_C(0xb845341cc3f6215d),\n    UINT64_C(0xf95917c370489700), UINT64_C(0xc652f689e122facb),\n    UINT64_C(0x7b61507c1735fbba), UINT64_C(0x446ab136865f9671),\n    UINT64_C(0x057692e935e1202c), UINT64_C(0x3a7d73a3a48b4de7),\n    UINT64_C(0x718c75ae7cf7bbe2), UINT64_C(0x4e8794e4ed9dd629),\n    UINT64_C(0x0f9bb73b5e236074), UINT64_C(0x30905671cf490dbf),\n    UINT64_C(0x8da3f084395e0cce), UINT64_C(0xb2a811cea8346105),\n    UINT64_C(0xf3b432111b8ad758), UINT64_C(0xccbfd35b8ae0ba93),\n    UINT64_C(0x1b0bd0d158aacb3f), UINT64_C(0x2400319bc9c0a6f4),\n    UINT64_C(0x651c12447a7e10a9), UINT64_C(0x5a17f30eeb147d62),\n    UINT64_C(0xe72455fb1d037c13), UINT64_C(0xd82fb4b18c6911d8),\n    UINT64_C(0x9933976e3fd7a785), UINT64_C(0xa6387624aebdca4e),\n    UINT64_C(0xa4833f50344d5a58), UINT64_C(0x9b88de1aa5273793),\n    UINT64_C(0xda94fdc5169981ce), UINT64_C(0xe59f1c8f87f3ec05),\n    UINT64_C(0x58acba7a71e4ed74), UINT64_C(0x67a75b30e08e80bf),\n    UINT64_C(0x26bb78ef533036e2), UINT64_C(0x19b099a5c25a5b29),\n    UINT64_C(0xce049a2f10102a85), UINT64_C(0xf10f7b65817a474e),\n    UINT64_C(0xb01358ba32c4f113), UINT64_C(0x8f18b9f0a3ae9cd8),\n    UINT64_C(0x322b1f0555b99da9), UINT64_C(0x0d20fe4fc4d3f062),\n    UINT64_C(0x4c3cdd90776d463f), UINT64_C(0x73373cdae6072bf4),\n    UINT64_C(0x494a4f79428c6613), UINT64_C(0x7641ae33d3e60bd8),\n    UINT64_C(0x375d8dec6058bd85), UINT64_C(0x08566ca6f132d04e),\n    UINT64_C(0xb565ca530725d13f), UINT64_C(0x8a6e2b19964fbcf4),\n    UINT64_C(0xcb7208c625f10aa9), UINT64_C(0xf479e98cb49b6762),\n    UINT64_C(0x23cdea0666d116ce), UINT64_C(0x1cc60b4cf7bb7b05),\n    UINT64_C(0x5dda28934405cd58), UINT64_C(0x62d1c9d9d56fa093),\n    UINT64_C(0xdfe26f2c2378a1e2), UINT64_C(0xe0e98e66b212cc29),\n    UINT64_C(0xa1f5adb901ac7a74), UINT64_C(0x9efe4cf390c617bf),\n    UINT64_C(0x9c4505870a3687a9), UINT64_C(0xa34ee4cd9b5cea62),\n    UINT64_C(0xe252c71228e25c3f), UINT64_C(0xdd592658b98831f4),\n    UINT64_C(0x606a80ad4f9f3085), UINT64_C(0x5f6161e7def55d4e),\n    UINT64_C(0x1e7d42386d4beb13), UINT64_C(0x2176a372fc2186d8),\n    UINT64_C(0xf6c2a0f82e6bf774), UINT64_C(0xc9c941b2bf019abf),\n    UINT64_C(0x88d5626d0cbf2ce2), UINT64_C(0xb7de83279dd54129),\n    UINT64_C(0x0aed25d26bc24058), UINT64_C(0x35e6c498faa82d93),\n    UINT64_C(0x74fae74749169bce), UINT64_C(0x4bf1060dd87cf605),\n    UINT64_C(0xe318eb5cf9ef77c4), UINT64_C(0xdc130a1668851a0f),\n    UINT64_C(0x9d0f29c9db3bac52), UINT64_C(0xa204c8834a51c199),\n    UINT64_C(0x1f376e76bc46c0e8), UINT64_C(0x203c8f3c2d2cad23),\n    UINT64_C(0x6120ace39e921b7e), UINT64_C(0x5e2b4da90ff876b5),\n    UINT64_C(0x899f4e23ddb20719), UINT64_C(0xb694af694cd86ad2),\n    UINT64_C(0xf7888cb6ff66dc8f), UINT64_C(0xc8836dfc6e0cb144),\n    UINT64_C(0x75b0cb09981bb035), UINT64_C(0x4abb2a430971ddfe),\n    UINT64_C(0x0ba7099cbacf6ba3), UINT64_C(0x34ace8d62ba50668),\n    UINT64_C(0x3617a1a2b155967e), UINT64_C(0x091c40e8203ffbb5),\n    UINT64_C(0x4800633793814de8), UINT64_C(0x770b827d02eb2023),\n    UINT64_C(0xca382488f4fc2152), UINT64_C(0xf533c5c265964c99),\n    UINT64_C(0xb42fe61dd628fac4), UINT64_C(0x8b2407574742970f),\n    UINT64_C(0x5c9004dd9508e6a3), UINT64_C(0x639be59704628b68),\n    UINT64_C(0x2287c648b7dc3d35), UINT64_C(0x1d8c270226b650fe),\n    UINT64_C(0xa0bf81f7d0a1518f), UINT64_C(0x9fb460bd41cb3c44),\n    UINT64_C(0xdea84362f2758a19), UINT64_C(0xe1a3a228631fe7d2),\n    UINT64_C(0xdbded18bc794aa35), UINT64_C(0xe4d530c156fec7fe),\n    UINT64_C(0xa5c9131ee54071a3), UINT64_C(0x9ac2f254742a1c68),\n    UINT64_C(0x27f154a1823d1d19), UINT64_C(0x18fab5eb135770d2),\n    UINT64_C(0x59e69634a0e9c68f), UINT64_C(0x66ed777e3183ab44),\n    UINT64_C(0xb15974f4e3c9dae8), UINT64_C(0x8e5295be72a3b723),\n    UINT64_C(0xcf4eb661c11d017e), UINT64_C(0xf045572b50776cb5),\n    UINT64_C(0x4d76f1dea6606dc4), UINT64_C(0x727d1094370a000f),\n    UINT64_C(0x3361334b84b4b652), UINT64_C(0x0c6ad20115dedb99),\n    UINT64_C(0x0ed19b758f2e4b8f), UINT64_C(0x31da7a3f1e442644),\n    UINT64_C(0x70c659e0adfa9019), UINT64_C(0x4fcdb8aa3c90fdd2),\n    UINT64_C(0xf2fe1e5fca87fca3), UINT64_C(0xcdf5ff155bed9168),\n    UINT64_C(0x8ce9dccae8532735), UINT64_C(0xb3e23d8079394afe),\n    UINT64_C(0x64563e0aab733b52), UINT64_C(0x5b5ddf403a195699),\n    UINT64_C(0x1a41fc9f89a7e0c4), UINT64_C(0x254a1dd518cd8d0f),\n    UINT64_C(0x9879bb20eeda8c7e), UINT64_C(0xa7725a6a7fb0e1b5),\n    UINT64_C(0xe66e79b5cc0e57e8), UINT64_C(0xd96598ff5d643a23),\n    UINT64_C(0x92949ef28518cc26), UINT64_C(0xad9f7fb81472a1ed),\n    UINT64_C(0xec835c67a7cc17b0), UINT64_C(0xd388bd2d36a67a7b),\n    UINT64_C(0x6ebb1bd8c0b17b0a), UINT64_C(0x51b0fa9251db16c1),\n    UINT64_C(0x10acd94de265a09c), UINT64_C(0x2fa73807730fcd57),\n    UINT64_C(0xf8133b8da145bcfb), UINT64_C(0xc718dac7302fd130),\n    UINT64_C(0x8604f9188391676d), UINT64_C(0xb90f185212fb0aa6),\n    UINT64_C(0x043cbea7e4ec0bd7), UINT64_C(0x3b375fed7586661c),\n    UINT64_C(0x7a2b7c32c638d041), UINT64_C(0x45209d785752bd8a),\n    UINT64_C(0x479bd40ccda22d9c), UINT64_C(0x789035465cc84057),\n    UINT64_C(0x398c1699ef76f60a), UINT64_C(0x0687f7d37e1c9bc1),\n    UINT64_C(0xbbb45126880b9ab0), UINT64_C(0x84bfb06c1961f77b),\n    UINT64_C(0xc5a393b3aadf4126), UINT64_C(0xfaa872f93bb52ced),\n    UINT64_C(0x2d1c7173e9ff5d41), UINT64_C(0x121790397895308a),\n    UINT64_C(0x530bb3e6cb2b86d7), UINT64_C(0x6c0052ac5a41eb1c),\n    UINT64_C(0xd133f459ac56ea6d), UINT64_C(0xee3815133d3c87a6),\n    UINT64_C(0xaf2436cc8e8231fb), UINT64_C(0x902fd7861fe85c30),\n    UINT64_C(0xaa52a425bb6311d7), UINT64_C(0x9559456f2a097c1c),\n    UINT64_C(0xd44566b099b7ca41), UINT64_C(0xeb4e87fa08dda78a),\n    UINT64_C(0x567d210ffecaa6fb), UINT64_C(0x6976c0456fa0cb30),\n    UINT64_C(0x286ae39adc1e7d6d), UINT64_C(0x176102d04d7410a6),\n    UINT64_C(0xc0d5015a9f3e610a), UINT64_C(0xffdee0100e540cc1),\n    UINT64_C(0xbec2c3cfbdeaba9c), UINT64_C(0x81c922852c80d757),\n    UINT64_C(0x3cfa8470da97d626), UINT64_C(0x03f1653a4bfdbbed),\n    UINT64_C(0x42ed46e5f8430db0), UINT64_C(0x7de6a7af6929607b),\n    UINT64_C(0x7f5deedbf3d9f06d), UINT64_C(0x40560f9162b39da6),\n    UINT64_C(0x014a2c4ed10d2bfb), UINT64_C(0x3e41cd0440674630),\n    UINT64_C(0x83726bf1b6704741), UINT64_C(0xbc798abb271a2a8a),\n    UINT64_C(0xfd65a96494a49cd7), UINT64_C(0xc26e482e05cef11c),\n    UINT64_C(0x15da4ba4d78480b0), UINT64_C(0x2ad1aaee46eeed7b),\n    UINT64_C(0x6bcd8931f5505b26), UINT64_C(0x54c6687b643a36ed),\n    UINT64_C(0xe9f5ce8e922d379c), UINT64_C(0xd6fe2fc403475a57),\n    UINT64_C(0x97e20c1bb0f9ec0a), UINT64_C(0xa8e9ed51219381c1)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x54e979925cd0f10d),\n    UINT64_C(0xa9d2f324b9a1e21a), UINT64_C(0xfd3b8ab6e5711317),\n    UINT64_C(0xc17d4962dc4ddab1), UINT64_C(0x959430f0809d2bbc),\n    UINT64_C(0x68afba4665ec38ab), UINT64_C(0x3c46c3d4393cc9a6),\n    UINT64_C(0x10223dee1795abe7), UINT64_C(0x44cb447c4b455aea),\n    UINT64_C(0xb9f0cecaae3449fd), UINT64_C(0xed19b758f2e4b8f0),\n    UINT64_C(0xd15f748ccbd87156), UINT64_C(0x85b60d1e9708805b),\n    UINT64_C(0x788d87a87279934c), UINT64_C(0x2c64fe3a2ea96241),\n    UINT64_C(0x20447bdc2f2b57ce), UINT64_C(0x74ad024e73fba6c3),\n    UINT64_C(0x899688f8968ab5d4), UINT64_C(0xdd7ff16aca5a44d9),\n    UINT64_C(0xe13932bef3668d7f), UINT64_C(0xb5d04b2cafb67c72),\n    UINT64_C(0x48ebc19a4ac76f65), UINT64_C(0x1c02b80816179e68),\n    UINT64_C(0x3066463238befc29), UINT64_C(0x648f3fa0646e0d24),\n    UINT64_C(0x99b4b516811f1e33), UINT64_C(0xcd5dcc84ddcfef3e),\n    UINT64_C(0xf11b0f50e4f32698), UINT64_C(0xa5f276c2b823d795),\n    UINT64_C(0x58c9fc745d52c482), UINT64_C(0x0c2085e60182358f),\n    UINT64_C(0x4088f7b85e56af9c), UINT64_C(0x14618e2a02865e91),\n    UINT64_C(0xe95a049ce7f74d86), UINT64_C(0xbdb37d0ebb27bc8b),\n    UINT64_C(0x81f5beda821b752d), UINT64_C(0xd51cc748decb8420),\n    UINT64_C(0x28274dfe3bba9737), UINT64_C(0x7cce346c676a663a),\n    UINT64_C(0x50aaca5649c3047b), UINT64_C(0x0443b3c41513f576),\n    UINT64_C(0xf9783972f062e661), UINT64_C(0xad9140e0acb2176c),\n    UINT64_C(0x91d78334958edeca), UINT64_C(0xc53efaa6c95e2fc7),\n    UINT64_C(0x380570102c2f3cd0), UINT64_C(0x6cec098270ffcddd),\n    UINT64_C(0x60cc8c64717df852), UINT64_C(0x3425f5f62dad095f),\n    UINT64_C(0xc91e7f40c8dc1a48), UINT64_C(0x9df706d2940ceb45),\n    UINT64_C(0xa1b1c506ad3022e3), UINT64_C(0xf558bc94f1e0d3ee),\n    UINT64_C(0x086336221491c0f9), UINT64_C(0x5c8a4fb0484131f4),\n    UINT64_C(0x70eeb18a66e853b5), UINT64_C(0x2407c8183a38a2b8),\n    UINT64_C(0xd93c42aedf49b1af), UINT64_C(0x8dd53b3c839940a2),\n    UINT64_C(0xb193f8e8baa58904), UINT64_C(0xe57a817ae6757809),\n    UINT64_C(0x18410bcc03046b1e), UINT64_C(0x4ca8725e5fd49a13),\n    UINT64_C(0x8111ef70bcad5f38), UINT64_C(0xd5f896e2e07dae35),\n    UINT64_C(0x28c31c54050cbd22), UINT64_C(0x7c2a65c659dc4c2f),\n    UINT64_C(0x406ca61260e08589), UINT64_C(0x1485df803c307484),\n    UINT64_C(0xe9be5536d9416793), UINT64_C(0xbd572ca48591969e),\n    UINT64_C(0x9133d29eab38f4df), UINT64_C(0xc5daab0cf7e805d2),\n    UINT64_C(0x38e121ba129916c5), UINT64_C(0x6c0858284e49e7c8),\n    UINT64_C(0x504e9bfc77752e6e), UINT64_C(0x04a7e26e2ba5df63),\n    UINT64_C(0xf99c68d8ced4cc74), UINT64_C(0xad75114a92043d79),\n    UINT64_C(0xa15594ac938608f6), UINT64_C(0xf5bced3ecf56f9fb),\n    UINT64_C(0x088767882a27eaec), UINT64_C(0x5c6e1e1a76f71be1),\n    UINT64_C(0x6028ddce4fcbd247), UINT64_C(0x34c1a45c131b234a),\n    UINT64_C(0xc9fa2eeaf66a305d), UINT64_C(0x9d135778aabac150),\n    UINT64_C(0xb177a9428413a311), UINT64_C(0xe59ed0d0d8c3521c),\n    UINT64_C(0x18a55a663db2410b), UINT64_C(0x4c4c23f46162b006),\n    UINT64_C(0x700ae020585e79a0), UINT64_C(0x24e399b2048e88ad),\n    UINT64_C(0xd9d81304e1ff9bba), UINT64_C(0x8d316a96bd2f6ab7),\n    UINT64_C(0xc19918c8e2fbf0a4), UINT64_C(0x9570615abe2b01a9),\n    UINT64_C(0x684bebec5b5a12be), UINT64_C(0x3ca2927e078ae3b3),\n    UINT64_C(0x00e451aa3eb62a15), UINT64_C(0x540d28386266db18),\n    UINT64_C(0xa936a28e8717c80f), UINT64_C(0xfddfdb1cdbc73902),\n    UINT64_C(0xd1bb2526f56e5b43), UINT64_C(0x85525cb4a9beaa4e),\n    UINT64_C(0x7869d6024ccfb959), UINT64_C(0x2c80af90101f4854),\n    UINT64_C(0x10c66c44292381f2), UINT64_C(0x442f15d675f370ff),\n    UINT64_C(0xb9149f60908263e8), UINT64_C(0xedfde6f2cc5292e5),\n    UINT64_C(0xe1dd6314cdd0a76a), UINT64_C(0xb5341a8691005667),\n    UINT64_C(0x480f903074714570), UINT64_C(0x1ce6e9a228a1b47d),\n    UINT64_C(0x20a02a76119d7ddb), UINT64_C(0x744953e44d4d8cd6),\n    UINT64_C(0x8972d952a83c9fc1), UINT64_C(0xdd9ba0c0f4ec6ecc),\n    UINT64_C(0xf1ff5efada450c8d), UINT64_C(0xa51627688695fd80),\n    UINT64_C(0x582dadde63e4ee97), UINT64_C(0x0cc4d44c3f341f9a),\n    UINT64_C(0x308217980608d63c), UINT64_C(0x646b6e0a5ad82731),\n    UINT64_C(0x9950e4bcbfa93426), UINT64_C(0xcdb99d2ee379c52b),\n    UINT64_C(0x90fb71cad654a0f5), UINT64_C(0xc41208588a8451f8),\n    UINT64_C(0x392982ee6ff542ef), UINT64_C(0x6dc0fb7c3325b3e2),\n    UINT64_C(0x518638a80a197a44), UINT64_C(0x056f413a56c98b49),\n    UINT64_C(0xf854cb8cb3b8985e), UINT64_C(0xacbdb21eef686953),\n    UINT64_C(0x80d94c24c1c10b12), UINT64_C(0xd43035b69d11fa1f),\n    UINT64_C(0x290bbf007860e908), UINT64_C(0x7de2c69224b01805),\n    UINT64_C(0x41a405461d8cd1a3), UINT64_C(0x154d7cd4415c20ae),\n    UINT64_C(0xe876f662a42d33b9), UINT64_C(0xbc9f8ff0f8fdc2b4),\n    UINT64_C(0xb0bf0a16f97ff73b), UINT64_C(0xe4567384a5af0636),\n    UINT64_C(0x196df93240de1521), UINT64_C(0x4d8480a01c0ee42c),\n    UINT64_C(0x71c2437425322d8a), UINT64_C(0x252b3ae679e2dc87),\n    UINT64_C(0xd810b0509c93cf90), UINT64_C(0x8cf9c9c2c0433e9d),\n    UINT64_C(0xa09d37f8eeea5cdc), UINT64_C(0xf4744e6ab23aadd1),\n    UINT64_C(0x094fc4dc574bbec6), UINT64_C(0x5da6bd4e0b9b4fcb),\n    UINT64_C(0x61e07e9a32a7866d), UINT64_C(0x350907086e777760),\n    UINT64_C(0xc8328dbe8b066477), UINT64_C(0x9cdbf42cd7d6957a),\n    UINT64_C(0xd073867288020f69), UINT64_C(0x849affe0d4d2fe64),\n    UINT64_C(0x79a1755631a3ed73), UINT64_C(0x2d480cc46d731c7e),\n    UINT64_C(0x110ecf10544fd5d8), UINT64_C(0x45e7b682089f24d5),\n    UINT64_C(0xb8dc3c34edee37c2), UINT64_C(0xec3545a6b13ec6cf),\n    UINT64_C(0xc051bb9c9f97a48e), UINT64_C(0x94b8c20ec3475583),\n    UINT64_C(0x698348b826364694), UINT64_C(0x3d6a312a7ae6b799),\n    UINT64_C(0x012cf2fe43da7e3f), UINT64_C(0x55c58b6c1f0a8f32),\n    UINT64_C(0xa8fe01dafa7b9c25), UINT64_C(0xfc177848a6ab6d28),\n    UINT64_C(0xf037fdaea72958a7), UINT64_C(0xa4de843cfbf9a9aa),\n    UINT64_C(0x59e50e8a1e88babd), UINT64_C(0x0d0c771842584bb0),\n    UINT64_C(0x314ab4cc7b648216), UINT64_C(0x65a3cd5e27b4731b),\n    UINT64_C(0x989847e8c2c5600c), UINT64_C(0xcc713e7a9e159101),\n    UINT64_C(0xe015c040b0bcf340), UINT64_C(0xb4fcb9d2ec6c024d),\n    UINT64_C(0x49c73364091d115a), UINT64_C(0x1d2e4af655cde057),\n    UINT64_C(0x216889226cf129f1), UINT64_C(0x7581f0b03021d8fc),\n    UINT64_C(0x88ba7a06d550cbeb), UINT64_C(0xdc53039489803ae6),\n    UINT64_C(0x11ea9eba6af9ffcd), UINT64_C(0x4503e72836290ec0),\n    UINT64_C(0xb8386d9ed3581dd7), UINT64_C(0xecd1140c8f88ecda),\n    UINT64_C(0xd097d7d8b6b4257c), UINT64_C(0x847eae4aea64d471),\n    UINT64_C(0x794524fc0f15c766), UINT64_C(0x2dac5d6e53c5366b),\n    UINT64_C(0x01c8a3547d6c542a), UINT64_C(0x5521dac621bca527),\n    UINT64_C(0xa81a5070c4cdb630), UINT64_C(0xfcf329e2981d473d),\n    UINT64_C(0xc0b5ea36a1218e9b), UINT64_C(0x945c93a4fdf17f96),\n    UINT64_C(0x6967191218806c81), UINT64_C(0x3d8e608044509d8c),\n    UINT64_C(0x31aee56645d2a803), UINT64_C(0x65479cf41902590e),\n    UINT64_C(0x987c1642fc734a19), UINT64_C(0xcc956fd0a0a3bb14),\n    UINT64_C(0xf0d3ac04999f72b2), UINT64_C(0xa43ad596c54f83bf),\n    UINT64_C(0x59015f20203e90a8), UINT64_C(0x0de826b27cee61a5),\n    UINT64_C(0x218cd888524703e4), UINT64_C(0x7565a11a0e97f2e9),\n    UINT64_C(0x885e2bacebe6e1fe), UINT64_C(0xdcb7523eb73610f3),\n    UINT64_C(0xe0f191ea8e0ad955), UINT64_C(0xb418e878d2da2858),\n    UINT64_C(0x492362ce37ab3b4f), UINT64_C(0x1dca1b5c6b7bca42),\n    UINT64_C(0x5162690234af5051), UINT64_C(0x058b1090687fa15c),\n    UINT64_C(0xf8b09a268d0eb24b), UINT64_C(0xac59e3b4d1de4346),\n    UINT64_C(0x901f2060e8e28ae0), UINT64_C(0xc4f659f2b4327bed),\n    UINT64_C(0x39cdd344514368fa), UINT64_C(0x6d24aad60d9399f7),\n    UINT64_C(0x414054ec233afbb6), UINT64_C(0x15a92d7e7fea0abb),\n    UINT64_C(0xe892a7c89a9b19ac), UINT64_C(0xbc7bde5ac64be8a1),\n    UINT64_C(0x803d1d8eff772107), UINT64_C(0xd4d4641ca3a7d00a),\n    UINT64_C(0x29efeeaa46d6c31d), UINT64_C(0x7d0697381a063210),\n    UINT64_C(0x712612de1b84079f), UINT64_C(0x25cf6b4c4754f692),\n    UINT64_C(0xd8f4e1faa225e585), UINT64_C(0x8c1d9868fef51488),\n    UINT64_C(0xb05b5bbcc7c9dd2e), UINT64_C(0xe4b2222e9b192c23),\n    UINT64_C(0x1989a8987e683f34), UINT64_C(0x4d60d10a22b8ce39),\n    UINT64_C(0x61042f300c11ac78), UINT64_C(0x35ed56a250c15d75),\n    UINT64_C(0xc8d6dc14b5b04e62), UINT64_C(0x9c3fa586e960bf6f),\n    UINT64_C(0xa0796652d05c76c9), UINT64_C(0xf4901fc08c8c87c4),\n    UINT64_C(0x09ab957669fd94d3), UINT64_C(0x5d42ece4352d65de)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0xb32e4cbe03a75f6f),\n    UINT64_C(0xf4843657a840a05b), UINT64_C(0x47aa7ae9abe7ff34),\n    UINT64_C(0x7bd0c384ff8f5e33), UINT64_C(0xc8fe8f3afc28015c),\n    UINT64_C(0x8f54f5d357cffe68), UINT64_C(0x3c7ab96d5468a107),\n    UINT64_C(0xf7a18709ff1ebc66), UINT64_C(0x448fcbb7fcb9e309),\n    UINT64_C(0x0325b15e575e1c3d), UINT64_C(0xb00bfde054f94352),\n    UINT64_C(0x8c71448d0091e255), UINT64_C(0x3f5f08330336bd3a),\n    UINT64_C(0x78f572daa8d1420e), UINT64_C(0xcbdb3e64ab761d61),\n    UINT64_C(0x7d9ba13851336649), UINT64_C(0xceb5ed8652943926),\n    UINT64_C(0x891f976ff973c612), UINT64_C(0x3a31dbd1fad4997d),\n    UINT64_C(0x064b62bcaebc387a), UINT64_C(0xb5652e02ad1b6715),\n    UINT64_C(0xf2cf54eb06fc9821), UINT64_C(0x41e11855055bc74e),\n    UINT64_C(0x8a3a2631ae2dda2f), UINT64_C(0x39146a8fad8a8540),\n    UINT64_C(0x7ebe1066066d7a74), UINT64_C(0xcd905cd805ca251b),\n    UINT64_C(0xf1eae5b551a2841c), UINT64_C(0x42c4a90b5205db73),\n    UINT64_C(0x056ed3e2f9e22447), UINT64_C(0xb6409f5cfa457b28),\n    UINT64_C(0xfb374270a266cc92), UINT64_C(0x48190ecea1c193fd),\n    UINT64_C(0x0fb374270a266cc9), UINT64_C(0xbc9d3899098133a6),\n    UINT64_C(0x80e781f45de992a1), UINT64_C(0x33c9cd4a5e4ecdce),\n    UINT64_C(0x7463b7a3f5a932fa), UINT64_C(0xc74dfb1df60e6d95),\n    UINT64_C(0x0c96c5795d7870f4), UINT64_C(0xbfb889c75edf2f9b),\n    UINT64_C(0xf812f32ef538d0af), UINT64_C(0x4b3cbf90f69f8fc0),\n    UINT64_C(0x774606fda2f72ec7), UINT64_C(0xc4684a43a15071a8),\n    UINT64_C(0x83c230aa0ab78e9c), UINT64_C(0x30ec7c140910d1f3),\n    UINT64_C(0x86ace348f355aadb), UINT64_C(0x3582aff6f0f2f5b4),\n    UINT64_C(0x7228d51f5b150a80), UINT64_C(0xc10699a158b255ef),\n    UINT64_C(0xfd7c20cc0cdaf4e8), UINT64_C(0x4e526c720f7dab87),\n    UINT64_C(0x09f8169ba49a54b3), UINT64_C(0xbad65a25a73d0bdc),\n    UINT64_C(0x710d64410c4b16bd), UINT64_C(0xc22328ff0fec49d2),\n    UINT64_C(0x85895216a40bb6e6), UINT64_C(0x36a71ea8a7ace989),\n    UINT64_C(0x0adda7c5f3c4488e), UINT64_C(0xb9f3eb7bf06317e1),\n    UINT64_C(0xfe5991925b84e8d5), UINT64_C(0x4d77dd2c5823b7ba),\n    UINT64_C(0x64b62bcaebc387a1), UINT64_C(0xd7986774e864d8ce),\n    UINT64_C(0x90321d9d438327fa), UINT64_C(0x231c512340247895),\n    UINT64_C(0x1f66e84e144cd992), UINT64_C(0xac48a4f017eb86fd),\n    UINT64_C(0xebe2de19bc0c79c9), UINT64_C(0x58cc92a7bfab26a6),\n    UINT64_C(0x9317acc314dd3bc7), UINT64_C(0x2039e07d177a64a8),\n    UINT64_C(0x67939a94bc9d9b9c), UINT64_C(0xd4bdd62abf3ac4f3),\n    UINT64_C(0xe8c76f47eb5265f4), UINT64_C(0x5be923f9e8f53a9b),\n    UINT64_C(0x1c4359104312c5af), UINT64_C(0xaf6d15ae40b59ac0),\n    UINT64_C(0x192d8af2baf0e1e8), UINT64_C(0xaa03c64cb957be87),\n    UINT64_C(0xeda9bca512b041b3), UINT64_C(0x5e87f01b11171edc),\n    UINT64_C(0x62fd4976457fbfdb), UINT64_C(0xd1d305c846d8e0b4),\n    UINT64_C(0x96797f21ed3f1f80), UINT64_C(0x2557339fee9840ef),\n    UINT64_C(0xee8c0dfb45ee5d8e), UINT64_C(0x5da24145464902e1),\n    UINT64_C(0x1a083bacedaefdd5), UINT64_C(0xa9267712ee09a2ba),\n    UINT64_C(0x955cce7fba6103bd), UINT64_C(0x267282c1b9c65cd2),\n    UINT64_C(0x61d8f8281221a3e6), UINT64_C(0xd2f6b4961186fc89),\n    UINT64_C(0x9f8169ba49a54b33), UINT64_C(0x2caf25044a02145c),\n    UINT64_C(0x6b055fede1e5eb68), UINT64_C(0xd82b1353e242b407),\n    UINT64_C(0xe451aa3eb62a1500), UINT64_C(0x577fe680b58d4a6f),\n    UINT64_C(0x10d59c691e6ab55b), UINT64_C(0xa3fbd0d71dcdea34),\n    UINT64_C(0x6820eeb3b6bbf755), UINT64_C(0xdb0ea20db51ca83a),\n    UINT64_C(0x9ca4d8e41efb570e), UINT64_C(0x2f8a945a1d5c0861),\n    UINT64_C(0x13f02d374934a966), UINT64_C(0xa0de61894a93f609),\n    UINT64_C(0xe7741b60e174093d), UINT64_C(0x545a57dee2d35652),\n    UINT64_C(0xe21ac88218962d7a), UINT64_C(0x5134843c1b317215),\n    UINT64_C(0x169efed5b0d68d21), UINT64_C(0xa5b0b26bb371d24e),\n    UINT64_C(0x99ca0b06e7197349), UINT64_C(0x2ae447b8e4be2c26),\n    UINT64_C(0x6d4e3d514f59d312), UINT64_C(0xde6071ef4cfe8c7d),\n    UINT64_C(0x15bb4f8be788911c), UINT64_C(0xa6950335e42fce73),\n    UINT64_C(0xe13f79dc4fc83147), UINT64_C(0x521135624c6f6e28),\n    UINT64_C(0x6e6b8c0f1807cf2f), UINT64_C(0xdd45c0b11ba09040),\n    UINT64_C(0x9aefba58b0476f74), UINT64_C(0x29c1f6e6b3e0301b),\n    UINT64_C(0xc96c5795d7870f42), UINT64_C(0x7a421b2bd420502d),\n    UINT64_C(0x3de861c27fc7af19), UINT64_C(0x8ec62d7c7c60f076),\n    UINT64_C(0xb2bc941128085171), UINT64_C(0x0192d8af2baf0e1e),\n    UINT64_C(0x4638a2468048f12a), UINT64_C(0xf516eef883efae45),\n    UINT64_C(0x3ecdd09c2899b324), UINT64_C(0x8de39c222b3eec4b),\n    UINT64_C(0xca49e6cb80d9137f), UINT64_C(0x7967aa75837e4c10),\n    UINT64_C(0x451d1318d716ed17), UINT64_C(0xf6335fa6d4b1b278),\n    UINT64_C(0xb199254f7f564d4c), UINT64_C(0x02b769f17cf11223),\n    UINT64_C(0xb4f7f6ad86b4690b), UINT64_C(0x07d9ba1385133664),\n    UINT64_C(0x4073c0fa2ef4c950), UINT64_C(0xf35d8c442d53963f),\n    UINT64_C(0xcf273529793b3738), UINT64_C(0x7c0979977a9c6857),\n    UINT64_C(0x3ba3037ed17b9763), UINT64_C(0x888d4fc0d2dcc80c),\n    UINT64_C(0x435671a479aad56d), UINT64_C(0xf0783d1a7a0d8a02),\n    UINT64_C(0xb7d247f3d1ea7536), UINT64_C(0x04fc0b4dd24d2a59),\n    UINT64_C(0x3886b22086258b5e), UINT64_C(0x8ba8fe9e8582d431),\n    UINT64_C(0xcc0284772e652b05), UINT64_C(0x7f2cc8c92dc2746a),\n    UINT64_C(0x325b15e575e1c3d0), UINT64_C(0x8175595b76469cbf),\n    UINT64_C(0xc6df23b2dda1638b), UINT64_C(0x75f16f0cde063ce4),\n    UINT64_C(0x498bd6618a6e9de3), UINT64_C(0xfaa59adf89c9c28c),\n    UINT64_C(0xbd0fe036222e3db8), UINT64_C(0x0e21ac88218962d7),\n    UINT64_C(0xc5fa92ec8aff7fb6), UINT64_C(0x76d4de52895820d9),\n    UINT64_C(0x317ea4bb22bfdfed), UINT64_C(0x8250e80521188082),\n    UINT64_C(0xbe2a516875702185), UINT64_C(0x0d041dd676d77eea),\n    UINT64_C(0x4aae673fdd3081de), UINT64_C(0xf9802b81de97deb1),\n    UINT64_C(0x4fc0b4dd24d2a599), UINT64_C(0xfceef8632775faf6),\n    UINT64_C(0xbb44828a8c9205c2), UINT64_C(0x086ace348f355aad),\n    UINT64_C(0x34107759db5dfbaa), UINT64_C(0x873e3be7d8faa4c5),\n    UINT64_C(0xc094410e731d5bf1), UINT64_C(0x73ba0db070ba049e),\n    UINT64_C(0xb86133d4dbcc19ff), UINT64_C(0x0b4f7f6ad86b4690),\n    UINT64_C(0x4ce50583738cb9a4), UINT64_C(0xffcb493d702be6cb),\n    UINT64_C(0xc3b1f050244347cc), UINT64_C(0x709fbcee27e418a3),\n    UINT64_C(0x3735c6078c03e797), UINT64_C(0x841b8ab98fa4b8f8),\n    UINT64_C(0xadda7c5f3c4488e3), UINT64_C(0x1ef430e13fe3d78c),\n    UINT64_C(0x595e4a08940428b8), UINT64_C(0xea7006b697a377d7),\n    UINT64_C(0xd60abfdbc3cbd6d0), UINT64_C(0x6524f365c06c89bf),\n    UINT64_C(0x228e898c6b8b768b), UINT64_C(0x91a0c532682c29e4),\n    UINT64_C(0x5a7bfb56c35a3485), UINT64_C(0xe955b7e8c0fd6bea),\n    UINT64_C(0xaeffcd016b1a94de), UINT64_C(0x1dd181bf68bdcbb1),\n    UINT64_C(0x21ab38d23cd56ab6), UINT64_C(0x9285746c3f7235d9),\n    UINT64_C(0xd52f0e859495caed), UINT64_C(0x6601423b97329582),\n    UINT64_C(0xd041dd676d77eeaa), UINT64_C(0x636f91d96ed0b1c5),\n    UINT64_C(0x24c5eb30c5374ef1), UINT64_C(0x97eba78ec690119e),\n    UINT64_C(0xab911ee392f8b099), UINT64_C(0x18bf525d915feff6),\n    UINT64_C(0x5f1528b43ab810c2), UINT64_C(0xec3b640a391f4fad),\n    UINT64_C(0x27e05a6e926952cc), UINT64_C(0x94ce16d091ce0da3),\n    UINT64_C(0xd3646c393a29f297), UINT64_C(0x604a2087398eadf8),\n    UINT64_C(0x5c3099ea6de60cff), UINT64_C(0xef1ed5546e415390),\n    UINT64_C(0xa8b4afbdc5a6aca4), UINT64_C(0x1b9ae303c601f3cb),\n    UINT64_C(0x56ed3e2f9e224471), UINT64_C(0xe5c372919d851b1e),\n    UINT64_C(0xa26908783662e42a), UINT64_C(0x114744c635c5bb45),\n    UINT64_C(0x2d3dfdab61ad1a42), UINT64_C(0x9e13b115620a452d),\n    UINT64_C(0xd9b9cbfcc9edba19), UINT64_C(0x6a978742ca4ae576),\n    UINT64_C(0xa14cb926613cf817), UINT64_C(0x1262f598629ba778),\n    UINT64_C(0x55c88f71c97c584c), UINT64_C(0xe6e6c3cfcadb0723),\n    UINT64_C(0xda9c7aa29eb3a624), UINT64_C(0x69b2361c9d14f94b),\n    UINT64_C(0x2e184cf536f3067f), UINT64_C(0x9d36004b35545910),\n    UINT64_C(0x2b769f17cf112238), UINT64_C(0x9858d3a9ccb67d57),\n    UINT64_C(0xdff2a94067518263), UINT64_C(0x6cdce5fe64f6dd0c),\n    UINT64_C(0x50a65c93309e7c0b), UINT64_C(0xe388102d33392364),\n    UINT64_C(0xa4226ac498dedc50), UINT64_C(0x170c267a9b79833f),\n    UINT64_C(0xdcd7181e300f9e5e), UINT64_C(0x6ff954a033a8c131),\n    UINT64_C(0x28532e49984f3e05), UINT64_C(0x9b7d62f79be8616a),\n    UINT64_C(0xa707db9acf80c06d), UINT64_C(0x14299724cc279f02),\n    UINT64_C(0x5383edcd67c06036), UINT64_C(0xe0ada17364673f59)\n  }\n};\n\nstatic const uint64_t crc64_interleaved_table[4][256] = {\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0xe88a0d0c5521de3d),\n    UINT64_C(0x43ccb533054da2ff), UINT64_C(0xab46b83f506c7cc2),\n    UINT64_C(0x87996a660a9b45fe), UINT64_C(0x6f13676a5fba9bc3),\n    UINT64_C(0xc455df550fd6e701), UINT64_C(0x2cdfd2595af7393c),\n    UINT64_C(0x9dea7be7ba389579), UINT64_C(0x756076ebef194b44),\n    UINT64_C(0xde26ced4bf753786), UINT64_C(0x36acc3d8ea54e9bb),\n    UINT64_C(0x1a731181b0a3d087), UINT64_C(0xf2f91c8de5820eba),\n    UINT64_C(0x59bfa4b2b5ee7278), UINT64_C(0xb135a9bee0cfac45),\n    UINT64_C(0xa90c58e4db7f3477), UINT64_C(0x418655e88e5eea4a),\n    UINT64_C(0xeac0edd7de329688), UINT64_C(0x024ae0db8b1348b5),\n    UINT64_C(0x2e953282d1e47189), UINT64_C(0xc61f3f8e84c5afb4),\n    UINT64_C(0x6d5987b1d4a9d376), UINT64_C(0x85d38abd81880d4b),\n    UINT64_C(0x34e623036147a10e), UINT64_C(0xdc6c2e0f34667f33),\n    UINT64_C(0x772a9630640a03f1), UINT64_C(0x9fa09b3c312bddcc),\n    UINT64_C(0xb37f49656bdce4f0), UINT64_C(0x5bf544693efd3acd),\n    UINT64_C(0xf0b3fc566e91460f), UINT64_C(0x1839f15a3bb09832),\n    UINT64_C(0xc0c01ee219f0766b), UINT64_C(0x284a13ee4cd1a856),\n    UINT64_C(0x830cabd11cbdd494), UINT64_C(0x6b86a6dd499c0aa9),\n    UINT64_C(0x47597484136b3395), UINT64_C(0xafd37988464aeda8),\n    UINT64_C(0x0495c1b71626916a), UINT64_C(0xec1fccbb43074f57),\n    UINT64_C(0x5d2a6505a3c8e312), UINT64_C(0xb5a06809f6e93d2f),\n    UINT64_C(0x1ee6d036a68541ed), UINT64_C(0xf66cdd3af3a49fd0),\n    UINT64_C(0xdab30f63a953a6ec), UINT64_C(0x3239026ffc7278d1),\n    UINT64_C(0x997fba50ac1e0413), UINT64_C(0x71f5b75cf93fda2e),\n    UINT64_C(0x69cc4606c28f421c), UINT64_C(0x81464b0a97ae9c21),\n    UINT64_C(0x2a00f335c7c2e0e3), UINT64_C(0xc28afe3992e33ede),\n    UINT64_C(0xee552c60c81407e2), UINT64_C(0x06df216c9d35d9df),\n    UINT64_C(0xad999953cd59a51d), UINT64_C(0x4513945f98787b20),\n    UINT64_C(0xf4263de178b7d765), UINT64_C(0x1cac30ed2d960958),\n    UINT64_C(0xb7ea88d27dfa759a), UINT64_C(0x5f6085de28dbaba7),\n    UINT64_C(0x73bf5787722c929b), UINT64_C(0x9b355a8b270d4ca6),\n    UINT64_C(0x3073e2b477613064), UINT64_C(0xd8f9efb82240ee59),\n    UINT64_C(0x135892ef9ceef253), UINT64_C(0xfbd29fe3c9cf2c6e),\n    UINT64_C(0x509427dc99a350ac), UINT64_C(0xb81e2ad0cc828e91),\n    UINT64_C(0x94c1f8899675b7ad), UINT64_C(0x7c4bf585c3546990),\n    UINT64_C(0xd70d4dba93381552), UINT64_C(0x3f8740b6c619cb6f),\n    UINT64_C(0x8eb2e90826d6672a), UINT64_C(0x6638e40473f7b917),\n    UINT64_C(0xcd7e5c3b239bc5d5), UINT64_C(0x25f4513776ba1be8),\n    UINT64_C(0x092b836e2c4d22d4), UINT64_C(0xe1a18e62796cfce9),\n    UINT64_C(0x4ae7365d2900802b), UINT64_C(0xa26d3b517c215e16),\n    UINT64_C(0xba54ca0b4791c624), UINT64_C(0x52dec70712b01819),\n    UINT64_C(0xf9987f3842dc64db), UINT64_C(0x1112723417fdbae6),\n    UINT64_C(0x3dcda06d4d0a83da), UINT64_C(0xd547ad61182b5de7),\n    UINT64_C(0x7e01155e48472125), UINT64_C(0x968b18521d66ff18),\n    UINT64_C(0x27beb1ecfda9535d), UINT64_C(0xcf34bce0a8888d60),\n    UINT64_C(0x647204dff8e4f1a2), UINT64_C(0x8cf809d3adc52f9f),\n    UINT64_C(0xa027db8af73216a3), UINT64_C(0x48add686a213c89e),\n    UINT64_C(0xe3eb6eb9f27fb45c), UINT64_C(0x0b6163b5a75e6a61),\n    UINT64_C(0xd3988c0d851e8438), UINT64_C(0x3b128101d03f5a05),\n    UINT64_C(0x9054393e805326c7), UINT64_C(0x78de3432d572f8fa),\n    UINT64_C(0x5401e66b8f85c1c6), UINT64_C(0xbc8beb67daa41ffb),\n    UINT64_C(0x17cd53588ac86339), UINT64_C(0xff475e54dfe9bd04),\n    UINT64_C(0x4e72f7ea3f261141), UINT64_C(0xa6f8fae66a07cf7c),\n    UINT64_C(0x0dbe42d93a6bb3be), UINT64_C(0xe5344fd56f4a6d83),\n    UINT64_C(0xc9eb9d8c35bd54bf), UINT64_C(0x21619080609c8a82),\n    UINT64_C(0x8a2728bf30f0f640), UINT64_C(0x62ad25b365d1287d),\n    UINT64_C(0x7a94d4e95e61b04f), UINT64_C(0x921ed9e50b406e72),\n    UINT64_C(0x395861da5b2c12b0), UINT64_C(0xd1d26cd60e0dcc8d),\n    UINT64_C(0xfd0dbe8f54faf5b1), UINT64_C(0x1587b38301db2b8c),\n    UINT64_C(0xbec10bbc51b7574e), UINT64_C(0x564b06b004968973),\n    UINT64_C(0xe77eaf0ee4592536), UINT64_C(0x0ff4a202b178fb0b),\n    UINT64_C(0xa4b21a3de11487c9), UINT64_C(0x4c381731b43559f4),\n    UINT64_C(0x60e7c568eec260c8), UINT64_C(0x886dc864bbe3bef5),\n    UINT64_C(0x232b705beb8fc237), UINT64_C(0xcba17d57beae1c0a),\n    UINT64_C(0x26b125df39dde4a6), UINT64_C(0xce3b28d36cfc3a9b),\n    UINT64_C(0x657d90ec3c904659), UINT64_C(0x8df79de069b19864),\n    UINT64_C(0xa1284fb93346a158), UINT64_C(0x49a242b566677f65),\n    UINT64_C(0xe2e4fa8a360b03a7), UINT64_C(0x0a6ef786632add9a),\n    UINT64_C(0xbb5b5e3883e571df), UINT64_C(0x53d15334d6c4afe2),\n    UINT64_C(0xf897eb0b86a8d320), UINT64_C(0x101de607d3890d1d),\n    UINT64_C(0x3cc2345e897e3421), UINT64_C(0xd4483952dc5fea1c),\n    UINT64_C(0x7f0e816d8c3396de), UINT64_C(0x97848c61d91248e3),\n    UINT64_C(0x8fbd7d3be2a2d0d1), UINT64_C(0x67377037b7830eec),\n    UINT64_C(0xcc71c808e7ef722e), UINT64_C(0x24fbc504b2ceac13),\n    UINT64_C(0x0824175de839952f), UINT64_C(0xe0ae1a51bd184b12),\n    UINT64_C(0x4be8a26eed7437d0), UINT64_C(0xa362af62b855e9ed),\n    UINT64_C(0x125706dc589a45a8), UINT64_C(0xfadd0bd00dbb9b95),\n    UINT64_C(0x519bb3ef5dd7e757), UINT64_C(0xb911bee308f6396a),\n    UINT64_C(0x95ce6cba52010056), UINT64_C(0x7d4461b60720de6b),\n    UINT64_C(0xd602d989574ca2a9), UINT64_C(0x3e88d485026d7c94),\n    UINT64_C(0xe6713b3d202d92cd), UINT64_C(0x0efb3631750c4cf0),\n    UINT64_C(0xa5bd8e0e25603032), UINT64_C(0x4d3783027041ee0f),\n    UINT64_C(0x61e8515b2ab6d733), UINT64_C(0x89625c577f97090e),\n    UINT64_C(0x2224e4682ffb75cc), UINT64_C(0xcaaee9647adaabf1),\n    UINT64_C(0x7b9b40da9a1507b4), UINT64_C(0x93114dd6cf34d989),\n    UINT64_C(0x3857f5e99f58a54b), UINT64_C(0xd0ddf8e5ca797b76),\n    UINT64_C(0xfc022abc908e424a), UINT64_C(0x148827b0c5af9c77),\n    UINT64_C(0xbfce9f8f95c3e0b5), UINT64_C(0x57449283c0e23e88),\n    UINT64_C(0x4f7d63d9fb52a6ba), UINT64_C(0xa7f76ed5ae737887),\n    UINT64_C(0x0cb1d6eafe1f0445), UINT64_C(0xe43bdbe6ab3eda78),\n    UINT64_C(0xc8e409bff1c9e344), UINT64_C(0x206e04b3a4e83d79),\n    UINT64_C(0x8b28bc8cf48441bb), UINT64_C(0x63a2b180a1a59f86),\n    UINT64_C(0xd297183e416a33c3), UINT64_C(0x3a1d1532144bedfe),\n    UINT64_C(0x915bad0d4427913c), UINT64_C(0x79d1a00111064f01),\n    UINT64_C(0x550e72584bf1763d), UINT64_C(0xbd847f541ed0a800),\n    UINT64_C(0x16c2c76b4ebcd4c2), UINT64_C(0xfe48ca671b9d0aff),\n    UINT64_C(0x35e9b730a53316f5), UINT64_C(0xdd63ba3cf012c8c8),\n    UINT64_C(0x76250203a07eb40a), UINT64_C(0x9eaf0f0ff55f6a37),\n    UINT64_C(0xb270dd56afa8530b), UINT64_C(0x5afad05afa898d36),\n    UINT64_C(0xf1bc6865aae5f1f4), UINT64_C(0x19366569ffc42fc9),\n    UINT64_C(0xa803ccd71f0b838c), UINT64_C(0x4089c1db4a2a5db1),\n    UINT64_C(0xebcf79e41a462173), UINT64_C(0x034574e84f67ff4e),\n    UINT64_C(0x2f9aa6b11590c672), UINT64_C(0xc710abbd40b1184f),\n    UINT64_C(0x6c56138210dd648d), UINT64_C(0x84dc1e8e45fcbab0),\n    UINT64_C(0x9ce5efd47e4c2282), UINT64_C(0x746fe2d82b6dfcbf),\n    UINT64_C(0xdf295ae77b01807d), UINT64_C(0x37a357eb2e205e40),\n    UINT64_C(0x1b7c85b274d7677c), UINT64_C(0xf3f688be21f6b941),\n    UINT64_C(0x58b03081719ac583), UINT64_C(0xb03a3d8d24bb1bbe),\n    UINT64_C(0x010f9433c474b7fb), UINT64_C(0xe985993f915569c6),\n    UINT64_C(0x42c32100c1391504), UINT64_C(0xaa492c0c9418cb39),\n    UINT64_C(0x8696fe55ceeff205), UINT64_C(0x6e1cf3599bce2c38),\n    UINT64_C(0xc55a4b66cba250fa), UINT64_C(0x2dd0466a9e838ec7),\n    UINT64_C(0xf529a9d2bcc3609e), UINT64_C(0x1da3a4dee9e2bea3),\n    UINT64_C(0xb6e51ce1b98ec261), UINT64_C(0x5e6f11edecaf1c5c),\n    UINT64_C(0x72b0c3b4b6582560), UINT64_C(0x9a3aceb8e379fb5d),\n    UINT64_C(0x317c7687b315879f), UINT64_C(0xd9f67b8be63459a2),\n    UINT64_C(0x68c3d23506fbf5e7), UINT64_C(0x8049df3953da2bda),\n    UINT64_C(0x2b0f670603b65718), UINT64_C(0xc3856a0a56978925),\n    UINT64_C(0xef5ab8530c60b019), UINT64_C(0x07d0b55f59416e24),\n    UINT64_C(0xac960d60092d12e6), UINT64_C(0x441c006c5c0cccdb),\n    UINT64_C(0x5c25f13667bc54e9), UINT64_C(0xb4affc3a329d8ad4),\n    UINT64_C(0x1fe9440562f1f616), UINT64_C(0xf763490937d0282b),\n    UINT64_C(0xdbbc9b506d271117), UINT64_C(0x3336965c3806cf2a),\n    UINT64_C(0x98702e63686ab3e8), UINT64_C(0x70fa236f3d4b6dd5),\n    UINT64_C(0xc1cf8ad1dd84c190), UINT64_C(0x294587dd88a51fad),\n    UINT64_C(0x82033fe2d8c9636f), UINT64_C(0x6a8932ee8de8bd52),\n    UINT64_C(0x4656e0b7d71f846e), UINT64_C(0xaedcedbb823e5a53),\n    UINT64_C(0x059a5584d2522691), UINT64_C(0xed1058888773f8ac)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x4d624bbe73bbc94c),\n    UINT64_C(0x9ac4977ce7779298), UINT64_C(0xd7a6dcc294cc5bd4),\n    UINT64_C(0xa75181d261e13bb5), UINT64_C(0xea33ca6c125af2f9),\n    UINT64_C(0x3d9516ae8696a92d), UINT64_C(0x70f75d10f52d6061),\n    UINT64_C(0xdc7bac8f6ccc69ef), UINT64_C(0x9119e7311f77a0a3),\n    UINT64_C(0x46bf3bf38bbbfb77), UINT64_C(0x0bdd704df800323b),\n    UINT64_C(0x7b2a2d5d0d2d525a), UINT64_C(0x364866e37e969b16),\n    UINT64_C(0xe1eeba21ea5ac0c2), UINT64_C(0xac8cf19f99e1098e),\n    UINT64_C(0x2a2ff6357696cd5b), UINT64_C(0x674dbd8b052d0417),\n    UINT64_C(0xb0eb614991e15fc3), UINT64_C(0xfd892af7e25a968f),\n    UINT64_C(0x8d7e77e71777f6ee), UINT64_C(0xc01c3c5964cc3fa2),\n    UINT64_C(0x17bae09bf0006476), UINT64_C(0x5ad8ab2583bbad3a),\n    UINT64_C(0xf6545aba1a5aa4b4), UINT64_C(0xbb36110469e16df8),\n    UINT64_C(0x6c90cdc6fd2d362c), UINT64_C(0x21f286788e96ff60),\n    UINT64_C(0x5105db687bbb9f01), UINT64_C(0x1c6790d60800564d),\n    UINT64_C(0xcbc14c149ccc0d99), UINT64_C(0x86a307aaef77c4d5),\n    UINT64_C(0x545fec6aed2d9ab6), UINT64_C(0x193da7d49e9653fa),\n    UINT64_C(0xce9b7b160a5a082e), UINT64_C(0x83f930a879e1c162),\n    UINT64_C(0xf30e6db88ccca103), UINT64_C(0xbe6c2606ff77684f),\n    UINT64_C(0x69cafac46bbb339b), UINT64_C(0x24a8b17a1800fad7),\n    UINT64_C(0x882440e581e1f359), UINT64_C(0xc5460b5bf25a3a15),\n    UINT64_C(0x12e0d799669661c1), UINT64_C(0x5f829c27152da88d),\n    UINT64_C(0x2f75c137e000c8ec), UINT64_C(0x62178a8993bb01a0),\n    UINT64_C(0xb5b1564b07775a74), UINT64_C(0xf8d31df574cc9338),\n    UINT64_C(0x7e701a5f9bbb57ed), UINT64_C(0x331251e1e8009ea1),\n    UINT64_C(0xe4b48d237cccc575), UINT64_C(0xa9d6c69d0f770c39),\n    UINT64_C(0xd9219b8dfa5a6c58), UINT64_C(0x9443d03389e1a514),\n    UINT64_C(0x43e50cf11d2dfec0), UINT64_C(0x0e87474f6e96378c),\n    UINT64_C(0xa20bb6d0f7773e02), UINT64_C(0xef69fd6e84ccf74e),\n    UINT64_C(0x38cf21ac1000ac9a), UINT64_C(0x75ad6a1263bb65d6),\n    UINT64_C(0x055a3702969605b7), UINT64_C(0x48387cbce52dccfb),\n    UINT64_C(0x9f9ea07e71e1972f), UINT64_C(0xd2fcebc0025a5e63),\n    UINT64_C(0xa8bfd8d5da5b356c), UINT64_C(0xe5dd936ba9e0fc20),\n    UINT64_C(0x327b4fa93d2ca7f4), UINT64_C(0x7f1904174e976eb8),\n    UINT64_C(0x0fee5907bbba0ed9), UINT64_C(0x428c12b9c801c795),\n    UINT64_C(0x952ace7b5ccd9c41), UINT64_C(0xd84885c52f76550d),\n    UINT64_C(0x74c4745ab6975c83), UINT64_C(0x39a63fe4c52c95cf),\n    UINT64_C(0xee00e32651e0ce1b), UINT64_C(0xa362a898225b0757),\n    UINT64_C(0xd395f588d7766736), UINT64_C(0x9ef7be36a4cdae7a),\n    UINT64_C(0x495162f43001f5ae), UINT64_C(0x0433294a43ba3ce2),\n    UINT64_C(0x82902ee0accdf837), UINT64_C(0xcff2655edf76317b),\n    UINT64_C(0x1854b99c4bba6aaf), UINT64_C(0x5536f2223801a3e3),\n    UINT64_C(0x25c1af32cd2cc382), UINT64_C(0x68a3e48cbe970ace),\n    UINT64_C(0xbf05384e2a5b511a), UINT64_C(0xf26773f059e09856),\n    UINT64_C(0x5eeb826fc00191d8), UINT64_C(0x1389c9d1b3ba5894),\n    UINT64_C(0xc42f151327760340), UINT64_C(0x894d5ead54cdca0c),\n    UINT64_C(0xf9ba03bda1e0aa6d), UINT64_C(0xb4d84803d25b6321),\n    UINT64_C(0x637e94c1469738f5), UINT64_C(0x2e1cdf7f352cf1b9),\n    UINT64_C(0xfce034bf3776afda), UINT64_C(0xb1827f0144cd6696),\n    UINT64_C(0x6624a3c3d0013d42), UINT64_C(0x2b46e87da3baf40e),\n    UINT64_C(0x5bb1b56d5697946f), UINT64_C(0x16d3fed3252c5d23),\n    UINT64_C(0xc1752211b1e006f7), UINT64_C(0x8c1769afc25bcfbb),\n    UINT64_C(0x209b98305bbac635), UINT64_C(0x6df9d38e28010f79),\n    UINT64_C(0xba5f0f4cbccd54ad), UINT64_C(0xf73d44f2cf769de1),\n    UINT64_C(0x87ca19e23a5bfd80), UINT64_C(0xcaa8525c49e034cc),\n    UINT64_C(0x1d0e8e9edd2c6f18), UINT64_C(0x506cc520ae97a654),\n    UINT64_C(0xd6cfc28a41e06281), UINT64_C(0x9bad8934325babcd),\n    UINT64_C(0x4c0b55f6a697f019), UINT64_C(0x01691e48d52c3955),\n    UINT64_C(0x719e435820015934), UINT64_C(0x3cfc08e653ba9078),\n    UINT64_C(0xeb5ad424c776cbac), UINT64_C(0xa6389f9ab4cd02e0),\n    UINT64_C(0x0ab46e052d2c0b6e), UINT64_C(0x47d625bb5e97c222),\n    UINT64_C(0x9070f979ca5b99f6), UINT64_C(0xdd12b2c7b9e050ba),\n    UINT64_C(0xade5efd74ccd30db), UINT64_C(0xe087a4693f76f997),\n    UINT64_C(0x372178ababbaa243), UINT64_C(0x7a433315d8016b0f),\n    UINT64_C(0xc3a71e801bb8745d), UINT64_C(0x8ec5553e6803bd11),\n    UINT64_C(0x596389fcfccfe6c5), UINT64_C(0x1401c2428f742f89),\n    UINT64_C(0x64f69f527a594fe8), UINT64_C(0x2994d4ec09e286a4),\n    UINT64_C(0xfe32082e9d2edd70), UINT64_C(0xb3504390ee95143c),\n    UINT64_C(0x1fdcb20f77741db2), UINT64_C(0x52bef9b104cfd4fe),\n    UINT64_C(0x8518257390038f2a), UINT64_C(0xc87a6ecde3b84666),\n    UINT64_C(0xb88d33dd16952607), UINT64_C(0xf5ef7863652eef4b),\n    UINT64_C(0x2249a4a1f1e2b49f), UINT64_C(0x6f2bef1f82597dd3),\n    UINT64_C(0xe988e8b56d2eb906), UINT64_C(0xa4eaa30b1e95704a),\n    UINT64_C(0x734c7fc98a592b9e), UINT64_C(0x3e2e3477f9e2e2d2),\n    UINT64_C(0x4ed969670ccf82b3), UINT64_C(0x03bb22d97f744bff),\n    UINT64_C(0xd41dfe1bebb8102b), UINT64_C(0x997fb5a59803d967),\n    UINT64_C(0x35f3443a01e2d0e9), UINT64_C(0x78910f84725919a5),\n    UINT64_C(0xaf37d346e6954271), UINT64_C(0xe25598f8952e8b3d),\n    UINT64_C(0x92a2c5e86003eb5c), UINT64_C(0xdfc08e5613b82210),\n    UINT64_C(0x08665294877479c4), UINT64_C(0x4504192af4cfb088),\n    UINT64_C(0x97f8f2eaf695eeeb), UINT64_C(0xda9ab954852e27a7),\n    UINT64_C(0x0d3c659611e27c73), UINT64_C(0x405e2e286259b53f),\n    UINT64_C(0x30a973389774d55e), UINT64_C(0x7dcb3886e4cf1c12),\n    UINT64_C(0xaa6de444700347c6), UINT64_C(0xe70faffa03b88e8a),\n    UINT64_C(0x4b835e659a598704), UINT64_C(0x06e115dbe9e24e48),\n    UINT64_C(0xd147c9197d2e159c), UINT64_C(0x9c2582a70e95dcd0),\n    UINT64_C(0xecd2dfb7fbb8bcb1), UINT64_C(0xa1b09409880375fd),\n    UINT64_C(0x761648cb1ccf2e29), UINT64_C(0x3b7403756f74e765),\n    UINT64_C(0xbdd704df800323b0), UINT64_C(0xf0b54f61f3b8eafc),\n    UINT64_C(0x271393a36774b128), UINT64_C(0x6a71d81d14cf7864),\n    UINT64_C(0x1a86850de1e21805), UINT64_C(0x57e4ceb39259d149),\n    UINT64_C(0x8042127106958a9d), UINT64_C(0xcd2059cf752e43d1),\n    UINT64_C(0x61aca850eccf4a5f), UINT64_C(0x2ccee3ee9f748313),\n    UINT64_C(0xfb683f2c0bb8d8c7), UINT64_C(0xb60a74927803118b),\n    UINT64_C(0xc6fd29828d2e71ea), UINT64_C(0x8b9f623cfe95b8a6),\n    UINT64_C(0x5c39befe6a59e372), UINT64_C(0x115bf54019e22a3e),\n    UINT64_C(0x6b18c655c1e34131), UINT64_C(0x267a8debb258887d),\n    UINT64_C(0xf1dc51292694d3a9), UINT64_C(0xbcbe1a97552f1ae5),\n    UINT64_C(0xcc494787a0027a84), UINT64_C(0x812b0c39d3b9b3c8),\n    UINT64_C(0x568dd0fb4775e81c), UINT64_C(0x1bef9b4534ce2150),\n    UINT64_C(0xb7636adaad2f28de), UINT64_C(0xfa012164de94e192),\n    UINT64_C(0x2da7fda64a58ba46), UINT64_C(0x60c5b61839e3730a),\n    UINT64_C(0x1032eb08ccce136b), UINT64_C(0x5d50a0b6bf75da27),\n    UINT64_C(0x8af67c742bb981f3), UINT64_C(0xc79437ca580248bf),\n    UINT64_C(0x41373060b7758c6a), UINT64_C(0x0c557bdec4ce4526),\n    UINT64_C(0xdbf3a71c50021ef2), UINT64_C(0x9691eca223b9d7be),\n    UINT64_C(0xe666b1b2d694b7df), UINT64_C(0xab04fa0ca52f7e93),\n    UINT64_C(0x7ca226ce31e32547), UINT64_C(0x31c06d704258ec0b),\n    UINT64_C(0x9d4c9cefdbb9e585), UINT64_C(0xd02ed751a8022cc9),\n    UINT64_C(0x07880b933cce771d), UINT64_C(0x4aea402d4f75be51),\n    UINT64_C(0x3a1d1d3dba58de30), UINT64_C(0x777f5683c9e3177c),\n    UINT64_C(0xa0d98a415d2f4ca8), UINT64_C(0xedbbc1ff2e9485e4),\n    UINT64_C(0x3f472a3f2ccedb87), UINT64_C(0x722561815f7512cb),\n    UINT64_C(0xa583bd43cbb9491f), UINT64_C(0xe8e1f6fdb8028053),\n    UINT64_C(0x9816abed4d2fe032), UINT64_C(0xd574e0533e94297e),\n    UINT64_C(0x02d23c91aa5872aa), UINT64_C(0x4fb0772fd9e3bbe6),\n    UINT64_C(0xe33c86b04002b268), UINT64_C(0xae5ecd0e33b97b24),\n    UINT64_C(0x79f811cca77520f0), UINT64_C(0x349a5a72d4cee9bc),\n    UINT64_C(0x446d076221e389dd), UINT64_C(0x090f4cdc52584091),\n    UINT64_C(0xdea9901ec6941b45), UINT64_C(0x93cbdba0b52fd209),\n    UINT64_C(0x1568dc0a5a5816dc), UINT64_C(0x580a97b429e3df90),\n    UINT64_C(0x8fac4b76bd2f8444), UINT64_C(0xc2ce00c8ce944d08),\n    UINT64_C(0xb2395dd83bb92d69), UINT64_C(0xff5b16664802e425),\n    UINT64_C(0x28fdcaa4dccebff1), UINT64_C(0x659f811aaf7576bd),\n    UINT64_C(0xc913708536947f33), UINT64_C(0x84713b3b452fb67f),\n    UINT64_C(0x53d7e7f9d1e3edab), UINT64_C(0x1eb5ac47a25824e7),\n    UINT64_C(0x6e42f15757754486), UINT64_C(0x2320bae924ce8dca),\n    UINT64_C(0xf486662bb002d61e), UINT64_C(0xb9e42d95c3b91f52)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x1596922b987ef63f),\n    UINT64_C(0x2b2d245730fdec7e), UINT64_C(0x3ebbb67ca8831a41),\n    UINT64_C(0x565a48ae61fbd8fc), UINT64_C(0x43ccda85f9852ec3),\n    UINT64_C(0x7d776cf951063482), UINT64_C(0x68e1fed2c978c2bd),\n    UINT64_C(0xacb4915cc3f7b1f8), UINT64_C(0xb92203775b8947c7),\n    UINT64_C(0x8799b50bf30a5d86), UINT64_C(0x920f27206b74abb9),\n    UINT64_C(0xfaeed9f2a20c6904), UINT64_C(0xef784bd93a729f3b),\n    UINT64_C(0xd1c3fda592f1857a), UINT64_C(0xc4556f8e0a8f7345),\n    UINT64_C(0xcbb18d9228e17d75), UINT64_C(0xde271fb9b09f8b4a),\n    UINT64_C(0xe09ca9c5181c910b), UINT64_C(0xf50a3bee80626734),\n    UINT64_C(0x9debc53c491aa589), UINT64_C(0x887d5717d16453b6),\n    UINT64_C(0xb6c6e16b79e749f7), UINT64_C(0xa3507340e199bfc8),\n    UINT64_C(0x67051cceeb16cc8d), UINT64_C(0x72938ee573683ab2),\n    UINT64_C(0x4c283899dbeb20f3), UINT64_C(0x59beaab24395d6cc),\n    UINT64_C(0x315f54608aed1471), UINT64_C(0x24c9c64b1293e24e),\n    UINT64_C(0x1a727037ba10f80f), UINT64_C(0x0fe4e21c226e0e30),\n    UINT64_C(0x05bbb40ffecce46f), UINT64_C(0x102d262466b21250),\n    UINT64_C(0x2e969058ce310811), UINT64_C(0x3b000273564ffe2e),\n    UINT64_C(0x53e1fca19f373c93), UINT64_C(0x46776e8a0749caac),\n    UINT64_C(0x78ccd8f6afcad0ed), UINT64_C(0x6d5a4add37b426d2),\n    UINT64_C(0xa90f25533d3b5597), UINT64_C(0xbc99b778a545a3a8),\n    UINT64_C(0x822201040dc6b9e9), UINT64_C(0x97b4932f95b84fd6),\n    UINT64_C(0xff556dfd5cc08d6b), UINT64_C(0xeac3ffd6c4be7b54),\n    UINT64_C(0xd47849aa6c3d6115), UINT64_C(0xc1eedb81f443972a),\n    UINT64_C(0xce0a399dd62d991a), UINT64_C(0xdb9cabb64e536f25),\n    UINT64_C(0xe5271dcae6d07564), UINT64_C(0xf0b18fe17eae835b),\n    UINT64_C(0x98507133b7d641e6), UINT64_C(0x8dc6e3182fa8b7d9),\n    UINT64_C(0xb37d5564872bad98), UINT64_C(0xa6ebc74f1f555ba7),\n    UINT64_C(0x62bea8c115da28e2), UINT64_C(0x77283aea8da4dedd),\n    UINT64_C(0x49938c962527c49c), UINT64_C(0x5c051ebdbd5932a3),\n    UINT64_C(0x34e4e06f7421f01e), UINT64_C(0x21727244ec5f0621),\n    UINT64_C(0x1fc9c43844dc1c60), UINT64_C(0x0a5f5613dca2ea5f),\n    UINT64_C(0x0b77681ffd99c8de), UINT64_C(0x1ee1fa3465e73ee1),\n    UINT64_C(0x205a4c48cd6424a0), UINT64_C(0x35ccde63551ad29f),\n    UINT64_C(0x5d2d20b19c621022), UINT64_C(0x48bbb29a041ce61d),\n    UINT64_C(0x760004e6ac9ffc5c), UINT64_C(0x639696cd34e10a63),\n    UINT64_C(0xa7c3f9433e6e7926), UINT64_C(0xb2556b68a6108f19),\n    UINT64_C(0x8ceedd140e939558), UINT64_C(0x99784f3f96ed6367),\n    UINT64_C(0xf199b1ed5f95a1da), UINT64_C(0xe40f23c6c7eb57e5),\n    UINT64_C(0xdab495ba6f684da4), UINT64_C(0xcf220791f716bb9b),\n    UINT64_C(0xc0c6e58dd578b5ab), UINT64_C(0xd55077a64d064394),\n    UINT64_C(0xebebc1dae58559d5), UINT64_C(0xfe7d53f17dfbafea),\n    UINT64_C(0x969cad23b4836d57), UINT64_C(0x830a3f082cfd9b68),\n    UINT64_C(0xbdb18974847e8129), UINT64_C(0xa8271b5f1c007716),\n    UINT64_C(0x6c7274d1168f0453), UINT64_C(0x79e4e6fa8ef1f26c),\n    UINT64_C(0x475f50862672e82d), UINT64_C(0x52c9c2adbe0c1e12),\n    UINT64_C(0x3a283c7f7774dcaf), UINT64_C(0x2fbeae54ef0a2a90),\n    UINT64_C(0x11051828478930d1), UINT64_C(0x04938a03dff7c6ee),\n    UINT64_C(0x0eccdc1003552cb1), UINT64_C(0x1b5a4e3b9b2bda8e),\n    UINT64_C(0x25e1f84733a8c0cf), UINT64_C(0x30776a6cabd636f0),\n    UINT64_C(0x589694be62aef44d), UINT64_C(0x4d000695fad00272),\n    UINT64_C(0x73bbb0e952531833), UINT64_C(0x662d22c2ca2dee0c),\n    UINT64_C(0xa2784d4cc0a29d49), UINT64_C(0xb7eedf6758dc6b76),\n    UINT64_C(0x8955691bf05f7137), UINT64_C(0x9cc3fb3068218708),\n    UINT64_C(0xf42205e2a15945b5), UINT64_C(0xe1b497c93927b38a),\n    UINT64_C(0xdf0f21b591a4a9cb), UINT64_C(0xca99b39e09da5ff4),\n    UINT64_C(0xc57d51822bb451c4), UINT64_C(0xd0ebc3a9b3caa7fb),\n    UINT64_C(0xee5075d51b49bdba), UINT64_C(0xfbc6e7fe83374b85),\n    UINT64_C(0x9327192c4a4f8938), UINT64_C(0x86b18b07d2317f07),\n    UINT64_C(0xb80a3d7b7ab26546), UINT64_C(0xad9caf50e2cc9379),\n    UINT64_C(0x69c9c0dee843e03c), UINT64_C(0x7c5f52f5703d1603),\n    UINT64_C(0x42e4e489d8be0c42), UINT64_C(0x577276a240c0fa7d),\n    UINT64_C(0x3f93887089b838c0), UINT64_C(0x2a051a5b11c6ceff),\n    UINT64_C(0x14beac27b945d4be), UINT64_C(0x01283e0c213b2281),\n    UINT64_C(0x16eed03ffb3391bc), UINT64_C(0x03784214634d6783),\n    UINT64_C(0x3dc3f468cbce7dc2), UINT64_C(0x2855664353b08bfd),\n    UINT64_C(0x40b498919ac84940), UINT64_C(0x55220aba02b6bf7f),\n    UINT64_C(0x6b99bcc6aa35a53e), UINT64_C(0x7e0f2eed324b5301),\n    UINT64_C(0xba5a416338c42044), UINT64_C(0xafccd348a0bad67b),\n    UINT64_C(0x917765340839cc3a), UINT64_C(0x84e1f71f90473a05),\n    UINT64_C(0xec0009cd593ff8b8), UINT64_C(0xf9969be6c1410e87),\n    UINT64_C(0xc72d2d9a69c214c6), UINT64_C(0xd2bbbfb1f1bce2f9),\n    UINT64_C(0xdd5f5dadd3d2ecc9), UINT64_C(0xc8c9cf864bac1af6),\n    UINT64_C(0xf67279fae32f00b7), UINT64_C(0xe3e4ebd17b51f688),\n    UINT64_C(0x8b051503b2293435), UINT64_C(0x9e9387282a57c20a),\n    UINT64_C(0xa028315482d4d84b), UINT64_C(0xb5bea37f1aaa2e74),\n    UINT64_C(0x71ebccf110255d31), UINT64_C(0x647d5eda885bab0e),\n    UINT64_C(0x5ac6e8a620d8b14f), UINT64_C(0x4f507a8db8a64770),\n    UINT64_C(0x27b1845f71de85cd), UINT64_C(0x32271674e9a073f2),\n    UINT64_C(0x0c9ca008412369b3), UINT64_C(0x190a3223d95d9f8c),\n    UINT64_C(0x1355643005ff75d3), UINT64_C(0x06c3f61b9d8183ec),\n    UINT64_C(0x38784067350299ad), UINT64_C(0x2deed24cad7c6f92),\n    UINT64_C(0x450f2c9e6404ad2f), UINT64_C(0x5099beb5fc7a5b10),\n    UINT64_C(0x6e2208c954f94151), UINT64_C(0x7bb49ae2cc87b76e),\n    UINT64_C(0xbfe1f56cc608c42b), UINT64_C(0xaa7767475e763214),\n    UINT64_C(0x94ccd13bf6f52855), UINT64_C(0x815a43106e8bde6a),\n    UINT64_C(0xe9bbbdc2a7f31cd7), UINT64_C(0xfc2d2fe93f8deae8),\n    UINT64_C(0xc2969995970ef0a9), UINT64_C(0xd7000bbe0f700696),\n    UINT64_C(0xd8e4e9a22d1e08a6), UINT64_C(0xcd727b89b560fe99),\n    UINT64_C(0xf3c9cdf51de3e4d8), UINT64_C(0xe65f5fde859d12e7),\n    UINT64_C(0x8ebea10c4ce5d05a), UINT64_C(0x9b283327d49b2665),\n    UINT64_C(0xa593855b7c183c24), UINT64_C(0xb0051770e466ca1b),\n    UINT64_C(0x745078feeee9b95e), UINT64_C(0x61c6ead576974f61),\n    UINT64_C(0x5f7d5ca9de145520), UINT64_C(0x4aebce82466aa31f),\n    UINT64_C(0x220a30508f1261a2), UINT64_C(0x379ca27b176c979d),\n    UINT64_C(0x09271407bfef8ddc), UINT64_C(0x1cb1862c27917be3),\n    UINT64_C(0x1d99b82006aa5962), UINT64_C(0x080f2a0b9ed4af5d),\n    UINT64_C(0x36b49c773657b51c), UINT64_C(0x23220e5cae294323),\n    UINT64_C(0x4bc3f08e6751819e), UINT64_C(0x5e5562a5ff2f77a1),\n    UINT64_C(0x60eed4d957ac6de0), UINT64_C(0x757846f2cfd29bdf),\n    UINT64_C(0xb12d297cc55de89a), UINT64_C(0xa4bbbb575d231ea5),\n    UINT64_C(0x9a000d2bf5a004e4), UINT64_C(0x8f969f006ddef2db),\n    UINT64_C(0xe77761d2a4a63066), UINT64_C(0xf2e1f3f93cd8c659),\n    UINT64_C(0xcc5a4585945bdc18), UINT64_C(0xd9ccd7ae0c252a27),\n    UINT64_C(0xd62835b22e4b2417), UINT64_C(0xc3bea799b635d228),\n    UINT64_C(0xfd0511e51eb6c869), UINT64_C(0xe89383ce86c83e56),\n    UINT64_C(0x80727d1c4fb0fceb), UINT64_C(0x95e4ef37d7ce0ad4),\n    UINT64_C(0xab5f594b7f4d1095), UINT64_C(0xbec9cb60e733e6aa),\n    UINT64_C(0x7a9ca4eeedbc95ef), UINT64_C(0x6f0a36c575c263d0),\n    UINT64_C(0x51b180b9dd417991), UINT64_C(0x44271292453f8fae),\n    UINT64_C(0x2cc6ec408c474d13), UINT64_C(0x39507e6b1439bb2c),\n    UINT64_C(0x07ebc817bcbaa16d), UINT64_C(0x127d5a3c24c45752),\n    UINT64_C(0x18220c2ff866bd0d), UINT64_C(0x0db49e0460184b32),\n    UINT64_C(0x330f2878c89b5173), UINT64_C(0x2699ba5350e5a74c),\n    UINT64_C(0x4e784481999d65f1), UINT64_C(0x5beed6aa01e393ce),\n    UINT64_C(0x655560d6a960898f), UINT64_C(0x70c3f2fd311e7fb0),\n    UINT64_C(0xb4969d733b910cf5), UINT64_C(0xa1000f58a3effaca),\n    UINT64_C(0x9fbbb9240b6ce08b), UINT64_C(0x8a2d2b0f931216b4),\n    UINT64_C(0xe2ccd5dd5a6ad409), UINT64_C(0xf75a47f6c2142236),\n    UINT64_C(0xc9e1f18a6a973877), UINT64_C(0xdc7763a1f2e9ce48),\n    UINT64_C(0xd39381bdd087c078), UINT64_C(0xc605139648f93647),\n    UINT64_C(0xf8bea5eae07a2c06), UINT64_C(0xed2837c17804da39),\n    UINT64_C(0x85c9c913b17c1884), UINT64_C(0x905f5b382902eebb),\n    UINT64_C(0xaee4ed448181f4fa), UINT64_C(0xbb727f6f19ff02c5),\n    UINT64_C(0x7f2710e113707180), UINT64_C(0x6ab182ca8b0e87bf),\n    UINT64_C(0x540a34b6238d9dfe), UINT64_C(0x419ca69dbbf36bc1),\n    UINT64_C(0x297d584f728ba97c), UINT64_C(0x3cebca64eaf55f43),\n    UINT64_C(0x02507c1842764502), UINT64_C(0x17c6ee33da08b33d)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x2ddda07ff6672378),\n    UINT64_C(0x5bbb40ffecce46f0), UINT64_C(0x7666e0801aa96588),\n    UINT64_C(0xb77681ffd99c8de0), UINT64_C(0x9aab21802ffbae98),\n    UINT64_C(0xeccdc1003552cb10), UINT64_C(0xc110617fc335e868),\n    UINT64_C(0xfc35acd41c370545), UINT64_C(0xd1e80cabea50263d),\n    UINT64_C(0xa78eec2bf0f943b5), UINT64_C(0x8a534c54069e60cd),\n    UINT64_C(0x4b432d2bc5ab88a5), UINT64_C(0x669e8d5433ccabdd),\n    UINT64_C(0x10f86dd42965ce55), UINT64_C(0x3d25cdabdf02ed2d),\n    UINT64_C(0x6ab3f6839760140f), UINT64_C(0x476e56fc61073777),\n    UINT64_C(0x3108b67c7bae52ff), UINT64_C(0x1cd516038dc97187),\n    UINT64_C(0xddc5777c4efc99ef), UINT64_C(0xf018d703b89bba97),\n    UINT64_C(0x867e3783a232df1f), UINT64_C(0xaba397fc5455fc67),\n    UINT64_C(0x96865a578b57114a), UINT64_C(0xbb5bfa287d303232),\n    UINT64_C(0xcd3d1aa8679957ba), UINT64_C(0xe0e0bad791fe74c2),\n    UINT64_C(0x21f0dba852cb9caa), UINT64_C(0x0c2d7bd7a4acbfd2),\n    UINT64_C(0x7a4b9b57be05da5a), UINT64_C(0x57963b284862f922),\n    UINT64_C(0xd567ed072ec0281e), UINT64_C(0xf8ba4d78d8a70b66),\n    UINT64_C(0x8edcadf8c20e6eee), UINT64_C(0xa3010d8734694d96),\n    UINT64_C(0x62116cf8f75ca5fe), UINT64_C(0x4fcccc87013b8686),\n    UINT64_C(0x39aa2c071b92e30e), UINT64_C(0x14778c78edf5c076),\n    UINT64_C(0x295241d332f72d5b), UINT64_C(0x048fe1acc4900e23),\n    UINT64_C(0x72e9012cde396bab), UINT64_C(0x5f34a153285e48d3),\n    UINT64_C(0x9e24c02ceb6ba0bb), UINT64_C(0xb3f960531d0c83c3),\n    UINT64_C(0xc59f80d307a5e64b), UINT64_C(0xe84220acf1c2c533),\n    UINT64_C(0xbfd41b84b9a03c11), UINT64_C(0x9209bbfb4fc71f69),\n    UINT64_C(0xe46f5b7b556e7ae1), UINT64_C(0xc9b2fb04a3095999),\n    UINT64_C(0x08a29a7b603cb1f1), UINT64_C(0x257f3a04965b9289),\n    UINT64_C(0x5319da848cf2f701), UINT64_C(0x7ec47afb7a95d479),\n    UINT64_C(0x43e1b750a5973954), UINT64_C(0x6e3c172f53f01a2c),\n    UINT64_C(0x185af7af49597fa4), UINT64_C(0x358757d0bf3e5cdc),\n    UINT64_C(0xf49736af7c0bb4b4), UINT64_C(0xd94a96d08a6c97cc),\n    UINT64_C(0xaf2c765090c5f244), UINT64_C(0x82f1d62f66a2d13c),\n    UINT64_C(0x38177525f28e4eb9), UINT64_C(0x15cad55a04e96dc1),\n    UINT64_C(0x63ac35da1e400849), UINT64_C(0x4e7195a5e8272b31),\n    UINT64_C(0x8f61f4da2b12c359), UINT64_C(0xa2bc54a5dd75e021),\n    UINT64_C(0xd4dab425c7dc85a9), UINT64_C(0xf907145a31bba6d1),\n    UINT64_C(0xc422d9f1eeb94bfc), UINT64_C(0xe9ff798e18de6884),\n    UINT64_C(0x9f99990e02770d0c), UINT64_C(0xb2443971f4102e74),\n    UINT64_C(0x7354580e3725c61c), UINT64_C(0x5e89f871c142e564),\n    UINT64_C(0x28ef18f1dbeb80ec), UINT64_C(0x0532b88e2d8ca394),\n    UINT64_C(0x52a483a665ee5ab6), UINT64_C(0x7f7923d9938979ce),\n    UINT64_C(0x091fc35989201c46), UINT64_C(0x24c263267f473f3e),\n    UINT64_C(0xe5d20259bc72d756), UINT64_C(0xc80fa2264a15f42e),\n    UINT64_C(0xbe6942a650bc91a6), UINT64_C(0x93b4e2d9a6dbb2de),\n    UINT64_C(0xae912f7279d95ff3), UINT64_C(0x834c8f0d8fbe7c8b),\n    UINT64_C(0xf52a6f8d95171903), UINT64_C(0xd8f7cff263703a7b),\n    UINT64_C(0x19e7ae8da045d213), UINT64_C(0x343a0ef25622f16b),\n    UINT64_C(0x425cee724c8b94e3), UINT64_C(0x6f814e0dbaecb79b),\n    UINT64_C(0xed709822dc4e66a7), UINT64_C(0xc0ad385d2a2945df),\n    UINT64_C(0xb6cbd8dd30802057), UINT64_C(0x9b1678a2c6e7032f),\n    UINT64_C(0x5a0619dd05d2eb47), UINT64_C(0x77dbb9a2f3b5c83f),\n    UINT64_C(0x01bd5922e91cadb7), UINT64_C(0x2c60f95d1f7b8ecf),\n    UINT64_C(0x114534f6c07963e2), UINT64_C(0x3c989489361e409a),\n    UINT64_C(0x4afe74092cb72512), UINT64_C(0x6723d476dad0066a),\n    UINT64_C(0xa633b50919e5ee02), UINT64_C(0x8bee1576ef82cd7a),\n    UINT64_C(0xfd88f5f6f52ba8f2), UINT64_C(0xd0555589034c8b8a),\n    UINT64_C(0x87c36ea14b2e72a8), UINT64_C(0xaa1ecedebd4951d0),\n    UINT64_C(0xdc782e5ea7e03458), UINT64_C(0xf1a58e2151871720),\n    UINT64_C(0x30b5ef5e92b2ff48), UINT64_C(0x1d684f2164d5dc30),\n    UINT64_C(0x6b0eafa17e7cb9b8), UINT64_C(0x46d30fde881b9ac0),\n    UINT64_C(0x7bf6c275571977ed), UINT64_C(0x562b620aa17e5495),\n    UINT64_C(0x204d828abbd7311d), UINT64_C(0x0d9022f54db01265),\n    UINT64_C(0xcc80438a8e85fa0d), UINT64_C(0xe15de3f578e2d975),\n    UINT64_C(0x973b0375624bbcfd), UINT64_C(0xbae6a30a942c9f85),\n    UINT64_C(0x702eea4be51c9d72), UINT64_C(0x5df34a34137bbe0a),\n    UINT64_C(0x2b95aab409d2db82), UINT64_C(0x06480acbffb5f8fa),\n    UINT64_C(0xc7586bb43c801092), UINT64_C(0xea85cbcbcae733ea),\n    UINT64_C(0x9ce32b4bd04e5662), UINT64_C(0xb13e8b342629751a),\n    UINT64_C(0x8c1b469ff92b9837), UINT64_C(0xa1c6e6e00f4cbb4f),\n    UINT64_C(0xd7a0066015e5dec7), UINT64_C(0xfa7da61fe382fdbf),\n    UINT64_C(0x3b6dc76020b715d7), UINT64_C(0x16b0671fd6d036af),\n    UINT64_C(0x60d6879fcc795327), UINT64_C(0x4d0b27e03a1e705f),\n    UINT64_C(0x1a9d1cc8727c897d), UINT64_C(0x3740bcb7841baa05),\n    UINT64_C(0x41265c379eb2cf8d), UINT64_C(0x6cfbfc4868d5ecf5),\n    UINT64_C(0xadeb9d37abe0049d), UINT64_C(0x80363d485d8727e5),\n    UINT64_C(0xf650ddc8472e426d), UINT64_C(0xdb8d7db7b1496115),\n    UINT64_C(0xe6a8b01c6e4b8c38), UINT64_C(0xcb751063982caf40),\n    UINT64_C(0xbd13f0e38285cac8), UINT64_C(0x90ce509c74e2e9b0),\n    UINT64_C(0x51de31e3b7d701d8), UINT64_C(0x7c03919c41b022a0),\n    UINT64_C(0x0a65711c5b194728), UINT64_C(0x27b8d163ad7e6450),\n    UINT64_C(0xa549074ccbdcb56c), UINT64_C(0x8894a7333dbb9614),\n    UINT64_C(0xfef247b32712f39c), UINT64_C(0xd32fe7ccd175d0e4),\n    UINT64_C(0x123f86b31240388c), UINT64_C(0x3fe226cce4271bf4),\n    UINT64_C(0x4984c64cfe8e7e7c), UINT64_C(0x6459663308e95d04),\n    UINT64_C(0x597cab98d7ebb029), UINT64_C(0x74a10be7218c9351),\n    UINT64_C(0x02c7eb673b25f6d9), UINT64_C(0x2f1a4b18cd42d5a1),\n    UINT64_C(0xee0a2a670e773dc9), UINT64_C(0xc3d78a18f8101eb1),\n    UINT64_C(0xb5b16a98e2b97b39), UINT64_C(0x986ccae714de5841),\n    UINT64_C(0xcffaf1cf5cbca163), UINT64_C(0xe22751b0aadb821b),\n    UINT64_C(0x9441b130b072e793), UINT64_C(0xb99c114f4615c4eb),\n    UINT64_C(0x788c703085202c83), UINT64_C(0x5551d04f73470ffb),\n    UINT64_C(0x233730cf69ee6a73), UINT64_C(0x0eea90b09f89490b),\n    UINT64_C(0x33cf5d1b408ba426), UINT64_C(0x1e12fd64b6ec875e),\n    UINT64_C(0x68741de4ac45e2d6), UINT64_C(0x45a9bd9b5a22c1ae),\n    UINT64_C(0x84b9dce4991729c6), UINT64_C(0xa9647c9b6f700abe),\n    UINT64_C(0xdf029c1b75d96f36), UINT64_C(0xf2df3c6483be4c4e),\n    UINT64_C(0x48399f6e1792d3cb), UINT64_C(0x65e43f11e1f5f0b3),\n    UINT64_C(0x1382df91fb5c953b), UINT64_C(0x3e5f7fee0d3bb643),\n    UINT64_C(0xff4f1e91ce0e5e2b), UINT64_C(0xd292beee38697d53),\n    UINT64_C(0xa4f45e6e22c018db), UINT64_C(0x8929fe11d4a73ba3),\n    UINT64_C(0xb40c33ba0ba5d68e), UINT64_C(0x99d193c5fdc2f5f6),\n    UINT64_C(0xefb77345e76b907e), UINT64_C(0xc26ad33a110cb306),\n    UINT64_C(0x037ab245d2395b6e), UINT64_C(0x2ea7123a245e7816),\n    UINT64_C(0x58c1f2ba3ef71d9e), UINT64_C(0x751c52c5c8903ee6),\n    UINT64_C(0x228a69ed80f2c7c4), UINT64_C(0x0f57c9927695e4bc),\n    UINT64_C(0x793129126c3c8134), UINT64_C(0x54ec896d9a5ba24c),\n    UINT64_C(0x95fce812596e4a24), UINT64_C(0xb821486daf09695c),\n    UINT64_C(0xce47a8edb5a00cd4), UINT64_C(0xe39a089243c72fac),\n    UINT64_C(0xdebfc5399cc5c281), UINT64_C(0xf36265466aa2e1f9),\n    UINT64_C(0x850485c6700b8471), UINT64_C(0xa8d925b9866ca709),\n    UINT64_C(0x69c944c645594f61), UINT64_C(0x4414e4b9b33e6c19),\n    UINT64_C(0x32720439a9970991), UINT64_C(0x1fafa4465ff02ae9),\n    UINT64_C(0x9d5e72693952fbd5), UINT64_C(0xb083d216cf35d8ad),\n    UINT64_C(0xc6e53296d59cbd25), UINT64_C(0xeb3892e923fb9e5d),\n    UINT64_C(0x2a28f396e0ce7635), UINT64_C(0x07f553e916a9554d),\n    UINT64_C(0x7193b3690c0030c5), UINT64_C(0x5c4e1316fa6713bd),\n    UINT64_C(0x616bdebd2565fe90), UINT64_C(0x4cb67ec2d302dde8),\n    UINT64_C(0x3ad09e42c9abb860), UINT64_C(0x170d3e3d3fcc9b18),\n    UINT64_C(0xd61d5f42fcf97370), UINT64_C(0xfbc0ff3d0a9e5008),\n    UINT64_C(0x8da61fbd10373580), UINT64_C(0xa07bbfc2e65016f8),\n    UINT64_C(0xf7ed84eaae32efda), UINT64_C(0xda3024955855cca2),\n    UINT64_C(0xac56c41542fca92a), UINT64_C(0x818b646ab49b8a52),\n    UINT64_C(0x409b051577ae623a), UINT64_C(0x6d46a56a81c94142),\n    UINT64_C(0x1b2045ea9b6024ca), UINT64_C(0x36fde5956d0707b2),\n    UINT64_C(0x0bd8283eb205ea9f), UINT64_C(0x260588414462c9e7),\n    UINT64_C(0x506368c15ecbac6f), UINT64_C(0x7dbec8bea8ac8f17),\n    UINT64_C(0xbcaea9c16b99677f), UINT64_C(0x917309be9dfe4407),\n    UINT64_C(0xe715e93e8757218f), UINT64_C(0xcac84941713002f7)\n  }\n};\n\n#pragma omp end declare target\n\nuint64_t crc64_slow(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  uint64_t cs = UINT64_C(0xffffffffffffffff);\n\n  while (nbytes--) {\n    uint32_t idx = ((uint32_t) (cs ^ *data++)) & 0xff;\n    cs = crc64_table[3][idx] ^ (cs >> 8);\n  }\n\n  return cs ^ UINT64_C(0xffffffffffffffff);\n}\n\n#pragma omp declare target\n\n\nstatic inline uint32_t crc64_load_le32_(const uint32_t *p) {\n  uint32_t w = *p;\n  return  ((((w) & 0xff000000) >> 24)\n         | (((w) & 0x00ff0000) >>  8)\n         | (((w) & 0x0000ff00) <<  8)\n         | (((w) & 0x000000ff) << 24));\n}\n\n\n\n\n\nuint64_t crc64(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  const unsigned char *end = data + nbytes;\n  uint64_t cs[5] = { UINT64_C(0xffffffffffffffff), 0, 0, 0, 0 };\n\n  \n\n  \n\n  \n\n  \n\n  while (data < end && ((((size_t) data) & 3) || (end - data < 20))) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  if (data == end)\n    return cs[0] ^ UINT64_C(0xffffffffffffffff);\n\n  const uint32_t one = 1;\n  bool big_endian = !(*((char *)(&one)));\n\n  uint64_t cry = 0;\n  uint32_t in[5];\n\n  if (!big_endian) {\n    for (unsigned i = 0; i < 5; ++i)\n      in[i] = ((const uint32_t*) data)[i];\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = ((const uint32_t*) data)[0];\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = ((const uint32_t*) data)[1];\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = ((const uint32_t*) data)[2];\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = ((const uint32_t*) data)[3];\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = ((const uint32_t*) data)[4];\n    }\n  } else {\n    for (unsigned i = 0; i < 5; ++i) {\n      in[i] = crc64_load_le32_(&((const uint32_t*) data)[i]);\n    }\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = crc64_load_le32_(&((const uint32_t*) data)[0]);\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = crc64_load_le32_(&((const uint32_t*) data)[1]);\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = crc64_load_le32_(&((const uint32_t*) data)[2]);\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = crc64_load_le32_(&((const uint32_t*) data)[3]);\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = crc64_load_le32_(&((const uint32_t*) data)[4]);\n    }\n  }\n\n  cs[0] ^= cry;\n\n  for (unsigned i = 0; i < 5; ++i) {\n    if (i > 0)\n      cs[0] ^= cs[i];\n    in[i] ^= (uint32_t) cs[0];\n    cs[0] = cs[0] >> 32;\n\n    for (unsigned b = 0; b < 3; ++b) {\n      cs[0] ^= crc64_table[b][in[i] & 0xff];\n      in[i] >>= 8;\n    }\n\n    cs[0] ^= crc64_table[3][in[i] & 0xff];\n  }\n\n  while (data < end) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  return cs[0] ^ UINT64_C(0xffffffffffffffff);\n}\n#pragma omp end declare target\n\n\n\n\n\nvoid crc64_invert(uint64_t cs, void *check_bytes) {\n  unsigned char *bytes = (unsigned char *) check_bytes;\n  cs ^= UINT64_C(0xffffffffffffffff);\n\n  \n\n  \n\n  bytes[7] = (cs >> 56) & 0xff;\n  bytes[6] = (cs >> 48) & 0xff;\n  bytes[5] = (cs >> 40) & 0xff;\n  bytes[4] = (cs >> 32) & 0xff;\n  bytes[3] = (cs >> 24) & 0xff;\n  bytes[2] = (cs >> 16) & 0xff;\n  bytes[1] = (cs >>  8) & 0xff;\n  bytes[0] =  cs        & 0xff;\n}\n\nstatic const uint64_t crc64_x_pow_2n[64] = {\n  UINT64_C(0x4000000000000000), UINT64_C(0x2000000000000000),\n  UINT64_C(0x0800000000000000), UINT64_C(0x0080000000000000),\n  UINT64_C(0x0000800000000000), UINT64_C(0x0000000080000000),\n  UINT64_C(0xc96c5795d7870f42), UINT64_C(0x6d5f4ad7e3c3afa0),\n  UINT64_C(0xd49f7e445077d8ea), UINT64_C(0x040fb02a53c216fa),\n  UINT64_C(0x6bec35957b9ef3a0), UINT64_C(0xb0e3bb0658964afe),\n  UINT64_C(0x218578c7a2dff638), UINT64_C(0x6dbb920f24dd5cf2),\n  UINT64_C(0x7a140cfcdb4d5eb5), UINT64_C(0x41b3705ecbc4057b),\n  UINT64_C(0xd46ab656accac1ea), UINT64_C(0x329beda6fc34fb73),\n  UINT64_C(0x51a4fcd4350b9797), UINT64_C(0x314fa85637efae9d),\n  UINT64_C(0xacf27e9a1518d512), UINT64_C(0xffe2a3388a4d8ce7),\n  UINT64_C(0x48b9697e60cc2e4e), UINT64_C(0xada73cb78dd62460),\n  UINT64_C(0x3ea5454d8ce5c1bb), UINT64_C(0x5e84e3a6c70feaf1),\n  UINT64_C(0x90fd49b66cbd81d1), UINT64_C(0xe2943e0c1db254e8),\n  UINT64_C(0xecfa6adeca8834a1), UINT64_C(0xf513e212593ee321),\n  UINT64_C(0xf36ae57331040916), UINT64_C(0x63fbd333b87b6717),\n  UINT64_C(0xbd60f8e152f50b8b), UINT64_C(0xa5ce4a8299c1567d),\n  UINT64_C(0x0bd445f0cbdb55ee), UINT64_C(0xfdd6824e20134285),\n  UINT64_C(0xcead8b6ebda2227a), UINT64_C(0xe44b17e4f5d4fb5c),\n  UINT64_C(0x9b29c81ad01ca7c5), UINT64_C(0x1b4366e40fea4055),\n  UINT64_C(0x27bca1551aae167b), UINT64_C(0xaa57bcd1b39a5690),\n  UINT64_C(0xd7fce83fa1234db9), UINT64_C(0xcce4986efea3ff8e),\n  UINT64_C(0x3602a4d9e65341f1), UINT64_C(0x722b1da2df516145),\n  UINT64_C(0xecfc3ddd3a08da83), UINT64_C(0x0fb96dcca83507e6),\n  UINT64_C(0x125f2fe78d70f080), UINT64_C(0x842f50b7651aa516),\n  UINT64_C(0x09bc34188cd9836f), UINT64_C(0xf43666c84196d909),\n  UINT64_C(0xb56feb30c0df6ccb), UINT64_C(0xaa66e04ce7f30958),\n  UINT64_C(0xb7b1187e9af29547), UINT64_C(0x113255f8476495de),\n  UINT64_C(0x8fb19f783095d77e), UINT64_C(0xaec4aacc7c82b133),\n  UINT64_C(0xf64e6d09218428cf), UINT64_C(0x036a72ea5ac258a0),\n  UINT64_C(0x5235ef12eb7aaa6a), UINT64_C(0x2fed7b1685657853),\n  UINT64_C(0x8ef8951d46606fb5), UINT64_C(0x9d58c1090f034d14)\n};\n\n\n\n\n\nstatic inline uint64_t crc64_multiply_(uint64_t a, uint64_t b) {\n  if ((a ^ (a-1)) < (b ^ (b-1))) {\n    uint64_t t = a;\n    a = b;\n    b = t;\n  }\n\n  if (a == 0)\n    return 0;\n\n  uint64_t r = 0, h = UINT64_C(1) << 63;\n  for (; a != 0; a <<= 1) {\n    if (a & h) {\n      r ^= b;\n      a ^= h;\n    }\n\n    b = (b >> 1) ^ ((b & 1) ? crc64_poly : 0);\n  }\n\n  return r;\n}\n\n\n\nstatic inline uint64_t crc64_x_pow_n_(uint64_t n) {\n  uint64_t r = UINT64_C(1) << 63;\n  for (size_t i = 0; n != 0; n >>= 1, ++i) {\n    if (n & 1)\n      r = crc64_multiply_(r, crc64_x_pow_2n[i]);\n  }\n\n  return r;\n}\n\nuint64_t crc64_combine(uint64_t cs1, uint64_t cs2, size_t nbytes2) {\n  \n\n  \n\n  return cs2 ^ crc64_multiply_(cs1, crc64_x_pow_n_(8*nbytes2));\n}\n\nstatic const size_t crc64_min_thread_bytes = 1024;\n\nuint64_t crc64_omp(const void *input, size_t nbytes) {\n\n#ifdef _OPENMP\n  if (nbytes > 2*crc64_min_thread_bytes) {\n    int nthreads = 96*8*32;\n\n    if (nbytes < nthreads*crc64_min_thread_bytes)\n      nthreads = nbytes/crc64_min_thread_bytes;\n\n    uint64_t thread_cs[nthreads];\n    size_t thread_sz[nthreads];\n\n    const unsigned char *data = (const unsigned char*) input;\n\n    #pragma omp target data map(from: thread_sz[0:nthreads], thread_cs[0:nthreads]) \\\n                            map(to: data[0:nbytes], crc64_table[0:4][0:256], \\\n                                    crc64_interleaved_table[0:4][0:256])\n    {\n       #pragma omp target teams distribute parallel for num_teams(nthreads/64) thread_limit(64)\n       for (int tid = 0; tid < nthreads; tid++) {\n          size_t bpt = nbytes/nthreads;\n          const unsigned char *start = data + bpt*tid, *end;\n          if (tid != nthreads - 1)\n            end = start + bpt;\n          else\n            end = data + nbytes;\n    \n          size_t sz = end - start;\n          thread_sz[tid] = sz;\n          thread_cs[tid] = crc64(start, sz);\n       }\n    }\n\n    uint64_t cs = thread_cs[0];\n    for (int i = 1; i < nthreads; ++i) {\n      cs = crc64_combine(cs, thread_cs[i], thread_sz[i]);\n    }\n\n    return cs;\n  }\n#endif\n\n  return crc64(input, nbytes);\n}\n", "CRC64Test.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define _XOPEN_SOURCE 600\n\n#include <ctime>\n#include <vector>\n#include <iostream>\n#include \"CRC64.h\"\n\nusing namespace std;\nint main(int argc, char *argv[]) {\n  int ntests = 10;\n  if (argc > 1) ntests = atoi(argv[1]);\n\n  int seed = 5;\n  if (argc > 2) seed = atoi(argv[2]);\n\n  int max_test_length = 2097152;\n  if (argc > 3) max_test_length = atoi(argv[3]);\n\n  cout << \"Running \" << ntests << \" tests with seed \" << seed << endl;\n\n  srand48(seed);\n\n#ifdef __bgp__\n#define THE_CLOCK CLOCK_REALTIME\n#else\n#define THE_CLOCK CLOCK_THREAD_CPUTIME_ID\n#endif\n\n  double tot_time = 0, tot_bytes = 0;\n\n  int ntest = 0;\n  while (++ntest <= ntests) {\n    cout << ntest << \" \";\n\n    size_t test_length = (size_t) (max_test_length*(drand48()+1));\n    cout << test_length << \" \";\n\n    vector<unsigned char> buffer(test_length);\n\n    for (size_t i = 0; i < test_length; ++i) {\n      buffer[i] = (unsigned char) (255*drand48());\n    }\n\n    timespec b_start, b_end;\n    clock_gettime(THE_CLOCK, &b_start);\n\n    uint64_t cs = crc64_omp(&buffer[0], test_length);\n\n    clock_gettime(THE_CLOCK, &b_end);\n    double b_time = (b_end.tv_sec - b_start.tv_sec);\n    b_time += 1e-9*(b_end.tv_nsec - b_start.tv_nsec);\n\n    if (ntest > 1) {\n      tot_time += b_time;\n      tot_bytes += test_length;\n    }\n\n    \n\n    size_t tlend = 8;\n    buffer.resize(test_length + tlend, 0);\n    crc64_invert(cs, &buffer[test_length]);\n\n    string pass(\"pass\"), fail(\"fail\");\n    uint64_t csc = crc64(&buffer[0], test_length+tlend);\n    cout << ((csc == (uint64_t) -1) ? pass : fail) << \" \";\n\n    size_t div_pt = (size_t) (test_length*drand48());\n    uint64_t cs1 = crc64(&buffer[0], div_pt);\n    uint64_t cs2 = crc64(&buffer[div_pt], test_length - div_pt);\n    csc = crc64_combine(cs1, cs2, test_length - div_pt);\n    cout << ((csc == cs) ? pass : fail);\n\n    cout << endl;\n  }\n\n  cout << (tot_bytes/(1024*1024))/tot_time << \" MB/s\" << endl;\n\n  return 0;\n}\n"}}
{"kernel_name": "crc64", "parallel_api": "serial", "code": {"CRC64.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef __STDC_CONSTANT_MACROS\n#define __STDC_CONSTANT_MACROS\n#endif\n\n#include \"CRC64.h\"\n\n#ifdef HAVE_CONFIG_H\n#include <config.h>\n#endif\n\n#ifdef _OPENMP\n#endif\n\n#include <stdbool.h>\n\n\n\nstatic const uint64_t crc64_poly = UINT64_C(0xc96c5795d7870f42);\n\nstatic const uint64_t crc64_table[4][256] = {\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x1dee8a5e222ca1dc),\n    UINT64_C(0x3bdd14bc445943b8), UINT64_C(0x26339ee26675e264),\n    UINT64_C(0x77ba297888b28770), UINT64_C(0x6a54a326aa9e26ac),\n    UINT64_C(0x4c673dc4ccebc4c8), UINT64_C(0x5189b79aeec76514),\n    UINT64_C(0xef7452f111650ee0), UINT64_C(0xf29ad8af3349af3c),\n    UINT64_C(0xd4a9464d553c4d58), UINT64_C(0xc947cc137710ec84),\n    UINT64_C(0x98ce7b8999d78990), UINT64_C(0x8520f1d7bbfb284c),\n    UINT64_C(0xa3136f35dd8eca28), UINT64_C(0xbefde56bffa26bf4),\n    UINT64_C(0x4c300ac98dc40345), UINT64_C(0x51de8097afe8a299),\n    UINT64_C(0x77ed1e75c99d40fd), UINT64_C(0x6a03942bebb1e121),\n    UINT64_C(0x3b8a23b105768435), UINT64_C(0x2664a9ef275a25e9),\n    UINT64_C(0x0057370d412fc78d), UINT64_C(0x1db9bd5363036651),\n    UINT64_C(0xa34458389ca10da5), UINT64_C(0xbeaad266be8dac79),\n    UINT64_C(0x98994c84d8f84e1d), UINT64_C(0x8577c6dafad4efc1),\n    UINT64_C(0xd4fe714014138ad5), UINT64_C(0xc910fb1e363f2b09),\n    UINT64_C(0xef2365fc504ac96d), UINT64_C(0xf2cdefa2726668b1),\n    UINT64_C(0x986015931b88068a), UINT64_C(0x858e9fcd39a4a756),\n    UINT64_C(0xa3bd012f5fd14532), UINT64_C(0xbe538b717dfde4ee),\n    UINT64_C(0xefda3ceb933a81fa), UINT64_C(0xf234b6b5b1162026),\n    UINT64_C(0xd4072857d763c242), UINT64_C(0xc9e9a209f54f639e),\n    UINT64_C(0x771447620aed086a), UINT64_C(0x6afacd3c28c1a9b6),\n    UINT64_C(0x4cc953de4eb44bd2), UINT64_C(0x5127d9806c98ea0e),\n    UINT64_C(0x00ae6e1a825f8f1a), UINT64_C(0x1d40e444a0732ec6),\n    UINT64_C(0x3b737aa6c606cca2), UINT64_C(0x269df0f8e42a6d7e),\n    UINT64_C(0xd4501f5a964c05cf), UINT64_C(0xc9be9504b460a413),\n    UINT64_C(0xef8d0be6d2154677), UINT64_C(0xf26381b8f039e7ab),\n    UINT64_C(0xa3ea36221efe82bf), UINT64_C(0xbe04bc7c3cd22363),\n    UINT64_C(0x9837229e5aa7c107), UINT64_C(0x85d9a8c0788b60db),\n    UINT64_C(0x3b244dab87290b2f), UINT64_C(0x26cac7f5a505aaf3),\n    UINT64_C(0x00f95917c3704897), UINT64_C(0x1d17d349e15ce94b),\n    UINT64_C(0x4c9e64d30f9b8c5f), UINT64_C(0x5170ee8d2db72d83),\n    UINT64_C(0x7743706f4bc2cfe7), UINT64_C(0x6aadfa3169ee6e3b),\n    UINT64_C(0xa218840d981e1391), UINT64_C(0xbff60e53ba32b24d),\n    UINT64_C(0x99c590b1dc475029), UINT64_C(0x842b1aeffe6bf1f5),\n    UINT64_C(0xd5a2ad7510ac94e1), UINT64_C(0xc84c272b3280353d),\n    UINT64_C(0xee7fb9c954f5d759), UINT64_C(0xf391339776d97685),\n    UINT64_C(0x4d6cd6fc897b1d71), UINT64_C(0x50825ca2ab57bcad),\n    UINT64_C(0x76b1c240cd225ec9), UINT64_C(0x6b5f481eef0eff15),\n    UINT64_C(0x3ad6ff8401c99a01), UINT64_C(0x273875da23e53bdd),\n    UINT64_C(0x010beb384590d9b9), UINT64_C(0x1ce5616667bc7865),\n    UINT64_C(0xee288ec415da10d4), UINT64_C(0xf3c6049a37f6b108),\n    UINT64_C(0xd5f59a785183536c), UINT64_C(0xc81b102673aff2b0),\n    UINT64_C(0x9992a7bc9d6897a4), UINT64_C(0x847c2de2bf443678),\n    UINT64_C(0xa24fb300d931d41c), UINT64_C(0xbfa1395efb1d75c0),\n    UINT64_C(0x015cdc3504bf1e34), UINT64_C(0x1cb2566b2693bfe8),\n    UINT64_C(0x3a81c88940e65d8c), UINT64_C(0x276f42d762cafc50),\n    UINT64_C(0x76e6f54d8c0d9944), UINT64_C(0x6b087f13ae213898),\n    UINT64_C(0x4d3be1f1c854dafc), UINT64_C(0x50d56bafea787b20),\n    UINT64_C(0x3a78919e8396151b), UINT64_C(0x27961bc0a1bab4c7),\n    UINT64_C(0x01a58522c7cf56a3), UINT64_C(0x1c4b0f7ce5e3f77f),\n    UINT64_C(0x4dc2b8e60b24926b), UINT64_C(0x502c32b8290833b7),\n    UINT64_C(0x761fac5a4f7dd1d3), UINT64_C(0x6bf126046d51700f),\n    UINT64_C(0xd50cc36f92f31bfb), UINT64_C(0xc8e24931b0dfba27),\n    UINT64_C(0xeed1d7d3d6aa5843), UINT64_C(0xf33f5d8df486f99f),\n    UINT64_C(0xa2b6ea171a419c8b), UINT64_C(0xbf586049386d3d57),\n    UINT64_C(0x996bfeab5e18df33), UINT64_C(0x848574f57c347eef),\n    UINT64_C(0x76489b570e52165e), UINT64_C(0x6ba611092c7eb782),\n    UINT64_C(0x4d958feb4a0b55e6), UINT64_C(0x507b05b56827f43a),\n    UINT64_C(0x01f2b22f86e0912e), UINT64_C(0x1c1c3871a4cc30f2),\n    UINT64_C(0x3a2fa693c2b9d296), UINT64_C(0x27c12ccde095734a),\n    UINT64_C(0x993cc9a61f3718be), UINT64_C(0x84d243f83d1bb962),\n    UINT64_C(0xa2e1dd1a5b6e5b06), UINT64_C(0xbf0f57447942fada),\n    UINT64_C(0xee86e0de97859fce), UINT64_C(0xf3686a80b5a93e12),\n    UINT64_C(0xd55bf462d3dcdc76), UINT64_C(0xc8b57e3cf1f07daa),\n    UINT64_C(0xd6e9a7309f3239a7), UINT64_C(0xcb072d6ebd1e987b),\n    UINT64_C(0xed34b38cdb6b7a1f), UINT64_C(0xf0da39d2f947dbc3),\n    UINT64_C(0xa1538e481780bed7), UINT64_C(0xbcbd041635ac1f0b),\n    UINT64_C(0x9a8e9af453d9fd6f), UINT64_C(0x876010aa71f55cb3),\n    UINT64_C(0x399df5c18e573747), UINT64_C(0x24737f9fac7b969b),\n    UINT64_C(0x0240e17dca0e74ff), UINT64_C(0x1fae6b23e822d523),\n    UINT64_C(0x4e27dcb906e5b037), UINT64_C(0x53c956e724c911eb),\n    UINT64_C(0x75fac80542bcf38f), UINT64_C(0x6814425b60905253),\n    UINT64_C(0x9ad9adf912f63ae2), UINT64_C(0x873727a730da9b3e),\n    UINT64_C(0xa104b94556af795a), UINT64_C(0xbcea331b7483d886),\n    UINT64_C(0xed6384819a44bd92), UINT64_C(0xf08d0edfb8681c4e),\n    UINT64_C(0xd6be903dde1dfe2a), UINT64_C(0xcb501a63fc315ff6),\n    UINT64_C(0x75adff0803933402), UINT64_C(0x6843755621bf95de),\n    UINT64_C(0x4e70ebb447ca77ba), UINT64_C(0x539e61ea65e6d666),\n    UINT64_C(0x0217d6708b21b372), UINT64_C(0x1ff95c2ea90d12ae),\n    UINT64_C(0x39cac2cccf78f0ca), UINT64_C(0x24244892ed545116),\n    UINT64_C(0x4e89b2a384ba3f2d), UINT64_C(0x536738fda6969ef1),\n    UINT64_C(0x7554a61fc0e37c95), UINT64_C(0x68ba2c41e2cfdd49),\n    UINT64_C(0x39339bdb0c08b85d), UINT64_C(0x24dd11852e241981),\n    UINT64_C(0x02ee8f674851fbe5), UINT64_C(0x1f0005396a7d5a39),\n    UINT64_C(0xa1fde05295df31cd), UINT64_C(0xbc136a0cb7f39011),\n    UINT64_C(0x9a20f4eed1867275), UINT64_C(0x87ce7eb0f3aad3a9),\n    UINT64_C(0xd647c92a1d6db6bd), UINT64_C(0xcba943743f411761),\n    UINT64_C(0xed9add965934f505), UINT64_C(0xf07457c87b1854d9),\n    UINT64_C(0x02b9b86a097e3c68), UINT64_C(0x1f5732342b529db4),\n    UINT64_C(0x3964acd64d277fd0), UINT64_C(0x248a26886f0bde0c),\n    UINT64_C(0x7503911281ccbb18), UINT64_C(0x68ed1b4ca3e01ac4),\n    UINT64_C(0x4ede85aec595f8a0), UINT64_C(0x53300ff0e7b9597c),\n    UINT64_C(0xedcdea9b181b3288), UINT64_C(0xf02360c53a379354),\n    UINT64_C(0xd610fe275c427130), UINT64_C(0xcbfe74797e6ed0ec),\n    UINT64_C(0x9a77c3e390a9b5f8), UINT64_C(0x879949bdb2851424),\n    UINT64_C(0xa1aad75fd4f0f640), UINT64_C(0xbc445d01f6dc579c),\n    UINT64_C(0x74f1233d072c2a36), UINT64_C(0x691fa96325008bea),\n    UINT64_C(0x4f2c37814375698e), UINT64_C(0x52c2bddf6159c852),\n    UINT64_C(0x034b0a458f9ead46), UINT64_C(0x1ea5801badb20c9a),\n    UINT64_C(0x38961ef9cbc7eefe), UINT64_C(0x257894a7e9eb4f22),\n    UINT64_C(0x9b8571cc164924d6), UINT64_C(0x866bfb923465850a),\n    UINT64_C(0xa05865705210676e), UINT64_C(0xbdb6ef2e703cc6b2),\n    UINT64_C(0xec3f58b49efba3a6), UINT64_C(0xf1d1d2eabcd7027a),\n    UINT64_C(0xd7e24c08daa2e01e), UINT64_C(0xca0cc656f88e41c2),\n    UINT64_C(0x38c129f48ae82973), UINT64_C(0x252fa3aaa8c488af),\n    UINT64_C(0x031c3d48ceb16acb), UINT64_C(0x1ef2b716ec9dcb17),\n    UINT64_C(0x4f7b008c025aae03), UINT64_C(0x52958ad220760fdf),\n    UINT64_C(0x74a614304603edbb), UINT64_C(0x69489e6e642f4c67),\n    UINT64_C(0xd7b57b059b8d2793), UINT64_C(0xca5bf15bb9a1864f),\n    UINT64_C(0xec686fb9dfd4642b), UINT64_C(0xf186e5e7fdf8c5f7),\n    UINT64_C(0xa00f527d133fa0e3), UINT64_C(0xbde1d8233113013f),\n    UINT64_C(0x9bd246c15766e35b), UINT64_C(0x863ccc9f754a4287),\n    UINT64_C(0xec9136ae1ca42cbc), UINT64_C(0xf17fbcf03e888d60),\n    UINT64_C(0xd74c221258fd6f04), UINT64_C(0xcaa2a84c7ad1ced8),\n    UINT64_C(0x9b2b1fd69416abcc), UINT64_C(0x86c59588b63a0a10),\n    UINT64_C(0xa0f60b6ad04fe874), UINT64_C(0xbd188134f26349a8),\n    UINT64_C(0x03e5645f0dc1225c), UINT64_C(0x1e0bee012fed8380),\n    UINT64_C(0x383870e3499861e4), UINT64_C(0x25d6fabd6bb4c038),\n    UINT64_C(0x745f4d278573a52c), UINT64_C(0x69b1c779a75f04f0),\n    UINT64_C(0x4f82599bc12ae694), UINT64_C(0x526cd3c5e3064748),\n    UINT64_C(0xa0a13c6791602ff9), UINT64_C(0xbd4fb639b34c8e25),\n    UINT64_C(0x9b7c28dbd5396c41), UINT64_C(0x8692a285f715cd9d),\n    UINT64_C(0xd71b151f19d2a889), UINT64_C(0xcaf59f413bfe0955),\n    UINT64_C(0xecc601a35d8beb31), UINT64_C(0xf1288bfd7fa74aed),\n    UINT64_C(0x4fd56e9680052119), UINT64_C(0x523be4c8a22980c5),\n    UINT64_C(0x74087a2ac45c62a1), UINT64_C(0x69e6f074e670c37d),\n    UINT64_C(0x386f47ee08b7a669), UINT64_C(0x2581cdb02a9b07b5),\n    UINT64_C(0x03b253524ceee5d1), UINT64_C(0x1e5cd90c6ec2440d)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x3f0be14a916a6dcb),\n    UINT64_C(0x7e17c29522d4db96), UINT64_C(0x411c23dfb3beb65d),\n    UINT64_C(0xfc2f852a45a9b72c), UINT64_C(0xc3246460d4c3dae7),\n    UINT64_C(0x823847bf677d6cba), UINT64_C(0xbd33a6f5f6170171),\n    UINT64_C(0x6a87a57f245d70dd), UINT64_C(0x558c4435b5371d16),\n    UINT64_C(0x149067ea0689ab4b), UINT64_C(0x2b9b86a097e3c680),\n    UINT64_C(0x96a8205561f4c7f1), UINT64_C(0xa9a3c11ff09eaa3a),\n    UINT64_C(0xe8bfe2c043201c67), UINT64_C(0xd7b4038ad24a71ac),\n    UINT64_C(0xd50f4afe48bae1ba), UINT64_C(0xea04abb4d9d08c71),\n    UINT64_C(0xab18886b6a6e3a2c), UINT64_C(0x94136921fb0457e7),\n    UINT64_C(0x2920cfd40d135696), UINT64_C(0x162b2e9e9c793b5d),\n    UINT64_C(0x57370d412fc78d00), UINT64_C(0x683cec0bbeade0cb),\n    UINT64_C(0xbf88ef816ce79167), UINT64_C(0x80830ecbfd8dfcac),\n    UINT64_C(0xc19f2d144e334af1), UINT64_C(0xfe94cc5edf59273a),\n    UINT64_C(0x43a76aab294e264b), UINT64_C(0x7cac8be1b8244b80),\n    UINT64_C(0x3db0a83e0b9afddd), UINT64_C(0x02bb49749af09016),\n    UINT64_C(0x38c63ad73e7bddf1), UINT64_C(0x07cddb9daf11b03a),\n    UINT64_C(0x46d1f8421caf0667), UINT64_C(0x79da19088dc56bac),\n    UINT64_C(0xc4e9bffd7bd26add), UINT64_C(0xfbe25eb7eab80716),\n    UINT64_C(0xbafe7d685906b14b), UINT64_C(0x85f59c22c86cdc80),\n    UINT64_C(0x52419fa81a26ad2c), UINT64_C(0x6d4a7ee28b4cc0e7),\n    UINT64_C(0x2c565d3d38f276ba), UINT64_C(0x135dbc77a9981b71),\n    UINT64_C(0xae6e1a825f8f1a00), UINT64_C(0x9165fbc8cee577cb),\n    UINT64_C(0xd079d8177d5bc196), UINT64_C(0xef72395dec31ac5d),\n    UINT64_C(0xedc9702976c13c4b), UINT64_C(0xd2c29163e7ab5180),\n    UINT64_C(0x93deb2bc5415e7dd), UINT64_C(0xacd553f6c57f8a16),\n    UINT64_C(0x11e6f50333688b67), UINT64_C(0x2eed1449a202e6ac),\n    UINT64_C(0x6ff1379611bc50f1), UINT64_C(0x50fad6dc80d63d3a),\n    UINT64_C(0x874ed556529c4c96), UINT64_C(0xb845341cc3f6215d),\n    UINT64_C(0xf95917c370489700), UINT64_C(0xc652f689e122facb),\n    UINT64_C(0x7b61507c1735fbba), UINT64_C(0x446ab136865f9671),\n    UINT64_C(0x057692e935e1202c), UINT64_C(0x3a7d73a3a48b4de7),\n    UINT64_C(0x718c75ae7cf7bbe2), UINT64_C(0x4e8794e4ed9dd629),\n    UINT64_C(0x0f9bb73b5e236074), UINT64_C(0x30905671cf490dbf),\n    UINT64_C(0x8da3f084395e0cce), UINT64_C(0xb2a811cea8346105),\n    UINT64_C(0xf3b432111b8ad758), UINT64_C(0xccbfd35b8ae0ba93),\n    UINT64_C(0x1b0bd0d158aacb3f), UINT64_C(0x2400319bc9c0a6f4),\n    UINT64_C(0x651c12447a7e10a9), UINT64_C(0x5a17f30eeb147d62),\n    UINT64_C(0xe72455fb1d037c13), UINT64_C(0xd82fb4b18c6911d8),\n    UINT64_C(0x9933976e3fd7a785), UINT64_C(0xa6387624aebdca4e),\n    UINT64_C(0xa4833f50344d5a58), UINT64_C(0x9b88de1aa5273793),\n    UINT64_C(0xda94fdc5169981ce), UINT64_C(0xe59f1c8f87f3ec05),\n    UINT64_C(0x58acba7a71e4ed74), UINT64_C(0x67a75b30e08e80bf),\n    UINT64_C(0x26bb78ef533036e2), UINT64_C(0x19b099a5c25a5b29),\n    UINT64_C(0xce049a2f10102a85), UINT64_C(0xf10f7b65817a474e),\n    UINT64_C(0xb01358ba32c4f113), UINT64_C(0x8f18b9f0a3ae9cd8),\n    UINT64_C(0x322b1f0555b99da9), UINT64_C(0x0d20fe4fc4d3f062),\n    UINT64_C(0x4c3cdd90776d463f), UINT64_C(0x73373cdae6072bf4),\n    UINT64_C(0x494a4f79428c6613), UINT64_C(0x7641ae33d3e60bd8),\n    UINT64_C(0x375d8dec6058bd85), UINT64_C(0x08566ca6f132d04e),\n    UINT64_C(0xb565ca530725d13f), UINT64_C(0x8a6e2b19964fbcf4),\n    UINT64_C(0xcb7208c625f10aa9), UINT64_C(0xf479e98cb49b6762),\n    UINT64_C(0x23cdea0666d116ce), UINT64_C(0x1cc60b4cf7bb7b05),\n    UINT64_C(0x5dda28934405cd58), UINT64_C(0x62d1c9d9d56fa093),\n    UINT64_C(0xdfe26f2c2378a1e2), UINT64_C(0xe0e98e66b212cc29),\n    UINT64_C(0xa1f5adb901ac7a74), UINT64_C(0x9efe4cf390c617bf),\n    UINT64_C(0x9c4505870a3687a9), UINT64_C(0xa34ee4cd9b5cea62),\n    UINT64_C(0xe252c71228e25c3f), UINT64_C(0xdd592658b98831f4),\n    UINT64_C(0x606a80ad4f9f3085), UINT64_C(0x5f6161e7def55d4e),\n    UINT64_C(0x1e7d42386d4beb13), UINT64_C(0x2176a372fc2186d8),\n    UINT64_C(0xf6c2a0f82e6bf774), UINT64_C(0xc9c941b2bf019abf),\n    UINT64_C(0x88d5626d0cbf2ce2), UINT64_C(0xb7de83279dd54129),\n    UINT64_C(0x0aed25d26bc24058), UINT64_C(0x35e6c498faa82d93),\n    UINT64_C(0x74fae74749169bce), UINT64_C(0x4bf1060dd87cf605),\n    UINT64_C(0xe318eb5cf9ef77c4), UINT64_C(0xdc130a1668851a0f),\n    UINT64_C(0x9d0f29c9db3bac52), UINT64_C(0xa204c8834a51c199),\n    UINT64_C(0x1f376e76bc46c0e8), UINT64_C(0x203c8f3c2d2cad23),\n    UINT64_C(0x6120ace39e921b7e), UINT64_C(0x5e2b4da90ff876b5),\n    UINT64_C(0x899f4e23ddb20719), UINT64_C(0xb694af694cd86ad2),\n    UINT64_C(0xf7888cb6ff66dc8f), UINT64_C(0xc8836dfc6e0cb144),\n    UINT64_C(0x75b0cb09981bb035), UINT64_C(0x4abb2a430971ddfe),\n    UINT64_C(0x0ba7099cbacf6ba3), UINT64_C(0x34ace8d62ba50668),\n    UINT64_C(0x3617a1a2b155967e), UINT64_C(0x091c40e8203ffbb5),\n    UINT64_C(0x4800633793814de8), UINT64_C(0x770b827d02eb2023),\n    UINT64_C(0xca382488f4fc2152), UINT64_C(0xf533c5c265964c99),\n    UINT64_C(0xb42fe61dd628fac4), UINT64_C(0x8b2407574742970f),\n    UINT64_C(0x5c9004dd9508e6a3), UINT64_C(0x639be59704628b68),\n    UINT64_C(0x2287c648b7dc3d35), UINT64_C(0x1d8c270226b650fe),\n    UINT64_C(0xa0bf81f7d0a1518f), UINT64_C(0x9fb460bd41cb3c44),\n    UINT64_C(0xdea84362f2758a19), UINT64_C(0xe1a3a228631fe7d2),\n    UINT64_C(0xdbded18bc794aa35), UINT64_C(0xe4d530c156fec7fe),\n    UINT64_C(0xa5c9131ee54071a3), UINT64_C(0x9ac2f254742a1c68),\n    UINT64_C(0x27f154a1823d1d19), UINT64_C(0x18fab5eb135770d2),\n    UINT64_C(0x59e69634a0e9c68f), UINT64_C(0x66ed777e3183ab44),\n    UINT64_C(0xb15974f4e3c9dae8), UINT64_C(0x8e5295be72a3b723),\n    UINT64_C(0xcf4eb661c11d017e), UINT64_C(0xf045572b50776cb5),\n    UINT64_C(0x4d76f1dea6606dc4), UINT64_C(0x727d1094370a000f),\n    UINT64_C(0x3361334b84b4b652), UINT64_C(0x0c6ad20115dedb99),\n    UINT64_C(0x0ed19b758f2e4b8f), UINT64_C(0x31da7a3f1e442644),\n    UINT64_C(0x70c659e0adfa9019), UINT64_C(0x4fcdb8aa3c90fdd2),\n    UINT64_C(0xf2fe1e5fca87fca3), UINT64_C(0xcdf5ff155bed9168),\n    UINT64_C(0x8ce9dccae8532735), UINT64_C(0xb3e23d8079394afe),\n    UINT64_C(0x64563e0aab733b52), UINT64_C(0x5b5ddf403a195699),\n    UINT64_C(0x1a41fc9f89a7e0c4), UINT64_C(0x254a1dd518cd8d0f),\n    UINT64_C(0x9879bb20eeda8c7e), UINT64_C(0xa7725a6a7fb0e1b5),\n    UINT64_C(0xe66e79b5cc0e57e8), UINT64_C(0xd96598ff5d643a23),\n    UINT64_C(0x92949ef28518cc26), UINT64_C(0xad9f7fb81472a1ed),\n    UINT64_C(0xec835c67a7cc17b0), UINT64_C(0xd388bd2d36a67a7b),\n    UINT64_C(0x6ebb1bd8c0b17b0a), UINT64_C(0x51b0fa9251db16c1),\n    UINT64_C(0x10acd94de265a09c), UINT64_C(0x2fa73807730fcd57),\n    UINT64_C(0xf8133b8da145bcfb), UINT64_C(0xc718dac7302fd130),\n    UINT64_C(0x8604f9188391676d), UINT64_C(0xb90f185212fb0aa6),\n    UINT64_C(0x043cbea7e4ec0bd7), UINT64_C(0x3b375fed7586661c),\n    UINT64_C(0x7a2b7c32c638d041), UINT64_C(0x45209d785752bd8a),\n    UINT64_C(0x479bd40ccda22d9c), UINT64_C(0x789035465cc84057),\n    UINT64_C(0x398c1699ef76f60a), UINT64_C(0x0687f7d37e1c9bc1),\n    UINT64_C(0xbbb45126880b9ab0), UINT64_C(0x84bfb06c1961f77b),\n    UINT64_C(0xc5a393b3aadf4126), UINT64_C(0xfaa872f93bb52ced),\n    UINT64_C(0x2d1c7173e9ff5d41), UINT64_C(0x121790397895308a),\n    UINT64_C(0x530bb3e6cb2b86d7), UINT64_C(0x6c0052ac5a41eb1c),\n    UINT64_C(0xd133f459ac56ea6d), UINT64_C(0xee3815133d3c87a6),\n    UINT64_C(0xaf2436cc8e8231fb), UINT64_C(0x902fd7861fe85c30),\n    UINT64_C(0xaa52a425bb6311d7), UINT64_C(0x9559456f2a097c1c),\n    UINT64_C(0xd44566b099b7ca41), UINT64_C(0xeb4e87fa08dda78a),\n    UINT64_C(0x567d210ffecaa6fb), UINT64_C(0x6976c0456fa0cb30),\n    UINT64_C(0x286ae39adc1e7d6d), UINT64_C(0x176102d04d7410a6),\n    UINT64_C(0xc0d5015a9f3e610a), UINT64_C(0xffdee0100e540cc1),\n    UINT64_C(0xbec2c3cfbdeaba9c), UINT64_C(0x81c922852c80d757),\n    UINT64_C(0x3cfa8470da97d626), UINT64_C(0x03f1653a4bfdbbed),\n    UINT64_C(0x42ed46e5f8430db0), UINT64_C(0x7de6a7af6929607b),\n    UINT64_C(0x7f5deedbf3d9f06d), UINT64_C(0x40560f9162b39da6),\n    UINT64_C(0x014a2c4ed10d2bfb), UINT64_C(0x3e41cd0440674630),\n    UINT64_C(0x83726bf1b6704741), UINT64_C(0xbc798abb271a2a8a),\n    UINT64_C(0xfd65a96494a49cd7), UINT64_C(0xc26e482e05cef11c),\n    UINT64_C(0x15da4ba4d78480b0), UINT64_C(0x2ad1aaee46eeed7b),\n    UINT64_C(0x6bcd8931f5505b26), UINT64_C(0x54c6687b643a36ed),\n    UINT64_C(0xe9f5ce8e922d379c), UINT64_C(0xd6fe2fc403475a57),\n    UINT64_C(0x97e20c1bb0f9ec0a), UINT64_C(0xa8e9ed51219381c1)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x54e979925cd0f10d),\n    UINT64_C(0xa9d2f324b9a1e21a), UINT64_C(0xfd3b8ab6e5711317),\n    UINT64_C(0xc17d4962dc4ddab1), UINT64_C(0x959430f0809d2bbc),\n    UINT64_C(0x68afba4665ec38ab), UINT64_C(0x3c46c3d4393cc9a6),\n    UINT64_C(0x10223dee1795abe7), UINT64_C(0x44cb447c4b455aea),\n    UINT64_C(0xb9f0cecaae3449fd), UINT64_C(0xed19b758f2e4b8f0),\n    UINT64_C(0xd15f748ccbd87156), UINT64_C(0x85b60d1e9708805b),\n    UINT64_C(0x788d87a87279934c), UINT64_C(0x2c64fe3a2ea96241),\n    UINT64_C(0x20447bdc2f2b57ce), UINT64_C(0x74ad024e73fba6c3),\n    UINT64_C(0x899688f8968ab5d4), UINT64_C(0xdd7ff16aca5a44d9),\n    UINT64_C(0xe13932bef3668d7f), UINT64_C(0xb5d04b2cafb67c72),\n    UINT64_C(0x48ebc19a4ac76f65), UINT64_C(0x1c02b80816179e68),\n    UINT64_C(0x3066463238befc29), UINT64_C(0x648f3fa0646e0d24),\n    UINT64_C(0x99b4b516811f1e33), UINT64_C(0xcd5dcc84ddcfef3e),\n    UINT64_C(0xf11b0f50e4f32698), UINT64_C(0xa5f276c2b823d795),\n    UINT64_C(0x58c9fc745d52c482), UINT64_C(0x0c2085e60182358f),\n    UINT64_C(0x4088f7b85e56af9c), UINT64_C(0x14618e2a02865e91),\n    UINT64_C(0xe95a049ce7f74d86), UINT64_C(0xbdb37d0ebb27bc8b),\n    UINT64_C(0x81f5beda821b752d), UINT64_C(0xd51cc748decb8420),\n    UINT64_C(0x28274dfe3bba9737), UINT64_C(0x7cce346c676a663a),\n    UINT64_C(0x50aaca5649c3047b), UINT64_C(0x0443b3c41513f576),\n    UINT64_C(0xf9783972f062e661), UINT64_C(0xad9140e0acb2176c),\n    UINT64_C(0x91d78334958edeca), UINT64_C(0xc53efaa6c95e2fc7),\n    UINT64_C(0x380570102c2f3cd0), UINT64_C(0x6cec098270ffcddd),\n    UINT64_C(0x60cc8c64717df852), UINT64_C(0x3425f5f62dad095f),\n    UINT64_C(0xc91e7f40c8dc1a48), UINT64_C(0x9df706d2940ceb45),\n    UINT64_C(0xa1b1c506ad3022e3), UINT64_C(0xf558bc94f1e0d3ee),\n    UINT64_C(0x086336221491c0f9), UINT64_C(0x5c8a4fb0484131f4),\n    UINT64_C(0x70eeb18a66e853b5), UINT64_C(0x2407c8183a38a2b8),\n    UINT64_C(0xd93c42aedf49b1af), UINT64_C(0x8dd53b3c839940a2),\n    UINT64_C(0xb193f8e8baa58904), UINT64_C(0xe57a817ae6757809),\n    UINT64_C(0x18410bcc03046b1e), UINT64_C(0x4ca8725e5fd49a13),\n    UINT64_C(0x8111ef70bcad5f38), UINT64_C(0xd5f896e2e07dae35),\n    UINT64_C(0x28c31c54050cbd22), UINT64_C(0x7c2a65c659dc4c2f),\n    UINT64_C(0x406ca61260e08589), UINT64_C(0x1485df803c307484),\n    UINT64_C(0xe9be5536d9416793), UINT64_C(0xbd572ca48591969e),\n    UINT64_C(0x9133d29eab38f4df), UINT64_C(0xc5daab0cf7e805d2),\n    UINT64_C(0x38e121ba129916c5), UINT64_C(0x6c0858284e49e7c8),\n    UINT64_C(0x504e9bfc77752e6e), UINT64_C(0x04a7e26e2ba5df63),\n    UINT64_C(0xf99c68d8ced4cc74), UINT64_C(0xad75114a92043d79),\n    UINT64_C(0xa15594ac938608f6), UINT64_C(0xf5bced3ecf56f9fb),\n    UINT64_C(0x088767882a27eaec), UINT64_C(0x5c6e1e1a76f71be1),\n    UINT64_C(0x6028ddce4fcbd247), UINT64_C(0x34c1a45c131b234a),\n    UINT64_C(0xc9fa2eeaf66a305d), UINT64_C(0x9d135778aabac150),\n    UINT64_C(0xb177a9428413a311), UINT64_C(0xe59ed0d0d8c3521c),\n    UINT64_C(0x18a55a663db2410b), UINT64_C(0x4c4c23f46162b006),\n    UINT64_C(0x700ae020585e79a0), UINT64_C(0x24e399b2048e88ad),\n    UINT64_C(0xd9d81304e1ff9bba), UINT64_C(0x8d316a96bd2f6ab7),\n    UINT64_C(0xc19918c8e2fbf0a4), UINT64_C(0x9570615abe2b01a9),\n    UINT64_C(0x684bebec5b5a12be), UINT64_C(0x3ca2927e078ae3b3),\n    UINT64_C(0x00e451aa3eb62a15), UINT64_C(0x540d28386266db18),\n    UINT64_C(0xa936a28e8717c80f), UINT64_C(0xfddfdb1cdbc73902),\n    UINT64_C(0xd1bb2526f56e5b43), UINT64_C(0x85525cb4a9beaa4e),\n    UINT64_C(0x7869d6024ccfb959), UINT64_C(0x2c80af90101f4854),\n    UINT64_C(0x10c66c44292381f2), UINT64_C(0x442f15d675f370ff),\n    UINT64_C(0xb9149f60908263e8), UINT64_C(0xedfde6f2cc5292e5),\n    UINT64_C(0xe1dd6314cdd0a76a), UINT64_C(0xb5341a8691005667),\n    UINT64_C(0x480f903074714570), UINT64_C(0x1ce6e9a228a1b47d),\n    UINT64_C(0x20a02a76119d7ddb), UINT64_C(0x744953e44d4d8cd6),\n    UINT64_C(0x8972d952a83c9fc1), UINT64_C(0xdd9ba0c0f4ec6ecc),\n    UINT64_C(0xf1ff5efada450c8d), UINT64_C(0xa51627688695fd80),\n    UINT64_C(0x582dadde63e4ee97), UINT64_C(0x0cc4d44c3f341f9a),\n    UINT64_C(0x308217980608d63c), UINT64_C(0x646b6e0a5ad82731),\n    UINT64_C(0x9950e4bcbfa93426), UINT64_C(0xcdb99d2ee379c52b),\n    UINT64_C(0x90fb71cad654a0f5), UINT64_C(0xc41208588a8451f8),\n    UINT64_C(0x392982ee6ff542ef), UINT64_C(0x6dc0fb7c3325b3e2),\n    UINT64_C(0x518638a80a197a44), UINT64_C(0x056f413a56c98b49),\n    UINT64_C(0xf854cb8cb3b8985e), UINT64_C(0xacbdb21eef686953),\n    UINT64_C(0x80d94c24c1c10b12), UINT64_C(0xd43035b69d11fa1f),\n    UINT64_C(0x290bbf007860e908), UINT64_C(0x7de2c69224b01805),\n    UINT64_C(0x41a405461d8cd1a3), UINT64_C(0x154d7cd4415c20ae),\n    UINT64_C(0xe876f662a42d33b9), UINT64_C(0xbc9f8ff0f8fdc2b4),\n    UINT64_C(0xb0bf0a16f97ff73b), UINT64_C(0xe4567384a5af0636),\n    UINT64_C(0x196df93240de1521), UINT64_C(0x4d8480a01c0ee42c),\n    UINT64_C(0x71c2437425322d8a), UINT64_C(0x252b3ae679e2dc87),\n    UINT64_C(0xd810b0509c93cf90), UINT64_C(0x8cf9c9c2c0433e9d),\n    UINT64_C(0xa09d37f8eeea5cdc), UINT64_C(0xf4744e6ab23aadd1),\n    UINT64_C(0x094fc4dc574bbec6), UINT64_C(0x5da6bd4e0b9b4fcb),\n    UINT64_C(0x61e07e9a32a7866d), UINT64_C(0x350907086e777760),\n    UINT64_C(0xc8328dbe8b066477), UINT64_C(0x9cdbf42cd7d6957a),\n    UINT64_C(0xd073867288020f69), UINT64_C(0x849affe0d4d2fe64),\n    UINT64_C(0x79a1755631a3ed73), UINT64_C(0x2d480cc46d731c7e),\n    UINT64_C(0x110ecf10544fd5d8), UINT64_C(0x45e7b682089f24d5),\n    UINT64_C(0xb8dc3c34edee37c2), UINT64_C(0xec3545a6b13ec6cf),\n    UINT64_C(0xc051bb9c9f97a48e), UINT64_C(0x94b8c20ec3475583),\n    UINT64_C(0x698348b826364694), UINT64_C(0x3d6a312a7ae6b799),\n    UINT64_C(0x012cf2fe43da7e3f), UINT64_C(0x55c58b6c1f0a8f32),\n    UINT64_C(0xa8fe01dafa7b9c25), UINT64_C(0xfc177848a6ab6d28),\n    UINT64_C(0xf037fdaea72958a7), UINT64_C(0xa4de843cfbf9a9aa),\n    UINT64_C(0x59e50e8a1e88babd), UINT64_C(0x0d0c771842584bb0),\n    UINT64_C(0x314ab4cc7b648216), UINT64_C(0x65a3cd5e27b4731b),\n    UINT64_C(0x989847e8c2c5600c), UINT64_C(0xcc713e7a9e159101),\n    UINT64_C(0xe015c040b0bcf340), UINT64_C(0xb4fcb9d2ec6c024d),\n    UINT64_C(0x49c73364091d115a), UINT64_C(0x1d2e4af655cde057),\n    UINT64_C(0x216889226cf129f1), UINT64_C(0x7581f0b03021d8fc),\n    UINT64_C(0x88ba7a06d550cbeb), UINT64_C(0xdc53039489803ae6),\n    UINT64_C(0x11ea9eba6af9ffcd), UINT64_C(0x4503e72836290ec0),\n    UINT64_C(0xb8386d9ed3581dd7), UINT64_C(0xecd1140c8f88ecda),\n    UINT64_C(0xd097d7d8b6b4257c), UINT64_C(0x847eae4aea64d471),\n    UINT64_C(0x794524fc0f15c766), UINT64_C(0x2dac5d6e53c5366b),\n    UINT64_C(0x01c8a3547d6c542a), UINT64_C(0x5521dac621bca527),\n    UINT64_C(0xa81a5070c4cdb630), UINT64_C(0xfcf329e2981d473d),\n    UINT64_C(0xc0b5ea36a1218e9b), UINT64_C(0x945c93a4fdf17f96),\n    UINT64_C(0x6967191218806c81), UINT64_C(0x3d8e608044509d8c),\n    UINT64_C(0x31aee56645d2a803), UINT64_C(0x65479cf41902590e),\n    UINT64_C(0x987c1642fc734a19), UINT64_C(0xcc956fd0a0a3bb14),\n    UINT64_C(0xf0d3ac04999f72b2), UINT64_C(0xa43ad596c54f83bf),\n    UINT64_C(0x59015f20203e90a8), UINT64_C(0x0de826b27cee61a5),\n    UINT64_C(0x218cd888524703e4), UINT64_C(0x7565a11a0e97f2e9),\n    UINT64_C(0x885e2bacebe6e1fe), UINT64_C(0xdcb7523eb73610f3),\n    UINT64_C(0xe0f191ea8e0ad955), UINT64_C(0xb418e878d2da2858),\n    UINT64_C(0x492362ce37ab3b4f), UINT64_C(0x1dca1b5c6b7bca42),\n    UINT64_C(0x5162690234af5051), UINT64_C(0x058b1090687fa15c),\n    UINT64_C(0xf8b09a268d0eb24b), UINT64_C(0xac59e3b4d1de4346),\n    UINT64_C(0x901f2060e8e28ae0), UINT64_C(0xc4f659f2b4327bed),\n    UINT64_C(0x39cdd344514368fa), UINT64_C(0x6d24aad60d9399f7),\n    UINT64_C(0x414054ec233afbb6), UINT64_C(0x15a92d7e7fea0abb),\n    UINT64_C(0xe892a7c89a9b19ac), UINT64_C(0xbc7bde5ac64be8a1),\n    UINT64_C(0x803d1d8eff772107), UINT64_C(0xd4d4641ca3a7d00a),\n    UINT64_C(0x29efeeaa46d6c31d), UINT64_C(0x7d0697381a063210),\n    UINT64_C(0x712612de1b84079f), UINT64_C(0x25cf6b4c4754f692),\n    UINT64_C(0xd8f4e1faa225e585), UINT64_C(0x8c1d9868fef51488),\n    UINT64_C(0xb05b5bbcc7c9dd2e), UINT64_C(0xe4b2222e9b192c23),\n    UINT64_C(0x1989a8987e683f34), UINT64_C(0x4d60d10a22b8ce39),\n    UINT64_C(0x61042f300c11ac78), UINT64_C(0x35ed56a250c15d75),\n    UINT64_C(0xc8d6dc14b5b04e62), UINT64_C(0x9c3fa586e960bf6f),\n    UINT64_C(0xa0796652d05c76c9), UINT64_C(0xf4901fc08c8c87c4),\n    UINT64_C(0x09ab957669fd94d3), UINT64_C(0x5d42ece4352d65de)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0xb32e4cbe03a75f6f),\n    UINT64_C(0xf4843657a840a05b), UINT64_C(0x47aa7ae9abe7ff34),\n    UINT64_C(0x7bd0c384ff8f5e33), UINT64_C(0xc8fe8f3afc28015c),\n    UINT64_C(0x8f54f5d357cffe68), UINT64_C(0x3c7ab96d5468a107),\n    UINT64_C(0xf7a18709ff1ebc66), UINT64_C(0x448fcbb7fcb9e309),\n    UINT64_C(0x0325b15e575e1c3d), UINT64_C(0xb00bfde054f94352),\n    UINT64_C(0x8c71448d0091e255), UINT64_C(0x3f5f08330336bd3a),\n    UINT64_C(0x78f572daa8d1420e), UINT64_C(0xcbdb3e64ab761d61),\n    UINT64_C(0x7d9ba13851336649), UINT64_C(0xceb5ed8652943926),\n    UINT64_C(0x891f976ff973c612), UINT64_C(0x3a31dbd1fad4997d),\n    UINT64_C(0x064b62bcaebc387a), UINT64_C(0xb5652e02ad1b6715),\n    UINT64_C(0xf2cf54eb06fc9821), UINT64_C(0x41e11855055bc74e),\n    UINT64_C(0x8a3a2631ae2dda2f), UINT64_C(0x39146a8fad8a8540),\n    UINT64_C(0x7ebe1066066d7a74), UINT64_C(0xcd905cd805ca251b),\n    UINT64_C(0xf1eae5b551a2841c), UINT64_C(0x42c4a90b5205db73),\n    UINT64_C(0x056ed3e2f9e22447), UINT64_C(0xb6409f5cfa457b28),\n    UINT64_C(0xfb374270a266cc92), UINT64_C(0x48190ecea1c193fd),\n    UINT64_C(0x0fb374270a266cc9), UINT64_C(0xbc9d3899098133a6),\n    UINT64_C(0x80e781f45de992a1), UINT64_C(0x33c9cd4a5e4ecdce),\n    UINT64_C(0x7463b7a3f5a932fa), UINT64_C(0xc74dfb1df60e6d95),\n    UINT64_C(0x0c96c5795d7870f4), UINT64_C(0xbfb889c75edf2f9b),\n    UINT64_C(0xf812f32ef538d0af), UINT64_C(0x4b3cbf90f69f8fc0),\n    UINT64_C(0x774606fda2f72ec7), UINT64_C(0xc4684a43a15071a8),\n    UINT64_C(0x83c230aa0ab78e9c), UINT64_C(0x30ec7c140910d1f3),\n    UINT64_C(0x86ace348f355aadb), UINT64_C(0x3582aff6f0f2f5b4),\n    UINT64_C(0x7228d51f5b150a80), UINT64_C(0xc10699a158b255ef),\n    UINT64_C(0xfd7c20cc0cdaf4e8), UINT64_C(0x4e526c720f7dab87),\n    UINT64_C(0x09f8169ba49a54b3), UINT64_C(0xbad65a25a73d0bdc),\n    UINT64_C(0x710d64410c4b16bd), UINT64_C(0xc22328ff0fec49d2),\n    UINT64_C(0x85895216a40bb6e6), UINT64_C(0x36a71ea8a7ace989),\n    UINT64_C(0x0adda7c5f3c4488e), UINT64_C(0xb9f3eb7bf06317e1),\n    UINT64_C(0xfe5991925b84e8d5), UINT64_C(0x4d77dd2c5823b7ba),\n    UINT64_C(0x64b62bcaebc387a1), UINT64_C(0xd7986774e864d8ce),\n    UINT64_C(0x90321d9d438327fa), UINT64_C(0x231c512340247895),\n    UINT64_C(0x1f66e84e144cd992), UINT64_C(0xac48a4f017eb86fd),\n    UINT64_C(0xebe2de19bc0c79c9), UINT64_C(0x58cc92a7bfab26a6),\n    UINT64_C(0x9317acc314dd3bc7), UINT64_C(0x2039e07d177a64a8),\n    UINT64_C(0x67939a94bc9d9b9c), UINT64_C(0xd4bdd62abf3ac4f3),\n    UINT64_C(0xe8c76f47eb5265f4), UINT64_C(0x5be923f9e8f53a9b),\n    UINT64_C(0x1c4359104312c5af), UINT64_C(0xaf6d15ae40b59ac0),\n    UINT64_C(0x192d8af2baf0e1e8), UINT64_C(0xaa03c64cb957be87),\n    UINT64_C(0xeda9bca512b041b3), UINT64_C(0x5e87f01b11171edc),\n    UINT64_C(0x62fd4976457fbfdb), UINT64_C(0xd1d305c846d8e0b4),\n    UINT64_C(0x96797f21ed3f1f80), UINT64_C(0x2557339fee9840ef),\n    UINT64_C(0xee8c0dfb45ee5d8e), UINT64_C(0x5da24145464902e1),\n    UINT64_C(0x1a083bacedaefdd5), UINT64_C(0xa9267712ee09a2ba),\n    UINT64_C(0x955cce7fba6103bd), UINT64_C(0x267282c1b9c65cd2),\n    UINT64_C(0x61d8f8281221a3e6), UINT64_C(0xd2f6b4961186fc89),\n    UINT64_C(0x9f8169ba49a54b33), UINT64_C(0x2caf25044a02145c),\n    UINT64_C(0x6b055fede1e5eb68), UINT64_C(0xd82b1353e242b407),\n    UINT64_C(0xe451aa3eb62a1500), UINT64_C(0x577fe680b58d4a6f),\n    UINT64_C(0x10d59c691e6ab55b), UINT64_C(0xa3fbd0d71dcdea34),\n    UINT64_C(0x6820eeb3b6bbf755), UINT64_C(0xdb0ea20db51ca83a),\n    UINT64_C(0x9ca4d8e41efb570e), UINT64_C(0x2f8a945a1d5c0861),\n    UINT64_C(0x13f02d374934a966), UINT64_C(0xa0de61894a93f609),\n    UINT64_C(0xe7741b60e174093d), UINT64_C(0x545a57dee2d35652),\n    UINT64_C(0xe21ac88218962d7a), UINT64_C(0x5134843c1b317215),\n    UINT64_C(0x169efed5b0d68d21), UINT64_C(0xa5b0b26bb371d24e),\n    UINT64_C(0x99ca0b06e7197349), UINT64_C(0x2ae447b8e4be2c26),\n    UINT64_C(0x6d4e3d514f59d312), UINT64_C(0xde6071ef4cfe8c7d),\n    UINT64_C(0x15bb4f8be788911c), UINT64_C(0xa6950335e42fce73),\n    UINT64_C(0xe13f79dc4fc83147), UINT64_C(0x521135624c6f6e28),\n    UINT64_C(0x6e6b8c0f1807cf2f), UINT64_C(0xdd45c0b11ba09040),\n    UINT64_C(0x9aefba58b0476f74), UINT64_C(0x29c1f6e6b3e0301b),\n    UINT64_C(0xc96c5795d7870f42), UINT64_C(0x7a421b2bd420502d),\n    UINT64_C(0x3de861c27fc7af19), UINT64_C(0x8ec62d7c7c60f076),\n    UINT64_C(0xb2bc941128085171), UINT64_C(0x0192d8af2baf0e1e),\n    UINT64_C(0x4638a2468048f12a), UINT64_C(0xf516eef883efae45),\n    UINT64_C(0x3ecdd09c2899b324), UINT64_C(0x8de39c222b3eec4b),\n    UINT64_C(0xca49e6cb80d9137f), UINT64_C(0x7967aa75837e4c10),\n    UINT64_C(0x451d1318d716ed17), UINT64_C(0xf6335fa6d4b1b278),\n    UINT64_C(0xb199254f7f564d4c), UINT64_C(0x02b769f17cf11223),\n    UINT64_C(0xb4f7f6ad86b4690b), UINT64_C(0x07d9ba1385133664),\n    UINT64_C(0x4073c0fa2ef4c950), UINT64_C(0xf35d8c442d53963f),\n    UINT64_C(0xcf273529793b3738), UINT64_C(0x7c0979977a9c6857),\n    UINT64_C(0x3ba3037ed17b9763), UINT64_C(0x888d4fc0d2dcc80c),\n    UINT64_C(0x435671a479aad56d), UINT64_C(0xf0783d1a7a0d8a02),\n    UINT64_C(0xb7d247f3d1ea7536), UINT64_C(0x04fc0b4dd24d2a59),\n    UINT64_C(0x3886b22086258b5e), UINT64_C(0x8ba8fe9e8582d431),\n    UINT64_C(0xcc0284772e652b05), UINT64_C(0x7f2cc8c92dc2746a),\n    UINT64_C(0x325b15e575e1c3d0), UINT64_C(0x8175595b76469cbf),\n    UINT64_C(0xc6df23b2dda1638b), UINT64_C(0x75f16f0cde063ce4),\n    UINT64_C(0x498bd6618a6e9de3), UINT64_C(0xfaa59adf89c9c28c),\n    UINT64_C(0xbd0fe036222e3db8), UINT64_C(0x0e21ac88218962d7),\n    UINT64_C(0xc5fa92ec8aff7fb6), UINT64_C(0x76d4de52895820d9),\n    UINT64_C(0x317ea4bb22bfdfed), UINT64_C(0x8250e80521188082),\n    UINT64_C(0xbe2a516875702185), UINT64_C(0x0d041dd676d77eea),\n    UINT64_C(0x4aae673fdd3081de), UINT64_C(0xf9802b81de97deb1),\n    UINT64_C(0x4fc0b4dd24d2a599), UINT64_C(0xfceef8632775faf6),\n    UINT64_C(0xbb44828a8c9205c2), UINT64_C(0x086ace348f355aad),\n    UINT64_C(0x34107759db5dfbaa), UINT64_C(0x873e3be7d8faa4c5),\n    UINT64_C(0xc094410e731d5bf1), UINT64_C(0x73ba0db070ba049e),\n    UINT64_C(0xb86133d4dbcc19ff), UINT64_C(0x0b4f7f6ad86b4690),\n    UINT64_C(0x4ce50583738cb9a4), UINT64_C(0xffcb493d702be6cb),\n    UINT64_C(0xc3b1f050244347cc), UINT64_C(0x709fbcee27e418a3),\n    UINT64_C(0x3735c6078c03e797), UINT64_C(0x841b8ab98fa4b8f8),\n    UINT64_C(0xadda7c5f3c4488e3), UINT64_C(0x1ef430e13fe3d78c),\n    UINT64_C(0x595e4a08940428b8), UINT64_C(0xea7006b697a377d7),\n    UINT64_C(0xd60abfdbc3cbd6d0), UINT64_C(0x6524f365c06c89bf),\n    UINT64_C(0x228e898c6b8b768b), UINT64_C(0x91a0c532682c29e4),\n    UINT64_C(0x5a7bfb56c35a3485), UINT64_C(0xe955b7e8c0fd6bea),\n    UINT64_C(0xaeffcd016b1a94de), UINT64_C(0x1dd181bf68bdcbb1),\n    UINT64_C(0x21ab38d23cd56ab6), UINT64_C(0x9285746c3f7235d9),\n    UINT64_C(0xd52f0e859495caed), UINT64_C(0x6601423b97329582),\n    UINT64_C(0xd041dd676d77eeaa), UINT64_C(0x636f91d96ed0b1c5),\n    UINT64_C(0x24c5eb30c5374ef1), UINT64_C(0x97eba78ec690119e),\n    UINT64_C(0xab911ee392f8b099), UINT64_C(0x18bf525d915feff6),\n    UINT64_C(0x5f1528b43ab810c2), UINT64_C(0xec3b640a391f4fad),\n    UINT64_C(0x27e05a6e926952cc), UINT64_C(0x94ce16d091ce0da3),\n    UINT64_C(0xd3646c393a29f297), UINT64_C(0x604a2087398eadf8),\n    UINT64_C(0x5c3099ea6de60cff), UINT64_C(0xef1ed5546e415390),\n    UINT64_C(0xa8b4afbdc5a6aca4), UINT64_C(0x1b9ae303c601f3cb),\n    UINT64_C(0x56ed3e2f9e224471), UINT64_C(0xe5c372919d851b1e),\n    UINT64_C(0xa26908783662e42a), UINT64_C(0x114744c635c5bb45),\n    UINT64_C(0x2d3dfdab61ad1a42), UINT64_C(0x9e13b115620a452d),\n    UINT64_C(0xd9b9cbfcc9edba19), UINT64_C(0x6a978742ca4ae576),\n    UINT64_C(0xa14cb926613cf817), UINT64_C(0x1262f598629ba778),\n    UINT64_C(0x55c88f71c97c584c), UINT64_C(0xe6e6c3cfcadb0723),\n    UINT64_C(0xda9c7aa29eb3a624), UINT64_C(0x69b2361c9d14f94b),\n    UINT64_C(0x2e184cf536f3067f), UINT64_C(0x9d36004b35545910),\n    UINT64_C(0x2b769f17cf112238), UINT64_C(0x9858d3a9ccb67d57),\n    UINT64_C(0xdff2a94067518263), UINT64_C(0x6cdce5fe64f6dd0c),\n    UINT64_C(0x50a65c93309e7c0b), UINT64_C(0xe388102d33392364),\n    UINT64_C(0xa4226ac498dedc50), UINT64_C(0x170c267a9b79833f),\n    UINT64_C(0xdcd7181e300f9e5e), UINT64_C(0x6ff954a033a8c131),\n    UINT64_C(0x28532e49984f3e05), UINT64_C(0x9b7d62f79be8616a),\n    UINT64_C(0xa707db9acf80c06d), UINT64_C(0x14299724cc279f02),\n    UINT64_C(0x5383edcd67c06036), UINT64_C(0xe0ada17364673f59)\n  }\n};\n\nstatic const uint64_t crc64_interleaved_table[4][256] = {\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0xe88a0d0c5521de3d),\n    UINT64_C(0x43ccb533054da2ff), UINT64_C(0xab46b83f506c7cc2),\n    UINT64_C(0x87996a660a9b45fe), UINT64_C(0x6f13676a5fba9bc3),\n    UINT64_C(0xc455df550fd6e701), UINT64_C(0x2cdfd2595af7393c),\n    UINT64_C(0x9dea7be7ba389579), UINT64_C(0x756076ebef194b44),\n    UINT64_C(0xde26ced4bf753786), UINT64_C(0x36acc3d8ea54e9bb),\n    UINT64_C(0x1a731181b0a3d087), UINT64_C(0xf2f91c8de5820eba),\n    UINT64_C(0x59bfa4b2b5ee7278), UINT64_C(0xb135a9bee0cfac45),\n    UINT64_C(0xa90c58e4db7f3477), UINT64_C(0x418655e88e5eea4a),\n    UINT64_C(0xeac0edd7de329688), UINT64_C(0x024ae0db8b1348b5),\n    UINT64_C(0x2e953282d1e47189), UINT64_C(0xc61f3f8e84c5afb4),\n    UINT64_C(0x6d5987b1d4a9d376), UINT64_C(0x85d38abd81880d4b),\n    UINT64_C(0x34e623036147a10e), UINT64_C(0xdc6c2e0f34667f33),\n    UINT64_C(0x772a9630640a03f1), UINT64_C(0x9fa09b3c312bddcc),\n    UINT64_C(0xb37f49656bdce4f0), UINT64_C(0x5bf544693efd3acd),\n    UINT64_C(0xf0b3fc566e91460f), UINT64_C(0x1839f15a3bb09832),\n    UINT64_C(0xc0c01ee219f0766b), UINT64_C(0x284a13ee4cd1a856),\n    UINT64_C(0x830cabd11cbdd494), UINT64_C(0x6b86a6dd499c0aa9),\n    UINT64_C(0x47597484136b3395), UINT64_C(0xafd37988464aeda8),\n    UINT64_C(0x0495c1b71626916a), UINT64_C(0xec1fccbb43074f57),\n    UINT64_C(0x5d2a6505a3c8e312), UINT64_C(0xb5a06809f6e93d2f),\n    UINT64_C(0x1ee6d036a68541ed), UINT64_C(0xf66cdd3af3a49fd0),\n    UINT64_C(0xdab30f63a953a6ec), UINT64_C(0x3239026ffc7278d1),\n    UINT64_C(0x997fba50ac1e0413), UINT64_C(0x71f5b75cf93fda2e),\n    UINT64_C(0x69cc4606c28f421c), UINT64_C(0x81464b0a97ae9c21),\n    UINT64_C(0x2a00f335c7c2e0e3), UINT64_C(0xc28afe3992e33ede),\n    UINT64_C(0xee552c60c81407e2), UINT64_C(0x06df216c9d35d9df),\n    UINT64_C(0xad999953cd59a51d), UINT64_C(0x4513945f98787b20),\n    UINT64_C(0xf4263de178b7d765), UINT64_C(0x1cac30ed2d960958),\n    UINT64_C(0xb7ea88d27dfa759a), UINT64_C(0x5f6085de28dbaba7),\n    UINT64_C(0x73bf5787722c929b), UINT64_C(0x9b355a8b270d4ca6),\n    UINT64_C(0x3073e2b477613064), UINT64_C(0xd8f9efb82240ee59),\n    UINT64_C(0x135892ef9ceef253), UINT64_C(0xfbd29fe3c9cf2c6e),\n    UINT64_C(0x509427dc99a350ac), UINT64_C(0xb81e2ad0cc828e91),\n    UINT64_C(0x94c1f8899675b7ad), UINT64_C(0x7c4bf585c3546990),\n    UINT64_C(0xd70d4dba93381552), UINT64_C(0x3f8740b6c619cb6f),\n    UINT64_C(0x8eb2e90826d6672a), UINT64_C(0x6638e40473f7b917),\n    UINT64_C(0xcd7e5c3b239bc5d5), UINT64_C(0x25f4513776ba1be8),\n    UINT64_C(0x092b836e2c4d22d4), UINT64_C(0xe1a18e62796cfce9),\n    UINT64_C(0x4ae7365d2900802b), UINT64_C(0xa26d3b517c215e16),\n    UINT64_C(0xba54ca0b4791c624), UINT64_C(0x52dec70712b01819),\n    UINT64_C(0xf9987f3842dc64db), UINT64_C(0x1112723417fdbae6),\n    UINT64_C(0x3dcda06d4d0a83da), UINT64_C(0xd547ad61182b5de7),\n    UINT64_C(0x7e01155e48472125), UINT64_C(0x968b18521d66ff18),\n    UINT64_C(0x27beb1ecfda9535d), UINT64_C(0xcf34bce0a8888d60),\n    UINT64_C(0x647204dff8e4f1a2), UINT64_C(0x8cf809d3adc52f9f),\n    UINT64_C(0xa027db8af73216a3), UINT64_C(0x48add686a213c89e),\n    UINT64_C(0xe3eb6eb9f27fb45c), UINT64_C(0x0b6163b5a75e6a61),\n    UINT64_C(0xd3988c0d851e8438), UINT64_C(0x3b128101d03f5a05),\n    UINT64_C(0x9054393e805326c7), UINT64_C(0x78de3432d572f8fa),\n    UINT64_C(0x5401e66b8f85c1c6), UINT64_C(0xbc8beb67daa41ffb),\n    UINT64_C(0x17cd53588ac86339), UINT64_C(0xff475e54dfe9bd04),\n    UINT64_C(0x4e72f7ea3f261141), UINT64_C(0xa6f8fae66a07cf7c),\n    UINT64_C(0x0dbe42d93a6bb3be), UINT64_C(0xe5344fd56f4a6d83),\n    UINT64_C(0xc9eb9d8c35bd54bf), UINT64_C(0x21619080609c8a82),\n    UINT64_C(0x8a2728bf30f0f640), UINT64_C(0x62ad25b365d1287d),\n    UINT64_C(0x7a94d4e95e61b04f), UINT64_C(0x921ed9e50b406e72),\n    UINT64_C(0x395861da5b2c12b0), UINT64_C(0xd1d26cd60e0dcc8d),\n    UINT64_C(0xfd0dbe8f54faf5b1), UINT64_C(0x1587b38301db2b8c),\n    UINT64_C(0xbec10bbc51b7574e), UINT64_C(0x564b06b004968973),\n    UINT64_C(0xe77eaf0ee4592536), UINT64_C(0x0ff4a202b178fb0b),\n    UINT64_C(0xa4b21a3de11487c9), UINT64_C(0x4c381731b43559f4),\n    UINT64_C(0x60e7c568eec260c8), UINT64_C(0x886dc864bbe3bef5),\n    UINT64_C(0x232b705beb8fc237), UINT64_C(0xcba17d57beae1c0a),\n    UINT64_C(0x26b125df39dde4a6), UINT64_C(0xce3b28d36cfc3a9b),\n    UINT64_C(0x657d90ec3c904659), UINT64_C(0x8df79de069b19864),\n    UINT64_C(0xa1284fb93346a158), UINT64_C(0x49a242b566677f65),\n    UINT64_C(0xe2e4fa8a360b03a7), UINT64_C(0x0a6ef786632add9a),\n    UINT64_C(0xbb5b5e3883e571df), UINT64_C(0x53d15334d6c4afe2),\n    UINT64_C(0xf897eb0b86a8d320), UINT64_C(0x101de607d3890d1d),\n    UINT64_C(0x3cc2345e897e3421), UINT64_C(0xd4483952dc5fea1c),\n    UINT64_C(0x7f0e816d8c3396de), UINT64_C(0x97848c61d91248e3),\n    UINT64_C(0x8fbd7d3be2a2d0d1), UINT64_C(0x67377037b7830eec),\n    UINT64_C(0xcc71c808e7ef722e), UINT64_C(0x24fbc504b2ceac13),\n    UINT64_C(0x0824175de839952f), UINT64_C(0xe0ae1a51bd184b12),\n    UINT64_C(0x4be8a26eed7437d0), UINT64_C(0xa362af62b855e9ed),\n    UINT64_C(0x125706dc589a45a8), UINT64_C(0xfadd0bd00dbb9b95),\n    UINT64_C(0x519bb3ef5dd7e757), UINT64_C(0xb911bee308f6396a),\n    UINT64_C(0x95ce6cba52010056), UINT64_C(0x7d4461b60720de6b),\n    UINT64_C(0xd602d989574ca2a9), UINT64_C(0x3e88d485026d7c94),\n    UINT64_C(0xe6713b3d202d92cd), UINT64_C(0x0efb3631750c4cf0),\n    UINT64_C(0xa5bd8e0e25603032), UINT64_C(0x4d3783027041ee0f),\n    UINT64_C(0x61e8515b2ab6d733), UINT64_C(0x89625c577f97090e),\n    UINT64_C(0x2224e4682ffb75cc), UINT64_C(0xcaaee9647adaabf1),\n    UINT64_C(0x7b9b40da9a1507b4), UINT64_C(0x93114dd6cf34d989),\n    UINT64_C(0x3857f5e99f58a54b), UINT64_C(0xd0ddf8e5ca797b76),\n    UINT64_C(0xfc022abc908e424a), UINT64_C(0x148827b0c5af9c77),\n    UINT64_C(0xbfce9f8f95c3e0b5), UINT64_C(0x57449283c0e23e88),\n    UINT64_C(0x4f7d63d9fb52a6ba), UINT64_C(0xa7f76ed5ae737887),\n    UINT64_C(0x0cb1d6eafe1f0445), UINT64_C(0xe43bdbe6ab3eda78),\n    UINT64_C(0xc8e409bff1c9e344), UINT64_C(0x206e04b3a4e83d79),\n    UINT64_C(0x8b28bc8cf48441bb), UINT64_C(0x63a2b180a1a59f86),\n    UINT64_C(0xd297183e416a33c3), UINT64_C(0x3a1d1532144bedfe),\n    UINT64_C(0x915bad0d4427913c), UINT64_C(0x79d1a00111064f01),\n    UINT64_C(0x550e72584bf1763d), UINT64_C(0xbd847f541ed0a800),\n    UINT64_C(0x16c2c76b4ebcd4c2), UINT64_C(0xfe48ca671b9d0aff),\n    UINT64_C(0x35e9b730a53316f5), UINT64_C(0xdd63ba3cf012c8c8),\n    UINT64_C(0x76250203a07eb40a), UINT64_C(0x9eaf0f0ff55f6a37),\n    UINT64_C(0xb270dd56afa8530b), UINT64_C(0x5afad05afa898d36),\n    UINT64_C(0xf1bc6865aae5f1f4), UINT64_C(0x19366569ffc42fc9),\n    UINT64_C(0xa803ccd71f0b838c), UINT64_C(0x4089c1db4a2a5db1),\n    UINT64_C(0xebcf79e41a462173), UINT64_C(0x034574e84f67ff4e),\n    UINT64_C(0x2f9aa6b11590c672), UINT64_C(0xc710abbd40b1184f),\n    UINT64_C(0x6c56138210dd648d), UINT64_C(0x84dc1e8e45fcbab0),\n    UINT64_C(0x9ce5efd47e4c2282), UINT64_C(0x746fe2d82b6dfcbf),\n    UINT64_C(0xdf295ae77b01807d), UINT64_C(0x37a357eb2e205e40),\n    UINT64_C(0x1b7c85b274d7677c), UINT64_C(0xf3f688be21f6b941),\n    UINT64_C(0x58b03081719ac583), UINT64_C(0xb03a3d8d24bb1bbe),\n    UINT64_C(0x010f9433c474b7fb), UINT64_C(0xe985993f915569c6),\n    UINT64_C(0x42c32100c1391504), UINT64_C(0xaa492c0c9418cb39),\n    UINT64_C(0x8696fe55ceeff205), UINT64_C(0x6e1cf3599bce2c38),\n    UINT64_C(0xc55a4b66cba250fa), UINT64_C(0x2dd0466a9e838ec7),\n    UINT64_C(0xf529a9d2bcc3609e), UINT64_C(0x1da3a4dee9e2bea3),\n    UINT64_C(0xb6e51ce1b98ec261), UINT64_C(0x5e6f11edecaf1c5c),\n    UINT64_C(0x72b0c3b4b6582560), UINT64_C(0x9a3aceb8e379fb5d),\n    UINT64_C(0x317c7687b315879f), UINT64_C(0xd9f67b8be63459a2),\n    UINT64_C(0x68c3d23506fbf5e7), UINT64_C(0x8049df3953da2bda),\n    UINT64_C(0x2b0f670603b65718), UINT64_C(0xc3856a0a56978925),\n    UINT64_C(0xef5ab8530c60b019), UINT64_C(0x07d0b55f59416e24),\n    UINT64_C(0xac960d60092d12e6), UINT64_C(0x441c006c5c0cccdb),\n    UINT64_C(0x5c25f13667bc54e9), UINT64_C(0xb4affc3a329d8ad4),\n    UINT64_C(0x1fe9440562f1f616), UINT64_C(0xf763490937d0282b),\n    UINT64_C(0xdbbc9b506d271117), UINT64_C(0x3336965c3806cf2a),\n    UINT64_C(0x98702e63686ab3e8), UINT64_C(0x70fa236f3d4b6dd5),\n    UINT64_C(0xc1cf8ad1dd84c190), UINT64_C(0x294587dd88a51fad),\n    UINT64_C(0x82033fe2d8c9636f), UINT64_C(0x6a8932ee8de8bd52),\n    UINT64_C(0x4656e0b7d71f846e), UINT64_C(0xaedcedbb823e5a53),\n    UINT64_C(0x059a5584d2522691), UINT64_C(0xed1058888773f8ac)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x4d624bbe73bbc94c),\n    UINT64_C(0x9ac4977ce7779298), UINT64_C(0xd7a6dcc294cc5bd4),\n    UINT64_C(0xa75181d261e13bb5), UINT64_C(0xea33ca6c125af2f9),\n    UINT64_C(0x3d9516ae8696a92d), UINT64_C(0x70f75d10f52d6061),\n    UINT64_C(0xdc7bac8f6ccc69ef), UINT64_C(0x9119e7311f77a0a3),\n    UINT64_C(0x46bf3bf38bbbfb77), UINT64_C(0x0bdd704df800323b),\n    UINT64_C(0x7b2a2d5d0d2d525a), UINT64_C(0x364866e37e969b16),\n    UINT64_C(0xe1eeba21ea5ac0c2), UINT64_C(0xac8cf19f99e1098e),\n    UINT64_C(0x2a2ff6357696cd5b), UINT64_C(0x674dbd8b052d0417),\n    UINT64_C(0xb0eb614991e15fc3), UINT64_C(0xfd892af7e25a968f),\n    UINT64_C(0x8d7e77e71777f6ee), UINT64_C(0xc01c3c5964cc3fa2),\n    UINT64_C(0x17bae09bf0006476), UINT64_C(0x5ad8ab2583bbad3a),\n    UINT64_C(0xf6545aba1a5aa4b4), UINT64_C(0xbb36110469e16df8),\n    UINT64_C(0x6c90cdc6fd2d362c), UINT64_C(0x21f286788e96ff60),\n    UINT64_C(0x5105db687bbb9f01), UINT64_C(0x1c6790d60800564d),\n    UINT64_C(0xcbc14c149ccc0d99), UINT64_C(0x86a307aaef77c4d5),\n    UINT64_C(0x545fec6aed2d9ab6), UINT64_C(0x193da7d49e9653fa),\n    UINT64_C(0xce9b7b160a5a082e), UINT64_C(0x83f930a879e1c162),\n    UINT64_C(0xf30e6db88ccca103), UINT64_C(0xbe6c2606ff77684f),\n    UINT64_C(0x69cafac46bbb339b), UINT64_C(0x24a8b17a1800fad7),\n    UINT64_C(0x882440e581e1f359), UINT64_C(0xc5460b5bf25a3a15),\n    UINT64_C(0x12e0d799669661c1), UINT64_C(0x5f829c27152da88d),\n    UINT64_C(0x2f75c137e000c8ec), UINT64_C(0x62178a8993bb01a0),\n    UINT64_C(0xb5b1564b07775a74), UINT64_C(0xf8d31df574cc9338),\n    UINT64_C(0x7e701a5f9bbb57ed), UINT64_C(0x331251e1e8009ea1),\n    UINT64_C(0xe4b48d237cccc575), UINT64_C(0xa9d6c69d0f770c39),\n    UINT64_C(0xd9219b8dfa5a6c58), UINT64_C(0x9443d03389e1a514),\n    UINT64_C(0x43e50cf11d2dfec0), UINT64_C(0x0e87474f6e96378c),\n    UINT64_C(0xa20bb6d0f7773e02), UINT64_C(0xef69fd6e84ccf74e),\n    UINT64_C(0x38cf21ac1000ac9a), UINT64_C(0x75ad6a1263bb65d6),\n    UINT64_C(0x055a3702969605b7), UINT64_C(0x48387cbce52dccfb),\n    UINT64_C(0x9f9ea07e71e1972f), UINT64_C(0xd2fcebc0025a5e63),\n    UINT64_C(0xa8bfd8d5da5b356c), UINT64_C(0xe5dd936ba9e0fc20),\n    UINT64_C(0x327b4fa93d2ca7f4), UINT64_C(0x7f1904174e976eb8),\n    UINT64_C(0x0fee5907bbba0ed9), UINT64_C(0x428c12b9c801c795),\n    UINT64_C(0x952ace7b5ccd9c41), UINT64_C(0xd84885c52f76550d),\n    UINT64_C(0x74c4745ab6975c83), UINT64_C(0x39a63fe4c52c95cf),\n    UINT64_C(0xee00e32651e0ce1b), UINT64_C(0xa362a898225b0757),\n    UINT64_C(0xd395f588d7766736), UINT64_C(0x9ef7be36a4cdae7a),\n    UINT64_C(0x495162f43001f5ae), UINT64_C(0x0433294a43ba3ce2),\n    UINT64_C(0x82902ee0accdf837), UINT64_C(0xcff2655edf76317b),\n    UINT64_C(0x1854b99c4bba6aaf), UINT64_C(0x5536f2223801a3e3),\n    UINT64_C(0x25c1af32cd2cc382), UINT64_C(0x68a3e48cbe970ace),\n    UINT64_C(0xbf05384e2a5b511a), UINT64_C(0xf26773f059e09856),\n    UINT64_C(0x5eeb826fc00191d8), UINT64_C(0x1389c9d1b3ba5894),\n    UINT64_C(0xc42f151327760340), UINT64_C(0x894d5ead54cdca0c),\n    UINT64_C(0xf9ba03bda1e0aa6d), UINT64_C(0xb4d84803d25b6321),\n    UINT64_C(0x637e94c1469738f5), UINT64_C(0x2e1cdf7f352cf1b9),\n    UINT64_C(0xfce034bf3776afda), UINT64_C(0xb1827f0144cd6696),\n    UINT64_C(0x6624a3c3d0013d42), UINT64_C(0x2b46e87da3baf40e),\n    UINT64_C(0x5bb1b56d5697946f), UINT64_C(0x16d3fed3252c5d23),\n    UINT64_C(0xc1752211b1e006f7), UINT64_C(0x8c1769afc25bcfbb),\n    UINT64_C(0x209b98305bbac635), UINT64_C(0x6df9d38e28010f79),\n    UINT64_C(0xba5f0f4cbccd54ad), UINT64_C(0xf73d44f2cf769de1),\n    UINT64_C(0x87ca19e23a5bfd80), UINT64_C(0xcaa8525c49e034cc),\n    UINT64_C(0x1d0e8e9edd2c6f18), UINT64_C(0x506cc520ae97a654),\n    UINT64_C(0xd6cfc28a41e06281), UINT64_C(0x9bad8934325babcd),\n    UINT64_C(0x4c0b55f6a697f019), UINT64_C(0x01691e48d52c3955),\n    UINT64_C(0x719e435820015934), UINT64_C(0x3cfc08e653ba9078),\n    UINT64_C(0xeb5ad424c776cbac), UINT64_C(0xa6389f9ab4cd02e0),\n    UINT64_C(0x0ab46e052d2c0b6e), UINT64_C(0x47d625bb5e97c222),\n    UINT64_C(0x9070f979ca5b99f6), UINT64_C(0xdd12b2c7b9e050ba),\n    UINT64_C(0xade5efd74ccd30db), UINT64_C(0xe087a4693f76f997),\n    UINT64_C(0x372178ababbaa243), UINT64_C(0x7a433315d8016b0f),\n    UINT64_C(0xc3a71e801bb8745d), UINT64_C(0x8ec5553e6803bd11),\n    UINT64_C(0x596389fcfccfe6c5), UINT64_C(0x1401c2428f742f89),\n    UINT64_C(0x64f69f527a594fe8), UINT64_C(0x2994d4ec09e286a4),\n    UINT64_C(0xfe32082e9d2edd70), UINT64_C(0xb3504390ee95143c),\n    UINT64_C(0x1fdcb20f77741db2), UINT64_C(0x52bef9b104cfd4fe),\n    UINT64_C(0x8518257390038f2a), UINT64_C(0xc87a6ecde3b84666),\n    UINT64_C(0xb88d33dd16952607), UINT64_C(0xf5ef7863652eef4b),\n    UINT64_C(0x2249a4a1f1e2b49f), UINT64_C(0x6f2bef1f82597dd3),\n    UINT64_C(0xe988e8b56d2eb906), UINT64_C(0xa4eaa30b1e95704a),\n    UINT64_C(0x734c7fc98a592b9e), UINT64_C(0x3e2e3477f9e2e2d2),\n    UINT64_C(0x4ed969670ccf82b3), UINT64_C(0x03bb22d97f744bff),\n    UINT64_C(0xd41dfe1bebb8102b), UINT64_C(0x997fb5a59803d967),\n    UINT64_C(0x35f3443a01e2d0e9), UINT64_C(0x78910f84725919a5),\n    UINT64_C(0xaf37d346e6954271), UINT64_C(0xe25598f8952e8b3d),\n    UINT64_C(0x92a2c5e86003eb5c), UINT64_C(0xdfc08e5613b82210),\n    UINT64_C(0x08665294877479c4), UINT64_C(0x4504192af4cfb088),\n    UINT64_C(0x97f8f2eaf695eeeb), UINT64_C(0xda9ab954852e27a7),\n    UINT64_C(0x0d3c659611e27c73), UINT64_C(0x405e2e286259b53f),\n    UINT64_C(0x30a973389774d55e), UINT64_C(0x7dcb3886e4cf1c12),\n    UINT64_C(0xaa6de444700347c6), UINT64_C(0xe70faffa03b88e8a),\n    UINT64_C(0x4b835e659a598704), UINT64_C(0x06e115dbe9e24e48),\n    UINT64_C(0xd147c9197d2e159c), UINT64_C(0x9c2582a70e95dcd0),\n    UINT64_C(0xecd2dfb7fbb8bcb1), UINT64_C(0xa1b09409880375fd),\n    UINT64_C(0x761648cb1ccf2e29), UINT64_C(0x3b7403756f74e765),\n    UINT64_C(0xbdd704df800323b0), UINT64_C(0xf0b54f61f3b8eafc),\n    UINT64_C(0x271393a36774b128), UINT64_C(0x6a71d81d14cf7864),\n    UINT64_C(0x1a86850de1e21805), UINT64_C(0x57e4ceb39259d149),\n    UINT64_C(0x8042127106958a9d), UINT64_C(0xcd2059cf752e43d1),\n    UINT64_C(0x61aca850eccf4a5f), UINT64_C(0x2ccee3ee9f748313),\n    UINT64_C(0xfb683f2c0bb8d8c7), UINT64_C(0xb60a74927803118b),\n    UINT64_C(0xc6fd29828d2e71ea), UINT64_C(0x8b9f623cfe95b8a6),\n    UINT64_C(0x5c39befe6a59e372), UINT64_C(0x115bf54019e22a3e),\n    UINT64_C(0x6b18c655c1e34131), UINT64_C(0x267a8debb258887d),\n    UINT64_C(0xf1dc51292694d3a9), UINT64_C(0xbcbe1a97552f1ae5),\n    UINT64_C(0xcc494787a0027a84), UINT64_C(0x812b0c39d3b9b3c8),\n    UINT64_C(0x568dd0fb4775e81c), UINT64_C(0x1bef9b4534ce2150),\n    UINT64_C(0xb7636adaad2f28de), UINT64_C(0xfa012164de94e192),\n    UINT64_C(0x2da7fda64a58ba46), UINT64_C(0x60c5b61839e3730a),\n    UINT64_C(0x1032eb08ccce136b), UINT64_C(0x5d50a0b6bf75da27),\n    UINT64_C(0x8af67c742bb981f3), UINT64_C(0xc79437ca580248bf),\n    UINT64_C(0x41373060b7758c6a), UINT64_C(0x0c557bdec4ce4526),\n    UINT64_C(0xdbf3a71c50021ef2), UINT64_C(0x9691eca223b9d7be),\n    UINT64_C(0xe666b1b2d694b7df), UINT64_C(0xab04fa0ca52f7e93),\n    UINT64_C(0x7ca226ce31e32547), UINT64_C(0x31c06d704258ec0b),\n    UINT64_C(0x9d4c9cefdbb9e585), UINT64_C(0xd02ed751a8022cc9),\n    UINT64_C(0x07880b933cce771d), UINT64_C(0x4aea402d4f75be51),\n    UINT64_C(0x3a1d1d3dba58de30), UINT64_C(0x777f5683c9e3177c),\n    UINT64_C(0xa0d98a415d2f4ca8), UINT64_C(0xedbbc1ff2e9485e4),\n    UINT64_C(0x3f472a3f2ccedb87), UINT64_C(0x722561815f7512cb),\n    UINT64_C(0xa583bd43cbb9491f), UINT64_C(0xe8e1f6fdb8028053),\n    UINT64_C(0x9816abed4d2fe032), UINT64_C(0xd574e0533e94297e),\n    UINT64_C(0x02d23c91aa5872aa), UINT64_C(0x4fb0772fd9e3bbe6),\n    UINT64_C(0xe33c86b04002b268), UINT64_C(0xae5ecd0e33b97b24),\n    UINT64_C(0x79f811cca77520f0), UINT64_C(0x349a5a72d4cee9bc),\n    UINT64_C(0x446d076221e389dd), UINT64_C(0x090f4cdc52584091),\n    UINT64_C(0xdea9901ec6941b45), UINT64_C(0x93cbdba0b52fd209),\n    UINT64_C(0x1568dc0a5a5816dc), UINT64_C(0x580a97b429e3df90),\n    UINT64_C(0x8fac4b76bd2f8444), UINT64_C(0xc2ce00c8ce944d08),\n    UINT64_C(0xb2395dd83bb92d69), UINT64_C(0xff5b16664802e425),\n    UINT64_C(0x28fdcaa4dccebff1), UINT64_C(0x659f811aaf7576bd),\n    UINT64_C(0xc913708536947f33), UINT64_C(0x84713b3b452fb67f),\n    UINT64_C(0x53d7e7f9d1e3edab), UINT64_C(0x1eb5ac47a25824e7),\n    UINT64_C(0x6e42f15757754486), UINT64_C(0x2320bae924ce8dca),\n    UINT64_C(0xf486662bb002d61e), UINT64_C(0xb9e42d95c3b91f52)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x1596922b987ef63f),\n    UINT64_C(0x2b2d245730fdec7e), UINT64_C(0x3ebbb67ca8831a41),\n    UINT64_C(0x565a48ae61fbd8fc), UINT64_C(0x43ccda85f9852ec3),\n    UINT64_C(0x7d776cf951063482), UINT64_C(0x68e1fed2c978c2bd),\n    UINT64_C(0xacb4915cc3f7b1f8), UINT64_C(0xb92203775b8947c7),\n    UINT64_C(0x8799b50bf30a5d86), UINT64_C(0x920f27206b74abb9),\n    UINT64_C(0xfaeed9f2a20c6904), UINT64_C(0xef784bd93a729f3b),\n    UINT64_C(0xd1c3fda592f1857a), UINT64_C(0xc4556f8e0a8f7345),\n    UINT64_C(0xcbb18d9228e17d75), UINT64_C(0xde271fb9b09f8b4a),\n    UINT64_C(0xe09ca9c5181c910b), UINT64_C(0xf50a3bee80626734),\n    UINT64_C(0x9debc53c491aa589), UINT64_C(0x887d5717d16453b6),\n    UINT64_C(0xb6c6e16b79e749f7), UINT64_C(0xa3507340e199bfc8),\n    UINT64_C(0x67051cceeb16cc8d), UINT64_C(0x72938ee573683ab2),\n    UINT64_C(0x4c283899dbeb20f3), UINT64_C(0x59beaab24395d6cc),\n    UINT64_C(0x315f54608aed1471), UINT64_C(0x24c9c64b1293e24e),\n    UINT64_C(0x1a727037ba10f80f), UINT64_C(0x0fe4e21c226e0e30),\n    UINT64_C(0x05bbb40ffecce46f), UINT64_C(0x102d262466b21250),\n    UINT64_C(0x2e969058ce310811), UINT64_C(0x3b000273564ffe2e),\n    UINT64_C(0x53e1fca19f373c93), UINT64_C(0x46776e8a0749caac),\n    UINT64_C(0x78ccd8f6afcad0ed), UINT64_C(0x6d5a4add37b426d2),\n    UINT64_C(0xa90f25533d3b5597), UINT64_C(0xbc99b778a545a3a8),\n    UINT64_C(0x822201040dc6b9e9), UINT64_C(0x97b4932f95b84fd6),\n    UINT64_C(0xff556dfd5cc08d6b), UINT64_C(0xeac3ffd6c4be7b54),\n    UINT64_C(0xd47849aa6c3d6115), UINT64_C(0xc1eedb81f443972a),\n    UINT64_C(0xce0a399dd62d991a), UINT64_C(0xdb9cabb64e536f25),\n    UINT64_C(0xe5271dcae6d07564), UINT64_C(0xf0b18fe17eae835b),\n    UINT64_C(0x98507133b7d641e6), UINT64_C(0x8dc6e3182fa8b7d9),\n    UINT64_C(0xb37d5564872bad98), UINT64_C(0xa6ebc74f1f555ba7),\n    UINT64_C(0x62bea8c115da28e2), UINT64_C(0x77283aea8da4dedd),\n    UINT64_C(0x49938c962527c49c), UINT64_C(0x5c051ebdbd5932a3),\n    UINT64_C(0x34e4e06f7421f01e), UINT64_C(0x21727244ec5f0621),\n    UINT64_C(0x1fc9c43844dc1c60), UINT64_C(0x0a5f5613dca2ea5f),\n    UINT64_C(0x0b77681ffd99c8de), UINT64_C(0x1ee1fa3465e73ee1),\n    UINT64_C(0x205a4c48cd6424a0), UINT64_C(0x35ccde63551ad29f),\n    UINT64_C(0x5d2d20b19c621022), UINT64_C(0x48bbb29a041ce61d),\n    UINT64_C(0x760004e6ac9ffc5c), UINT64_C(0x639696cd34e10a63),\n    UINT64_C(0xa7c3f9433e6e7926), UINT64_C(0xb2556b68a6108f19),\n    UINT64_C(0x8ceedd140e939558), UINT64_C(0x99784f3f96ed6367),\n    UINT64_C(0xf199b1ed5f95a1da), UINT64_C(0xe40f23c6c7eb57e5),\n    UINT64_C(0xdab495ba6f684da4), UINT64_C(0xcf220791f716bb9b),\n    UINT64_C(0xc0c6e58dd578b5ab), UINT64_C(0xd55077a64d064394),\n    UINT64_C(0xebebc1dae58559d5), UINT64_C(0xfe7d53f17dfbafea),\n    UINT64_C(0x969cad23b4836d57), UINT64_C(0x830a3f082cfd9b68),\n    UINT64_C(0xbdb18974847e8129), UINT64_C(0xa8271b5f1c007716),\n    UINT64_C(0x6c7274d1168f0453), UINT64_C(0x79e4e6fa8ef1f26c),\n    UINT64_C(0x475f50862672e82d), UINT64_C(0x52c9c2adbe0c1e12),\n    UINT64_C(0x3a283c7f7774dcaf), UINT64_C(0x2fbeae54ef0a2a90),\n    UINT64_C(0x11051828478930d1), UINT64_C(0x04938a03dff7c6ee),\n    UINT64_C(0x0eccdc1003552cb1), UINT64_C(0x1b5a4e3b9b2bda8e),\n    UINT64_C(0x25e1f84733a8c0cf), UINT64_C(0x30776a6cabd636f0),\n    UINT64_C(0x589694be62aef44d), UINT64_C(0x4d000695fad00272),\n    UINT64_C(0x73bbb0e952531833), UINT64_C(0x662d22c2ca2dee0c),\n    UINT64_C(0xa2784d4cc0a29d49), UINT64_C(0xb7eedf6758dc6b76),\n    UINT64_C(0x8955691bf05f7137), UINT64_C(0x9cc3fb3068218708),\n    UINT64_C(0xf42205e2a15945b5), UINT64_C(0xe1b497c93927b38a),\n    UINT64_C(0xdf0f21b591a4a9cb), UINT64_C(0xca99b39e09da5ff4),\n    UINT64_C(0xc57d51822bb451c4), UINT64_C(0xd0ebc3a9b3caa7fb),\n    UINT64_C(0xee5075d51b49bdba), UINT64_C(0xfbc6e7fe83374b85),\n    UINT64_C(0x9327192c4a4f8938), UINT64_C(0x86b18b07d2317f07),\n    UINT64_C(0xb80a3d7b7ab26546), UINT64_C(0xad9caf50e2cc9379),\n    UINT64_C(0x69c9c0dee843e03c), UINT64_C(0x7c5f52f5703d1603),\n    UINT64_C(0x42e4e489d8be0c42), UINT64_C(0x577276a240c0fa7d),\n    UINT64_C(0x3f93887089b838c0), UINT64_C(0x2a051a5b11c6ceff),\n    UINT64_C(0x14beac27b945d4be), UINT64_C(0x01283e0c213b2281),\n    UINT64_C(0x16eed03ffb3391bc), UINT64_C(0x03784214634d6783),\n    UINT64_C(0x3dc3f468cbce7dc2), UINT64_C(0x2855664353b08bfd),\n    UINT64_C(0x40b498919ac84940), UINT64_C(0x55220aba02b6bf7f),\n    UINT64_C(0x6b99bcc6aa35a53e), UINT64_C(0x7e0f2eed324b5301),\n    UINT64_C(0xba5a416338c42044), UINT64_C(0xafccd348a0bad67b),\n    UINT64_C(0x917765340839cc3a), UINT64_C(0x84e1f71f90473a05),\n    UINT64_C(0xec0009cd593ff8b8), UINT64_C(0xf9969be6c1410e87),\n    UINT64_C(0xc72d2d9a69c214c6), UINT64_C(0xd2bbbfb1f1bce2f9),\n    UINT64_C(0xdd5f5dadd3d2ecc9), UINT64_C(0xc8c9cf864bac1af6),\n    UINT64_C(0xf67279fae32f00b7), UINT64_C(0xe3e4ebd17b51f688),\n    UINT64_C(0x8b051503b2293435), UINT64_C(0x9e9387282a57c20a),\n    UINT64_C(0xa028315482d4d84b), UINT64_C(0xb5bea37f1aaa2e74),\n    UINT64_C(0x71ebccf110255d31), UINT64_C(0x647d5eda885bab0e),\n    UINT64_C(0x5ac6e8a620d8b14f), UINT64_C(0x4f507a8db8a64770),\n    UINT64_C(0x27b1845f71de85cd), UINT64_C(0x32271674e9a073f2),\n    UINT64_C(0x0c9ca008412369b3), UINT64_C(0x190a3223d95d9f8c),\n    UINT64_C(0x1355643005ff75d3), UINT64_C(0x06c3f61b9d8183ec),\n    UINT64_C(0x38784067350299ad), UINT64_C(0x2deed24cad7c6f92),\n    UINT64_C(0x450f2c9e6404ad2f), UINT64_C(0x5099beb5fc7a5b10),\n    UINT64_C(0x6e2208c954f94151), UINT64_C(0x7bb49ae2cc87b76e),\n    UINT64_C(0xbfe1f56cc608c42b), UINT64_C(0xaa7767475e763214),\n    UINT64_C(0x94ccd13bf6f52855), UINT64_C(0x815a43106e8bde6a),\n    UINT64_C(0xe9bbbdc2a7f31cd7), UINT64_C(0xfc2d2fe93f8deae8),\n    UINT64_C(0xc2969995970ef0a9), UINT64_C(0xd7000bbe0f700696),\n    UINT64_C(0xd8e4e9a22d1e08a6), UINT64_C(0xcd727b89b560fe99),\n    UINT64_C(0xf3c9cdf51de3e4d8), UINT64_C(0xe65f5fde859d12e7),\n    UINT64_C(0x8ebea10c4ce5d05a), UINT64_C(0x9b283327d49b2665),\n    UINT64_C(0xa593855b7c183c24), UINT64_C(0xb0051770e466ca1b),\n    UINT64_C(0x745078feeee9b95e), UINT64_C(0x61c6ead576974f61),\n    UINT64_C(0x5f7d5ca9de145520), UINT64_C(0x4aebce82466aa31f),\n    UINT64_C(0x220a30508f1261a2), UINT64_C(0x379ca27b176c979d),\n    UINT64_C(0x09271407bfef8ddc), UINT64_C(0x1cb1862c27917be3),\n    UINT64_C(0x1d99b82006aa5962), UINT64_C(0x080f2a0b9ed4af5d),\n    UINT64_C(0x36b49c773657b51c), UINT64_C(0x23220e5cae294323),\n    UINT64_C(0x4bc3f08e6751819e), UINT64_C(0x5e5562a5ff2f77a1),\n    UINT64_C(0x60eed4d957ac6de0), UINT64_C(0x757846f2cfd29bdf),\n    UINT64_C(0xb12d297cc55de89a), UINT64_C(0xa4bbbb575d231ea5),\n    UINT64_C(0x9a000d2bf5a004e4), UINT64_C(0x8f969f006ddef2db),\n    UINT64_C(0xe77761d2a4a63066), UINT64_C(0xf2e1f3f93cd8c659),\n    UINT64_C(0xcc5a4585945bdc18), UINT64_C(0xd9ccd7ae0c252a27),\n    UINT64_C(0xd62835b22e4b2417), UINT64_C(0xc3bea799b635d228),\n    UINT64_C(0xfd0511e51eb6c869), UINT64_C(0xe89383ce86c83e56),\n    UINT64_C(0x80727d1c4fb0fceb), UINT64_C(0x95e4ef37d7ce0ad4),\n    UINT64_C(0xab5f594b7f4d1095), UINT64_C(0xbec9cb60e733e6aa),\n    UINT64_C(0x7a9ca4eeedbc95ef), UINT64_C(0x6f0a36c575c263d0),\n    UINT64_C(0x51b180b9dd417991), UINT64_C(0x44271292453f8fae),\n    UINT64_C(0x2cc6ec408c474d13), UINT64_C(0x39507e6b1439bb2c),\n    UINT64_C(0x07ebc817bcbaa16d), UINT64_C(0x127d5a3c24c45752),\n    UINT64_C(0x18220c2ff866bd0d), UINT64_C(0x0db49e0460184b32),\n    UINT64_C(0x330f2878c89b5173), UINT64_C(0x2699ba5350e5a74c),\n    UINT64_C(0x4e784481999d65f1), UINT64_C(0x5beed6aa01e393ce),\n    UINT64_C(0x655560d6a960898f), UINT64_C(0x70c3f2fd311e7fb0),\n    UINT64_C(0xb4969d733b910cf5), UINT64_C(0xa1000f58a3effaca),\n    UINT64_C(0x9fbbb9240b6ce08b), UINT64_C(0x8a2d2b0f931216b4),\n    UINT64_C(0xe2ccd5dd5a6ad409), UINT64_C(0xf75a47f6c2142236),\n    UINT64_C(0xc9e1f18a6a973877), UINT64_C(0xdc7763a1f2e9ce48),\n    UINT64_C(0xd39381bdd087c078), UINT64_C(0xc605139648f93647),\n    UINT64_C(0xf8bea5eae07a2c06), UINT64_C(0xed2837c17804da39),\n    UINT64_C(0x85c9c913b17c1884), UINT64_C(0x905f5b382902eebb),\n    UINT64_C(0xaee4ed448181f4fa), UINT64_C(0xbb727f6f19ff02c5),\n    UINT64_C(0x7f2710e113707180), UINT64_C(0x6ab182ca8b0e87bf),\n    UINT64_C(0x540a34b6238d9dfe), UINT64_C(0x419ca69dbbf36bc1),\n    UINT64_C(0x297d584f728ba97c), UINT64_C(0x3cebca64eaf55f43),\n    UINT64_C(0x02507c1842764502), UINT64_C(0x17c6ee33da08b33d)\n  },\n  {\n    UINT64_C(0x0000000000000000), UINT64_C(0x2ddda07ff6672378),\n    UINT64_C(0x5bbb40ffecce46f0), UINT64_C(0x7666e0801aa96588),\n    UINT64_C(0xb77681ffd99c8de0), UINT64_C(0x9aab21802ffbae98),\n    UINT64_C(0xeccdc1003552cb10), UINT64_C(0xc110617fc335e868),\n    UINT64_C(0xfc35acd41c370545), UINT64_C(0xd1e80cabea50263d),\n    UINT64_C(0xa78eec2bf0f943b5), UINT64_C(0x8a534c54069e60cd),\n    UINT64_C(0x4b432d2bc5ab88a5), UINT64_C(0x669e8d5433ccabdd),\n    UINT64_C(0x10f86dd42965ce55), UINT64_C(0x3d25cdabdf02ed2d),\n    UINT64_C(0x6ab3f6839760140f), UINT64_C(0x476e56fc61073777),\n    UINT64_C(0x3108b67c7bae52ff), UINT64_C(0x1cd516038dc97187),\n    UINT64_C(0xddc5777c4efc99ef), UINT64_C(0xf018d703b89bba97),\n    UINT64_C(0x867e3783a232df1f), UINT64_C(0xaba397fc5455fc67),\n    UINT64_C(0x96865a578b57114a), UINT64_C(0xbb5bfa287d303232),\n    UINT64_C(0xcd3d1aa8679957ba), UINT64_C(0xe0e0bad791fe74c2),\n    UINT64_C(0x21f0dba852cb9caa), UINT64_C(0x0c2d7bd7a4acbfd2),\n    UINT64_C(0x7a4b9b57be05da5a), UINT64_C(0x57963b284862f922),\n    UINT64_C(0xd567ed072ec0281e), UINT64_C(0xf8ba4d78d8a70b66),\n    UINT64_C(0x8edcadf8c20e6eee), UINT64_C(0xa3010d8734694d96),\n    UINT64_C(0x62116cf8f75ca5fe), UINT64_C(0x4fcccc87013b8686),\n    UINT64_C(0x39aa2c071b92e30e), UINT64_C(0x14778c78edf5c076),\n    UINT64_C(0x295241d332f72d5b), UINT64_C(0x048fe1acc4900e23),\n    UINT64_C(0x72e9012cde396bab), UINT64_C(0x5f34a153285e48d3),\n    UINT64_C(0x9e24c02ceb6ba0bb), UINT64_C(0xb3f960531d0c83c3),\n    UINT64_C(0xc59f80d307a5e64b), UINT64_C(0xe84220acf1c2c533),\n    UINT64_C(0xbfd41b84b9a03c11), UINT64_C(0x9209bbfb4fc71f69),\n    UINT64_C(0xe46f5b7b556e7ae1), UINT64_C(0xc9b2fb04a3095999),\n    UINT64_C(0x08a29a7b603cb1f1), UINT64_C(0x257f3a04965b9289),\n    UINT64_C(0x5319da848cf2f701), UINT64_C(0x7ec47afb7a95d479),\n    UINT64_C(0x43e1b750a5973954), UINT64_C(0x6e3c172f53f01a2c),\n    UINT64_C(0x185af7af49597fa4), UINT64_C(0x358757d0bf3e5cdc),\n    UINT64_C(0xf49736af7c0bb4b4), UINT64_C(0xd94a96d08a6c97cc),\n    UINT64_C(0xaf2c765090c5f244), UINT64_C(0x82f1d62f66a2d13c),\n    UINT64_C(0x38177525f28e4eb9), UINT64_C(0x15cad55a04e96dc1),\n    UINT64_C(0x63ac35da1e400849), UINT64_C(0x4e7195a5e8272b31),\n    UINT64_C(0x8f61f4da2b12c359), UINT64_C(0xa2bc54a5dd75e021),\n    UINT64_C(0xd4dab425c7dc85a9), UINT64_C(0xf907145a31bba6d1),\n    UINT64_C(0xc422d9f1eeb94bfc), UINT64_C(0xe9ff798e18de6884),\n    UINT64_C(0x9f99990e02770d0c), UINT64_C(0xb2443971f4102e74),\n    UINT64_C(0x7354580e3725c61c), UINT64_C(0x5e89f871c142e564),\n    UINT64_C(0x28ef18f1dbeb80ec), UINT64_C(0x0532b88e2d8ca394),\n    UINT64_C(0x52a483a665ee5ab6), UINT64_C(0x7f7923d9938979ce),\n    UINT64_C(0x091fc35989201c46), UINT64_C(0x24c263267f473f3e),\n    UINT64_C(0xe5d20259bc72d756), UINT64_C(0xc80fa2264a15f42e),\n    UINT64_C(0xbe6942a650bc91a6), UINT64_C(0x93b4e2d9a6dbb2de),\n    UINT64_C(0xae912f7279d95ff3), UINT64_C(0x834c8f0d8fbe7c8b),\n    UINT64_C(0xf52a6f8d95171903), UINT64_C(0xd8f7cff263703a7b),\n    UINT64_C(0x19e7ae8da045d213), UINT64_C(0x343a0ef25622f16b),\n    UINT64_C(0x425cee724c8b94e3), UINT64_C(0x6f814e0dbaecb79b),\n    UINT64_C(0xed709822dc4e66a7), UINT64_C(0xc0ad385d2a2945df),\n    UINT64_C(0xb6cbd8dd30802057), UINT64_C(0x9b1678a2c6e7032f),\n    UINT64_C(0x5a0619dd05d2eb47), UINT64_C(0x77dbb9a2f3b5c83f),\n    UINT64_C(0x01bd5922e91cadb7), UINT64_C(0x2c60f95d1f7b8ecf),\n    UINT64_C(0x114534f6c07963e2), UINT64_C(0x3c989489361e409a),\n    UINT64_C(0x4afe74092cb72512), UINT64_C(0x6723d476dad0066a),\n    UINT64_C(0xa633b50919e5ee02), UINT64_C(0x8bee1576ef82cd7a),\n    UINT64_C(0xfd88f5f6f52ba8f2), UINT64_C(0xd0555589034c8b8a),\n    UINT64_C(0x87c36ea14b2e72a8), UINT64_C(0xaa1ecedebd4951d0),\n    UINT64_C(0xdc782e5ea7e03458), UINT64_C(0xf1a58e2151871720),\n    UINT64_C(0x30b5ef5e92b2ff48), UINT64_C(0x1d684f2164d5dc30),\n    UINT64_C(0x6b0eafa17e7cb9b8), UINT64_C(0x46d30fde881b9ac0),\n    UINT64_C(0x7bf6c275571977ed), UINT64_C(0x562b620aa17e5495),\n    UINT64_C(0x204d828abbd7311d), UINT64_C(0x0d9022f54db01265),\n    UINT64_C(0xcc80438a8e85fa0d), UINT64_C(0xe15de3f578e2d975),\n    UINT64_C(0x973b0375624bbcfd), UINT64_C(0xbae6a30a942c9f85),\n    UINT64_C(0x702eea4be51c9d72), UINT64_C(0x5df34a34137bbe0a),\n    UINT64_C(0x2b95aab409d2db82), UINT64_C(0x06480acbffb5f8fa),\n    UINT64_C(0xc7586bb43c801092), UINT64_C(0xea85cbcbcae733ea),\n    UINT64_C(0x9ce32b4bd04e5662), UINT64_C(0xb13e8b342629751a),\n    UINT64_C(0x8c1b469ff92b9837), UINT64_C(0xa1c6e6e00f4cbb4f),\n    UINT64_C(0xd7a0066015e5dec7), UINT64_C(0xfa7da61fe382fdbf),\n    UINT64_C(0x3b6dc76020b715d7), UINT64_C(0x16b0671fd6d036af),\n    UINT64_C(0x60d6879fcc795327), UINT64_C(0x4d0b27e03a1e705f),\n    UINT64_C(0x1a9d1cc8727c897d), UINT64_C(0x3740bcb7841baa05),\n    UINT64_C(0x41265c379eb2cf8d), UINT64_C(0x6cfbfc4868d5ecf5),\n    UINT64_C(0xadeb9d37abe0049d), UINT64_C(0x80363d485d8727e5),\n    UINT64_C(0xf650ddc8472e426d), UINT64_C(0xdb8d7db7b1496115),\n    UINT64_C(0xe6a8b01c6e4b8c38), UINT64_C(0xcb751063982caf40),\n    UINT64_C(0xbd13f0e38285cac8), UINT64_C(0x90ce509c74e2e9b0),\n    UINT64_C(0x51de31e3b7d701d8), UINT64_C(0x7c03919c41b022a0),\n    UINT64_C(0x0a65711c5b194728), UINT64_C(0x27b8d163ad7e6450),\n    UINT64_C(0xa549074ccbdcb56c), UINT64_C(0x8894a7333dbb9614),\n    UINT64_C(0xfef247b32712f39c), UINT64_C(0xd32fe7ccd175d0e4),\n    UINT64_C(0x123f86b31240388c), UINT64_C(0x3fe226cce4271bf4),\n    UINT64_C(0x4984c64cfe8e7e7c), UINT64_C(0x6459663308e95d04),\n    UINT64_C(0x597cab98d7ebb029), UINT64_C(0x74a10be7218c9351),\n    UINT64_C(0x02c7eb673b25f6d9), UINT64_C(0x2f1a4b18cd42d5a1),\n    UINT64_C(0xee0a2a670e773dc9), UINT64_C(0xc3d78a18f8101eb1),\n    UINT64_C(0xb5b16a98e2b97b39), UINT64_C(0x986ccae714de5841),\n    UINT64_C(0xcffaf1cf5cbca163), UINT64_C(0xe22751b0aadb821b),\n    UINT64_C(0x9441b130b072e793), UINT64_C(0xb99c114f4615c4eb),\n    UINT64_C(0x788c703085202c83), UINT64_C(0x5551d04f73470ffb),\n    UINT64_C(0x233730cf69ee6a73), UINT64_C(0x0eea90b09f89490b),\n    UINT64_C(0x33cf5d1b408ba426), UINT64_C(0x1e12fd64b6ec875e),\n    UINT64_C(0x68741de4ac45e2d6), UINT64_C(0x45a9bd9b5a22c1ae),\n    UINT64_C(0x84b9dce4991729c6), UINT64_C(0xa9647c9b6f700abe),\n    UINT64_C(0xdf029c1b75d96f36), UINT64_C(0xf2df3c6483be4c4e),\n    UINT64_C(0x48399f6e1792d3cb), UINT64_C(0x65e43f11e1f5f0b3),\n    UINT64_C(0x1382df91fb5c953b), UINT64_C(0x3e5f7fee0d3bb643),\n    UINT64_C(0xff4f1e91ce0e5e2b), UINT64_C(0xd292beee38697d53),\n    UINT64_C(0xa4f45e6e22c018db), UINT64_C(0x8929fe11d4a73ba3),\n    UINT64_C(0xb40c33ba0ba5d68e), UINT64_C(0x99d193c5fdc2f5f6),\n    UINT64_C(0xefb77345e76b907e), UINT64_C(0xc26ad33a110cb306),\n    UINT64_C(0x037ab245d2395b6e), UINT64_C(0x2ea7123a245e7816),\n    UINT64_C(0x58c1f2ba3ef71d9e), UINT64_C(0x751c52c5c8903ee6),\n    UINT64_C(0x228a69ed80f2c7c4), UINT64_C(0x0f57c9927695e4bc),\n    UINT64_C(0x793129126c3c8134), UINT64_C(0x54ec896d9a5ba24c),\n    UINT64_C(0x95fce812596e4a24), UINT64_C(0xb821486daf09695c),\n    UINT64_C(0xce47a8edb5a00cd4), UINT64_C(0xe39a089243c72fac),\n    UINT64_C(0xdebfc5399cc5c281), UINT64_C(0xf36265466aa2e1f9),\n    UINT64_C(0x850485c6700b8471), UINT64_C(0xa8d925b9866ca709),\n    UINT64_C(0x69c944c645594f61), UINT64_C(0x4414e4b9b33e6c19),\n    UINT64_C(0x32720439a9970991), UINT64_C(0x1fafa4465ff02ae9),\n    UINT64_C(0x9d5e72693952fbd5), UINT64_C(0xb083d216cf35d8ad),\n    UINT64_C(0xc6e53296d59cbd25), UINT64_C(0xeb3892e923fb9e5d),\n    UINT64_C(0x2a28f396e0ce7635), UINT64_C(0x07f553e916a9554d),\n    UINT64_C(0x7193b3690c0030c5), UINT64_C(0x5c4e1316fa6713bd),\n    UINT64_C(0x616bdebd2565fe90), UINT64_C(0x4cb67ec2d302dde8),\n    UINT64_C(0x3ad09e42c9abb860), UINT64_C(0x170d3e3d3fcc9b18),\n    UINT64_C(0xd61d5f42fcf97370), UINT64_C(0xfbc0ff3d0a9e5008),\n    UINT64_C(0x8da61fbd10373580), UINT64_C(0xa07bbfc2e65016f8),\n    UINT64_C(0xf7ed84eaae32efda), UINT64_C(0xda3024955855cca2),\n    UINT64_C(0xac56c41542fca92a), UINT64_C(0x818b646ab49b8a52),\n    UINT64_C(0x409b051577ae623a), UINT64_C(0x6d46a56a81c94142),\n    UINT64_C(0x1b2045ea9b6024ca), UINT64_C(0x36fde5956d0707b2),\n    UINT64_C(0x0bd8283eb205ea9f), UINT64_C(0x260588414462c9e7),\n    UINT64_C(0x506368c15ecbac6f), UINT64_C(0x7dbec8bea8ac8f17),\n    UINT64_C(0xbcaea9c16b99677f), UINT64_C(0x917309be9dfe4407),\n    UINT64_C(0xe715e93e8757218f), UINT64_C(0xcac84941713002f7)\n  }\n};\n\n\nuint64_t crc64_slow(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  uint64_t cs = UINT64_C(0xffffffffffffffff);\n\n  while (nbytes--) {\n    uint32_t idx = ((uint32_t) (cs ^ *data++)) & 0xff;\n    cs = crc64_table[3][idx] ^ (cs >> 8);\n  }\n\n  return cs ^ UINT64_C(0xffffffffffffffff);\n}\n\n\n\nstatic inline uint32_t crc64_load_le32_(const uint32_t *p) {\n  uint32_t w = *p;\n  return  ((((w) & 0xff000000) >> 24)\n         | (((w) & 0x00ff0000) >>  8)\n         | (((w) & 0x0000ff00) <<  8)\n         | (((w) & 0x000000ff) << 24));\n}\n\n\n\n\n\nuint64_t crc64(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  const unsigned char *end = data + nbytes;\n  uint64_t cs[5] = { UINT64_C(0xffffffffffffffff), 0, 0, 0, 0 };\n\n  \n\n  \n\n  \n\n  \n\n  while (data < end && ((((size_t) data) & 3) || (end - data < 20))) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  if (data == end)\n    return cs[0] ^ UINT64_C(0xffffffffffffffff);\n\n  const uint32_t one = 1;\n  bool big_endian = !(*((char *)(&one)));\n\n  uint64_t cry = 0;\n  uint32_t in[5];\n\n  if (!big_endian) {\n    for (unsigned i = 0; i < 5; ++i)\n      in[i] = ((const uint32_t*) data)[i];\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = ((const uint32_t*) data)[0];\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = ((const uint32_t*) data)[1];\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = ((const uint32_t*) data)[2];\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = ((const uint32_t*) data)[3];\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = ((const uint32_t*) data)[4];\n    }\n  } else {\n    for (unsigned i = 0; i < 5; ++i) {\n      in[i] = crc64_load_le32_(&((const uint32_t*) data)[i]);\n    }\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = crc64_load_le32_(&((const uint32_t*) data)[0]);\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = crc64_load_le32_(&((const uint32_t*) data)[1]);\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = crc64_load_le32_(&((const uint32_t*) data)[2]);\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = crc64_load_le32_(&((const uint32_t*) data)[3]);\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = crc64_load_le32_(&((const uint32_t*) data)[4]);\n    }\n  }\n\n  cs[0] ^= cry;\n\n  for (unsigned i = 0; i < 5; ++i) {\n    if (i > 0)\n      cs[0] ^= cs[i];\n    in[i] ^= (uint32_t) cs[0];\n    cs[0] = cs[0] >> 32;\n\n    for (unsigned b = 0; b < 3; ++b) {\n      cs[0] ^= crc64_table[b][in[i] & 0xff];\n      in[i] >>= 8;\n    }\n\n    cs[0] ^= crc64_table[3][in[i] & 0xff];\n  }\n\n  while (data < end) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  return cs[0] ^ UINT64_C(0xffffffffffffffff);\n}\n\n\n\n\n\nvoid crc64_invert(uint64_t cs, void *check_bytes) {\n  unsigned char *bytes = (unsigned char *) check_bytes;\n  cs ^= UINT64_C(0xffffffffffffffff);\n\n  \n\n  \n\n  bytes[7] = (cs >> 56) & 0xff;\n  bytes[6] = (cs >> 48) & 0xff;\n  bytes[5] = (cs >> 40) & 0xff;\n  bytes[4] = (cs >> 32) & 0xff;\n  bytes[3] = (cs >> 24) & 0xff;\n  bytes[2] = (cs >> 16) & 0xff;\n  bytes[1] = (cs >>  8) & 0xff;\n  bytes[0] =  cs        & 0xff;\n}\n\nstatic const uint64_t crc64_x_pow_2n[64] = {\n  UINT64_C(0x4000000000000000), UINT64_C(0x2000000000000000),\n  UINT64_C(0x0800000000000000), UINT64_C(0x0080000000000000),\n  UINT64_C(0x0000800000000000), UINT64_C(0x0000000080000000),\n  UINT64_C(0xc96c5795d7870f42), UINT64_C(0x6d5f4ad7e3c3afa0),\n  UINT64_C(0xd49f7e445077d8ea), UINT64_C(0x040fb02a53c216fa),\n  UINT64_C(0x6bec35957b9ef3a0), UINT64_C(0xb0e3bb0658964afe),\n  UINT64_C(0x218578c7a2dff638), UINT64_C(0x6dbb920f24dd5cf2),\n  UINT64_C(0x7a140cfcdb4d5eb5), UINT64_C(0x41b3705ecbc4057b),\n  UINT64_C(0xd46ab656accac1ea), UINT64_C(0x329beda6fc34fb73),\n  UINT64_C(0x51a4fcd4350b9797), UINT64_C(0x314fa85637efae9d),\n  UINT64_C(0xacf27e9a1518d512), UINT64_C(0xffe2a3388a4d8ce7),\n  UINT64_C(0x48b9697e60cc2e4e), UINT64_C(0xada73cb78dd62460),\n  UINT64_C(0x3ea5454d8ce5c1bb), UINT64_C(0x5e84e3a6c70feaf1),\n  UINT64_C(0x90fd49b66cbd81d1), UINT64_C(0xe2943e0c1db254e8),\n  UINT64_C(0xecfa6adeca8834a1), UINT64_C(0xf513e212593ee321),\n  UINT64_C(0xf36ae57331040916), UINT64_C(0x63fbd333b87b6717),\n  UINT64_C(0xbd60f8e152f50b8b), UINT64_C(0xa5ce4a8299c1567d),\n  UINT64_C(0x0bd445f0cbdb55ee), UINT64_C(0xfdd6824e20134285),\n  UINT64_C(0xcead8b6ebda2227a), UINT64_C(0xe44b17e4f5d4fb5c),\n  UINT64_C(0x9b29c81ad01ca7c5), UINT64_C(0x1b4366e40fea4055),\n  UINT64_C(0x27bca1551aae167b), UINT64_C(0xaa57bcd1b39a5690),\n  UINT64_C(0xd7fce83fa1234db9), UINT64_C(0xcce4986efea3ff8e),\n  UINT64_C(0x3602a4d9e65341f1), UINT64_C(0x722b1da2df516145),\n  UINT64_C(0xecfc3ddd3a08da83), UINT64_C(0x0fb96dcca83507e6),\n  UINT64_C(0x125f2fe78d70f080), UINT64_C(0x842f50b7651aa516),\n  UINT64_C(0x09bc34188cd9836f), UINT64_C(0xf43666c84196d909),\n  UINT64_C(0xb56feb30c0df6ccb), UINT64_C(0xaa66e04ce7f30958),\n  UINT64_C(0xb7b1187e9af29547), UINT64_C(0x113255f8476495de),\n  UINT64_C(0x8fb19f783095d77e), UINT64_C(0xaec4aacc7c82b133),\n  UINT64_C(0xf64e6d09218428cf), UINT64_C(0x036a72ea5ac258a0),\n  UINT64_C(0x5235ef12eb7aaa6a), UINT64_C(0x2fed7b1685657853),\n  UINT64_C(0x8ef8951d46606fb5), UINT64_C(0x9d58c1090f034d14)\n};\n\n\n\n\n\nstatic inline uint64_t crc64_multiply_(uint64_t a, uint64_t b) {\n  if ((a ^ (a-1)) < (b ^ (b-1))) {\n    uint64_t t = a;\n    a = b;\n    b = t;\n  }\n\n  if (a == 0)\n    return 0;\n\n  uint64_t r = 0, h = UINT64_C(1) << 63;\n  for (; a != 0; a <<= 1) {\n    if (a & h) {\n      r ^= b;\n      a ^= h;\n    }\n\n    b = (b >> 1) ^ ((b & 1) ? crc64_poly : 0);\n  }\n\n  return r;\n}\n\n\n\nstatic inline uint64_t crc64_x_pow_n_(uint64_t n) {\n  uint64_t r = UINT64_C(1) << 63;\n  for (size_t i = 0; n != 0; n >>= 1, ++i) {\n    if (n & 1)\n      r = crc64_multiply_(r, crc64_x_pow_2n[i]);\n  }\n\n  return r;\n}\n\nuint64_t crc64_combine(uint64_t cs1, uint64_t cs2, size_t nbytes2) {\n  \n\n  \n\n  return cs2 ^ crc64_multiply_(cs1, crc64_x_pow_n_(8*nbytes2));\n}\n\nstatic const size_t crc64_min_thread_bytes = 1024;\n\nuint64_t crc64_omp(const void *input, size_t nbytes) {\n\n#ifdef _OPENMP\n  if (nbytes > 2*crc64_min_thread_bytes) {\n    int nthreads = 96*8*32;\n\n    if (nbytes < nthreads*crc64_min_thread_bytes)\n      nthreads = nbytes/crc64_min_thread_bytes;\n\n    uint64_t thread_cs[nthreads];\n    size_t thread_sz[nthreads];\n\n    const unsigned char *data = (const unsigned char*) input;\n\n        {\n              for (int tid = 0; tid < nthreads; tid++) {\n          size_t bpt = nbytes/nthreads;\n          const unsigned char *start = data + bpt*tid, *end;\n          if (tid != nthreads - 1)\n            end = start + bpt;\n          else\n            end = data + nbytes;\n    \n          size_t sz = end - start;\n          thread_sz[tid] = sz;\n          thread_cs[tid] = crc64(start, sz);\n       }\n    }\n\n    uint64_t cs = thread_cs[0];\n    for (int i = 1; i < nthreads; ++i) {\n      cs = crc64_combine(cs, thread_cs[i], thread_sz[i]);\n    }\n\n    return cs;\n  }\n#endif\n\n  return crc64(input, nbytes);\n}", "CRC64Test.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define _XOPEN_SOURCE 600\n\n#include <ctime>\n#include <vector>\n#include <iostream>\n#include \"CRC64.h\"\n\nusing namespace std;\nint main(int argc, char *argv[]) {\n  int ntests = 10;\n  if (argc > 1) ntests = atoi(argv[1]);\n\n  int seed = 5;\n  if (argc > 2) seed = atoi(argv[2]);\n\n  int max_test_length = 2097152;\n  if (argc > 3) max_test_length = atoi(argv[3]);\n\n  cout << \"Running \" << ntests << \" tests with seed \" << seed << endl;\n\n  srand48(seed);\n\n#ifdef __bgp__\n#define THE_CLOCK CLOCK_REALTIME\n#else\n#define THE_CLOCK CLOCK_THREAD_CPUTIME_ID\n#endif\n\n  double tot_time = 0, tot_bytes = 0;\n\n  int ntest = 0;\n  while (++ntest <= ntests) {\n    cout << ntest << \" \";\n\n    size_t test_length = (size_t) (max_test_length*(drand48()+1));\n    cout << test_length << \" \";\n\n    vector<unsigned char> buffer(test_length);\n\n    for (size_t i = 0; i < test_length; ++i) {\n      buffer[i] = (unsigned char) (255*drand48());\n    }\n\n    timespec b_start, b_end;\n    clock_gettime(THE_CLOCK, &b_start);\n\n    uint64_t cs = crc64_omp(&buffer[0], test_length);\n\n    clock_gettime(THE_CLOCK, &b_end);\n    double b_time = (b_end.tv_sec - b_start.tv_sec);\n    b_time += 1e-9*(b_end.tv_nsec - b_start.tv_nsec);\n\n    if (ntest > 1) {\n      tot_time += b_time;\n      tot_bytes += test_length;\n    }\n\n    \n\n    size_t tlend = 8;\n    buffer.resize(test_length + tlend, 0);\n    crc64_invert(cs, &buffer[test_length]);\n\n    string pass(\"pass\"), fail(\"fail\");\n    uint64_t csc = crc64(&buffer[0], test_length+tlend);\n    cout << ((csc == (uint64_t) -1) ? pass : fail) << \" \";\n\n    size_t div_pt = (size_t) (test_length*drand48());\n    uint64_t cs1 = crc64(&buffer[0], div_pt);\n    uint64_t cs2 = crc64(&buffer[div_pt], test_length - div_pt);\n    csc = crc64_combine(cs1, cs2, test_length - div_pt);\n    cout << ((csc == cs) ? pass : fail);\n\n    cout << endl;\n  }\n\n  cout << (tot_bytes/(1024*1024))/tot_time << \" MB/s\" << endl;\n\n  return 0;\n}"}}
{"kernel_name": "crc64", "parallel_api": "sycl", "code": {"CRC64.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef __STDC_CONSTANT_MACROS\n#define __STDC_CONSTANT_MACROS\n#endif\n\n#ifdef HAVE_CONFIG_H\n#include <config.h>\n#endif\n\n#include <stdbool.h>\n\n#include <sycl/sycl.hpp>\n#include \"CRC64.h\"\n\n\n\nstatic const uint64_t crc64_poly = UINT64_C(0xc96c5795d7870f42);\n\n#include \"crc64_table.h\"\n\nuint64_t crc64_slow(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  uint64_t cs = UINT64_C(0xffffffffffffffff);\n\n  while (nbytes--) {\n    uint32_t idx = ((uint32_t) (cs ^ *data++)) & 0xff;\n    cs = crc64_table[3][idx] ^ (cs >> 8);\n  }\n\n  return cs ^ UINT64_C(0xffffffffffffffff);\n}\n\n\n\nstatic inline uint32_t crc64_load_le32_(const uint32_t *p) {\n  uint32_t w = *p;\n  return  ((((w) & 0xff000000) >> 24)\n         | (((w) & 0x00ff0000) >>  8)\n         | (((w) & 0x0000ff00) <<  8)\n         | (((w) & 0x000000ff) << 24));\n}\n\n\n\n\n\nuint64_t crc64(const void *input, size_t nbytes) {\n  const unsigned char *data = (const unsigned char*) input;\n  const unsigned char *end = data + nbytes;\n  uint64_t cs[5] = { UINT64_C(0xffffffffffffffff), 0, 0, 0, 0 };\n\n  \n\n  \n\n  \n\n  \n\n  while (data < end && ((((size_t) data) & 3) || (end - data < 20))) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  if (data == end)\n    return cs[0] ^ UINT64_C(0xffffffffffffffff);\n\n  const uint32_t one = 1;\n  bool big_endian = !(*((char *)(&one)));\n\n  uint64_t cry = 0;\n  uint32_t in[5];\n\n  if (!big_endian) {\n    for (unsigned i = 0; i < 5; ++i)\n      in[i] = ((const uint32_t*) data)[i];\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = ((const uint32_t*) data)[0];\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = ((const uint32_t*) data)[1];\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = ((const uint32_t*) data)[2];\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = ((const uint32_t*) data)[3];\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = ((const uint32_t*) data)[4];\n    }\n  } else {\n    for (unsigned i = 0; i < 5; ++i) {\n      in[i] = crc64_load_le32_(&((const uint32_t*) data)[i]);\n    }\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = crc64_interleaved_table[0][in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = crc64_interleaved_table[0][in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = crc64_interleaved_table[0][in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = crc64_interleaved_table[0][in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = crc64_interleaved_table[0][in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= crc64_interleaved_table[b][in[0] & 0xff];\n        in[0] >>= 8;\n\n        cs[1] ^= crc64_interleaved_table[b][in[1] & 0xff];\n        in[1] >>= 8;\n\n        cs[2] ^= crc64_interleaved_table[b][in[2] & 0xff];\n        in[2] >>= 8;\n\n        cs[3] ^= crc64_interleaved_table[b][in[3] & 0xff];\n        in[3] >>= 8;\n\n        cs[4] ^= crc64_interleaved_table[b][in[4] & 0xff];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= crc64_interleaved_table[3][in[0] & 0xff];\n      in[0] = crc64_load_le32_(&((const uint32_t*) data)[0]);\n\n      cs[1] ^= crc64_interleaved_table[3][in[1] & 0xff];\n      in[1] = crc64_load_le32_(&((const uint32_t*) data)[1]);\n\n      cs[2] ^= crc64_interleaved_table[3][in[2] & 0xff];\n      in[2] = crc64_load_le32_(&((const uint32_t*) data)[2]);\n\n      cs[3] ^= crc64_interleaved_table[3][in[3] & 0xff];\n      in[3] = crc64_load_le32_(&((const uint32_t*) data)[3]);\n\n      cs[4] ^= crc64_interleaved_table[3][in[4] & 0xff];\n      in[4] = crc64_load_le32_(&((const uint32_t*) data)[4]);\n    }\n  }\n\n  cs[0] ^= cry;\n\n  for (unsigned i = 0; i < 5; ++i) {\n    if (i > 0)\n      cs[0] ^= cs[i];\n    in[i] ^= (uint32_t) cs[0];\n    cs[0] = cs[0] >> 32;\n\n    for (unsigned b = 0; b < 3; ++b) {\n      cs[0] ^= crc64_table[b][in[i] & 0xff];\n      in[i] >>= 8;\n    }\n\n    cs[0] ^= crc64_table[3][in[i] & 0xff];\n  }\n\n  while (data < end) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = crc64_table[3][idx] ^ (cs[0] >> 8);\n  }\n\n  return cs[0] ^ UINT64_C(0xffffffffffffffff);\n}\n\ninline\nuint64_t crc64_device(const unsigned char *input, size_t nbytes, \n\t\tconst uint64_t *d_crc64_table, \n\t\tconst uint64_t *d_crc64_interleaved_table) {\n  const unsigned char *data = input;\n  const unsigned char *end = data + nbytes;\n  uint64_t cs[5] = { UINT64_C(0xffffffffffffffff), 0, 0, 0, 0 };\n\n  \n\n  \n\n  \n\n  \n\n  while (data < end && ((((size_t) data) & 3) || (end - data < 20))) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = d_crc64_table[3*256+idx] ^ (cs[0] >> 8);\n  }\n\n  if (data == end)\n    return cs[0] ^ UINT64_C(0xffffffffffffffff);\n\n  const uint32_t one = 1;\n  bool big_endian = !(*((char *)(&one)));\n\n  uint64_t cry = 0;\n  uint32_t in[5];\n\n  if (!big_endian) {\n    for (unsigned i = 0; i < 5; ++i)\n      in[i] = ((const uint32_t*) data)[i];\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = d_crc64_interleaved_table[in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = d_crc64_interleaved_table[in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = d_crc64_interleaved_table[in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = d_crc64_interleaved_table[in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = d_crc64_interleaved_table[in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= d_crc64_interleaved_table[b*256+(in[0] & 0xff)];\n        in[0] >>= 8;\n\n        cs[1] ^= d_crc64_interleaved_table[b*256+(in[1] & 0xff)];\n        in[1] >>= 8;\n\n        cs[2] ^= d_crc64_interleaved_table[b*256+(in[2] & 0xff)];\n        in[2] >>= 8;\n\n        cs[3] ^= d_crc64_interleaved_table[b*256+(in[3] & 0xff)];\n        in[3] >>= 8;\n\n        cs[4] ^= d_crc64_interleaved_table[b*256+(in[4] & 0xff)];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= d_crc64_interleaved_table[3*256+(in[0] & 0xff)];\n      in[0] = ((const uint32_t*) data)[0];\n\n      cs[1] ^= d_crc64_interleaved_table[3*256+(in[1] & 0xff)];\n      in[1] = ((const uint32_t*) data)[1];\n\n      cs[2] ^= d_crc64_interleaved_table[3*256+(in[2] & 0xff)];\n      in[2] = ((const uint32_t*) data)[2];\n\n      cs[3] ^= d_crc64_interleaved_table[3*256+(in[3] & 0xff)];\n      in[3] = ((const uint32_t*) data)[3];\n\n      cs[4] ^= d_crc64_interleaved_table[3*256+(in[4] & 0xff)];\n      in[4] = ((const uint32_t*) data)[4];\n    }\n  } else {\n    for (unsigned i = 0; i < 5; ++i) {\n      in[i] = crc64_load_le32_(&((const uint32_t*) data)[i]);\n    }\n    data += 20;\n\n    for (; end - data >= 20; data += 20) {\n      cs[0] ^= cry;\n\n      in[0] ^= (uint32_t) cs[0];\n      cs[1] ^= cs[0] >> 32;\n      cs[0] = d_crc64_interleaved_table[in[0] & 0xff];\n      in[0] >>= 8;\n\n      in[1] ^= (uint32_t) cs[1];\n      cs[2] ^= cs[1] >> 32;\n      cs[1] = d_crc64_interleaved_table[in[1] & 0xff];\n      in[1] >>= 8;\n\n      in[2] ^= (uint32_t) cs[2];\n      cs[3] ^= cs[2] >> 32;\n      cs[2] = d_crc64_interleaved_table[in[2] & 0xff];\n      in[2] >>= 8;\n\n      in[3] ^= (uint32_t) cs[3];\n      cs[4] ^= cs[3] >> 32;\n      cs[3] = d_crc64_interleaved_table[in[3] & 0xff];\n      in[3] >>= 8;\n\n      in[4] ^= (uint32_t) cs[4];\n      cry = cs[4] >> 32;\n      cs[4] = d_crc64_interleaved_table[in[4] & 0xff];\n      in[4] >>= 8;\n\n      for (unsigned b = 1; b < 3; ++b) {\n        cs[0] ^= d_crc64_interleaved_table[b*256+(in[0] & 0xff)];\n        in[0] >>= 8;\n\n        cs[1] ^= d_crc64_interleaved_table[b*256+(in[1] & 0xff)];\n        in[1] >>= 8;\n\n        cs[2] ^= d_crc64_interleaved_table[b*256+(in[2] & 0xff)];\n        in[2] >>= 8;\n\n        cs[3] ^= d_crc64_interleaved_table[b*256+(in[3] & 0xff)];\n        in[3] >>= 8;\n\n        cs[4] ^= d_crc64_interleaved_table[b*256+(in[4] & 0xff)];\n        in[4] >>= 8;\n      }\n\n      cs[0] ^= d_crc64_interleaved_table[3*256+(in[0] & 0xff)];\n      in[0] = crc64_load_le32_(&((const uint32_t*) data)[0]);\n\n      cs[1] ^= d_crc64_interleaved_table[3*256+(in[1] & 0xff)];\n      in[1] = crc64_load_le32_(&((const uint32_t*) data)[1]);\n\n      cs[2] ^= d_crc64_interleaved_table[3*256+(in[2] & 0xff)];\n      in[2] = crc64_load_le32_(&((const uint32_t*) data)[2]);\n\n      cs[3] ^= d_crc64_interleaved_table[3*256+(in[3] & 0xff)];\n      in[3] = crc64_load_le32_(&((const uint32_t*) data)[3]);\n\n      cs[4] ^= d_crc64_interleaved_table[3*256+(in[4] & 0xff)];\n      in[4] = crc64_load_le32_(&((const uint32_t*) data)[4]);\n    }\n  }\n\n  cs[0] ^= cry;\n\n  for (unsigned i = 0; i < 5; ++i) {\n    if (i > 0)\n      cs[0] ^= cs[i];\n    in[i] ^= (uint32_t) cs[0];\n    cs[0] = cs[0] >> 32;\n\n    for (unsigned b = 0; b < 3; ++b) {\n      cs[0] ^= d_crc64_table[b*256+(in[i] & 0xff)];\n      in[i] >>= 8;\n    }\n\n    cs[0] ^= d_crc64_table[3*256+(in[i] & 0xff)];\n  }\n\n  while (data < end) {\n    uint32_t idx = ((uint32_t) (cs[0] ^ *data++)) & 0xff;\n    cs[0] = d_crc64_table[3*256+idx] ^ (cs[0] >> 8);\n  }\n\n  return cs[0] ^ UINT64_C(0xffffffffffffffff);\n}\n\n\n\n\n\nvoid crc64_invert(uint64_t cs, void *check_bytes) {\n  unsigned char *bytes = (unsigned char *) check_bytes;\n  cs ^= UINT64_C(0xffffffffffffffff);\n\n  \n\n  \n\n  bytes[7] = (cs >> 56) & 0xff;\n  bytes[6] = (cs >> 48) & 0xff;\n  bytes[5] = (cs >> 40) & 0xff;\n  bytes[4] = (cs >> 32) & 0xff;\n  bytes[3] = (cs >> 24) & 0xff;\n  bytes[2] = (cs >> 16) & 0xff;\n  bytes[1] = (cs >>  8) & 0xff;\n  bytes[0] =  cs        & 0xff;\n}\n\nstatic const uint64_t crc64_x_pow_2n[64] = {\n  UINT64_C(0x4000000000000000), UINT64_C(0x2000000000000000),\n  UINT64_C(0x0800000000000000), UINT64_C(0x0080000000000000),\n  UINT64_C(0x0000800000000000), UINT64_C(0x0000000080000000),\n  UINT64_C(0xc96c5795d7870f42), UINT64_C(0x6d5f4ad7e3c3afa0),\n  UINT64_C(0xd49f7e445077d8ea), UINT64_C(0x040fb02a53c216fa),\n  UINT64_C(0x6bec35957b9ef3a0), UINT64_C(0xb0e3bb0658964afe),\n  UINT64_C(0x218578c7a2dff638), UINT64_C(0x6dbb920f24dd5cf2),\n  UINT64_C(0x7a140cfcdb4d5eb5), UINT64_C(0x41b3705ecbc4057b),\n  UINT64_C(0xd46ab656accac1ea), UINT64_C(0x329beda6fc34fb73),\n  UINT64_C(0x51a4fcd4350b9797), UINT64_C(0x314fa85637efae9d),\n  UINT64_C(0xacf27e9a1518d512), UINT64_C(0xffe2a3388a4d8ce7),\n  UINT64_C(0x48b9697e60cc2e4e), UINT64_C(0xada73cb78dd62460),\n  UINT64_C(0x3ea5454d8ce5c1bb), UINT64_C(0x5e84e3a6c70feaf1),\n  UINT64_C(0x90fd49b66cbd81d1), UINT64_C(0xe2943e0c1db254e8),\n  UINT64_C(0xecfa6adeca8834a1), UINT64_C(0xf513e212593ee321),\n  UINT64_C(0xf36ae57331040916), UINT64_C(0x63fbd333b87b6717),\n  UINT64_C(0xbd60f8e152f50b8b), UINT64_C(0xa5ce4a8299c1567d),\n  UINT64_C(0x0bd445f0cbdb55ee), UINT64_C(0xfdd6824e20134285),\n  UINT64_C(0xcead8b6ebda2227a), UINT64_C(0xe44b17e4f5d4fb5c),\n  UINT64_C(0x9b29c81ad01ca7c5), UINT64_C(0x1b4366e40fea4055),\n  UINT64_C(0x27bca1551aae167b), UINT64_C(0xaa57bcd1b39a5690),\n  UINT64_C(0xd7fce83fa1234db9), UINT64_C(0xcce4986efea3ff8e),\n  UINT64_C(0x3602a4d9e65341f1), UINT64_C(0x722b1da2df516145),\n  UINT64_C(0xecfc3ddd3a08da83), UINT64_C(0x0fb96dcca83507e6),\n  UINT64_C(0x125f2fe78d70f080), UINT64_C(0x842f50b7651aa516),\n  UINT64_C(0x09bc34188cd9836f), UINT64_C(0xf43666c84196d909),\n  UINT64_C(0xb56feb30c0df6ccb), UINT64_C(0xaa66e04ce7f30958),\n  UINT64_C(0xb7b1187e9af29547), UINT64_C(0x113255f8476495de),\n  UINT64_C(0x8fb19f783095d77e), UINT64_C(0xaec4aacc7c82b133),\n  UINT64_C(0xf64e6d09218428cf), UINT64_C(0x036a72ea5ac258a0),\n  UINT64_C(0x5235ef12eb7aaa6a), UINT64_C(0x2fed7b1685657853),\n  UINT64_C(0x8ef8951d46606fb5), UINT64_C(0x9d58c1090f034d14)\n};\n\n\n\n\n\nstatic inline uint64_t crc64_multiply_(uint64_t a, uint64_t b) {\n  if ((a ^ (a-1)) < (b ^ (b-1))) {\n    uint64_t t = a;\n    a = b;\n    b = t;\n  }\n\n  if (a == 0)\n    return 0;\n\n  uint64_t r = 0, h = UINT64_C(1) << 63;\n  for (; a != 0; a <<= 1) {\n    if (a & h) {\n      r ^= b;\n      a ^= h;\n    }\n\n    b = (b >> 1) ^ ((b & 1) ? crc64_poly : 0);\n  }\n\n  return r;\n}\n\n\n\nstatic inline uint64_t crc64_x_pow_n_(uint64_t n) {\n  uint64_t r = UINT64_C(1) << 63;\n  for (size_t i = 0; n != 0; n >>= 1, ++i) {\n    if (n & 1)\n      r = crc64_multiply_(r, crc64_x_pow_2n[i]);\n  }\n\n  return r;\n}\n\nuint64_t crc64_combine(uint64_t cs1, uint64_t cs2, size_t nbytes2) {\n  \n\n  \n\n  return cs2 ^ crc64_multiply_(cs1, crc64_x_pow_n_(8*nbytes2));\n}\n\nstatic const size_t crc64_min_thread_bytes = 1024;\n\nuint64_t crc64_parallel(sycl::queue &q, const void *input, size_t nbytes) {\n\n  if (nbytes > 2*crc64_min_thread_bytes) {\n    int nthreads = 96*8*32;\n\n    if (nbytes < nthreads*crc64_min_thread_bytes)\n      nthreads = nbytes/crc64_min_thread_bytes;\n\n    uint64_t thread_cs[nthreads];\n    size_t thread_sz[nthreads];\n\n    const unsigned char *data = (const unsigned char*) input;\n\n    uint64_t *d_thread_sz = sycl::malloc_device<size_t>(nthreads, q);\n    size_t *d_thread_cs = sycl::malloc_device<uint64_t>(nthreads, q);\n\n    unsigned char *d_data = sycl::malloc_device<unsigned char>(nbytes, q);\n    q.memcpy(d_data, data, nbytes);\n\n    uint64_t *d_crc64_table = sycl::malloc_device<uint64_t>(4*256, q);\n    q.memcpy(d_crc64_table, crc64_table_1D, sizeof(uint64_t) * 4 * 256);\n\n    uint64_t *d_crc64_interleaved_table = sycl::malloc_device<uint64_t>(4*256, q);\n    q.memcpy(d_crc64_interleaved_table, crc64_interleaved_table_1D, sizeof(uint64_t) * 4 * 256);\n\n    sycl::range<1> local_size(64);\n    sycl::range<1> global_size(nthreads);\n\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class crc64_block>(\n        sycl::nd_range<1>(global_size, local_size), [=](sycl::nd_item<1> item) {\n        int tid = item.get_global_id(0);\n          size_t bpt = nbytes/nthreads;\n          const unsigned char *start = d_data + bpt*tid;\n          const unsigned char *end;\n          if (tid != nthreads - 1)\n            end = start + bpt;\n          else\n            end = d_data + nbytes;\n    \n          size_t sz = end - start;\n          d_thread_sz[tid] = sz;\n          d_thread_cs[tid] = crc64_device(start, sz, d_crc64_table, d_crc64_interleaved_table);\n      });\n    });\n\n    q.memcpy(thread_sz, d_thread_sz, sizeof(size_t) * nthreads);\n    q.memcpy(thread_cs, d_thread_cs, sizeof(uint64_t) * nthreads);\n\n    q.wait();\n\n    uint64_t cs = thread_cs[0];\n    for (int i = 1; i < nthreads; ++i) {\n      cs = crc64_combine(cs, thread_cs[i], thread_sz[i]);\n    }\n\n    sycl::free(d_thread_sz, q);\n    sycl::free(d_thread_cs, q);\n    sycl::free(d_data, q);\n    sycl::free(d_crc64_table, q);\n    sycl::free(d_crc64_interleaved_table, q);\n    return cs;\n  }\n\n  return crc64(input, nbytes);\n}\n", "CRC64Test.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define _XOPEN_SOURCE 600\n\n#include <ctime>\n#include <vector>\n#include <iostream>\n#include \"CRC64.h\"\n#include <sycl/sycl.hpp>\n\n\n\nint main(int argc, char *argv[]) {\n  int ntests = 10;\n  if (argc > 1) ntests = atoi(argv[1]);\n\n  int seed = 5;\n  if (argc > 2) seed = atoi(argv[2]);\n\n  int max_test_length = 2097152;\n  if (argc > 3) max_test_length = atoi(argv[3]);\n\n  std::cout << \"Running \" << ntests << \" tests with seed \" << seed << std::endl;\n\n  srand48(seed);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n#ifdef __bgp__\n#define THE_CLOCK CLOCK_REALTIME\n#else\n#define THE_CLOCK CLOCK_THREAD_CPUTIME_ID\n#endif\n\n  double tot_time = 0, tot_bytes = 0;\n\n  int ntest = 0;\n  while (++ntest <= ntests) {\n    std::cout << ntest << \" \";\n\n    size_t test_length = (size_t) (max_test_length*(drand48()+1));\n    std::cout << test_length << \" \";\n\n    std::vector<unsigned char> input_buffer(test_length);\n\n    for (size_t i = 0; i < test_length; ++i) {\n      input_buffer[i] = (unsigned char) (255*drand48());\n    }\n\n    timespec b_start, b_end;\n    clock_gettime(THE_CLOCK, &b_start);\n\n    uint64_t cs = crc64_parallel(q, &input_buffer[0], test_length);\n\n    clock_gettime(THE_CLOCK, &b_end);\n    double b_time = (b_end.tv_sec - b_start.tv_sec);\n    b_time += 1e-9*(b_end.tv_nsec - b_start.tv_nsec);\n\n    if (ntest > 1) {\n      tot_time += b_time;\n      tot_bytes += test_length;\n    }\n\n    \n\n    size_t tlend = 8;\n    input_buffer.resize(test_length + tlend, 0);\n    crc64_invert(cs, &input_buffer[test_length]);\n\n    std::string pass(\"pass\"), fail(\"fail\");\n    uint64_t csc = crc64(&input_buffer[0], test_length+tlend);\n    std::cout << ((csc == (uint64_t) -1) ? pass : fail) << \" \";\n\n    size_t div_pt = (size_t) (test_length*drand48());\n    uint64_t cs1 = crc64(&input_buffer[0], div_pt);\n    uint64_t cs2 = crc64(&input_buffer[div_pt], test_length - div_pt);\n    csc = crc64_combine(cs1, cs2, test_length - div_pt);\n    std::cout << ((csc == cs) ? pass : fail);\n\n    std::cout << std::endl;\n  }\n\n  std::cout << (tot_bytes/(1024*1024))/tot_time << \" MB/s\" << std::endl;\n\n  return 0;\n}\n"}}
{"kernel_name": "daphne", "parallel_api": "cuda", "code": {"main.cpp": "\n\n#include <chrono>\n#include <iostream>\n#include <string.h>\n#include <stdlib.h>\n#include \"benchmark.h\"\n\nstd::chrono::high_resolution_clock::time_point start,end;\nstd::chrono::duration<double> elapsed;\nstd::chrono::high_resolution_clock timer;\nbool pause = false;\n\n\n\nint pipelined = 1;\n\nextern kernel& myKernel;\n\nvoid pause_timer()\n{\n  end = timer.now();\n  elapsed += (end-start);\n  pause = true;\n}  \n\nvoid unpause_timer() \n{\n  pause = false;\n  start = timer.now();\n}\n\nvoid usage(char *exec)\n{\n  std::cout << \"Usage: \\n\" << exec << \" [-p N]\\nOptions:\\n  -p N   executes N invocations in sequence,\";\n  std::cout << \"before taking time and check the result.\\n\";\n  std::cout << \"         Default: N=1\\n\";\n}\nint main(int argc, char **argv) {\n\n  if ((argc != 1) && (argc !=  3))\n  {\n    usage(argv[0]);\n    exit(2);\n  }\n  if (argc == 3)\n  {\n    if (strcmp(argv[1], \"-p\") != 0)\n    {\n      usage(argv[0]);\n      exit(3);\n    }\n    errno = 0;\n    pipelined = strtol(argv[2], NULL, 10);\n    if (errno || (pipelined < 1) )\n    {\n      usage(argv[0]);\n      exit(4);\n    }\n    std::cout << \"Invoking kernel \" << pipelined << \" time(s) per measure/checking step\\n\";\n  }\n  \n\n  myKernel.set_timer_functions(pause_timer, unpause_timer);\n  myKernel.init();\n\n  \n\n  start = timer.now();\n\n  \n\n  myKernel.run(pipelined);\n\n  \n\n  if (!pause) \n  {\n    end = timer.now();\n    elapsed += end-start;\n  }\n  std::cout << \"Elapsed time: \"<< elapsed.count() << \" seconds, average time per testcase (#\"\n            << myKernel.testcases << \"): \" << elapsed.count() / (double) myKernel.testcases\n            << \" seconds\" << std::endl;\n\n  \n\n  if (myKernel.check_output())\n    std::cout << \"PASS\\n\";\n  else \n    std::cout << \"FAIL\\n\";\n\n  return 0;\n}\n", "kernel.cu": "\n\n#include <cmath>\n#include <iostream>\n#include <fstream>\n#include <cstring>\n#include \"benchmark.h\"\n#include \"datatypes.h\"\n\n\n\n#define MAX_EPS 0.001\n\n\n#define THREADS 256\n\nclass points2image : public kernel {\n  private:\n    \n\n    int read_testcases = 0;\n    \n\n    std::ifstream input_file, output_file;\n    \n\n    bool error_so_far = false;\n    \n\n    double max_delta = 0.0;\n  public:\n    \n\n    virtual void init();\n    \n\n    virtual void run(int p = 1);\n    \n\n    virtual bool check_output();\n    \n\n    PointCloud2* pointcloud2 = NULL;\n    \n\n    Mat44* cameraExtrinsicMat = NULL;\n    \n\n    Mat33* cameraMat = NULL;\n    \n\n    Vec5* distCoeff = NULL;\n    \n\n    ImageSize* imageSize = NULL;\n    \n\n    PointsImage* results = NULL;\n  protected:\n    \n\n    virtual int read_next_testcases(int count);\n    \n\n    virtual void check_next_outputs(int count);\n    \n\n    int  read_number_testcases(std::ifstream& input_file);\n};\n\n\n\n\n\n__device__ __managed__ float result_buffer[800*600*4];\n\nint points2image::read_number_testcases(std::ifstream& input_file)\n{\n  \n\n  int number;\n  try {\n    input_file.read((char*)&(number), sizeof(int));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the number of testcases.\");\n  }\n  return number;\n}\n\n\nvoid  parsePointCloud(std::ifstream& input_file, PointCloud2* pointcloud2) {\n  input_file.read((char*)&(pointcloud2->height), sizeof(int));\n  input_file.read((char*)&(pointcloud2->width), sizeof(int));\n  input_file.read((char*)&(pointcloud2->point_step), sizeof(uint));\n#ifdef DEBUG\n  printf(\"PointCloud: height=%d width=%d point_step=%d\\n\",\n          pointcloud2->height , pointcloud2->width , pointcloud2->point_step);\n#endif\n  cudaMallocManaged(&pointcloud2->data, pointcloud2->height * pointcloud2->width * pointcloud2->point_step);\n  input_file.read((char*)pointcloud2->data, pointcloud2->height * pointcloud2->width * pointcloud2->point_step);\n}\n\n\n\nvoid  parseCameraExtrinsicMat(std::ifstream& input_file, Mat44* cameraExtrinsicMat) {\n  try {\n    for (int h = 0; h < 4; h++)\n      for (int w = 0; w < 4; w++)\n        input_file.read((char*)&(cameraExtrinsicMat->data[h][w]),sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next extrinsic matrix.\");    \n  }\n}\n\n\nvoid parseCameraMat(std::ifstream& input_file, Mat33* cameraMat ) {\n  try {\n    for (int h = 0; h < 3; h++)\n      for (int w = 0; w < 3; w++)\n        input_file.read((char*)&(cameraMat->data[h][w]), sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next camera matrix.\");\n  }\n}\n\n\n\nvoid  parseDistCoeff(std::ifstream& input_file, Vec5* distCoeff) {\n  try {\n    for (int w = 0; w < 5; w++)\n      input_file.read((char*)&(distCoeff->data[w]), sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next set of distance coefficients.\");\n  }\n}\n\n\n\nvoid  parseImageSize(std::ifstream& input_file, ImageSize* imageSize) {\n  try {\n    input_file.read((char*)&(imageSize->width), sizeof(int));\n    input_file.read((char*)&(imageSize->height), sizeof(int));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next image size.\");\n  }\n}\n\n\n\nvoid parsePointsImage(std::ifstream& output_file, PointsImage* goldenResult) {\n  try {\n    \n\n    output_file.read((char*)&(goldenResult->image_width), sizeof(int));\n    output_file.read((char*)&(goldenResult->image_height), sizeof(int));\n    output_file.read((char*)&(goldenResult->max_y), sizeof(int));\n    output_file.read((char*)&(goldenResult->min_y), sizeof(int));\n    int pos = 0;\n    int elements = goldenResult->image_height * goldenResult->image_width;\n    goldenResult->intensity = new float[elements];\n    goldenResult->distance = new float[elements];\n    goldenResult->min_height = new float[elements];\n    goldenResult->max_height = new float[elements];\n    \n\n    for (int h = 0; h < goldenResult->image_height; h++)\n      for (int w = 0; w < goldenResult->image_width; w++)\n      {\n        output_file.read((char*)&(goldenResult->intensity[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->distance[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->min_height[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->max_height[pos]), sizeof(float));\n        pos++;\n      }\n  } catch (std::ios_base::failure) {\n    throw std::ios_base::failure(\"Error reading the next reference image.\");\n  }\n}\n\n\n\nint points2image::read_next_testcases(int count)\n{\n  int i;\n  \n\n  \n\n  delete [] pointcloud2;\n  pointcloud2 = new PointCloud2[count];\n  delete [] cameraExtrinsicMat;\n  cameraExtrinsicMat = new Mat44[count];\n  delete [] cameraMat;\n  cameraMat = new Mat33[count];\n  delete [] distCoeff;\n  distCoeff = new Vec5[count];\n  delete [] imageSize;\n  imageSize = new ImageSize[count];\n  delete [] results;\n  results = new PointsImage[count];\n  \n\n  for (i = 0; (i < count) && (read_testcases < testcases); i++,read_testcases++)\n  {\n    try {\n      parsePointCloud(input_file, pointcloud2 + i);\n      parseCameraExtrinsicMat(input_file, cameraExtrinsicMat + i);\n      parseCameraMat(input_file, cameraMat + i);\n      parseDistCoeff(input_file, distCoeff + i);\n      parseImageSize(input_file, imageSize + i);\n    } catch (std::ios_base::failure& e) {\n      std::cerr << e.what() << std::endl;\n      exit(-3);\n    }\n  }\n  return i;\n}\n\nvoid points2image::init() {\n  std::cout << \"Open testcase and reference data streams\\n\";\n  input_file.exceptions ( std::ifstream::failbit | std::ifstream::badbit );\n  output_file.exceptions ( std::ifstream::failbit | std::ifstream::badbit );\n  try {\n    input_file.open(\"../../data/p2i_input.dat\", std::ios::binary);\n  } catch (std::ifstream::failure) {\n    std::cerr << \"Error opening the input data file\" << std::endl;\n    exit(-2);\n  }\n  try {\n    output_file.open(\"../../data/p2i_output.dat\", std::ios::binary);\n  } catch (std::ifstream::failure) {\n    std::cerr << \"Error opening the output data file\" << std::endl;\n    exit(-2);\n  }\n  try {\n    \n\n    testcases = read_number_testcases(input_file);\n    printf(\"the total number of testcases = %d\\n\", testcases);\n  } catch (std::ios_base::failure& e) {\n    std::cerr << e.what() << std::endl;\n    exit(-3);\n  }\n\n  \n\n  error_so_far = false;\n  max_delta = 0.0;\n  pointcloud2 = NULL;\n  cameraExtrinsicMat = NULL;\n  cameraMat = NULL;\n  distCoeff = NULL;\n  imageSize = NULL;\n  results = NULL;\n\n  std::cout << \"Done\\n\" << std::endl;\n}\n\n\n\n__device__ __forceinline__ float atomicFloatMin(float * addr, float value) {\n  return  __int_as_float(atomicMin((int *)addr, __float_as_int(value)));\n}\n\n\n\n__global__ void compute_point_from_pointcloud(\n    const float*  __restrict__ cp, \n          float* volatile msg_distance,\n          float* volatile msg_intensity,\n          float* __restrict__ msg_min_height,\n    int width, int height, int point_step,\n    int w, int h, \n    Mat33 invR,\n    Mat13 invT,\n    Vec5 distCoeff,\n    Mat33 cameraMat,\n    int* __restrict__ min_y,\n    int* __restrict__ max_y) \n{\n\n  \n\n  int y = blockIdx.x;\n  int x = blockIdx.y * THREADS + threadIdx.x;\n  if (x >= width) return;\n\n  const float* fp = (float *)((uintptr_t)cp + (x + y*width) * point_step);\n\n  float intensity = fp[4];\n  \n\n  Mat13 point, point2;\n  point2.data[0] = double(fp[0]);\n  point2.data[1] = double(fp[1]);\n  point2.data[2] = double(fp[2]);\n\n  for (int row = 0; row < 3; row++) {\n    point.data[row] = invT.data[row];\n    for (int col = 0; col < 3; col++) \n      point.data[row] += point2.data[col] * invR.data[row][col];\n  }\n\n  \n\n  if (point.data[2] <= 2.5) return;\n\n  \n\n  double tmpx = point.data[0] / point.data[2];\n  double tmpy = point.data[1] / point.data[2];\n  double r2 = tmpx * tmpx + tmpy * tmpy;\n  double tmpdist = 1.0 + distCoeff.data[0] * r2 + distCoeff.data[1] * r2 * r2\n                   + distCoeff.data[4] * r2 * r2 * r2;\n\n  Point2d imagepoint;\n  imagepoint.x = tmpx * tmpdist + 2.0 * distCoeff.data[2] * tmpx * tmpy\n                 + distCoeff.data[3] * (r2 + 2.0 * tmpx * tmpx);\n  imagepoint.y = tmpy * tmpdist + distCoeff.data[2] * (r2 + 2.0 * tmpy * tmpy)\n                 + 2.0 * distCoeff.data[3] * tmpx * tmpy;\n\n  \n\n  imagepoint.x = cameraMat.data[0][0] * imagepoint.x + cameraMat.data[0][2];\n  imagepoint.y = cameraMat.data[1][1] * imagepoint.y + cameraMat.data[1][2];\n  int px = int(imagepoint.x + 0.5);\n  int py = int(imagepoint.y + 0.5);\n\n  float cm_point;\n  int pid;\n  \n\n  if (0 <= px && px < w && 0 <= py && py < h)\n  {\n    pid = py * w + px;\n    cm_point = point.data[2] * 100.0;  \n\n    atomicCAS((int*)&msg_distance[pid], 0, __float_as_int(cm_point));\n    atomicFloatMin(&msg_distance[pid], cm_point);\n  }\n  \n\n  __syncthreads();\n\n  if (0 <= px && px < w && 0 <= py && py < h)\n  {\n    float newvalue = msg_distance[pid];\n\n    \n\n    if ( newvalue>= cm_point)\n    {\n      msg_intensity[pid] = intensity;\n      atomicMax(max_y, py);\n      atomicMin(min_y, py);\n    }\n    msg_min_height[pid] = -1.25f;\n  }\n}\n\n\n\nPointsImage pointcloud2_to_image(\n    const PointCloud2& pointcloud2,\n    const Mat44& cameraExtrinsicMat,\n    const Mat33& cameraMat, const Vec5& distCoeff,\n    const ImageSize& imageSize)\n{\n  \n\n  int w = imageSize.width;\n  int h = imageSize.height;\n  PointsImage msg;\n  msg.max_y = -1;\n  msg.min_y = h;\n  msg.image_height = imageSize.height;\n  msg.image_width = imageSize.width;\n  msg.intensity = result_buffer;\n  msg.distance = msg.intensity + h*w;\n  msg.min_height = msg.distance + h*w;\n  msg.max_height = msg.min_height + h*w;\n  std::memset(msg.intensity, 0, sizeof(float)*w*h);\n  std::memset(msg.distance, 0, sizeof(float)*w*h);\n  std::memset(msg.min_height, 0, sizeof(float)*w*h);\n  std::memset(msg.max_height, 0, sizeof(float)*w*h);\n\n  \n\n  Mat33 invR;\n  Mat13 invT;\n  \n\n  for (int row = 0; row < 3; row++)\n    for (int col = 0; col < 3; col++)\n      invR.data[row][col] = cameraExtrinsicMat.data[col][row];\n  \n\n  for (int row = 0; row < 3; row++) {\n    invT.data[row] = 0.0;\n    for (int col = 0; col < 3; col++)\n      invT.data[row] -= invR.data[row][col] * cameraExtrinsicMat.data[col][3];\n  }\n  \n\n  int *msg_min_y, *msg_max_y;\n  cudaMalloc((void**)&msg_min_y, sizeof(int));\n  cudaMalloc((void**)&msg_max_y, sizeof(int));\n  cudaMemcpy(msg_min_y, &msg.min_y, sizeof(int), cudaMemcpyHostToDevice);\n  cudaMemcpy(msg_max_y, &msg.max_y, sizeof(int), cudaMemcpyHostToDevice);\n\n  \n\n  dim3 threaddim(THREADS);\n  dim3 blockdim(pointcloud2.height, (pointcloud2.width+THREADS-1)/THREADS);\n\n  compute_point_from_pointcloud<<<blockdim, threaddim>>>(\n    pointcloud2.data,\n    msg.distance,\n    msg.intensity,\n    msg.min_height,\n    pointcloud2.width,\n    pointcloud2.height,\n    pointcloud2.point_step,\n    w, h,\n    invR, invT, distCoeff, cameraMat,\n    msg_min_y, msg_max_y);\n\n  \n\n  cudaMemcpy(&msg.min_y, msg_min_y, sizeof(int), cudaMemcpyDeviceToHost);\n  cudaMemcpy(&msg.max_y, msg_max_y, sizeof(int), cudaMemcpyDeviceToHost);\n  cudaFree(msg_max_y);\n  cudaFree(msg_min_y);\n  cudaFree(pointcloud2.data);\n\n  return msg;\n}\n\nvoid points2image::run(int p) {\n  \n\n  \n\n  pause_func();\n  while (read_testcases < testcases)\n  {\n    int count = read_next_testcases(p);\n    unpause_func();\n    \n\n    for (int i = 0; i < count; i++)\n    {\n      results[i] = pointcloud2_to_image(pointcloud2[i],\n          cameraExtrinsicMat[i],\n          cameraMat[i], distCoeff[i],\n          imageSize[i]);\n    }\n    pause_func();\n    \n\n    check_next_outputs(count);\n  }\n}\n\nvoid points2image::check_next_outputs(int count)\n{\n  PointsImage reference;\n  \n\n  \n\n  for (int i = 0; i < count; i++)\n  {\n    try {\n      parsePointsImage(output_file, &reference);\n    } catch (std::ios_base::failure& e) {\n      std::cerr << e.what() << std::endl;\n      exit(-3);\n    }\n    \n\n    if ((results[i].image_height != reference.image_height)\n        || (results[i].image_width != reference.image_width))\n    {\n      error_so_far = true;\n    }\n    \n\n    if ((results[i].min_y != reference.min_y)\n        || (results[i].max_y != reference.max_y))\n    {\n      error_so_far = true;\n    }\n    \n\n    int pos = 0;\n    for (int h = 0; h < reference.image_height; h++)\n      for (int w = 0; w < reference.image_width; w++)\n      {\n        \n\n        if (std::fabs(reference.intensity[pos] - results[i].intensity[pos]) > max_delta)\n          max_delta = fabs(reference.intensity[pos] - results[i].intensity[pos]);\n        if (std::fabs(reference.distance[pos] - results[i].distance[pos]) > max_delta)\n          max_delta = fabs(reference.distance[pos] - results[i].distance[pos]);\n        if (std::fabs(reference.min_height[pos] - results[i].min_height[pos]) > max_delta)\n          max_delta = fabs(reference.min_height[pos] - results[i].min_height[pos]);\n        if (std::fabs(reference.max_height[pos] - results[i].max_height[pos]) > max_delta)\n          max_delta = fabs(reference.max_height[pos] - results[i].max_height[pos]);\n        pos++;\n      }\n    \n\n    delete [] reference.intensity;\n    delete [] reference.distance;\n    delete [] reference.min_height;\n    delete [] reference.max_height;\n  }\n}\n\nbool points2image::check_output() {\n  std::cout << \"checking output \\n\";\n  input_file.close();\n  output_file.close();\n  std::cout << \"max delta: \" << max_delta << \"\\n\";\n  if ((max_delta > MAX_EPS) || error_so_far) {\n    return false;\n  } else {\n    return true;\n  }\n}\n\n\npoints2image a = points2image();\nkernel& myKernel = a;\n"}}
{"kernel_name": "daphne", "parallel_api": "hip", "code": {"kernel.cu": "\n\n#include <cmath>\n#include <iostream>\n#include <fstream>\n#include <cstring>\n#include <hip/hip_runtime.h>\n#include \"benchmark.h\"\n#include \"datatypes.h\"\n\n\n\n#define MAX_EPS 0.001\n\n\n#define THREADS 256\n\nclass points2image : public kernel {\n  private:\n    \n\n    int read_testcases = 0;\n    \n\n    std::ifstream input_file, output_file;\n    \n\n    bool error_so_far = false;\n    \n\n    double max_delta = 0.0;\n  public:\n    \n\n    virtual void init();\n    \n\n    virtual void run(int p = 1);\n    \n\n    virtual bool check_output();\n    \n\n    PointCloud2* pointcloud2 = NULL;\n    \n\n    Mat44* cameraExtrinsicMat = NULL;\n    \n\n    Mat33* cameraMat = NULL;\n    \n\n    Vec5* distCoeff = NULL;\n    \n\n    ImageSize* imageSize = NULL;\n    \n\n    PointsImage* results = NULL;\n  protected:\n    \n\n    virtual int read_next_testcases(int count);\n    \n\n    virtual void check_next_outputs(int count);\n    \n\n    int  read_number_testcases(std::ifstream& input_file);\n};\n\n\n\n\n\n__device__ __managed__ float result_buffer[800*600*4];\n\nint points2image::read_number_testcases(std::ifstream& input_file)\n{\n  \n\n  int number;\n  try {\n    input_file.read((char*)&(number), sizeof(int));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the number of testcases.\");\n  }\n  return number;\n}\n\n\nvoid  parsePointCloud(std::ifstream& input_file, PointCloud2* pointcloud2) {\n  input_file.read((char*)&(pointcloud2->height), sizeof(int));\n  input_file.read((char*)&(pointcloud2->width), sizeof(int));\n  input_file.read((char*)&(pointcloud2->point_step), sizeof(uint));\n#ifdef DEBUG\n  printf(\"PointCloud: height=%d width=%d point_step=%d\\n\",\n          pointcloud2->height , pointcloud2->width , pointcloud2->point_step);\n#endif\n  hipMallocManaged(&pointcloud2->data, pointcloud2->height * pointcloud2->width * pointcloud2->point_step);\n  input_file.read((char*)pointcloud2->data, pointcloud2->height * pointcloud2->width * pointcloud2->point_step);\n}\n\n\n\nvoid  parseCameraExtrinsicMat(std::ifstream& input_file, Mat44* cameraExtrinsicMat) {\n  try {\n    for (int h = 0; h < 4; h++)\n      for (int w = 0; w < 4; w++)\n        input_file.read((char*)&(cameraExtrinsicMat->data[h][w]),sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next extrinsic matrix.\");    \n  }\n}\n\n\nvoid parseCameraMat(std::ifstream& input_file, Mat33* cameraMat ) {\n  try {\n    for (int h = 0; h < 3; h++)\n      for (int w = 0; w < 3; w++)\n        input_file.read((char*)&(cameraMat->data[h][w]), sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next camera matrix.\");\n  }\n}\n\n\n\nvoid  parseDistCoeff(std::ifstream& input_file, Vec5* distCoeff) {\n  try {\n    for (int w = 0; w < 5; w++)\n      input_file.read((char*)&(distCoeff->data[w]), sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next set of distance coefficients.\");\n  }\n}\n\n\n\nvoid  parseImageSize(std::ifstream& input_file, ImageSize* imageSize) {\n  try {\n    input_file.read((char*)&(imageSize->width), sizeof(int));\n    input_file.read((char*)&(imageSize->height), sizeof(int));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next image size.\");\n  }\n}\n\n\n\nvoid parsePointsImage(std::ifstream& output_file, PointsImage* goldenResult) {\n  try {\n    \n\n    output_file.read((char*)&(goldenResult->image_width), sizeof(int));\n    output_file.read((char*)&(goldenResult->image_height), sizeof(int));\n    output_file.read((char*)&(goldenResult->max_y), sizeof(int));\n    output_file.read((char*)&(goldenResult->min_y), sizeof(int));\n    int pos = 0;\n    int elements = goldenResult->image_height * goldenResult->image_width;\n    goldenResult->intensity = new float[elements];\n    goldenResult->distance = new float[elements];\n    goldenResult->min_height = new float[elements];\n    goldenResult->max_height = new float[elements];\n    \n\n    for (int h = 0; h < goldenResult->image_height; h++)\n      for (int w = 0; w < goldenResult->image_width; w++)\n      {\n        output_file.read((char*)&(goldenResult->intensity[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->distance[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->min_height[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->max_height[pos]), sizeof(float));\n        pos++;\n      }\n  } catch (std::ios_base::failure) {\n    throw std::ios_base::failure(\"Error reading the next reference image.\");\n  }\n}\n\n\n\nint points2image::read_next_testcases(int count)\n{\n  int i;\n  \n\n  \n\n  delete [] pointcloud2;\n  pointcloud2 = new PointCloud2[count];\n  delete [] cameraExtrinsicMat;\n  cameraExtrinsicMat = new Mat44[count];\n  delete [] cameraMat;\n  cameraMat = new Mat33[count];\n  delete [] distCoeff;\n  distCoeff = new Vec5[count];\n  delete [] imageSize;\n  imageSize = new ImageSize[count];\n  delete [] results;\n  results = new PointsImage[count];\n  \n\n  for (i = 0; (i < count) && (read_testcases < testcases); i++,read_testcases++)\n  {\n    try {\n      parsePointCloud(input_file, pointcloud2 + i);\n      parseCameraExtrinsicMat(input_file, cameraExtrinsicMat + i);\n      parseCameraMat(input_file, cameraMat + i);\n      parseDistCoeff(input_file, distCoeff + i);\n      parseImageSize(input_file, imageSize + i);\n    } catch (std::ios_base::failure& e) {\n      std::cerr << e.what() << std::endl;\n      exit(-3);\n    }\n  }\n  return i;\n}\n\n\n\nvoid points2image::init() {\n  std::cout << \"Open testcase and reference data streams\\n\";\n  input_file.exceptions ( std::ifstream::failbit | std::ifstream::badbit );\n  output_file.exceptions ( std::ifstream::failbit | std::ifstream::badbit );\n  try {\n    input_file.open(\"../../../daphne-cuda/data/p2i_input.dat\", std::ios::binary);\n  } catch (std::ifstream::failure) {\n    std::cerr << \"Error opening the input data file\" << std::endl;\n    exit(-2);\n  }\n  try {\n    output_file.open(\"../../../daphne-cuda/data/p2i_output.dat\", std::ios::binary);\n  } catch (std::ifstream::failure) {\n    std::cerr << \"Error opening the output data file\" << std::endl;\n    exit(-2);\n  }\n  try {\n    \n\n    testcases = read_number_testcases(input_file);\n    printf(\"the total number of testcases = %d\\n\", testcases);\n  } catch (std::ios_base::failure& e) {\n    std::cerr << e.what() << std::endl;\n    exit(-3);\n  }\n\n  \n\n  error_so_far = false;\n  max_delta = 0.0;\n  pointcloud2 = NULL;\n  cameraExtrinsicMat = NULL;\n  cameraMat = NULL;\n  distCoeff = NULL;\n  imageSize = NULL;\n  results = NULL;\n\n  std::cout << \"Done\\n\" << std::endl;\n}\n\n\n\n__device__ __forceinline__ float atomicFloatMin(float * addr, float value) {\n  return  __int_as_float(atomicMin((int *)addr, __float_as_int(value)));\n}\n\n\n\n__global__ void compute_point_from_pointcloud(\n    const float*  __restrict__ cp, \n          float* volatile msg_distance,\n          float* volatile msg_intensity,\n          float* __restrict__ msg_min_height,\n    int width, int height, int point_step,\n    int w, int h, \n    Mat33 invR,\n    Mat13 invT,\n    Vec5 distCoeff,\n    Mat33 cameraMat,\n    int* __restrict__ min_y,\n    int* __restrict__ max_y) \n{\n\n  \n\n  int y = blockIdx.x;\n  int x = blockIdx.y * THREADS + threadIdx.x;\n  if (x >= width) return;\n\n  const float* fp = (float *)((uintptr_t)cp + (x + y*width) * point_step);\n\n  float intensity = fp[4];\n  \n\n  Mat13 point, point2;\n  point2.data[0] = double(fp[0]);\n  point2.data[1] = double(fp[1]);\n  point2.data[2] = double(fp[2]);\n\n  for (int row = 0; row < 3; row++) {\n    point.data[row] = invT.data[row];\n    for (int col = 0; col < 3; col++) \n      point.data[row] += point2.data[col] * invR.data[row][col];\n  }\n\n  \n\n  if (point.data[2] <= 2.5) return;\n\n  \n\n  double tmpx = point.data[0] / point.data[2];\n  double tmpy = point.data[1] / point.data[2];\n  double r2 = tmpx * tmpx + tmpy * tmpy;\n  double tmpdist = 1.0 + distCoeff.data[0] * r2 + distCoeff.data[1] * r2 * r2\n                   + distCoeff.data[4] * r2 * r2 * r2;\n\n  Point2d imagepoint;\n  imagepoint.x = tmpx * tmpdist + 2.0 * distCoeff.data[2] * tmpx * tmpy\n                 + distCoeff.data[3] * (r2 + 2.0 * tmpx * tmpx);\n  imagepoint.y = tmpy * tmpdist + distCoeff.data[2] * (r2 + 2.0 * tmpy * tmpy)\n                 + 2.0 * distCoeff.data[3] * tmpx * tmpy;\n\n  \n\n  imagepoint.x = cameraMat.data[0][0] * imagepoint.x + cameraMat.data[0][2];\n  imagepoint.y = cameraMat.data[1][1] * imagepoint.y + cameraMat.data[1][2];\n  int px = int(imagepoint.x + 0.5);\n  int py = int(imagepoint.y + 0.5);\n\n  float cm_point;\n  int pid;\n  \n\n  if (0 <= px && px < w && 0 <= py && py < h)\n  {\n    pid = py * w + px;\n    cm_point = point.data[2] * 100.0;  \n\n    atomicCAS((int*)&msg_distance[pid], 0, __float_as_int(cm_point));\n    atomicFloatMin(&msg_distance[pid], cm_point);\n  }\n  \n\n  __syncthreads();\n\n  if (0 <= px && px < w && 0 <= py && py < h)\n  {\n    float newvalue = msg_distance[pid];\n\n    \n\n    if ( newvalue>= cm_point)\n    {\n      msg_intensity[pid] = intensity;\n      atomicMax(max_y, py);\n      atomicMin(min_y, py);\n    }\n    msg_min_height[pid] = -1.25f;\n  }\n}\n\n\n\nPointsImage pointcloud2_to_image(\n    const PointCloud2& pointcloud2,\n    const Mat44& cameraExtrinsicMat,\n    const Mat33& cameraMat, const Vec5& distCoeff,\n    const ImageSize& imageSize)\n{\n  \n\n  int w = imageSize.width;\n  int h = imageSize.height;\n  PointsImage msg;\n  msg.max_y = -1;\n  msg.min_y = h;\n  msg.image_height = imageSize.height;\n  msg.image_width = imageSize.width;\n  msg.intensity = result_buffer;\n  msg.distance = msg.intensity + h*w;\n  msg.min_height = msg.distance + h*w;\n  msg.max_height = msg.min_height + h*w;\n  std::memset(msg.intensity, 0, sizeof(float)*w*h);\n  std::memset(msg.distance, 0, sizeof(float)*w*h);\n  std::memset(msg.min_height, 0, sizeof(float)*w*h);\n  std::memset(msg.max_height, 0, sizeof(float)*w*h);\n\n  \n\n  Mat33 invR;\n  Mat13 invT;\n  \n\n  for (int row = 0; row < 3; row++)\n    for (int col = 0; col < 3; col++)\n      invR.data[row][col] = cameraExtrinsicMat.data[col][row];\n  \n\n  for (int row = 0; row < 3; row++) {\n    invT.data[row] = 0.0;\n    for (int col = 0; col < 3; col++)\n      invT.data[row] -= invR.data[row][col] * cameraExtrinsicMat.data[col][3];\n  }\n  \n\n  int *msg_min_y, *msg_max_y;\n  hipMalloc((void**)&msg_min_y, sizeof(int));\n  hipMalloc((void**)&msg_max_y, sizeof(int));\n  hipMemcpy(msg_min_y, &msg.min_y, sizeof(int), hipMemcpyHostToDevice);\n  hipMemcpy(msg_max_y, &msg.max_y, sizeof(int), hipMemcpyHostToDevice);\n\n  \n\n  dim3 threaddim(THREADS);\n  dim3 blockdim(pointcloud2.height, (pointcloud2.width+THREADS-1)/THREADS);\n\n  hipLaunchKernelGGL(compute_point_from_pointcloud, blockdim, threaddim, 0, 0, \n    pointcloud2.data,\n    msg.distance,\n    msg.intensity,\n    msg.min_height,\n    pointcloud2.width,\n    pointcloud2.height,\n    pointcloud2.point_step,\n    w, h,\n    invR, invT, distCoeff, cameraMat,\n    msg_min_y, msg_max_y);\n\n  \n\n  hipMemcpy(&msg.min_y, msg_min_y, sizeof(int), hipMemcpyDeviceToHost);\n  hipMemcpy(&msg.max_y, msg_max_y, sizeof(int), hipMemcpyDeviceToHost);\n  hipFree(msg_max_y);\n  hipFree(msg_min_y);\n  hipFree(pointcloud2.data);\n\n  return msg;\n}\n\nvoid points2image::run(int p) {\n  \n\n  \n\n  pause_func();\n  while (read_testcases < testcases)\n  {\n    int count = read_next_testcases(p);\n    unpause_func();\n    \n\n    for (int i = 0; i < count; i++)\n    {\n      results[i] = pointcloud2_to_image(pointcloud2[i],\n          cameraExtrinsicMat[i],\n          cameraMat[i], distCoeff[i],\n          imageSize[i]);\n    }\n    pause_func();\n    \n\n    check_next_outputs(count);\n  }\n}\n\nvoid points2image::check_next_outputs(int count)\n{\n  PointsImage reference;\n  \n\n  \n\n  for (int i = 0; i < count; i++)\n  {\n    try {\n      parsePointsImage(output_file, &reference);\n    } catch (std::ios_base::failure& e) {\n      std::cerr << e.what() << std::endl;\n      exit(-3);\n    }\n    \n\n    if ((results[i].image_height != reference.image_height)\n        || (results[i].image_width != reference.image_width))\n    {\n      error_so_far = true;\n    }\n    \n\n    if ((results[i].min_y != reference.min_y)\n        || (results[i].max_y != reference.max_y))\n    {\n      error_so_far = true;\n    }\n    \n\n    int pos = 0;\n    for (int h = 0; h < reference.image_height; h++)\n      for (int w = 0; w < reference.image_width; w++)\n      {\n        \n\n        if (std::fabs(reference.intensity[pos] - results[i].intensity[pos]) > max_delta)\n          max_delta = fabs(reference.intensity[pos] - results[i].intensity[pos]);\n        if (std::fabs(reference.distance[pos] - results[i].distance[pos]) > max_delta)\n          max_delta = fabs(reference.distance[pos] - results[i].distance[pos]);\n        if (std::fabs(reference.min_height[pos] - results[i].min_height[pos]) > max_delta)\n          max_delta = fabs(reference.min_height[pos] - results[i].min_height[pos]);\n        if (std::fabs(reference.max_height[pos] - results[i].max_height[pos]) > max_delta)\n          max_delta = fabs(reference.max_height[pos] - results[i].max_height[pos]);\n        pos++;\n      }\n    \n\n    delete [] reference.intensity;\n    delete [] reference.distance;\n    delete [] reference.min_height;\n    delete [] reference.max_height;\n  }\n}\n\nbool points2image::check_output() {\n  std::cout << \"checking output \\n\";\n  input_file.close();\n  output_file.close();\n  std::cout << \"max delta: \" << max_delta << \"\\n\";\n  if ((max_delta > MAX_EPS) || error_so_far) {\n    return false;\n  } else {\n    return true;\n  }\n}\n\n\npoints2image a = points2image();\nkernel& myKernel = a;\n"}}
{"kernel_name": "daphne", "parallel_api": "sycl", "code": {"main.cpp": "\n\n#include <chrono>\n#include <iostream>\n#include <string.h>\n#include <stdlib.h>\n#include \"benchmark.h\"\n\nstd::chrono::high_resolution_clock::time_point start,end;\nstd::chrono::duration<double> elapsed;\nstd::chrono::high_resolution_clock timer;\nbool pause = false;\n\n\n\nint pipelined = 1;\n\nextern benchmark& myKernelBenchmark;\n\nvoid pause_timer()\n{\n  end = timer.now();\n  elapsed += (end-start);\n  pause = true;\n}  \n\nvoid unpause_timer() \n{\n  pause = false;\n  start = timer.now();\n}\n\nvoid usage(char *exec)\n{\n  std::cout << \"Usage: \\n\" << exec << \" [-p N]\\nOptions:\\n  -p N   executes N invocations in sequence,\";\n  std::cout << \"before taking time and check the result.\\n\";\n  std::cout << \"         Default: N=1\\n\";\n}\nint main(int argc, char **argv) {\n\n  if ((argc != 1) && (argc !=  3))\n  {\n    usage(argv[0]);\n    exit(2);\n  }\n  if (argc == 3)\n  {\n    if (strcmp(argv[1], \"-p\") != 0)\n    {\n      usage(argv[0]);\n      exit(3);\n    }\n    errno = 0;\n    pipelined = strtol(argv[2], NULL, 10);\n    if (errno || (pipelined < 1) )\n    {\n      usage(argv[0]);\n      exit(4);\n    }\n    std::cout << \"Invoking kernel \" << pipelined << \" time(s) per measure/checking step\\n\";\n  }\n  \n\n  myKernelBenchmark.set_timer_functions(pause_timer, unpause_timer);\n  myKernelBenchmark.init();\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  start = timer.now();\n\n  \n\n  myKernelBenchmark.run(q, pipelined);\n\n  \n\n  if (!pause) \n  {\n    end = timer.now();\n    elapsed += end-start;\n  }\n  std::cout << \"Elapsed time: \"<< elapsed.count() << \" seconds, average time per testcase (#\"\n            << myKernelBenchmark.testcases << \"): \" << elapsed.count() / (double) myKernelBenchmark.testcases\n            << \" seconds\" << std::endl;\n\n  \n\n  if (myKernelBenchmark.check_output())\n    std::cout << \"PASS\\n\";\n  else \n    std::cout << \"FAIL\\n\";\n\n  return 0;\n}\n", "kernel.cpp": "\n\n#include <cmath>\n#include <iostream>\n#include <fstream>\n#include <cstring>\n#include <sycl/sycl.hpp>\n#include \"benchmark.h\"\n#include \"datatypes.h\"\n\n\n\n#define MAX_EPS 0.001\n\n\n#define THREADS 256\n\ntemplate<typename T>\nstatic inline void atomicMin(T& val, const T delta)\n{\n  sycl::atomic_ref<T, sycl::memory_order::relaxed, \n                   sycl::memory_scope::device,\n                   sycl::access::address_space::global_space> ref(val);\n  ref.fetch_min(delta);\n}\n\ntemplate<typename T>\nstatic inline void atomicMax(T& val, const T delta)\n{\n  sycl::atomic_ref<T, sycl::memory_order::relaxed, \n                   sycl::memory_scope::device,\n                   sycl::access::address_space::global_space> ref(val);\n  ref.fetch_max(delta);\n}\n\ntemplate <typename T>\ninline T atomicCAS(T *val, T expected, T desired) \n{\n  T expected_value = expected;\n  auto atm = sycl::atomic_ref<T,\n    sycl::memory_order::relaxed,\n    sycl::memory_scope::device,\n    sycl::access::address_space::global_space>(*val);\n  atm.compare_exchange_strong(expected_value, desired);\n  return expected_value;\n}\n\nclass points2image : public benchmark {\n  private:\n    \n\n    int read_testcases = 0;\n    \n\n    std::ifstream input_file, output_file;\n    \n\n    bool error_so_far = false;\n    \n\n    double max_delta = 0.0;\n  public:\n    \n\n    virtual void init();\n    \n\n    virtual void run(sycl::queue &q, int p = 1);\n    \n\n    virtual bool check_output();\n    \n\n    PointCloud2* pointcloud2 = NULL;\n    \n\n    Mat44* cameraExtrinsicMat = NULL;\n    \n\n    Mat33* cameraMat = NULL;\n    \n\n    Vec5* distCoeff = NULL;\n    \n\n    ImageSize* imageSize = NULL;\n    \n\n    PointsImage* results = NULL;\n  protected:\n    \n\n    virtual int read_next_testcases(sycl::queue &q, int count);\n    \n\n    virtual void check_next_outputs(int count);\n    \n\n    int  read_number_testcases(std::ifstream& input_file);\n};\n\n\n\n\n\nfloat* result_buffer;\n\nint points2image::read_number_testcases(std::ifstream& input_file)\n{\n  \n\n  int number;\n  try {\n    input_file.read((char*)&(number), sizeof(int));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the number of testcases.\");\n  }\n  return number;\n}\n\n\nvoid  parsePointCloud(sycl::queue &q, std::ifstream& input_file, PointCloud2* pointcloud2) {\n  input_file.read((char*)&(pointcloud2->height), sizeof(int));\n  input_file.read((char*)&(pointcloud2->width), sizeof(int));\n  input_file.read((char*)&(pointcloud2->point_step), sizeof(uint));\n#ifdef DEBUG\n  printf(\"PointCloud: height=%d width=%d point_step=%d\\n\",\n          pointcloud2->height , pointcloud2->width , pointcloud2->point_step);\n#endif\n  pointcloud2->data = (float*) sycl::malloc_shared(\n      pointcloud2->height * pointcloud2->width * pointcloud2->point_step, q);\n  input_file.read((char*)pointcloud2->data, pointcloud2->height * pointcloud2->width * pointcloud2->point_step);\n}\n\n\n\nvoid  parseCameraExtrinsicMat(std::ifstream& input_file, Mat44* cameraExtrinsicMat) {\n  try {\n    for (int h = 0; h < 4; h++)\n      for (int w = 0; w < 4; w++)\n        input_file.read((char*)&(cameraExtrinsicMat->data[h][w]),sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next extrinsic matrix.\");    \n  }\n}\n\n\nvoid parseCameraMat(std::ifstream& input_file, Mat33* cameraMat ) {\n  try {\n    for (int h = 0; h < 3; h++)\n      for (int w = 0; w < 3; w++)\n        input_file.read((char*)&(cameraMat->data[h][w]), sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next camera matrix.\");\n  }\n}\n\n\n\nvoid  parseDistCoeff(std::ifstream& input_file, Vec5* distCoeff) {\n  try {\n    for (int w = 0; w < 5; w++)\n      input_file.read((char*)&(distCoeff->data[w]), sizeof(double));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next set of distance coefficients.\");\n  }\n}\n\n\n\nvoid  parseImageSize(std::ifstream& input_file, ImageSize* imageSize) {\n  try {\n    input_file.read((char*)&(imageSize->width), sizeof(int));\n    input_file.read((char*)&(imageSize->height), sizeof(int));\n  } catch (std::ifstream::failure) {\n    throw std::ios_base::failure(\"Error reading the next image size.\");\n  }\n}\n\n\n\nvoid parsePointsImage(std::ifstream& output_file, PointsImage* goldenResult) {\n  try {\n    \n\n    output_file.read((char*)&(goldenResult->image_width), sizeof(int));\n    output_file.read((char*)&(goldenResult->image_height), sizeof(int));\n    output_file.read((char*)&(goldenResult->max_y), sizeof(int));\n    output_file.read((char*)&(goldenResult->min_y), sizeof(int));\n    int pos = 0;\n    int elements = goldenResult->image_height * goldenResult->image_width;\n    goldenResult->intensity = new float[elements];\n    goldenResult->distance = new float[elements];\n    goldenResult->min_height = new float[elements];\n    goldenResult->max_height = new float[elements];\n    \n\n    for (int h = 0; h < goldenResult->image_height; h++)\n      for (int w = 0; w < goldenResult->image_width; w++)\n      {\n        output_file.read((char*)&(goldenResult->intensity[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->distance[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->min_height[pos]), sizeof(float));\n        output_file.read((char*)&(goldenResult->max_height[pos]), sizeof(float));\n        pos++;\n      }\n  } catch (std::ios_base::failure) {\n    throw std::ios_base::failure(\"Error reading the next reference image.\");\n  }\n}\n\n\n\nint points2image::read_next_testcases(sycl::queue &q, int count)\n{\n  int i;\n  \n\n  \n\n  delete [] pointcloud2;\n  pointcloud2 = new PointCloud2[count];\n  delete [] cameraExtrinsicMat;\n  cameraExtrinsicMat = new Mat44[count];\n  delete [] cameraMat;\n  cameraMat = new Mat33[count];\n  delete [] distCoeff;\n  distCoeff = new Vec5[count];\n  delete [] imageSize;\n  imageSize = new ImageSize[count];\n  delete [] results;\n  results = new PointsImage[count];\n  \n\n  for (i = 0; (i < count) && (read_testcases < testcases); i++,read_testcases++)\n  {\n    try {\n      parsePointCloud(q, input_file, pointcloud2 + i);\n      parseCameraExtrinsicMat(input_file, cameraExtrinsicMat + i);\n      parseCameraMat(input_file, cameraMat + i);\n      parseDistCoeff(input_file, distCoeff + i);\n      parseImageSize(input_file, imageSize + i);\n    } catch (std::ios_base::failure& e) {\n      std::cerr << e.what() << std::endl;\n      exit(-3);\n    }\n  }\n  return i;\n}\n\nvoid points2image::init() {\n  std::cout << \"Open testcase and reference data streams\\n\";\n  input_file.exceptions ( std::ifstream::failbit | std::ifstream::badbit );\n  output_file.exceptions ( std::ifstream::failbit | std::ifstream::badbit );\n  try {\n    input_file.open(\"../../../daphne-cuda/data/p2i_input.dat\", std::ios::binary);\n  } catch (std::ifstream::failure) {\n    std::cerr << \"Error opening the input data file\" << std::endl;\n    exit(-2);\n  }\n  try {\n    output_file.open(\"../../../daphne-cuda/data/p2i_output.dat\", std::ios::binary);\n  } catch (std::ifstream::failure) {\n    std::cerr << \"Error opening the output data file\" << std::endl;\n    exit(-2);\n  }\n  try {\n    \n\n    testcases = read_number_testcases(input_file);\n    printf(\"the total number of testcases = %d\\n\", testcases);\n  } catch (std::ios_base::failure& e) {\n    std::cerr << e.what() << std::endl;\n    exit(-3);\n  }\n\n  \n\n  error_so_far = false;\n  max_delta = 0.0;\n  pointcloud2 = NULL;\n  cameraExtrinsicMat = NULL;\n  cameraMat = NULL;\n  distCoeff = NULL;\n  imageSize = NULL;\n  results = NULL;\n\n  std::cout << \"Done\\n\" << std::endl;\n}\n\n\n\nvoid compute_point_from_pointcloud(\n    const float*  __restrict cp, \n          float* volatile msg_distance,\n          float* volatile msg_intensity,\n          float* __restrict msg_min_height,\n    int width, int height, int point_step,\n    int w, int h, \n    Mat33 invR,\n    Mat13 invT,\n    Vec5 distCoeff,\n    Mat33 cameraMat,\n    int* __restrict min_y,\n    int* __restrict max_y,\n    sycl::nd_item<3> &item) \n{\n\n  \n\n  int y = item.get_group(2);\n  int x = item.get_group(1) * THREADS + item.get_local_id(2);\n  if (x >= width) return;\n\n  const float* fp = (float *)((uintptr_t)cp + (x + y*width) * point_step);\n\n  float intensity = fp[4];\n  \n\n  Mat13 point, point2;\n  point2.data[0] = double(fp[0]);\n  point2.data[1] = double(fp[1]);\n  point2.data[2] = double(fp[2]);\n\n  for (int row = 0; row < 3; row++) {\n    point.data[row] = invT.data[row];\n    for (int col = 0; col < 3; col++) \n      point.data[row] += point2.data[col] * invR.data[row][col];\n  }\n\n  \n\n  if (point.data[2] <= 2.5) return;\n\n  \n\n  double tmpx = point.data[0] / point.data[2];\n  double tmpy = point.data[1] / point.data[2];\n  double r2 = tmpx * tmpx + tmpy * tmpy;\n  double tmpdist = 1.0 + distCoeff.data[0] * r2 + distCoeff.data[1] * r2 * r2\n                   + distCoeff.data[4] * r2 * r2 * r2;\n\n  Point2d imagepoint;\n  imagepoint.x = tmpx * tmpdist + 2.0 * distCoeff.data[2] * tmpx * tmpy\n                 + distCoeff.data[3] * (r2 + 2.0 * tmpx * tmpx);\n  imagepoint.y = tmpy * tmpdist + distCoeff.data[2] * (r2 + 2.0 * tmpy * tmpy)\n                 + 2.0 * distCoeff.data[3] * tmpx * tmpy;\n\n  \n\n  imagepoint.x = cameraMat.data[0][0] * imagepoint.x + cameraMat.data[0][2];\n  imagepoint.y = cameraMat.data[1][1] * imagepoint.y + cameraMat.data[1][2];\n  int px = int(imagepoint.x + 0.5);\n  int py = int(imagepoint.y + 0.5);\n\n  float cm_point;\n  int pid;\n  \n\n  if (0 <= px && px < w && 0 <= py && py < h)\n  {\n    pid = py * w + px;\n    cm_point = point.data[2] * 100.0;  \n\n    atomicCAS((int*)&msg_distance[pid], 0, sycl::bit_cast<int>(cm_point));\n\n    \n\n    atomicMin(msg_distance[pid], cm_point);\n  }\n  \n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (0 <= px && px < w && 0 <= py && py < h)\n  {\n    float newvalue = msg_distance[pid];\n\n    \n\n    if ( newvalue>= cm_point)\n    {\n      msg_intensity[pid] = intensity;\n      atomicMax(*max_y, py);\n      atomicMin(*min_y, py);\n    }\n    msg_min_height[pid] = -1.25f;\n  }\n}\n\n\n\nPointsImage pointcloud2_to_image(\n    sycl::queue &q,\n    const PointCloud2& pointcloud2,\n    const Mat44& cameraExtrinsicMat,\n    const Mat33& cameraMat, const Vec5& distCoeff,\n    const ImageSize& imageSize)\n{\n  \n\n  int w = imageSize.width;\n  int h = imageSize.height;\n  PointsImage msg;\n  msg.max_y = -1;\n  msg.min_y = h;\n  msg.image_height = imageSize.height;\n  msg.image_width = imageSize.width;\n  msg.intensity = result_buffer;\n  msg.distance = msg.intensity + h*w;\n  msg.min_height = msg.distance + h*w;\n  msg.max_height = msg.min_height + h*w;\n  std::memset(msg.intensity, 0, sizeof(float)*w*h);\n  std::memset(msg.distance, 0, sizeof(float)*w*h);\n  std::memset(msg.min_height, 0, sizeof(float)*w*h);\n  std::memset(msg.max_height, 0, sizeof(float)*w*h);\n\n  \n\n  Mat33 invR;\n  Mat13 invT;\n  \n\n  for (int row = 0; row < 3; row++)\n    for (int col = 0; col < 3; col++)\n      invR.data[row][col] = cameraExtrinsicMat.data[col][row];\n  \n\n  for (int row = 0; row < 3; row++) {\n    invT.data[row] = 0.0;\n    for (int col = 0; col < 3; col++)\n      invT.data[row] -= invR.data[row][col] * cameraExtrinsicMat.data[col][3];\n  }\n  \n\n  int *msg_min_y, *msg_max_y;\n  msg_min_y = sycl::malloc_device<int>(1, q);\n  msg_max_y = sycl::malloc_device<int>(1, q);\n  q.memcpy(msg_min_y, &msg.min_y, sizeof(int));\n  q.memcpy(msg_max_y, &msg.max_y, sizeof(int)).wait();\n\n  \n\n  sycl::range<3> lws (1, 1, THREADS);\n  sycl::range<3> gws(1, (pointcloud2.width + THREADS - 1) / THREADS,\n                     THREADS * pointcloud2.height);\n\n  q.parallel_for(sycl::nd_range<3>(gws, lws), [=](sycl::nd_item<3> item) {\n    compute_point_from_pointcloud(\n      pointcloud2.data, msg.distance, msg.intensity, msg.min_height,\n      pointcloud2.width, pointcloud2.height, pointcloud2.point_step, w, h,\n      invR, invT, distCoeff, cameraMat, msg_min_y, msg_max_y, item);\n  });\n\n  \n\n  q.memcpy(&msg.min_y, msg_min_y, sizeof(int));\n  q.memcpy(&msg.max_y, msg_max_y, sizeof(int)).wait();\n  sycl::free(msg_max_y, q);\n  sycl::free(msg_min_y, q);\n  sycl::free(pointcloud2.data, q);\n\n  return msg;\n}\n\nvoid points2image::run(sycl::queue &q, int p) {\n  \n\n  \n\n  pause_func();\n  \n  \n\n  result_buffer = sycl::malloc_shared<float>(800*600*4, q);\n\n  while (read_testcases < testcases)\n  {\n    int count = read_next_testcases(q, p);\n    unpause_func();\n    \n\n    for (int i = 0; i < count; i++)\n    {\n      results[i] = pointcloud2_to_image(\n          q,\n          pointcloud2[i],\n          cameraExtrinsicMat[i],\n          cameraMat[i], distCoeff[i],\n          imageSize[i]);\n    }\n    pause_func();\n    \n\n    check_next_outputs(count);\n  }\n\n  sycl::free(result_buffer, q);\n}\n\nvoid points2image::check_next_outputs(int count)\n{\n  PointsImage reference;\n  \n\n  \n\n  for (int i = 0; i < count; i++)\n  {\n    try {\n      parsePointsImage(output_file, &reference);\n    } catch (std::ios_base::failure& e) {\n      std::cerr << e.what() << std::endl;\n      exit(-3);\n    }\n    \n\n    if ((results[i].image_height != reference.image_height)\n        || (results[i].image_width != reference.image_width))\n    {\n      error_so_far = true;\n    }\n    \n\n    if ((results[i].min_y != reference.min_y)\n        || (results[i].max_y != reference.max_y))\n    {\n      error_so_far = true;\n    }\n    \n\n    int pos = 0;\n    for (int h = 0; h < reference.image_height; h++)\n      for (int w = 0; w < reference.image_width; w++)\n      {\n        \n\n        if (std::fabs(reference.intensity[pos] - results[i].intensity[pos]) > max_delta)\n          max_delta = fabs(reference.intensity[pos] - results[i].intensity[pos]);\n        if (std::fabs(reference.distance[pos] - results[i].distance[pos]) > max_delta)\n          max_delta = fabs(reference.distance[pos] - results[i].distance[pos]);\n        if (std::fabs(reference.min_height[pos] - results[i].min_height[pos]) > max_delta)\n          max_delta = fabs(reference.min_height[pos] - results[i].min_height[pos]);\n        if (std::fabs(reference.max_height[pos] - results[i].max_height[pos]) > max_delta)\n          max_delta = fabs(reference.max_height[pos] - results[i].max_height[pos]);\n        pos++;\n      }\n    \n\n    delete [] reference.intensity;\n    delete [] reference.distance;\n    delete [] reference.min_height;\n    delete [] reference.max_height;\n  }\n}\n\nbool points2image::check_output() {\n  std::cout << \"checking output \\n\";\n  input_file.close();\n  output_file.close();\n  std::cout << \"max delta: \" << max_delta << \"\\n\";\n  if ((max_delta > MAX_EPS) || error_so_far) {\n    return false;\n  } else {\n    return true;\n  }\n}\n\n\npoints2image a = points2image();\nbenchmark& myKernelBenchmark = a;\n"}}
{"kernel_name": "gelu", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n#include <cuda_fp16.h>\n#include \"reference.h\"\n\n\n\n\n\n\n__global__ void gelu_bias_loop(__half* src, const __half* bias, int width, int height)\n{\n  int x     = blockIdx.x;  \n\n  int y     = threadIdx.x * 2;\n  int batch = blockIdx.y;\n\n  if (x < height) {\n    int    index = batch * width * height + x * width;\n    half2  v_src;\n    half2  v_bias;\n    half2  v;\n    float2 t;\n    for (; y < width; y = y + blockDim.x * 2) {\n      v_bias = ((half2*)bias)[y >> 1];\n      v_src  = ((half2*)src)[(index + y) >> 1];\n      v      = __hadd2(v_src, v_bias);\n      t      = __half22float2(v);\n      t.x    = (0.5f * t.x * (1.0f + tanhf(0.79788456f * (t.x + 0.044715f * t.x * t.x * t.x))));\n      t.y    = (0.5f * t.y * (1.0f + tanhf(0.79788456f * (t.y + 0.044715f * t.y * t.y * t.y))));\n\n      ((half2*)src)[(index + y) >> 1] = __float22half2_rn(t);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <batch> <sequence length> <hidden dimension> <repeat>\\n\", argv[0]);\n    printf(\"The hidden dimension is a multiple of two\\n\");\n    return 1;\n  }\n\n  const int batch_size = atoi(argv[1]);\n  const int seq_len = atoi(argv[2]);\n  const int hidden_dim = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const size_t src_size = (size_t)batch_size * seq_len * hidden_dim;\n\n  const size_t src_size_bytes =  src_size * sizeof(__half);\n  const int bias_size_bytes = hidden_dim * sizeof(__half);\n\n  srand(123);\n  __half* output = (__half*) malloc (src_size_bytes);\n  __half* output_ref = (__half*) malloc (src_size_bytes);\n  for (size_t i = 0; i < src_size; i++) {\n    output_ref[i] = output[i] = __float2half(rand() / (float)RAND_MAX);\n  }\n\n  __half* bias = (__half*) malloc (bias_size_bytes);\n  for (int i = 0; i < hidden_dim; i++) {\n    bias[i] = __float2half(-6 + (rand() % 12)); \n  }\n\n  __half* d_output;\n  cudaMalloc((void**)&d_output, src_size_bytes);\n  cudaMemcpy(d_output, output, src_size_bytes, cudaMemcpyHostToDevice);\n\n  __half* d_bias;\n  cudaMalloc((void**)&d_bias, bias_size_bytes);\n  cudaMemcpy(d_bias, bias, bias_size_bytes, cudaMemcpyHostToDevice);\n  \n  int block_size;\n  if (hidden_dim >= 4096)\n    block_size = 512;\n  else if (hidden_dim >= 2048)\n    block_size = 256;\n  else\n    block_size = 128;\n \n  dim3 block(block_size, 1);\n  dim3 grid(seq_len, batch_size);\n\n  \n\n  gelu_bias_loop <<<grid, block>>> (d_output, d_bias, hidden_dim, seq_len);\n  gelu_bias_loop_cpu (output_ref, bias, batch_size, hidden_dim, seq_len);\n  cudaMemcpy(output, d_output, src_size_bytes, cudaMemcpyDeviceToHost);\n\n  bool ok = true;\n  for (size_t i = 0; i < src_size; i++) {\n    if (fabsf(__half2float(output_ref[i]) - __half2float(output[i])) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    gelu_bias_loop <<<grid, block>>> (d_output, d_bias, hidden_dim, seq_len);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaFree(d_output);\n  cudaFree(d_bias);\n  free(output);\n  free(output_ref);\n  free(bias);\n\n  return 0;\n}\n"}}
{"kernel_name": "gelu", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include <hip/hip_fp16.h>\n#include \"reference.h\"\n\n\n\n\n\n\n__global__ void gelu_bias_loop(__half* src, const __half* bias, int width, int height)\n{\n  int x     = blockIdx.x;  \n\n  int y     = threadIdx.x * 2;\n  int batch = blockIdx.y;\n\n  if (x < height) {\n    int    index = batch * width * height + x * width;\n    half2  v_src;\n    half2  v_bias;\n    half2  v;\n    float2 t;\n    for (; y < width; y = y + blockDim.x * 2) {\n      v_bias = ((half2*)bias)[y >> 1];\n      v_src  = ((half2*)src)[(index + y) >> 1];\n      v      = __hadd2(v_src, v_bias);\n      t      = __half22float2(v);\n      t.x    = (0.5f * t.x * (1.0f + tanhf(0.79788456f * (t.x + 0.044715f * t.x * t.x * t.x))));\n      t.y    = (0.5f * t.y * (1.0f + tanhf(0.79788456f * (t.y + 0.044715f * t.y * t.y * t.y))));\n\n      ((half2*)src)[(index + y) >> 1] = __float22half2_rn(t);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <batch> <sequence length> <hidden dimension> <repeat>\\n\", argv[0]);\n    printf(\"The hidden dimension is a multiple of two\\n\");\n    return 1;\n  }\n\n  const int batch_size = atoi(argv[1]);\n  const int seq_len = atoi(argv[2]);\n  const int hidden_dim = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const size_t src_size = (size_t)batch_size * seq_len * hidden_dim;\n\n  const size_t src_size_bytes =  src_size * sizeof(__half);\n  const int bias_size_bytes = hidden_dim * sizeof(__half);\n\n  srand(123);\n  __half* output = (__half*) malloc (src_size_bytes);\n  __half* output_ref = (__half*) malloc (src_size_bytes);\n  for (size_t i = 0; i < src_size; i++) {\n    output_ref[i] = output[i] = __float2half(rand() / (float)RAND_MAX);\n  }\n\n  __half* bias = (__half*) malloc (bias_size_bytes);\n  for (int i = 0; i < hidden_dim; i++) {\n    bias[i] = __float2half(-6 + (rand() % 12)); \n  }\n\n  __half* d_output;\n  hipMalloc((void**)&d_output, src_size_bytes);\n  hipMemcpy(d_output, output, src_size_bytes, hipMemcpyHostToDevice);\n\n  __half* d_bias;\n  hipMalloc((void**)&d_bias, bias_size_bytes);\n  hipMemcpy(d_bias, bias, bias_size_bytes, hipMemcpyHostToDevice);\n  \n  int block_size;\n  if (hidden_dim >= 4096)\n    block_size = 512;\n  else if (hidden_dim >= 2048)\n    block_size = 256;\n  else\n    block_size = 128;\n\n  dim3 block(block_size, 1);\n  dim3 grid(seq_len, batch_size);\n\n  \n\n  gelu_bias_loop <<<grid, block>>> (d_output, d_bias, hidden_dim, seq_len);\n  gelu_bias_loop_cpu (output_ref, bias, batch_size, hidden_dim, seq_len);\n  hipMemcpy(output, d_output, src_size_bytes, hipMemcpyDeviceToHost);\n\n  bool ok = true;\n  for (size_t i = 0; i < src_size; i++) {\n    if (fabsf(__half2float(output_ref[i]) - __half2float(output[i])) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    gelu_bias_loop <<<grid, block>>> (d_output, d_bias, hidden_dim, seq_len);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipFree(d_output);\n  hipFree(d_bias);\n  free(output);\n  free(output_ref);\n  free(bias);\n\n  return 0;\n}\n"}}
{"kernel_name": "gelu", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n\n\n\n\n\nvoid gelu_bias_loop(sycl::half *src, const sycl::half *bias, int width,\n                    int height, sycl::nd_item<2> &item)\n{\n  int x = item.get_group(1); \n\n  int y = item.get_local_id(1) * 2;\n  int batch = item.get_group(0);\n\n  if (x < height) {\n    int    index = batch * width * height + x * width;\n    sycl::half2 v_src;\n    sycl::half2 v_bias;\n    sycl::half2 v;\n    sycl::float2 t;\n    for (; y < width; y = y + item.get_local_range(1) * 2) {\n      v_bias = ((sycl::half2 *)bias)[y >> 1];\n      v_src = ((sycl::half2 *)src)[(index + y) >> 1];\n      v = v_src + v_bias;\n      t = v.convert<float, sycl::rounding_mode::automatic>();\n      t.x() = (0.5f * t.x() * (1.0f + sycl::tanh(0.79788456f * (t.x() + 0.044715f * t.x() * t.x() * t.x()))));\n      t.y() = (0.5f * t.y() * (1.0f + sycl::tanh(0.79788456f * (t.y() + 0.044715f * t.y() * t.y() * t.y()))));\n\n      ((sycl::half2 *)src)[(index + y) >> 1] = t.convert<sycl::half, sycl::rounding_mode::rte>();\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <batch> <sequence length> <hidden dimension> <repeat>\\n\", argv[0]);\n    printf(\"The hidden dimension is a multiple of two\\n\");\n    return 1;\n  }\n\n  const int batch_size = atoi(argv[1]);\n  const int seq_len = atoi(argv[2]);\n  const int hidden_dim = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const size_t src_size = (size_t)batch_size * seq_len * hidden_dim;\n\n  const size_t src_size_bytes = src_size * sizeof(sycl::half);\n  const int bias_size_bytes = hidden_dim * sizeof(sycl::half);\n\n  srand(123);\n  sycl::half *output = (sycl::half *)malloc(src_size_bytes);\n  sycl::half *output_ref = (sycl::half *)malloc(src_size_bytes);\n  for (size_t i = 0; i < src_size; i++) {\n    output_ref[i] = output[i] = sycl::vec<float, 1>{rand() / (float)RAND_MAX}\n                    .convert<sycl::half, sycl::rounding_mode::automatic>()[0];\n  }\n\n  sycl::half *bias = (sycl::half *)malloc(bias_size_bytes);\n  for (int i = 0; i < hidden_dim; i++) {\n    bias[i] = sycl::vec<float, 1>{-6 + (rand() % 12)}\n                  .convert<sycl::half, sycl::rounding_mode::automatic>()[0];\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  sycl::half *d_output;\n  d_output = (sycl::half *)sycl::malloc_device(src_size_bytes, q);\n  q.memcpy(d_output, output, src_size_bytes);\n\n  sycl::half *d_bias;\n  d_bias = (sycl::half *)sycl::malloc_device(bias_size_bytes, q);\n  q.memcpy(d_bias, bias, bias_size_bytes);\n\n  int block_size;\n  if (hidden_dim >= 4096)\n    block_size = 512;\n  else if (hidden_dim >= 2048)\n    block_size = 256;\n  else\n    block_size = 128;\n\n  sycl::range<2> lws (1, block_size);\n  sycl::range<2> gws (batch_size, seq_len * block_size);\n\n  \n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for(\n      sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n      gelu_bias_loop(d_output, d_bias, hidden_dim, seq_len, item);\n    });\n  });\n  gelu_bias_loop_cpu (output_ref, bias, batch_size, hidden_dim, seq_len);\n  q.memcpy(output, d_output, src_size_bytes).wait();\n\n  bool ok = true;\n  for (size_t i = 0; i < src_size; i++) {\n    if (fabsf(sycl::vec<sycl::half, 1>{output[i]}.\n              convert<float, sycl::rounding_mode::automatic>()[0] -\n              sycl::vec<sycl::half, 1>{output_ref[i]}.\n              convert<float, sycl::rounding_mode::automatic>()[0]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  q.wait(); \n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        gelu_bias_loop(d_output, d_bias, hidden_dim, seq_len, item);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  sycl::free(d_output, q);\n  sycl::free(d_bias, q);\n  free(output);\n  free(output_ref);\n  free(bias);\n\n  return 0;\n}\n"}}
{"kernel_name": "geodesic", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <iostream>\n#include <cstdlib>\n#include <cstdio>\n#include <chrono>\n#include <cuda.h>\n\nfloat  distance_host ( int i, float latitude_1, float longitude_1,\n                       float latitude_2, float longitude_2 )\n{\n  float  dist ;\n  float  rad_latitude_1 ;\n  float  rad_latitude_2 ;\n  float  rad_longitude_1 ;\n  float  rad_longitude_2 ;\n\n  float  BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n         D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n  const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n  const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n  const float GC_SEMI_MINOR = 6356752.31424518f;\n  const float EPS = 0.5e-5f;\n\n  rad_longitude_1 = longitude_1 * GDC_DEG_TO_RAD ;\n  rad_latitude_1 = latitude_1 * GDC_DEG_TO_RAD ;\n  rad_longitude_2 = longitude_2 * GDC_DEG_TO_RAD ;\n  rad_latitude_2 = latitude_2 * GDC_DEG_TO_RAD ;\n\n  TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n    cosf ( rad_latitude_1 ) ;\n  TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n    cosf ( rad_latitude_2 ) ;\n\n  CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n  SU1 = CU1 * TU1 ;\n  CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n  dist = CU1 * CU2 ;\n  BAZ = dist * TU2 ;\n  FAZ = BAZ * TU1 ;\n  X = rad_longitude_2 - rad_longitude_1 ;\n\n  do {\n    SX = sinf ( X ) ;\n    CX = cosf ( X ) ;\n    TU1 = CU2 * SX ;\n    TU2 = BAZ - SU1 * CU2 * CX ;\n    SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n    CY = dist * CX + FAZ ;\n    Y = atan2f ( SY, CY ) ;\n    SA = dist * SX / SY ;\n    C2A = - SA * SA + 1.0f;\n    CZ = FAZ + FAZ ;\n    if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n    E = CZ * CZ * 2.0f - 1.0f ;\n    C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n      GDC_FLATTENING / 16.0f ;\n    D = X ;\n    X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n    X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n  } while ( fabsf ( D - X ) > EPS );\n\n  X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n  X = ( X - 2.0f ) / X ;\n  C = 1.0f - X ;\n  C = ( X * X / 4.0f + 1.0f ) / C ;\n  D = ( 0.375f * X * X - 1.0f ) * X ;\n  X = E * CY ;\n  dist = 1.0f - E - E ;\n  dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n          X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GC_SEMI_MINOR ;\n  return dist;\n}\n\n__global__ void \nkernel_distance (const float4 *__restrict__ d_A,\n                        float *__restrict__ d_C,\n                 const int N)\n{\n  const int wiID = blockIdx.x * blockDim.x + threadIdx.x;\n  if (wiID >= N) return;\n\n  const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n  const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n  const float GC_SEMI_MINOR = 6356752.31424518f;\n  const float EPS                    = 0.5e-5f;\n  float  dist, BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n         D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n  const float rad_latitude_1  = d_A[wiID].x * GDC_DEG_TO_RAD ;\n  const float rad_longitude_1 = d_A[wiID].y * GDC_DEG_TO_RAD ;\n  const float rad_latitude_2  = d_A[wiID].z * GDC_DEG_TO_RAD ;\n  const float rad_longitude_2 = d_A[wiID].w * GDC_DEG_TO_RAD ;\n\n  TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n    cosf ( rad_latitude_1 ) ;\n  TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n    cosf ( rad_latitude_2 ) ;\n\n  CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n  SU1 = CU1 * TU1 ;\n  CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n  dist = CU1 * CU2 ;\n  BAZ = dist * TU2 ;\n  FAZ = BAZ * TU1 ;\n  X = rad_longitude_2 - rad_longitude_1 ;\n\n  do {\n    SX = sinf ( X ) ;\n    CX = cosf ( X ) ;\n    TU1 = CU2 * SX ;\n    TU2 = BAZ - SU1 * CU2 * CX ;\n    SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n    CY = dist * CX + FAZ ;\n    Y = atan2f ( SY, CY ) ;\n    SA = dist * SX / SY ;\n    C2A = - SA * SA + 1.0f;\n    CZ = FAZ + FAZ ;\n    if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n    E = CZ * CZ * 2.0f - 1.0f ;\n    C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n      GDC_FLATTENING / 16.0f ;\n    D = X ;\n    X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n    X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n  } while ( fabsf ( D - X ) > EPS ) ;\n\n  X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n  X = ( X - 2.0f ) / X ;\n  C = 1.0f - X ;\n  C = ( X * X / 4.0f + 1.0f ) / C ;\n  D = ( 0.375f * X * X - 1.0f ) * X ;\n  X = E * CY ;\n  dist = 1.0f - E - E ;\n  dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n          X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GC_SEMI_MINOR ;\n  d_C[wiID] = dist;\n}\n\nvoid distance_device(const float4* VA, float* VC, const size_t N, const int iteration) {\n\n  dim3 grids ((N+255)/256);\n  dim3 threads (256);\n\n  float4 *d_VA;\n  float *d_VC;\n  cudaMalloc((void**)&d_VA, sizeof(float4)*N);\n  cudaMemcpy(d_VA, VA, sizeof(float4)*N, cudaMemcpyHostToDevice);\n  cudaMalloc((void**)&d_VC, sizeof(float)*N);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < iteration; n++) {\n    kernel_distance<<<grids, threads>>>(d_VA, d_VC, N);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / iteration);\n\n  cudaMemcpy(VC, d_VC, sizeof(float)*N, cudaMemcpyDeviceToHost);\n  cudaFree(d_VA);\n  cudaFree(d_VC);\n}\n\nvoid verify(int size, const float *output, const float *expected_output) {\n  float error_rate = 0;\n  for (int i = 0; i < size; i++) {\n    if (fabs(output[i] - expected_output[i]) > error_rate) {\n      error_rate = fabs(output[i] - expected_output[i]);\n    }\n  }\n  printf(\"The maximum error in distance for single precision is %f\\n\", error_rate); \n}\n\nint main(int argc, char** argv) {\n  if (argc != 2) {\n    printf(\"Usage %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int iteration = atoi(argv[1]);\n\n  int num_cities = 2097152; \n\n  int num_ref_cities = 6; \n\n  int index_map[] ={436483, 1952407, 627919, 377884, 442703, 1863423};\n  int N = num_cities * num_ref_cities;\n  int city = 0;\n  float lat, lon;\n\n  const char* filename = \"locations.txt\";\n  printf(\"Reading city locations from file %s...\\n\", filename);\n  FILE* fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    perror (\"Error opening the file\");\n    exit(-1);\n  }\n\n  float4* input  = (float4*) aligned_alloc(4096, N*sizeof(float4));\n  float*  output = (float*) aligned_alloc(4096, N*sizeof(float));\n  float*  expected_output = (float*) malloc(N*sizeof(float));\n\n  while (fscanf(fp, \"%f %f\\n\", &lat, &lon) != EOF) { \n    input[city].x = lat;\n    input[city].y = lon;\n    city++;\n    if (city == num_cities) break;  \n  }\n  fclose(fp);\n\n  \n\n  for (int c = 1;  c < num_ref_cities; c++) {\n    std::copy(input, input+num_cities, input+c*num_cities);\n  }\n  \n\n  for (int c = 0;  c < num_ref_cities; c++) {\n    int index = index_map[c] - 1;\n    for(int j = c*num_cities; j < (c+1)*num_cities; ++j) {\n      input[j].z = input[index].x;\n      input[j].w = input[index].y;\n    }\n  }\n\n  \n\n  for (int i = 0; i < N; i++)\n  {\n    float lat1 = input[i].x;\n    float lon1 = input[i].y;\n    float lat2 = input[i].z;\n    float lon2 = input[i].w;\n    expected_output[i] = distance_host(i, lat1, lon1, lat2, lon2);\n  }\n\n  distance_device(input, output, N, iteration);\n\n  verify(N, output, expected_output);\n\n  free(input);\n  free(output);\n  free(expected_output);\n  return 0;\n}\n"}}
{"kernel_name": "geodesic", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <iostream>\n#include <cstdlib>\n#include <cstdio>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\nfloat  distance_host ( int i, float latitude_1, float longitude_1,\n                       float latitude_2, float longitude_2 )\n{\n  float  dist ;\n  float  rad_latitude_1 ;\n  float  rad_latitude_2 ;\n  float  rad_longitude_1 ;\n  float  rad_longitude_2 ;\n\n  float  BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n         D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n  const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n  const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n  const float GC_SEMI_MINOR = 6356752.31424518f;\n  const float EPS = 0.5e-5f;\n\n  rad_longitude_1 = longitude_1 * GDC_DEG_TO_RAD ;\n  rad_latitude_1 = latitude_1 * GDC_DEG_TO_RAD ;\n  rad_longitude_2 = longitude_2 * GDC_DEG_TO_RAD ;\n  rad_latitude_2 = latitude_2 * GDC_DEG_TO_RAD ;\n\n  TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n    cosf ( rad_latitude_1 ) ;\n  TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n    cosf ( rad_latitude_2 ) ;\n\n  CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n  SU1 = CU1 * TU1 ;\n  CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n  dist = CU1 * CU2 ;\n  BAZ = dist * TU2 ;\n  FAZ = BAZ * TU1 ;\n  X = rad_longitude_2 - rad_longitude_1 ;\n\n  do {\n    SX = sinf ( X ) ;\n    CX = cosf ( X ) ;\n    TU1 = CU2 * SX ;\n    TU2 = BAZ - SU1 * CU2 * CX ;\n    SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n    CY = dist * CX + FAZ ;\n    Y = atan2f ( SY, CY ) ;\n    SA = dist * SX / SY ;\n    C2A = - SA * SA + 1.0f;\n    CZ = FAZ + FAZ ;\n    if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n    E = CZ * CZ * 2.0f - 1.0f ;\n    C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n      GDC_FLATTENING / 16.0f ;\n    D = X ;\n    X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n    X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n  } while ( fabsf ( D - X ) > EPS );\n\n  X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n  X = ( X - 2.0f ) / X ;\n  C = 1.0f - X ;\n  C = ( X * X / 4.0f + 1.0f ) / C ;\n  D = ( 0.375f * X * X - 1.0f ) * X ;\n  X = E * CY ;\n  dist = 1.0f - E - E ;\n  dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n          X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GC_SEMI_MINOR ;\n  return dist;\n}\n\n__global__ void \nkernel_distance (const float4 *__restrict__ d_A,\n                        float *__restrict__ d_C,\n                 const int N)\n{\n  const int wiID = blockIdx.x * blockDim.x + threadIdx.x;\n  if (wiID >= N) return;\n\n  const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n  const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ELLIPSOIDAL = 1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n  const float GC_SEMI_MINOR = 6356752.31424518f;\n  const float EPS = 0.5e-5f;\n  float  dist, BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n         D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n  const float4 rad4 = d_A[wiID] * make_float4(GDC_DEG_TO_RAD, GDC_DEG_TO_RAD, \n                                              GDC_DEG_TO_RAD, GDC_DEG_TO_RAD);\n  const float rad_latitude_1  = rad4.x;\n  const float rad_longitude_1 = rad4.y;\n  const float rad_latitude_2  = rad4.z;\n  const float rad_longitude_2 = rad4.w;\n\n  TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n    cosf ( rad_latitude_1 ) ;\n  TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n    cosf ( rad_latitude_2 ) ;\n\n  CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n  SU1 = CU1 * TU1 ;\n  CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n  dist = CU1 * CU2 ;\n  BAZ = dist * TU2 ;\n  FAZ = BAZ * TU1 ;\n  X = rad_longitude_2 - rad_longitude_1 ;\n\n  do {\n    SX = sinf ( X ) ;\n    CX = cosf ( X ) ;\n    TU1 = CU2 * SX ;\n    TU2 = BAZ - SU1 * CU2 * CX ;\n    SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n    CY = dist * CX + FAZ ;\n    Y = atan2f ( SY, CY ) ;\n    SA = dist * SX / SY ;\n    C2A = - SA * SA + 1.0f;\n    CZ = FAZ + FAZ ;\n    if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n    E = CZ * CZ * 2.0f - 1.0f ;\n    C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n      GDC_FLATTENING / 16.0f ;\n    D = X ;\n    X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n    X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n  } while ( fabsf ( D - X ) > EPS ) ;\n\n  X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n  X = ( X - 2.0f ) / X ;\n  C = 1.0f - X ;\n  C = ( X * X / 4.0f + 1.0f ) / C ;\n  D = ( 0.375f * X * X - 1.0f ) * X ;\n  X = E * CY ;\n  dist = 1.0f - E - E ;\n  dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n          X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GC_SEMI_MINOR ;\n  d_C[wiID] = dist;\n}\n\nvoid distance_device(const float4* VA, float* VC, const size_t N, const int iteration) {\n\n  dim3 grids ((N+255)/256);\n  dim3 threads (256);\n\n  float4 *d_VA;\n  float *d_VC;\n  hipMalloc((void**)&d_VA, sizeof(float4)*N);\n  hipMemcpy(d_VA, VA, sizeof(float4)*N, hipMemcpyHostToDevice);\n  hipMalloc((void**)&d_VC, sizeof(float)*N);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < iteration; n++) {\n    hipLaunchKernelGGL(kernel_distance, grids, threads, 0, 0, d_VA, d_VC, N);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / iteration);\n\n  hipMemcpy(VC, d_VC, sizeof(float)*N, hipMemcpyDeviceToHost);\n  hipFree(d_VA);\n  hipFree(d_VC);\n}\n\nvoid verify(int size, const float *output, const float *expected_output) {\n  float error_rate = 0;\n  for (int i = 0; i < size; i++) {\n    if (fabs(output[i] - expected_output[i]) > error_rate) {\n      error_rate = fabs(output[i] - expected_output[i]);\n    }\n  }\n  printf(\"The maximum error in distance for single precision is %f\\n\", error_rate); \n}\n\nint main(int argc, char** argv) {\n  if (argc != 2) {\n    printf(\"Usage %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int iteration = atoi(argv[1]);\n\n  int num_cities = 2097152; \n\n  int num_ref_cities = 6; \n\n  int index_map[] ={436483, 1952407, 627919, 377884, 442703, 1863423};\n  int N = num_cities * num_ref_cities;\n  int city = 0;\n  float lat, lon;\n\n  const char* filename = \"locations.txt\";\n  printf(\"Reading city locations from file %s...\\n\", filename);\n  FILE* fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    perror (\"Error opening the file\");\n    exit(-1);\n  }\n\n  float4* input  = (float4*) aligned_alloc(4096, N*sizeof(float4));\n  float*  output = (float*) aligned_alloc(4096, N*sizeof(float));\n  float*  expected_output = (float*) malloc(N*sizeof(float));\n\n  while (fscanf(fp, \"%f %f\\n\", &lat, &lon) != EOF) { \n    input[city].x = lat;\n    input[city].y = lon;\n    city++;\n    if (city == num_cities) break;  \n  }\n  fclose(fp);\n\n  \n\n  for (int c = 1;  c < num_ref_cities; c++) {\n    std::copy(input, input+num_cities, input+c*num_cities);\n  }\n  \n\n  for (int c = 0;  c < num_ref_cities; c++) {\n    int index = index_map[c] - 1;\n    for(int j = c*num_cities; j < (c+1)*num_cities; ++j) {\n      input[j].z = input[index].x;\n      input[j].w = input[index].y;\n    }\n  }\n\n  \n\n  for (int i = 0; i < N; i++)\n  {\n    float lat1 = input[i].x;\n    float lon1 = input[i].y;\n    float lat2 = input[i].z;\n    float lon2 = input[i].w;\n    expected_output[i] = distance_host(i, lat1, lon1, lat2, lon2);\n  }\n\n  distance_device(input, output, N, iteration);\n\n  verify(N, output, expected_output);\n\n  free(input);\n  free(output);\n  free(expected_output);\n  return 0;\n}\n"}}
{"kernel_name": "geodesic", "parallel_api": "omp", "code": {"main.cpp": "#include <iostream>\n#include <cstdlib>\n#include <cstdio>\n#include <chrono>\n#include <cmath>\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x;\n  float y;\n  float z;\n  float w;\n} float4;\n\nfloat  distance_host ( int i, float latitude_1, float longitude_1,\n                       float latitude_2, float longitude_2 )\n{\n  float  dist ;\n  float  rad_latitude_1 ;\n  float  rad_latitude_2 ;\n  float  rad_longitude_1 ;\n  float  rad_longitude_2 ;\n\n  float  BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n         D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n  const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n  const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n  const float GDC_SEMI_MINOR = 6356752.31424518f;\n  const float EPS = 0.5e-5f;\n\n  rad_longitude_1 = longitude_1 * GDC_DEG_TO_RAD ;\n  rad_latitude_1 = latitude_1 * GDC_DEG_TO_RAD ;\n  rad_longitude_2 = longitude_2 * GDC_DEG_TO_RAD ;\n  rad_latitude_2 = latitude_2 * GDC_DEG_TO_RAD ;\n\n  TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n    cosf ( rad_latitude_1 ) ;\n  TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n    cosf ( rad_latitude_2 ) ;\n\n  CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n  SU1 = CU1 * TU1 ;\n  CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n  dist = CU1 * CU2 ;\n  BAZ = dist * TU2 ;\n  FAZ = BAZ * TU1 ;\n  X = rad_longitude_2 - rad_longitude_1 ;\n\n  do {\n    SX = sinf ( X ) ;\n    CX = cosf ( X ) ;\n    TU1 = CU2 * SX ;\n    TU2 = BAZ - SU1 * CU2 * CX ;\n    SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n    CY = dist * CX + FAZ ;\n    Y = atan2f ( SY, CY ) ;\n    SA = dist * SX / SY ;\n    C2A = - SA * SA + 1.0f;\n    CZ = FAZ + FAZ ;\n    if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n    E = CZ * CZ * 2.0f - 1.0f ;\n    C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n      GDC_FLATTENING / 16.0f ;\n    D = X ;\n    X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n    X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n  } while ( fabsf ( D - X ) > EPS );\n\n  X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n  X = ( X - 2.0f ) / X ;\n  C = 1.0f - X ;\n  C = ( X * X / 4.0f + 1.0f ) / C ;\n  D = ( 0.375f * X * X - 1.0f ) * X ;\n  X = E * CY ;\n  dist = 1.0f - E - E ;\n  dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n          X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GDC_SEMI_MINOR ;\n  return dist;\n}\n\nvoid distance_device(const float4* VA, float* VC, const size_t N, const int iteration) {\n\n  #pragma omp target data map(to: VA[0:N]) map(from: VC[0:N])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < iteration; n++) {\n\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (int wiID = 0; wiID < N; wiID++) {\n\n        const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n        const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n        const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n        const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n        const float GDC_SEMI_MINOR = 6356752.31424518f;\n        const float EPS = 0.5e-5f;\n        float  dist, BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n               D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n        const float rad_latitude_1  = VA[wiID].x * GDC_DEG_TO_RAD ;\n        const float rad_longitude_1 = VA[wiID].y * GDC_DEG_TO_RAD ;\n        const float rad_latitude_2  = VA[wiID].z * GDC_DEG_TO_RAD ;\n        const float rad_longitude_2 = VA[wiID].w * GDC_DEG_TO_RAD ;\n\n        TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n          cosf ( rad_latitude_1 ) ;\n        TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n          cosf ( rad_latitude_2 ) ;\n\n        CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n        SU1 = CU1 * TU1 ;\n        CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n        dist = CU1 * CU2 ;\n        BAZ = dist * TU2 ;\n        FAZ = BAZ * TU1 ;\n        X = rad_longitude_2 - rad_longitude_1 ;\n\n        do {\n          SX = sinf ( X ) ;\n          CX = cosf ( X ) ;\n          TU1 = CU2 * SX ;\n          TU2 = BAZ - SU1 * CU2 * CX ;\n          SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n          CY = dist * CX + FAZ ;\n          Y = atan2f ( SY, CY ) ;\n          SA = dist * SX / SY ;\n          C2A = - SA * SA + 1.0f;\n          CZ = FAZ + FAZ ;\n          if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n          E = CZ * CZ * 2.0f - 1.0f ;\n          C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n            GDC_FLATTENING / 16.0f ;\n          D = X ;\n          X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n          X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n        } while ( fabsf ( D - X ) > EPS ) ;\n\n        X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n        X = ( X - 2.0f ) / X ;\n        C = 1.0f - X ;\n        C = ( X * X / 4.0f + 1.0f ) / C ;\n        D = ( 0.375f * X * X - 1.0f ) * X ;\n        X = E * CY ;\n        dist = 1.0f - E - E ;\n        dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n                X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GDC_SEMI_MINOR ;\n        VC[wiID] = dist;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / iteration);\n  }\n}\n\nvoid verify(int size, const float *output, const float *expected_output) {\n  float error_rate = 0;\n  for (int i = 0; i < size; i++) {\n    if (fabs(output[i] - expected_output[i]) > error_rate) {\n      error_rate = fabs(output[i] - expected_output[i]);\n    }\n  }\n  printf(\"The maximum error in distance for single precision is %f\\n\", error_rate); \n}\n\nint main(int argc, char** argv) {\n  if (argc != 2) {\n    printf(\"Usage %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int iteration = atoi(argv[1]);\n\n  int num_cities = 2097152; \n\n  int num_ref_cities = 6; \n\n  int index_map[] ={436483, 1952407, 627919, 377884, 442703, 1863423};\n  int N = num_cities * num_ref_cities;\n  int city = 0;\n  float lat, lon;\n\n  const char* filename = \"locations.txt\";\n  printf(\"Reading city locations from file %s...\\n\", filename);\n  FILE* fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    perror (\"Error opening the file\");\n    exit(-1);\n  }\n\n  float4* input  = (float4*) aligned_alloc(4096, N*sizeof(float4));\n  float*  output = (float*) aligned_alloc(4096, N*sizeof(float));\n  float*  expected_output = (float*) malloc(N*sizeof(float));\n\n  while (fscanf(fp, \"%f %f\\n\", &lat, &lon) != EOF) { \n    input[city].x = lat;\n    input[city].y = lon;\n    city++;\n    if (city == num_cities) break;  \n  }\n  fclose(fp);\n\n  \n\n  for (int c = 1;  c < num_ref_cities; c++) {\n    std::copy(input, input+num_cities, input+c*num_cities);\n  }\n  \n\n  for (int c = 0;  c < num_ref_cities; c++) {\n    int index = index_map[c] - 1;\n    for(int j = c*num_cities; j < (c+1)*num_cities; ++j) {\n      input[j].z = input[index].x;\n      input[j].w = input[index].y;\n    }\n  }\n\n  \n\n  for (int i = 0; i < N; i++)\n  {\n    float lat1 = input[i].x;\n    float lon1 = input[i].y;\n    float lat2 = input[i].z;\n    float lon2 = input[i].w;\n    expected_output[i] = distance_host(i, lat1, lon1, lat2, lon2);\n  }\n\n  distance_device(input, output, N, iteration);\n\n  verify(N, output, expected_output);\n\n  free(input);\n  free(output);\n  free(expected_output);\n  return 0;\n}\n"}}
{"kernel_name": "geodesic", "parallel_api": "serial", "code": {"main.cpp": "#include <iostream>\n#include <cstdlib>\n#include <cstdio>\n#include <chrono>\n#include <cmath>\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x;\n  float y;\n  float z;\n  float w;\n} float4;\n\nfloat  distance_host ( int i, float latitude_1, float longitude_1,\n                       float latitude_2, float longitude_2 )\n{\n  float  dist ;\n  float  rad_latitude_1 ;\n  float  rad_latitude_2 ;\n  float  rad_longitude_1 ;\n  float  rad_longitude_2 ;\n\n  float  BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n         D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n  const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n  const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n  const float GDC_SEMI_MINOR = 6356752.31424518f;\n  const float EPS = 0.5e-5f;\n\n  rad_longitude_1 = longitude_1 * GDC_DEG_TO_RAD ;\n  rad_latitude_1 = latitude_1 * GDC_DEG_TO_RAD ;\n  rad_longitude_2 = longitude_2 * GDC_DEG_TO_RAD ;\n  rad_latitude_2 = latitude_2 * GDC_DEG_TO_RAD ;\n\n  TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n    cosf ( rad_latitude_1 ) ;\n  TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n    cosf ( rad_latitude_2 ) ;\n\n  CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n  SU1 = CU1 * TU1 ;\n  CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n  dist = CU1 * CU2 ;\n  BAZ = dist * TU2 ;\n  FAZ = BAZ * TU1 ;\n  X = rad_longitude_2 - rad_longitude_1 ;\n\n  do {\n    SX = sinf ( X ) ;\n    CX = cosf ( X ) ;\n    TU1 = CU2 * SX ;\n    TU2 = BAZ - SU1 * CU2 * CX ;\n    SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n    CY = dist * CX + FAZ ;\n    Y = atan2f ( SY, CY ) ;\n    SA = dist * SX / SY ;\n    C2A = - SA * SA + 1.0f;\n    CZ = FAZ + FAZ ;\n    if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n    E = CZ * CZ * 2.0f - 1.0f ;\n    C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n      GDC_FLATTENING / 16.0f ;\n    D = X ;\n    X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n    X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n  } while ( fabsf ( D - X ) > EPS );\n\n  X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n  X = ( X - 2.0f ) / X ;\n  C = 1.0f - X ;\n  C = ( X * X / 4.0f + 1.0f ) / C ;\n  D = ( 0.375f * X * X - 1.0f ) * X ;\n  X = E * CY ;\n  dist = 1.0f - E - E ;\n  dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n          X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GDC_SEMI_MINOR ;\n  return dist;\n}\n\nvoid distance_device(const float4* VA, float* VC, const size_t N, const int iteration) {\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < iteration; n++) {\n\n            for (int wiID = 0; wiID < N; wiID++) {\n\n        const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n        const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n        const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n        const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n        const float GDC_SEMI_MINOR = 6356752.31424518f;\n        const float EPS = 0.5e-5f;\n        float  dist, BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n               D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n        const float rad_latitude_1  = VA[wiID].x * GDC_DEG_TO_RAD ;\n        const float rad_longitude_1 = VA[wiID].y * GDC_DEG_TO_RAD ;\n        const float rad_latitude_2  = VA[wiID].z * GDC_DEG_TO_RAD ;\n        const float rad_longitude_2 = VA[wiID].w * GDC_DEG_TO_RAD ;\n\n        TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n          cosf ( rad_latitude_1 ) ;\n        TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n          cosf ( rad_latitude_2 ) ;\n\n        CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n        SU1 = CU1 * TU1 ;\n        CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n        dist = CU1 * CU2 ;\n        BAZ = dist * TU2 ;\n        FAZ = BAZ * TU1 ;\n        X = rad_longitude_2 - rad_longitude_1 ;\n\n        do {\n          SX = sinf ( X ) ;\n          CX = cosf ( X ) ;\n          TU1 = CU2 * SX ;\n          TU2 = BAZ - SU1 * CU2 * CX ;\n          SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n          CY = dist * CX + FAZ ;\n          Y = atan2f ( SY, CY ) ;\n          SA = dist * SX / SY ;\n          C2A = - SA * SA + 1.0f;\n          CZ = FAZ + FAZ ;\n          if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n          E = CZ * CZ * 2.0f - 1.0f ;\n          C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n            GDC_FLATTENING / 16.0f ;\n          D = X ;\n          X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n          X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n        } while ( fabsf ( D - X ) > EPS ) ;\n\n        X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n        X = ( X - 2.0f ) / X ;\n        C = 1.0f - X ;\n        C = ( X * X / 4.0f + 1.0f ) / C ;\n        D = ( 0.375f * X * X - 1.0f ) * X ;\n        X = E * CY ;\n        dist = 1.0f - E - E ;\n        dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n                X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GDC_SEMI_MINOR ;\n        VC[wiID] = dist;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / iteration);\n  }\n}\n\nvoid verify(int size, const float *output, const float *expected_output) {\n  float error_rate = 0;\n  for (int i = 0; i < size; i++) {\n    if (fabs(output[i] - expected_output[i]) > error_rate) {\n      error_rate = fabs(output[i] - expected_output[i]);\n    }\n  }\n  printf(\"The maximum error in distance for single precision is %f\\n\", error_rate); \n}\n\nint main(int argc, char** argv) {\n  if (argc != 2) {\n    printf(\"Usage %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int iteration = atoi(argv[1]);\n\n  int num_cities = 2097152; \n\n  int num_ref_cities = 6; \n\n  int index_map[] ={436483, 1952407, 627919, 377884, 442703, 1863423};\n  int N = num_cities * num_ref_cities;\n  int city = 0;\n  float lat, lon;\n\n  const char* filename = \"locations.txt\";\n  printf(\"Reading city locations from file %s...\\n\", filename);\n  FILE* fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    perror (\"Error opening the file\");\n    exit(-1);\n  }\n\n  float4* input  = (float4*) aligned_alloc(4096, N*sizeof(float4));\n  float*  output = (float*) aligned_alloc(4096, N*sizeof(float));\n  float*  expected_output = (float*) malloc(N*sizeof(float));\n\n  while (fscanf(fp, \"%f %f\\n\", &lat, &lon) != EOF) { \n    input[city].x = lat;\n    input[city].y = lon;\n    city++;\n    if (city == num_cities) break;  \n  }\n  fclose(fp);\n\n  \n\n  for (int c = 1;  c < num_ref_cities; c++) {\n    std::copy(input, input+num_cities, input+c*num_cities);\n  }\n  \n\n  for (int c = 0;  c < num_ref_cities; c++) {\n    int index = index_map[c] - 1;\n    for(int j = c*num_cities; j < (c+1)*num_cities; ++j) {\n      input[j].z = input[index].x;\n      input[j].w = input[index].y;\n    }\n  }\n\n  \n\n  for (int i = 0; i < N; i++)\n  {\n    float lat1 = input[i].x;\n    float lon1 = input[i].y;\n    float lat2 = input[i].z;\n    float lon2 = input[i].w;\n    expected_output[i] = distance_host(i, lat1, lon1, lat2, lon2);\n  }\n\n  distance_device(input, output, N, iteration);\n\n  verify(N, output, expected_output);\n\n  free(input);\n  free(output);\n  free(expected_output);\n  return 0;\n}"}}
{"kernel_name": "geodesic", "parallel_api": "sycl", "code": {"main.cpp": "#include <iostream>\n#include <cstdlib>\n#include <cstdio>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nfloat  distance_host ( int i, float latitude_1, float longitude_1,\n                       float latitude_2, float longitude_2 )\n{\n  float  dist ;\n  float  rad_latitude_1 ;\n  float  rad_latitude_2 ;\n  float  rad_longitude_1 ;\n  float  rad_longitude_2 ;\n\n  float  BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n         D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n  const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n  const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n  const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n  const float GC_SEMI_MINOR = 6356752.31424518f;\n  const float EPS = 0.5e-5f;\n\n  rad_longitude_1 = longitude_1 * GDC_DEG_TO_RAD ;\n  rad_latitude_1 = latitude_1 * GDC_DEG_TO_RAD ;\n  rad_longitude_2 = longitude_2 * GDC_DEG_TO_RAD ;\n  rad_latitude_2 = latitude_2 * GDC_DEG_TO_RAD ;\n\n  TU1 = GDC_ECCENTRICITY * sinf ( rad_latitude_1 ) /\n    cosf ( rad_latitude_1 ) ;\n  TU2 = GDC_ECCENTRICITY * sinf ( rad_latitude_2 ) /\n    cosf ( rad_latitude_2 ) ;\n\n  CU1 = 1.0f / sqrtf ( TU1 * TU1 + 1.0f ) ;\n  SU1 = CU1 * TU1 ;\n  CU2 = 1.0f / sqrtf ( TU2 * TU2 + 1.0f ) ;\n  dist = CU1 * CU2 ;\n  BAZ = dist * TU2 ;\n  FAZ = BAZ * TU1 ;\n  X = rad_longitude_2 - rad_longitude_1 ;\n\n  do {\n    SX = sinf ( X ) ;\n    CX = cosf ( X ) ;\n    TU1 = CU2 * SX ;\n    TU2 = BAZ - SU1 * CU2 * CX ;\n    SY = sqrtf ( TU1 * TU1 + TU2 * TU2 ) ;\n    CY = dist * CX + FAZ ;\n    Y = atan2f ( SY, CY ) ;\n    SA = dist * SX / SY ;\n    C2A = - SA * SA + 1.0f;\n    CZ = FAZ + FAZ ;\n    if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n    E = CZ * CZ * 2.0f - 1.0f ;\n    C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n      GDC_FLATTENING / 16.0f ;\n    D = X ;\n    X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n    X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n  } while ( fabsf ( D - X ) > EPS );\n\n  X = sqrtf ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n  X = ( X - 2.0f ) / X ;\n  C = 1.0f - X ;\n  C = ( X * X / 4.0f + 1.0f ) / C ;\n  D = ( 0.375f * X * X - 1.0f ) * X ;\n  X = E * CY ;\n  dist = 1.0f - E - E ;\n  dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n          X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GC_SEMI_MINOR ;\n  return dist;\n}\n\nvoid distance_device(const sycl::float4* VA, float* VC, const size_t N, const int iteration) {\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  sycl::range<1> gws ((N+255)/256*256);\n  sycl::range<1> lws (256);\n\n  sycl::float4 *d_A = sycl::malloc_device<sycl::float4>(N, q);\n  q.memcpy(d_A, VA, N * sizeof(sycl::float4));\n\n  float *d_C = sycl::malloc_device<float>(N, q);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < iteration; n++) {\n    q.submit([&](sycl::handler& cgh) {\n      cgh.parallel_for<class geodesic_distance>(\n        sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        const int i = item.get_global_id(0);\n        if (i >= N) return;\n\n        const float GDC_DEG_TO_RAD = 3.141592654 / 180.0 ;  \n\n        const float GDC_FLATTENING = 1.0 - ( 6356752.31424518 / 6378137.0 ) ; \n        const float GDC_ECCENTRICITY = ( 6356752.31424518 / 6378137.0 ) ; \n        const float GDC_ELLIPSOIDAL =  1.0 / ( 6356752.31414 / 6378137.0 ) / ( 6356752.31414 / 6378137.0 ) - 1.0 ;\n        const float GC_SEMI_MINOR = 6356752.31424518f;\n        const float EPS = 0.5e-5f;\n        float  dist, BAZ , C , C2A , CU1 , CU2 , CX , CY , CZ ,\n        D , E , FAZ , SA , SU1 , SX  , SY , TU1 , TU2 , X , Y ; \n\n        const sycl::float4 rad4 = d_A[i] * GDC_DEG_TO_RAD; \n        const float rad_latitude_1  = rad4.x();\n        const float rad_longitude_1 = rad4.y();\n        const float rad_latitude_2  = rad4.z();\n        const float rad_longitude_2 = rad4.w();\n\n        TU1 = GDC_ECCENTRICITY * sycl::sin ( rad_latitude_1 ) /\n          sycl::cos ( rad_latitude_1 ) ;\n        TU2 = GDC_ECCENTRICITY * sycl::sin ( rad_latitude_2 ) /\n          sycl::cos ( rad_latitude_2 ) ;\n\n        CU1 = 1.0f / sycl::sqrt ( TU1 * TU1 + 1.0f ) ;\n        SU1 = CU1 * TU1 ;\n        CU2 = 1.0f / sycl::sqrt ( TU2 * TU2 + 1.0f ) ;\n        dist = CU1 * CU2 ;\n        BAZ = dist * TU2 ;\n        FAZ = BAZ * TU1 ;\n        X = rad_longitude_2 - rad_longitude_1 ;\n\n        do {\n          SX = sycl::sin ( X ) ;\n          CX = sycl::cos ( X ) ;\n          TU1 = CU2 * SX ;\n          TU2 = BAZ - SU1 * CU2 * CX ;\n          SY = sycl::sqrt ( TU1 * TU1 + TU2 * TU2 ) ;\n          CY = dist * CX + FAZ ;\n          Y = sycl::atan2 ( SY, CY ) ;\n          SA = dist * SX / SY ;\n          C2A = - SA * SA + 1.0f;\n          CZ = FAZ + FAZ ;\n          if ( C2A > 0.0f ) CZ = -CZ / C2A + CY ;\n          E = CZ * CZ * 2.0f - 1.0f ;\n          C = ( ( -3.0f * C2A + 4.0f ) * GDC_FLATTENING + 4.0f ) * C2A *\n            GDC_FLATTENING / 16.0f ;\n          D = X ;\n          X = ( ( E * CY * C + CZ ) * SY * C + Y ) * SA ;\n          X = ( 1.0f - C ) * X * GDC_FLATTENING + rad_longitude_2 - rad_longitude_1 ;\n        } while ( sycl::fabs ( D - X ) > EPS ) ;\n\n        X = sycl::sqrt ( GDC_ELLIPSOIDAL * C2A + 1.0f ) + 1.0f ;\n        X = ( X - 2.0f ) / X ;\n        C = 1.0f - X ;\n        C = ( X * X / 4.0f + 1.0f ) / C ;\n        D = ( 0.375f * X * X - 1.0f ) * X ;\n        X = E * CY ;\n        dist = 1.0f - E - E ;\n        dist = ( ( ( ( SY * SY * 4.0f - 3.0f ) * dist * CZ * D / 6.0f -\n                X ) * D / 4.0f + CZ ) * SY * D + Y ) * C * GC_SEMI_MINOR ;\n        d_C[i] = dist;\n      });\n    });\n  }\n  q.wait();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / iteration);\n\n  q.memcpy(VC, d_C, N * sizeof(float)).wait();\n  sycl::free(d_A, q);\n  sycl::free(d_C, q);\n}\n\nvoid verify( int size, const float *output, const float *expected_output) {\n  float error_rate = 0;\n  for ( int i = 0; i < size; i++) {\n    if (fabs(output[i] - expected_output[i]) > error_rate) {\n      error_rate = fabs(output[i] - expected_output[i]);\n    }\n  }\n  printf(\"The maximum error in distance for single precision is %f\\n\", error_rate); \n}\n\nint main(int argc, char** argv) {\n  if (argc != 2) {\n    printf(\"Usage %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int iteration = atoi(argv[1]);\n\n  int num_cities = 2097152; \n\n  int num_ref_cities = 6; \n\n  int index_map[] ={436483, 1952407, 627919, 377884, 442703, 1863423};\n  int N = num_cities * num_ref_cities;\n  int city = 0;\n  float lat, lon;\n\n  const char* filename = \"locations.txt\";\n  printf(\"Reading city locations from file %s...\\n\", filename);\n  FILE* fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    perror (\"Error opening the file\");\n    exit(-1);\n  }\n\n  sycl::float4* input  = (sycl::float4*) aligned_alloc(4096, N*sizeof(sycl::float4));\n  float*  output = (float*) aligned_alloc(4096, N*sizeof(float));\n  float*  expected_output = (float*) malloc(N*sizeof(float));\n\n  while (fscanf(fp, \"%f %f\\n\", &lat, &lon) != EOF) { \n    input[city].s0() = lat;\n    input[city].s1() = lon;\n    city++;\n    if (city == num_cities) break;  \n  }\n  fclose(fp);\n\n  \n\n  for (int c = 1;  c < num_ref_cities; c++) {\n    std::copy(input, input+num_cities, input+c*num_cities);\n  }\n  \n\n  for (int c = 0;  c < num_ref_cities; c++) {\n    int index = index_map[c] - 1;\n    for(int j = c*num_cities; j < (c+1)*num_cities; ++j) {\n      input[j].s2() = input[index].s0();\n      input[j].s3() = input[index].s1();\n    }\n  }\n\n  \n\n  for (int i = 0; i < N; i++)\n  {\n    float lat1 = input[i].s0();\n    float lon1 = input[i].s1();\n    float lat2 = input[i].s2();\n    float lon2 = input[i].s3();\n    expected_output[i] = distance_host(i, lat1, lon1, lat2, lon2);\n  }\n\n  distance_device(input, output, N, iteration);\n\n  verify(N, output, expected_output);\n\n  free(input);\n  free(output);\n  free(expected_output);\n  return 0;\n}\n"}}
{"kernel_name": "heat", "parallel_api": "cuda", "code": {"heat.cu": "\n\n\n#include <iostream>\n#include <chrono>\n#include <cmath>\n#include <fstream>\n#include <cuda.h>\n\n\n\n#define PI acos(-1.0) \n\n#define LINE \"--------------------\" \n\n\n__global__ void initial_value(const unsigned int n, const double dx, const double length, double * u);\n__global__ void zero(const unsigned int n, double * u);\n__global__ void solve(const unsigned int n, const double alpha, const double dx, const double dt, const double r, const double r2,\n\t\tdouble * __restrict__ u, double * __restrict__ u_tmp);\ndouble solution(const double t, const double x, const double y, const double alpha, const double length);\ndouble l2norm(const int n, const double * u, const int nsteps, const double dt, const double alpha, const double dx, const double length);\n\nint main(int argc, char *argv[]) {\n\n  \n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  \n\n  int n = 1000;\n\n  \n\n  int nsteps = 10;\n\n  \n\n  \n\n  if (argc == 3) {\n\n    \n\n    n = atoi(argv[1]);\n    if (n < 0) {\n      std::cerr << \"Error: n must be positive\" << std::endl;\n      exit(EXIT_FAILURE);\n    }\n\n    \n\n    nsteps = atoi(argv[2]);\n    if (nsteps < 0) {\n      std::cerr << \"Error: nsteps must be positive\" << std::endl;\n      exit(EXIT_FAILURE);\n    }\n  }\n\n  \n\n  \n\n  \n\n  double alpha = 0.1;          \n\n  double length = 1000.0;      \n\n  double dx = length / (n+1);  \n\n  double dt = 0.5 / nsteps;    \n\n\n  \n\n  double r = alpha * dt / (dx * dx);\n\n  cudaDeviceProp prop;\n  cudaGetDeviceProperties(&prop, 0);\n  char *device_name = prop.name;\n\n  \n\n  std::cout\n    << std::endl\n    << \" MMS heat equation\" << std::endl << std::endl\n    << LINE << std::endl\n    << \"Problem input\" << std::endl << std::endl\n    << \" Grid size: \" << n << \" x \" << n << std::endl\n    << \" Cell width: \" << dx << std::endl\n    << \" Grid length: \" << length << \"x\" << length << std::endl\n    << std::endl\n    << \" Alpha: \" << alpha << std::endl\n    << std::endl\n    << \" Steps: \" <<  nsteps << std::endl\n    << \" Total time: \" << dt*(double)nsteps << std::endl\n    << \" Time step: \" << dt << std::endl\n    << \" GPU device: \" << device_name << std::endl\n    << LINE << std::endl;\n\n  \n\n  std::cout << \"Stability\" << std::endl << std::endl;\n  std::cout << \" r value: \" << r << std::endl;\n  if (r > 0.5)\n    std::cout << \" Warning: unstable\" << std::endl;\n  std::cout << LINE << std::endl;\n\n\n  \n\n  double *u;\n  double *u_tmp;\n  cudaMalloc((void**)&u,     sizeof(double)*n*n);\n  cudaMalloc((void**)&u_tmp, sizeof(double)*n*n);\n\n  \n\n  const int block_size = 256;\n  int n_ceil = (n*n+block_size-1) / block_size;\n  dim3 grid(n_ceil);\n  dim3 block(block_size);\n  initial_value <<< dim3(grid), dim3(block) >>> (n, dx, length, u);\n  zero <<< dim3(grid), dim3(block) >>> (n, u_tmp);\n\n  \n\n  cudaError_t err = cudaDeviceSynchronize();\n  if (err != cudaSuccess) {\n    std::cerr << \"CUDA error after initalisation\" << std::endl;\n    exit(EXIT_FAILURE);\n  }\n\n  \n\n  \n\n  \n\n  \n\n  const double r2 = 1.0 - 4.0*r;\n\n  \n\n  auto tic = std::chrono::high_resolution_clock::now();\n\n  for (int t = 0; t < nsteps; ++t) {\n\n    \n\n    \n\n    \n\n    solve<<< dim3(grid), dim3(block) >>> (n, alpha, dx, dt, r, r2, u, u_tmp);\n\n    \n\n    auto tmp = u;\n    u = u_tmp;\n    u_tmp = tmp;\n  }\n\n  \n\n  cudaDeviceSynchronize();\n  auto toc = std::chrono::high_resolution_clock::now();\n\n  \n\n  double *u_host = new double[n*n];\n  err = cudaMemcpy(u_host, u, sizeof(double)*n*n, cudaMemcpyDeviceToHost);\n  if (err != cudaSuccess) {\n    std::cerr << \"CUDA error on copying back data\" << std::endl;\n    exit(EXIT_FAILURE);\n  }\n\n  \n\n  \n\n  \n\n  \n\n  double norm = l2norm(n, u_host, nsteps, dt, alpha, dx, length);\n\n  \n\n  auto stop = std::chrono::high_resolution_clock::now();\n\n  \n\n  std::cout\n    << \"Results\" << std::endl << std::endl\n    << \"Error (L2norm): \" << norm << std::endl\n    << \"Solve time (s): \" << std::chrono::duration_cast<std::chrono::duration<double>>(toc-tic).count() << std::endl\n    << \"Total time (s): \" << std::chrono::duration_cast<std::chrono::duration<double>>(stop-start).count() << std::endl\n    << \"Bandwidth (GB/s): \" << 1.0E-9*2.0*n*n*nsteps*sizeof(double)/std::chrono::duration_cast<std::chrono::duration<double>>(toc-tic).count() << std::endl\n    << LINE << std::endl;\n\n  delete[] u_host;\n  cudaFree(u);\n  cudaFree(u_tmp);\n}\n\n\n\n__global__ void initial_value(const unsigned int n, const double dx, const double length, double * u) {\n\n  int idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if (idx < n*n) {\n    int i = idx % n;\n    int j = idx / n;\n    double y = dx * (j+1); \n\n    double x = dx * (i+1); \n\n    u[i+j*n] = sin(PI * x / length) * sin(PI * y / length);\n  }\n}\n\n\n\n\n__global__ void zero(const unsigned int n, double * u) {\n\n  int idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if (idx < n*n) u[idx] = 0.0;\n}\n\n\n\n\n\n\n__global__ void solve(const unsigned int n, const double alpha, const double dx, const double dt, \n\t\tconst double r, const double r2,\n\t\tdouble * __restrict__ u, double * __restrict__ u_tmp) {\n\n  int idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if (idx < n * n) {\n    int i = idx % n;\n    int j = idx / n;\n    \n\n    u_tmp[i+j*n] =  r2 * u[i+j*n] +\n    r * ((i < n-1) ? u[i+1+j*n] : 0.0) +\n    r * ((i > 0)   ? u[i-1+j*n] : 0.0) +\n    r * ((j < n-1) ? u[i+(j+1)*n] : 0.0) +\n    r * ((j > 0)   ? u[i+(j-1)*n] : 0.0);\n  }\n}\n\n\n\n\ndouble solution(const double t, const double x, const double y, const double alpha, const double length) {\n\n  return exp(-2.0*alpha*PI*PI*t/(length*length)) * sin(PI*x/length) * sin(PI*y/length);\n\n}\n\n\n\n\n\n\ndouble l2norm(const int n, const double * u, const int nsteps, const double dt, const double alpha, const double dx, const double length) {\n\n  \n\n  double time = dt * (double)nsteps;\n\n  \n\n  double l2norm = 0.0;\n\n  \n\n  double y = dx;\n  for (int j = 0; j < n; ++j) {\n    double x = dx;\n    for (int i = 0; i < n; ++i) {\n      double answer = solution(time, x, y, alpha, length);\n      l2norm += (u[i+j*n] - answer) * (u[i+j*n] - answer);\n\n      x += dx;\n    }\n    y += dx;\n  }\n\n  return sqrt(l2norm);\n}\n"}}
{"kernel_name": "heat", "parallel_api": "hip", "code": {"heat.cu": "\n\n\n#include <iostream>\n#include <chrono>\n#include <cmath>\n#include <fstream>\n\n#include <hip/hip_runtime.h>\n\n\n\n#define PI acos(-1.0) \n\n#define LINE \"--------------------\" \n\n\n__global__ void initial_value(const unsigned int n, const double dx, const double length, double * u);\n__global__ void zero(const unsigned int n, double * u);\n__global__ void solve(const unsigned int n, const double alpha, const double dx, const double dt, const double r, const double r2,\n\t\tdouble * __restrict__ u, double * __restrict__ u_tmp);\ndouble solution(const double t, const double x, const double y, const double alpha, const double length);\ndouble l2norm(const int n, const double * u, const int nsteps, const double dt, const double alpha, const double dx, const double length);\n\nint main(int argc, char *argv[]) {\n\n  \n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  \n\n  int n = 1000;\n\n  \n\n  int nsteps = 10;\n\n  \n\n  \n\n  if (argc == 3) {\n\n    \n\n    n = atoi(argv[1]);\n    if (n < 0) {\n      std::cerr << \"Error: n must be positive\" << std::endl;\n      exit(EXIT_FAILURE);\n    }\n\n    \n\n    nsteps = atoi(argv[2]);\n    if (nsteps < 0) {\n      std::cerr << \"Error: nsteps must be positive\" << std::endl;\n      exit(EXIT_FAILURE);\n    }\n  }\n\n  \n\n  \n\n  \n\n  double alpha = 0.1;          \n\n  double length = 1000.0;      \n\n  double dx = length / (n+1);  \n\n  double dt = 0.5 / nsteps;    \n\n\n  \n\n  double r = alpha * dt / (dx * dx);\n\n  hipDeviceProp_t prop;\n  hipGetDeviceProperties(&prop, 0);\n  char *device_name = prop.name;\n\n  \n\n  std::cout\n    << std::endl\n    << \" MMS heat equation\" << std::endl << std::endl\n    << LINE << std::endl\n    << \"Problem input\" << std::endl << std::endl\n    << \" Grid size: \" << n << \" x \" << n << std::endl\n    << \" Cell width: \" << dx << std::endl\n    << \" Grid length: \" << length << \"x\" << length << std::endl\n    << std::endl\n    << \" Alpha: \" << alpha << std::endl\n    << std::endl\n    << \" Steps: \" <<  nsteps << std::endl\n    << \" Total time: \" << dt*(double)nsteps << std::endl\n    << \" Time step: \" << dt << std::endl\n    << \" GPU device: \" << device_name << std::endl\n    << LINE << std::endl;\n\n  \n\n  std::cout << \"Stability\" << std::endl << std::endl;\n  std::cout << \" r value: \" << r << std::endl;\n  if (r > 0.5)\n    std::cout << \" Warning: unstable\" << std::endl;\n  std::cout << LINE << std::endl;\n\n  \n\n  double *u;\n  double *u_tmp;\n  hipMalloc((void**)&u,     sizeof(double)*n*n);\n  hipMalloc((void**)&u_tmp, sizeof(double)*n*n);\n\n  \n\n  const int block_size = 256;\n  int n_ceil = (n*n+block_size-1) / block_size;\n  dim3 grid(n_ceil);\n  dim3 block(block_size);\n  hipLaunchKernelGGL(initial_value, grid, block, 0, 0, n, dx, length, u);\n  hipLaunchKernelGGL(zero, grid, block, 0, 0, n, u_tmp);\n\n  \n\n  hipError_t err = hipDeviceSynchronize();\n  if (err != hipSuccess) {\n    std::cerr << \"CUDA error after initalisation\" << std::endl;\n    exit(EXIT_FAILURE);\n  }\n\n  \n\n  \n\n  \n\n  \n\n  const double r2 = 1.0 - 4.0*r;\n\n  \n\n  auto tic = std::chrono::high_resolution_clock::now();\n\n  for (int t = 0; t < nsteps; ++t) {\n\n    \n\n    \n\n    \n\n    hipLaunchKernelGGL(solve, grid, block, 0, 0, n, alpha, dx, dt, r, r2, u, u_tmp);\n\n    \n\n    auto tmp = u;\n    u = u_tmp;\n    u_tmp = tmp;\n  }\n\n  \n\n  hipDeviceSynchronize();\n  auto toc = std::chrono::high_resolution_clock::now();\n\n  \n\n  double *u_host = new double[n*n];\n  err = hipMemcpy(u_host, u, sizeof(double)*n*n, hipMemcpyDeviceToHost);\n  if (err != hipSuccess) {\n    std::cerr << \"CUDA error on copying back data\" << std::endl;\n    exit(EXIT_FAILURE);\n  }\n\n  \n\n  \n\n  \n\n  \n\n  double norm = l2norm(n, u_host, nsteps, dt, alpha, dx, length);\n\n  \n\n  auto stop = std::chrono::high_resolution_clock::now();\n\n  \n\n  std::cout\n    << \"Results\" << std::endl << std::endl\n    << \"Error (L2norm): \" << norm << std::endl\n    << \"Solve time (s): \" << std::chrono::duration_cast<std::chrono::duration<double>>(toc-tic).count() << std::endl\n    << \"Total time (s): \" << std::chrono::duration_cast<std::chrono::duration<double>>(stop-start).count() << std::endl\n    << \"Bandwidth (GB/s): \" << 1.0E-9*2.0*n*n*nsteps*sizeof(double)/std::chrono::duration_cast<std::chrono::duration<double>>(toc-tic).count() << std::endl\n    << LINE << std::endl;\n\n  delete[] u_host;\n  hipFree(u);\n  hipFree(u_tmp);\n}\n\n\n\n__global__ void initial_value(const unsigned int n, const double dx, const double length, double * u) {\n\n  int idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if (idx < n*n) {\n    int i = idx % n;\n    int j = idx / n;\n    double y = dx * (j+1); \n\n    double x = dx * (i+1); \n\n    u[i+j*n] = sin(PI * x / length) * sin(PI * y / length);\n  }\n}\n\n\n\n\n__global__ void zero(const unsigned int n, double * u) {\n\n  int idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if (idx < n*n) u[idx] = 0.0;\n}\n\n\n\n\n\n\n__global__ void solve(const unsigned int n, const double alpha, const double dx, const double dt, \n\t\tconst double r, const double r2,\n\t\tdouble * __restrict__ u, double * __restrict__ u_tmp) {\n\n  int idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if (idx < n * n) {\n    int i = idx % n;\n    int j = idx / n;\n    \n\n    u_tmp[i+j*n] =  r2 * u[i+j*n] +\n    r * ((i < n-1) ? u[i+1+j*n] : 0.0) +\n    r * ((i > 0)   ? u[i-1+j*n] : 0.0) +\n    r * ((j < n-1) ? u[i+(j+1)*n] : 0.0) +\n    r * ((j > 0)   ? u[i+(j-1)*n] : 0.0);\n  }\n}\n\n\n\n\ndouble solution(const double t, const double x, const double y, const double alpha, const double length) {\n\n  return exp(-2.0*alpha*PI*PI*t/(length*length)) * sin(PI*x/length) * sin(PI*y/length);\n\n}\n\n\n\n\n\n\ndouble l2norm(const int n, const double * u, const int nsteps, const double dt, const double alpha, const double dx, const double length) {\n\n  \n\n  double time = dt * (double)nsteps;\n\n  \n\n  double l2norm = 0.0;\n\n  \n\n  double y = dx;\n  for (int j = 0; j < n; ++j) {\n    double x = dx;\n    for (int i = 0; i < n; ++i) {\n      double answer = solution(time, x, y, alpha, length);\n      l2norm += (u[i+j*n] - answer) * (u[i+j*n] - answer);\n\n      x += dx;\n    }\n    y += dx;\n  }\n\n  return sqrt(l2norm);\n}\n"}}
{"kernel_name": "heat", "parallel_api": "omp", "code": {"heat.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <omp.h>\n\n\n\n#define PI acos(-1.0) \n\n#define LINE \"--------------------\\n\" \n\n\ndouble solution(const double t, const double x, const double y, const double alpha, const double length);\ndouble l2norm(const int n, const double * __restrict u, const int nsteps, const double dt, const double alpha, const double dx, const double length);\n\nint main(int argc, char *argv[]) {\n\n  \n\n  double start = omp_get_wtime();\n\n  \n\n  int n = 1000;\n\n  \n\n  int nsteps = 10;\n\n  \n\n  \n\n  if (argc == 3) {\n\n    \n\n    n = atoi(argv[1]);\n    if (n < 0) {\n      fprintf(stderr, \"Error: n must be positive\\n\");\n      exit(EXIT_FAILURE);\n    }\n\n    \n\n    nsteps = atoi(argv[2]);\n    if (nsteps < 0) {\n      fprintf(stderr, \"Error: nsteps must be positive\\n\");\n      exit(EXIT_FAILURE);\n    }\n  }\n\n  \n\n  \n\n  \n\n  double alpha = 0.1;          \n\n  double length = 1000.0;      \n\n  double dx = length / (n+1);  \n\n  double dt = 0.5 / nsteps;    \n\n\n  \n\n  double r = alpha * dt / (dx * dx);\n\n  \n\n  printf(\"\\n\");\n  printf(\" MMS heat equation\\n\\n\");\n  printf(LINE);\n  printf(\"Problem input\\n\\n\");\n  printf(\" Grid size: %d x %d\\n\", n, n);\n  printf(\" Cell width: %E\\n\", dx);\n  printf(\" Grid length: %lf x %lf\\n\", length, length);\n  printf(\"\\n\");\n  printf(\" Alpha: %E\\n\", alpha);\n  printf(\"\\n\");\n  printf(\" Steps: %d\\n\", nsteps);\n  printf(\" Total time: %E\\n\", dt*(double)nsteps);\n  printf(\" Time step: %E\\n\", dt);\n  printf(LINE);\n\n  \n\n  printf(\"Stability\\n\\n\");\n  printf(\" r value: %lf\\n\", r);\n  if (r > 0.5)\n    printf(\" Warning: unstable\\n\");\n  printf(LINE);\n\n  \n\n  double *u     = (double*) malloc(sizeof(double)*n*n);\n  double *u_tmp = (double*) malloc(sizeof(double)*n*n);\n\n  double tic, toc;\n  const int block_size = 256;\n\n#pragma omp target data map(tofrom: u[0:n*n], u_tmp[0:n*n]) \n{\n  \n\n  #pragma omp target teams distribute parallel for simd collapse(2) thread_limit(block_size)\n  for (int j = 0; j < n; ++j) {\n    for (int i = 0; i < n; ++i) {\n      double y = (j+1)*dx; \n\n      double x = (i+1)*dx; \n\n      u[i+j*n] = sin(PI * x / length) * sin(PI * y / length);\n    }\n  }\n\n  #pragma omp target teams distribute parallel for simd collapse(2) thread_limit(block_size)\n  for (int j = 0; j < n; ++j) {\n    for (int i = 0; i < n; ++i) {\n      u_tmp[i+j*n] = 0.0;\n    }\n  }\n\n  \n\n  \n\n  \n\n\n  \n\n  const double r2 = 1.0 - 4.0*r;\n\n  \n\n  tic = omp_get_wtime();\n\n  for (int t = 0; t < nsteps; ++t) {\n\n    \n\n    \n\n    \n\n    \n\n    #pragma omp target teams distribute parallel for simd collapse(2) thread_limit(block_size)\n    for (int j = 0; j < n; ++j) {\n      for (int i = 0; i < n; ++i) {\n        \n\n        \n\n        u_tmp[i+j*n] =  r2 * u[i+j*n] +\n        r * ((i < n-1) ? u[i+1+j*n] : 0.0) +\n        r * ((i > 0)   ? u[i-1+j*n] : 0.0) +\n        r * ((j < n-1) ? u[i+(j+1)*n] : 0.0) +\n        r * ((j > 0)   ? u[i+(j-1)*n] : 0.0);\n      }\n    }\n\n    \n\n    double *tmp = u;\n    u = u_tmp;\n    u_tmp = tmp;\n  }\n  \n\n  toc = omp_get_wtime();\n}\n\n  \n\n  \n\n  \n\n  \n\n  double norm = l2norm(n, u, nsteps, dt, alpha, dx, length);\n\n  \n\n  double stop = omp_get_wtime();\n\n  \n\n  printf(\"Results\\n\\n\");\n  printf(\"Error (L2norm): %E\\n\", norm);\n  printf(\"Solve time (s): %lf\\n\", toc-tic);\n  printf(\"Total time (s): %lf\\n\", stop-start);\n  printf(\"Bandwidth (GB/s): %lf\\n\", 1.0E-9*2.0*n*n*nsteps*sizeof(double)/(toc-tic));\n  printf(LINE);\n\n  \n\n  free(u);\n  free(u_tmp);\n}\n\n\n\n\ndouble solution(const double t, const double x, const double y, const double alpha, const double length) {\n\n  return exp(-2.0*alpha*PI*PI*t/(length*length)) * sin(PI*x/length) * sin(PI*y/length);\n\n}\n\n\n\n\n\n\ndouble l2norm(const int n, const double * u, const int nsteps, const double dt,\n              const double alpha, const double dx, const double length) {\n\n  \n\n  double time = dt * (double)nsteps;\n\n  \n\n  double l2norm = 0.0;\n\n  \n\n  double y = dx;\n  for (int j = 0; j < n; ++j) {\n    double x = dx;\n    for (int i = 0; i < n; ++i) {\n      double answer = solution(time, x, y, alpha, length);\n      l2norm += (u[i+j*n] - answer) * (u[i+j*n] - answer);\n\n      x += dx;\n    }\n    y += dx;\n  }\n\n  return sqrt(l2norm);\n}\n"}}
{"kernel_name": "heat", "parallel_api": "serial", "code": {"heat.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n\n\n\n#define PI acos(-1.0) \n\n#define LINE \"--------------------\\n\" \n\n\ndouble solution(const double t, const double x, const double y, const double alpha, const double length);\ndouble l2norm(const int n, const double * __restrict u, const int nsteps, const double dt, const double alpha, const double dx, const double length);\n\nint main(int argc, char *argv[]) {\n\n  \n\n  double start = omp_get_wtime();\n\n  \n\n  int n = 1000;\n\n  \n\n  int nsteps = 10;\n\n  \n\n  \n\n  if (argc == 3) {\n\n    \n\n    n = atoi(argv[1]);\n    if (n < 0) {\n      fprintf(stderr, \"Error: n must be positive\\n\");\n      exit(EXIT_FAILURE);\n    }\n\n    \n\n    nsteps = atoi(argv[2]);\n    if (nsteps < 0) {\n      fprintf(stderr, \"Error: nsteps must be positive\\n\");\n      exit(EXIT_FAILURE);\n    }\n  }\n\n  \n\n  \n\n  \n\n  double alpha = 0.1;          \n\n  double length = 1000.0;      \n\n  double dx = length / (n+1);  \n\n  double dt = 0.5 / nsteps;    \n\n\n  \n\n  double r = alpha * dt / (dx * dx);\n\n  \n\n  printf(\"\\n\");\n  printf(\" MMS heat equation\\n\\n\");\n  printf(LINE);\n  printf(\"Problem input\\n\\n\");\n  printf(\" Grid size: %d x %d\\n\", n, n);\n  printf(\" Cell width: %E\\n\", dx);\n  printf(\" Grid length: %lf x %lf\\n\", length, length);\n  printf(\"\\n\");\n  printf(\" Alpha: %E\\n\", alpha);\n  printf(\"\\n\");\n  printf(\" Steps: %d\\n\", nsteps);\n  printf(\" Total time: %E\\n\", dt*(double)nsteps);\n  printf(\" Time step: %E\\n\", dt);\n  printf(LINE);\n\n  \n\n  printf(\"Stability\\n\\n\");\n  printf(\" r value: %lf\\n\", r);\n  if (r > 0.5)\n    printf(\" Warning: unstable\\n\");\n  printf(LINE);\n\n  \n\n  double *u     = (double*) malloc(sizeof(double)*n*n);\n  double *u_tmp = (double*) malloc(sizeof(double)*n*n);\n\n  double tic, toc;\n  const int block_size = 256;\n\n{\n  \n\n    for (int j = 0; j < n; ++j) {\n    for (int i = 0; i < n; ++i) {\n      double y = (j+1)*dx; \n\n      double x = (i+1)*dx; \n\n      u[i+j*n] = sin(PI * x / length) * sin(PI * y / length);\n    }\n  }\n\n    for (int j = 0; j < n; ++j) {\n    for (int i = 0; i < n; ++i) {\n      u_tmp[i+j*n] = 0.0;\n    }\n  }\n\n  \n\n  \n\n  \n\n\n  \n\n  const double r2 = 1.0 - 4.0*r;\n\n  \n\n  tic = omp_get_wtime();\n\n  for (int t = 0; t < nsteps; ++t) {\n\n    \n\n    \n\n    \n\n    \n\n        for (int j = 0; j < n; ++j) {\n      for (int i = 0; i < n; ++i) {\n        \n\n        \n\n        u_tmp[i+j*n] =  r2 * u[i+j*n] +\n        r * ((i < n-1) ? u[i+1+j*n] : 0.0) +\n        r * ((i > 0)   ? u[i-1+j*n] : 0.0) +\n        r * ((j < n-1) ? u[i+(j+1)*n] : 0.0) +\n        r * ((j > 0)   ? u[i+(j-1)*n] : 0.0);\n      }\n    }\n\n    \n\n    double *tmp = u;\n    u = u_tmp;\n    u_tmp = tmp;\n  }\n  \n\n  toc = omp_get_wtime();\n}\n\n  \n\n  \n\n  \n\n  \n\n  double norm = l2norm(n, u, nsteps, dt, alpha, dx, length);\n\n  \n\n  double stop = omp_get_wtime();\n\n  \n\n  printf(\"Results\\n\\n\");\n  printf(\"Error (L2norm): %E\\n\", norm);\n  printf(\"Solve time (s): %lf\\n\", toc-tic);\n  printf(\"Total time (s): %lf\\n\", stop-start);\n  printf(\"Bandwidth (GB/s): %lf\\n\", 1.0E-9*2.0*n*n*nsteps*sizeof(double)/(toc-tic));\n  printf(LINE);\n\n  \n\n  free(u);\n  free(u_tmp);\n}\n\n\n\n\ndouble solution(const double t, const double x, const double y, const double alpha, const double length) {\n\n  return exp(-2.0*alpha*PI*PI*t/(length*length)) * sin(PI*x/length) * sin(PI*y/length);\n\n}\n\n\n\n\n\n\ndouble l2norm(const int n, const double * u, const int nsteps, const double dt,\n              const double alpha, const double dx, const double length) {\n\n  \n\n  double time = dt * (double)nsteps;\n\n  \n\n  double l2norm = 0.0;\n\n  \n\n  double y = dx;\n  for (int j = 0; j < n; ++j) {\n    double x = dx;\n    for (int i = 0; i < n; ++i) {\n      double answer = solution(time, x, y, alpha, length);\n      l2norm += (u[i+j*n] - answer) * (u[i+j*n] - answer);\n\n      x += dx;\n    }\n    y += dx;\n  }\n\n  return sqrt(l2norm);\n}"}}
{"kernel_name": "heat", "parallel_api": "sycl", "code": {"heat.cpp": "\n\n\n#include <iostream>\n#include <chrono>\n#include <cmath>\n#include <sycl/sycl.hpp>\n\n\n\n#define PI sycl::acos(-1.0) \n\n#define LINE \"--------------------\" \n\n\nvoid initial_value(sycl::queue &q, const unsigned int n, const double dx, const double length, double *u);\nvoid zero(sycl::queue &q, const unsigned int n, double *u);\nvoid solve(sycl::queue &q, const unsigned int n, const double alpha, const double dx, const double dt, double *u, double *u_tmp);\ndouble solution(const double t, const double x, const double y, const double alpha, const double length);\ndouble l2norm(const unsigned int n, const double * u, const int nsteps, const double dt, const double alpha, const double dx, const double length);\n\n\n\nint main(int argc, char *argv[]) {\n\n  \n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  \n\n  unsigned int n = 1000;\n\n  \n\n  int nsteps = 10;\n\n  \n\n  \n\n  if (argc == 3) {\n\n    \n\n    n = atoi(argv[1]);\n    if (n < 0) {\n      std::cerr << \"Error: n must be positive\" << std::endl;\n      exit(EXIT_FAILURE);\n    }\n\n    \n\n    nsteps = atoi(argv[2]);\n    if (nsteps < 0) {\n      std::cerr << \"Error: nsteps must be positive\" << std::endl;\n      exit(EXIT_FAILURE);\n    }\n  }\n\n  \n\n  \n\n  \n\n  double alpha = 0.1;          \n\n  double length = 1000.0;      \n\n  double dx = length / (n+1);  \n\n  double dt = 0.5 / nsteps;    \n\n\n  \n\n  double r = alpha * dt / (dx * dx);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  std::cout\n    << std::endl\n    << \" MMS heat equation\" << std::endl << std::endl\n    << LINE << std::endl\n    << \"Problem input\" << std::endl << std::endl\n    << \" Grid size: \" << n << \" x \" << n << std::endl\n    << \" Cell width: \" << dx << std::endl\n    << \" Grid length: \" << length << \"x\" << length << std::endl\n    << std::endl\n    << \" Alpha: \" << alpha << std::endl\n    << std::endl\n    << \" Steps: \" <<  nsteps << std::endl\n    << \" Total time: \" << dt*(double)nsteps << std::endl\n    << \" Time step: \" << dt << std::endl\n    << \" GPU device: \" << q.get_device().get_info<sycl::info::device::name>() << std::endl\n    << LINE << std::endl;\n\n  \n\n  std::cout << \"Stability\" << std::endl << std::endl;\n  std::cout << \" r value: \" << r << std::endl;\n  if (r > 0.5)\n    std::cout << \" Warning: unstable\" << std::endl;\n  std::cout << LINE << std::endl;\n\n  const unsigned int grid_size = n * n;\n\n  \n\n  double *u = sycl::malloc_device<double>(grid_size, q);\n  double *u_tmp = sycl::malloc_device<double>(grid_size, q);\n\n  const int block_size = 256;\n  const int n_ceil = (grid_size+block_size-1) / block_size * block_size;\n\n  \n\n  q.submit([&](sycl::handler& cgh) {\n    cgh.parallel_for<class initial_value_kernel>(\n      sycl::nd_range<1>(sycl::range<1>(n_ceil), sycl::range<1>(block_size)),\n      [=](sycl::nd_item<1> item) {\n      int idx = item.get_global_id(0);\n      if (idx < grid_size) {\n        int i = idx % n;\n        int j = idx / n;\n        double y = dx * (j+1); \n\n        double x = dx * (i+1); \n\n        u[i+j*n] = sycl::sin(PI * x / length) * sycl::sin(PI * y / length);\n      }\n    });\n  });\n\n  q.submit([&](sycl::handler& cgh) {\n    cgh.parallel_for<class zero_kernel>(\n      sycl::nd_range<1>(sycl::range<1>(n_ceil), sycl::range<1>(block_size)),\n      [=](sycl::nd_item<1> item) {\n      int idx = item.get_global_id(0);\n      if (idx < grid_size) u_tmp[idx] = 0.0;\n    });\n  });\n\n  \n\n  q.wait();\n\n  \n\n  \n\n  \n\n\n  const double r2 = 1.0 - 4.0*r;\n\n  \n\n  auto tic = std::chrono::high_resolution_clock::now();\n\n  for (int t = 0; t < nsteps; ++t) {\n\n    \n\n    \n\n    \n\n    q.submit([&](sycl::handler& cgh) {\n      \n\n      cgh.parallel_for<class solve_kernel>(\n        sycl::nd_range<1>(sycl::range<1>(n_ceil), sycl::range<1>(block_size)),\n        [=](sycl::nd_item<1> item) {\n        int idx = item.get_global_id(0);\n        if (idx < grid_size) {\n          int i = idx % n;\n          int j = idx / n;\n\n          \n\n          \n\n          u_tmp[i+j*n] = r2 * u[i+j*n] +\n          r * ((i < n-1) ? u[i+1+j*n] : 0.0) +\n          r * ((i > 0)   ? u[i-1+j*n] : 0.0) +\n          r * ((j < n-1) ? u[i+(j+1)*n] : 0.0) +\n          r * ((j > 0)   ? u[i+(j-1)*n] : 0.0);\n        }\n      });\n    });\n\n    \n\n    auto tmp = u;\n    u = u_tmp;\n    u_tmp = tmp;\n  }\n\n  q.wait();\n  auto toc = std::chrono::high_resolution_clock::now();\n\n  double *u_host = new double[grid_size];\n  q.memcpy(u_host, u, sizeof(double) * grid_size).wait();\n\n  \n\n  \n\n  \n\n  \n\n  double norm = l2norm(n, u_host, nsteps, dt, alpha, dx, length);\n\n  \n\n  auto stop = std::chrono::high_resolution_clock::now();\n\n  \n\n  std::cout\n    << \"Results\" << std::endl << std::endl\n    << \"Error (L2norm): \" << norm << std::endl\n    << \"Solve time (s): \" << std::chrono::duration_cast<std::chrono::duration<double>>(toc-tic).count() << std::endl\n    << \"Total time (s): \" << std::chrono::duration_cast<std::chrono::duration<double>>(stop-start).count() << std::endl\n    << \"Bandwidth (GB/s): \" << 1.0E-9*2.0*n*n*nsteps*sizeof(double)/std::chrono::duration_cast<std::chrono::duration<double>>(toc-tic).count() << std::endl\n    << LINE << std::endl;\n\n  sycl::free(u, q);\n  sycl::free(u_tmp, q);\n  delete[] u_host;\n}\n\n\n\n\ndouble solution(const double t, const double x, const double y, const double alpha, const double length) {\n\n  return exp(-2.0*alpha*PI*PI*t/(length*length)) * sin(PI*x/length) * sin(PI*y/length);\n\n}\n\n\n\n\n\n\ndouble l2norm(const unsigned int n, const double * u, const int nsteps, const double dt, const double alpha, const double dx, const double length) {\n  \n\n  double time = dt * (double)nsteps;\n\n  \n\n  double l2norm = 0.0;\n\n  \n\n  double y = dx;\n  for (int j = 0; j < n; ++j) {\n    double x = dx;\n    for (int i = 0; i < n; ++i) {\n      double answer = solution(time, x, y, alpha, length);\n      l2norm += (u[i+j*n] - answer) * (u[i+j*n] - answer);\n\n      x += dx;\n    }\n    y += dx;\n  }\n\n  return sqrt(l2norm);\n}\n"}}
{"kernel_name": "hotspot3D", "parallel_api": "cuda", "code": {"3D.cu": "#include <sys/types.h>\n#include <chrono>\n#include <cuda.h>\n#include \"3D_helper.h\"\n\n#define TOL      (0.001)\n#define STR_SIZE (256)\n#define MAX_PD   (3.0e6)\n\n\n\n#define PRECISION    0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI         100\n\n\n\n#define FACTOR_CHIP  0.5\n\n#define WG_SIZE_X (64)\n#define WG_SIZE_Y (4)\nfloat t_chip      = 0.0005;\nfloat chip_height = 0.016;\nfloat chip_width  = 0.016;\nfloat amb_temp    = 80.0;\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <rows/cols> <layers> <iterations> <powerFile> <tempFile> <outputFile>\\n\", argv[0]);\n  fprintf(stderr, \"\\t<rows/cols>  - number of rows/cols in the grid (positive integer)\\n\");\n  fprintf(stderr, \"\\t<layers>  - number of layers in the grid (positive integer)\\n\");\n\n  fprintf(stderr, \"\\t<iteration> - number of iterations\\n\");\n  fprintf(stderr, \"\\t<powerFile>  - name of the file containing the initial power values of each cell\\n\");\n  fprintf(stderr, \"\\t<tempFile>  - name of the file containing the initial temperature values of each cell\\n\");\n  fprintf(stderr, \"\\t<outputFile - output file\\n\");\n  exit(1);\n}\n\n__global__ void\nhotspot3d(\n    const float*__restrict__ tIn, \n    const float*__restrict__ pIn, \n          float*__restrict__ tOut,\n    const int numCols, \n    const int numRows, \n    const int layers,\n    const float ce, \n    const float cw,\n    const float cn, \n    const float cs,\n    const float ct,\n    const float cb,\n    const float cc,\n    const float stepDivCap)\n{\n  float amb_temp = 80.0;\n\n  int i = blockDim.x * blockIdx.x + threadIdx.x;\n  int j = blockDim.y * blockIdx.y + threadIdx.y;\n  int c = i + j * numCols;\n  int xy = numCols * numRows;\n\n  int W = (i == 0)        ? c : c - 1;\n  int E = (i == numCols-1)     ? c : c + 1;\n  int N = (j == 0)        ? c : c - numCols;\n  int S = (j == numRows-1)     ? c : c + numCols;\n\n  float temp1, temp2, temp3;\n  temp1 = temp2 = tIn[c];\n  temp3 = tIn[c+xy];\n  tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n    + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n  c += xy;\n  W += xy;\n  E += xy;\n  N += xy;\n  S += xy;\n\n  for (int k = 1; k < layers-1; ++k) {\n    temp1 = temp2;\n    temp2 = temp3;\n    temp3 = tIn[c+xy];\n    tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n      + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n    c += xy;\n    W += xy;\n    E += xy;\n    N += xy;\n    S += xy;\n  }\n  temp1 = temp2;\n  temp2 = temp3;\n  tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n    + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 7)\n  {\n    usage(argc,argv);\n  }\n\n  char *pfile, *tfile, *ofile;\n  int iterations = atoi(argv[3]);\n\n  pfile            = argv[4];\n  tfile            = argv[5];\n  ofile            = argv[6];\n  int numCols      = atoi(argv[1]);\n  int numRows      = atoi(argv[1]);\n  int layers       = atoi(argv[2]);\n\n  \n\n\n  float dx         = chip_height/numRows;\n  float dy         = chip_width/numCols;\n  float dz         = t_chip/layers;\n\n  float Cap        = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * dx * dy;\n  float Rx         = dy / (2.0 * K_SI * t_chip * dx);\n  float Ry         = dx / (2.0 * K_SI * t_chip * dy);\n  float Rz         = dz / (K_SI * dx * dy);\n\n  float max_slope  = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n  float dt         = PRECISION / max_slope;\n\n  float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce               = cw = stepDivCap/ Rx;\n  cn               = cs = stepDivCap/ Ry;\n  ct               = cb = stepDivCap/ Rz;\n\n  cc               = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int size = numCols * numRows * layers;\n  float* tIn   = (float*) calloc(size,sizeof(float));\n  float* pIn   = (float*) calloc(size,sizeof(float));\n  float* tCopy = (float*) malloc(size * sizeof(float));\n  float* tOut  = (float*) calloc(size,sizeof(float));\n\n  readinput(tIn,numRows, numCols, layers, tfile);\n  readinput(pIn,numRows, numCols, layers, pfile);\n\n  memcpy(tCopy,tIn, size * sizeof(float));\n\n  long long start = get_time();\n\n  float *d_tIn, *d_pIn, *d_tOut;\n  cudaMalloc((void**)&d_tIn, sizeof(float)*size);\n  cudaMalloc((void**)&d_pIn, sizeof(float)*size);\n  cudaMalloc((void**)&d_tOut, sizeof(float)*size);\n\n  cudaMemcpy(d_tIn, tIn,  sizeof(float)*size, cudaMemcpyHostToDevice); \n  cudaMemcpy(d_pIn, pIn,  sizeof(float)*size, cudaMemcpyHostToDevice); \n\n  dim3 gridDim(numCols/WG_SIZE_X, numRows/WG_SIZE_Y);\n  dim3 blockDim(WG_SIZE_X, WG_SIZE_Y);\n\n  cudaDeviceSynchronize();\n  auto kstart = std::chrono::steady_clock::now();\n\n  for(int j = 0; j < iterations; j++)\n  {\n    hotspot3d<<<gridDim, blockDim>>>(\n        d_tIn, d_pIn, d_tOut, numCols, numRows, layers,\n        ce, cw, cn, cs, ct, cb, cc, stepDivCap);\n\n    float* temp = d_tIn;\n    d_tIn = d_tOut;\n    d_tOut = temp;\n  }\n\n  cudaDeviceSynchronize();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n  printf(\"Average kernel execution time %f (us)\\n\", (ktime * 1e-3f) / iterations);\n\n  float* d_sel = (iterations & 01) ? d_tIn : d_tOut;\n  cudaMemcpy(tOut, d_sel,  sizeof(float)*size, cudaMemcpyDeviceToHost); \n  cudaFree(d_tIn);\n  cudaFree(d_pIn);\n  cudaFree(d_tOut);\n  long long stop = get_time();\n\n  float* answer = (float*)calloc(size, sizeof(float));\n  computeTempCPU(pIn, tCopy, answer, numCols, numRows, layers, Cap, Rx, Ry, Rz, dt, amb_temp, iterations);\n\n  float acc = accuracy(tOut,answer,numRows*numCols*layers);\n  float time = (float)((stop - start)/(1000.0 * 1000.0));\n  printf(\"Device offloading time: %.3f (s)\\n\",time);\n  printf(\"Root-mean-square error: %e\\n\",acc);\n\n  writeoutput(tOut,numRows,numCols,layers,ofile);\n\n  free(answer);\n  free(tIn);\n  free(pIn);\n  free(tCopy);\n  free(tOut);\n  return 0;\n}\n", "3D_helper.cu": "#include \"3D_helper.h\"\n\n#define STR_SIZE 256\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nvoid fatal(const char *s)\n{\n  fprintf(stderr, \"Error: %s\\n\", s);\n}\n\nvoid readinput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n\n  int i,j,k;\n  FILE *fp;\n  char str[STR_SIZE];\n  float val;\n\n  if( (fp  = fopen(file, \"r\" )) ==0 )\n    fatal( \"The file was not opened\" );\n\n  for (i=0; i <= grid_rows-1; i++) \n    for (j=0; j <= grid_cols-1; j++)\n      for (k=0; k <= layers-1; k++)\n      {\n        if (fgets(str, STR_SIZE, fp) == NULL) fatal(\"Error reading file\\n\");\n        if (feof(fp))\n          fatal(\"not enough lines in file\");\n        \n\n        if ((sscanf(str, \"%f\", &val) != 1))\n          fatal(\"invalid file format\");\n        vect[i*grid_cols+j+k*grid_rows*grid_cols] = val;\n      }\n  fclose(fp);  \n}\n\n\nvoid writeoutput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n  int i,j,k, index=0;\n  FILE *fp;\n  char str[STR_SIZE];\n\n  if( (fp = fopen(file, \"w\" )) == 0 )\n    printf( \"The file was not opened\\n\" );\n\n  for (i=0; i < grid_rows; i++) \n    for (j=0; j < grid_cols; j++)\n      for (k=0; k < layers; k++)\n      {\n        sprintf(str, \"%d\\t%g\\n\", index, vect[i*grid_cols+j+k*grid_rows*grid_cols]);\n        fputs(str,fp);\n        index++;\n      }\n\n  fclose(fp);  \n}\n\nvoid computeTempCPU(float *pIn, float* tIn, float *tOut, \n    int nx, int ny, int nz, float Cap, \n    float Rx, float Ry, float Rz, \n    float dt, float amb_temp, int numiter) \n{   float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce = cw =stepDivCap/ Rx;\n  cn = cs =stepDivCap/ Ry;\n  ct = cb =stepDivCap/ Rz;\n\n  cc = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int c,w,e,n,s,b,t;\n  int x,y,z;\n  int i = 0;\n  do{\n    for(z = 0; z < nz; z++)\n      for(y = 0; y < ny; y++)\n        for(x = 0; x < nx; x++)\n        {\n          c = x + y * nx + z * nx * ny;\n\n          w = (x == 0) ? c : c - 1;\n          e = (x == nx - 1) ? c : c + 1;\n          n = (y == 0) ? c : c - nx;\n          s = (y == ny - 1) ? c : c + nx;\n          b = (z == 0) ? c : c - nx * ny;\n          t = (z == nz - 1) ? c : c + nx * ny;\n\n\n          tOut[c] = tIn[c]*cc + tIn[n]*cn + tIn[s]*cs + tIn[e]*ce + tIn[w]*cw +\n                    tIn[t]*ct + tIn[b]*cb + (dt/Cap) * pIn[c] + ct*amb_temp;\n        }\n    float *temp = tIn;\n    tIn = tOut;\n    tOut = temp; \n    i++;\n  }\n  while(i < numiter);\n}\n\nfloat accuracy(float *arr1, float *arr2, int len)\n{\n  float err = 0.0; \n  int i;\n  for(i = 0; i < len; i++)\n  {\n    err += (arr1[i]-arr2[i]) * (arr1[i]-arr2[i]);\n  }\n\n  return (float)sqrt(err/len);\n}\n"}}
{"kernel_name": "hotspot3D", "parallel_api": "hip", "code": {"3D.cu": "#include <sys/types.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"3D_helper.h\"\n\n#define TOL      (0.001)\n#define STR_SIZE (256)\n#define MAX_PD   (3.0e6)\n\n\n\n#define PRECISION    0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI         100\n\n\n\n#define FACTOR_CHIP  0.5\n\n#define WG_SIZE_X (64)\n#define WG_SIZE_Y (4)\nfloat t_chip      = 0.0005;\nfloat chip_height = 0.016;\nfloat chip_width  = 0.016;\nfloat amb_temp    = 80.0;\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <rows/cols> <layers> <iterations> <powerFile> <tempFile> <outputFile>\\n\", argv[0]);\n  fprintf(stderr, \"\\t<rows/cols>  - number of rows/cols in the grid (positive integer)\\n\");\n  fprintf(stderr, \"\\t<layers>  - number of layers in the grid (positive integer)\\n\");\n\n  fprintf(stderr, \"\\t<iteration> - number of iterations\\n\");\n  fprintf(stderr, \"\\t<powerFile>  - name of the file containing the initial power values of each cell\\n\");\n  fprintf(stderr, \"\\t<tempFile>  - name of the file containing the initial temperature values of each cell\\n\");\n  fprintf(stderr, \"\\t<outputFile - output file\\n\");\n  exit(1);\n}\n\n__global__ void\nhotspot3d(\n    const float*__restrict__ tIn, \n    const float*__restrict__ pIn, \n          float*__restrict__ tOut,\n    const int numCols, \n    const int numRows, \n    const int layers,\n    const float ce, \n    const float cw,\n    const float cn, \n    const float cs,\n    const float ct,\n    const float cb,\n    const float cc,\n    const float stepDivCap)\n{\n  float amb_temp = 80.0;\n\n  int i = blockDim.x * blockIdx.x + threadIdx.x;\n  int j = blockDim.y * blockIdx.y + threadIdx.y;\n  int c = i + j * numCols;\n  int xy = numCols * numRows;\n\n  int W = (i == 0)        ? c : c - 1;\n  int E = (i == numCols-1)     ? c : c + 1;\n  int N = (j == 0)        ? c : c - numCols;\n  int S = (j == numRows-1)     ? c : c + numCols;\n\n  float temp1, temp2, temp3;\n  temp1 = temp2 = tIn[c];\n  temp3 = tIn[c+xy];\n  tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n    + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n  c += xy;\n  W += xy;\n  E += xy;\n  N += xy;\n  S += xy;\n\n  for (int k = 1; k < layers-1; ++k) {\n    temp1 = temp2;\n    temp2 = temp3;\n    temp3 = tIn[c+xy];\n    tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n      + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n    c += xy;\n    W += xy;\n    E += xy;\n    N += xy;\n    S += xy;\n  }\n  temp1 = temp2;\n  temp2 = temp3;\n  tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n    + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 7)\n  {\n    usage(argc,argv);\n  }\n\n  char *pfile, *tfile, *ofile;\n  int iterations = atoi(argv[3]);\n\n  pfile            = argv[4];\n  tfile            = argv[5];\n  ofile            = argv[6];\n  int numCols      = atoi(argv[1]);\n  int numRows      = atoi(argv[1]);\n  int layers       = atoi(argv[2]);\n\n  \n\n\n  float dx         = chip_height/numRows;\n  float dy         = chip_width/numCols;\n  float dz         = t_chip/layers;\n\n  float Cap        = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * dx * dy;\n  float Rx         = dy / (2.0 * K_SI * t_chip * dx);\n  float Ry         = dx / (2.0 * K_SI * t_chip * dy);\n  float Rz         = dz / (K_SI * dx * dy);\n\n  float max_slope  = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n  float dt         = PRECISION / max_slope;\n\n  float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce               = cw = stepDivCap/ Rx;\n  cn               = cs = stepDivCap/ Ry;\n  ct               = cb = stepDivCap/ Rz;\n\n  cc               = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int size = numCols * numRows * layers;\n  float* tIn   = (float*) calloc(size,sizeof(float));\n  float* pIn   = (float*) calloc(size,sizeof(float));\n  float* tCopy = (float*) malloc(size * sizeof(float));\n  float* tOut  = (float*) calloc(size,sizeof(float));\n\n  readinput(tIn,numRows, numCols, layers, tfile);\n  readinput(pIn,numRows, numCols, layers, pfile);\n\n  memcpy(tCopy,tIn, size * sizeof(float));\n\n  long long start = get_time();\n\n  float *d_tIn, *d_pIn, *d_tOut;\n  hipMalloc((void**)&d_tIn, sizeof(float)*size);\n  hipMalloc((void**)&d_pIn, sizeof(float)*size);\n  hipMalloc((void**)&d_tOut, sizeof(float)*size);\n\n  hipMemcpy(d_tIn, tIn,  sizeof(float)*size, hipMemcpyHostToDevice); \n  hipMemcpy(d_pIn, pIn,  sizeof(float)*size, hipMemcpyHostToDevice); \n\n  dim3 gridDim(numCols/WG_SIZE_X, numRows/WG_SIZE_Y);\n  dim3 blockDim(WG_SIZE_X, WG_SIZE_Y);\n\n  hipDeviceSynchronize();\n  auto kstart = std::chrono::steady_clock::now();\n\n  for(int j = 0; j < iterations; j++)\n  {\n    hipLaunchKernelGGL(hotspot3d, gridDim, blockDim, 0, 0, \n        d_tIn, d_pIn, d_tOut, numCols, numRows, layers,\n        ce, cw, cn, cs, ct, cb, cc, stepDivCap);\n\n    float* temp = d_tIn;\n    d_tIn = d_tOut;\n    d_tOut = temp;\n  }\n\n  hipDeviceSynchronize();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n  printf(\"Average kernel execution time %f (us)\\n\", (ktime * 1e-3f) / iterations);\n\n  float* d_sel = (iterations & 01) ? d_tIn : d_tOut;\n  hipMemcpy(tOut, d_sel,  sizeof(float)*size, hipMemcpyDeviceToHost); \n  hipFree(d_tIn);\n  hipFree(d_pIn);\n  hipFree(d_tOut);\n  long long stop = get_time();\n\n  float* answer = (float*)calloc(size, sizeof(float));\n  computeTempCPU(pIn, tCopy, answer, numCols, numRows, layers, Cap, Rx, Ry, Rz, dt, amb_temp, iterations);\n\n  float acc = accuracy(tOut,answer,numRows*numCols*layers);\n  float time = (float)((stop - start)/(1000.0 * 1000.0));\n  printf(\"Device offloading time: %.3f (s)\\n\",time);\n  printf(\"Root-mean-square error: %e\\n\",acc);\n\n  writeoutput(tOut,numRows,numCols,layers,ofile);\n\n  free(answer);\n  free(tIn);\n  free(pIn);\n  free(tCopy);\n  free(tOut);\n  return 0;\n}\n", "3D_helper.cu": "#include \"3D_helper.h\"\n\n#define STR_SIZE 256\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nvoid fatal(const char *s)\n{\n  fprintf(stderr, \"Error: %s\\n\", s);\n}\n\nvoid readinput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n\n  int i,j,k;\n  FILE *fp;\n  char str[STR_SIZE];\n  float val;\n\n  if( (fp  = fopen(file, \"r\" )) ==0 )\n    fatal( \"The file was not opened\" );\n\n  for (i=0; i <= grid_rows-1; i++) \n    for (j=0; j <= grid_cols-1; j++)\n      for (k=0; k <= layers-1; k++)\n      {\n        if (fgets(str, STR_SIZE, fp) == NULL) fatal(\"Error reading file\\n\");\n        if (feof(fp))\n          fatal(\"not enough lines in file\");\n        \n\n        if ((sscanf(str, \"%f\", &val) != 1))\n          fatal(\"invalid file format\");\n        vect[i*grid_cols+j+k*grid_rows*grid_cols] = val;\n      }\n  fclose(fp);  \n}\n\n\nvoid writeoutput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n  int i,j,k, index=0;\n  FILE *fp;\n  char str[STR_SIZE];\n\n  if( (fp = fopen(file, \"w\" )) == 0 )\n    printf( \"The file was not opened\\n\" );\n\n  for (i=0; i < grid_rows; i++) \n    for (j=0; j < grid_cols; j++)\n      for (k=0; k < layers; k++)\n      {\n        sprintf(str, \"%d\\t%g\\n\", index, vect[i*grid_cols+j+k*grid_rows*grid_cols]);\n        fputs(str,fp);\n        index++;\n      }\n\n  fclose(fp);  \n}\n\nvoid computeTempCPU(float *pIn, float* tIn, float *tOut, \n    int nx, int ny, int nz, float Cap, \n    float Rx, float Ry, float Rz, \n    float dt, float amb_temp, int numiter) \n{   float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce = cw =stepDivCap/ Rx;\n  cn = cs =stepDivCap/ Ry;\n  ct = cb =stepDivCap/ Rz;\n\n  cc = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int c,w,e,n,s,b,t;\n  int x,y,z;\n  int i = 0;\n  do{\n    for(z = 0; z < nz; z++)\n      for(y = 0; y < ny; y++)\n        for(x = 0; x < nx; x++)\n        {\n          c = x + y * nx + z * nx * ny;\n\n          w = (x == 0) ? c : c - 1;\n          e = (x == nx - 1) ? c : c + 1;\n          n = (y == 0) ? c : c - nx;\n          s = (y == ny - 1) ? c : c + nx;\n          b = (z == 0) ? c : c - nx * ny;\n          t = (z == nz - 1) ? c : c + nx * ny;\n\n\n          tOut[c] = tIn[c]*cc + tIn[n]*cn + tIn[s]*cs + tIn[e]*ce + tIn[w]*cw +\n                    tIn[t]*ct + tIn[b]*cb + (dt/Cap) * pIn[c] + ct*amb_temp;\n        }\n    float *temp = tIn;\n    tIn = tOut;\n    tOut = temp; \n    i++;\n  }\n  while(i < numiter);\n}\n\nfloat accuracy(float *arr1, float *arr2, int len)\n{\n  float err = 0.0; \n  int i;\n  for(i = 0; i < len; i++)\n  {\n    err += (arr1[i]-arr2[i]) * (arr1[i]-arr2[i]);\n  }\n\n  return (float)sqrt(err/len);\n}\n"}}
{"kernel_name": "hotspot3D", "parallel_api": "omp", "code": {"3D.cpp": "#include <sys/types.h>\n#include <chrono>\n#include <omp.h>\n#include \"3D_helper.h\"\n\n#define TOL      (0.001)\n#define STR_SIZE (256)\n#define MAX_PD   (3.0e6)\n\n\n\n#define PRECISION    0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI         100\n\n\n\n#define FACTOR_CHIP  0.5\n\nfloat t_chip      = 0.0005;\nfloat chip_height = 0.016;\nfloat chip_width  = 0.016;\nfloat amb_temp    = 80.0;\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <rows/cols> <layers> <iterations> <powerFile> <tempFile> <outputFile>\\n\", argv[0]);\n  fprintf(stderr, \"\\t<rows/cols>  - number of rows/cols in the grid (positive integer)\\n\");\n  fprintf(stderr, \"\\t<layers>  - number of layers in the grid (positive integer)\\n\");\n\n  fprintf(stderr, \"\\t<iteration> - number of iterations\\n\");\n  fprintf(stderr, \"\\t<powerFile>  - name of the file containing the initial power values of each cell\\n\");\n  fprintf(stderr, \"\\t<tempFile>  - name of the file containing the initial temperature values of each cell\\n\");\n  fprintf(stderr, \"\\t<outputFile - output file\\n\");\n  exit(1);\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 7)\n  {\n    usage(argc,argv);\n  }\n\n  char *pfile, *tfile, *ofile;\n  int iterations = atoi(argv[3]);\n\n  pfile            = argv[4];\n  tfile            = argv[5];\n  ofile            = argv[6];\n  int numCols      = atoi(argv[1]);\n  int numRows      = atoi(argv[1]);\n  int layers       = atoi(argv[2]);\n\n  \n\n\n  float dx         = chip_height/numRows;\n  float dy         = chip_width/numCols;\n  float dz         = t_chip/layers;\n\n  float Cap        = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * dx * dy;\n  float Rx         = dy / (2.0 * K_SI * t_chip * dx);\n  float Ry         = dx / (2.0 * K_SI * t_chip * dy);\n  float Rz         = dz / (K_SI * dx * dy);\n\n  float max_slope  = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n  float dt         = PRECISION / max_slope;\n\n  float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce               = cw                                              = stepDivCap/ Rx;\n  cn               = cs                                              = stepDivCap/ Ry;\n  ct               = cb                                              = stepDivCap/ Rz;\n  cc               = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int size = numCols * numRows * layers;\n  float* tIn      = (float*) calloc(size,sizeof(float));\n  float* pIn      = (float*) calloc(size,sizeof(float));\n  float* tCopy = (float*)malloc(size * sizeof(float));\n  float* tOut  = (float*) calloc(size,sizeof(float));\n  float* sel; \n\n\n  readinput(tIn,numRows, numCols, layers, tfile);\n  readinput(pIn,numRows, numCols, layers, pfile);\n\n  memcpy(tCopy,tIn, size * sizeof(float));\n\n  long long start = get_time();\n\n  #pragma omp target data map(to: tIn[0:size], pIn[0:size]) map(alloc: tOut[0:size])\n  {\n    auto kstart = std::chrono::steady_clock::now();\n\n    for(int j = 0; j < iterations; j++)\n    {\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n      for (int j = 0; j < numRows; j++)  \n      {\n        for (int i = 0; i < numCols; i++)  \n        {\n          float amb_temp = 80.0;\n\n          int c = i + j * numCols;\n          int xy = numCols * numRows;\n\n          int W = (i == 0)        ? c : c - 1;\n          int E = (i == numCols-1)     ? c : c + 1;\n          int N = (j == 0)        ? c : c - numCols;\n          int S = (j == numRows-1)     ? c : c + numCols;\n\n          float temp1, temp2, temp3;\n          temp1 = temp2 = tIn[c];\n          temp3 = tIn[c+xy];\n          tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n            + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n          c += xy;\n          W += xy;\n          E += xy;\n          N += xy;\n          S += xy;\n\n          for (int k = 1; k < layers-1; ++k) {\n            temp1 = temp2;\n            temp2 = temp3;\n            temp3 = tIn[c+xy];\n            tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n              + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n            c += xy;\n            W += xy;\n            E += xy;\n            N += xy;\n            S += xy;\n          }\n          temp1 = temp2;\n          temp2 = temp3;\n          tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n            + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n        }\n      }\n      auto temp = tIn;\n      tIn = tOut;\n      tOut = temp;\n    }\n\n    auto kend = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n    printf(\"Average kernel execution time %f (us)\\n\", (ktime * 1e-3f) / iterations);\n\n    if (iterations & 01) {\n     #pragma omp target update from (tIn[0:size])\n     sel = tIn;\n    }\n    else {\n     #pragma omp target update from (tOut[0:size])\n     sel = tOut;\n    }\n  } \n  long long stop = get_time();\n\n  float* answer = (float*)calloc(size, sizeof(float));\n  computeTempCPU(pIn, tCopy, answer, numCols, numRows, layers, Cap, Rx, Ry, Rz, dt, amb_temp, iterations);\n\n  float acc = accuracy(sel,answer,numRows*numCols*layers);\n  float time = (float)((stop - start)/(1000.0 * 1000.0));\n  printf(\"Device offloading time: %.3f (s)\\n\",time);\n  printf(\"Root-mean-square error: %e\\n\",acc);\n\n  writeoutput(tOut,numRows,numCols,layers,ofile);\n\n  free(answer);\n  free(tIn);\n  free(pIn);\n  free(tCopy);\n  free(tOut);\n  return 0;\n}\n", "3D_helper.cpp": "#include \"3D_helper.h\"\n\n#define STR_SIZE 256\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nvoid fatal(const char *s)\n{\n  fprintf(stderr, \"Error: %s\\n\", s);\n}\n\nvoid readinput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n\n  int i,j,k;\n  FILE *fp;\n  char str[STR_SIZE];\n  float val;\n\n  if( (fp  = fopen(file, \"r\" )) ==0 )\n    fatal( \"The file was not opened\" );\n\n  for (i=0; i <= grid_rows-1; i++) \n    for (j=0; j <= grid_cols-1; j++)\n      for (k=0; k <= layers-1; k++)\n      {\n        if (fgets(str, STR_SIZE, fp) == NULL) fatal(\"Error reading file\\n\");\n        if (feof(fp))\n          fatal(\"not enough lines in file\");\n        \n\n        if ((sscanf(str, \"%f\", &val) != 1))\n          fatal(\"invalid file format\");\n        vect[i*grid_cols+j+k*grid_rows*grid_cols] = val;\n      }\n  fclose(fp);  \n}\n\n\nvoid writeoutput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n  int i,j,k, index=0;\n  FILE *fp;\n  char str[STR_SIZE];\n\n  if( (fp = fopen(file, \"w\" )) == 0 )\n    printf( \"The file was not opened\\n\" );\n\n  for (i=0; i < grid_rows; i++) \n    for (j=0; j < grid_cols; j++)\n      for (k=0; k < layers; k++)\n      {\n        sprintf(str, \"%d\\t%g\\n\", index, vect[i*grid_cols+j+k*grid_rows*grid_cols]);\n        fputs(str,fp);\n        index++;\n      }\n\n  fclose(fp);  \n}\n\nvoid computeTempCPU(float *pIn, float* tIn, float *tOut, \n    int nx, int ny, int nz, float Cap, \n    float Rx, float Ry, float Rz, \n    float dt, float amb_temp, int numiter) \n{   float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce = cw =stepDivCap/ Rx;\n  cn = cs =stepDivCap/ Ry;\n  ct = cb =stepDivCap/ Rz;\n\n  cc = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int c,w,e,n,s,b,t;\n  int x,y,z;\n  int i = 0;\n  do{\n    for(z = 0; z < nz; z++)\n      for(y = 0; y < ny; y++)\n        for(x = 0; x < nx; x++)\n        {\n          c = x + y * nx + z * nx * ny;\n\n          w = (x == 0) ? c : c - 1;\n          e = (x == nx - 1) ? c : c + 1;\n          n = (y == 0) ? c : c - nx;\n          s = (y == ny - 1) ? c : c + nx;\n          b = (z == 0) ? c : c - nx * ny;\n          t = (z == nz - 1) ? c : c + nx * ny;\n\n\n          tOut[c] = tIn[c]*cc + tIn[n]*cn + tIn[s]*cs + tIn[e]*ce + tIn[w]*cw +\n                    tIn[t]*ct + tIn[b]*cb + (dt/Cap) * pIn[c] + ct*amb_temp;\n        }\n    float *temp = tIn;\n    tIn = tOut;\n    tOut = temp; \n    i++;\n  }\n  while(i < numiter);\n}\n\nfloat accuracy(float *arr1, float *arr2, int len)\n{\n  float err = 0.0; \n  int i;\n  for(i = 0; i < len; i++)\n  {\n    err += (arr1[i]-arr2[i]) * (arr1[i]-arr2[i]);\n  }\n\n  return (float)sqrt(err/len);\n}\n"}}
{"kernel_name": "hotspot3D", "parallel_api": "serial", "code": {"3D.cpp": "#include <sys/types.h>\n#include <chrono>\n#include \"3D_helper.h\"\n\n#define TOL      (0.001)\n#define STR_SIZE (256)\n#define MAX_PD   (3.0e6)\n\n\n\n#define PRECISION    0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI         100\n\n\n\n#define FACTOR_CHIP  0.5\n\nfloat t_chip      = 0.0005;\nfloat chip_height = 0.016;\nfloat chip_width  = 0.016;\nfloat amb_temp    = 80.0;\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <rows/cols> <layers> <iterations> <powerFile> <tempFile> <outputFile>\\n\", argv[0]);\n  fprintf(stderr, \"\\t<rows/cols>  - number of rows/cols in the grid (positive integer)\\n\");\n  fprintf(stderr, \"\\t<layers>  - number of layers in the grid (positive integer)\\n\");\n\n  fprintf(stderr, \"\\t<iteration> - number of iterations\\n\");\n  fprintf(stderr, \"\\t<powerFile>  - name of the file containing the initial power values of each cell\\n\");\n  fprintf(stderr, \"\\t<tempFile>  - name of the file containing the initial temperature values of each cell\\n\");\n  fprintf(stderr, \"\\t<outputFile - output file\\n\");\n  exit(1);\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 7)\n  {\n    usage(argc,argv);\n  }\n\n  char *pfile, *tfile, *ofile;\n  int iterations = atoi(argv[3]);\n\n  pfile            = argv[4];\n  tfile            = argv[5];\n  ofile            = argv[6];\n  int numCols      = atoi(argv[1]);\n  int numRows      = atoi(argv[1]);\n  int layers       = atoi(argv[2]);\n\n  \n\n\n  float dx         = chip_height/numRows;\n  float dy         = chip_width/numCols;\n  float dz         = t_chip/layers;\n\n  float Cap        = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * dx * dy;\n  float Rx         = dy / (2.0 * K_SI * t_chip * dx);\n  float Ry         = dx / (2.0 * K_SI * t_chip * dy);\n  float Rz         = dz / (K_SI * dx * dy);\n\n  float max_slope  = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n  float dt         = PRECISION / max_slope;\n\n  float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce               = cw                                              = stepDivCap/ Rx;\n  cn               = cs                                              = stepDivCap/ Ry;\n  ct               = cb                                              = stepDivCap/ Rz;\n  cc               = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int size = numCols * numRows * layers;\n  float* tIn      = (float*) calloc(size,sizeof(float));\n  float* pIn      = (float*) calloc(size,sizeof(float));\n  float* tCopy = (float*)malloc(size * sizeof(float));\n  float* tOut  = (float*) calloc(size,sizeof(float));\n  float* sel; \n\n\n  readinput(tIn,numRows, numCols, layers, tfile);\n  readinput(pIn,numRows, numCols, layers, pfile);\n\n  memcpy(tCopy,tIn, size * sizeof(float));\n\n  long long start = get_time();\n\n    {\n    auto kstart = std::chrono::steady_clock::now();\n\n    for(int j = 0; j < iterations; j++)\n    {\n            for (int j = 0; j < numRows; j++)  \n      {\n        for (int i = 0; i < numCols; i++)  \n        {\n          float amb_temp = 80.0;\n\n          int c = i + j * numCols;\n          int xy = numCols * numRows;\n\n          int W = (i == 0)        ? c : c - 1;\n          int E = (i == numCols-1)     ? c : c + 1;\n          int N = (j == 0)        ? c : c - numCols;\n          int S = (j == numRows-1)     ? c : c + numCols;\n\n          float temp1, temp2, temp3;\n          temp1 = temp2 = tIn[c];\n          temp3 = tIn[c+xy];\n          tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n            + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n          c += xy;\n          W += xy;\n          E += xy;\n          N += xy;\n          S += xy;\n\n          for (int k = 1; k < layers-1; ++k) {\n            temp1 = temp2;\n            temp2 = temp3;\n            temp3 = tIn[c+xy];\n            tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n              + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n            c += xy;\n            W += xy;\n            E += xy;\n            N += xy;\n            S += xy;\n          }\n          temp1 = temp2;\n          temp2 = temp3;\n          tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n            + cn * tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * pIn[c] + ct * amb_temp;\n        }\n      }\n      auto temp = tIn;\n      tIn = tOut;\n      tOut = temp;\n    }\n\n    auto kend = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n    printf(\"Average kernel execution time %f (us)\\n\", (ktime * 1e-3f) / iterations);\n\n    if (iterations & 01) {\n          sel = tIn;\n    }\n    else {\n          sel = tOut;\n    }\n  } \n  long long stop = get_time();\n\n  float* answer = (float*)calloc(size, sizeof(float));\n  computeTempCPU(pIn, tCopy, answer, numCols, numRows, layers, Cap, Rx, Ry, Rz, dt, amb_temp, iterations);\n\n  float acc = accuracy(sel,answer,numRows*numCols*layers);\n  float time = (float)((stop - start)/(1000.0 * 1000.0));\n  printf(\"Device offloading time: %.3f (s)\\n\",time);\n  printf(\"Root-mean-square error: %e\\n\",acc);\n\n  writeoutput(tOut,numRows,numCols,layers,ofile);\n\n  free(answer);\n  free(tIn);\n  free(pIn);\n  free(tCopy);\n  free(tOut);\n  return 0;\n}", "3D_helper.cpp": "#include \"3D_helper.h\"\n\n#define STR_SIZE 256\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nvoid fatal(const char *s)\n{\n  fprintf(stderr, \"Error: %s\\n\", s);\n}\n\nvoid readinput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n\n  int i,j,k;\n  FILE *fp;\n  char str[STR_SIZE];\n  float val;\n\n  if( (fp  = fopen(file, \"r\" )) ==0 )\n    fatal( \"The file was not opened\" );\n\n  for (i=0; i <= grid_rows-1; i++) \n    for (j=0; j <= grid_cols-1; j++)\n      for (k=0; k <= layers-1; k++)\n      {\n        if (fgets(str, STR_SIZE, fp) == NULL) fatal(\"Error reading file\\n\");\n        if (feof(fp))\n          fatal(\"not enough lines in file\");\n        \n\n        if ((sscanf(str, \"%f\", &val) != 1))\n          fatal(\"invalid file format\");\n        vect[i*grid_cols+j+k*grid_rows*grid_cols] = val;\n      }\n  fclose(fp);  \n}\n\n\nvoid writeoutput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n  int i,j,k, index=0;\n  FILE *fp;\n  char str[STR_SIZE];\n\n  if( (fp = fopen(file, \"w\" )) == 0 )\n    printf( \"The file was not opened\\n\" );\n\n  for (i=0; i < grid_rows; i++) \n    for (j=0; j < grid_cols; j++)\n      for (k=0; k < layers; k++)\n      {\n        sprintf(str, \"%d\\t%g\\n\", index, vect[i*grid_cols+j+k*grid_rows*grid_cols]);\n        fputs(str,fp);\n        index++;\n      }\n\n  fclose(fp);  \n}\n\nvoid computeTempCPU(float *pIn, float* tIn, float *tOut, \n    int nx, int ny, int nz, float Cap, \n    float Rx, float Ry, float Rz, \n    float dt, float amb_temp, int numiter) \n{   float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce = cw =stepDivCap/ Rx;\n  cn = cs =stepDivCap/ Ry;\n  ct = cb =stepDivCap/ Rz;\n\n  cc = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int c,w,e,n,s,b,t;\n  int x,y,z;\n  int i = 0;\n  do{\n    for(z = 0; z < nz; z++)\n      for(y = 0; y < ny; y++)\n        for(x = 0; x < nx; x++)\n        {\n          c = x + y * nx + z * nx * ny;\n\n          w = (x == 0) ? c : c - 1;\n          e = (x == nx - 1) ? c : c + 1;\n          n = (y == 0) ? c : c - nx;\n          s = (y == ny - 1) ? c : c + nx;\n          b = (z == 0) ? c : c - nx * ny;\n          t = (z == nz - 1) ? c : c + nx * ny;\n\n\n          tOut[c] = tIn[c]*cc + tIn[n]*cn + tIn[s]*cs + tIn[e]*ce + tIn[w]*cw +\n                    tIn[t]*ct + tIn[b]*cb + (dt/Cap) * pIn[c] + ct*amb_temp;\n        }\n    float *temp = tIn;\n    tIn = tOut;\n    tOut = temp; \n    i++;\n  }\n  while(i < numiter);\n}\n\nfloat accuracy(float *arr1, float *arr2, int len)\n{\n  float err = 0.0; \n  int i;\n  for(i = 0; i < len; i++)\n  {\n    err += (arr1[i]-arr2[i]) * (arr1[i]-arr2[i]);\n  }\n\n  return (float)sqrt(err/len);\n}"}}
{"kernel_name": "hotspot3D", "parallel_api": "sycl", "code": {"3D.cpp": "#include <sys/types.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"3D_helper.h\"\n\n#define TOL      (0.001)\n#define STR_SIZE (256)\n#define MAX_PD   (3.0e6)\n\n\n\n#define PRECISION    0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI         100\n\n\n\n#define FACTOR_CHIP\t0.5\n\n#define WG_SIZE_X (64)\n#define WG_SIZE_Y (4)\nfloat t_chip      = 0.0005;\nfloat chip_height = 0.016;\nfloat chip_width  = 0.016;\nfloat amb_temp    = 80.0;\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <rows/cols> <layers> <iterations> <powerFile> <tempFile> <outputFile>\\n\", argv[0]);\n  fprintf(stderr, \"\\t<rows/cols>  - number of rows/cols in the grid (positive integer)\\n\");\n  fprintf(stderr, \"\\t<layers>  - number of layers in the grid (positive integer)\\n\");\n\n  fprintf(stderr, \"\\t<iteration> - number of iterations\\n\");\n  fprintf(stderr, \"\\t<powerFile>  - name of the file containing the initial power values of each cell\\n\");\n  fprintf(stderr, \"\\t<tempFile>  - name of the file containing the initial temperature values of each cell\\n\");\n  fprintf(stderr, \"\\t<outputFile - output file\\n\");\n  exit(1);\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 7)\n  {\n    usage(argc,argv);\n  }\n\n  char *pfile, *tfile, *ofile;\n  int iterations = atoi(argv[3]);\n\n  pfile            = argv[4];\n  tfile            = argv[5];\n  ofile            = argv[6];\n  int numCols      = atoi(argv[1]);\n  int numRows      = atoi(argv[1]);\n  int layers       = atoi(argv[2]);\n\n  \n\n\n  float dx         = chip_height/numRows;\n  float dy         = chip_width/numCols;\n  float dz         = t_chip/layers;\n\n  float Cap        = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * dx * dy;\n  float Rx         = dy / (2.0 * K_SI * t_chip * dx);\n  float Ry         = dx / (2.0 * K_SI * t_chip * dy);\n  float Rz         = dz / (K_SI * dx * dy);\n\n  float max_slope  = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n  float dt         = PRECISION / max_slope;\n\n  float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce               = cw                                              = stepDivCap/ Rx;\n  cn               = cs                                              = stepDivCap/ Ry;\n  ct               = cb                                              = stepDivCap/ Rz;\n\n  cc               = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int size = numCols * numRows * layers;\n  float* tIn   = (float*) calloc(size,sizeof(float));\n  float* pIn   = (float*) calloc(size,sizeof(float));\n  float* tCopy = (float*) malloc(size * sizeof(float));\n  float* tOut  = (float*) calloc(size,sizeof(float));\n\n  readinput(tIn,numRows, numCols, layers, tfile);\n  readinput(pIn,numRows, numCols, layers, pfile);\n\n  size_t global_work_size[2];                   \n  size_t local_work_size[2];\n  memcpy(tCopy,tIn, size * sizeof(float));\n\n  long long start = get_time();\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_tIn = sycl::malloc_device<float>(size, q);\n  float *d_pIn = sycl::malloc_device<float>(size, q);\n  float *d_tOut = sycl::malloc_device<float>(size, q);\n\n  q.memcpy(d_tIn, tIn, sizeof(float)*size);\n  q.memcpy(d_pIn, pIn, sizeof(float)*size);\n\n  global_work_size[1] = numCols;\n  global_work_size[0] = numRows;\n\n  local_work_size[1] = WG_SIZE_X;\n  local_work_size[0] = WG_SIZE_Y;\n\n  sycl::range<2> gws (global_work_size[0], global_work_size[1]);\n  sycl::range<2> lws (local_work_size[0], local_work_size[1]);\n\n  q.wait();\n  auto kstart = std::chrono::steady_clock::now();\n\n  for(int j = 0; j < iterations; j++)\n  {\n    q.submit([&](sycl::handler& cgh) {\n      cgh.parallel_for<class hotspot>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n          #include \"kernel_hotspot.sycl\"\n      });\n    });\n\n    float* temp = d_tIn;\n    d_tIn = d_tOut;\n    d_tOut = temp;\n  }\n\n  q.wait();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::nanoseconds>(kend - kstart).count();\n  printf(\"Average kernel execution time %f (us)\\n\", (ktime * 1e-3f) / iterations);\n\n  float* d_sel = (iterations & 01) ? d_tIn : d_tOut;\n  q.memcpy(tOut, d_sel, sizeof(float)*size).wait();\n\n  sycl::free(d_tIn, q);\n  sycl::free(d_pIn, q);\n  sycl::free(d_tOut, q);\n\n  long long stop = get_time();\n\n  float* answer = (float*)calloc(size, sizeof(float));\n  computeTempCPU(pIn, tCopy, answer, numCols, numRows, layers, Cap, Rx, Ry, Rz, dt, amb_temp, iterations);\n\n  float acc = accuracy(tOut,answer,numRows*numCols*layers);\n  float time = (float)((stop - start)/(1000.0 * 1000.0));\n  printf(\"Device offloading time: %.3f (s)\\n\",time);\n  printf(\"Root-mean-square error: %e\\n\",acc);\n\n  writeoutput(tOut,numRows,numCols,layers,ofile);\n\n  free(answer);\n  free(tIn);\n  free(pIn);\n  free(tCopy);\n  free(tOut);\n  return 0;\n}\n", "3D_helper.cpp": "#include \"3D_helper.h\"\n\n#define STR_SIZE 256\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nvoid fatal(const char *s)\n{\n  fprintf(stderr, \"Error: %s\\n\", s);\n}\n\nvoid readinput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n\n  int i,j,k;\n  FILE *fp;\n  char str[STR_SIZE];\n  float val;\n\n  if( (fp  = fopen(file, \"r\" )) ==0 )\n    fatal( \"The file was not opened\" );\n\n  for (i=0; i <= grid_rows-1; i++) \n    for (j=0; j <= grid_cols-1; j++)\n      for (k=0; k <= layers-1; k++)\n      {\n        if (fgets(str, STR_SIZE, fp) == NULL) fatal(\"Error reading file\\n\");\n        if (feof(fp))\n          fatal(\"not enough lines in file\");\n        \n\n        if ((sscanf(str, \"%f\", &val) != 1))\n          fatal(\"invalid file format\");\n        vect[i*grid_cols+j+k*grid_rows*grid_cols] = val;\n      }\n  fclose(fp);  \n}\n\n\nvoid writeoutput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n  int i,j,k, index=0;\n  FILE *fp;\n  char str[STR_SIZE];\n\n  if( (fp = fopen(file, \"w\" )) == 0 )\n    printf( \"The file was not opened\\n\" );\n\n  for (i=0; i < grid_rows; i++) \n    for (j=0; j < grid_cols; j++)\n      for (k=0; k < layers; k++)\n      {\n        sprintf(str, \"%d\\t%g\\n\", index, vect[i*grid_cols+j+k*grid_rows*grid_cols]);\n        fputs(str,fp);\n        index++;\n      }\n\n  fclose(fp);  \n}\n\nvoid computeTempCPU(float *pIn, float* tIn, float *tOut, \n    int nx, int ny, int nz, float Cap, \n    float Rx, float Ry, float Rz, \n    float dt, float amb_temp, int numiter) \n{   float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce = cw =stepDivCap/ Rx;\n  cn = cs =stepDivCap/ Ry;\n  ct = cb =stepDivCap/ Rz;\n\n  cc = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n  int c,w,e,n,s,b,t;\n  int x,y,z;\n  int i = 0;\n  do{\n    for(z = 0; z < nz; z++)\n      for(y = 0; y < ny; y++)\n        for(x = 0; x < nx; x++)\n        {\n          c = x + y * nx + z * nx * ny;\n\n          w = (x == 0) ? c : c - 1;\n          e = (x == nx - 1) ? c : c + 1;\n          n = (y == 0) ? c : c - nx;\n          s = (y == ny - 1) ? c : c + nx;\n          b = (z == 0) ? c : c - nx * ny;\n          t = (z == nz - 1) ? c : c + nx * ny;\n\n\n          tOut[c] = tIn[c]*cc + tIn[n]*cn + tIn[s]*cs + tIn[e]*ce + tIn[w]*cw +\n                    tIn[t]*ct + tIn[b]*cb + (dt/Cap) * pIn[c] + ct*amb_temp;\n        }\n    float *temp = tIn;\n    tIn = tOut;\n    tOut = temp; \n    i++;\n  }\n  while(i < numiter);\n}\n\nfloat accuracy(float *arr1, float *arr2, int len)\n{\n  float err = 0.0; \n  int i;\n  for(i = 0; i < len; i++)\n  {\n    err += (arr1[i]-arr2[i]) * (arr1[i]-arr2[i]);\n  }\n\n  return (float)sqrt(err/len);\n}\n", "kernel_hotspot.sycl": "  float amb_temp = 80.0;\n\n  int i = item.get_global_id(1);\n  int j = item.get_global_id(0);\n  int c = i + j * numCols;\n  int xy = numCols * numRows;\n\n  int W = (i == 0)         ? c : c - 1;\n  int E = (i == numCols-1) ? c : c + 1;\n  int N = (j == 0)         ? c : c - numCols;\n  int S = (j == numRows-1) ? c : c + numCols;\n\n  float temp1, temp2, temp3;\n  temp1 = temp2 = d_tIn[c];\n  temp3 = d_tIn[c+xy];\n  d_tOut[c] = cc * temp2 + cw * d_tIn[W] + ce * d_tIn[E] + cs * d_tIn[S]\n    + cn * d_tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * d_pIn[c] + ct * amb_temp;\n  c += xy;\n  W += xy;\n  E += xy;\n  N += xy;\n  S += xy;\n\n  for (int k = 1; k < layers-1; ++k) {\n      temp1 = temp2;\n      temp2 = temp3;\n      temp3 = d_tIn[c+xy];\n      d_tOut[c] = cc * temp2 + cw * d_tIn[W] + ce * d_tIn[E] + cs * d_tIn[S]\n        + cn * d_tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * d_pIn[c] + ct * amb_temp;\n      c += xy;\n      W += xy;\n      E += xy;\n      N += xy;\n      S += xy;\n  }\n  temp1 = temp2;\n  temp2 = temp3;\n  d_tOut[c] = cc * temp2 + cw * d_tIn[W] + ce * d_tIn[E] + cs * d_tIn[S]\n    + cn * d_tIn[N] + cb * temp1 + ct * temp3 + stepDivCap * d_pIn[c] + ct * amb_temp;\n"}}
{"kernel_name": "jaccard", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <cuda.h>\n#include <stdio.h>\n#include <algorithm> \n#include <iostream> \n#include <vector> \n#include <chrono>\n\nusing namespace std; \n\n#define MAX_KERNEL_THREADS 256\n#define mask 0xFFFFFFFF\n\n\n\ntypedef float vtype;\ntypedef vector<vector<vtype>> matrix; \n\ntemplate<typename T>\n__device__\nT parallel_prefix_sum(const int n, const int *ind, const T *w) \n{\n\n  T sum = 0.0;\n  T last;\n\n  int mn =(((n+blockDim.x-1)/blockDim.x)*blockDim.x); \n\n  for (int i=threadIdx.x; i<mn; i+=blockDim.x) {\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    bool valid  = i<n;\n\n    \n\n    \n\n    \n\n\n    \n\n    last = __shfl_sync(mask, sum, blockDim.x-1, blockDim.x);\n\n    \n\n    sum = (valid) ? w[ind[i]] : 0.0;\n\n    \n\n    for (int j=1; j<blockDim.x; j*=2) {\n      T v = __shfl_up_sync(mask, sum, j, blockDim.x);\n      if (threadIdx.x >= j) sum += v;\n    }\n    \n\n    sum += last;\n    \n\n  }\n  \n\n  last = __shfl_sync(mask, sum, blockDim.x-1, blockDim.x);\n\n  return last;\n}\n\n\n\ntemplate<bool weighted, typename T>\n__global__ void \njaccard_row_sum(const int n,\n                const int *__restrict__ csrPtr,\n                const int *__restrict__ csrInd,\n                const T *__restrict__ w,\n                      T *__restrict__ work)\n{\n  for (int row=threadIdx.y+blockIdx.y*blockDim.y; row<n; row+=gridDim.y*blockDim.y) {\n    int start = csrPtr[row];\n    int end   = csrPtr[row+1];\n    int length= end-start;\n    \n\n    if (weighted) {\n      T sum = parallel_prefix_sum(length, csrInd + start, w); \n      if (threadIdx.x == 0) work[row] = sum;\n    }\n    else {\n      work[row] = (T)length;\n    }\n  }\n}\n\n\n\n\n\ntemplate<bool weighted, typename T>\n__global__ void\njaccard_is(const int n, const int e,\n           const int *__restrict__ csrPtr,\n           const int *__restrict__ csrInd,\n           const T *__restrict__ v,\n           const T *__restrict__ work,\n                 T *__restrict__ weight_i,\n                 T *__restrict__ weight_s) \n{\n  for (int row=threadIdx.z+blockIdx.z*blockDim.z; row<n; row+=gridDim.z*blockDim.z) {  \n    for (int j=csrPtr[row]+threadIdx.y+blockIdx.y*blockDim.y;\n             j<csrPtr[row+1]; j+=gridDim.y*blockDim.y) { \n      int col = csrInd[j];\n      \n\n      int Ni = csrPtr[row+1] - csrPtr[row];\n      int Nj = csrPtr[col+1] - csrPtr[col];\n      int ref= (Ni < Nj) ? row : col;\n      int cur= (Ni < Nj) ? col : row;\n\n      \n\n      weight_s[j] = work[row] + work[col];\n\n      \n\n      \n\n      for (int i=csrPtr[ref]+threadIdx.x+blockIdx.x*blockDim.x; i<csrPtr[ref+1]; i+=gridDim.x*blockDim.x) {\n        int match  =-1;           \n        int ref_col = csrInd[i];\n        T ref_val = weighted ? v[ref_col] : (T)1.0;\n\n        \n\n        int left = csrPtr[cur]; \n        int right= csrPtr[cur+1]-1; \n        while(left <= right){\n          int middle = (left+right)>>1; \n          int cur_col= csrInd[middle];\n          if (cur_col > ref_col) {\n            right=middle-1;\n          }\n          else if (cur_col < ref_col) {\n            left=middle+1;\n          }\n          else {\n            match = middle; \n            break; \n          }\n        }            \n\n        \n\n        if (match != -1){\n          atomicAdd(&weight_i[j],ref_val);\n        }\n      }\n    }\n  }\n}\n\ntemplate<bool weighted, typename T>\n__global__ void \njaccard_jw(const int e,\n    const T *__restrict__ csrVal,\n    const T gamma,\n    const T *__restrict__ weight_i,\n    const T *__restrict__ weight_s,\n          T *__restrict__ weight_j) \n{\n  for (int j=threadIdx.x+blockIdx.x*blockDim.x; j<e; j+=gridDim.x*blockDim.x) {  \n    T Wi =  weight_i[j];\n    T Ws =  weight_s[j];\n    weight_j[j] = (gamma*csrVal[j])* (Wi/(Ws-Wi));\n  }\n}\n\ntemplate <bool weighted, typename T>\n__global__ void \nfill(const int e, T* w, const T value) \n{\n  for (int j=threadIdx.x+blockIdx.x*blockDim.x; j<e; j+=gridDim.x*blockDim.x) {  \n    \n\n    \n\n    \n\n    w[j] = weighted ? (T)(j+1)/e : value; \n  }\n}\n\ntemplate <bool weighted, typename T>\nvoid jaccard_weight (const int iteration, const int n, const int e, \n    int* csr_ptr, int* csr_ind, T* csr_val)\n{\n  const T gamma = (T)0.46;  \n\n\n  T *d_weight_i, \n    *d_weight_s, \n    *d_weight_j, \n    *d_work;\n  int *d_csrInd;\n  int *d_csrPtr;\n  T *d_csrVal;\n\n#ifdef DEBUG\n  T* weight_i = (T*) malloc (sizeof(T) * e);\n  T* weight_s = (T*) malloc (sizeof(T) * e);\n  T* work = (T*) malloc (sizeof(T) * n);\n#endif\n  T* weight_j = (T*) malloc (sizeof(T) * e);\n\n  cudaMalloc ((void**)&d_work, sizeof(T) * n);\n  cudaMalloc ((void**)&d_weight_i, sizeof(T) * e);\n  cudaMalloc ((void**)&d_weight_s, sizeof(T) * e);\n  cudaMalloc ((void**)&d_weight_j, sizeof(T) * e);\n  cudaMalloc ((void**)&d_csrVal, sizeof(T) * e);\n  cudaMalloc ((void**)&d_csrPtr, sizeof(int) * (n+1));\n  cudaMalloc ((void**)&d_csrInd, sizeof(int) * e);\n\n  cudaMemcpy(d_csrPtr, csr_ptr, sizeof(int) * (n+1), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_csrInd, csr_ind, sizeof(int) * e, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_csrVal, csr_val, sizeof(T) * e, cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iteration; i++) {\n    dim3 nthreads, nblocks; \n\n\n    nthreads.x = MAX_KERNEL_THREADS;\n    nthreads.y = 1; \n    nthreads.z = 1; \n    nblocks.x  = (e+MAX_KERNEL_THREADS-1) / MAX_KERNEL_THREADS;\n    nblocks.y  = 1;\n    nblocks.z  = 1; \n\n    fill<weighted, T><<<nblocks, nthreads>>>(e, d_weight_j, (T)1.0);\n#ifdef DEBUG\n    cudaMemcpy(weight_j, d_weight_j, sizeof(T) * e, cudaMemcpyDeviceToHost);\n    for (int i = 0; i < e; i++) printf(\"wj: %d %f\\n\", i, weight_j[i]);\n#endif\n\n    \n\n    fill<false, T><<<nblocks, nthreads>>>(e, d_weight_i, (T)0.0);\n\n    \n\n    const int y = 4;\n    nthreads.x = 64/y;\n    nthreads.y = y; \n    nthreads.z = 1; \n    nblocks.x  = 1; \n    nblocks.y  = (n + nthreads.y - 1) / nthreads.y;  \n\n    nblocks.z  = 1; \n    jaccard_row_sum<weighted,T><<<nblocks,nthreads>>>(n, d_csrPtr, d_csrInd, d_weight_j, d_work);\n\n#ifdef DEBUG\n    cudaMemcpy(work, d_work, sizeof(T) * n, cudaMemcpyDeviceToHost);\n    for (int i = 0; i < n; i++) printf(\"work: %d %f\\n\", i, work[i]);\n#endif\n\n    \n\n    \n\n    nthreads.x = 32/y;\n    nthreads.y = y;\n    nthreads.z = 8;\n    nblocks.x  = 1;\n    nblocks.y  = 1;\n    nblocks.z  = (n + nthreads.z - 1)/nthreads.z; \n\n    jaccard_is<weighted,T><<<nblocks,nthreads>>>(n, e, d_csrPtr,\n        d_csrInd, d_weight_j, d_work, d_weight_i, d_weight_s);\n\n#ifdef DEBUG\n    cudaMemcpy(weight_i, d_weight_i, sizeof(T) * e, cudaMemcpyDeviceToHost);\n    cudaMemcpy(weight_s, d_weight_s, sizeof(T) * e, cudaMemcpyDeviceToHost);\n    for (int i = 0; i < e; i++) printf(\"wi: %d %f\\n\", i, weight_i[i]);\n    for (int i = 0; i < e; i++) printf(\"ws: %d %f\\n\", i, weight_s[i]);\n#endif\n\n    \n\n    nthreads.x = std::min(e, MAX_KERNEL_THREADS); \n    nthreads.y = 1; \n    nthreads.z = 1;  \n    nblocks.x  = (e + nthreads.x - 1)/nthreads.x;  \n\n    nblocks.y  = 1; \n    nblocks.z  = 1;\n    jaccard_jw<weighted,T><<<nblocks,nthreads>>>(e, \n        d_csrVal, gamma, d_weight_i, d_weight_s, d_weight_j);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  cout << \"Average execution time of kernels: \" << (time * 1e-9f) / iteration << \" (s)\\n\";\n\n  cudaMemcpy(weight_j, d_weight_j, sizeof(T) * e, cudaMemcpyDeviceToHost);\n#ifdef DEBUG\n  \n\n  float error; \n\n  if (weighted)\n    error = std::fabs(weight_j[0] - 0.306667) +\n            std::fabs(weight_j[1] - 0.000000) +\n            std::fabs(weight_j[2] - 3.680000) +\n            std::fabs(weight_j[3] - 1.380000) +\n            std::fabs(weight_j[4] - 0.788571) +\n            std::fabs(weight_j[5] - 0.460000);\n\n  else\n    error = std::fabs(weight_j[0] - 0.230000) +\n            std::fabs(weight_j[1] - 0.000000) +\n            std::fabs(weight_j[2] - 3.680000) +\n            std::fabs(weight_j[3] - 1.380000) +\n            std::fabs(weight_j[4] - 0.920000) +\n            std::fabs(weight_j[5] - 0.460000);\n\n  if (error > 1e-5) {\n    for (int i = 0; i < e; i++) printf(\"wj: %d %f\\n\", i, weight_j[i]);\n    printf(\"FAIL\");\n  } else {\n    printf(\"PASS\");\n  }\n  printf(\"\\n\");\n#endif\n\n  cudaFree (d_work);\n  cudaFree (d_weight_i);\n  cudaFree (d_weight_s);\n  cudaFree (d_weight_j);\n  cudaFree (d_csrInd);\n  cudaFree (d_csrVal);\n  cudaFree (d_csrPtr);\n  free(weight_j);\n#ifdef DEBUG\n  free(weight_i);\n  free(weight_s);\n  free(work);\n#endif\n}\n\n\n\nvoid printMatrix(const matrix& M) \n{ \n  int m = M.size(); \n  int n = M[0].size(); \n  for (int i = 0; i < m; i++) { \n    for (int j = 0; j < n; j++) \n      cout << M[i][j] << \" \";     \n    cout << endl; \n  } \n} \n\ntemplate <typename T>\nvoid printVector(const vector<T>& V, char* msg) \n{ \n  cout << msg << \"[ \"; \n  for_each(V.begin(), V.end(), [](int a) { cout << a << \" \"; }); \n  cout << \"]\" << endl; \n} \n\n\n\nint main(int argc, char** argv) \n{ \n  int iteration = 10;\n\n#ifdef DEBUG\n  matrix M  = { \n    { 0, 0, 0, 1}, \n    { 5, 8, 0, 0}, \n    { 0, 0, 3, 0}, \n    { 0, 6, 0, 1} \n  }; \n#else\n\n  int numRow = atoi(argv[1]);\n  int numCol = atoi(argv[2]);\n  iteration = atoi(argv[3]);\n\n  srand(2);\n\n  matrix M;\n  vector<vtype> rowElems(numCol);\n  for (int r = 0; r < numRow; r++) {\n    for (int c = 0; c < numCol; c++)\n      rowElems[c] = rand() % 10;\n    M.push_back(rowElems);\n  }\n#endif\n\n  int row = M.size();\n  int col = M[0].size();\n  printf(\"Number of matrix rows and cols: %d %d\\n\", row, col);\n  vector<vtype> csr_val;\n  vector<int> csr_ptr = { 0 }; \n\n  vector<int> csr_ind;\n  int nnz = 0; \n\n\n  for (int i = 0; i < row; i++) { \n    for (int j = 0; j < col; j++) { \n      if (M[i][j] != (vtype)0) { \n        csr_val.push_back(M[i][j]); \n        csr_ind.push_back(j); \n        nnz++; \n      } \n    } \n    csr_ptr.push_back(nnz); \n  } \n\n  \n\n  if (row <= 16 && col <= 16) {\n    printMatrix(M); \n    printVector(csr_val, (char*)\"values = \"); \n    printVector(csr_ptr, (char*)\"row pointer = \"); \n    printVector(csr_ind, (char*)\"col indices = \"); \n  }\n\n  jaccard_weight<true, vtype>(iteration, row, nnz, csr_ptr.data(), csr_ind.data(), csr_val.data());\n  jaccard_weight<false, vtype>(iteration, row, nnz, csr_ptr.data(), csr_ind.data(), csr_val.data());\n\n  return 0; \n} \n\n"}}
{"kernel_name": "jaccard", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <algorithm> \n#include <iostream> \n#include <vector> \n#include <hip/hip_runtime.h>\n\nusing namespace std; \n\n#define MAX_KERNEL_THREADS 256\n\n\n\ntypedef float vtype;\ntypedef vector<vector<vtype>> matrix; \n\ntemplate<typename T>\n__device__\nT parallel_prefix_sum(const int n, const int *ind, const T *w) \n{\n\n  T sum = 0.0;\n  T last;\n\n  int mn =(((n+blockDim.x-1)/blockDim.x)*blockDim.x); \n\n  for (int i=threadIdx.x; i<mn; i+=blockDim.x) {\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    bool valid  = i<n;\n\n    \n\n    \n\n    \n\n\n    \n\n    last = __shfl(sum, blockDim.x-1, blockDim.x);\n\n    \n\n    sum = (valid) ? w[ind[i]] : 0.0;\n\n    \n\n    for (int j=1; j<blockDim.x; j*=2) {\n      T v = __shfl_up(sum, j, blockDim.x);\n      if (threadIdx.x >= j) sum += v;\n    }\n    \n\n    sum += last;\n    \n\n  }\n  \n\n  last = __shfl(sum, blockDim.x-1, blockDim.x);\n\n  return last;\n}\n\n\n\ntemplate<bool weighted, typename T>\n__global__ void \njaccard_row_sum(const int n,\n                const int *__restrict__ csrPtr,\n                const int *__restrict__ csrInd,\n                const T *__restrict__ w,\n                      T *__restrict__ work) \n{\n  for (int row=threadIdx.y+blockIdx.y*blockDim.y; row<n; row+=gridDim.y*blockDim.y) {\n    int start = csrPtr[row];\n    int end   = csrPtr[row+1];\n    int length= end-start;\n    \n\n    if (weighted) {\n      T sum = parallel_prefix_sum(length, csrInd + start, w); \n      if (threadIdx.x == 0) work[row] = sum;\n    }\n    else {\n      work[row] = (T)length;\n    }\n  }\n}\n\n\n\n\n\ntemplate<bool weighted, typename T>\n__global__ void \njaccard_is(const int n, const int e,\n           const int *__restrict__ csrPtr,\n           const int *__restrict__ csrInd, \n           const T *__restrict__ v,\n           const T *__restrict__ work,\n                 T *__restrict__ weight_i,\n                 T *__restrict__ weight_s) \n{\n  for (int row=threadIdx.z+blockIdx.z*blockDim.z; row<n; row+=gridDim.z*blockDim.z) {  \n    for (int j=csrPtr[row]+threadIdx.y+blockIdx.y*blockDim.y; j<csrPtr[row+1]; j+=gridDim.y*blockDim.y) { \n      int col = csrInd[j];\n      \n\n      int Ni = csrPtr[row+1] - csrPtr[row];\n      int Nj = csrPtr[col+1] - csrPtr[col];\n      int ref= (Ni < Nj) ? row : col;\n      int cur= (Ni < Nj) ? col : row;\n\n      \n\n      weight_s[j] = work[row] + work[col];\n\n      \n\n      \n\n      for (int i=csrPtr[ref]+threadIdx.x+blockIdx.x*blockDim.x; i<csrPtr[ref+1]; i+=gridDim.x*blockDim.x) {\n        int match  =-1;           \n        int ref_col = csrInd[i];\n        T ref_val = weighted ? v[ref_col] : (T)1.0;\n\n        \n\n        int left = csrPtr[cur]; \n        int right= csrPtr[cur+1]-1; \n        while(left <= right){\n          int middle = (left+right)>>1; \n          int cur_col= csrInd[middle];\n          if (cur_col > ref_col) {\n            right=middle-1;\n          }\n          else if (cur_col < ref_col) {\n            left=middle+1;\n          }\n          else {\n            match = middle; \n            break; \n          }\n        }            \n\n        \n\n        if (match != -1){\n          atomicAdd(&weight_i[j],ref_val);\n        }\n      }\n    }\n  }\n}\n\ntemplate<bool weighted, typename T>\n__global__ void \njaccard_jw(const int e,\n    const T *__restrict__ csrVal,\n    const T gamma, \n    const T *__restrict__ weight_i,\n    const T *__restrict__ weight_s, \n          T *__restrict__ weight_j) \n{\n  for (int j=threadIdx.x+blockIdx.x*blockDim.x; j<e; j+=gridDim.x*blockDim.x) {  \n    T Wi =  weight_i[j];\n    T Ws =  weight_s[j];\n    weight_j[j] = (gamma*csrVal[j])* (Wi/(Ws-Wi));\n  }\n}\n\ntemplate <bool weighted, typename T>\n__global__ void \nfill(const int e, T* w, const T value) \n{\n  for (int j=threadIdx.x+blockIdx.x*blockDim.x; j<e; j+=gridDim.x*blockDim.x) {  \n    \n\n    \n\n    \n\n    w[j] = weighted ? (T)(j+1)/e : value; \n  }\n}\n\ntemplate <bool weighted, typename T>\nvoid jaccard_weight (const int iteration, const int n, const int e, \n    int* csr_ptr, int* csr_ind, T* csr_val)\n{\n\n  const T gamma = (T)0.46;  \n\n\n  T *d_weight_i, \n    *d_weight_s, \n    *d_weight_j, \n    *d_work;\n  int *d_csrInd;\n  int *d_csrPtr;\n  T *d_csrVal;\n\n#ifdef DEBUG\n  T* weight_i = (T*) malloc (sizeof(T) * e);\n  T* weight_s = (T*) malloc (sizeof(T) * e);\n  T* work = (T*) malloc (sizeof(T) * n);\n#endif\n  T* weight_j = (T*) malloc (sizeof(T) * e);\n\n  hipMalloc ((void**)&d_work, sizeof(T) * n);\n  hipMalloc ((void**)&d_weight_i, sizeof(T) * e);\n  hipMalloc ((void**)&d_weight_s, sizeof(T) * e);\n  hipMalloc ((void**)&d_weight_j, sizeof(T) * e);\n  hipMalloc ((void**)&d_csrVal, sizeof(T) * e);\n  hipMalloc ((void**)&d_csrPtr, sizeof(int) * (n+1));\n  hipMalloc ((void**)&d_csrInd, sizeof(int) * e);\n\n  hipMemcpy(d_csrPtr, csr_ptr, sizeof(int) * (n+1), hipMemcpyHostToDevice);\n  hipMemcpy(d_csrInd, csr_ind, sizeof(int) * e, hipMemcpyHostToDevice);\n  hipMemcpy(d_csrVal, csr_val, sizeof(T) * e, hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iteration; i++) {\n    dim3 nthreads, nblocks; \n\n\n    nthreads.x = MAX_KERNEL_THREADS;\n    nthreads.y = 1; \n    nthreads.z = 1; \n    nblocks.x  = (e+MAX_KERNEL_THREADS-1) / MAX_KERNEL_THREADS;\n    nblocks.y  = 1;\n    nblocks.z  = 1; \n\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(fill<weighted, T>), dim3(nblocks), dim3(nthreads), 0, 0, e, d_weight_j, (T)1.0);\n#ifdef DEBUG\n    hipMemcpy(weight_j, d_weight_j, sizeof(T) * e, hipMemcpyDeviceToHost);\n    for (int i = 0; i < e; i++) printf(\"wj: %d %f\\n\", i, weight_j[i]);\n#endif\n\n    \n\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(fill<false, T>), dim3(nblocks), dim3(nthreads), 0, 0, e, d_weight_i, (T)0.0);\n\n    \n\n    const int y = 4;\n    nthreads.x = 64/y;\n    nthreads.y = y; \n    nthreads.z = 1; \n    nblocks.x  = 1; \n    nblocks.y  = (n + nthreads.y - 1) / nthreads.y;  \n\n    nblocks.z  = 1; \n    hipLaunchKernelGGL(HIP_KERNEL_NAME(jaccard_row_sum<weighted,T>), dim3(nblocks), dim3(nthreads), 0, 0, n, d_csrPtr, d_csrInd, d_weight_j, d_work);\n\n#ifdef DEBUG\n    hipMemcpy(work, d_work, sizeof(T) * n, hipMemcpyDeviceToHost);\n    for (int i = 0; i < n; i++) printf(\"work: %d %f\\n\", i, work[i]);\n#endif\n\n    \n\n    \n\n    nthreads.x = 32/y;\n    nthreads.y = y;\n    nthreads.z = 8;\n    nblocks.x  = 1;\n    nblocks.y  = 1;\n    nblocks.z  = (n + nthreads.z - 1)/nthreads.z; \n\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(jaccard_is<weighted,T>), dim3(nblocks), dim3(nthreads), 0, 0, n, e, d_csrPtr,\n        d_csrInd, d_weight_j, d_work, d_weight_i, d_weight_s);\n\n#ifdef DEBUG\n    hipMemcpy(weight_i, d_weight_i, sizeof(T) * e, hipMemcpyDeviceToHost);\n    hipMemcpy(weight_s, d_weight_s, sizeof(T) * e, hipMemcpyDeviceToHost);\n    for (int i = 0; i < e; i++) printf(\"wi: %d %f\\n\", i, weight_i[i]);\n    for (int i = 0; i < e; i++) printf(\"ws: %d %f\\n\", i, weight_s[i]);\n#endif\n\n    \n\n    nthreads.x = std::min(e, MAX_KERNEL_THREADS); \n    nthreads.y = 1; \n    nthreads.z = 1;  \n    nblocks.x  = (e + nthreads.x - 1)/nthreads.x;  \n\n    nblocks.y  = 1; \n    nblocks.z  = 1;\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(jaccard_jw<weighted,T>), dim3(nblocks), dim3(nthreads), 0, 0, e, \n        d_csrVal, gamma, d_weight_i, d_weight_s, d_weight_j);\n\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  cout << \"Average execution time of kernels: \" << (time * 1e-9f) / iteration << \" (s)\\n\";\n\n  hipMemcpy(weight_j, d_weight_j, sizeof(T) * e, hipMemcpyDeviceToHost);\n#ifdef DEBUG\n  \n\n  float error; \n\n  if (weighted)\n    error = std::fabs(weight_j[0] - 0.306667) +\n            std::fabs(weight_j[1] - 0.000000) +\n            std::fabs(weight_j[2] - 3.680000) +\n            std::fabs(weight_j[3] - 1.380000) +\n            std::fabs(weight_j[4] - 0.788571) +\n            std::fabs(weight_j[5] - 0.460000);\n\n  else\n    error = std::fabs(weight_j[0] - 0.230000) +\n            std::fabs(weight_j[1] - 0.000000) +\n            std::fabs(weight_j[2] - 3.680000) +\n            std::fabs(weight_j[3] - 1.380000) +\n            std::fabs(weight_j[4] - 0.920000) +\n            std::fabs(weight_j[5] - 0.460000);\n\n  if (error > 1e-5) {\n    for (int i = 0; i < e; i++) printf(\"wj: %d %f\\n\", i, weight_j[i]);\n    printf(\"FAILED\");\n  } else {\n    printf(\"PASSED\");\n  }\n  printf(\"\\n\");\n#endif\n\n  hipFree (d_work);\n  hipFree (d_weight_i);\n  hipFree (d_weight_s);\n  hipFree (d_weight_j);\n  hipFree (d_csrInd);\n  hipFree (d_csrVal);\n  hipFree (d_csrPtr);\n  free(weight_j);\n#ifdef DEBUG\n  free(weight_i);\n  free(weight_s);\n  free(work);\n#endif\n}\n\n\n\nvoid printMatrix(const matrix& M) \n{ \n  int m = M.size(); \n  int n = M[0].size(); \n  for (int i = 0; i < m; i++) { \n    for (int j = 0; j < n; j++) \n      cout << M[i][j] << \" \";     \n    cout << endl; \n  } \n} \n\n  template <typename T>\nvoid printVector(const vector<T>& V, char* msg) \n{ \n  cout << msg << \"[ \"; \n  for_each(V.begin(), V.end(), [](int a) { cout << a << \" \"; }); \n  cout << \"]\" << endl; \n} \n\n\n\nint main(int argc, char** argv) \n{ \n  int iteration = 10;\n\n#ifdef DEBUG\n  matrix M  = { \n    { 0, 0, 0, 1}, \n    { 5, 8, 0, 0}, \n    { 0, 0, 3, 0}, \n    { 0, 6, 0, 1} \n  }; \n#else\n\n  int numRow = atoi(argv[1]);\n  int numCol = atoi(argv[2]);\n  iteration = atoi(argv[3]);\n\n  srand(2);\n\n  matrix M;\n  vector<vtype> rowElems(numCol);\n  for (int r = 0; r < numRow; r++) {\n    for (int c = 0; c < numCol; c++)\n      rowElems[c] = rand() % 10;\n    M.push_back(rowElems);\n  }\n#endif\n\n  int row = M.size();\n  int col = M[0].size();\n  printf(\"Number of matrix rows and cols: %d %d\\n\", row, col);\n  vector<vtype> csr_val;\n  vector<int> csr_ptr = { 0 }; \n\n  vector<int> csr_ind;\n  int nnz = 0; \n\n\n  for (int i = 0; i < row; i++) { \n    for (int j = 0; j < col; j++) { \n      if (M[i][j] != (vtype)0) { \n        csr_val.push_back(M[i][j]); \n        csr_ind.push_back(j); \n        nnz++; \n      } \n    } \n    csr_ptr.push_back(nnz); \n  } \n\n  \n\n  if (row <= 16 && col <= 16) {\n    printMatrix(M); \n    printVector(csr_val, (char*)\"values = \"); \n    printVector(csr_ptr, (char*)\"row pointer = \"); \n    printVector(csr_ind, (char*)\"col indices = \"); \n  }\n\n  jaccard_weight<true, vtype>(iteration, row, nnz, csr_ptr.data(), csr_ind.data(), csr_val.data());\n  jaccard_weight<false, vtype>(iteration, row, nnz, csr_ptr.data(), csr_ind.data(), csr_val.data());\n\n  return 0; \n} \n\n"}}
{"kernel_name": "jaccard", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <algorithm>\n#include <iostream>\n#include <vector>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nusing namespace std;\n\n#define MAX_KERNEL_THREADS 256\n\n\n\ntypedef float vtype;\ntypedef vector<vector<vtype>> matrix;\n\n\n\ntemplate<bool weighted, typename T>\nclass row_sum;\n\ntemplate<bool weighted, typename T>\nclass intersection;\n\ntemplate<bool weighted, typename T>\nclass jw;\n\ntemplate<bool weighted, typename T>\nclass fill_elements;\n\ntemplate<typename T, sycl::memory_scope MemoryScope = sycl::memory_scope::device>\nstatic inline void atomicAdd(T& val, const T delta)\n{\n  sycl::atomic_ref<T, sycl::memory_order::relaxed,\n    MemoryScope, sycl::access::address_space::global_space> ref(val);\n  ref.fetch_add(delta);\n}\n\ntemplate<typename T>\nT parallel_prefix_sum(sycl::nd_item<3> &item, const int n, const int *ind, T *w)\n{\n  T sum = 0.0;\n  T last;\n  const int blockDim_x = item.get_local_range(2);\n  const int threadIdx = item.get_local_id(2);\n  auto sg = item.get_sub_group();\n\n  \n\n  int mn =((n+blockDim_x-1)/blockDim_x*blockDim_x);\n\n  for (int i=threadIdx; i<mn; i+=blockDim_x) {\n    bool valid = i < n;\n    last = sycl::select_from_group(sg, sum, blockDim_x-1);\n    sum = (valid) ? w[ind[i]] : 0.0;\n\n    for (int j=1; j<blockDim_x; j*=2) {\n      T v = sycl::shift_group_right(sg, sum, j);\n      if (threadIdx >= j) sum += v;\n    }\n    sum += last;\n  }\n  last = sycl::select_from_group(sg, sum, blockDim_x-1);\n  return last;\n}\n\n\n\ntemplate<bool weighted, typename T>\nvoid jaccard_row_sum(\n  sycl::queue &q,\n  const int n,\n  int *d_csrPtr,\n  int *d_csrInd,\n  T *d_weight_j,\n  T *d_work)\n{\n  const int y = 4;\n  sycl::range<3> sum_gws (1, (n+y-1)/y*y, 64/y);\n  sycl::range<3> sum_lws (1, y, 64/y);\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class row_sum<weighted,T>>(\n      sycl::nd_range<3>(sum_gws, sum_lws), [=] (sycl::nd_item<3> item)\n         [[sycl::reqd_sub_group_size(32)]] {\n\n      for(int row = item.get_global_id(1); row < n;\n              row += item.get_group_range(1)*item.get_local_range(1)) {\n        int start = d_csrPtr[row];\n        int end   = d_csrPtr[row+1];\n        int length= end-start;\n        if (weighted) {\n          T sum = parallel_prefix_sum(item, length, d_csrInd + start, d_weight_j);\n          if (item.get_local_id(2) == 0) d_work[row] = sum;\n        } else {\n          d_work[row] = (T)length;\n        }\n      }\n    });\n  });\n}\n\n\n\n\n\ntemplate<bool weighted, typename T>\nvoid jaccard_is(\n  sycl::queue &q,\n  const int n,\n  const int e,\n  int *d_csrPtr,\n  int *d_csrInd,\n  T *d_weight_j,\n  T *d_work,\n  T *d_weight_i,\n  T *d_weight_s)\n{\n  const int y = 4;\n  sycl::range<3> is_gws ((n+7)/8*8, y, 32/y);\n  sycl::range<3> is_lws(8, y, 32/y);\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class intersection<weighted,T>>(\n      sycl::nd_range<3>(is_gws, is_lws), [=] (sycl::nd_item<3> item) {\n\n      for(int row = item.get_global_id(0); row < n;\n              row += item.get_group_range(0)*item.get_local_range(0)) {\n        for (int j = d_csrPtr[row]+item.get_global_id(1); j < d_csrPtr[row+1];\n                 j+= item.get_local_range(1) * item.get_group_range(1)) {\n\n          int col = d_csrInd[j];\n          \n\n          int Ni = d_csrPtr[row+1] - d_csrPtr[row];\n          int Nj = d_csrPtr[col+1] - d_csrPtr[col];\n          int ref= (Ni < Nj) ? row : col;\n          int cur= (Ni < Nj) ? col : row;\n\n          \n\n          d_weight_s[j] = d_work[row] + d_work[col];\n\n          \n\n          \n\n          for (int i = d_csrPtr[ref]+item.get_global_id(2); i < d_csrPtr[ref+1];\n                   i += item.get_local_range(2) * item.get_group_range(2)) {\n            int match  =-1;\n            int ref_col = d_csrInd[i];\n            T ref_val = weighted ? d_weight_j[ref_col] : (T)1.0;\n\n            \n\n            int left = d_csrPtr[cur];\n            int right= d_csrPtr[cur+1]-1;\n            while(left <= right){\n              int middle = (left+right)>>1;\n              int cur_col= d_csrInd[middle];\n              if (cur_col > ref_col) {\n                right=middle-1;\n              }\n              else if (cur_col < ref_col) {\n                left=middle+1;\n              }\n              else {\n                match = middle;\n                break;\n              }\n            }\n\n            \n\n            if (match != -1){\n              atomicAdd(d_weight_i[j], ref_val);\n            }\n          }\n        }\n      }\n    });\n  });\n}\n\ntemplate<bool weighted, typename T>\nvoid jaccard_jw(\n  sycl::queue &q,\n  const int e,\n  T *d_csrVal,\n  const T gamma,\n  T *d_weight_i,\n  T *d_weight_s,\n  T *d_weight_j)\n{\n  int threads = std::min(e, MAX_KERNEL_THREADS);\n\n  sycl::range<1> jw_gws ((e+threads-1)/threads*threads);\n  sycl::range<1> jw_lws (threads);\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class jw<weighted,T>>(\n      sycl::nd_range<1>(jw_gws, jw_lws), [=] (sycl::nd_item<1> item) {\n      for (int j = item.get_global_id(0); j < e;\n               j += item.get_group_range(0)*item.get_local_range(0)) {\n        T Wi =  d_weight_i[j];\n        T Ws =  d_weight_s[j];\n        d_weight_j[j] = (gamma*d_csrVal[j])* (Wi/(Ws-Wi));\n      }\n    });\n  });\n}\n\ntemplate <bool weighted, typename T>\nvoid fill_weights(sycl::queue &q, const int e, T *d_w, const T value)\n{\n  sycl::range<1> fill_gws((e+MAX_KERNEL_THREADS-1)/MAX_KERNEL_THREADS*MAX_KERNEL_THREADS);\n  sycl::range<1> fill_lws(MAX_KERNEL_THREADS);\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class fill_elements<weighted, T>>(\n      sycl::nd_range<1>(fill_gws, fill_lws), [=] (sycl::nd_item<1> item) {\n      for (int j = item.get_global_id(0); j<e; j+=item.get_group_range(0)*item.get_local_range(0))\n        d_w[j] = weighted ? (T)(j+1)/e : value;\n    });\n  });\n}\n\ntemplate <bool weighted, typename T>\nvoid jaccard_weight (sycl::queue &q, const int iteration, const int n, const int e,\n    int* csr_ptr, int* csr_ind, T* csr_val)\n{\n\n  const T gamma = (T)0.46;  \n\n\n#ifdef DEBUG\n  T* weight_i = (T*) malloc (sizeof(T) * e);\n  T* weight_s = (T*) malloc (sizeof(T) * e);\n  T* work = (T*) malloc (sizeof(T) * n);\n#endif\n  T* weight_j = (T*) malloc (sizeof(T) * e);\n\n  T *d_work = sycl::malloc_device<T>(n, q);\n  T *d_weight_i = sycl::malloc_device<T>(e, q);\n  T *d_weight_s = sycl::malloc_device<T>(e, q);\n  T *d_weight_j = sycl::malloc_device<T>(e, q);\n  T *d_csrVal = sycl::malloc_device<T>(e, q);\n  int *d_csrPtr = sycl::malloc_device<int>(n+1, q);\n  int *d_csrInd = sycl::malloc_device<int>(e, q);\n\n  q.memcpy(d_csrPtr, csr_ptr, sizeof(int) * (n+1));\n  q.memcpy(d_csrInd, csr_ind, sizeof(int) * e);\n  q.memcpy(d_csrVal, csr_val, sizeof(T) * e);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iteration; i++) {\n\n    fill_weights<weighted, T>(q, e, d_weight_j, (T)1.0);\n\n    #ifdef DEBUG\n    q.memcpy(weight_j, d_weight_j, sizeof(T) * e).wait();\n    for (int i = 0; i < e; i++) printf(\"wj: %d %f\\n\", i, weight_j[i]);\n    #endif\n\n    \n\n    fill_weights<false, T>(q, e, d_weight_i, (T)0.0);\n\n    jaccard_row_sum<weighted,T>(q, n, d_csrPtr, d_csrInd, d_weight_j, d_work);\n\n    #ifdef DEBUG\n    q.memcpy(work, d_work, sizeof(T) * n).wait();\n    for (int i = 0; i < n; i++) printf(\"work: %d %f\\n\", i, work[i]);\n    #endif\n\n    \n\n    jaccard_is<weighted,T>(q, n, e, d_csrPtr,\n        d_csrInd, d_weight_j, d_work, d_weight_i, d_weight_s);\n\n#ifdef DEBUG\n    q.memcpy(weight_i, d_weight_i, sizeof(T) * e);\n    q.memcpy(weight_s, d_weight_s, sizeof(T) * e);\n    q.wait();\n    for (int i = 0; i < e; i++) printf(\"wi: %d %f\\n\", i, weight_i[i]);\n    for (int i = 0; i < e; i++) printf(\"ws: %d %f\\n\", i, weight_s[i]);\n#endif\n\n    \n\n    jaccard_jw<weighted,T>(q, e, d_csrVal, gamma, d_weight_i, d_weight_s, d_weight_j);\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of kernels: \" << (time * 1e-9f) / iteration << \" (s)\\n\";\n\n  q.memcpy(weight_j, d_weight_j, sizeof(T) * e).wait();\n\n#ifdef DEBUG\n  \n\n  float error;\n\n  if (weighted)\n    error = std::fabs(weight_j[0] - 0.306667) +\n      std::fabs(weight_j[1] - 0.000000) +\n      std::fabs(weight_j[2] - 3.680000) +\n      std::fabs(weight_j[3] - 1.380000) +\n      std::fabs(weight_j[4] - 0.788571) +\n      std::fabs(weight_j[5] - 0.460000);\n\n  else\n    error = std::fabs(weight_j[0] - 0.230000) +\n      std::fabs(weight_j[1] - 0.000000) +\n      std::fabs(weight_j[2] - 3.680000) +\n      std::fabs(weight_j[3] - 1.380000) +\n      std::fabs(weight_j[4] - 0.920000) +\n      std::fabs(weight_j[5] - 0.460000);\n\n  if (error > 1e-5) {\n    for (int i = 0; i < e; i++) printf(\"wj: %d %f\\n\", i, weight_j[i]);\n    printf(\"FAIL\");\n  } else {\n    printf(\"PASS\");\n  }\n  printf(\"\\n\");\n#endif\n\n  sycl::free(d_work, q);\n  sycl::free(d_weight_i, q);\n  sycl::free(d_weight_s, q);\n  sycl::free(d_weight_j, q);\n  sycl::free(d_csrInd, q);\n  sycl::free(d_csrVal, q);\n  sycl::free(d_csrPtr, q);\n\n  free(weight_j);\n#ifdef DEBUG\n  free(weight_i);\n  free(weight_s);\n  free(work);\n#endif\n}\n\n\n\nvoid printMatrix(const matrix& M)\n{\n  int m = M.size();\n  int n = M[0].size();\n  for (int i = 0; i < m; i++) {\n    for (int j = 0; j < n; j++)\n      printf(\"%lf \", M[i][j]);\n    printf(\"\\n\");\n  }\n}\n\n  template <typename T>\nvoid printVector(const vector<T>& V, char* msg)\n{\n  printf(\"%s [ \", msg);\n  for_each(V.begin(), V.end(), [](int a) { printf(\"%d \", a); });\n  printf(\"]\\n\");\n}\n\n\n\nint main(int argc, char** argv)\n{\n  int iteration = 10;\n\n#ifdef DEBUG\n  matrix M  = {\n    { 0, 0, 0, 1},\n    { 5, 8, 0, 0},\n    { 0, 0, 3, 0},\n    { 0, 6, 0, 1}\n  };\n#else\n\n  int numRow = atoi(argv[1]);\n  int numCol = atoi(argv[2]);\n  iteration = atoi(argv[3]);\n\n  srand(2);\n\n  matrix M;\n  vector<vtype> rowElems(numCol);\n  for (int r = 0; r < numRow; r++) {\n    for (int c = 0; c < numCol; c++)\n      rowElems[c] = rand() % 10;\n    M.push_back(rowElems);\n  }\n#endif\n\n  int row = M.size();\n  int col = M[0].size();\n  printf(\"Number of matrix rows and cols: %d %d\\n\", row, col);\n  vector<vtype> csr_val;\n  vector<int> csr_ptr = { 0 }; \n\n  vector<int> csr_ind;\n  int nnz = 0; \n\n\n  for (int i = 0; i < row; i++) {\n    for (int j = 0; j < col; j++) {\n      if (M[i][j] != (vtype)0) {\n        csr_val.push_back(M[i][j]);\n        csr_ind.push_back(j);\n        nnz++;\n      }\n    }\n    csr_ptr.push_back(nnz);\n  }\n\n  \n\n  if (row <= 16 && col <= 16) {\n    printMatrix(M);\n    printVector(csr_val, (char*)\"values = \");\n    printVector(csr_ptr, (char*)\"row pointer = \");\n    printVector(csr_ind, (char*)\"col indices = \");\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  jaccard_weight<true, vtype>(q, iteration, row, nnz, csr_ptr.data(), csr_ind.data(), csr_val.data());\n  jaccard_weight<false, vtype>(q, iteration, row, nnz, csr_ptr.data(), csr_ind.data(), csr_val.data());\n\n  return 0;\n}\n"}}
{"kernel_name": "keogh", "parallel_api": "cuda", "code": {"main.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n\n\n__global__\nvoid lb_keogh(const float *__restrict__ subject,\n              const float *__restrict__ avgs,\n              const float *__restrict__ stds, \n                    float *__restrict__ lb_keogh,\n              const float *__restrict__ lower_bound,\n              const float *__restrict__ upper_bound,\n              const int M,\n              const int N) \n{\n  \n\n  extern __shared__ float cache[];\n\n  int lid = threadIdx.x;\n  int blockSize = blockDim.x * blockIdx.x;\n  int idx = blockSize + lid;\n\n  for (int k = lid; k < blockDim.x + M; k += blockDim.x)\n    if (blockSize + k < N) cache[k] = subject[blockSize + k];\n\n  __syncthreads();\n\n  if (idx < N-M+1) {\n\n    \n\n    float residues = 0;\n    float avg = avgs[idx];\n    float std = stds[idx];\n\n    for (int i = 0; i < M; ++i) {\n      \n\n      float value = (cache[lid+i] - avg) / std;\n      float lower = value - lower_bound[i];\n      float upper = value - upper_bound[i];\n\n      \n\n      residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n    }\n\n    lb_keogh[idx] = residues;\n  }\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower = (float*) malloc (sizeof(float)*N);\n  float *upper = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower[i] = (float)rand() / (float)RAND_MAX;\n\n  float *d_subject = NULL, *d_avgs = NULL, *d_stds = NULL, \n        *d_lb = NULL, *d_lower = NULL, *d_upper = NULL;\n\n  cudaMalloc(&d_subject, sizeof(float)*N);\n  cudaMalloc(&d_avgs, sizeof(float)*(N-M+1));\n  cudaMalloc(&d_stds, sizeof(float)*(N-M+1));\n  cudaMalloc(&d_lb, sizeof(float)*(N-M+1));\n  cudaMalloc(&d_lower, sizeof(float)*M);\n  cudaMalloc(&d_upper, sizeof(float)*M);\n\n  cudaMemcpy(d_subject, subject, sizeof(float)*N, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_avgs, avgs, sizeof(float)*(N-M+1), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_stds, stds, sizeof(float)*(N-M+1), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_lower, lower, sizeof(float)*M, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_upper, upper, sizeof(float)*M, cudaMemcpyHostToDevice);\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n  int smem_size = (M+blocks)*sizeof(float);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    lb_keogh<<<grids, blocks, smem_size>>>\n      (d_subject, d_avgs, d_stds, d_lb, d_lower, d_upper, M, N);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(lb, d_lb, sizeof(float)*(N-M+1), cudaMemcpyDeviceToHost);\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower, upper, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabsf(lb[i] - lb_h[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_lb);\n  cudaFree(d_avgs);\n  cudaFree(d_stds);\n  cudaFree(d_subject);\n  cudaFree(d_lower);\n  cudaFree(d_upper);\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower);\n  free(upper);\n  return 0;\n}\n"}}
{"kernel_name": "keogh", "parallel_api": "hip", "code": {"main.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n\n\n__global__\nvoid lb_keogh(const float *__restrict__ subject,\n              const float *__restrict__ avgs,\n              const float *__restrict__ stds, \n                    float *__restrict__ lb_keogh,\n              const float *__restrict__ lower_bound,\n              const float *__restrict__ upper_bound,\n              const int M,\n              const int N) \n{\n  \n\n  extern __shared__ float cache[];\n\n  int lid = threadIdx.x;\n  int blockSize = blockDim.x * blockIdx.x;\n  int idx = blockSize + lid;\n\n  for (int k = lid; k < blockDim.x + M; k += blockDim.x)\n    if (blockSize + k < N) cache[k] = subject[blockSize + k];\n\n  __syncthreads();\n\n  if (idx < N-M+1) {\n\n    \n\n    float residues = 0;\n    float avg = avgs[idx];\n    float std = stds[idx];\n\n    for (int i = 0; i < M; ++i) {\n      \n\n      float value = (cache[lid+i] - avg) / std;\n      float lower = value - lower_bound[i];\n      float upper = value - upper_bound[i];\n\n      \n\n      residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n    }\n\n    lb_keogh[idx] = residues;\n  }\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower = (float*) malloc (sizeof(float)*N);\n  float *upper = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower[i] = (float)rand() / (float)RAND_MAX;\n\n  float *d_subject = NULL, *d_avgs = NULL, *d_stds = NULL, \n        *d_lb = NULL, *d_lower = NULL, *d_upper = NULL;\n\n  hipMalloc(&d_subject, sizeof(float)*N);\n  hipMalloc(&d_avgs, sizeof(float)*(N-M+1));\n  hipMalloc(&d_stds, sizeof(float)*(N-M+1));\n  hipMalloc(&d_lb, sizeof(float)*(N-M+1));\n  hipMalloc(&d_lower, sizeof(float)*M);\n  hipMalloc(&d_upper, sizeof(float)*M);\n\n  hipMemcpy(d_subject, subject, sizeof(float)*N, hipMemcpyHostToDevice);\n  hipMemcpy(d_avgs, avgs, sizeof(float)*(N-M+1), hipMemcpyHostToDevice);\n  hipMemcpy(d_stds, stds, sizeof(float)*(N-M+1), hipMemcpyHostToDevice);\n  hipMemcpy(d_lower, lower, sizeof(float)*M, hipMemcpyHostToDevice);\n  hipMemcpy(d_upper, upper, sizeof(float)*M, hipMemcpyHostToDevice);\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n  int smem_size = (M+blocks)*sizeof(float);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(lb_keogh, grids, blocks, smem_size, 0, d_subject, d_avgs, d_stds, d_lb, d_lower, d_upper, M, N);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(lb, d_lb, sizeof(float)*(N-M+1), hipMemcpyDeviceToHost);\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower, upper, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabsf(lb[i] - lb_h[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_lb);\n  hipFree(d_avgs);\n  hipFree(d_stds);\n  hipFree(d_subject);\n  hipFree(d_lower);\n  hipFree(d_upper);\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower);\n  free(upper);\n  return 0;\n}\n"}}
{"kernel_name": "keogh", "parallel_api": "omp", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return -1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower_bound = (float*) malloc (sizeof(float)*N);\n  float *upper_bound = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper_bound[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower_bound[i] = (float)rand() / (float)RAND_MAX;\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n\n  #pragma omp target data map (to: subject[0:N], \\\n                                   avgs[0:N-M+1],\\\n                                   stds[0:N-M+1],\\\n                                   lower_bound[0:N],\\\n                                   upper_bound[0:N])\\\n                          map(from: lb[0:N-M+1])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target teams distribute num_teams(grids) thread_limit(blocks)\n      for (int idx = 0; idx < N-M+1; idx++) {\n        \n\n        float residues = 0;\n        float avg = avgs[idx];\n        float std = stds[idx];\n\n        #pragma omp parallel for reduction(+:residues)\n        for (int i = 0; i < M; ++i) {\n          \n\n          float value = (subject[idx+i] - avg) / std;\n          float lower = value - lower_bound[i];\n          float upper = value - upper_bound[i];\n\n          \n\n          residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n        }\n\n        lb[idx] = residues;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower_bound, upper_bound, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabs(lb[i] - lb_h[i]) > 1e-3) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower_bound);\n  free(upper_bound);\n  return 0;\n}\n"}}
{"kernel_name": "keogh", "parallel_api": "serial", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return -1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower_bound = (float*) malloc (sizeof(float)*N);\n  float *upper_bound = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper_bound[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower_bound[i] = (float)rand() / (float)RAND_MAX;\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n            for (int idx = 0; idx < N-M+1; idx++) {\n        \n\n        float residues = 0;\n        float avg = avgs[idx];\n        float std = stds[idx];\n\n                for (int i = 0; i < M; ++i) {\n          \n\n          float value = (subject[idx+i] - avg) / std;\n          float lower = value - lower_bound[i];\n          float upper = value - upper_bound[i];\n\n          \n\n          residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n        }\n\n        lb[idx] = residues;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower_bound, upper_bound, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabs(lb[i] - lb_h[i]) > 1e-3) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower_bound);\n  free(upper_bound);\n  return 0;\n}"}}
{"kernel_name": "keogh", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <query length> <subject length> <repeat>\\n\", argv[0]);\n    return -1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"Query length = %d\\n\", M);\n  printf(\"Subject length = %d\\n\", N);\n\n  \n\n  float *subject = (float*) malloc (sizeof(float)*N);\n  float *lower = (float*) malloc (sizeof(float)*N);\n  float *upper = (float*) malloc (sizeof(float)*N);\n  float *lb = (float*) malloc (sizeof(float)*(N-M+1));\n  float *lb_h = (float*) malloc (sizeof(float)*(N-M+1));\n  float *avgs = (float*) malloc (sizeof(float)*(N-M+1));\n  float *stds = (float*) malloc (sizeof(float)*(N-M+1));\n\n  srand(123);\n  for (int i = 0; i < N; ++i) subject[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) avgs[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < N-M+1; ++i) stds[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) upper[i] = (float)rand() / (float)RAND_MAX;\n  for (int i = 0; i < M; ++i) lower[i] = (float)rand() / (float)RAND_MAX;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_subject = sycl::malloc_device<float>(N, q);\n  q.memcpy(d_subject, subject, sizeof(float)*N);\n\n  float *d_avgs = sycl::malloc_device<float>(N-M+1, q);\n  q.memcpy(d_avgs, avgs, sizeof(float)*(N-M+1));\n\n  float *d_stds = sycl::malloc_device<float>(N-M+1, q);\n  q.memcpy(d_stds, stds, sizeof(float)*(N-M+1));\n\n  float *d_lb = sycl::malloc_device<float>(N-M+1, q);\n\n  float *d_lower = sycl::malloc_device<float>(N, q);\n  q.memcpy(d_lower, lower, sizeof(float)*M);\n\n  float *d_upper = sycl::malloc_device<float>(N, q);\n  q.memcpy(d_upper, upper, sizeof(float)*M);\n\n  const int blocks = 256;\n  const int grids = (N-M+1 + blocks - 1) / blocks;\n  sycl::range<1> gws (grids * blocks);\n  sycl::range<1> lws (blocks);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> cache (sycl::range<1>(M+blocks), cgh);\n      cgh.parallel_for<class lp_koegh>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int lid = item.get_local_id(0);\n        int blockDim = item.get_local_range(0);\n        int blockIdx = item.get_group(0);\n        int blockSize = blockDim * blockIdx;\n        int idx = blockSize + lid;\n\n        for (int k = lid; k < blockDim + M; k += blockDim)\n          if (blockSize + k < N) {\n            cache[k] = d_subject[blockSize + k];\n          }\n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        if (idx < N-M+1) {\n\n          \n\n          float residues = 0;\n          float avg = d_avgs[idx];\n          float std = d_stds[idx];\n\n          for (int i = 0; i < M; ++i) {\n            \n\n            float value = (cache[lid+i] - avg) / std;\n            float lower = value - d_lower[i];\n            float upper = value - d_upper[i];\n\n            \n\n            residues += upper*upper*(upper > 0) + lower*lower*(lower < 0);\n          }\n\n          d_lb[idx] = residues;\n        }\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(lb, d_lb, sizeof(float)*(N-M+1)).wait();\n\n  \n\n  reference(subject, avgs, stds, lb_h, lower, upper, M, N);\n  bool ok = true;\n  for (int i = 0; i < N-M+1; i++) {\n    if (fabs(lb[i] - lb_h[i]) > 1e-3) {\n      printf(\"%d %f %f\\n\", i, lb[i], lb_h[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_lb, q);\n  sycl::free(d_avgs, q);\n  sycl::free(d_stds, q);\n  sycl::free(d_subject, q);\n  sycl::free(d_lower, q);\n  sycl::free(d_upper, q);\n  free(lb);\n  free(lb_h);\n  free(avgs);\n  free(stds);\n  free(subject);\n  free(lower);\n  free(upper);\n  return 0;\n}\n\n\n"}}
{"kernel_name": "marchingCubes", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n\n\n\n#include <cstdio>\n#include <random>\n#include <chrono>\n#include <cuda.h>\n#include \"tables.h\"\n\n\n\nconstexpr unsigned int N(1024);\nconstexpr unsigned int Nd2(N / 2);\nconstexpr unsigned int voxelXLv1(16);\nconstexpr unsigned int voxelYLv1(16);\nconstexpr unsigned int voxelZLv1(64);\nconstexpr unsigned int gridXLv1((N - 1) / (voxelXLv1 - 1));\nconstexpr unsigned int gridYLv1((N - 1) / (voxelYLv1 - 1));\nconstexpr unsigned int gridZLv1((N - 1) / (voxelZLv1 - 1));\nconstexpr unsigned int countingThreadNumLv1(128);\nconstexpr unsigned int blockNum(gridXLv1* gridYLv1* gridZLv1);\nconstexpr unsigned int countingBlockNumLv1(blockNum / countingThreadNumLv1);\n\nconstexpr unsigned int voxelXLv2(4);\nconstexpr unsigned int voxelYLv2(4);\nconstexpr unsigned int voxelZLv2(8);\nconstexpr unsigned int blockXLv2(5);\nconstexpr unsigned int blockYLv2(5);\nconstexpr unsigned int blockZLv2(9);\nconstexpr unsigned int voxelNumLv2(blockXLv2* blockYLv2* blockZLv2);\n\nconstexpr unsigned int countingThreadNumLv2(1024);\nconstexpr unsigned int gridXLv2(gridXLv1* blockXLv2);\nconstexpr unsigned int gridYLv2(gridYLv1* blockYLv2);\n\n\n\n__inline__ __device__ float f(unsigned int x, unsigned int y, unsigned int z)\n{\n  constexpr float d(2.0f / N);\n  float xf((int(x - Nd2)) * d);\n\n  float yf((int(z - Nd2)) * d);\n  float zf((int(z - Nd2)) * d);\n  return 1.f - 16.f * xf * yf * zf - 4.f * (xf * xf + yf * yf + zf * zf);\n}\n\n__inline__ __device__ float zeroPoint(unsigned int x, float v0, float v1, float isoValue)\n{\n  return ((x * (v1 - isoValue) + (x + 1) * (isoValue - v0)) / (v1 - v0) - Nd2) * (2.0f / N);\n}\n\n__inline__ __device__ float transformToCoord(unsigned int x)\n{\n  return (int(x) - int(Nd2)) * (2.0f / N);\n}\n\n__global__ void computeMinMaxLv1(float*__restrict__ minMax)\n{\n  __shared__ float sminMax[64];\n  constexpr unsigned int threadNum(voxelXLv1 * voxelYLv1);\n  constexpr unsigned int warpNum(threadNum / 32);\n  unsigned int x(blockIdx.x * (voxelXLv1 - 1) + threadIdx.x);\n  unsigned int y(blockIdx.y * (voxelYLv1 - 1) + threadIdx.y);\n  unsigned int z(blockIdx.z * (voxelZLv1 - 1));\n  unsigned int tid(threadIdx.x + voxelXLv1 * threadIdx.y);\n  unsigned int laneid = tid % 32;\n  unsigned int blockid(blockIdx.x + gridXLv1 * (blockIdx.y + gridYLv1 * blockIdx.z));\n  unsigned int warpid(tid >> 5);\n  float v(f(x, y, z));\n  float minV(v), maxV(v);\n  for (int c0(1); c0 < voxelZLv1; ++c0)\n  {\n    v = f(x, y, z + c0);\n    if (v < minV)minV = v;\n    if (v > maxV)maxV = v;\n  }\n#pragma unroll\n  for (int c0(16); c0 > 0; c0 /= 2)\n  {\n    float t0, t1;\n    t0 = __shfl_down_sync(0xffffffffu, minV, c0);\n    t1 = __shfl_down_sync(0xffffffffu, maxV, c0);\n    if (t0 < minV)minV = t0;\n    if (t1 > maxV)maxV = t1;\n  }\n  if (laneid == 0)\n  {\n    sminMax[warpid] = minV;\n    sminMax[warpid + warpNum] = maxV;\n  }\n  __syncthreads();\n  if (warpid == 0)\n  {\n    minV = sminMax[laneid];\n    maxV = sminMax[laneid + warpNum];\n#pragma unroll\n    for (int c0(warpNum / 2); c0 > 0; c0 /= 2)\n    {\n      float t0, t1;\n      t0 = __shfl_down_sync(0xffffffffu, minV, c0);\n      t1 = __shfl_down_sync(0xffffffffu, maxV, c0);\n      if (t0 < minV)minV = t0;\n      if (t1 > maxV)maxV = t1;\n    }\n    if (laneid == 0)\n    {\n      minMax[blockid * 2] = minV;\n      minMax[blockid * 2 + 1] = maxV;\n    }\n  }\n}\n\n__global__ void compactLv1(\n  float isoValue, \n  const float*__restrict__ minMax,\n  unsigned int*__restrict__ blockIndices,\n  unsigned int*__restrict__ countedBlockNum)\n{\n  __shared__ unsigned int sums[32];\n  constexpr unsigned int warpNum(countingThreadNumLv1 / 32);\n  unsigned int tid(threadIdx.x);\n  unsigned int laneid = tid % 32;\n  unsigned int bIdx(blockIdx.x * countingThreadNumLv1 + tid);\n  unsigned int warpid(tid >> 5);\n  unsigned int test;\n  if (minMax[2 * bIdx] <= isoValue && minMax[2 * bIdx + 1] >= isoValue)test = 1;\n  else test = 0;\n  unsigned int testSum(test);\n#pragma unroll\n  for (int c0(1); c0 < 32; c0 *= 2)\n  {\n    unsigned int tp(__shfl_up_sync(0xffffffffu, testSum, c0));\n    if (laneid >= c0)testSum += tp;\n  }\n  if (laneid == 31)sums[warpid] = testSum;\n  __syncthreads();\n  if (warpid == 0)\n  {\n    unsigned int warpSum = sums[laneid];\n#pragma unroll\n    for (int c0(1); c0 < warpNum; c0 *= 2)\n    {\n      unsigned int tp(__shfl_up_sync(0xffffffffu, warpSum, c0));\n      if (laneid >= c0) warpSum += tp;\n    }\n    sums[laneid] = warpSum;\n  }\n  __syncthreads();\n  if (warpid != 0)testSum += sums[warpid - 1];\n  if (tid == countingThreadNumLv1 - 1 && testSum != 0)\n    sums[31] = atomicAdd(countedBlockNum, testSum);\n  __syncthreads();\n  if (test)blockIndices[testSum + sums[31] - 1] = bIdx;\n}\n\n__global__ void computeMinMaxLv2(\n  const unsigned int*__restrict__ blockIndicesLv1,\n  float*__restrict__ minMax)\n{\n  unsigned int tid(threadIdx.x);\n  unsigned int voxelOffset(threadIdx.y);\n  unsigned int blockIndex(blockIndicesLv1[blockIdx.x]);\n  unsigned int tp(blockIndex);\n  unsigned int x((blockIndex % gridXLv1) * (voxelXLv1 - 1) + (voxelOffset % 5) * (voxelXLv2 - 1) + (tid & 3));\n  tp /= gridXLv1;\n  unsigned int y((tp % gridYLv1) * (voxelYLv1 - 1) + (voxelOffset / 5) * (voxelYLv2 - 1) + (tid >> 2));\n  tp /= gridYLv1;\n  unsigned int z(tp * (voxelZLv1 - 1));\n  float v(f(x, y, z));\n  float minV(v), maxV(v);\n  unsigned int idx(2 * (voxelOffset + voxelNumLv2 * blockIdx.x));\n  for (int c0(0); c0 < blockZLv2; ++c0)\n  {\n    for (int c1(1); c1 < voxelZLv2; ++c1)\n    {\n      v = f(x, y, z + c1);\n      if (v < minV)minV = v;\n      if (v > maxV)maxV = v;\n    }\n    z += voxelZLv2 - 1;\n#pragma unroll\n    for (int c1(8); c1 > 0; c1 /= 2)\n    {\n      float t0, t1;\n      t0 = __shfl_down_sync(0xffffffffu, minV, c1);\n      t1 = __shfl_down_sync(0xffffffffu, maxV, c1);\n      if (t0 < minV)minV = t0;\n      if (t1 > maxV)maxV = t1;\n    }\n    if (tid == 0)\n    {\n      minMax[idx] = minV;\n      minMax[idx + 1] = maxV;\n      constexpr unsigned int offsetSize(2 * blockXLv2 * blockYLv2);\n      idx += offsetSize;\n    }\n    minV = v;\n    maxV = v;\n  }\n}\n\n__global__ void compactLv2(\n  float isoValue,\n  const float*__restrict__ minMax,\n  const unsigned int*__restrict__ blockIndicesLv1,\n  unsigned int*__restrict__ blockIndicesLv2,\n  unsigned int counterBlockNumLv1,\n  unsigned int*__restrict__ countedBlockNumLv2)\n{\n  __shared__ unsigned int sums[32];\n  constexpr unsigned int warpNum(countingThreadNumLv2 / 32);\n  unsigned int tid(threadIdx.x);\n  unsigned int laneid = tid % 32;\n  unsigned int warpid(tid >> 5);\n  unsigned int id0(tid + blockIdx.x * countingThreadNumLv2);\n  unsigned int id1(id0 / voxelNumLv2);\n  unsigned int test;\n  if (id1 < counterBlockNumLv1)\n  {\n    if (minMax[2 * id0] <= isoValue && minMax[2 * id0 + 1] >= isoValue)\n      test = 1;\n    else\n      test = 0;\n  }\n  else test = 0;\n  unsigned int testSum(test);\n#pragma unroll\n  for (int c0(1); c0 < 32; c0 *= 2)\n  {\n    unsigned int tp(__shfl_up_sync(0xffffffffu, testSum, c0));\n    if (laneid >= c0)testSum += tp;\n  }\n  if (laneid == 31)sums[warpid] = testSum;\n  __syncthreads();\n  if (warpid == 0)\n  {\n    unsigned warpSum = sums[laneid];\n#pragma unroll\n    for (int c0(1); c0 < warpNum; c0 *= 2)\n    {\n      unsigned int tp(__shfl_up_sync(0xffffffffu, warpSum, c0));\n      if (laneid >= c0)warpSum += tp;\n    }\n    sums[laneid] = warpSum;\n  }\n  __syncthreads();\n  if (warpid != 0)testSum += sums[warpid - 1];\n  if (tid == countingThreadNumLv2 - 1)\n    sums[31] = atomicAdd(countedBlockNumLv2, testSum);\n  __syncthreads();\n\n  if (test)\n  {\n    unsigned int bIdx1(blockIndicesLv1[id1]);\n    unsigned int bIdx2;\n    unsigned int x1, y1, z1;\n    unsigned int x2, y2, z2;\n    unsigned int tp1(bIdx1);\n    unsigned int tp2((tid + blockIdx.x * countingThreadNumLv2) % voxelNumLv2);\n    x1 = tp1 % gridXLv1;\n    x2 = tp2 % blockXLv2;\n    tp1 /= gridXLv1;\n    tp2 /= blockXLv2;\n    y1 = tp1 % gridYLv1;\n    y2 = tp2 % blockYLv2;\n    z1 = tp1 / gridYLv1;\n    z2 = tp2 / blockYLv2;\n    bIdx2 = x2 + blockXLv2 * (x1 + gridXLv1 * (y2 + blockYLv2 * (y1 + gridYLv1 * (z1 * blockZLv2 + z2))));\n    blockIndicesLv2[testSum + sums[31] - 1] = bIdx2;\n  }\n}\n\n__global__ void generatingTriangles(\n  float isoValue, \n  const unsigned int*__restrict__ blockIndicesLv2,\n  const unsigned short *__restrict__ distinctEdgesTable,\n  const int *__restrict__ triTable,\n  const uchar4 *__restrict__ edgeIDTable,\n  unsigned int*__restrict__ countedVerticesNum,\n  unsigned int*__restrict__ countedTrianglesNum,\n  unsigned long long*__restrict__ triangles,\n  float*__restrict__ coordX,\n  float*__restrict__ coordY,\n  float*__restrict__ coordZ,\n  float*__restrict__ coordZP)\n{\n  __shared__ unsigned short vertexIndices[voxelZLv2][voxelYLv2][voxelXLv2];\n  __shared__ float value[voxelZLv2 + 1][voxelYLv2 + 1][voxelXLv2 + 1];\n  __shared__ unsigned int sumsVertices[32];\n  __shared__ unsigned int sumsTriangles[32];\n\n  unsigned int blockId(blockIndicesLv2[blockIdx.x]);\n  unsigned int tp(blockId);\n  unsigned int x((tp % gridXLv2) * (voxelXLv2 - 1) + threadIdx.x);\n  tp /= gridXLv2;\n  unsigned int y((tp % gridYLv2) * (voxelYLv2 - 1) + threadIdx.y);\n  unsigned int z((tp / gridYLv2) * (voxelZLv2 - 1) + threadIdx.z);\n  unsigned int eds(7);\n  float v(value[threadIdx.z][threadIdx.y][threadIdx.x] = f(x, y, z));\n  if (threadIdx.x == voxelXLv2 - 1)\n  {\n    eds &= 6;\n    value[threadIdx.z][threadIdx.y][voxelXLv2] = f(x + 1, y, z);\n    if (threadIdx.y == voxelYLv2 - 1)\n      value[threadIdx.z][voxelYLv2][voxelXLv2] = f(x + 1, y + 1, z);\n  }\n  if (threadIdx.y == voxelYLv2 - 1)\n  {\n    eds &= 5;\n    value[threadIdx.z][voxelYLv2][threadIdx.x] = f(x, y + 1, z);\n    if (threadIdx.z == voxelZLv2 - 1)\n      value[voxelZLv2][voxelYLv2][threadIdx.x] = f(x, y + 1, z + 1);\n  }\n  if (threadIdx.z == voxelZLv2 - 1)\n  {\n    eds &= 3;\n    value[voxelZLv2][threadIdx.y][threadIdx.x] = f(x, y, z + 1);\n    if (threadIdx.x == voxelXLv2 - 1)\n      value[voxelZLv2][threadIdx.y][voxelXLv2] = f(x + 1, y, z + 1);\n  }\n  eds <<= 13;\n  __syncthreads();\n  unsigned int cubeCase(0);\n  if (value[threadIdx.z][threadIdx.y][threadIdx.x] < isoValue) cubeCase |= 1;\n  if (value[threadIdx.z][threadIdx.y][threadIdx.x + 1] < isoValue) cubeCase |= 2;\n  if (value[threadIdx.z][threadIdx.y + 1][threadIdx.x + 1] < isoValue) cubeCase |= 4;\n  if (value[threadIdx.z][threadIdx.y + 1][threadIdx.x] < isoValue) cubeCase |= 8;\n  if (value[threadIdx.z + 1][threadIdx.y][threadIdx.x] < isoValue) cubeCase |= 16;\n  if (value[threadIdx.z + 1][threadIdx.y][threadIdx.x + 1] < isoValue) cubeCase |= 32;\n  if (value[threadIdx.z + 1][threadIdx.y + 1][threadIdx.x + 1] < isoValue) cubeCase |= 64;\n  if (value[threadIdx.z + 1][threadIdx.y + 1][threadIdx.x] < isoValue) cubeCase |= 128;\n\n  unsigned int distinctEdges(eds ? distinctEdgesTable[cubeCase] : 0);\n  unsigned int numTriangles(eds != 0xe000 ? 0 : distinctEdges & 7);\n  unsigned int numVertices(__popc(distinctEdges &= eds));\n  unsigned int laneid = (threadIdx.x + voxelXLv2 * (threadIdx.y + voxelYLv2 * threadIdx.z)) % 32;\n  unsigned warpid((threadIdx.x + voxelXLv2 * (threadIdx.y + voxelYLv2 * threadIdx.z)) >> 5);\n  constexpr unsigned int threadNum(voxelXLv2 * voxelYLv2 * voxelZLv2);\n  constexpr unsigned int warpNum(threadNum / 32);\n  unsigned int sumVertices(numVertices);\n  unsigned int sumTriangles(numTriangles);\n\n#pragma unroll\n  for (int c0(1); c0 < 32; c0 *= 2)\n  {\n    unsigned int tp0(__shfl_up_sync(0xffffffffu, sumVertices, c0));\n    unsigned int tp1(__shfl_up_sync(0xffffffffu, sumTriangles, c0));\n    if (laneid >= c0)\n    {\n      sumVertices += tp0;\n      sumTriangles += tp1;\n    }\n  }\n  if (laneid == 31)\n  {\n    sumsVertices[warpid] = sumVertices;\n    sumsTriangles[warpid] = sumTriangles;\n  }\n  __syncthreads();\n  if (warpid == 0)\n  {\n    unsigned warpSumVertices = sumsVertices[laneid];\n    unsigned warpSumTriangles = sumsTriangles[laneid];\n#pragma unroll\n    for (int c0(1); c0 < warpNum; c0 *= 2)\n    {\n      unsigned int tp0(__shfl_up_sync(0xffffffffu, warpSumVertices, c0));\n      unsigned int tp1(__shfl_up_sync(0xffffffffu, warpSumTriangles, c0));\n      if (laneid >= c0)\n      {\n        warpSumVertices += tp0;\n        warpSumTriangles += tp1;\n      }\n    }\n    sumsVertices[laneid] = warpSumVertices;\n    sumsTriangles[laneid] = warpSumTriangles;\n  }\n  __syncthreads();\n  if (warpid != 0)\n  {\n    sumVertices += sumsVertices[warpid - 1];\n    sumTriangles += sumsTriangles[warpid - 1];\n  }\n  if (eds == 0)\n  {\n    sumsVertices[31] = atomicAdd(countedVerticesNum, sumVertices);\n    sumsTriangles[31] = atomicAdd(countedTrianglesNum, sumTriangles);\n  }\n\n  unsigned int interOffsetVertices(sumVertices - numVertices);\n  sumVertices = interOffsetVertices + sumsVertices[31];\n\n  sumTriangles = sumTriangles + sumsTriangles[31] - numTriangles;\n\n  vertexIndices[threadIdx.z][threadIdx.y][threadIdx.x] = interOffsetVertices | distinctEdges;\n  __syncthreads();\n\n  for (unsigned int c0(0); c0 < numTriangles; ++c0)\n  {\n#pragma unroll\n    for (unsigned int c1(0); c1 < 3; ++c1)\n    {\n      int edgeID(triTable[16 * cubeCase + 3 * c0 + c1]);\n      uchar4 edgePos(edgeIDTable[edgeID]);\n      unsigned short vertexIndex(vertexIndices[threadIdx.z + edgePos.z][threadIdx.y + edgePos.y][threadIdx.x + edgePos.x]);\n      unsigned int tp(__popc(vertexIndex >> (16 - edgePos.w)) + (vertexIndex & 0x1fff));\n      atomicAdd(triangles, (unsigned long long)(sumsVertices[31] + tp));\n    }\n  }\n\n  \n\n  float zp = 0.f, cx = 0.f, cy = 0.f, cz = 0.f;\n\n  if (distinctEdges & (1 << 15))\n  {\n    zp = zeroPoint(x, v, value[threadIdx.z][threadIdx.y][threadIdx.x + 1], isoValue);\n    cy = transformToCoord(y);\n    cz = transformToCoord(z);\n  }\n  if (distinctEdges & (1 << 14))\n  {\n    cx = transformToCoord(x);\n    zp += zeroPoint(y, v, value[threadIdx.z][threadIdx.y + 1][threadIdx.x], isoValue);\n    cz += transformToCoord(z);\n  }\n  if (distinctEdges & (1 << 13))\n  {\n    cx += transformToCoord(x);\n    cy += transformToCoord(y);\n    zp += zeroPoint(z, v, value[threadIdx.z + 1][threadIdx.y][threadIdx.x], isoValue);\n  }\n  atomicAdd(coordX, cx);\n  atomicAdd(coordY, cy);\n  atomicAdd(coordZ, cz);\n  atomicAdd(coordZP, zp);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  unsigned int repeat = atoi(argv[1]);\n\n  std::uniform_real_distribution<float>rd(0, 1);\n  std::mt19937 mt(123);\n\n  float* minMaxLv1Device;\n  float* minMaxLv2Device;\n  unsigned int* blockIndicesLv1Device;\n  unsigned int* blockIndicesLv2Device;\n  unsigned int* countedBlockNumLv1Device;\n  unsigned int* countedBlockNumLv2Device;\n  unsigned short* distinctEdgesTableDevice;\n  int* triTableDevice;\n  uchar4* edgeIDTableDevice;\n  unsigned int* countedVerticesNumDevice;\n  unsigned int* countedTrianglesNumDevice;\n  unsigned long long* trianglesDevice;\n  float *coordXDevice;\n  float *coordYDevice;\n  float *coordZDevice;\n  float *coordZPDevice;\n\n  cudaMalloc(&minMaxLv1Device, blockNum * 2 * sizeof(float));\n  cudaMalloc(&blockIndicesLv1Device, blockNum * sizeof(unsigned int));\n  cudaMalloc(&countedBlockNumLv1Device, sizeof(unsigned int));\n  cudaMalloc(&countedBlockNumLv2Device, sizeof(unsigned int));\n  cudaMalloc(&distinctEdgesTableDevice, sizeof(distinctEdgesTable));\n  cudaMalloc(&triTableDevice, sizeof(triTable));\n  cudaMalloc(&edgeIDTableDevice, sizeof(edgeIDTable));\n  cudaMalloc(&countedVerticesNumDevice, sizeof(unsigned int));\n  cudaMalloc(&countedTrianglesNumDevice, sizeof(unsigned int));\n  cudaMemcpy(distinctEdgesTableDevice, distinctEdgesTable, sizeof(distinctEdgesTable), cudaMemcpyHostToDevice);\n  cudaMemcpy(triTableDevice, triTable, sizeof(triTable), cudaMemcpyHostToDevice);\n  cudaMemcpy(edgeIDTableDevice, edgeIDTable, sizeof(edgeIDTable), cudaMemcpyHostToDevice);\n\n  \n\n  cudaMalloc(&trianglesDevice, sizeof(unsigned long long));\n  cudaMalloc(&coordXDevice, sizeof(float));\n  cudaMalloc(&coordYDevice, sizeof(float));\n  cudaMalloc(&coordZDevice, sizeof(float));\n  cudaMalloc(&coordZPDevice, sizeof(float));\n\n  const dim3 BlockSizeLv1{ voxelXLv1, voxelYLv1, 1 };\n  const dim3 GridSizeLv1{ gridXLv1, gridYLv1, gridZLv1 };\n  \n  const dim3 BlockSizeLv2{ voxelXLv2 * voxelYLv2, blockXLv2 * blockYLv2, 1 };\n  const dim3 BlockSizeGenerating{ voxelXLv2, voxelYLv2, voxelZLv2 };\n\n  float isoValue(-0.9f);\n\n  unsigned int countedBlockNumLv1;\n  unsigned int countedBlockNumLv2;\n  unsigned int countedVerticesNum;\n  unsigned int countedTrianglesNum;\n\n  float time(0.f);\n\n  for (unsigned int c0(0); c0 < repeat; ++c0)\n  {\n    cudaDeviceSynchronize();\n    cudaMemset(countedBlockNumLv1Device, 0, sizeof(unsigned int));\n    cudaMemset(countedBlockNumLv2Device, 0, sizeof(unsigned int));\n    cudaMemset(countedVerticesNumDevice, 0, sizeof(unsigned int));\n    cudaMemset(countedTrianglesNumDevice,0, sizeof(unsigned int));\n    cudaMemset(trianglesDevice, 0, sizeof(unsigned long long));\n    cudaMemset(coordXDevice, 0, sizeof(float));\n    cudaMemset(coordYDevice, 0, sizeof(float));\n    cudaMemset(coordZDevice, 0, sizeof(float));\n    cudaMemset(coordZPDevice, 0, sizeof(float));\n\n    computeMinMaxLv1 <<< GridSizeLv1, BlockSizeLv1 >>> (minMaxLv1Device);\n    compactLv1 <<< countingBlockNumLv1, countingThreadNumLv1 >>> (\n      isoValue, minMaxLv1Device, blockIndicesLv1Device, countedBlockNumLv1Device);\n\n    cudaMemcpy(&countedBlockNumLv1, countedBlockNumLv1Device, sizeof(unsigned int), cudaMemcpyDeviceToHost);\n    cudaMalloc(&minMaxLv2Device, countedBlockNumLv1 * voxelNumLv2 * 2 * sizeof(float));\n\n    computeMinMaxLv2 <<< countedBlockNumLv1, BlockSizeLv2 >>> (blockIndicesLv1Device, minMaxLv2Device);\n\n    cudaMalloc(&blockIndicesLv2Device, countedBlockNumLv1 * voxelNumLv2 * sizeof(unsigned int));\n    unsigned int countingBlockNumLv2((countedBlockNumLv1 * voxelNumLv2 + countingThreadNumLv2 - 1) / countingThreadNumLv2);\n\n    compactLv2 <<< countingBlockNumLv2, countingThreadNumLv2 >>> (\n      isoValue, minMaxLv2Device, blockIndicesLv1Device, blockIndicesLv2Device, countedBlockNumLv1, countedBlockNumLv2Device);\n\n    cudaMemcpy(&countedBlockNumLv2, countedBlockNumLv2Device, sizeof(unsigned int), cudaMemcpyDeviceToHost);\n\n    auto start = std::chrono::steady_clock::now();\n\n    generatingTriangles <<< countedBlockNumLv2, BlockSizeGenerating >>> (\n        isoValue, blockIndicesLv2Device,\n        distinctEdgesTableDevice, triTableDevice, edgeIDTableDevice,\n        countedVerticesNumDevice, countedTrianglesNumDevice, trianglesDevice,\n        coordXDevice, coordYDevice, coordZDevice, coordZPDevice);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    time += ktime;\n\n    cudaMemcpy(&countedVerticesNum, countedVerticesNumDevice, sizeof(unsigned int), cudaMemcpyDeviceToHost);\n    cudaMemcpy(&countedTrianglesNum, countedTrianglesNumDevice, sizeof(unsigned int), cudaMemcpyDeviceToHost);\n\n    cudaFree(minMaxLv2Device);\n    cudaFree(blockIndicesLv2Device);\n  }\n\n  printf(\"Block Lv1: %u\\nBlock Lv2: %u\\n\", countedBlockNumLv1, countedBlockNumLv2);\n  printf(\"Vertices Size: %u\\n\", countedBlockNumLv2 * 304);\n  printf(\"Triangles Size: %u\\n\", countedBlockNumLv2 * 315 * 3);\n  printf(\"Vertices: %u\\nTriangles: %u\\n\", countedVerticesNum, countedTrianglesNum);\n  printf(\"Average kernel execution time (generatingTriangles): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  bool ok = (countedBlockNumLv1 == 8296 && countedBlockNumLv2 == 240380 &&\n             countedVerticesNum == 4856560 && countedTrianglesNum == 6101640);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(minMaxLv1Device);\n  cudaFree(blockIndicesLv1Device);\n  cudaFree(countedBlockNumLv1Device);\n  cudaFree(countedBlockNumLv2Device);\n  cudaFree(distinctEdgesTableDevice);\n  cudaFree(triTableDevice);\n  cudaFree(edgeIDTableDevice);\n  cudaFree(countedVerticesNumDevice);\n  cudaFree(countedTrianglesNumDevice);\n  cudaFree(trianglesDevice);\n  cudaFree(coordXDevice);\n  cudaFree(coordYDevice);\n  cudaFree(coordZDevice);\n  cudaFree(coordZPDevice);\n  return 0;\n}\n"}}
{"kernel_name": "marchingCubes", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n\n\n\n#include <cstdio>\n#include <random>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"tables.h\"\n\n\n\nconstexpr unsigned int N(1024);\nconstexpr unsigned int Nd2(N / 2);\nconstexpr unsigned int voxelXLv1(16);\nconstexpr unsigned int voxelYLv1(16);\nconstexpr unsigned int voxelZLv1(64);\nconstexpr unsigned int gridXLv1((N - 1) / (voxelXLv1 - 1));\nconstexpr unsigned int gridYLv1((N - 1) / (voxelYLv1 - 1));\nconstexpr unsigned int gridZLv1((N - 1) / (voxelZLv1 - 1));\nconstexpr unsigned int countingThreadNumLv1(128);\nconstexpr unsigned int blockNum(gridXLv1* gridYLv1* gridZLv1);\nconstexpr unsigned int countingBlockNumLv1(blockNum / countingThreadNumLv1);\n\nconstexpr unsigned int voxelXLv2(4);\nconstexpr unsigned int voxelYLv2(4);\nconstexpr unsigned int voxelZLv2(8);\nconstexpr unsigned int blockXLv2(5);\nconstexpr unsigned int blockYLv2(5);\nconstexpr unsigned int blockZLv2(9);\nconstexpr unsigned int voxelNumLv2(blockXLv2* blockYLv2* blockZLv2);\n\nconstexpr unsigned int countingThreadNumLv2(1024);\nconstexpr unsigned int gridXLv2(gridXLv1* blockXLv2);\nconstexpr unsigned int gridYLv2(gridYLv1* blockYLv2);\n\n\n\n__inline__ __device__ float f(unsigned int x, unsigned int y, unsigned int z)\n{\n  constexpr float d(2.0f / N);\n  float xf((int(x - Nd2)) * d);\n\n  float yf((int(z - Nd2)) * d);\n  float zf((int(z - Nd2)) * d);\n  return 1.f - 16.f * xf * yf * zf - 4.f * (xf * xf + yf * yf + zf * zf);\n}\n\n__inline__ __device__ float zeroPoint(unsigned int x, float v0, float v1, float isoValue)\n{\n  return ((x * (v1 - isoValue) + (x + 1) * (isoValue - v0)) / (v1 - v0) - Nd2) * (2.0f / N);\n}\n\n__inline__ __device__ float transformToCoord(unsigned int x)\n{\n  return (int(x) - int(Nd2)) * (2.0f / N);\n}\n\n__global__ void computeMinMaxLv1(float*__restrict__ minMax)\n{\n  __shared__ float sminMax[64];\n  constexpr unsigned int threadNum(voxelXLv1 * voxelYLv1);\n  constexpr unsigned int warpNum(threadNum / 32);\n  unsigned int x(blockIdx.x * (voxelXLv1 - 1) + threadIdx.x);\n  unsigned int y(blockIdx.y * (voxelYLv1 - 1) + threadIdx.y);\n  unsigned int z(blockIdx.z * (voxelZLv1 - 1));\n  unsigned int tid(threadIdx.x + voxelXLv1 * threadIdx.y);\n  unsigned int laneid = tid % 32;\n  unsigned int blockid(blockIdx.x + gridXLv1 * (blockIdx.y + gridYLv1 * blockIdx.z));\n  unsigned int warpid(tid >> 5);\n  float v(f(x, y, z));\n  float minV(v), maxV(v);\n  for (int c0(1); c0 < voxelZLv1; ++c0)\n  {\n    v = f(x, y, z + c0);\n    if (v < minV)minV = v;\n    if (v > maxV)maxV = v;\n  }\n#pragma unroll\n  for (int c0(16); c0 > 0; c0 /= 2)\n  {\n    float t0, t1;\n    t0 = __shfl_down(minV, c0);\n    t1 = __shfl_down(maxV, c0);\n    if (t0 < minV)minV = t0;\n    if (t1 > maxV)maxV = t1;\n  }\n  if (laneid == 0)\n  {\n    sminMax[warpid] = minV;\n    sminMax[warpid + warpNum] = maxV;\n  }\n  __syncthreads();\n  if (warpid == 0)\n  {\n    minV = sminMax[laneid];\n    maxV = sminMax[laneid + warpNum];\n#pragma unroll\n    for (int c0(warpNum / 2); c0 > 0; c0 /= 2)\n    {\n      float t0, t1;\n      t0 = __shfl_down(minV, c0);\n      t1 = __shfl_down(maxV, c0);\n      if (t0 < minV)minV = t0;\n      if (t1 > maxV)maxV = t1;\n    }\n    if (laneid == 0)\n    {\n      minMax[blockid * 2] = minV;\n      minMax[blockid * 2 + 1] = maxV;\n    }\n  }\n}\n\n__global__ void compactLv1(\n  float isoValue, \n  const float*__restrict__ minMax,\n  unsigned int*__restrict__ blockIndices,\n  unsigned int*__restrict__ countedBlockNum)\n{\n  __shared__ unsigned int sums[32];\n  constexpr unsigned int warpNum(countingThreadNumLv1 / 32);\n  unsigned int tid(threadIdx.x);\n  unsigned int laneid = tid % 32;\n  unsigned int bIdx(blockIdx.x * countingThreadNumLv1 + tid);\n  unsigned int warpid(tid >> 5);\n  unsigned int test;\n  if (minMax[2 * bIdx] <= isoValue && minMax[2 * bIdx + 1] >= isoValue)test = 1;\n  else test = 0;\n  unsigned int testSum(test);\n#pragma unroll\n  for (int c0(1); c0 < 32; c0 *= 2)\n  {\n    unsigned int tp(__shfl_up(testSum, c0));\n    if (laneid >= c0)testSum += tp;\n  }\n  if (laneid == 31)sums[warpid] = testSum;\n  __syncthreads();\n  if (warpid == 0)\n  {\n    unsigned int warpSum = sums[laneid];\n#pragma unroll\n    for (int c0(1); c0 < warpNum; c0 *= 2)\n    {\n      unsigned int tp(__shfl_up(warpSum, c0));\n      if (laneid >= c0) warpSum += tp;\n    }\n    sums[laneid] = warpSum;\n  }\n  __syncthreads();\n  if (warpid != 0)testSum += sums[warpid - 1];\n  if (tid == countingThreadNumLv1 - 1 && testSum != 0)\n    sums[31] = atomicAdd(countedBlockNum, testSum);\n  __syncthreads();\n  if (test)blockIndices[testSum + sums[31] - 1] = bIdx;\n}\n\n__global__ void computeMinMaxLv2(\n  const unsigned int*__restrict__ blockIndicesLv1,\n  float*__restrict__ minMax)\n{\n  unsigned int tid(threadIdx.x);\n  unsigned int voxelOffset(threadIdx.y);\n  unsigned int blockIndex(blockIndicesLv1[blockIdx.x]);\n  unsigned int tp(blockIndex);\n  unsigned int x((blockIndex % gridXLv1) * (voxelXLv1 - 1) + (voxelOffset % 5) * (voxelXLv2 - 1) + (tid & 3));\n  tp /= gridXLv1;\n  unsigned int y((tp % gridYLv1) * (voxelYLv1 - 1) + (voxelOffset / 5) * (voxelYLv2 - 1) + (tid >> 2));\n  tp /= gridYLv1;\n  unsigned int z(tp * (voxelZLv1 - 1));\n  float v(f(x, y, z));\n  float minV(v), maxV(v);\n  unsigned int idx(2 * (voxelOffset + voxelNumLv2 * blockIdx.x));\n  for (int c0(0); c0 < blockZLv2; ++c0)\n  {\n    for (int c1(1); c1 < voxelZLv2; ++c1)\n    {\n      v = f(x, y, z + c1);\n      if (v < minV)minV = v;\n      if (v > maxV)maxV = v;\n    }\n    z += voxelZLv2 - 1;\n#pragma unroll\n    for (int c1(8); c1 > 0; c1 /= 2)\n    {\n      float t0, t1;\n      t0 = __shfl_down(minV, c1);\n      t1 = __shfl_down(maxV, c1);\n      if (t0 < minV)minV = t0;\n      if (t1 > maxV)maxV = t1;\n    }\n    if (tid == 0)\n    {\n      minMax[idx] = minV;\n      minMax[idx + 1] = maxV;\n      constexpr unsigned int offsetSize(2 * blockXLv2 * blockYLv2);\n      idx += offsetSize;\n    }\n    minV = v;\n    maxV = v;\n  }\n}\n\n__global__ void compactLv2(\n  float isoValue,\n  const float*__restrict__ minMax,\n  const unsigned int*__restrict__ blockIndicesLv1,\n  unsigned int*__restrict__ blockIndicesLv2,\n  unsigned int counterBlockNumLv1,\n  unsigned int*__restrict__ countedBlockNumLv2)\n{\n  __shared__ unsigned int sums[32];\n  constexpr unsigned int warpNum(countingThreadNumLv2 / 32);\n  unsigned int tid(threadIdx.x);\n  unsigned int laneid = tid % 32;\n  unsigned int warpid(tid >> 5);\n  unsigned int id0(tid + blockIdx.x * countingThreadNumLv2);\n  unsigned int id1(id0 / voxelNumLv2);\n  unsigned int test;\n  if (id1 < counterBlockNumLv1)\n  {\n    if (minMax[2 * id0] <= isoValue && minMax[2 * id0 + 1] >= isoValue)\n      test = 1;\n    else\n      test = 0;\n  }\n  else test = 0;\n  unsigned int testSum(test);\n#pragma unroll\n  for (int c0(1); c0 < 32; c0 *= 2)\n  {\n    unsigned int tp(__shfl_up(testSum, c0));\n    if (laneid >= c0)testSum += tp;\n  }\n  if (laneid == 31)sums[warpid] = testSum;\n  __syncthreads();\n  if (warpid == 0)\n  {\n    unsigned warpSum = sums[laneid];\n#pragma unroll\n    for (int c0(1); c0 < warpNum; c0 *= 2)\n    {\n      unsigned int tp(__shfl_up(warpSum, c0));\n      if (laneid >= c0)warpSum += tp;\n    }\n    sums[laneid] = warpSum;\n  }\n  __syncthreads();\n  if (warpid != 0)testSum += sums[warpid - 1];\n  if (tid == countingThreadNumLv2 - 1)\n    sums[31] = atomicAdd(countedBlockNumLv2, testSum);\n  __syncthreads();\n\n  if (test)\n  {\n    unsigned int bIdx1(blockIndicesLv1[id1]);\n    unsigned int bIdx2;\n    unsigned int x1, y1, z1;\n    unsigned int x2, y2, z2;\n    unsigned int tp1(bIdx1);\n    unsigned int tp2((tid + blockIdx.x * countingThreadNumLv2) % voxelNumLv2);\n    x1 = tp1 % gridXLv1;\n    x2 = tp2 % blockXLv2;\n    tp1 /= gridXLv1;\n    tp2 /= blockXLv2;\n    y1 = tp1 % gridYLv1;\n    y2 = tp2 % blockYLv2;\n    z1 = tp1 / gridYLv1;\n    z2 = tp2 / blockYLv2;\n    bIdx2 = x2 + blockXLv2 * (x1 + gridXLv1 * (y2 + blockYLv2 * (y1 + gridYLv1 * (z1 * blockZLv2 + z2))));\n    blockIndicesLv2[testSum + sums[31] - 1] = bIdx2;\n  }\n}\n\n__global__ void generatingTriangles(\n  float isoValue, \n  const unsigned int*__restrict__ blockIndicesLv2,\n  const unsigned short *__restrict__ distinctEdgesTable,\n  const int *__restrict__ triTable,\n  const uchar4 *__restrict__ edgeIDTable,\n  unsigned int*__restrict__ countedVerticesNum,\n  unsigned int*__restrict__ countedTrianglesNum,\n  unsigned long long*__restrict__ triangles,\n  float*__restrict__ coordX,\n  float*__restrict__ coordY,\n  float*__restrict__ coordZ,\n  float*__restrict__ coordZP)\n{\n  __shared__ unsigned short vertexIndices[voxelZLv2][voxelYLv2][voxelXLv2];\n  __shared__ float value[voxelZLv2 + 1][voxelYLv2 + 1][voxelXLv2 + 1];\n  __shared__ unsigned int sumsVertices[32];\n  __shared__ unsigned int sumsTriangles[32];\n\n  unsigned int blockId(blockIndicesLv2[blockIdx.x]);\n  unsigned int tp(blockId);\n  unsigned int x((tp % gridXLv2) * (voxelXLv2 - 1) + threadIdx.x);\n  tp /= gridXLv2;\n  unsigned int y((tp % gridYLv2) * (voxelYLv2 - 1) + threadIdx.y);\n  unsigned int z((tp / gridYLv2) * (voxelZLv2 - 1) + threadIdx.z);\n  unsigned int eds(7);\n  float v(value[threadIdx.z][threadIdx.y][threadIdx.x] = f(x, y, z));\n  if (threadIdx.x == voxelXLv2 - 1)\n  {\n    eds &= 6;\n    value[threadIdx.z][threadIdx.y][voxelXLv2] = f(x + 1, y, z);\n    if (threadIdx.y == voxelYLv2 - 1)\n      value[threadIdx.z][voxelYLv2][voxelXLv2] = f(x + 1, y + 1, z);\n  }\n  if (threadIdx.y == voxelYLv2 - 1)\n  {\n    eds &= 5;\n    value[threadIdx.z][voxelYLv2][threadIdx.x] = f(x, y + 1, z);\n    if (threadIdx.z == voxelZLv2 - 1)\n      value[voxelZLv2][voxelYLv2][threadIdx.x] = f(x, y + 1, z + 1);\n  }\n  if (threadIdx.z == voxelZLv2 - 1)\n  {\n    eds &= 3;\n    value[voxelZLv2][threadIdx.y][threadIdx.x] = f(x, y, z + 1);\n    if (threadIdx.x == voxelXLv2 - 1)\n      value[voxelZLv2][threadIdx.y][voxelXLv2] = f(x + 1, y, z + 1);\n  }\n  eds <<= 13;\n  __syncthreads();\n  unsigned int cubeCase(0);\n  if (value[threadIdx.z][threadIdx.y][threadIdx.x] < isoValue) cubeCase |= 1;\n  if (value[threadIdx.z][threadIdx.y][threadIdx.x + 1] < isoValue) cubeCase |= 2;\n  if (value[threadIdx.z][threadIdx.y + 1][threadIdx.x + 1] < isoValue) cubeCase |= 4;\n  if (value[threadIdx.z][threadIdx.y + 1][threadIdx.x] < isoValue) cubeCase |= 8;\n  if (value[threadIdx.z + 1][threadIdx.y][threadIdx.x] < isoValue) cubeCase |= 16;\n  if (value[threadIdx.z + 1][threadIdx.y][threadIdx.x + 1] < isoValue) cubeCase |= 32;\n  if (value[threadIdx.z + 1][threadIdx.y + 1][threadIdx.x + 1] < isoValue) cubeCase |= 64;\n  if (value[threadIdx.z + 1][threadIdx.y + 1][threadIdx.x] < isoValue) cubeCase |= 128;\n\n  unsigned int distinctEdges(eds ? distinctEdgesTable[cubeCase] : 0);\n  unsigned int numTriangles(eds != 0xe000 ? 0 : distinctEdges & 7);\n  unsigned int numVertices(__popc(distinctEdges &= eds));\n  unsigned int laneid = (threadIdx.x + voxelXLv2 * (threadIdx.y + voxelYLv2 * threadIdx.z)) % 32;\n  unsigned warpid((threadIdx.x + voxelXLv2 * (threadIdx.y + voxelYLv2 * threadIdx.z)) >> 5);\n  constexpr unsigned int threadNum(voxelXLv2 * voxelYLv2 * voxelZLv2);\n  constexpr unsigned int warpNum(threadNum / 32);\n  unsigned int sumVertices(numVertices);\n  unsigned int sumTriangles(numTriangles);\n\n#pragma unroll\n  for (int c0(1); c0 < 32; c0 *= 2)\n  {\n    unsigned int tp0(__shfl_up(sumVertices, c0));\n    unsigned int tp1(__shfl_up(sumTriangles, c0));\n    if (laneid >= c0)\n    {\n      sumVertices += tp0;\n      sumTriangles += tp1;\n    }\n  }\n  if (laneid == 31)\n  {\n    sumsVertices[warpid] = sumVertices;\n    sumsTriangles[warpid] = sumTriangles;\n  }\n  __syncthreads();\n  if (warpid == 0)\n  {\n    unsigned warpSumVertices = sumsVertices[laneid];\n    unsigned warpSumTriangles = sumsTriangles[laneid];\n#pragma unroll\n    for (int c0(1); c0 < warpNum; c0 *= 2)\n    {\n      unsigned int tp0(__shfl_up(warpSumVertices, c0));\n      unsigned int tp1(__shfl_up(warpSumTriangles, c0));\n      if (laneid >= c0)\n      {\n        warpSumVertices += tp0;\n        warpSumTriangles += tp1;\n      }\n    }\n    sumsVertices[laneid] = warpSumVertices;\n    sumsTriangles[laneid] = warpSumTriangles;\n  }\n  __syncthreads();\n  if (warpid != 0)\n  {\n    sumVertices += sumsVertices[warpid - 1];\n    sumTriangles += sumsTriangles[warpid - 1];\n  }\n  if (eds == 0)\n  {\n    sumsVertices[31] = atomicAdd(countedVerticesNum, sumVertices);\n    sumsTriangles[31] = atomicAdd(countedTrianglesNum, sumTriangles);\n  }\n\n  unsigned int interOffsetVertices(sumVertices - numVertices);\n  sumVertices = interOffsetVertices + sumsVertices[31];\n\n  sumTriangles = sumTriangles + sumsTriangles[31] - numTriangles;\n\n  vertexIndices[threadIdx.z][threadIdx.y][threadIdx.x] = interOffsetVertices | distinctEdges;\n  __syncthreads();\n\n  for (unsigned int c0(0); c0 < numTriangles; ++c0)\n  {\n#pragma unroll\n    for (unsigned int c1(0); c1 < 3; ++c1)\n    {\n      int edgeID(triTable[16 * cubeCase + 3 * c0 + c1]);\n      uchar4 edgePos(edgeIDTable[edgeID]);\n      unsigned short vertexIndex(vertexIndices[threadIdx.z + edgePos.z][threadIdx.y + edgePos.y][threadIdx.x + edgePos.x]);\n      unsigned int tp(__popc(vertexIndex >> (16 - edgePos.w)) + (vertexIndex & 0x1fff));\n      atomicAdd(triangles, (unsigned long long)(sumsVertices[31] + tp));\n    }\n  }\n\n  \n\n  float zp = 0.f, cx = 0.f, cy = 0.f, cz = 0.f;\n\n  if (distinctEdges & (1 << 15))\n  {\n    zp = zeroPoint(x, v, value[threadIdx.z][threadIdx.y][threadIdx.x + 1], isoValue);\n    cy = transformToCoord(y);\n    cz = transformToCoord(z);\n  }\n  if (distinctEdges & (1 << 14))\n  {\n    cx = transformToCoord(x);\n    zp += zeroPoint(y, v, value[threadIdx.z][threadIdx.y + 1][threadIdx.x], isoValue);\n    cz += transformToCoord(z);\n  }\n  if (distinctEdges & (1 << 13))\n  {\n    cx += transformToCoord(x);\n    cy += transformToCoord(y);\n    zp += zeroPoint(z, v, value[threadIdx.z + 1][threadIdx.y][threadIdx.x], isoValue);\n  }\n  atomicAdd(coordX, cx);\n  atomicAdd(coordY, cy);\n  atomicAdd(coordZ, cz);\n  atomicAdd(coordZP, zp);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  unsigned int repeat = atoi(argv[1]);\n\n  std::uniform_real_distribution<float>rd(0, 1);\n  std::mt19937 mt(123);\n\n  float* minMaxLv1Device;\n  float* minMaxLv2Device;\n  unsigned int* blockIndicesLv1Device;\n  unsigned int* blockIndicesLv2Device;\n  unsigned int* countedBlockNumLv1Device;\n  unsigned int* countedBlockNumLv2Device;\n  unsigned short* distinctEdgesTableDevice;\n  int* triTableDevice;\n  uchar4* edgeIDTableDevice;\n  unsigned int* countedVerticesNumDevice;\n  unsigned int* countedTrianglesNumDevice;\n  unsigned long long* trianglesDevice;\n  float *coordXDevice;\n  float *coordYDevice;\n  float *coordZDevice;\n  float *coordZPDevice;\n\n  hipMalloc(&minMaxLv1Device, blockNum * 2 * sizeof(float));\n  hipMalloc(&blockIndicesLv1Device, blockNum * sizeof(unsigned int));\n  hipMalloc(&countedBlockNumLv1Device, sizeof(unsigned int));\n  hipMalloc(&countedBlockNumLv2Device, sizeof(unsigned int));\n  hipMalloc(&distinctEdgesTableDevice, sizeof(distinctEdgesTable));\n  hipMalloc(&triTableDevice, sizeof(triTable));\n  hipMalloc(&edgeIDTableDevice, sizeof(edgeIDTable));\n  hipMalloc(&countedVerticesNumDevice, sizeof(unsigned int));\n  hipMalloc(&countedTrianglesNumDevice, sizeof(unsigned int));\n  hipMemcpy(distinctEdgesTableDevice, distinctEdgesTable, sizeof(distinctEdgesTable), hipMemcpyHostToDevice);\n  hipMemcpy(triTableDevice, triTable, sizeof(triTable), hipMemcpyHostToDevice);\n  hipMemcpy(edgeIDTableDevice, edgeIDTable, sizeof(edgeIDTable), hipMemcpyHostToDevice);\n\n  \n\n  hipMalloc(&trianglesDevice, sizeof(unsigned long long));\n  hipMalloc(&coordXDevice, sizeof(float));\n  hipMalloc(&coordYDevice, sizeof(float));\n  hipMalloc(&coordZDevice, sizeof(float));\n  hipMalloc(&coordZPDevice, sizeof(float));\n\n  const dim3 BlockSizeLv1{ voxelXLv1, voxelYLv1, 1 };\n  const dim3 GridSizeLv1{ gridXLv1, gridYLv1, gridZLv1 };\n  \n  const dim3 BlockSizeLv2{ voxelXLv2 * voxelYLv2, blockXLv2 * blockYLv2, 1 };\n  const dim3 BlockSizeGenerating{ voxelXLv2, voxelYLv2, voxelZLv2 };\n\n  float isoValue(-0.9f);\n\n  unsigned int countedBlockNumLv1;\n  unsigned int countedBlockNumLv2;\n  unsigned int countedVerticesNum;\n  unsigned int countedTrianglesNum;\n\n  float time(0.f);\n\n  for (unsigned int c0(0); c0 < repeat; ++c0)\n  {\n    hipDeviceSynchronize();\n    hipMemset(countedBlockNumLv1Device, 0, sizeof(unsigned int));\n    hipMemset(countedBlockNumLv2Device, 0, sizeof(unsigned int));\n    hipMemset(countedVerticesNumDevice, 0, sizeof(unsigned int));\n    hipMemset(countedTrianglesNumDevice,0, sizeof(unsigned int));\n    hipMemset(trianglesDevice, 0, sizeof(unsigned long long));\n    hipMemset(coordXDevice, 0, sizeof(float));\n    hipMemset(coordYDevice, 0, sizeof(float));\n    hipMemset(coordZDevice, 0, sizeof(float));\n    hipMemset(coordZPDevice, 0, sizeof(float));\n\n    hipLaunchKernelGGL(computeMinMaxLv1, GridSizeLv1, BlockSizeLv1, 0, 0, minMaxLv1Device);\n    hipLaunchKernelGGL(compactLv1, dim3(countingBlockNumLv1), dim3(countingThreadNumLv1), 0, 0, \n      isoValue, minMaxLv1Device, blockIndicesLv1Device, countedBlockNumLv1Device);\n\n    hipMemcpy(&countedBlockNumLv1, countedBlockNumLv1Device, sizeof(unsigned int), hipMemcpyDeviceToHost);\n    hipMalloc(&minMaxLv2Device, countedBlockNumLv1 * voxelNumLv2 * 2 * sizeof(float));\n\n    hipLaunchKernelGGL(computeMinMaxLv2, dim3(countedBlockNumLv1), BlockSizeLv2, 0, 0, blockIndicesLv1Device, minMaxLv2Device);\n\n    hipMalloc(&blockIndicesLv2Device, countedBlockNumLv1 * voxelNumLv2 * sizeof(unsigned int));\n    unsigned int countingBlockNumLv2((countedBlockNumLv1 * voxelNumLv2 + countingThreadNumLv2 - 1) / countingThreadNumLv2);\n\n    hipLaunchKernelGGL(compactLv2, dim3(countingBlockNumLv2), dim3(countingThreadNumLv2 ), 0, 0, \n      isoValue, minMaxLv2Device, blockIndicesLv1Device, blockIndicesLv2Device, countedBlockNumLv1, countedBlockNumLv2Device);\n\n    hipMemcpy(&countedBlockNumLv2, countedBlockNumLv2Device, sizeof(unsigned int), hipMemcpyDeviceToHost);\n\n    auto start = std::chrono::steady_clock::now();\n\n    hipLaunchKernelGGL(generatingTriangles, dim3(countedBlockNumLv2), BlockSizeGenerating, 0, 0, \n        isoValue, blockIndicesLv2Device,\n        distinctEdgesTableDevice, triTableDevice, edgeIDTableDevice,\n        countedVerticesNumDevice, countedTrianglesNumDevice, trianglesDevice,\n        coordXDevice, coordYDevice, coordZDevice, coordZPDevice);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    time += ktime;\n\n    hipMemcpy(&countedVerticesNum, countedVerticesNumDevice, sizeof(unsigned int), hipMemcpyDeviceToHost);\n    hipMemcpy(&countedTrianglesNum, countedTrianglesNumDevice, sizeof(unsigned int), hipMemcpyDeviceToHost);\n\n    hipFree(minMaxLv2Device);\n    hipFree(blockIndicesLv2Device);\n  }\n\n  printf(\"Block Lv1: %u\\nBlock Lv2: %u\\n\", countedBlockNumLv1, countedBlockNumLv2);\n  printf(\"Vertices Size: %u\\n\", countedBlockNumLv2 * 304);\n  printf(\"Triangles Size: %u\\n\", countedBlockNumLv2 * 315 * 3);\n  printf(\"Vertices: %u\\nTriangles: %u\\n\", countedVerticesNum, countedTrianglesNum);\n  printf(\"Average kernel execution time (generatingTriangles): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  bool ok = (countedBlockNumLv1 == 8296 && countedBlockNumLv2 == 240380 &&\n             countedVerticesNum == 4856560 && countedTrianglesNum == 6101640);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(minMaxLv1Device);\n  hipFree(blockIndicesLv1Device);\n  hipFree(countedBlockNumLv1Device);\n  hipFree(countedBlockNumLv2Device);\n  hipFree(distinctEdgesTableDevice);\n  hipFree(triTableDevice);\n  hipFree(edgeIDTableDevice);\n  hipFree(countedVerticesNumDevice);\n  hipFree(countedTrianglesNumDevice);\n  hipFree(trianglesDevice);\n  hipFree(coordXDevice);\n  hipFree(coordYDevice);\n  hipFree(coordZDevice);\n  hipFree(coordZPDevice);\n  return 0;\n}\n"}}
{"kernel_name": "marchingCubes", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n\n\n\n#include <cstdio>\n#include <random>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nusing uchar4 = sycl::uchar4;\n#include \"tables.h\"\n\n\n\nconstexpr unsigned int N(1024);\nconstexpr unsigned int Nd2(N / 2);\nconstexpr unsigned int voxelXLv1(16);\nconstexpr unsigned int voxelYLv1(16);\nconstexpr unsigned int voxelZLv1(64);\nconstexpr unsigned int gridXLv1((N - 1) / (voxelXLv1 - 1));\nconstexpr unsigned int gridYLv1((N - 1) / (voxelYLv1 - 1));\nconstexpr unsigned int gridZLv1((N - 1) / (voxelZLv1 - 1));\nconstexpr unsigned int countingThreadNumLv1(128);\nconstexpr unsigned int blockNum(gridXLv1* gridYLv1* gridZLv1);\nconstexpr unsigned int countingBlockNumLv1(blockNum / countingThreadNumLv1);\n\nconstexpr unsigned int voxelXLv2(4);\nconstexpr unsigned int voxelYLv2(4);\nconstexpr unsigned int voxelZLv2(8);\nconstexpr unsigned int blockXLv2(5);\nconstexpr unsigned int blockYLv2(5);\nconstexpr unsigned int blockZLv2(9);\nconstexpr unsigned int voxelNumLv2(blockXLv2* blockYLv2* blockZLv2);\n\nconstexpr unsigned int countingThreadNumLv2(1024);\nconstexpr unsigned int gridXLv2(gridXLv1* blockXLv2);\nconstexpr unsigned int gridYLv2(gridYLv1* blockYLv2);\n\n\n\ntemplate <typename T>\ninline T atomicAdd(T *var, T val)\n{\n  auto atm = sycl::atomic_ref<T,\n    sycl::memory_order::relaxed,\n    sycl::memory_scope::device,\n    sycl::access::address_space::global_space>(*var);\n  return atm.fetch_add(val);\n}\n\ninline float f(unsigned int x, unsigned int y, unsigned int z)\n{\n  constexpr float d(2.0f / N);\n  float xf((int(x - Nd2)) * d);\n\n  float yf((int(z - Nd2)) * d);\n  float zf((int(z - Nd2)) * d);\n  return 1.f - 16.f * xf * yf * zf - 4.f * (xf * xf + yf * yf + zf * zf);\n}\n\ninline float zeroPoint(unsigned int x, float v0, float v1, float isoValue)\n{\n  return ((x * (v1 - isoValue) + (x + 1) * (isoValue - v0)) / (v1 - v0) - Nd2) * (2.0f / N);\n}\n\ninline float transformToCoord(unsigned int x)\n{\n  return (int(x) - int(Nd2)) * (2.0f / N);\n}\n\nvoid computeMinMaxLv1(float*__restrict minMax, float *__restrict sminMax, sycl::nd_item<3> &item)\n{\n  constexpr unsigned int threadNum(voxelXLv1 * voxelYLv1);\n  constexpr unsigned int warpNum(threadNum / 32);\n  auto sg = item.get_sub_group();\n  int blockIdx_z = item.get_group(0);\n  int blockIdx_y = item.get_group(1);\n  int blockIdx_x = item.get_group(2);\n  int threadIdx_z = item.get_local_id(0);\n  int threadIdx_y = item.get_local_id(1);\n  int threadIdx_x = item.get_local_id(2);\n  unsigned int x(blockIdx_x * (voxelXLv1 - 1) + threadIdx_x);\n  unsigned int y(blockIdx_y * (voxelYLv1 - 1) + threadIdx_y);\n  unsigned int z(blockIdx_z * (voxelZLv1 - 1));\n  unsigned int tid(threadIdx_x + voxelXLv1 * threadIdx_y);\n  unsigned int laneid = tid % 32;\n  unsigned int blockid(blockIdx_x + gridXLv1 * (blockIdx_y + gridYLv1 * blockIdx_z));\n  unsigned int warpid(tid >> 5);\n  float v(f(x, y, z));\n  float minV(v), maxV(v);\n  for (int c0(1); c0 < voxelZLv1; ++c0)\n  {\n    v = f(x, y, z + c0);\n    if (v < minV)minV = v;\n    if (v > maxV)maxV = v;\n  }\n#pragma unroll\n  for (int c0(16); c0 > 0; c0 /= 2)\n  {\n    float t0, t1;\n    t0 = sg.shuffle_down(minV, c0);\n    t1 = sg.shuffle_down(maxV, c0);\n    if (t0 < minV)minV = t0;\n    if (t1 > maxV)maxV = t1;\n  }\n  if (laneid == 0)\n  {\n    sminMax[warpid] = minV;\n    sminMax[warpid + warpNum] = maxV;\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n  if (warpid == 0)\n  {\n    minV = sminMax[laneid];\n    maxV = sminMax[laneid + warpNum];\n#pragma unroll\n    for (int c0(warpNum / 2); c0 > 0; c0 /= 2)\n    {\n      float t0, t1;\n      t0 = sg.shuffle_down(minV, c0);\n      t1 = sg.shuffle_down(maxV, c0);\n      if (t0 < minV)minV = t0;\n      if (t1 > maxV)maxV = t1;\n    }\n    if (laneid == 0)\n    {\n      minMax[blockid * 2] = minV;\n      minMax[blockid * 2 + 1] = maxV;\n    }\n  }\n}\n\nvoid compactLv1(\n  float isoValue,\n  const float*__restrict minMax,\n  unsigned int*__restrict blockIndices,\n  unsigned int*__restrict countedBlockNum,\n  unsigned int*__restrict sums,\n  sycl::nd_item<1> &item)\n{\n  auto sg = item.get_sub_group();\n  constexpr unsigned int warpNum(countingThreadNumLv1 / 32);\n  unsigned int tid(item.get_local_id(0));\n  unsigned int laneid = tid % 32;\n  unsigned int bIdx(item.get_group(0) * countingThreadNumLv1 + tid);\n  unsigned int warpid(tid >> 5);\n  unsigned int test;\n  if (minMax[2 * bIdx] <= isoValue && minMax[2 * bIdx + 1] >= isoValue)test = 1;\n  else test = 0;\n  unsigned int testSum(test);\n#pragma unroll\n  for (int c0(1); c0 < 32; c0 *= 2)\n  {\n    unsigned int tp(sg.shuffle_up(testSum, c0));\n    if (laneid >= c0) testSum += tp;\n  }\n  if (laneid == 31)sums[warpid] = testSum;\n  item.barrier(sycl::access::fence_space::local_space);\n  if (warpid == 0)\n  {\n    unsigned warpSum = sums[laneid];\n#pragma unroll\n    for (int c0(1); c0 < warpNum; c0 *= 2)\n    {\n      unsigned int tp(sg.shuffle_up(warpSum, c0));\n      if (laneid >= c0) warpSum += tp;\n    }\n    sums[laneid] = warpSum;\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n  if (warpid != 0)testSum += sums[warpid - 1];\n  if (tid == countingThreadNumLv1 - 1 && testSum != 0) {\n    sums[31] = atomicAdd(countedBlockNum, testSum);\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n  if (test) blockIndices[testSum + sums[31] - 1] = bIdx;\n}\n\nvoid computeMinMaxLv2(\n  const unsigned int*__restrict blockIndicesLv1,\n  float*__restrict minMax,\n  sycl::nd_item<2> &item)\n{\n  auto sg = item.get_sub_group();\n  unsigned int tid(item.get_local_id(1));\n  unsigned int voxelOffset(item.get_local_id(0));\n  unsigned int blockIdx_x = item.get_group(1);\n  unsigned int blockIndex(blockIndicesLv1[blockIdx_x]);\n  unsigned int tp(blockIndex);\n  unsigned int x((blockIndex % gridXLv1) * (voxelXLv1 - 1) + (voxelOffset % 5) * (voxelXLv2 - 1) + (tid & 3));\n  tp /= gridXLv1;\n  unsigned int y((tp % gridYLv1) * (voxelYLv1 - 1) + (voxelOffset / 5) * (voxelYLv2 - 1) + (tid >> 2));\n  tp /= gridYLv1;\n  unsigned int z(tp * (voxelZLv1 - 1));\n  float v(f(x, y, z));\n  float minV(v), maxV(v);\n  unsigned int idx(2 * (voxelOffset + voxelNumLv2 * blockIdx_x));\n  for (int c0(0); c0 < blockZLv2; ++c0)\n  {\n    for (int c1(1); c1 < voxelZLv2; ++c1)\n    {\n      v = f(x, y, z + c1);\n      if (v < minV)minV = v;\n      if (v > maxV)maxV = v;\n    }\n    z += voxelZLv2 - 1;\n#pragma unroll\n    for (int c1(8); c1 > 0; c1 /= 2)\n    {\n      float t0, t1;\n      t0 = sg.shuffle_down(minV, c1);\n      t1 = sg.shuffle_down(maxV, c1);\n      if (t0 < minV)minV = t0;\n      if (t1 > maxV)maxV = t1;\n    }\n    if (tid == 0)\n    {\n      minMax[idx] = minV;\n      minMax[idx + 1] = maxV;\n      constexpr unsigned int offsetSize(2 * blockXLv2 * blockYLv2);\n      idx += offsetSize;\n    }\n    minV = v;\n    maxV = v;\n  }\n}\n\nvoid compactLv2(\n  float isoValue,\n  const float*__restrict minMax,\n  const unsigned int*__restrict blockIndicesLv1,\n  unsigned int*__restrict blockIndicesLv2,\n  unsigned int counterBlockNumLv1,\n  unsigned int*__restrict countedBlockNumLv2,\n  unsigned int*__restrict sums,\n  sycl::nd_item<1> &item)\n{\n  auto sg = item.get_sub_group();\n  constexpr unsigned int warpNum(countingThreadNumLv2 / 32);\n  unsigned int tid(item.get_local_id(0));\n  unsigned int laneid = tid % 32;\n  unsigned int warpid(tid >> 5);\n  unsigned int id0(tid + item.get_group(0) * countingThreadNumLv2);\n  unsigned int id1(id0 / voxelNumLv2);\n  unsigned int test;\n  if (id1 < counterBlockNumLv1)\n  {\n    if (minMax[2 * id0] <= isoValue && minMax[2 * id0 + 1] >= isoValue)\n      test = 1;\n    else\n      test = 0;\n  }\n  else test = 0;\n  unsigned int testSum(test);\n#pragma unroll\n  for (int c0(1); c0 < 32; c0 *= 2)\n  {\n    unsigned int tp(sg.shuffle_up(testSum, c0));\n    if (laneid >= c0) testSum += tp;\n  }\n  if (laneid == 31) sums[warpid] = testSum;\n  item.barrier(sycl::access::fence_space::local_space);\n  if (warpid == 0)\n  {\n    unsigned int warpSum = sums[laneid];\n#pragma unroll\n    for (int c0(1); c0 < warpNum; c0 *= 2)\n    {\n      unsigned int tp(sg.shuffle_up(warpSum, c0));\n      if (laneid >= c0)warpSum += tp;\n    }\n    sums[laneid] = warpSum;\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n  if (warpid != 0) testSum += sums[warpid - 1];\n  if (tid == countingThreadNumLv2 - 1) {\n    sums[31] = atomicAdd(countedBlockNumLv2, testSum);\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (test)\n  {\n    unsigned int bIdx1(blockIndicesLv1[id1]);\n    unsigned int bIdx2;\n    unsigned int x1, y1, z1;\n    unsigned int x2, y2, z2;\n    unsigned int tp1(bIdx1);\n    unsigned int tp2((tid + item.get_group(0) * countingThreadNumLv2) % voxelNumLv2);\n    x1 = tp1 % gridXLv1;\n    x2 = tp2 % blockXLv2;\n    tp1 /= gridXLv1;\n    tp2 /= blockXLv2;\n    y1 = tp1 % gridYLv1;\n    y2 = tp2 % blockYLv2;\n    z1 = tp1 / gridYLv1;\n    z2 = tp2 / blockYLv2;\n    bIdx2 = x2 + blockXLv2 * (x1 + gridXLv1 * (y2 + blockYLv2 * (y1 + gridYLv1 * (z1 * blockZLv2 + z2))));\n    blockIndicesLv2[testSum + sums[31] - 1] = bIdx2;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  unsigned int repeat = atoi(argv[1]);\n\n  std::uniform_real_distribution<float>rd(0, 1);\n  std::mt19937 mt(123);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *minMaxLv1Device = sycl::malloc_device<float>(blockNum * 2 , q);\n  unsigned int *blockIndicesLv1Device = sycl::malloc_device<unsigned int>( blockNum , q);\n  unsigned int *countedBlockNumLv1Device = sycl::malloc_device<unsigned int>(1, q);\n  unsigned int *countedBlockNumLv2Device = sycl::malloc_device<unsigned int>(1, q);\n\n  unsigned short *distinctEdgesTableDevice = sycl::malloc_device<unsigned short>(256, q);\n  q.memcpy(distinctEdgesTableDevice, distinctEdgesTable, sizeof(distinctEdgesTable));\n\n  int *triTableDevice = sycl::malloc_device<int>(256*16, q);\n  q.memcpy(triTableDevice, triTable, sizeof(triTable));\n\n  uchar4 *edgeIDTableDevice = sycl::malloc_device<uchar4>(12, q);\n  q.memcpy(edgeIDTableDevice, edgeIDTable, sizeof(edgeIDTable));\n\n  unsigned int *countedVerticesNumDevice = sycl::malloc_device<unsigned int>(1, q);\n  unsigned int *countedTrianglesNumDevice = sycl::malloc_device<unsigned int>(1, q);\n\n  \n\n  unsigned long long *trianglesDevice = sycl::malloc_device<unsigned long long>(1, q);\n  float *coordXDevice = sycl::malloc_device<float>(1, q);\n  float *coordYDevice = sycl::malloc_device<float>(1, q);\n  float *coordZDevice = sycl::malloc_device<float>(1, q);\n  float *coordZPDevice = sycl::malloc_device<float>(1, q);\n\n  const sycl::range<3> BlockSizeLv1{ 1, voxelYLv1, voxelXLv1};\n  const sycl::range<3> GridSizeLv1{ gridZLv1, gridYLv1, gridXLv1 };\n  const sycl::range<2> BlockSizeLv2{ blockXLv2 * blockYLv2, voxelXLv2 * voxelYLv2 };\n  const sycl::range<3> BlockSizeGenerating{ voxelZLv2, voxelYLv2, voxelXLv2 };\n\n  float isoValue(-0.9f);\n\n  unsigned int countedBlockNumLv1;\n  unsigned int countedBlockNumLv2;\n  unsigned int countedVerticesNum;\n  unsigned int countedTrianglesNum;\n\n  float time(0.f);\n\n  for (unsigned int c0(0); c0 < repeat; ++c0)\n  {\n    q.wait();\n\n    q.memset(countedBlockNumLv1Device, 0, sizeof(unsigned int));\n    q.memset(countedBlockNumLv2Device, 0, sizeof(unsigned int));\n    q.memset(countedVerticesNumDevice, 0, sizeof(unsigned int));\n    q.memset(countedTrianglesNumDevice,0, sizeof(unsigned int));\n    q.memset(trianglesDevice, 0, sizeof(unsigned long long));\n    q.memset(coordXDevice, 0, sizeof(float));\n    q.memset(coordYDevice, 0, sizeof(float));\n    q.memset(coordZDevice, 0, sizeof(float));\n    q.memset(coordZPDevice, 0, sizeof(float));\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> smem (sycl::range<1>(64), cgh);\n      cgh.parallel_for<class min_max1>(\n        sycl::nd_range<3>(GridSizeLv1*BlockSizeLv1, BlockSizeLv1), [=] (sycl::nd_item<3> item) {\n        computeMinMaxLv1(minMaxLv1Device, smem.get_pointer(), item);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<unsigned int, 1> smem (sycl::range<1>(32), cgh);\n      cgh.parallel_for<class compact1>(sycl::nd_range<1>(\n        sycl::range<1>(countingBlockNumLv1*countingThreadNumLv1),\n        sycl::range<1>(countingThreadNumLv1)), [=] (sycl::nd_item<1> item) {\n        compactLv1(isoValue,\n                   minMaxLv1Device,\n                   blockIndicesLv1Device,\n                   countedBlockNumLv1Device,\n                   smem.get_pointer(),\n                   item);\n      });\n    });\n\n    q.memcpy(&countedBlockNumLv1, countedBlockNumLv1Device, sizeof(unsigned int));\n\n    float *minMaxLv2Device = sycl::malloc_device<float>(countedBlockNumLv1 * voxelNumLv2 * 2, q);\n\n    const sycl::range<2> GridSizeLv2 (1, countedBlockNumLv1);\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class min_max2>(\n        sycl::nd_range<2>(GridSizeLv2*BlockSizeLv2, BlockSizeLv2), [=] (sycl::nd_item<2> item) {\n        computeMinMaxLv2(blockIndicesLv1Device, minMaxLv2Device, item);\n      });\n    });\n\n    unsigned int *blockIndicesLv2Device = sycl::malloc_device<unsigned int>(countedBlockNumLv1 * voxelNumLv2, q);\n    unsigned int countingBlockNumLv2((countedBlockNumLv1 * voxelNumLv2 + countingThreadNumLv2 - 1) / countingThreadNumLv2);\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<unsigned int, 1> smem (sycl::range<1>(32), cgh);\n      cgh.parallel_for<class compact2>(sycl::nd_range<1>(\n        sycl::range<1>(countingBlockNumLv2*countingThreadNumLv2),\n        sycl::range<1>(countingThreadNumLv2)), [=] (sycl::nd_item<1> item) {\n        compactLv2(isoValue,\n                     minMaxLv2Device,\n                     blockIndicesLv1Device,\n                     blockIndicesLv2Device,\n                     countedBlockNumLv1,\n                     countedBlockNumLv2Device,\n                     smem.get_pointer(),\n                     item);\n      });\n    });\n\n    q.memcpy(&countedBlockNumLv2, countedBlockNumLv2Device, sizeof(unsigned int)).wait();\n\n    auto start = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<unsigned short, 3> vertexIndices(sycl::range<3>{voxelZLv2, voxelYLv2, voxelXLv2}, cgh);\n      sycl::local_accessor<float, 3> value(sycl::range<3>{voxelZLv2+1, voxelYLv2+1, voxelXLv2+1}, cgh);\n      sycl::local_accessor<unsigned int, 1> sumsVertices(sycl::range<1>(32), cgh);\n      sycl::local_accessor<unsigned int, 1> sumsTriangles(sycl::range<1>(32), cgh);\n\n      const sycl::range<3> trianglesBlock (1,1,countedBlockNumLv2);\n      cgh.parallel_for<class triangles_gen>(\n        sycl::nd_range<3>(trianglesBlock*BlockSizeGenerating, BlockSizeGenerating), [=] (sycl::nd_item<3> item) {\n        auto sg = item.get_sub_group();\n        unsigned int threadIdx_x = item.get_local_id(2);\n        unsigned int threadIdx_y = item.get_local_id(1);\n        unsigned int threadIdx_z = item.get_local_id(0);\n\n        unsigned int blockId(blockIndicesLv2Device[item.get_group(2)]);\n        unsigned int tp(blockId);\n        unsigned int x((tp % gridXLv2) * (voxelXLv2 - 1) + threadIdx_x);\n        tp /= gridXLv2;\n        unsigned int y((tp % gridYLv2) * (voxelYLv2 - 1) + threadIdx_y);\n        unsigned int z((tp / gridYLv2) * (voxelZLv2 - 1) + threadIdx_z);\n        unsigned int eds(7);\n        float v(value[threadIdx_z][threadIdx_y][threadIdx_x] = f(x, y, z));\n        if (threadIdx_x == voxelXLv2 - 1)\n        {\n          eds &= 6;\n          value[threadIdx_z][threadIdx_y][voxelXLv2] = f(x + 1, y, z);\n          if (threadIdx_y == voxelYLv2 - 1)\n            value[threadIdx_z][voxelYLv2][voxelXLv2] = f(x + 1, y + 1, z);\n        }\n        if (threadIdx_y == voxelYLv2 - 1)\n        {\n          eds &= 5;\n          value[threadIdx_z][voxelYLv2][threadIdx_x] = f(x, y + 1, z);\n          if (threadIdx_z == voxelZLv2 - 1)\n            value[voxelZLv2][voxelYLv2][threadIdx_x] = f(x, y + 1, z + 1);\n        }\n        if (threadIdx_z == voxelZLv2 - 1)\n        {\n          eds &= 3;\n          value[voxelZLv2][threadIdx_y][threadIdx_x] = f(x, y, z + 1);\n          if (threadIdx_x == voxelXLv2 - 1)\n            value[voxelZLv2][threadIdx_y][voxelXLv2] = f(x + 1, y, z + 1);\n        }\n        eds <<= 13;\n        item.barrier(sycl::access::fence_space::local_space);\n        unsigned int cubeCase(0);\n        if (value[threadIdx_z][threadIdx_y][threadIdx_x] < isoValue) cubeCase |= 1;\n        if (value[threadIdx_z][threadIdx_y][threadIdx_x + 1] < isoValue) cubeCase |= 2;\n        if (value[threadIdx_z][threadIdx_y + 1][threadIdx_x + 1] < isoValue) cubeCase |= 4;\n        if (value[threadIdx_z][threadIdx_y + 1][threadIdx_x] < isoValue) cubeCase |= 8;\n        if (value[threadIdx_z + 1][threadIdx_y][threadIdx_x] < isoValue) cubeCase |= 16;\n        if (value[threadIdx_z + 1][threadIdx_y][threadIdx_x + 1] < isoValue) cubeCase |= 32;\n        if (value[threadIdx_z + 1][threadIdx_y + 1][threadIdx_x + 1] < isoValue) cubeCase |= 64;\n        if (value[threadIdx_z + 1][threadIdx_y + 1][threadIdx_x] < isoValue) cubeCase |= 128;\n\n        unsigned int distinctEdges(eds ? distinctEdgesTableDevice[cubeCase] : 0);\n        unsigned int numTriangles(eds != 0xe000 ? 0 : distinctEdges & 7);\n        unsigned int numVertices(sycl::popcount(distinctEdges &= eds));\n        unsigned int laneid = (threadIdx_x + voxelXLv2 * (threadIdx_y + voxelYLv2 * threadIdx_z)) % 32;\n        unsigned warpid((threadIdx_x + voxelXLv2 * (threadIdx_y + voxelYLv2 * threadIdx_z)) >> 5);\n        constexpr unsigned int threadNum(voxelXLv2 * voxelYLv2 * voxelZLv2);\n        constexpr unsigned int warpNum(threadNum / 32);\n        unsigned int sumVertices(numVertices);\n        unsigned int sumTriangles(numTriangles);\n\n        #pragma unroll\n        for (int c0(1); c0 < 32; c0 *= 2)\n        {\n          unsigned int tp0(sg.shuffle_up(sumVertices, c0));\n          unsigned int tp1(sg.shuffle_up(sumTriangles, c0));\n          if (laneid >= c0)\n          {\n            sumVertices += tp0;\n            sumTriangles += tp1;\n          }\n        }\n        if (laneid == 31)\n        {\n          sumsVertices[warpid] = sumVertices;\n          sumsTriangles[warpid] = sumTriangles;\n        }\n        item.barrier(sycl::access::fence_space::local_space);\n        if (warpid == 0)\n        {\n          unsigned warpSumVertices = sumsVertices[laneid];\n          unsigned warpSumTriangles = sumsTriangles[laneid];\n          #pragma unroll\n          for (int c0(1); c0 < warpNum; c0 *= 2)\n          {\n            unsigned int tp0(sg.shuffle_up(warpSumVertices, c0));\n            unsigned int tp1(sg.shuffle_up(warpSumTriangles, c0));\n            if (laneid >= c0)\n            {\n              warpSumVertices += tp0;\n              warpSumTriangles += tp1;\n            }\n          }\n          sumsVertices[laneid] = warpSumVertices;\n          sumsTriangles[laneid] = warpSumTriangles;\n        }\n        item.barrier(sycl::access::fence_space::local_space);\n        if (warpid != 0)\n        {\n          sumVertices += sumsVertices[warpid - 1];\n          sumTriangles += sumsTriangles[warpid - 1];\n        }\n        if (eds == 0)\n        {\n          sumsVertices[31] = atomicAdd(countedVerticesNumDevice, sumVertices);\n          sumsTriangles[31] = atomicAdd(countedTrianglesNumDevice, sumTriangles);\n        }\n\n        unsigned int interOffsetVertices(sumVertices - numVertices);\n        sumVertices = interOffsetVertices + sumsVertices[31];\n\n        sumTriangles = sumTriangles + sumsTriangles[31] - numTriangles;\n\n        vertexIndices[threadIdx_z][threadIdx_y][threadIdx_x] = interOffsetVertices | distinctEdges;\n        item.barrier(sycl::access::fence_space::local_space);\n\n        for (unsigned int c0(0); c0 < numTriangles; ++c0)\n        {\n          #pragma unroll\n          for (unsigned int c1(0); c1 < 3; ++c1)\n          {\n            int edgeID(triTableDevice[16 * cubeCase + 3 * c0 + c1]);\n            uchar4 edgePos(edgeIDTableDevice[edgeID]);\n            unsigned short vertexIndex(\n              vertexIndices[threadIdx_z + edgePos.z()][threadIdx_y + edgePos.y()][threadIdx_x + edgePos.x()]);\n            unsigned int tp(sycl::popcount(vertexIndex >> (16 - edgePos.w())) + (vertexIndex & 0x1fff));\n            atomicAdd(trianglesDevice, (unsigned long long)(sumsVertices[31] + tp));\n          }\n        }\n\n        \n\n        float zp = 0.f, cx = 0.f, cy = 0.f, cz = 0.f;\n\n        if (distinctEdges & (1 << 15))\n        {\n          zp = zeroPoint(x, v, value[threadIdx_z][threadIdx_y][threadIdx_x + 1], isoValue);\n          cy = transformToCoord(y);\n          cz = transformToCoord(z);\n        }\n        if (distinctEdges & (1 << 14))\n        {\n          cx = transformToCoord(x);\n          zp += zeroPoint(y, v, value[threadIdx_z][threadIdx_y + 1][threadIdx_x], isoValue);\n          cz += transformToCoord(z);\n        }\n        if (distinctEdges & (1 << 13))\n        {\n          cx += transformToCoord(x);\n          cy += transformToCoord(y);\n          zp += zeroPoint(z, v, value[threadIdx_z + 1][threadIdx_y][threadIdx_x], isoValue);\n        }\n        atomicAdd(coordXDevice, cx);\n        atomicAdd(coordYDevice, cy);\n        atomicAdd(coordZDevice, cz);\n        atomicAdd(coordZPDevice, zp);\n      });\n    }).wait();\n\n    auto end = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    time += ktime;\n\n    q.memcpy(&countedVerticesNum, countedVerticesNumDevice, sizeof(unsigned int));\n    q.memcpy(&countedTrianglesNum, countedTrianglesNumDevice, sizeof(unsigned int));\n    q.wait();\n\n    sycl::free(minMaxLv2Device, q);\n    sycl::free(blockIndicesLv2Device, q);\n  }\n\n  printf(\"Block Lv1: %u\\nBlock Lv2: %u\\n\", countedBlockNumLv1, countedBlockNumLv2);\n  printf(\"Vertices Size: %u\\n\", countedBlockNumLv2 * 304);\n  printf(\"Triangles Size: %u\\n\", countedBlockNumLv2 * 315 * 3);\n  printf(\"Vertices: %u\\nTriangles: %u\\n\", countedVerticesNum, countedTrianglesNum);\n  printf(\"Average kernel execution time (generatingTriangles): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  bool ok = (countedBlockNumLv1 == 8296 && countedBlockNumLv2 == 240380 &&\n             countedVerticesNum == 4856560 && countedTrianglesNum == 6101640);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(minMaxLv1Device, q);\n  sycl::free(blockIndicesLv1Device, q);\n  sycl::free(countedBlockNumLv1Device, q);\n  sycl::free(countedBlockNumLv2Device, q);\n  sycl::free(distinctEdgesTableDevice, q);\n  sycl::free(triTableDevice, q);\n  sycl::free(edgeIDTableDevice, q);\n  sycl::free(countedVerticesNumDevice, q);\n  sycl::free(countedTrianglesNumDevice, q);\n  sycl::free(trianglesDevice, q);\n  sycl::free(coordXDevice, q);\n  sycl::free(coordYDevice, q);\n  sycl::free(coordZDevice, q);\n  sycl::free(coordZPDevice, q);\n  return 0;\n}\n"}}
{"kernel_name": "meanshift", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include <cuda.h>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  __global__ void mean_shift(const float *data, float *data_next) {\n    size_t tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    if (tid < N) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  __global__ void mean_shift_tiling(const float* data, float* data_next) {\n\n    \n\n    __shared__ float local_data[TILE_WIDTH * D];\n    __shared__ float valid_data[TILE_WIDTH];\n    \n\n    int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    int row = tid * D;\n    int local_row = threadIdx.x * D;\n    float new_position[D] = {0.f};\n    float tot_weight = 0.f;\n    \n\n    for (int t = 0; t < BLOCKS; ++t) {\n      int tid_in_tile = t * TILE_WIDTH + threadIdx.x;\n      if (tid_in_tile < N) {\n        int row_in_tile = tid_in_tile * D;\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = data[row_in_tile + j];\n        }\n        valid_data[threadIdx.x] = 1;\n      }\n      else {\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = 0;\n        }\n        valid_data[threadIdx.x] = 0;\n      }\n      __syncthreads();\n      for (int i = 0; i < TILE_WIDTH; ++i) {\n        int local_row_tile = i * D;\n        float valid_radius = RADIUS * valid_data[i];\n        float sq_dist = 0.;\n        for (int j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                     (data[row + j] - local_data[local_row_tile + j]);\n        }\n        if (sq_dist <= valid_radius) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (int j = 0; j < D; ++j) {\n            new_position[j] += (weight * local_data[local_row_tile + j]);\n          }\n          tot_weight += (weight * valid_data[i]);\n        }\n      }\n      __syncthreads();\n    }\n    if (tid < N) {\n      for (int j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result;\n\n  \n\n  float *d_data;\n  float *d_data_next;\n  size_t data_bytes = N * D * sizeof(float);\n  cudaMalloc((void**)&d_data, data_bytes);\n  cudaMalloc((void**)&d_data_next, data_bytes);\n\n  \n\n  cudaMemcpy(d_data, data.data(), data_bytes, cudaMemcpyHostToDevice);\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    mean_shift::gpu::mean_shift<<<BLOCKS, THREADS>>>(d_data, d_data_next);\n    cudaDeviceSynchronize();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (base) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  cudaMemcpy(result.data(), d_data, data_bytes, cudaMemcpyDeviceToHost);\n  auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  \n\n  cudaMemcpy(d_data, data.data(), data_bytes, cudaMemcpyHostToDevice);\n\n  start = std::chrono::steady_clock::now();\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    mean_shift::gpu::mean_shift_tiling<<<BLOCKS, THREADS>>>(d_data, d_data_next);\n    cudaDeviceSynchronize();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  cudaMemcpy(result.data(), d_data, data_bytes, cudaMemcpyDeviceToHost);\n\n  centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  cudaFree(d_data);\n  cudaFree(d_data_next);\n  return 0;\n}\n"}}
{"kernel_name": "meanshift", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include <hip/hip_runtime.h>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  __global__ void mean_shift(const float *data, float *data_next) {\n    size_t tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    if (tid < N) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  __global__ void mean_shift_tiling(const float* data, float* data_next) {\n\n    \n\n    __shared__ float local_data[TILE_WIDTH * D];\n    __shared__ float valid_data[TILE_WIDTH];\n    \n\n    int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    int row = tid * D;\n    int local_row = threadIdx.x * D;\n    float new_position[D] = {0.f};\n    float tot_weight = 0.f;\n    \n\n    for (int t = 0; t < BLOCKS; ++t) {\n      int tid_in_tile = t * TILE_WIDTH + threadIdx.x;\n      if (tid_in_tile < N) {\n        int row_in_tile = tid_in_tile * D;\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = data[row_in_tile + j];\n        }\n        valid_data[threadIdx.x] = 1;\n      }\n      else {\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = 0;\n        }\n        valid_data[threadIdx.x] = 0;\n      }\n      __syncthreads();\n      for (int i = 0; i < TILE_WIDTH; ++i) {\n        int local_row_tile = i * D;\n        float valid_radius = RADIUS * valid_data[i];\n        float sq_dist = 0.;\n        for (int j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                     (data[row + j] - local_data[local_row_tile + j]);\n        }\n        if (sq_dist <= valid_radius) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (int j = 0; j < D; ++j) {\n            new_position[j] += (weight * local_data[local_row_tile + j]);\n          }\n          tot_weight += (weight * valid_data[i]);\n        }\n      }\n      __syncthreads();\n    }\n    if (tid < N) {\n      for (int j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result;\n\n  \n\n  float *d_data;\n  float *d_data_next;\n  size_t data_bytes = N * D * sizeof(float);\n  hipMalloc((void**)&d_data, data_bytes);\n  hipMalloc((void**)&d_data_next, data_bytes);\n\n  \n\n  hipMemcpy(d_data, data.data(), data_bytes, hipMemcpyHostToDevice);\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    hipLaunchKernelGGL(mean_shift::gpu::mean_shift, BLOCKS, THREADS, 0, 0, d_data, d_data_next);\n    hipDeviceSynchronize();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (base) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  hipMemcpy(result.data(), d_data, data_bytes, hipMemcpyDeviceToHost);\n  auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  \n\n  hipMemcpy(d_data, data.data(), data_bytes, hipMemcpyHostToDevice);\n\n  start = std::chrono::steady_clock::now();\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    hipLaunchKernelGGL(mean_shift::gpu::mean_shift_tiling, BLOCKS, THREADS, 0, 0, d_data, d_data_next);\n    hipDeviceSynchronize();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  hipMemcpy(result.data(), d_data, data_bytes, hipMemcpyDeviceToHost);\n  centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n\n  hipFree(d_data);\n  hipFree(d_data_next);\n  return 0;\n}\n"}}
{"kernel_name": "meanshift", "parallel_api": "omp", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include <omp.h>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  void mean_shift(const float *data, float *data_next,\n                  const int teams, const int threads) {\n    #pragma omp target teams distribute parallel for num_teams(teams) thread_limit(64)\n    for (size_t tid = 0; tid < N; tid++) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  void mean_shift_tiling(const float* data, float* data_next,\n                         const int teams, const int threads) {\n    #pragma omp target teams num_teams(teams) thread_limit(threads)\n    {\n      float local_data[TILE_WIDTH * D];\n      float valid_data[TILE_WIDTH];\n      #pragma omp parallel \n      {\n        int lid = omp_get_thread_num();\n        int bid = omp_get_team_num();\n        int tid = bid * omp_get_num_threads() + lid;\n        int row = tid * D;\n        int local_row = lid * D;\n        float new_position[D] = {0.f};\n        float tot_weight = 0.f;\n        \n\n        for (int t = 0; t < BLOCKS; ++t) {\n          int tid_in_tile = t * TILE_WIDTH + lid;\n          if (tid_in_tile < N) {\n            int row_in_tile = tid_in_tile * D;\n            for (int j = 0; j < D; ++j) {\n              local_data[local_row + j] = data[row_in_tile + j];\n            }\n            valid_data[lid] = 1;\n          }\n          else {\n            for (int j = 0; j < D; ++j) {\n              local_data[local_row + j] = 0;\n            }\n            valid_data[lid] = 0;\n          }\n          #pragma omp barrier\n          for (int i = 0; i < TILE_WIDTH; ++i) {\n            int local_row_tile = i * D;\n            float valid_radius = RADIUS * valid_data[i];\n            float sq_dist = 0.;\n            for (int j = 0; j < D; ++j) {\n              sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                         (data[row + j] - local_data[local_row_tile + j]);\n            }\n            if (sq_dist <= valid_radius) {\n              float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n              for (int j = 0; j < D; ++j) {\n                new_position[j] += (weight * local_data[local_row_tile + j]);\n              }\n              tot_weight += (weight * valid_data[i]);\n            }\n          }\n          #pragma omp barrier\n        }\n        if (tid < N) {\n          for (int j = 0; j < D; ++j) {\n            data_next[row + j] = new_position[j] / tot_weight;\n          }\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result = data;\n\n  \n\n  size_t data_bytes = N * D * sizeof(float);\n  float *d_data = result.data();\n  float *d_data_next = (float*) malloc (data_bytes);\n\n  \n\n  #pragma omp target data map(to: d_data[0:N*D]) map(alloc: d_data_next[0:N*D])\n  {\n    \n\n    auto start = std::chrono::steady_clock::now();\n\n    for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n      mean_shift::gpu::mean_shift(d_data, d_data_next, BLOCKS, THREADS);\n      mean_shift::gpu::utils::swap(d_data, d_data_next);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"\\nAverage execution time of mean-shift (base) \"\n              << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n    \n\n    #pragma omp target update from (d_data[0:N*D])\n    auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n    bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n    if (centroids.size() == M && are_close)\n       std::cout << \"PASS\\n\";\n    else\n       std::cout << \"FAIL\\n\";\n\n    \n\n    result = data;\n    #pragma omp target update to (d_data[0:N*D])\n\n    start = std::chrono::steady_clock::now();\n    for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n      mean_shift::gpu::mean_shift_tiling(d_data, d_data_next, BLOCKS, THREADS);\n      mean_shift::gpu::utils::swap(d_data, d_data_next);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n              << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n    \n\n    #pragma omp target update from (d_data[0:N*D])\n    centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n    are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n    if (centroids.size() == M && are_close)\n       std::cout << \"PASS\\n\";\n    else\n       std::cout << \"FAIL\\n\";\n  }\n\n  free(d_data_next);\n  return 0;\n}\n"}}
{"kernel_name": "meanshift", "parallel_api": "serial", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  void mean_shift(const float *data, float *data_next,\n                  const int teams, const int threads) {\n        for (size_t tid = 0; tid < N; tid++) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  void mean_shift_tiling(const float* data, float* data_next,\n                         const int teams, const int threads) {\n        {\n      float local_data[TILE_WIDTH * D];\n      float valid_data[TILE_WIDTH];\n            {\n        int lid = omp_get_thread_num();\n        int bid = omp_get_team_num();\n        int tid = bid * omp_get_num_threads() + lid;\n        int row = tid * D;\n        int local_row = lid * D;\n        float new_position[D] = {0.f};\n        float tot_weight = 0.f;\n        \n\n        for (int t = 0; t < BLOCKS; ++t) {\n          int tid_in_tile = t * TILE_WIDTH + lid;\n          if (tid_in_tile < N) {\n            int row_in_tile = tid_in_tile * D;\n            for (int j = 0; j < D; ++j) {\n              local_data[local_row + j] = data[row_in_tile + j];\n            }\n            valid_data[lid] = 1;\n          }\n          else {\n            for (int j = 0; j < D; ++j) {\n              local_data[local_row + j] = 0;\n            }\n            valid_data[lid] = 0;\n          }\n                    for (int i = 0; i < TILE_WIDTH; ++i) {\n            int local_row_tile = i * D;\n            float valid_radius = RADIUS * valid_data[i];\n            float sq_dist = 0.;\n            for (int j = 0; j < D; ++j) {\n              sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                         (data[row + j] - local_data[local_row_tile + j]);\n            }\n            if (sq_dist <= valid_radius) {\n              float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n              for (int j = 0; j < D; ++j) {\n                new_position[j] += (weight * local_data[local_row_tile + j]);\n              }\n              tot_weight += (weight * valid_data[i]);\n            }\n          }\n                  }\n        if (tid < N) {\n          for (int j = 0; j < D; ++j) {\n            data_next[row + j] = new_position[j] / tot_weight;\n          }\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result = data;\n\n  \n\n  size_t data_bytes = N * D * sizeof(float);\n  float *d_data = result.data();\n  float *d_data_next = (float*) malloc (data_bytes);\n\n  \n\n    {\n    \n\n    auto start = std::chrono::steady_clock::now();\n\n    for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n      mean_shift::gpu::mean_shift(d_data, d_data_next, BLOCKS, THREADS);\n      mean_shift::gpu::utils::swap(d_data, d_data_next);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"\\nAverage execution time of mean-shift (base) \"\n              << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n    \n\n        auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n    bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n    if (centroids.size() == M && are_close)\n       std::cout << \"PASS\\n\";\n    else\n       std::cout << \"FAIL\\n\";\n\n    \n\n    result = data;\n    \n    start = std::chrono::steady_clock::now();\n    for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n      mean_shift::gpu::mean_shift_tiling(d_data, d_data_next, BLOCKS, THREADS);\n      mean_shift::gpu::utils::swap(d_data, d_data_next);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n              << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n    \n\n        centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n    are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n    if (centroids.size() == M && are_close)\n       std::cout << \"PASS\\n\";\n    else\n       std::cout << \"FAIL\\n\";\n  }\n\n  free(d_data_next);\n  return 0;\n}"}}
{"kernel_name": "meanshift", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  void mean_shift(sycl::nd_item<1> &item, const float *data, float *data_next) {\n    size_t tid = item.get_global_id(0);\n    if (tid < N) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = sycl::exp(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  void mean_shift_tiling(sycl::nd_item<1> &item,\n                         float *__restrict local_data,\n                         float *__restrict valid_data,\n                         const float* data,\n                               float*__restrict data_next) {\n\n    \n\n    \n\n    int tid = item.get_global_id(0);\n    int lid = item.get_local_id(0);\n    int row = tid * D;\n    int local_row = lid * D;\n    float new_position[D] = {0.f};\n    float tot_weight = 0.f;\n    \n\n    for (int t = 0; t < BLOCKS; ++t) {\n      int tid_in_tile = t * TILE_WIDTH + lid;\n      if (tid_in_tile < N) {\n        int row_in_tile = tid_in_tile * D;\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = data[row_in_tile + j];\n        }\n        valid_data[lid] = 1;\n      }\n      else {\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = 0;\n        }\n        valid_data[lid] = 0;\n      }\n      item.barrier(sycl::access::fence_space::local_space);\n      for (int i = 0; i < TILE_WIDTH; ++i) {\n        int local_row_tile = i * D;\n        float valid_radius = RADIUS * valid_data[i];\n        float sq_dist = 0.;\n        for (int j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                     (data[row + j] - local_data[local_row_tile + j]);\n        }\n        if (sq_dist <= valid_radius) {\n          float weight = sycl::exp(-sq_dist / DBL_SIGMA_SQ);\n          for (int j = 0; j < D; ++j) {\n            new_position[j] += (weight * local_data[local_row_tile + j]);\n          }\n          tot_weight += (weight * valid_data[i]);\n        }\n      }\n      item.barrier(sycl::access::fence_space::local_space);\n    }\n    if (tid < N) {\n      for (int j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result {};\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  size_t data_bytes = N * D * sizeof(float);\n  float *d_data = (float*) sycl::malloc_device (data_bytes, q);\n  float *d_data_next = (float*) sycl::malloc_device (data_bytes, q);;\n\n  \n\n  q.memcpy(d_data, data.data(), data_bytes).wait();\n\n  sycl::range<1> gws (BLOCKS * THREADS);\n  sycl::range<1> lws (THREADS);\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class base>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        mean_shift::gpu::mean_shift(item, d_data, d_data_next);\n      });\n    }).wait();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (base) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  q.memcpy(result.data(), d_data, data_bytes).wait();\n  auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  \n\n  q.memcpy(d_data, data.data(), data_bytes).wait();\n\n  start = std::chrono::steady_clock::now();\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> local_data (sycl::range<1>(TILE_WIDTH * D), cgh);\n      sycl::local_accessor<float, 1> valid_data (sycl::range<1>(TILE_WIDTH), cgh);\n      cgh.parallel_for<class opt>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        mean_shift::gpu::mean_shift_tiling(item, local_data.get_pointer(),\n                                           valid_data.get_pointer(),\n                                           d_data, d_data_next);\n      });\n    }).wait();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  q.memcpy(result.data(), d_data, data_bytes).wait();\n  centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  sycl::free(d_data, q);\n  sycl::free(d_data_next, q);\n  return 0;\n}\n"}}
{"kernel_name": "michalewicz", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n\n__device__ __forceinline__\nfloat atomic_min(float *addr, float value)\n{\n  unsigned ret = __float_as_uint(*addr);\n  while(value < __uint_as_float(ret))\n  {\n    unsigned old = ret;\n    if((ret = atomicCAS((unsigned *)addr, old, __float_as_uint(value))) == old)\n      break;\n  }\n  return __uint_as_float(ret);\n}\n\n__device__ __forceinline__\nfloat michalewicz(const float *xValues, const int dim) {\n  float result = 0;\n  for (int i = 0; i < dim; ++i) {\n    float a = sinf(xValues[i]);\n    float b = sinf(((i + 1) * xValues[i] * xValues[i]) / (float)M_PI);\n    float c = powf(b, 20); \n\n    result += a * c;\n  }\n  return -1.0f * result;\n}\n\n__global__ void eval (const float *values, float *minima,\n                      const size_t nVectors, const int dim)\n{\n  size_t n = blockIdx.x * blockDim.x + threadIdx.x;\n  if (n < nVectors) {\n    atomic_min(minima, michalewicz(values + n * dim, dim));\n  }\n}\n\n\n\nvoid Error(float value, int dim) {\n  printf(\"Global minima = %f\\n\", value);\n  float trueMin = 0.0;\n  if (dim == 2)\n    trueMin = -1.8013;\n  else if (dim == 5)\n    trueMin = -4.687658;\n  else if (dim == 10)\n    trueMin = -9.66015;\n  printf(\"Error = %f\\n\", fabsf(trueMin - value));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of vectors> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const size_t n = atol(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  \n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dis(0.0, 4.0);\n  \n  \n\n  const int dims[] = {2, 5, 10}; \n\n  for (int d = 0; d < 3; d++) {\n\n    const int dim = dims[d];\n\n    const size_t size = n * dim;\n\n    const size_t size_bytes = size * sizeof(float);\n    \n    float *values = (float*) malloc (size_bytes);\n    \n    for (size_t i = 0; i < size; i++) {\n      values[i] = dis(gen);\n    }\n    \n    float *d_values;\n    cudaMalloc((void**)&d_values, size_bytes);\n    cudaMemcpy(d_values, values, size_bytes, cudaMemcpyHostToDevice);\n\n    float *d_minValue;\n    float minValue;\n    cudaMalloc((void**)&d_minValue, sizeof(float));\n\n    dim3 grids ((n + 255) / 256);\n    dim3 blocks (256);\n\n    cudaMemset(d_minValue, 0, sizeof(float));\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      eval<<<grids, blocks>>>(d_values, d_minValue, n, dim);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernel (dim = %d): %f (us)\\n\",\n           dim, (time * 1e-3f) / repeat);\n\n    cudaMemcpy(&minValue, d_minValue, sizeof(float), cudaMemcpyDeviceToHost);\n    Error(minValue, dim);\n\n    cudaFree(d_values);\n    cudaFree(d_minValue);\n    free(values);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "michalewicz", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n\n__device__ __forceinline__\nfloat michalewicz(const float *xValues, const int dim) {\n  float result = 0;\n  for (int i = 0; i < dim; ++i) {\n      float a = sinf(xValues[i]);\n      float b = sinf(((i + 1) * xValues[i] * xValues[i]) / (float)M_PI);\n      float c = powf(b, 20); \n\n      result += a * c;\n  }\n  return -1.0f * result;\n}\n\n__global__ void eval (const float *values, float *minima,\n                      const size_t nVectors, const int dim)\n{\n  size_t n = blockIdx.x * blockDim.x + threadIdx.x;\n  if (n < nVectors) {\n    atomicMin(minima, michalewicz(values + n * dim, dim));\n  }\n}\n\n\n\nvoid Error(float value, int dim) {\n  printf(\"Global minima = %f\\n\", value);\n  float trueMin = 0.0;\n  if (dim == 2)\n    trueMin = -1.8013;\n  else if (dim == 5)\n    trueMin = -4.687658;\n  else if (dim == 10)\n    trueMin = -9.66015;\n  printf(\"Error = %f\\n\", fabsf(trueMin - value));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of vectors> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const size_t n = atol(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  \n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dis(0.0, 4.0);\n  \n  \n\n  const int dims[] = {2, 5, 10}; \n\n  for (int d = 0; d < 3; d++) {\n\n    const int dim = dims[d];\n\n    const size_t size = n * dim;\n\n    const size_t size_bytes = size * sizeof(float);\n    \n    float *values = (float*) malloc (size_bytes);\n    \n    for (size_t i = 0; i < size; i++) {\n      values[i] = dis(gen);\n    }\n    \n    float *d_values;\n    hipMalloc((void**)&d_values, size_bytes);\n    hipMemcpy(d_values, values, size_bytes, hipMemcpyHostToDevice);\n\n    float *d_minValue;\n    float minValue;\n    hipMalloc((void**)&d_minValue, sizeof(float));\n\n    dim3 grids ((n + 255) / 256);\n    dim3 blocks (256);\n\n    hipMemset(d_minValue, 0, sizeof(float));\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      eval<<<grids, blocks>>>(d_values, d_minValue, n, dim);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernel (dim = %d): %f (us)\\n\",\n           dim, (time * 1e-3f) / repeat);\n\n    hipMemcpy(&minValue, d_minValue, sizeof(float), hipMemcpyDeviceToHost);\n    Error(minValue, dim);\n\n    hipFree(d_values);\n    hipFree(d_minValue);\n    free(values);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "michalewicz", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n\n#define min(a,b) (a) < (b) ? (a) : (b)\n\ninline\nfloat michalewicz(const float *xValues, const int dim) {\n  float result = 0;\n  for (int i = 0; i < dim; ++i) {\n      float a = sinf(xValues[i]);\n      float b = sinf(((i + 1) * xValues[i] * xValues[i]) / (float)M_PI);\n      float c = powf(b, 20); \n\n      result += a * c;\n  }\n  return -1.0f * result;\n}\n\n\n\nvoid Error(float value, int dim) {\n  printf(\"Global minima = %f\\n\", value);\n  float trueMin = 0.0;\n  if (dim == 2)\n    trueMin = -1.8013;\n  else if (dim == 5)\n    trueMin = -4.687658;\n  else if (dim == 10)\n    trueMin = -9.66015;\n  printf(\"Error = %f\\n\", fabsf(trueMin - value));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of vectors> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const size_t n = atol(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  \n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dis(0.0, 4.0);\n \n  \n\n  const int dims[] = {2, 5, 10}; \n\n  for (int d = 0; d < 3; d++) {\n\n    const int dim = dims[d];\n\n    const size_t size = n * dim;\n\n    const size_t size_bytes = size * sizeof(float);\n    \n    float *values = (float*) malloc (size_bytes);\n    \n    for (size_t i = 0; i < size; i++) {\n      values[i] = dis(gen);\n    }\n\n    float minValue = 0;\n    \n    #pragma omp target data map(to: values[0:size]) \\\n                            map(tofrom: minValue)\n    {\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        #pragma omp target teams distribute parallel for thread_limit(256) reduction(min: minValue)\n        for (size_t j = 0; j < n; j++) {\n          minValue = min(minValue, michalewicz(values + j * dim, dim));\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of kernel (dim = %d): %f (us)\\n\",\n             dim, (time * 1e-3f) / repeat);\n    }\n    Error(minValue, dim);\n    free(values);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "michalewicz", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n\n#define min(a,b) (a) < (b) ? (a) : (b)\n\ninline\nfloat michalewicz(const float *xValues, const int dim) {\n  float result = 0;\n  for (int i = 0; i < dim; ++i) {\n      float a = sinf(xValues[i]);\n      float b = sinf(((i + 1) * xValues[i] * xValues[i]) / (float)M_PI);\n      float c = powf(b, 20); \n\n      result += a * c;\n  }\n  return -1.0f * result;\n}\n\n\n\nvoid Error(float value, int dim) {\n  printf(\"Global minima = %f\\n\", value);\n  float trueMin = 0.0;\n  if (dim == 2)\n    trueMin = -1.8013;\n  else if (dim == 5)\n    trueMin = -4.687658;\n  else if (dim == 10)\n    trueMin = -9.66015;\n  printf(\"Error = %f\\n\", fabsf(trueMin - value));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of vectors> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const size_t n = atol(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  \n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dis(0.0, 4.0);\n \n  \n\n  const int dims[] = {2, 5, 10}; \n\n  for (int d = 0; d < 3; d++) {\n\n    const int dim = dims[d];\n\n    const size_t size = n * dim;\n\n    const size_t size_bytes = size * sizeof(float);\n    \n    float *values = (float*) malloc (size_bytes);\n    \n    for (size_t i = 0; i < size; i++) {\n      values[i] = dis(gen);\n    }\n\n    float minValue = 0;\n    \n        {\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n                for (size_t j = 0; j < n; j++) {\n          minValue = min(minValue, michalewicz(values + j * dim, dim));\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of kernel (dim = %d): %f (us)\\n\",\n             dim, (time * 1e-3f) / repeat);\n    }\n    Error(minValue, dim);\n    free(values);\n  }\n\n  return 0;\n}"}}
{"kernel_name": "michalewicz", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n\ninline\nfloat michalewicz(const float *xValues, const int dim) {\n  float result = 0;\n  for (int i = 0; i < dim; ++i) {\n      float a = sycl::sin(xValues[i]);\n      float b = sycl::sin(((i + 1) * xValues[i] * xValues[i]) / (float)M_PI);\n      float c = sycl::pow(b, 20.f); \n\n      result += a * c;\n  }\n  return -1.0f * result;\n}\n\n\n\nvoid Error(float value, int dim) {\n  printf(\"Global minima = %f\\n\", value);\n  float trueMin = 0.0;\n  if (dim == 2)\n    trueMin = -1.8013;\n  else if (dim == 5)\n    trueMin = -4.687658;\n  else if (dim == 10)\n    trueMin = -9.66015;\n  printf(\"Error = %f\\n\", fabsf(trueMin - value));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of vectors> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const size_t n = atol(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  \n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dis(0.0, 4.0);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n  \n  \n\n  const int dims[] = {2, 5, 10}; \n\n  for (int d = 0; d < 3; d++) {\n\n    const int dim = dims[d];\n\n    const size_t size = n * dim;\n    const size_t size_bytes = size * sizeof(float);\n    \n    float *values = (float*) malloc (size_bytes);\n    \n    for (int i = 0; i < size; i++) {\n      values[i] = dis(gen);\n    }\n    \n    float *d_values = sycl::malloc_device<float>(size, q);\n    q.memcpy(d_values, values, size_bytes);\n\n    float *d_minValue = sycl::malloc_device<float>(1, q);\n    float minValue;\n\n    sycl::range<1> gws ((n + 255) / 256 * 256);\n    sycl::range<1> lws (256);\n\n    q.memset(d_minValue, 0, sizeof(float)).wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &h) {\n        h.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n          size_t i = item.get_global_id(0);\n          if (i < n) {\n            auto ao = sycl::atomic_ref<float, sycl::memory_order::relaxed, \\\n                      sycl::memory_scope::device,\\\n                      sycl::access::address_space::generic_space>(*d_minValue);\n            ao.fetch_min(michalewicz(d_values + i * dim, dim));\n          }\n        });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernel (dim = %d): %f (us)\\n\",\n           dim, (time * 1e-3f) / repeat);\n\n    q.memcpy(&minValue, d_minValue, sizeof(float)).wait();\n    Error(minValue, dim);\n\n    sycl::free(d_values, q);\n    sycl::free(d_minValue, q);\n    free(values);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "mixbench", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\n__global__ void benchmark_func(float *g_data,\n                               const int compute_iterations)\n{\n  const unsigned int blockSize = blockDim.x;\n  const int stride = blockSize;\n  int idx = blockIdx.x*blockSize*granularity + threadIdx.x;\n  const int big_stride = gridDim.x*blockSize*granularity;\n\n  float tmps[granularity];\n  for(int k=0; k<fusion_degree; k++) {\n    #pragma unroll\n    for(int j=0; j<granularity; j++) {\n      \n\n      tmps[j] = g_data[idx+j*stride+k*big_stride];\n\n      \n\n      for(int i=0; i<compute_iterations; i++)\n        tmps[j] = tmps[j]*tmps[j]+seed;\n    }\n\n    \n\n    float sum = 0.f;\n    #pragma unroll\n    for(int j=0; j<granularity; j+=2)\n      sum += tmps[j]*tmps[j+1];\n\n    #pragma unroll\n    for(int j=0; j<granularity; j++)\n      g_data[idx+k*big_stride] = sum;\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size/block_dim;\n\n  float *d_cd;\n  cudaMalloc((void**)&d_cd, size*sizeof(float));\n  cudaMemcpy(d_cd, cd,  size*sizeof(float), cudaMemcpyHostToDevice);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    benchmark_func<<<grid_dim, block_dim>>>(d_cd, i);\n  }\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    benchmark_func<<<grid_dim, block_dim>>>(d_cd, i);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  cudaMemcpy(cd, d_cd, size*sizeof(float), cudaMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(cd);\n  cudaFree(d_cd);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mixbench", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\n__global__ void benchmark_func(float *g_data,\n                               const int compute_iterations)\n{\n  const unsigned int blockSize = blockDim.x;\n  const int stride = blockSize;\n  int idx = blockIdx.x*blockSize*granularity + threadIdx.x;\n  const int big_stride = gridDim.x*blockSize*granularity;\n\n  float tmps[granularity];\n  for(int k=0; k<fusion_degree; k++) {\n    #pragma unroll\n    for(int j=0; j<granularity; j++) {\n      \n\n      tmps[j] = g_data[idx+j*stride+k*big_stride];\n\n      \n\n      for(int i=0; i<compute_iterations; i++)\n        tmps[j] = tmps[j]*tmps[j]+seed;\n    }\n\n    \n\n    float sum = 0.f;\n    #pragma unroll\n    for(int j=0; j<granularity; j+=2)\n      sum += tmps[j]*tmps[j+1];\n\n    #pragma unroll\n    for(int j=0; j<granularity; j++)\n      g_data[idx+k*big_stride] = sum;\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size/block_dim;\n\n  float *d_cd;\n  hipMalloc((void**)&d_cd, size*sizeof(float));\n  hipMemcpy(d_cd, cd,  size*sizeof(float), hipMemcpyHostToDevice);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(benchmark_func, grid_dim, 0, 0, d_cd, block_dim, i);\n  }\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(benchmark_func, grid_dim, 0, 0, d_cd, block_dim, i);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  hipMemcpy(cd, d_cd, size*sizeof(float), hipMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(cd);\n  hipFree(d_cd);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mixbench", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\nvoid benchmark_func(float *cd, int grid_dim, int block_dim, int compute_iterations) { \n      \n  #pragma omp target teams num_teams(grid_dim) thread_limit(block_dim)\n  { \n    #pragma omp parallel \n    {\n      const unsigned int blockSize = block_dim;\n      const int stride = blockSize;\n      int idx = omp_get_team_num()*blockSize*granularity + omp_get_thread_num();\n      const int big_stride = omp_get_num_teams()*blockSize*granularity;\n      float tmps[granularity];\n      for(int k=0; k<fusion_degree; k++) {\n        #pragma unroll\n        for(int j=0; j<granularity; j++) {\n          \n\n          tmps[j] = cd[idx+j*stride+k*big_stride];\n\n          \n\n          for(int i=0; i<compute_iterations; i++)\n            tmps[j] = tmps[j]*tmps[j]+(float)seed;\n        }\n\n        \n\n        float sum = 0;\n        #pragma unroll\n        for(int j=0; j<granularity; j+=2)\n          sum += tmps[j]*tmps[j+1];\n\n        #pragma unroll\n        for(int j=0; j<granularity; j++)\n          cd[idx+k*big_stride] = sum;\n      }\n    }\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size/block_dim;\n\n  #pragma omp target data map(tofrom: cd[0:size]) \n  {\n    \n\n    for (int i = 0; i < repeat; i++) {\n      benchmark_func(cd, grid_dim, block_dim, i);\n    }\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      benchmark_func(cd, grid_dim, block_dim, i);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  }\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(cd);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mixbench", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <chrono>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\nvoid benchmark_func(float *cd, int grid_dim, int block_dim, int compute_iterations) { \n      \n    { \n        {\n      const unsigned int blockSize = block_dim;\n      const int stride = blockSize;\n      int idx = omp_get_team_num()*blockSize*granularity + omp_get_thread_num();\n      const int big_stride = omp_get_num_teams()*blockSize*granularity;\n      float tmps[granularity];\n      for(int k=0; k<fusion_degree; k++) {\n                for(int j=0; j<granularity; j++) {\n          \n\n          tmps[j] = cd[idx+j*stride+k*big_stride];\n\n          \n\n          for(int i=0; i<compute_iterations; i++)\n            tmps[j] = tmps[j]*tmps[j]+(float)seed;\n        }\n\n        \n\n        float sum = 0;\n                for(int j=0; j<granularity; j+=2)\n          sum += tmps[j]*tmps[j+1];\n\n                for(int j=0; j<granularity; j++)\n          cd[idx+k*big_stride] = sum;\n      }\n    }\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size/block_dim;\n\n    {\n    \n\n    for (int i = 0; i < repeat; i++) {\n      benchmark_func(cd, grid_dim, block_dim, i);\n    }\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      benchmark_func(cd, grid_dim, block_dim, i);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  }\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(cd);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "mixbench", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <sycl/sycl.hpp>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\nvoid benchmark_func(sycl::nd_item<1> &item,\n                    float *g_data,\n                    const int compute_iterations)\n{\n  const unsigned int blockSize = item.get_local_range(0);\n  const int stride = blockSize;\n  int idx = item.get_group(0)*blockSize*granularity + item.get_local_id(0);\n  const int big_stride = item.get_group_range(0)*blockSize*granularity;\n\n  float tmps[granularity];\n  for(int k=0; k<fusion_degree; k++){\n    #pragma unroll\n    for(int j=0; j<granularity; j++){\n      \n\n      tmps[j] = g_data[idx+j*stride+k*big_stride];\n      \n\n      for(int i=0; i<compute_iterations; i++)\n        tmps[j] = tmps[j]*tmps[j]+(float)seed;\n    }\n    \n\n    float sum = 0;\n    #pragma unroll\n    for(int j=0; j<granularity; j+=2)\n      sum += tmps[j]*tmps[j+1];\n    #pragma unroll\n    for(int j=0; j<granularity; j++)\n      g_data[idx+k*big_stride] = sum;\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_cd = sycl::malloc_device<float>(size, q);\n  q.memcpy(d_cd, cd, sizeof(float) * size);\n\n  sycl::range<1> gws (grid_dim);\n  sycl::range<1> lws (block_dim);\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class mixbench_warmup>(\n        sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        benchmark_func(item, d_cd, i);\n      });\n    });\n  }\n  q.wait();\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class mixbench_timing>(\n        sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        benchmark_func(item, d_cd, i);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  \n  q.memcpy(cd, d_cd, sizeof(float) * size).wait();\n  sycl::free(d_cd, q);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n\n  free(cd);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "particlefilter", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <limits.h>\n#include <math.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <float.h>\n#include <time.h>\n#include <sys/time.h>\n#include <iostream>\n#include <cuda.h>\n\n#define BLOCK_X 16\n#define BLOCK_Y 16\n#define PI 3.1415926535897932f\n#define A 1103515245\n#define C 12345\n#define M INT_MAX\n#define SCALE_FACTOR 300.0f\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 256\n#endif\n\n#include \"kernel_find_index.h\"\n#include \"kernel_likelihood.h\"\n#include \"kernel_normalize_weights.h\"\n#include \"kernel_sum.h\"\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\n\n\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) +tv.tv_usec;\n}\n\n\n\nfloat elapsed_time(long long start_time, long long end_time) {\n  return (float) (end_time - start_time) / (1000 * 1000);\n}\n\n\n\nfloat randu(int * seed, int index) {\n  int num = A * seed[index] + C;\n  seed[index] = num % M;\n  return fabs(seed[index] / ((float) M));\n}\n\n\n\nfloat randn(int * seed, int index) {\n  \n\n  float u = randu(seed, index);\n  float v = randu(seed, index);\n  float cosine = cos(2 * PI * v);\n  float rt = -2 * log(u);\n  return sqrt(rt) * cosine;\n}\n\n\n\nfloat roundFloat(float value) {\n  int newValue = (int) (value);\n  if (value - newValue < .5)\n    return newValue;\n  else\n    return newValue++;\n}\n\n\n\nvoid setIf(int testValue, int newValue, unsigned char * array3D, int * dimX, int * dimY, int * dimZ) {\n  int x, y, z;\n  for (x = 0; x < *dimX; x++) {\n    for (y = 0; y < *dimY; y++) {\n      for (z = 0; z < *dimZ; z++) {\n        if (array3D[x * *dimY * *dimZ + y * *dimZ + z] == testValue)\n          array3D[x * *dimY * *dimZ + y * *dimZ + z] = newValue;\n      }\n    }\n  }\n}\n\n\n\nvoid addNoise(unsigned char * array3D, int * dimX, int * dimY, int * dimZ, int * seed) {\n  int x, y, z;\n  for (x = 0; x < *dimX; x++) {\n    for (y = 0; y < *dimY; y++) {\n      for (z = 0; z < *dimZ; z++) {\n        array3D[x * *dimY * *dimZ + y * *dimZ + z] = array3D[x * *dimY * *dimZ + y * *dimZ + z] + (unsigned char) (5 * randn(seed, 0));\n      }\n    }\n  }\n}\n\n\n\nvoid strelDisk(int * disk, int radius) {\n  int diameter = radius * 2 - 1;\n  int x, y;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      float distance = sqrt(pow((float) (x - radius + 1), 2) + pow((float) (y - radius + 1), 2));\n      if (distance < radius)\n        disk[x * diameter + y] = 1;\n      else\n        disk[x * diameter + y] = 0;\n    }\n  }\n}\n\n\n\nvoid dilate_matrix(unsigned char * matrix, int posX, int posY, int posZ, int dimX, int dimY, int dimZ, int error) {\n  int startX = posX - error;\n  while (startX < 0)\n    startX++;\n  int startY = posY - error;\n  while (startY < 0)\n    startY++;\n  int endX = posX + error;\n  while (endX > dimX)\n    endX--;\n  int endY = posY + error;\n  while (endY > dimY)\n    endY--;\n  int x, y;\n  for (x = startX; x < endX; x++) {\n    for (y = startY; y < endY; y++) {\n      float distance = sqrt(pow((float) (x - posX), 2) + pow((float) (y - posY), 2));\n      if (distance < error)\n        matrix[x * dimY * dimZ + y * dimZ + posZ] = 1;\n    }\n  }\n}\n\n\n\nvoid imdilate_disk(unsigned char * matrix, int dimX, int dimY, int dimZ, int error, unsigned char * newMatrix) {\n  int x, y, z;\n  for (z = 0; z < dimZ; z++) {\n    for (x = 0; x < dimX; x++) {\n      for (y = 0; y < dimY; y++) {\n        if (matrix[x * dimY * dimZ + y * dimZ + z] == 1) {\n          dilate_matrix(newMatrix, x, y, z, dimX, dimY, dimZ, error);\n        }\n      }\n    }\n  }\n}\n\n\n\nvoid getneighbors(int * se, int numOnes, int * neighbors, int radius) {\n  int x, y;\n  int neighY = 0;\n  int center = radius - 1;\n  int diameter = radius * 2 - 1;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      if (se[x * diameter + y]) {\n        neighbors[neighY * 2] = (int) (y - center);\n        neighbors[neighY * 2 + 1] = (int) (x - center);\n        neighY++;\n      }\n    }\n  }\n}\n\n\n\nvoid videoSequence(unsigned char * I, int IszX, int IszY, int Nfr, int * seed) {\n  int k;\n  int max_size = IszX * IszY * Nfr;\n  \n\n  int x0 = (int) roundFloat(IszY / 2.0);\n  int y0 = (int) roundFloat(IszX / 2.0);\n  I[x0 * IszY * Nfr + y0 * Nfr + 0] = 1;\n\n  \n\n  int xk, yk, pos;\n  for (k = 1; k < Nfr; k++) {\n    xk = abs(x0 + (k - 1));\n    yk = abs(y0 - 2 * (k - 1));\n    pos = yk * IszY * Nfr + xk * Nfr + k;\n    if (pos >= max_size)\n      pos = 0;\n    I[pos] = 1;\n  }\n\n  \n\n  unsigned char * newMatrix = (unsigned char *) calloc(IszX * IszY * Nfr, sizeof(unsigned char));\n  imdilate_disk(I, IszX, IszY, Nfr, 5, newMatrix);\n  int x, y;\n  for (x = 0; x < IszX; x++) {\n    for (y = 0; y < IszY; y++) {\n      for (k = 0; k < Nfr; k++) {\n        I[x * IszY * Nfr + y * Nfr + k] = newMatrix[x * IszY * Nfr + y * Nfr + k];\n      }\n    }\n  }\n  free(newMatrix);\n\n  \n\n  setIf(0, 100, I, &IszX, &IszY, &Nfr);\n  setIf(1, 228, I, &IszX, &IszY, &Nfr);\n  \n\n  addNoise(I, &IszX, &IszY, &Nfr, seed);\n\n}\n\n\n\nint findIndex(float * CDF, int lengthCDF, float value) {\n  int index = -1;\n  int x;\n  for (x = 0; x < lengthCDF; x++) {\n    if (CDF[x] >= value) {\n      index = x;\n      break;\n    }\n  }\n  if (index == -1) {\n    return lengthCDF - 1;\n  }\n  return index;\n}\n\n\n\nint particleFilter(unsigned char * I, int IszX, int IszY, int Nfr, int * seed, int Nparticles) {\n  int max_size = IszX * IszY*Nfr;\n  \n\n  float xe = roundFloat(IszY / 2.0);\n  float ye = roundFloat(IszX / 2.0);\n\n  \n\n  int radius = 5;\n  int diameter = radius * 2 - 1;\n  int * disk = (int*) calloc(diameter * diameter, sizeof (int));\n  strelDisk(disk, radius);\n  int countOnes = 0;\n  int x, y;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      if (disk[x * diameter + y] == 1)\n        countOnes++;\n    }\n  }\n  int * objxy = (int *) calloc(countOnes * 2, sizeof(int));\n  getneighbors(disk, countOnes, objxy, radius);\n\n  \n\n  float * weights = (float *) calloc(Nparticles, sizeof(float));\n  for (x = 0; x < Nparticles; x++) {\n    weights[x] = 1 / ((float) (Nparticles));\n  }\n  \n\n  float * likelihood = (float *) calloc(Nparticles + 1, sizeof (float));\n  float * arrayX = (float *) calloc(Nparticles, sizeof (float));\n  float * arrayY = (float *) calloc(Nparticles, sizeof (float));\n  float * xj = (float *) calloc(Nparticles, sizeof (float));\n  float * yj = (float *) calloc(Nparticles, sizeof (float));\n  float * CDF = (float *) calloc(Nparticles, sizeof(float));\n\n  \n\n  int * ind = (int*) calloc(countOnes * Nparticles, sizeof(int));\n  float * u = (float *) calloc(Nparticles, sizeof(float));\n\n  \n\n  \n\n  \n\n  for (x = 0; x < Nparticles; x++) {\n    xj[x] = xe;\n    yj[x] = ye;\n  }\n\n  long long offload_start = get_time();\n\n  int num_blocks = (Nparticles + BLOCK_SIZE - 1) / BLOCK_SIZE;\n#ifdef DEBUG\n  printf(\"BLOCK_SIZE=%d \\n\",BLOCK_SIZE);\n#endif\n\n  float* likelihood_GPU;\n  float* arrayX_GPU;\n  float* arrayY_GPU;\n  float* xj_GPU;\n  float* yj_GPU;\n  float* CDF_GPU;\n  float* partial_sums_GPU;\n  float* u_GPU;\n  int* objxy_GPU;\n  int* ind_GPU;\n  int* seed_GPU;\n  float* weights_GPU;\n  unsigned char* I_GPU;\n\n  cudaMalloc((void**)&likelihood_GPU, (Nparticles + 1)*sizeof(float));\n\n  cudaMalloc((void**)&arrayX_GPU, Nparticles*sizeof(float));\n  cudaMalloc((void**)&arrayY_GPU, Nparticles*sizeof(float));\n  cudaMalloc((void**)&xj_GPU, Nparticles*sizeof(float));\n  cudaMalloc((void**)&yj_GPU, Nparticles*sizeof(float));\n  cudaMemcpy(xj_GPU, xj, Nparticles*sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(yj_GPU, yj, Nparticles*sizeof(float), cudaMemcpyHostToDevice);\n  cudaMalloc((void**)&CDF_GPU, Nparticles*sizeof(float));\n  cudaMalloc((void**)&u_GPU, Nparticles*sizeof(float));\n  \n\n\n  cudaMalloc((void**)&ind_GPU, countOnes*Nparticles*sizeof(int));\n  \n\n\n  cudaMalloc((void**)&weights_GPU, Nparticles*sizeof(float));\n  \n\n  \n\n  \n\n  cudaMemcpy(weights_GPU, weights, Nparticles*sizeof(float), cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&I_GPU, IszX * IszY * Nfr * sizeof(unsigned char));\n  cudaMemcpy(I_GPU, I, IszX * IszY * Nfr * sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&seed_GPU, Nparticles*sizeof(int));\n  cudaMemcpy(seed_GPU, seed, Nparticles*sizeof(int), cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&partial_sums_GPU, (Nparticles+1)*sizeof(float));\n  \n\n\n  cudaMalloc((void**)&objxy_GPU, 2*countOnes*sizeof(int));\n  cudaMemcpy(objxy_GPU, objxy, 2*countOnes*sizeof(int), cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  long long start = get_time();\n  \n  for (int k = 1; k < Nfr; k++) {\n    \n\n    kernel_likelihood<<<num_blocks, BLOCK_SIZE>>>(\n        arrayX_GPU, arrayY_GPU, xj_GPU, yj_GPU, ind_GPU,\n        objxy_GPU, likelihood_GPU, I_GPU, weights_GPU, seed_GPU, partial_sums_GPU,\n        Nparticles, countOnes, IszY, Nfr, k, max_size);\n\n#ifdef DEBUG\n    float * sum = (float *) calloc(Nparticles + 1, sizeof (float));\n    cudaMemcpy(sum, partial_sums_GPU, (Nparticles+1)*sizeof(float), cudaMemcpyDeviceToHost);\n    for (int i = 0; i < Nparticles+1; i++)\n      printf(\"%f \", sum[i]);\n    printf(\"\\n\");\n#endif\n\n    kernel_sum<<<1, 1>>>(partial_sums_GPU, Nparticles);\n\n#ifdef DEBUG\n    \n\n    cudaMemcpy(sum, partial_sums_GPU, sizeof(float), cudaMemcpyDeviceToHost);\n    printf(\"kernel sum: frame=%d partial_sums[0]=%f\\n\", k, sum[0]);\n    free(sum);\n#endif\n\n    kernel_normalize_weights<<<num_blocks, BLOCK_SIZE>>>(\n        weights_GPU,\n        partial_sums_GPU,\n        CDF_GPU,\n        u_GPU,\n        seed_GPU,\n        Nparticles );\n\n    kernel_find_index<<<num_blocks, BLOCK_SIZE>>>(\n        arrayX_GPU,\n        arrayY_GPU,\n        CDF_GPU,\n        u_GPU,\n        xj_GPU,\n        yj_GPU,\n        Nparticles );\n  } \n\n\n  cudaDeviceSynchronize();\n  long long end = get_time();\n  printf(\"Average execution time of kernels: %f (s)\\n\",\n         elapsed_time(start, end) / (Nfr-1));\n\n  cudaMemcpy(arrayX, arrayX_GPU, Nparticles*sizeof(float), cudaMemcpyDeviceToHost);\n  cudaMemcpy(arrayY, arrayY_GPU, Nparticles*sizeof(float), cudaMemcpyDeviceToHost);\n  cudaMemcpy(weights, weights_GPU, Nparticles*sizeof(float), cudaMemcpyDeviceToHost);\n\n  cudaFree(likelihood_GPU);\n  cudaFree(arrayX_GPU);\n  cudaFree(arrayY_GPU);\n  cudaFree(xj_GPU);\n  cudaFree(yj_GPU);\n  cudaFree(CDF_GPU);\n  cudaFree(partial_sums_GPU);\n  cudaFree(objxy_GPU);\n  cudaFree(u_GPU);\n  cudaFree(ind_GPU);\n  cudaFree(seed_GPU);\n  cudaFree(weights_GPU);\n  cudaFree(I_GPU);\n\n  long long offload_end = get_time();\n  printf(\"Device offloading time: %f (s)\\n\", elapsed_time(offload_start, offload_end));\n\n  xe = 0;\n  ye = 0;\n  \n\n  for (x = 0; x < Nparticles; x++) {\n    xe += arrayX[x] * weights[x];\n    ye += arrayY[x] * weights[x];\n  }\n  float distance = sqrt(pow((float) (xe - (int) roundFloat(IszY / 2.0)), 2) + pow((float) (ye - (int) roundFloat(IszX / 2.0)), 2));\n\n  \n\n  FILE *fid;\n  fid=fopen(\"output.txt\", \"w+\");\n  if( fid == NULL ){\n    printf( \"The file was not opened for writing\\n\" );\n    return -1;\n  }\n  fprintf(fid, \"XE: %f\\n\", xe);\n  fprintf(fid, \"YE: %f\\n\", ye);\n  fprintf(fid, \"distance: %f\\n\", distance);\n  fclose(fid);\n\n  \n\n  free(likelihood);\n  free(arrayX);\n  free(arrayY);\n  free(xj);\n  free(yj);\n  free(CDF);\n  free(ind);\n  free(u);\n  return 0;\n}\n\nint main(int argc, char * argv[]) {\n\n  const char* usage = \"./main -x <dimX> -y <dimY> -z <Nfr> -np <Nparticles>\";\n  \n\n  if (argc != 9) {\n    printf(\"%s\\n\", usage);\n    return 0;\n  }\n  \n\n  if (strcmp(argv[1], \"-x\") || strcmp(argv[3], \"-y\") || strcmp(argv[5], \"-z\") || strcmp(argv[7], \"-np\")) {\n    printf(\"%s\\n\", usage);\n    return 0;\n  }\n\n  int IszX, IszY, Nfr, Nparticles;\n\n  \n\n  if (sscanf(argv[2], \"%d\", &IszX) == EOF) {\n    printf(\"ERROR: dimX input is incorrect\");\n    return 0;\n  }\n\n  if (IszX <= 0) {\n    printf(\"dimX must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[4], \"%d\", &IszY) == EOF) {\n    printf(\"ERROR: dimY input is incorrect\");\n    return 0;\n  }\n\n  if (IszY <= 0) {\n    printf(\"dimY must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[6], \"%d\", &Nfr) == EOF) {\n    printf(\"ERROR: Number of frames input is incorrect\");\n    return 0;\n  }\n\n  if (Nfr <= 0) {\n    printf(\"number of frames must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[8], \"%d\", &Nparticles) == EOF) {\n    printf(\"ERROR: Number of particles input is incorrect\");\n    return 0;\n  }\n\n  if (Nparticles <= 0) {\n    printf(\"Number of particles must be > 0\\n\");\n    return 0;\n  }\n\n#ifdef DEBUG\n  printf(\"dimX=%d dimY=%d Nfr=%d Nparticles=%d\\n\", \n      IszX, IszY, Nfr, Nparticles);\n#endif\n\n  \n\n  int * seed = (int *) calloc(Nparticles, sizeof(int));\n  int i;\n  for (i = 0; i < Nparticles; i++)\n    seed[i] = i+1;\n\n  \n\n  unsigned char * I = (unsigned char *) calloc(IszX * IszY * Nfr, sizeof(unsigned char));\n  long long start = get_time();\n\n  \n\n  videoSequence(I, IszX, IszY, Nfr, seed);\n  long long endVideoSequence = get_time();\n  printf(\"VIDEO SEQUENCE TOOK %f (s)\\n\", elapsed_time(start, endVideoSequence));\n\n  \n\n  particleFilter(I, IszX, IszY, Nfr, seed, Nparticles);\n  long long endParticleFilter = get_time();\n  printf(\"PARTICLE FILTER TOOK %f (s)\\n\", elapsed_time(endVideoSequence, endParticleFilter));\n\n  printf(\"ENTIRE PROGRAM TOOK %f (s)\\n\", elapsed_time(start, endParticleFilter));\n\n  free(seed);\n  free(I);\n  return 0;\n}\n"}}
{"kernel_name": "particlefilter", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <limits.h>\n#include <math.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <float.h>\n#include <time.h>\n#include <sys/time.h>\n#include <iostream>\n#include <hip/hip_runtime.h>\n\n#define BLOCK_X 16\n#define BLOCK_Y 16\n#define PI 3.1415926535897932f\n#define A 1103515245\n#define C 12345\n#define M INT_MAX\n#define SCALE_FACTOR 300.0f\n\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 256\n#endif\n\n#include \"kernel_find_index.h\"\n#include \"kernel_likelihood.h\"\n#include \"kernel_normalize_weights.h\"\n#include \"kernel_sum.h\"\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\n\n\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) +tv.tv_usec;\n}\n\n\n\nfloat elapsed_time(long long start_time, long long end_time) {\n  return (float) (end_time - start_time) / (1000 * 1000);\n}\n\n\n\nfloat randu(int * seed, int index) {\n  int num = A * seed[index] + C;\n  seed[index] = num % M;\n  return fabs(seed[index] / ((float) M));\n}\n\n\n\nfloat randn(int * seed, int index) {\n  \n\n  float u = randu(seed, index);\n  float v = randu(seed, index);\n  float cosine = cos(2 * PI * v);\n  float rt = -2 * log(u);\n  return sqrt(rt) * cosine;\n}\n\n\n\nfloat roundFloat(float value) {\n  int newValue = (int) (value);\n  if (value - newValue < .5)\n    return newValue;\n  else\n    return newValue++;\n}\n\n\n\nvoid setIf(int testValue, int newValue, unsigned char * array3D, int * dimX, int * dimY, int * dimZ) {\n  int x, y, z;\n  for (x = 0; x < *dimX; x++) {\n    for (y = 0; y < *dimY; y++) {\n      for (z = 0; z < *dimZ; z++) {\n        if (array3D[x * *dimY * *dimZ + y * *dimZ + z] == testValue)\n          array3D[x * *dimY * *dimZ + y * *dimZ + z] = newValue;\n      }\n    }\n  }\n}\n\n\n\nvoid addNoise(unsigned char * array3D, int * dimX, int * dimY, int * dimZ, int * seed) {\n  int x, y, z;\n  for (x = 0; x < *dimX; x++) {\n    for (y = 0; y < *dimY; y++) {\n      for (z = 0; z < *dimZ; z++) {\n        array3D[x * *dimY * *dimZ + y * *dimZ + z] = array3D[x * *dimY * *dimZ + y * *dimZ + z] + (unsigned char) (5 * randn(seed, 0));\n      }\n    }\n  }\n}\n\n\n\nvoid strelDisk(int * disk, int radius) {\n  int diameter = radius * 2 - 1;\n  int x, y;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      float distance = sqrt(pow((float) (x - radius + 1), 2) + pow((float) (y - radius + 1), 2));\n      if (distance < radius)\n        disk[x * diameter + y] = 1;\n      else\n        disk[x * diameter + y] = 0;\n    }\n  }\n}\n\n\n\nvoid dilate_matrix(unsigned char * matrix, int posX, int posY, int posZ, int dimX, int dimY, int dimZ, int error) {\n  int startX = posX - error;\n  while (startX < 0)\n    startX++;\n  int startY = posY - error;\n  while (startY < 0)\n    startY++;\n  int endX = posX + error;\n  while (endX > dimX)\n    endX--;\n  int endY = posY + error;\n  while (endY > dimY)\n    endY--;\n  int x, y;\n  for (x = startX; x < endX; x++) {\n    for (y = startY; y < endY; y++) {\n      float distance = sqrt(pow((float) (x - posX), 2) + pow((float) (y - posY), 2));\n      if (distance < error)\n        matrix[x * dimY * dimZ + y * dimZ + posZ] = 1;\n    }\n  }\n}\n\n\n\nvoid imdilate_disk(unsigned char * matrix, int dimX, int dimY, int dimZ, int error, unsigned char * newMatrix) {\n  int x, y, z;\n  for (z = 0; z < dimZ; z++) {\n    for (x = 0; x < dimX; x++) {\n      for (y = 0; y < dimY; y++) {\n        if (matrix[x * dimY * dimZ + y * dimZ + z] == 1) {\n          dilate_matrix(newMatrix, x, y, z, dimX, dimY, dimZ, error);\n        }\n      }\n    }\n  }\n}\n\n\n\nvoid getneighbors(int * se, int numOnes, int * neighbors, int radius) {\n  int x, y;\n  int neighY = 0;\n  int center = radius - 1;\n  int diameter = radius * 2 - 1;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      if (se[x * diameter + y]) {\n        neighbors[neighY * 2] = (int) (y - center);\n        neighbors[neighY * 2 + 1] = (int) (x - center);\n        neighY++;\n      }\n    }\n  }\n}\n\n\n\nvoid videoSequence(unsigned char * I, int IszX, int IszY, int Nfr, int * seed) {\n  int k;\n  int max_size = IszX * IszY * Nfr;\n  \n\n  int x0 = (int) roundFloat(IszY / 2.0);\n  int y0 = (int) roundFloat(IszX / 2.0);\n  I[x0 * IszY * Nfr + y0 * Nfr + 0] = 1;\n\n  \n\n  int xk, yk, pos;\n  for (k = 1; k < Nfr; k++) {\n    xk = abs(x0 + (k - 1));\n    yk = abs(y0 - 2 * (k - 1));\n    pos = yk * IszY * Nfr + xk * Nfr + k;\n    if (pos >= max_size)\n      pos = 0;\n    I[pos] = 1;\n  }\n\n  \n\n  unsigned char * newMatrix = (unsigned char *) calloc(IszX * IszY * Nfr, sizeof(unsigned char));\n  imdilate_disk(I, IszX, IszY, Nfr, 5, newMatrix);\n  int x, y;\n  for (x = 0; x < IszX; x++) {\n    for (y = 0; y < IszY; y++) {\n      for (k = 0; k < Nfr; k++) {\n        I[x * IszY * Nfr + y * Nfr + k] = newMatrix[x * IszY * Nfr + y * Nfr + k];\n      }\n    }\n  }\n  free(newMatrix);\n\n  \n\n  setIf(0, 100, I, &IszX, &IszY, &Nfr);\n  setIf(1, 228, I, &IszX, &IszY, &Nfr);\n  \n\n  addNoise(I, &IszX, &IszY, &Nfr, seed);\n\n}\n\n\n\nint findIndex(float * CDF, int lengthCDF, float value) {\n  int index = -1;\n  int x;\n  for (x = 0; x < lengthCDF; x++) {\n    if (CDF[x] >= value) {\n      index = x;\n      break;\n    }\n  }\n  if (index == -1) {\n    return lengthCDF - 1;\n  }\n  return index;\n}\n\n\n\nint particleFilter(unsigned char * I, int IszX, int IszY, int Nfr, int * seed, int Nparticles) {\n  int max_size = IszX * IszY*Nfr;\n  \n\n  float xe = roundFloat(IszY / 2.0);\n  float ye = roundFloat(IszX / 2.0);\n\n  \n\n  int radius = 5;\n  int diameter = radius * 2 - 1;\n  int * disk = (int*) calloc(diameter * diameter, sizeof (int));\n  strelDisk(disk, radius);\n  int countOnes = 0;\n  int x, y;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      if (disk[x * diameter + y] == 1)\n        countOnes++;\n    }\n  }\n  int * objxy = (int *) calloc(countOnes * 2, sizeof(int));\n  getneighbors(disk, countOnes, objxy, radius);\n\n  \n\n  float * weights = (float *) calloc(Nparticles, sizeof(float));\n  for (x = 0; x < Nparticles; x++) {\n    weights[x] = 1 / ((float) (Nparticles));\n  }\n  \n\n  float * likelihood = (float *) calloc(Nparticles + 1, sizeof (float));\n  float * arrayX = (float *) calloc(Nparticles, sizeof (float));\n  float * arrayY = (float *) calloc(Nparticles, sizeof (float));\n  float * xj = (float *) calloc(Nparticles, sizeof (float));\n  float * yj = (float *) calloc(Nparticles, sizeof (float));\n  float * CDF = (float *) calloc(Nparticles, sizeof(float));\n\n  \n\n  int * ind = (int*) calloc(countOnes * Nparticles, sizeof(int));\n  float * u = (float *) calloc(Nparticles, sizeof(float));\n\n  \n\n  \n\n  \n\n  for (x = 0; x < Nparticles; x++) {\n    xj[x] = xe;\n    yj[x] = ye;\n  }\n\n  long long offload_start = get_time();\n\n  int num_blocks = (Nparticles + BLOCK_SIZE - 1) / BLOCK_SIZE;\n#ifdef DEBUG\n  printf(\"BLOCK_SIZE=%d \\n\",BLOCK_SIZE);\n#endif\n\n  float* likelihood_GPU;\n  float* arrayX_GPU;\n  float* arrayY_GPU;\n  float* xj_GPU;\n  float* yj_GPU;\n  float* CDF_GPU;\n  float* partial_sums_GPU;\n  float* u_GPU;\n  int* objxy_GPU;\n  int* ind_GPU;\n  int* seed_GPU;\n  float* weights_GPU;\n  unsigned char* I_GPU;\n\n  hipMalloc((void**)&likelihood_GPU, (Nparticles + 1)*sizeof(float));\n\n  hipMalloc((void**)&arrayX_GPU, Nparticles*sizeof(float));\n  hipMalloc((void**)&arrayY_GPU, Nparticles*sizeof(float));\n  hipMalloc((void**)&xj_GPU, Nparticles*sizeof(float));\n  hipMalloc((void**)&yj_GPU, Nparticles*sizeof(float));\n  hipMemcpy(xj_GPU, xj, Nparticles*sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(yj_GPU, yj, Nparticles*sizeof(float), hipMemcpyHostToDevice);\n  hipMalloc((void**)&CDF_GPU, Nparticles*sizeof(float));\n  hipMalloc((void**)&u_GPU, Nparticles*sizeof(float));\n  \n\n\n  hipMalloc((void**)&ind_GPU, countOnes*Nparticles*sizeof(int));\n  \n\n\n  hipMalloc((void**)&weights_GPU, Nparticles*sizeof(float));\n  \n\n  \n\n  \n\n  hipMemcpy(weights_GPU, weights, Nparticles*sizeof(float), hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&I_GPU, IszX * IszY * Nfr * sizeof(unsigned char));\n  hipMemcpy(I_GPU, I, IszX * IszY * Nfr * sizeof(unsigned char), hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&seed_GPU, Nparticles*sizeof(int));\n  hipMemcpy(seed_GPU, seed, Nparticles*sizeof(int), hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&partial_sums_GPU, (Nparticles+1)*sizeof(float));\n  \n\n\n  hipMalloc((void**)&objxy_GPU, 2*countOnes*sizeof(int));\n  hipMemcpy(objxy_GPU, objxy, 2*countOnes*sizeof(int), hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  long long start = get_time();\n  \n  for (int k = 1; k < Nfr; k++) {\n    \n\n    hipLaunchKernelGGL(kernel_likelihood, num_blocks, BLOCK_SIZE, 0, 0, \n        arrayX_GPU, arrayY_GPU, xj_GPU, yj_GPU, ind_GPU,\n        objxy_GPU, likelihood_GPU, I_GPU, weights_GPU, seed_GPU, partial_sums_GPU,\n        Nparticles, countOnes, IszY, Nfr, k, max_size);\n\n#ifdef DEBUG\n    float * sum = (float *) calloc(Nparticles + 1, sizeof (float));\n    hipMemcpy(sum, partial_sums_GPU, (Nparticles+1)*sizeof(float), hipMemcpyDeviceToHost);\n    for (int i = 0; i < Nparticles+1; i++)\n      printf(\"%f \", sum[i]);\n    printf(\"\\n\");\n#endif\n\n    hipLaunchKernelGGL(kernel_sum, 1, 1, 0, 0, partial_sums_GPU, Nparticles);\n\n#ifdef DEBUG\n    \n\n    hipMemcpy(sum, partial_sums_GPU, sizeof(float), hipMemcpyDeviceToHost);\n    printf(\"kernel sum: frame=%d partial_sums[0]=%f\\n\", k, sum[0]);\n    free(sum);\n#endif\n\n    hipLaunchKernelGGL(kernel_normalize_weights, num_blocks, BLOCK_SIZE, 0, 0, \n        weights_GPU,\n        partial_sums_GPU,\n        CDF_GPU,\n        u_GPU,\n        seed_GPU,\n        Nparticles );\n\n    hipLaunchKernelGGL(kernel_find_index, num_blocks, BLOCK_SIZE, 0, 0, \n        arrayX_GPU,\n        arrayY_GPU,\n        CDF_GPU,\n        u_GPU,\n        xj_GPU,\n        yj_GPU,\n        Nparticles );\n  } \n\n\n  hipDeviceSynchronize();\n  long long end = get_time();\n  printf(\"Average execution time of kernels: %f (s)\\n\",\n         elapsed_time(start, end) / (Nfr-1));\n\n  hipMemcpy(arrayX, arrayX_GPU, Nparticles*sizeof(float), hipMemcpyDeviceToHost);\n  hipMemcpy(arrayY, arrayY_GPU, Nparticles*sizeof(float), hipMemcpyDeviceToHost);\n  hipMemcpy(weights, weights_GPU, Nparticles*sizeof(float), hipMemcpyDeviceToHost);\n\n  hipFree(likelihood_GPU);\n  hipFree(arrayX_GPU);\n  hipFree(arrayY_GPU);\n  hipFree(xj_GPU);\n  hipFree(yj_GPU);\n  hipFree(CDF_GPU);\n  hipFree(partial_sums_GPU);\n  hipFree(objxy_GPU);\n  hipFree(u_GPU);\n  hipFree(ind_GPU);\n  hipFree(seed_GPU);\n  hipFree(weights_GPU);\n  hipFree(I_GPU);\n\n  long long offload_end = get_time();\n  printf(\"Device offloading time: %f (s)\\n\", elapsed_time(offload_start, offload_end));\n\n  xe = 0;\n  ye = 0;\n  \n\n  for (x = 0; x < Nparticles; x++) {\n    xe += arrayX[x] * weights[x];\n    ye += arrayY[x] * weights[x];\n  }\n  float distance = sqrt(pow((float) (xe - (int) roundFloat(IszY / 2.0)), 2) + pow((float) (ye - (int) roundFloat(IszX / 2.0)), 2));\n\n  \n\n  FILE *fid;\n  fid=fopen(\"output.txt\", \"w+\");\n  if( fid == NULL ){\n    printf( \"The file was not opened for writing\\n\" );\n    return -1;\n  }\n  fprintf(fid, \"XE: %f\\n\", xe);\n  fprintf(fid, \"YE: %f\\n\", ye);\n  fprintf(fid, \"distance: %f\\n\", distance);\n  fclose(fid);\n\n  \n\n  free(likelihood);\n  free(arrayX);\n  free(arrayY);\n  free(xj);\n  free(yj);\n  free(CDF);\n  free(ind);\n  free(u);\n  return 0;\n}\n\nint main(int argc, char * argv[]) {\n\n  const char* usage = \"./main -x <dimX> -y <dimY> -z <Nfr> -np <Nparticles>\";\n  \n\n  if (argc != 9) {\n    printf(\"%s\\n\", usage);\n    return 0;\n  }\n  \n\n  if (strcmp(argv[1], \"-x\") || strcmp(argv[3], \"-y\") || strcmp(argv[5], \"-z\") || strcmp(argv[7], \"-np\")) {\n    printf(\"%s\\n\", usage);\n    return 0;\n  }\n\n  int IszX, IszY, Nfr, Nparticles;\n\n  \n\n  if (sscanf(argv[2], \"%d\", &IszX) == EOF) {\n    printf(\"ERROR: dimX input is incorrect\");\n    return 0;\n  }\n\n  if (IszX <= 0) {\n    printf(\"dimX must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[4], \"%d\", &IszY) == EOF) {\n    printf(\"ERROR: dimY input is incorrect\");\n    return 0;\n  }\n\n  if (IszY <= 0) {\n    printf(\"dimY must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[6], \"%d\", &Nfr) == EOF) {\n    printf(\"ERROR: Number of frames input is incorrect\");\n    return 0;\n  }\n\n  if (Nfr <= 0) {\n    printf(\"number of frames must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[8], \"%d\", &Nparticles) == EOF) {\n    printf(\"ERROR: Number of particles input is incorrect\");\n    return 0;\n  }\n\n  if (Nparticles <= 0) {\n    printf(\"Number of particles must be > 0\\n\");\n    return 0;\n  }\n\n#ifdef DEBUG\n  printf(\"dimX=%d dimY=%d Nfr=%d Nparticles=%d\\n\", \n      IszX, IszY, Nfr, Nparticles);\n#endif\n\n  \n\n  int * seed = (int *) calloc(Nparticles, sizeof(int));\n  int i;\n  for (i = 0; i < Nparticles; i++)\n    seed[i] = i+1;\n\n  \n\n  unsigned char * I = (unsigned char *) calloc(IszX * IszY * Nfr, sizeof(unsigned char));\n  long long start = get_time();\n\n  \n\n  videoSequence(I, IszX, IszY, Nfr, seed);\n  long long endVideoSequence = get_time();\n  printf(\"VIDEO SEQUENCE TOOK %f (s)\\n\", elapsed_time(start, endVideoSequence));\n\n  \n\n  particleFilter(I, IszX, IszY, Nfr, seed, Nparticles);\n  long long endParticleFilter = get_time();\n  printf(\"PARTICLE FILTER TOOK %f (s)\\n\", elapsed_time(endVideoSequence, endParticleFilter));\n\n  printf(\"ENTIRE PROGRAM TOOK %f (s)\\n\", elapsed_time(start, endParticleFilter));\n\n  free(seed);\n  free(I);\n  return 0;\n}\n"}}
{"kernel_name": "particlefilter", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <limits.h>\n#include <math.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <float.h>\n#include <time.h>\n#include <sys/time.h>\n#include <omp.h>\n\n#define BLOCK_X 16\n#define BLOCK_Y 16\n#define PI 3.1415926535897932f\n#define A 1103515245\n#define C 12345\n#define M INT_MAX\n#define SCALE_FACTOR 300.0f\n\n#ifndef BLOCK_SIZE \n#define BLOCK_SIZE 256\n#endif\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\n\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\n\n\nfloat elapsed_time(long long start_time, long long end_time) {\n  return (float) (end_time - start_time) / (1000 * 1000);\n}\n\n\n\nfloat randu(int * seed, int index) {\n  int num = A * seed[index] + C;\n  seed[index] = num % M;\n  return fabs(seed[index] / ((float) M));\n}\n\n\n\nfloat randn(int * seed, int index) {\n  \n\n  float u = randu(seed, index);\n  float v = randu(seed, index);\n  float cosine = cos(2 * PI * v);\n  float rt = -2 * log(u);\n  return sqrt(rt) * cosine;\n}\n\n\n\nfloat roundFloat(float value) {\n  int newValue = (int) (value);\n  if (value - newValue < .5)\n    return newValue;\n  else\n    return newValue++;\n}\n\n\n\nvoid setIf(int testValue, int newValue, unsigned char * array3D, int * dimX, int * dimY, int * dimZ) {\n  int x, y, z;\n  for (x = 0; x < *dimX; x++) {\n    for (y = 0; y < *dimY; y++) {\n      for (z = 0; z < *dimZ; z++) {\n        if (array3D[x * *dimY * *dimZ + y * *dimZ + z] == testValue)\n          array3D[x * *dimY * *dimZ + y * *dimZ + z] = newValue;\n      }\n    }\n  }\n}\n\n\n\nvoid addNoise(unsigned char * array3D, int * dimX, int * dimY, int * dimZ, int * seed) {\n  int x, y, z;\n  for (x = 0; x < *dimX; x++) {\n    for (y = 0; y < *dimY; y++) {\n      for (z = 0; z < *dimZ; z++) {\n        array3D[x * *dimY * *dimZ + y * *dimZ + z] = array3D[x * *dimY * *dimZ + y * *dimZ + z] + (unsigned char) (5 * randn(seed, 0));\n      }\n    }\n  }\n}\n\n\n\nvoid strelDisk(int * disk, int radius) {\n  int diameter = radius * 2 - 1;\n  int x, y;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      float distance = sqrt(pow((float) (x - radius + 1), 2) + pow((float) (y - radius + 1), 2));\n      if (distance < radius)\n        disk[x * diameter + y] = 1;\n      else\n        disk[x * diameter + y] = 0;\n    }\n  }\n}\n\n\n\nvoid dilate_matrix(unsigned char * matrix, int posX, int posY, int posZ, int dimX, int dimY, int dimZ, int error) {\n  int startX = posX - error;\n  while (startX < 0)\n    startX++;\n  int startY = posY - error;\n  while (startY < 0)\n    startY++;\n  int endX = posX + error;\n  while (endX > dimX)\n    endX--;\n  int endY = posY + error;\n  while (endY > dimY)\n    endY--;\n  int x, y;\n  for (x = startX; x < endX; x++) {\n    for (y = startY; y < endY; y++) {\n      float distance = sqrt(pow((float) (x - posX), 2) + pow((float) (y - posY), 2));\n      if (distance < error)\n        matrix[x * dimY * dimZ + y * dimZ + posZ] = 1;\n    }\n  }\n}\n\n\n\nvoid imdilate_disk(unsigned char * matrix, int dimX, int dimY, int dimZ, int error, unsigned char * newMatrix) {\n  int x, y, z;\n  for (z = 0; z < dimZ; z++) {\n    for (x = 0; x < dimX; x++) {\n      for (y = 0; y < dimY; y++) {\n        if (matrix[x * dimY * dimZ + y * dimZ + z] == 1) {\n          dilate_matrix(newMatrix, x, y, z, dimX, dimY, dimZ, error);\n        }\n      }\n    }\n  }\n}\n\n\n\nvoid getneighbors(int * se, int numOnes, int * neighbors, int radius) {\n  int x, y;\n  int neighY = 0;\n  int center = radius - 1;\n  int diameter = radius * 2 - 1;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      if (se[x * diameter + y]) {\n        neighbors[neighY * 2] = (int) (y - center);\n        neighbors[neighY * 2 + 1] = (int) (x - center);\n        neighY++;\n      }\n    }\n  }\n}\n\n\n\nvoid videoSequence(unsigned char * I, int IszX, int IszY, int Nfr, int * seed) {\n  int k;\n  int max_size = IszX * IszY * Nfr;\n  \n\n  int x0 = (int) roundFloat(IszY / 2.0);\n  int y0 = (int) roundFloat(IszX / 2.0);\n  I[x0 * IszY * Nfr + y0 * Nfr + 0] = 1;\n\n  \n\n  int xk, yk, pos;\n  for (k = 1; k < Nfr; k++) {\n    xk = abs(x0 + (k - 1));\n    yk = abs(y0 - 2 * (k - 1));\n    pos = yk * IszY * Nfr + xk * Nfr + k;\n    if (pos >= max_size)\n      pos = 0;\n    I[pos] = 1;\n  }\n\n  \n\n  unsigned char * newMatrix = (unsigned char *) calloc(IszX * IszY * Nfr, sizeof(unsigned char));\n  imdilate_disk(I, IszX, IszY, Nfr, 5, newMatrix);\n  int x, y;\n  for (x = 0; x < IszX; x++) {\n    for (y = 0; y < IszY; y++) {\n      for (k = 0; k < Nfr; k++) {\n        I[x * IszY * Nfr + y * Nfr + k] = newMatrix[x * IszY * Nfr + y * Nfr + k];\n      }\n    }\n  }\n  free(newMatrix);\n\n  \n\n  setIf(0, 100, I, &IszX, &IszY, &Nfr);\n  setIf(1, 228, I, &IszX, &IszY, &Nfr);\n  \n\n  addNoise(I, &IszX, &IszY, &Nfr, seed);\n\n}\n\n\n\nint findIndex(float * CDF, int lengthCDF, float value) {\n  int index = -1;\n  int x;\n  for (x = 0; x < lengthCDF; x++) {\n    if (CDF[x] >= value) {\n      index = x;\n      break;\n    }\n  }\n  if (index == -1) {\n    return lengthCDF - 1;\n  }\n  return index;\n}\n\n\n\nint particleFilter(unsigned char * I, int IszX, int IszY, int Nfr, int * seed, int Nparticles) {\n  int max_size = IszX * IszY*Nfr;\n  \n\n  float xe = roundFloat(IszY / 2.0);\n  float ye = roundFloat(IszX / 2.0);\n\n  \n\n  int radius = 5;\n  int diameter = radius * 2 - 1;\n  int * disk = (int*) calloc(diameter * diameter, sizeof (int));\n  strelDisk(disk, radius);\n  int countOnes = 0;\n  int x, y;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      if (disk[x * diameter + y] == 1)\n        countOnes++;\n    }\n  }\n  int * objxy = (int *) calloc(countOnes * 2, sizeof(int));\n  getneighbors(disk, countOnes, objxy, radius);\n\n  \n\n  float * weights = (float *) calloc(Nparticles, sizeof(float));\n  for (x = 0; x < Nparticles; x++) {\n    weights[x] = 1 / ((float) (Nparticles));\n  }\n  \n\n  float * likelihood = (float *) calloc(Nparticles + 1, sizeof (float));\n  float * partial_sums = (float *) calloc(Nparticles + 1, sizeof (float));\n  float * arrayX = (float *) calloc(Nparticles, sizeof (float));\n  float * arrayY = (float *) calloc(Nparticles, sizeof (float));\n  float * xj = (float *) calloc(Nparticles, sizeof (float));\n  float * yj = (float *) calloc(Nparticles, sizeof (float));\n  float * CDF = (float *) calloc(Nparticles, sizeof(float));\n\n\n  \n\n  int * ind = (int*) calloc(countOnes * Nparticles, sizeof(int));\n  float * u = (float *) calloc(Nparticles, sizeof(float));\n\n  \n\n  \n\n  \n\n  for (x = 0; x < Nparticles; x++) {\n\n    xj[x] = xe;\n    yj[x] = ye;\n  }\n\n  long long offload_start = get_time();\n\n\n  int k;\n\n  int num_blocks = (Nparticles + BLOCK_SIZE - 1) / BLOCK_SIZE;\n#ifdef DEBUG\n  printf(\"BLOCK_SIZE=%d \\n\",BLOCK_SIZE);\n#endif\n\n#pragma omp target data \\\n  map(alloc: likelihood[0:Nparticles+1], \\\n             ind[0:countOnes*Nparticles], \\\n             u[0:Nparticles], \\\n             partial_sums[0:Nparticles+1], \\\n             CDF[0:Nparticles]) \\\n  map(from: arrayX[0:Nparticles], \\\n            arrayY[0:Nparticles]) \\\n  map(tofrom: weights[0:Nparticles]) \\\n  map(to: xj[0:Nparticles], \\\n          yj[0:Nparticles], \\\n          seed[0:Nparticles], \\\n          I[0:IszX * IszY * Nfr], \\\n          objxy[0:2*countOnes])\n  {\n    long long start = get_time();\n\n    for (k = 1; k < Nfr; k++) {\n      \n\n      #pragma omp target teams num_teams(num_blocks) thread_limit(BLOCK_SIZE)\n      {\n        float weights_local[BLOCK_SIZE];\n        #pragma omp parallel\n        {\n          int block_id = omp_get_team_num();\n          int thread_id = omp_get_thread_num();\n          int block_dim = omp_get_num_threads();\n          int i = block_id * block_dim + thread_id;\n          int y;\n          int indX, indY;\n          float u, v;\n\n          if(i < Nparticles){\n            arrayX[i] = xj[i];\n            arrayY[i] = yj[i];\n            weights[i] = 1.0f / ((float) (Nparticles)); \n            seed[i] = (A*seed[i] + C) % M;\n            u = fabsf(seed[i]/((float)M));\n            seed[i] = (A*seed[i] + C) % M;\n            v = fabsf(seed[i]/((float)M));\n            arrayX[i] += 1.0f + 5.0f*(sqrtf(-2.0f*logf(u))*cosf(2.0f*PI*v));\n\n            seed[i] = (A*seed[i] + C) % M;\n            u = fabsf(seed[i]/((float)M));\n            seed[i] = (A*seed[i] + C) % M;\n            v = fabsf(seed[i]/((float)M));\n            arrayY[i] += -2.0f + 2.0f*(sqrtf(-2.0f*logf(u))*cosf(2.0f*PI*v));\n          }\n\n          #pragma omp barrier\n\n          if(i < Nparticles)\n          {\n            for(y = 0; y < countOnes; y++){\n\n              int iX = arrayX[i];\n              int iY = arrayY[i];\n              int rnd_iX = (arrayX[i] - iX) < .5f ? iX : iX++;\n              int rnd_iY = (arrayY[i] - iY) < .5f ? iY : iY++;\n              indX = rnd_iX + objxy[y*2 + 1];\n              indY = rnd_iY + objxy[y*2];\n\n              ind[i*countOnes + y] = abs(indX*IszY*Nfr + indY*Nfr + k);\n              if(ind[i*countOnes + y] >= max_size)\n                ind[i*countOnes + y] = 0;\n            }\n            float likelihoodSum = 0.0f;\n            for(int x = 0; x < countOnes; x++)\n              likelihoodSum += ((I[ind[i*countOnes + x]] - 100) * (I[ind[i*countOnes + x]] - 100) -\n                  (I[ind[i*countOnes + x]] - 228) * (I[ind[i*countOnes + x]] - 228)) / 50.0f;\n            likelihood[i] = likelihoodSum/countOnes-SCALE_FACTOR;\n\n            weights[i] = weights[i] * expf(likelihood[i]);\n\n          }\n\n          weights_local[thread_id] = (i < Nparticles) ?  weights[i] : 0.f;\n\n          #pragma omp barrier\n\n          for(unsigned int s=block_dim/2; s>0; s>>=1)\n          {\n            if(thread_id < s)\n            {\n              weights_local[thread_id] += weights_local[thread_id + s];\n            }\n          #pragma omp barrier\n          }\n          if(thread_id == 0)\n          {\n            partial_sums[block_id] = weights_local[0];\n          }\n        }\n      }\n\n      #pragma omp target\n      {\n        float sum = 0;\n        int num_blocks = (Nparticles + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        for (int x = 0; x < num_blocks; x++) {\n          sum += partial_sums[x];\n        }\n        partial_sums[0] = sum;\n      }\n\n#ifdef DEBUG\n      \n\n#pragma omp target update from (partial_sums[0:1])\n      printf(\"kernel sum: frame=%d partial_sums[0]=%f\\n\",\n          k, partial_sums[0]);\n#endif\n\n      #pragma omp target teams num_teams(num_blocks) thread_limit(BLOCK_SIZE)\n      {\n        float u1;\n        float sumWeights; \n        #pragma omp parallel\n        {\n          int local_id = omp_get_thread_num();\n          int i = omp_get_team_num() * omp_get_num_threads() + local_id;\n          if(0 == local_id)\n            sumWeights = partial_sums[0];\n\n          #pragma omp barrier\n          if(i < Nparticles) {\n            weights[i] = weights[i]/sumWeights;\n          }\n\n          #pragma omp barrier\n          if(i == 0) {\n            CDF[0] = weights[0];\n            for(int x = 1; x < Nparticles; x++){\n              CDF[x] = weights[x] + CDF[x-1];\n            }\n\n            seed[i] = (A*seed[i] + C) % M;\n            float p = fabsf(seed[i]/((float)M));\n            seed[i] = (A*seed[i] + C) % M;\n            float q = fabsf(seed[i]/((float)M));\n            u[0] = (1.0f/((float)(Nparticles))) * \n              (sqrtf(-2.0f*logf(p))*cosf(2.0f*PI*q));\n            \n\n          }\n\n          #pragma omp barrier\n          if(0 == local_id)\n            u1 = u[0];\n\n          #pragma omp barrier\n          if(i < Nparticles)\n          {\n            u[i] = u1 + i/((float)(Nparticles));\n          }\n        }\n      }\n\n#ifdef DEBUG\n\n#pragma omp target update from (arrayX[0:Nparticles])\n#pragma omp target update from (arrayY[0:Nparticles])\n#pragma omp target update from (weights[0:Nparticles])\n\n      xe = 0;\n      ye = 0;\n      float total=0.0;\n      \n\n      for (x = 0; x < Nparticles; x++) {\n        xe += arrayX[x] * weights[x];\n        ye += arrayY[x] * weights[x];\n        total+= weights[x];\n      }\n      printf(\"total weight: %lf\\n\", total);\n      printf(\"XE: %lf\\n\", xe);\n      printf(\"YE: %lf\\n\", ye);\n      float distance = sqrt(pow((float) (xe - (int) roundFloat(IszY / 2.0)), 2) + pow((float) (ye - (int) roundFloat(IszX / 2.0)), 2));\n      printf(\"distance: %lf\\n\", distance);\n#endif\n\n      #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n      for (int i = 0; i < Nparticles; i++)\n      {\n        int index = -1;\n        int x;\n\n        for(x = 0; x < Nparticles; x++){\n          if(CDF[x] >= u[i]){\n            index = x;\n            break;\n          }\n        }\n        if(index == -1){\n          index = Nparticles-1;\n        }\n\n        xj[i] = arrayX[index];\n        yj[i] = arrayY[index];\n      }\n    }\n\n\n    long long end = get_time();\n    printf(\"Average execution time of kernels: %f (s)\\n\",\n           elapsed_time(start, end) / (Nfr-1));\n\n  } \n\n\n  long long offload_end = get_time();\n  printf(\"Device offloading time: %lf (s)\\n\", elapsed_time(offload_start, offload_end));\n\n  xe = 0;\n  ye = 0;\n  \n\n  for (x = 0; x < Nparticles; x++) {\n    xe += arrayX[x] * weights[x];\n    ye += arrayY[x] * weights[x];\n  }\n  float distance = sqrt(pow((float) (xe - (int) roundFloat(IszY / 2.0)), 2) + pow((float) (ye - (int) roundFloat(IszX / 2.0)), 2));\n\n  \n\n  FILE *fid;\n  fid=fopen(\"output.txt\", \"w+\");\n  if( fid == NULL ){\n    printf( \"The file was not opened for writing\\n\" );\n    return -1;\n  }\n  fprintf(fid, \"XE: %lf\\n\", xe);\n  fprintf(fid, \"YE: %lf\\n\", ye);\n  fprintf(fid, \"distance: %lf\\n\", distance);\n  fclose(fid);\n\n  \n\n  free(likelihood);\n  free(partial_sums);\n  free(arrayX);\n  free(arrayY);\n  free(xj);\n  free(yj);\n  free(CDF);\n  free(ind);\n  free(u);\n  return 0;\n}\n\nint main(int argc, char * argv[]) {\n\n  const char* usage = \"./main -x <dimX> -y <dimY> -z <Nfr> -np <Nparticles>\";\n  \n\n  if (argc != 9) {\n    printf(\"%s\\n\", usage);\n    return 0;\n  }\n  \n\n  if (strcmp(argv[1], \"-x\") || strcmp(argv[3], \"-y\") || strcmp(argv[5], \"-z\") || strcmp(argv[7], \"-np\")) {\n    printf(\"%s\\n\", usage);\n    return 0;\n  }\n\n  int IszX, IszY, Nfr, Nparticles;\n\n  \n\n  if (sscanf(argv[2], \"%d\", &IszX) == EOF) {\n    printf(\"ERROR: dimX input is incorrect\");\n    return 0;\n  }\n\n  if (IszX <= 0) {\n    printf(\"dimX must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[4], \"%d\", &IszY) == EOF) {\n    printf(\"ERROR: dimY input is incorrect\");\n    return 0;\n  }\n\n  if (IszY <= 0) {\n    printf(\"dimY must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[6], \"%d\", &Nfr) == EOF) {\n    printf(\"ERROR: Number of frames input is incorrect\");\n    return 0;\n  }\n\n  if (Nfr <= 0) {\n    printf(\"number of frames must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[8], \"%d\", &Nparticles) == EOF) {\n    printf(\"ERROR: Number of particles input is incorrect\");\n    return 0;\n  }\n\n  if (Nparticles <= 0) {\n    printf(\"Number of particles must be > 0\\n\");\n    return 0;\n  }\n\n#ifdef DEBUG\n  printf(\"dimX=%d dimY=%d Nfr=%d Nparticles=%d\\n\", \n      IszX, IszY, Nfr, Nparticles);\n#endif\n\n  \n\n  int * seed = (int *) calloc(Nparticles, sizeof(int));\n  int i;\n  for (i = 0; i < Nparticles; i++)\n    seed[i] = i+1;\n\n  \n\n  unsigned char * I = (unsigned char *) calloc(IszX * IszY * Nfr, sizeof(unsigned char));\n  long long start = get_time();\n\n  \n\n  videoSequence(I, IszX, IszY, Nfr, seed);\n  long long endVideoSequence = get_time();\n  printf(\"VIDEO SEQUENCE TOOK %f (s)\\n\", elapsed_time(start, endVideoSequence));\n\n  \n\n  particleFilter(I, IszX, IszY, Nfr, seed, Nparticles);\n  long long endParticleFilter = get_time();\n  printf(\"PARTICLE FILTER TOOK %f (s)\\n\", elapsed_time(endVideoSequence, endParticleFilter));\n\n  printf(\"ENTIRE PROGRAM TOOK %f (s)\\n\", elapsed_time(start, endParticleFilter));\n\n  free(seed);\n  free(I);\n  return 0;\n}\n"}}
{"kernel_name": "particlefilter", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <limits.h>\n#include <math.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <float.h>\n#include <time.h>\n#include <sys/time.h>\n\n#define BLOCK_X 16\n#define BLOCK_Y 16\n#define PI 3.1415926535897932f\n#define A 1103515245\n#define C 12345\n#define M INT_MAX\n#define SCALE_FACTOR 300.0f\n\n#ifndef BLOCK_SIZE \n#define BLOCK_SIZE 256\n#endif\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\n\n\nlong long get_time() {\n  struct timeval tv;\n  gettimeofday(&tv, NULL);\n  return (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\n\n\nfloat elapsed_time(long long start_time, long long end_time) {\n  return (float) (end_time - start_time) / (1000 * 1000);\n}\n\n\n\nfloat randu(int * seed, int index) {\n  int num = A * seed[index] + C;\n  seed[index] = num % M;\n  return fabs(seed[index] / ((float) M));\n}\n\n\n\nfloat randn(int * seed, int index) {\n  \n\n  float u = randu(seed, index);\n  float v = randu(seed, index);\n  float cosine = cos(2 * PI * v);\n  float rt = -2 * log(u);\n  return sqrt(rt) * cosine;\n}\n\n\n\nfloat roundFloat(float value) {\n  int newValue = (int) (value);\n  if (value - newValue < .5)\n    return newValue;\n  else\n    return newValue++;\n}\n\n\n\nvoid setIf(int testValue, int newValue, unsigned char * array3D, int * dimX, int * dimY, int * dimZ) {\n  int x, y, z;\n  for (x = 0; x < *dimX; x++) {\n    for (y = 0; y < *dimY; y++) {\n      for (z = 0; z < *dimZ; z++) {\n        if (array3D[x * *dimY * *dimZ + y * *dimZ + z] == testValue)\n          array3D[x * *dimY * *dimZ + y * *dimZ + z] = newValue;\n      }\n    }\n  }\n}\n\n\n\nvoid addNoise(unsigned char * array3D, int * dimX, int * dimY, int * dimZ, int * seed) {\n  int x, y, z;\n  for (x = 0; x < *dimX; x++) {\n    for (y = 0; y < *dimY; y++) {\n      for (z = 0; z < *dimZ; z++) {\n        array3D[x * *dimY * *dimZ + y * *dimZ + z] = array3D[x * *dimY * *dimZ + y * *dimZ + z] + (unsigned char) (5 * randn(seed, 0));\n      }\n    }\n  }\n}\n\n\n\nvoid strelDisk(int * disk, int radius) {\n  int diameter = radius * 2 - 1;\n  int x, y;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      float distance = sqrt(pow((float) (x - radius + 1), 2) + pow((float) (y - radius + 1), 2));\n      if (distance < radius)\n        disk[x * diameter + y] = 1;\n      else\n        disk[x * diameter + y] = 0;\n    }\n  }\n}\n\n\n\nvoid dilate_matrix(unsigned char * matrix, int posX, int posY, int posZ, int dimX, int dimY, int dimZ, int error) {\n  int startX = posX - error;\n  while (startX < 0)\n    startX++;\n  int startY = posY - error;\n  while (startY < 0)\n    startY++;\n  int endX = posX + error;\n  while (endX > dimX)\n    endX--;\n  int endY = posY + error;\n  while (endY > dimY)\n    endY--;\n  int x, y;\n  for (x = startX; x < endX; x++) {\n    for (y = startY; y < endY; y++) {\n      float distance = sqrt(pow((float) (x - posX), 2) + pow((float) (y - posY), 2));\n      if (distance < error)\n        matrix[x * dimY * dimZ + y * dimZ + posZ] = 1;\n    }\n  }\n}\n\n\n\nvoid imdilate_disk(unsigned char * matrix, int dimX, int dimY, int dimZ, int error, unsigned char * newMatrix) {\n  int x, y, z;\n  for (z = 0; z < dimZ; z++) {\n    for (x = 0; x < dimX; x++) {\n      for (y = 0; y < dimY; y++) {\n        if (matrix[x * dimY * dimZ + y * dimZ + z] == 1) {\n          dilate_matrix(newMatrix, x, y, z, dimX, dimY, dimZ, error);\n        }\n      }\n    }\n  }\n}\n\n\n\nvoid getneighbors(int * se, int numOnes, int * neighbors, int radius) {\n  int x, y;\n  int neighY = 0;\n  int center = radius - 1;\n  int diameter = radius * 2 - 1;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      if (se[x * diameter + y]) {\n        neighbors[neighY * 2] = (int) (y - center);\n        neighbors[neighY * 2 + 1] = (int) (x - center);\n        neighY++;\n      }\n    }\n  }\n}\n\n\n\nvoid videoSequence(unsigned char * I, int IszX, int IszY, int Nfr, int * seed) {\n  int k;\n  int max_size = IszX * IszY * Nfr;\n  \n\n  int x0 = (int) roundFloat(IszY / 2.0);\n  int y0 = (int) roundFloat(IszX / 2.0);\n  I[x0 * IszY * Nfr + y0 * Nfr + 0] = 1;\n\n  \n\n  int xk, yk, pos;\n  for (k = 1; k < Nfr; k++) {\n    xk = abs(x0 + (k - 1));\n    yk = abs(y0 - 2 * (k - 1));\n    pos = yk * IszY * Nfr + xk * Nfr + k;\n    if (pos >= max_size)\n      pos = 0;\n    I[pos] = 1;\n  }\n\n  \n\n  unsigned char * newMatrix = (unsigned char *) calloc(IszX * IszY * Nfr, sizeof(unsigned char));\n  imdilate_disk(I, IszX, IszY, Nfr, 5, newMatrix);\n  int x, y;\n  for (x = 0; x < IszX; x++) {\n    for (y = 0; y < IszY; y++) {\n      for (k = 0; k < Nfr; k++) {\n        I[x * IszY * Nfr + y * Nfr + k] = newMatrix[x * IszY * Nfr + y * Nfr + k];\n      }\n    }\n  }\n  free(newMatrix);\n\n  \n\n  setIf(0, 100, I, &IszX, &IszY, &Nfr);\n  setIf(1, 228, I, &IszX, &IszY, &Nfr);\n  \n\n  addNoise(I, &IszX, &IszY, &Nfr, seed);\n\n}\n\n\n\nint findIndex(float * CDF, int lengthCDF, float value) {\n  int index = -1;\n  int x;\n  for (x = 0; x < lengthCDF; x++) {\n    if (CDF[x] >= value) {\n      index = x;\n      break;\n    }\n  }\n  if (index == -1) {\n    return lengthCDF - 1;\n  }\n  return index;\n}\n\n\n\nint particleFilter(unsigned char * I, int IszX, int IszY, int Nfr, int * seed, int Nparticles) {\n  int max_size = IszX * IszY*Nfr;\n  \n\n  float xe = roundFloat(IszY / 2.0);\n  float ye = roundFloat(IszX / 2.0);\n\n  \n\n  int radius = 5;\n  int diameter = radius * 2 - 1;\n  int * disk = (int*) calloc(diameter * diameter, sizeof (int));\n  strelDisk(disk, radius);\n  int countOnes = 0;\n  int x, y;\n  for (x = 0; x < diameter; x++) {\n    for (y = 0; y < diameter; y++) {\n      if (disk[x * diameter + y] == 1)\n        countOnes++;\n    }\n  }\n  int * objxy = (int *) calloc(countOnes * 2, sizeof(int));\n  getneighbors(disk, countOnes, objxy, radius);\n\n  \n\n  float * weights = (float *) calloc(Nparticles, sizeof(float));\n  for (x = 0; x < Nparticles; x++) {\n    weights[x] = 1 / ((float) (Nparticles));\n  }\n  \n\n  float * likelihood = (float *) calloc(Nparticles + 1, sizeof (float));\n  float * partial_sums = (float *) calloc(Nparticles + 1, sizeof (float));\n  float * arrayX = (float *) calloc(Nparticles, sizeof (float));\n  float * arrayY = (float *) calloc(Nparticles, sizeof (float));\n  float * xj = (float *) calloc(Nparticles, sizeof (float));\n  float * yj = (float *) calloc(Nparticles, sizeof (float));\n  float * CDF = (float *) calloc(Nparticles, sizeof(float));\n\n\n  \n\n  int * ind = (int*) calloc(countOnes * Nparticles, sizeof(int));\n  float * u = (float *) calloc(Nparticles, sizeof(float));\n\n  \n\n  \n\n  \n\n  for (x = 0; x < Nparticles; x++) {\n\n    xj[x] = xe;\n    yj[x] = ye;\n  }\n\n  long long offload_start = get_time();\n\n\n  int k;\n\n  int num_blocks = (Nparticles + BLOCK_SIZE - 1) / BLOCK_SIZE;\n#ifdef DEBUG\n  printf(\"BLOCK_SIZE=%d \\n\",BLOCK_SIZE);\n#endif\n\n  {\n    long long start = get_time();\n\n    for (k = 1; k < Nfr; k++) {\n      \n\n            {\n        float weights_local[BLOCK_SIZE];\n                {\n          int block_id = omp_get_team_num();\n          int thread_id = omp_get_thread_num();\n          int block_dim = omp_get_num_threads();\n          int i = block_id * block_dim + thread_id;\n          int y;\n          int indX, indY;\n          float u, v;\n\n          if(i < Nparticles){\n            arrayX[i] = xj[i];\n            arrayY[i] = yj[i];\n            weights[i] = 1.0f / ((float) (Nparticles)); \n            seed[i] = (A*seed[i] + C) % M;\n            u = fabsf(seed[i]/((float)M));\n            seed[i] = (A*seed[i] + C) % M;\n            v = fabsf(seed[i]/((float)M));\n            arrayX[i] += 1.0f + 5.0f*(sqrtf(-2.0f*logf(u))*cosf(2.0f*PI*v));\n\n            seed[i] = (A*seed[i] + C) % M;\n            u = fabsf(seed[i]/((float)M));\n            seed[i] = (A*seed[i] + C) % M;\n            v = fabsf(seed[i]/((float)M));\n            arrayY[i] += -2.0f + 2.0f*(sqrtf(-2.0f*logf(u))*cosf(2.0f*PI*v));\n          }\n\n          \n          if(i < Nparticles)\n          {\n            for(y = 0; y < countOnes; y++){\n\n              int iX = arrayX[i];\n              int iY = arrayY[i];\n              int rnd_iX = (arrayX[i] - iX) < .5f ? iX : iX++;\n              int rnd_iY = (arrayY[i] - iY) < .5f ? iY : iY++;\n              indX = rnd_iX + objxy[y*2 + 1];\n              indY = rnd_iY + objxy[y*2];\n\n              ind[i*countOnes + y] = abs(indX*IszY*Nfr + indY*Nfr + k);\n              if(ind[i*countOnes + y] >= max_size)\n                ind[i*countOnes + y] = 0;\n            }\n            float likelihoodSum = 0.0f;\n            for(int x = 0; x < countOnes; x++)\n              likelihoodSum += ((I[ind[i*countOnes + x]] - 100) * (I[ind[i*countOnes + x]] - 100) -\n                  (I[ind[i*countOnes + x]] - 228) * (I[ind[i*countOnes + x]] - 228)) / 50.0f;\n            likelihood[i] = likelihoodSum/countOnes-SCALE_FACTOR;\n\n            weights[i] = weights[i] * expf(likelihood[i]);\n\n          }\n\n          weights_local[thread_id] = (i < Nparticles) ?  weights[i] : 0.f;\n\n          \n          for(unsigned int s=block_dim/2; s>0; s>>=1)\n          {\n            if(thread_id < s)\n            {\n              weights_local[thread_id] += weights_local[thread_id + s];\n            }\n                    }\n          if(thread_id == 0)\n          {\n            partial_sums[block_id] = weights_local[0];\n          }\n        }\n      }\n\n            {\n        float sum = 0;\n        int num_blocks = (Nparticles + BLOCK_SIZE - 1) / BLOCK_SIZE;\n        for (int x = 0; x < num_blocks; x++) {\n          sum += partial_sums[x];\n        }\n        partial_sums[0] = sum;\n      }\n\n#ifdef DEBUG\n      \n\n      printf(\"kernel sum: frame=%d partial_sums[0]=%f\\n\",\n          k, partial_sums[0]);\n#endif\n\n            {\n        float u1;\n        float sumWeights; \n                {\n          int local_id = omp_get_thread_num();\n          int i = omp_get_team_num() * omp_get_num_threads() + local_id;\n          if(0 == local_id)\n            sumWeights = partial_sums[0];\n\n                    if(i < Nparticles) {\n            weights[i] = weights[i]/sumWeights;\n          }\n\n                    if(i == 0) {\n            CDF[0] = weights[0];\n            for(int x = 1; x < Nparticles; x++){\n              CDF[x] = weights[x] + CDF[x-1];\n            }\n\n            seed[i] = (A*seed[i] + C) % M;\n            float p = fabsf(seed[i]/((float)M));\n            seed[i] = (A*seed[i] + C) % M;\n            float q = fabsf(seed[i]/((float)M));\n            u[0] = (1.0f/((float)(Nparticles))) * \n              (sqrtf(-2.0f*logf(p))*cosf(2.0f*PI*q));\n            \n\n          }\n\n                    if(0 == local_id)\n            u1 = u[0];\n\n                    if(i < Nparticles)\n          {\n            u[i] = u1 + i/((float)(Nparticles));\n          }\n        }\n      }\n\n#ifdef DEBUG\n\n\n      xe = 0;\n      ye = 0;\n      float total=0.0;\n      \n\n      for (x = 0; x < Nparticles; x++) {\n        xe += arrayX[x] * weights[x];\n        ye += arrayY[x] * weights[x];\n        total+= weights[x];\n      }\n      printf(\"total weight: %lf\\n\", total);\n      printf(\"XE: %lf\\n\", xe);\n      printf(\"YE: %lf\\n\", ye);\n      float distance = sqrt(pow((float) (xe - (int) roundFloat(IszY / 2.0)), 2) + pow((float) (ye - (int) roundFloat(IszX / 2.0)), 2));\n      printf(\"distance: %lf\\n\", distance);\n#endif\n\n            for (int i = 0; i < Nparticles; i++)\n      {\n        int index = -1;\n        int x;\n\n        for(x = 0; x < Nparticles; x++){\n          if(CDF[x] >= u[i]){\n            index = x;\n            break;\n          }\n        }\n        if(index == -1){\n          index = Nparticles-1;\n        }\n\n        xj[i] = arrayX[index];\n        yj[i] = arrayY[index];\n      }\n    }\n\n\n    long long end = get_time();\n    printf(\"Average execution time of kernels: %f (s)\\n\",\n           elapsed_time(start, end) / (Nfr-1));\n\n  } \n\n\n  long long offload_end = get_time();\n  printf(\"Device offloading time: %lf (s)\\n\", elapsed_time(offload_start, offload_end));\n\n  xe = 0;\n  ye = 0;\n  \n\n  for (x = 0; x < Nparticles; x++) {\n    xe += arrayX[x] * weights[x];\n    ye += arrayY[x] * weights[x];\n  }\n  float distance = sqrt(pow((float) (xe - (int) roundFloat(IszY / 2.0)), 2) + pow((float) (ye - (int) roundFloat(IszX / 2.0)), 2));\n\n  \n\n  FILE *fid;\n  fid=fopen(\"output.txt\", \"w+\");\n  if( fid == NULL ){\n    printf( \"The file was not opened for writing\\n\" );\n    return -1;\n  }\n  fprintf(fid, \"XE: %lf\\n\", xe);\n  fprintf(fid, \"YE: %lf\\n\", ye);\n  fprintf(fid, \"distance: %lf\\n\", distance);\n  fclose(fid);\n\n  \n\n  free(likelihood);\n  free(partial_sums);\n  free(arrayX);\n  free(arrayY);\n  free(xj);\n  free(yj);\n  free(CDF);\n  free(ind);\n  free(u);\n  return 0;\n}\n\nint main(int argc, char * argv[]) {\n\n  const char* usage = \"./main -x <dimX> -y <dimY> -z <Nfr> -np <Nparticles>\";\n  \n\n  if (argc != 9) {\n    printf(\"%s\\n\", usage);\n    return 0;\n  }\n  \n\n  if (strcmp(argv[1], \"-x\") || strcmp(argv[3], \"-y\") || strcmp(argv[5], \"-z\") || strcmp(argv[7], \"-np\")) {\n    printf(\"%s\\n\", usage);\n    return 0;\n  }\n\n  int IszX, IszY, Nfr, Nparticles;\n\n  \n\n  if (sscanf(argv[2], \"%d\", &IszX) == EOF) {\n    printf(\"ERROR: dimX input is incorrect\");\n    return 0;\n  }\n\n  if (IszX <= 0) {\n    printf(\"dimX must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[4], \"%d\", &IszY) == EOF) {\n    printf(\"ERROR: dimY input is incorrect\");\n    return 0;\n  }\n\n  if (IszY <= 0) {\n    printf(\"dimY must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[6], \"%d\", &Nfr) == EOF) {\n    printf(\"ERROR: Number of frames input is incorrect\");\n    return 0;\n  }\n\n  if (Nfr <= 0) {\n    printf(\"number of frames must be > 0\\n\");\n    return 0;\n  }\n\n  \n\n  if (sscanf(argv[8], \"%d\", &Nparticles) == EOF) {\n    printf(\"ERROR: Number of particles input is incorrect\");\n    return 0;\n  }\n\n  if (Nparticles <= 0) {\n    printf(\"Number of particles must be > 0\\n\");\n    return 0;\n  }\n\n#ifdef DEBUG\n  printf(\"dimX=%d dimY=%d Nfr=%d Nparticles=%d\\n\", \n      IszX, IszY, Nfr, Nparticles);\n#endif\n\n  \n\n  int * seed = (int *) calloc(Nparticles, sizeof(int));\n  int i;\n  for (i = 0; i < Nparticles; i++)\n    seed[i] = i+1;\n\n  \n\n  unsigned char * I = (unsigned char *) calloc(IszX * IszY * Nfr, sizeof(unsigned char));\n  long long start = get_time();\n\n  \n\n  videoSequence(I, IszX, IszY, Nfr, seed);\n  long long endVideoSequence = get_time();\n  printf(\"VIDEO SEQUENCE TOOK %f (s)\\n\", elapsed_time(start, endVideoSequence));\n\n  \n\n  particleFilter(I, IszX, IszY, Nfr, seed, Nparticles);\n  long long endParticleFilter = get_time();\n  printf(\"PARTICLE FILTER TOOK %f (s)\\n\", elapsed_time(endVideoSequence, endParticleFilter));\n\n  printf(\"ENTIRE PROGRAM TOOK %f (s)\\n\", elapsed_time(start, endParticleFilter));\n\n  free(seed);\n  free(I);\n  return 0;\n}"}}
{"kernel_name": "pcc", "parallel_api": "cuda", "code": {"device.cu": "#include <chrono>\n#include <iostream>\n#include <fstream>\n#include <cublas_v2.h>\n#include <cuda_runtime.h>\n#include \"device.h\"\n\nsize_t remaining_B(int , size_t );\nvoid preprocessing(float * , int , int );\n\n__global__ void ker(const float * cormat, float * upper,int n)\n{\n  size_t idx = blockDim.x*blockIdx.x+threadIdx.x;\n  if (idx < (size_t)n * n) {\n    size_t i = idx/n;\n    size_t j = idx%n;\n    if(i<j)\n    {\n      size_t t = n * i - i * (i+1) / 2 + j - i - 1;\n      \n\n      upper[t]=cormat[j*n+i];\n    }\n  }\n}\n\n__global__ void ker2(const float * cormat, float * upper, int n1, int n)\n{\n  size_t idx = blockDim.x*blockIdx.x+threadIdx.x;\n  if (idx < (size_t)n1 * n) {\n    size_t i = idx/n;\n    size_t j = idx%n;\n    if(i<j && i<n1)\n    {\n      size_t t = n * i - i * (i+1) / 2 + j - i - 1;\n      upper[t]=cormat[j*n1+i];\n    }\n  }\n}\n\n\nint CorMat_singlePass(float* upper_tri, float * data, int N, int L)\n{\n  size_t M1 = (N-1); \n\n  M1 *= N;\n  M1 /= 2;\n  size_t total=N*N;\n\n\n  preprocessing(data, N, L);\n\n\n  cublasStatus_t stat;\n  cublasHandle_t handle;\n  stat = cublasCreate(&handle) ;\n  if (stat != CUBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in creating cublas handle\";\n    return stat;\n  }\n\n  float * dev_data; \n\n  cudaMalloc ((void**)&dev_data, sizeof(float) * L * N) ;\n\n  stat = cublasSetMatrix(N, L, sizeof(float), data, N, dev_data, N);\n\n  if (stat != CUBLAS_STATUS_SUCCESS) {\n    std::cout<<\"Error in copying data to GPU\";\n    return stat;\n  }\n\n  const float alpha = 1.0;\n  const float beta = 0.0;\n\n  float* dev_cormat;\n\n  cudaMalloc ((void**)&dev_cormat, sizeof(float) * total) ;\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  stat = cublasSgemm(handle, CUBLAS_OP_T, CUBLAS_OP_N,\n                     N,N,L,\n                     &alpha, dev_data, L,\n                     dev_data, L, &beta,\n                     dev_cormat, N);\n  if (stat != CUBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in performing multiplication\";\n    return stat;\n  }\n  cudaDeviceSynchronize(); \n\n  auto end = std::chrono::steady_clock::now();\n  auto gemm_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  float* dev_upper;\n\n  cudaMalloc ((void**)&dev_upper, sizeof(float) * M1) ;\n\n  int block_size=THREAD_BLOCK_SIZE;\n\n  size_t grid_size=1+((total-1)/block_size);\n\n\n  start = std::chrono::steady_clock::now();\n\n  ker<<<grid_size,block_size>>>(dev_cormat,dev_upper,N);\n\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  auto extract_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  cudaMemcpy(upper_tri, dev_upper, sizeof(float) * M1, cudaMemcpyDeviceToHost);\n\n  cudaFree (dev_data);\n  cudaFree (dev_cormat);\n  cudaFree (dev_upper);\n\n  stat = cublasDestroy(handle);\n  if (stat != CUBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in destroying cublas handle\";\n    return stat;\n  }\n\n  std::cout << \"Kernel time (s)\\n\"\n            << \"GEMM: \" << gemm_time * 1e-9 << \", \"\n            << \"Extract upper triangle: \" << extract_time * 1e-9 << \"\\n\";\n\n  return 1;\n}\n\n\nint CorMat_multiPass(float* upper_tri, float * data, int N, int L)\n{\n  int flag=1;\n\n  preprocessing(data, N, L);\n\n\n  cublasStatus_t stat;\n  cublasHandle_t handle;\n\n  float * dev_data;\n\n  cudaMalloc ((void**)&dev_data, sizeof(float) * L * N);\n\n  stat = cublasSetMatrix(N, L, sizeof(float), data, N, dev_data, N);\n  if (stat != CUBLAS_STATUS_SUCCESS) {\n    std::cout<<\"Error in copying data to GPU\";\n    return stat;\n  }\n\n  stat = cublasCreate(&handle) ;\n  if (stat != CUBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in creating cublas handle\";\n    return stat;\n  }\n\n  const float alpha = 1.0;\n  const float beta = 0.0;\n\n  const size_t free_memory = FREE_MEMORY;\n  size_t available_memory = free_memory / sizeof(float) - (long)N * L;\n\n  int block=remaining_B(N, available_memory);\n  int N_prime=N;\n\n  float* add_uper_cpu=upper_tri;\n  size_t M1,temp,temp2=0,temp3=0;\n  int so_far=0;\n  int pak=0;\n  float* dev_cormat;\n  float* dev_upper;\n  size_t cormat_fullsize;\n  size_t gemm_time = 0, extract_time = 0;\n\n  while(flag==1)\n  {\n    if(block==N_prime)\n\n      flag=0;\n\n    temp = block;\n    temp *= (block +1);\n    temp /= 2;\n    M1=N_prime;\n    M1*=block;\n    M1-=temp; \n\n\n    if(pak!=0)\n    {\n      cudaFree (dev_upper);\n      cudaFree (dev_cormat);\n    }\n    cormat_fullsize=block;\n    cormat_fullsize*=N_prime;\n\n    cudaMalloc ((void**)&dev_cormat, sizeof(float) * cormat_fullsize) ;\n    cudaMalloc ((void**)&dev_upper, sizeof(float) * M1) ;\n\n    pak++;\n\n    \n\n    auto start = std::chrono::steady_clock::now();\n    stat = cublasSgemm(handle, CUBLAS_OP_T,  CUBLAS_OP_N,\n                       block, N_prime, L,\n                       &alpha, dev_data+(so_far*L), L, dev_data+(so_far*L), L, &beta,\n                       dev_cormat, block);\n\n    if (stat != CUBLAS_STATUS_SUCCESS)\n    {\n      std::cout<<\"Error in performing multiplication\";\n      return stat;\n    }\n    cudaDeviceSynchronize(); \n\n    auto end = std::chrono::steady_clock::now();\n    gemm_time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    temp2=block;\n    temp2*=N_prime;\n\n    int block_size=THREAD_BLOCK_SIZE;\n    size_t grid_size=1+((temp2-1)/block_size);\n\n    start = std::chrono::steady_clock::now();\n\n    ker2<<<grid_size,block_size>>>(dev_cormat,dev_upper,block,N_prime);\n\n    cudaDeviceSynchronize();\n    end = std::chrono::steady_clock::now();\n    extract_time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    cudaMemcpy(add_uper_cpu, dev_upper, sizeof(float) * M1, cudaMemcpyDeviceToHost);\n\n    temp3+=M1;\n    add_uper_cpu=upper_tri+temp3;\n    so_far+=block;\n\n    if(N_prime>block)\n    {\n      N_prime=N_prime-block;\n      block=remaining_B(N_prime, available_memory);\n\n      if(N_prime < block)\n\n        block=N_prime;\n    }\n  }\n  cudaFree (dev_data);\n  cudaFree (dev_upper);\n  cudaFree (dev_cormat);\n\n  stat = cublasDestroy(handle);\n  if (stat != CUBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in destroying cublas handle\";\n    return stat;\n  }\n\n  std::cout << \"Total Kernel time (s)\\n\"\n            << \"GEMM: \" << gemm_time * 1e-9 << \", \"\n            << \"Extract upper triangle: \" << extract_time * 1e-9 << \"\\n\";\n\n  return 1;\n}\n", "main.cpp": "#include <chrono>\n#include <iostream>\n#include <fstream>\n#include <random>\n#include \"device.h\"\n\nint CorMat_singlePass(float* , float * , int , int);\nint CorMat_multiPass(float* , float * , int , int);\n\nsize_t remaining_B(int N, size_t available_memory)\n{\n  size_t x=available_memory;\n  size_t temp=N;\n  temp*=2;\n  x/=temp;\n  return x;\n}\n\nvoid preprocessing(float * data_t, int N,int L)\n{\n  for (int i = 0; i < N; i++)\n  {\n    float * row = data_t + i * L;\n    double sum1 = 0, sum2 = 0;\n    for (int l = 0; l < L; l++)\n    {\n      sum1 += row[l];\n    }\n    sum1 /= L;\n    for (int l = 0; l < L; l++)\n    {\n      sum2 += (row[l] - sum1) * (row[l] - sum1);\n    }\n    sum2 = sqrt(sum2);\n    for (int l = 0; l < L; l++)\n    {\n      if(sum2!=0)\n        row[l] = (row[l] - sum1) / sum2;\n      else\n        if(sum2==0)\n          row[l]=0;\n    }\n  }\n}\n\n\nint main(int argc, char *argv[])\n{\n  if (argc != 3) {\n     std::cout<<\"Usage: \" << argv[0] << \" <Number of voxels> <Length of time series>\\n\";\n     return 1;\n  }\n\n  int N = atoi(argv[1]);\n  int L = atoi(argv[2]);\n  std::cout<<\"Number of voxels: \"<<N<<\"  \"<<\"Length of time series: \"<<L<<\"\\n\\n\";\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> uniform_distr (-6.f, 6.f);\n\n  int k = 0, l = 0;\n  float * data = new float [L * N];\n  for (  k = 0; k < N; k++)\n    for ( l = 0; l < L; l++)\n      data[k*L+l] = uniform_distr(g);\n\n  size_t M11 = (N-1);\n  M11 *= N;\n  M11 /= 2;\n\n  float * upper_tri = new float [M11];\n\n  for(size_t indii=0;indii<M11;indii++)\n    upper_tri[indii]=0;\n\n  std::cout<<\"\\nComputing correlations ...\\n\";\n\n  const size_t free_memory = FREE_MEMORY;\n\n  size_t app_memory = sizeof(float) * ((size_t)N * L + (size_t)N * N + M11);\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (app_memory < free_memory) {\n    CorMat_singlePass(upper_tri, data, N, L);\n  }\n  else {\n    CorMat_multiPass(upper_tri, data, N, L);\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout<<\"\\nRunning time for computing correlations: \\n\"<< (time * 1e-9f) << \" (s)\\n\";\n\n  double checksum = 0;\n  for(size_t tab =0;tab<M11;tab++) {\n    checksum += upper_tri[tab];\n  }\n  std::cout<<\"Checksum: \" << checksum << \"\\n\";\n\n  if (N < 100 && L < 100) {\n    std::cout<<\"\\nWriting correlation values into the text file ... \\n\";\n    std::ofstream correlations_print;\n    correlations_print.open(\"corrs.txt\");\n    for(size_t tab =0;tab<M11;tab++) {\n      correlations_print << upper_tri[tab] << '\\n';\n    }\n    correlations_print.close();\n    std::cout<<\"\\nCorrelations are stored into the text file corrs.txt \\n\";\n  }\n\n  delete [] upper_tri;\n  delete [] data;\n\n  return 0;\n}\n"}}
{"kernel_name": "pcc", "parallel_api": "hip", "code": {"device.cu": "#include <chrono>\n#include <iostream>\n#include <fstream>\n#include <hipblas.h>\n#include <hip/hip_runtime.h>\n#include \"device.h\"\n\nsize_t remaining_B(int , size_t );\nvoid preprocessing(float * , int , int );\n\n__global__ void ker(const float * cormat, float * upper,int n)\n{\n  size_t idx = blockDim.x*blockIdx.x+threadIdx.x;\n  if (idx < (size_t)n * n) {\n    size_t i = idx/n;\n    size_t j = idx%n;\n    if(i<j)\n    {\n      size_t t = n * i - i * (i+1) / 2 + j - i - 1;\n      \n\n      upper[t]=cormat[j*n+i];\n    }\n  }\n}\n\n__global__ void ker2(const float * cormat, float * upper, int n1, int n)\n{\n  size_t idx = blockDim.x*blockIdx.x+threadIdx.x;\n  if (idx < (size_t)n1 * n) {\n    size_t i = idx/n;\n    size_t j = idx%n;\n    if(i<j && i<n1)\n    {\n      size_t t = n * i - i * (i+1) / 2 + j - i - 1;\n      upper[t]=cormat[j*n1+i];\n    }\n  }\n}\n\n\nint CorMat_singlePass(float* upper_tri, float * data, int N, int L)\n{\n  size_t M1 = (N-1); \n\n  M1 *= N;\n  M1 /= 2;\n  size_t total=N*N;\n\n\n  preprocessing(data, N, L);\n\n\n  hipblasStatus_t stat;\n  hipblasHandle_t handle;\n  stat = hipblasCreate(&handle) ;\n  if (stat != HIPBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in creating hipblas handle\";\n    return stat;\n  }\n\n  float * dev_data; \n\n  hipMalloc ((void**)&dev_data, sizeof(float) * L * N) ;\n\n  stat = hipblasSetMatrix(N, L, sizeof(float), data, N, dev_data, N);\n\n  if (stat != HIPBLAS_STATUS_SUCCESS) {\n    std::cout<<\"Error in copying data to GPU\";\n    return stat;\n  }\n\n  const float alpha = 1.0;\n  const float beta = 0.0;\n\n  float* dev_cormat;\n\n  hipMalloc ((void**)&dev_cormat, sizeof(float) * total) ;\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  stat = hipblasSgemm(handle, HIPBLAS_OP_T, HIPBLAS_OP_N,\n                      N,N,L,\n                      &alpha, dev_data, L,\n                      dev_data, L, &beta,\n                      dev_cormat, N);\n  if (stat != HIPBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in performing multiplication\";\n    return stat;\n  }\n  hipDeviceSynchronize(); \n\n  auto end = std::chrono::steady_clock::now();\n  auto gemm_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  float* dev_upper;\n\n  hipMalloc ((void**)&dev_upper, sizeof(float) * M1) ;\n\n  int block_size=THREAD_BLOCK_SIZE;\n\n  size_t grid_size=1+((total-1)/block_size);\n\n\n  start = std::chrono::steady_clock::now();\n\n  ker<<<grid_size,block_size>>>(dev_cormat,dev_upper,N);\n\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  auto extract_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  hipMemcpy(upper_tri, dev_upper, sizeof(float) * M1, hipMemcpyDeviceToHost);\n\n  hipFree (dev_data);\n  hipFree (dev_cormat);\n  hipFree (dev_upper);\n\n  stat = hipblasDestroy(handle);\n  if (stat != HIPBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in destroying hipblas handle\";\n    return stat;\n  }\n\n  std::cout << \"Kernel time (s)\\n\"\n            << \"GEMM: \" << gemm_time * 1e-9 << \", \"\n            << \"Extract upper triangle: \" << extract_time * 1e-9 << \"\\n\";\n\n  return 1;\n}\n\n\nint CorMat_multiPass(float* upper_tri, float * data, int N, int L)\n{\n  int flag=1;\n\n  preprocessing(data, N, L);\n\n\n  hipblasStatus_t stat;\n  hipblasHandle_t handle;\n\n  float * dev_data;\n\n  hipMalloc ((void**)&dev_data, sizeof(float) * L * N);\n\n  stat = hipblasSetMatrix(N, L, sizeof(float), data, N, dev_data, N);\n  if (stat != HIPBLAS_STATUS_SUCCESS) {\n    std::cout<<\"Error in copying data to GPU\";\n    return stat;\n  }\n\n  stat = hipblasCreate(&handle) ;\n  if (stat != HIPBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in creating hipblas handle\";\n    return stat;\n  }\n\n  const float alpha = 1.0;\n  const float beta = 0.0;\n\n  const size_t free_memory = FREE_MEMORY;\n  size_t available_memory = free_memory / sizeof(float) - (long)N * L;\n\n  int block=remaining_B(N, available_memory);\n  int N_prime=N;\n\n  float* add_uper_cpu=upper_tri;\n  size_t M1,temp,temp2=0,temp3=0;\n  int so_far=0;\n  int pak=0;\n  float* dev_cormat;\n  float* dev_upper;\n  size_t cormat_fullsize;\n  size_t gemm_time = 0, extract_time = 0;\n\n  while(flag==1)\n  {\n    if(block==N_prime)\n\n      flag=0;\n\n    temp = block;\n    temp *= (block +1);\n    temp /= 2;\n    M1=N_prime;\n    M1*=block;\n    M1-=temp; \n\n\n    if(pak!=0)\n    {\n      hipFree (dev_upper);\n      hipFree (dev_cormat);\n    }\n    cormat_fullsize=block;\n    cormat_fullsize*=N_prime;\n\n    hipMalloc ((void**)&dev_cormat, sizeof(float) * cormat_fullsize) ;\n    hipMalloc ((void**)&dev_upper, sizeof(float) * M1) ;\n\n    pak++;\n\n    \n\n    auto start = std::chrono::steady_clock::now();\n    stat = hipblasSgemm(handle, HIPBLAS_OP_T,  HIPBLAS_OP_N,\n                       block, N_prime, L,\n                       &alpha, dev_data+(so_far*L), L, dev_data+(so_far*L), L, &beta,\n                       dev_cormat, block);\n\n    if (stat != HIPBLAS_STATUS_SUCCESS)\n    {\n      std::cout<<\"Error in performing multiplication\";\n      return stat;\n    }\n    hipDeviceSynchronize(); \n\n    auto end = std::chrono::steady_clock::now();\n    gemm_time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    temp2=block;\n    temp2*=N_prime;\n\n    int block_size=THREAD_BLOCK_SIZE;\n    size_t grid_size=1+((temp2-1)/block_size);\n\n    start = std::chrono::steady_clock::now();\n\n    ker2<<<grid_size,block_size>>>(dev_cormat,dev_upper,block,N_prime);\n\n    hipDeviceSynchronize();\n    end = std::chrono::steady_clock::now();\n    extract_time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    hipMemcpy(add_uper_cpu, dev_upper, sizeof(float) * M1, hipMemcpyDeviceToHost);\n\n    temp3+=M1;\n    add_uper_cpu=upper_tri+temp3;\n    so_far+=block;\n\n    if(N_prime>block)\n    {\n      N_prime=N_prime-block;\n      block=remaining_B(N_prime, available_memory);\n\n      if(N_prime < block)\n\n        block=N_prime;\n    }\n  }\n  hipFree (dev_data);\n  hipFree (dev_upper);\n  hipFree (dev_cormat);\n\n  stat = hipblasDestroy(handle);\n  if (stat != HIPBLAS_STATUS_SUCCESS)\n  {\n    std::cout<<\"Error in destroying hipblas handle\";\n    return stat;\n  }\n\n  std::cout << \"Total Kernel time (s)\\n\"\n            << \"GEMM: \" << gemm_time * 1e-9 << \", \"\n            << \"Extract upper triangle: \" << extract_time * 1e-9 << \"\\n\";\n\n  return 1;\n}\n"}}
{"kernel_name": "pcc", "parallel_api": "sycl", "code": {"device.cpp": "#include <chrono>\n#include <iostream>\n#include <fstream>\n#include <sycl/sycl.hpp>\n#include <oneapi/mkl.hpp>\n#include \"device.h\"\n\nvoid ker(const float * cormat, float * upper,int n,\n         const sycl::nd_item<1> &item)\n{\n  size_t idx = item.get_global_id(0);\n  if (idx < (size_t)n * n) {\n    size_t i = idx/n;\n    size_t j = idx%n;\n    if(i<j)\n    {\n      size_t t = n * i - i * (i+1) / 2 + j - i - 1;\n      \n\n      upper[t]=cormat[j*n+i];\n    }\n  }\n}\n\nvoid ker2(const float * cormat, float * upper, int n1, int n,\n          const sycl::nd_item<1> &item)\n{\n  size_t idx = item.get_global_id(0);\n  if (idx < (size_t)n1 * n) {\n    size_t i = idx/n;\n    size_t j = idx%n;\n    if(i<j && i<n1)\n    {\n      size_t t = n * i - i * (i+1) / 2 + j - i - 1;\n      upper[t]=cormat[j*n1+i];\n    }\n  }\n}\n\nint CorMat_singlePass(float *upper_tri, float *data, int N, int L) {\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  size_t M1 = (N-1); \n\n  M1 *= N;\n  M1 /= 2;\n  size_t total=N*N;\n\n\n  preprocessing(data, N, L);\n\n\n  float * dev_data; \n\n  dev_data = (float *)sycl::malloc_device(sizeof(float) * L * N, q);\n\n  q.memcpy(dev_data, data, sizeof(float) * L * N);\n\n  const float alpha = 1.0;\n  const float beta = 0.0;\n\n  float* dev_cormat;\n\n  dev_cormat = sycl::malloc_device<float>(total, q);\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n\n  sycl::event stat = oneapi::mkl::blas::column_major::gemm(\n              q, oneapi::mkl::transpose::trans,\n              oneapi::mkl::transpose::nontrans, N, N, L, alpha, dev_data, L,\n              dev_data, L, beta, dev_cormat, N);\n  stat.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto gemm_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  float* dev_upper;\n\n  dev_upper = sycl::malloc_device<float>(M1, q);\n\n  int block_size=THREAD_BLOCK_SIZE;\n\n  size_t grid_size=1+((total-1)/block_size);\n\n\n  sycl::range<1> lws (block_size);\n  sycl::range<1> gws (block_size * grid_size);\n\n  start = std::chrono::steady_clock::now();\n\n  \n\n  \n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class k>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      ker(dev_cormat, dev_upper, N, item);\n    });\n  }).wait();\n\n  end = std::chrono::steady_clock::now();\n  auto extract_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  q.memcpy(upper_tri, dev_upper, sizeof(float) * M1).wait(); \n\n  sycl::free(dev_data, q);\n  sycl::free(dev_cormat, q);\n  sycl::free(dev_upper, q);\n\n  std::cout << \"Kernel time (s)\\n\"\n            << \"GEMM: \" << gemm_time * 1e-9 << \", \"\n            << \"Extract upper triangle: \" << extract_time * 1e-9 << \"\\n\";\n\n  return 1;\n}\n\nint CorMat_multiPass(float *upper_tri, float *data, int N, int L) {\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int flag=1;\n\n  preprocessing(data,  N, L);\n\n\n  float * dev_data;\n\n  dev_data = (float *)sycl::malloc_device(sizeof(float) * L * N, q);\n\n  q.memcpy(dev_data, data, sizeof(float) * L * N);\n\n  const float alpha = 1.0;\n  const float beta = 0.0;\n\n  const size_t free_memory = FREE_MEMORY;\n  size_t available_memory = free_memory / sizeof(float) - (long)N * L;\n\n  int block=remaining_B(N, available_memory);\n  int N_prime=N;\n\n  float* add_uper_cpu=upper_tri;\n  size_t M1,temp,temp2=0,temp3=0;\n  int so_far=0;\n  int pak=0;\n  float* dev_cormat;\n  float* dev_upper;\n  size_t cormat_fullsize;\n  size_t gemm_time = 0, extract_time = 0;\n\n  while(flag==1)\n  {\n    if(block==N_prime)\n\n      flag=0;\n\n    temp = block;\n    temp *= (block +1);\n    temp /= 2;\n    M1=N_prime;\n    M1*=block;\n    M1-=temp; \n\n\n    if(pak!=0)\n    {\n      sycl::free(dev_upper, q);\n      sycl::free(dev_cormat, q);\n    }\n    cormat_fullsize=block;\n    cormat_fullsize*=N_prime;\n\n    dev_cormat = sycl::malloc_device<float>(cormat_fullsize, q);\n    dev_upper = sycl::malloc_device<float>(M1, q);\n\n    pak++;\n\n    \n\n    auto start = std::chrono::steady_clock::now();\n    sycl::event stat = oneapi::mkl::blas::column_major::gemm(\n                q, oneapi::mkl::transpose::trans,\n                oneapi::mkl::transpose::nontrans, block, N_prime, L, alpha,\n                dev_data + (so_far * L), L, dev_data + (so_far * L), L, beta,\n                dev_cormat, block);\n    stat.wait();\n    auto end = std::chrono::steady_clock::now();\n    gemm_time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    temp2=block;\n    temp2*=N_prime;\n\n    int block_size=THREAD_BLOCK_SIZE;\n    size_t grid_size=1+((temp2-1)/block_size);\n\n    sycl::range<1> lws (block_size);\n    sycl::range<1> gws (block_size * grid_size);\n\n    start = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k2>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        ker2(dev_cormat, dev_upper, block, N_prime, item);\n      });\n    }).wait();\n\n    q.wait();\n    end = std::chrono::steady_clock::now();\n    extract_time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    q.memcpy(add_uper_cpu, dev_upper, sizeof(float) * M1).wait();\n\n    temp3+=M1;\n    add_uper_cpu=upper_tri+temp3;\n    so_far+=block;\n\n    if(N_prime>block)\n    {\n      N_prime=N_prime-block;\n      block=remaining_B(N_prime, available_memory);\n\n      if(N_prime < block)\n\n        block=N_prime;\n    }\n  }\n  sycl::free(dev_data, q);\n  sycl::free(dev_upper, q);\n  sycl::free(dev_cormat, q);\n\n  std::cout << \"Total Kernel time (s)\\n\"\n            << \"GEMM: \" << gemm_time * 1e-9 << \", \"\n            << \"Extract upper triangle: \" << extract_time * 1e-9 << \"\\n\";\n\n  return 1;\n}\n"}}
{"kernel_name": "pnpoly", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <random>\n#include <chrono>\n#include <cuda.h>\n\n#define VERTICES 600\n#define BLOCK_SIZE_X 256\n\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: ./%s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int nPoints = 2e7;\n  const int vertices = VERTICES;\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float2 *point = (float2*) malloc (sizeof(float2) * nPoints);\n  for (int i = 0; i < nPoints; i++) {\n    point[i].x = distribution(rng);\n    point[i].y = distribution(rng);\n  }\n\n  float2 *vertex = (float2*) malloc (vertices * sizeof(float2));\n  for (int i = 0; i < vertices; i++) {\n    float t = distribution(rng) * 2.f * M_PI;\n    vertex[i].x = cosf(t);\n    vertex[i].y = sinf(t);\n  }\n\n  \n\n  int *bitmap_ref = (int*) malloc (nPoints * sizeof(int));\n  int *bitmap_opt = (int*) malloc (nPoints * sizeof(int));\n\n  float2 *d_point;\n  float2 *d_vertex;\n  int *d_bitmap_ref, *d_bitmap_opt;\n\n  cudaMalloc(&d_point, nPoints*sizeof(float2));\n  cudaMalloc(&d_vertex, vertices*sizeof(float2));\n  cudaMalloc(&d_bitmap_ref, nPoints*sizeof(int));\n  cudaMalloc(&d_bitmap_opt, nPoints*sizeof(int));\n\n  \n\n  dim3 threads (BLOCK_SIZE_X);\n  dim3 grid ((nPoints+BLOCK_SIZE_X-1)/BLOCK_SIZE_X);\n\n  cudaMemcpy(d_point, point, nPoints*sizeof(float2), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_vertex, vertex, vertices*sizeof(float2), cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    pnpoly_base<<<grid, threads>>>(d_bitmap_ref, d_point, d_vertex, nPoints);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_base): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(bitmap_ref, d_bitmap_ref, nPoints*sizeof(int), cudaMemcpyDeviceToHost);\n\n  \n\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    pnpoly_opt<1><<<grid, threads>>>(d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<1>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    pnpoly_opt<2><<<grid, threads>>>(d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<2>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    pnpoly_opt<4><<<grid, threads>>>(d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<4>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    pnpoly_opt<8><<<grid, threads>>>(d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<8>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    pnpoly_opt<16><<<grid, threads>>>(d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<16>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    pnpoly_opt<32><<<grid, threads>>>(d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<32>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    pnpoly_opt<64><<<grid, threads>>>(d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<64>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(bitmap_opt, d_bitmap_opt, nPoints*sizeof(int), cudaMemcpyDeviceToHost);\n\n  \n\n  int error = memcmp(bitmap_opt, bitmap_ref, nPoints*sizeof(int)); \n  \n  \n\n  int checksum = 0;\n  for (int i = 0; i < nPoints; i++) checksum += bitmap_opt[i];\n  printf(\"Checksum: %d\\n\", checksum);\n\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  cudaFree(d_vertex);\n  cudaFree(d_point);\n  cudaFree(d_bitmap_ref);\n  cudaFree(d_bitmap_opt);\n\n  free(vertex);\n  free(point);\n  free(bitmap_ref);\n  free(bitmap_opt);\n  return 0;\n}\n"}}
{"kernel_name": "pnpoly", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <random>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define VERTICES 600\n#define BLOCK_SIZE_X 256\n\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: ./%s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int nPoints = 2e7;\n  const int vertices = VERTICES;\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float2 *point = (float2*) malloc (sizeof(float2) * nPoints);\n  for (int i = 0; i < nPoints; i++) {\n    point[i].x = distribution(rng);\n    point[i].y = distribution(rng);\n  }\n\n  float2 *vertex = (float2*) malloc (vertices * sizeof(float2));\n  for (int i = 0; i < vertices; i++) {\n    float t = distribution(rng) * 2.f * M_PI;\n    vertex[i].x = cosf(t);\n    vertex[i].y = sinf(t);\n  }\n\n  \n\n  int *bitmap_ref = (int*) malloc (nPoints * sizeof(int));\n  int *bitmap_opt = (int*) malloc (nPoints * sizeof(int));\n\n  float2 *d_point;\n  float2 *d_vertex;\n  int *d_bitmap_ref, *d_bitmap_opt;\n\n  hipMalloc(&d_point, nPoints*sizeof(float2));\n  hipMalloc(&d_vertex, vertices*sizeof(float2));\n  hipMalloc(&d_bitmap_ref, nPoints*sizeof(int));\n  hipMalloc(&d_bitmap_opt, nPoints*sizeof(int));\n\n  \n\n  dim3 threads (BLOCK_SIZE_X);\n  dim3 grid ((nPoints+BLOCK_SIZE_X-1)/BLOCK_SIZE_X);\n\n  hipMemcpy(d_point, point, nPoints*sizeof(float2), hipMemcpyHostToDevice);\n  hipMemcpy(d_vertex, vertex, vertices*sizeof(float2), hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(pnpoly_base, grid, threads, 0, 0, d_bitmap_ref, d_point, d_vertex, nPoints);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_base): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(bitmap_ref, d_bitmap_ref, nPoints*sizeof(int), hipMemcpyDeviceToHost);\n\n  \n\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(pnpoly_opt<1>), grid, threads, 0, 0, d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<1>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(pnpoly_opt<2>), grid, threads, 0, 0, d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<2>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(pnpoly_opt<4>), grid, threads, 0, 0, d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<4>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(pnpoly_opt<8>), grid, threads, 0, 0, d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<8>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(pnpoly_opt<16>), grid, threads, 0, 0, d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<16>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(pnpoly_opt<32>), grid, threads, 0, 0, d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<32>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(pnpoly_opt<64>), grid, threads, 0, 0, d_bitmap_opt, d_point, d_vertex, nPoints);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<64>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(bitmap_opt, d_bitmap_opt, nPoints*sizeof(int), hipMemcpyDeviceToHost);\n\n  \n\n  int error = memcmp(bitmap_opt, bitmap_ref, nPoints*sizeof(int)); \n  \n  \n\n  int checksum = 0;\n  for (int i = 0; i < nPoints; i++) checksum += bitmap_opt[i];\n  printf(\"Checksum: %d\\n\", checksum);\n\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  hipFree(d_vertex);\n  hipFree(d_point);\n  hipFree(d_bitmap_ref);\n  hipFree(d_bitmap_opt);\n\n  free(vertex);\n  free(point);\n  free(bitmap_ref);\n  free(bitmap_opt);\n  return 0;\n}\n"}}
{"kernel_name": "pnpoly", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <random>\n#include <chrono>\n#include <omp.h>\n\n#define VERTICES 600\n#define BLOCK_SIZE_X 256\n\ntypedef struct __attribute__((__aligned__(8)))\n{\n  float x, y;\n} float2;\n\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: ./%s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int nPoints = 2e7;\n  const int vertices = VERTICES;\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float2 *point = (float2*) malloc (sizeof(float2) * nPoints);\n  for (int i = 0; i < nPoints; i++) {\n    point[i].x = distribution(rng);\n    point[i].y = distribution(rng);\n  }\n\n  float2 *vertex = (float2*) malloc (vertices * sizeof(float2));\n  for (int i = 0; i < vertices; i++) {\n    float t = distribution(rng) * 2.f * M_PI;\n    vertex[i].x = cosf(t);\n    vertex[i].y = sinf(t);\n  }\n\n  \n\n  int *bitmap_ref = (int*) malloc (nPoints * sizeof(int));\n  int *bitmap_opt = (int*) malloc (nPoints * sizeof(int));\n\n  #pragma omp target data map (to: point[0:nPoints], \\\n                                  vertex[0:vertices]) \\\n                         map (from: bitmap_ref[0:nPoints], \\\n                                    bitmap_opt[0:nPoints])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_base(bitmap_ref, point, vertex, nPoints);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_base): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    \n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<1>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<1>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<2>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<2>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<4>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<4>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<8>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<8>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<16>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<16>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<32>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<32>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<64>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<64>): %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  int error = memcmp(bitmap_opt, bitmap_ref, nPoints*sizeof(int)); \n  \n  \n\n  int checksum = 0;\n  for (int i = 0; i < nPoints; i++) checksum += bitmap_opt[i];\n  printf(\"Checksum: %d\\n\", checksum);\n\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(vertex);\n  free(point);\n  free(bitmap_ref);\n  free(bitmap_opt);\n  return 0;\n}\n"}}
{"kernel_name": "pnpoly", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <random>\n#include <chrono>\n\n#define VERTICES 600\n#define BLOCK_SIZE_X 256\n\ntypedef struct __attribute__((__aligned__(8)))\n{\n  float x, y;\n} float2;\n\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: ./%s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int nPoints = 2e7;\n  const int vertices = VERTICES;\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float2 *point = (float2*) malloc (sizeof(float2) * nPoints);\n  for (int i = 0; i < nPoints; i++) {\n    point[i].x = distribution(rng);\n    point[i].y = distribution(rng);\n  }\n\n  float2 *vertex = (float2*) malloc (vertices * sizeof(float2));\n  for (int i = 0; i < vertices; i++) {\n    float t = distribution(rng) * 2.f * M_PI;\n    vertex[i].x = cosf(t);\n    vertex[i].y = sinf(t);\n  }\n\n  \n\n  int *bitmap_ref = (int*) malloc (nPoints * sizeof(int));\n  int *bitmap_opt = (int*) malloc (nPoints * sizeof(int));\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_base(bitmap_ref, point, vertex, nPoints);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_base): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    \n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<1>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<1>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<2>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<2>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<4>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<4>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<8>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<8>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<16>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<16>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<32>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<32>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      pnpoly_opt<64>(bitmap_opt, point, vertex, nPoints);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (pnpoly_opt<64>): %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  int error = memcmp(bitmap_opt, bitmap_ref, nPoints*sizeof(int)); \n  \n  \n\n  int checksum = 0;\n  for (int i = 0; i < nPoints; i++) checksum += bitmap_opt[i];\n  printf(\"Checksum: %d\\n\", checksum);\n\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(vertex);\n  free(point);\n  free(bitmap_ref);\n  free(bitmap_opt);\n  return 0;\n}"}}
{"kernel_name": "pnpoly", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <random>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define VERTICES 600\n#define BLOCK_SIZE_X 256\n\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: ./%s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int nPoints = 2e7;\n  const int vertices = VERTICES;\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float2 *point = (float2*) malloc (sizeof(float2) * nPoints);\n  for (int i = 0; i < nPoints; i++) {\n    point[i].x() = distribution(rng);\n    point[i].y() = distribution(rng);\n  }\n\n  float2 *vertex = (float2*) malloc (vertices * sizeof(float2));\n  for (int i = 0; i < vertices; i++) {\n    float t = distribution(rng) * 2.f * M_PI;\n    vertex[i].x() = cosf(t);\n    vertex[i].y() = sinf(t);\n  }\n\n  \n\n  int *bitmap_ref = (int*) malloc (nPoints * sizeof(int));\n  int *bitmap_opt = (int*) malloc (nPoints * sizeof(int));\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float2 *d_point = sycl::malloc_device<float2>(nPoints, q);\n  float2 *d_vertex = sycl::malloc_device<float2>(vertices, q);\n  q.memcpy(d_point, point, nPoints*sizeof(float2));\n  q.memcpy(d_vertex, vertex, vertices*sizeof(float2));\n\n  int *d_bitmap_ref = sycl::malloc_device<int>(nPoints, q);\n  int *d_bitmap_opt = sycl::malloc_device<int>(nPoints, q);\n\n  \n\n  sycl::range<1> lws (BLOCK_SIZE_X);\n  sycl::range<1> gws ((nPoints+BLOCK_SIZE_X-1) / BLOCK_SIZE_X * BLOCK_SIZE_X);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class reference>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        pnpoly_base(item, d_bitmap_ref, d_point, d_vertex, nPoints);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_base): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(bitmap_ref, d_bitmap_ref, nPoints*sizeof(int)).wait();\n\n  \n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class opt1>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        pnpoly_opt<1>(item, d_bitmap_opt, d_point, d_vertex, nPoints);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<1>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class opt2>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        pnpoly_opt<2>(item, d_bitmap_opt, d_point, d_vertex, nPoints);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<2>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class opt3>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        pnpoly_opt<4>(item, d_bitmap_opt, d_point, d_vertex, nPoints);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<4>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class opt4>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        pnpoly_opt<8>(item, d_bitmap_opt, d_point, d_vertex, nPoints);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<8>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class opt5>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        pnpoly_opt<16>(item, d_bitmap_opt, d_point, d_vertex, nPoints);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<16>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class opt6>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        pnpoly_opt<32>(item, d_bitmap_opt, d_point, d_vertex, nPoints);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<32>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class opt7>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        pnpoly_opt<64>(item, d_bitmap_opt, d_point, d_vertex, nPoints);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pnpoly_opt<64>): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(bitmap_opt, d_bitmap_opt, nPoints*sizeof(int)).wait();\n\n  \n\n  int error = memcmp(bitmap_opt, bitmap_ref, nPoints*sizeof(int)); \n\n  \n\n  int checksum = 0;\n  for (int i = 0; i < nPoints; i++) checksum += bitmap_opt[i];\n  printf(\"Checksum: %d\\n\", checksum);\n\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  sycl::free(d_vertex, q);\n  sycl::free(d_point, q);\n  sycl::free(d_bitmap_ref, q);\n  sycl::free(d_bitmap_opt, q);\n\n  free(vertex);\n  free(point);\n  free(bitmap_ref);\n  free(bitmap_opt);\n  return 0;\n}\n"}}
{"kernel_name": "pool", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n#include <cuda.h>\n\n#define HOSTDEVICE __host__ __device__\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    HOSTDEVICE inline void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    HOSTDEVICE inline void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\ntemplate <typename PoolProcess, typename T,\n          int ksize_height,\n          int ksize_width,\n          int stride_height,\n          int stride_width,\n          int padding_height,\n          int padding_width,\n          bool exclusive>\n__global__ void KernelPool2DGrad(\n    const int nthreads,\n    const T*__restrict__ input_data,\n    const T*__restrict__ output_data,\n    const T*__restrict__ output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    PoolProcess pool_process,\n    T*__restrict__ input_grad,\n    bool channel_last = false)\n{\n  for (int index = blockIdx.x * blockDim.x + threadIdx.x; index < nthreads;\n           index += blockDim.x * gridDim.x) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = min(h_offset / stride_height + 1, output_height);\n    pwend = min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict__ output_data_t = output_data + output_stride;\n    const T *__restrict__ output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = min(hstart + ksize_height, input_height);\n        int wend = min(wstart + ksize_width, input_width);\n        hstart = max(hstart, 0);\n        wstart = max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 1;\n  const int padding_width = 1;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n  float *input_data, *output_data, *output_grad_data, *input_grad_data;\n  cudaMalloc((void **)&input_data, input_numel * sizeof(float));\n  cudaMalloc((void **)&input_grad_data, input_numel * sizeof(float));\n  cudaMalloc((void **)&output_data, output_numel * sizeof(float));\n  cudaMalloc((void **)&output_grad_data, output_numel * sizeof(float));\n  cudaMemcpy(input_data, input, input_numel * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(output_data, output, output_numel * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(output_grad_data, output_grad, output_numel * sizeof(float), cudaMemcpyHostToDevice);\n\n  int blocks = (nthreads + BSIZE - 1) / BSIZE;\n  dim3 threads(BSIZE);\n  dim3 grid(blocks);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    KernelPool2DGrad<AvgPoolGrad<float>, float, ksize_height, ksize_width,\n                     stride_height, stride_width, padding_height, padding_width,\n                     exclusive><<<grid, threads, 0, 0>>>(\n        nthreads, input_data, output_data, output_grad_data, input_channels,\n        input_height, input_width, output_height, output_width, pool_process,\n        input_grad_data, channel_last);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(input_grad, input_grad_data, input_numel * sizeof(float), cudaMemcpyDeviceToHost);\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  cudaFree(input_data);\n  cudaFree(input_grad_data);\n  cudaFree(output_data);\n  cudaFree(output_grad_data);\n  return 0;\n}\n"}}
{"kernel_name": "pool", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n#include <hip/hip_runtime.h>\n\n#define HOSTDEVICE __host__ __device__\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    HOSTDEVICE inline void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    HOSTDEVICE inline void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\ntemplate <typename PoolProcess, typename T,\n          int ksize_height,\n          int ksize_width,\n          int stride_height,\n          int stride_width,\n          int padding_height,\n          int padding_width,\n          bool exclusive>\n__global__ void KernelPool2DGrad(\n    const int nthreads,\n    const T*__restrict__ input_data,\n    const T*__restrict__ output_data,\n    const T*__restrict__ output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    PoolProcess pool_process,\n    T*__restrict__ input_grad,\n    bool channel_last = false)\n{\n  for (int index = blockIdx.x * blockDim.x + threadIdx.x; index < nthreads;\n           index += blockDim.x * gridDim.x) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = min(h_offset / stride_height + 1, output_height);\n    pwend = min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict__ output_data_t = output_data + output_stride;\n    const T *__restrict__ output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = min(hstart + ksize_height, input_height);\n        int wend = min(wstart + ksize_width, input_width);\n        hstart = max(hstart, 0);\n        wstart = max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 1;\n  const int padding_width = 1;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n  float *input_data, *output_data, *output_grad_data, *input_grad_data;\n  hipMalloc((void **)&input_data, input_numel * sizeof(float));\n  hipMalloc((void **)&input_grad_data, input_numel * sizeof(float));\n  hipMalloc((void **)&output_data, output_numel * sizeof(float));\n  hipMalloc((void **)&output_grad_data, output_numel * sizeof(float));\n  hipMemcpy(input_data, input, input_numel * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(output_data, output, output_numel * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(output_grad_data, output_grad, output_numel * sizeof(float), hipMemcpyHostToDevice);\n\n  int blocks = (nthreads + BSIZE - 1) / BSIZE;\n  dim3 threads(BSIZE);\n  dim3 grid(blocks);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    KernelPool2DGrad<AvgPoolGrad<float>, float, ksize_height, ksize_width,\n                     stride_height, stride_width, padding_height, padding_width,\n                     exclusive><<<grid, threads, 0, 0>>>(\n        nthreads, input_data, output_data, output_grad_data, input_channels,\n        input_height, input_width, output_height, output_width, pool_process,\n        input_grad_data, channel_last);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(input_grad, input_grad_data, input_numel * sizeof(float), hipMemcpyDeviceToHost);\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  hipFree(input_data);\n  hipFree(input_grad_data);\n  hipFree(output_data);\n  hipFree(output_grad_data);\n  return 0;\n}\n"}}
{"kernel_name": "pool", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n#include <omp.h>\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\ntemplate <typename PoolProcess, typename T>\nvoid KernelPool2DGrad(\n    const int nthreads,\n    const T*__restrict input_data,\n    const T*__restrict output_data,\n    const T*__restrict output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    const int ksize_height,\n    const int ksize_width,\n    const int stride_height,\n    const int stride_width,\n    const int padding_height,\n    const int padding_width,\n    PoolProcess pool_process,\n    bool exclusive,\n    T*__restrict input_grad,\n    bool channel_last = false)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BSIZE)\n  for (int index = 0; index < nthreads; index ++) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = std::min(h_offset / stride_height + 1, output_height);\n    pwend = std::min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict output_data_t = output_data + output_stride;\n    const T *__restrict output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = std::min(hstart + ksize_height, input_height);\n        int wend = std::min(wstart + ksize_width, input_width);\n        hstart = std::max(hstart, 0);\n        wstart = std::max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 1;\n  const int padding_width = 1;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n  #pragma omp target data map(to: input[0:input_numel], \\\n                                  output[0:output_numel],\\\n                                  output_grad[0:output_numel]) \\\n                          map(from: input_grad[0:input_numel])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      KernelPool2DGrad<AvgPoolGrad<float>, float>(\n        nthreads, input, output, output_grad, input_channels,\n        input_height, input_width, output_height, output_width, ksize_height,\n        ksize_width, stride_height, stride_width, padding_height, padding_width,\n        pool_process, exclusive, input_grad, channel_last);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  return 0;\n}\n"}}
{"kernel_name": "pool", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\ntemplate <typename PoolProcess, typename T>\nvoid KernelPool2DGrad(\n    const int nthreads,\n    const T*__restrict input_data,\n    const T*__restrict output_data,\n    const T*__restrict output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    const int ksize_height,\n    const int ksize_width,\n    const int stride_height,\n    const int stride_width,\n    const int padding_height,\n    const int padding_width,\n    PoolProcess pool_process,\n    bool exclusive,\n    T*__restrict input_grad,\n    bool channel_last = false)\n{\n    for (int index = 0; index < nthreads; index ++) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = std::min(h_offset / stride_height + 1, output_height);\n    pwend = std::min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict output_data_t = output_data + output_stride;\n    const T *__restrict output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = std::min(hstart + ksize_height, input_height);\n        int wend = std::min(wstart + ksize_width, input_width);\n        hstart = std::max(hstart, 0);\n        wstart = std::max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 1;\n  const int padding_width = 1;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      KernelPool2DGrad<AvgPoolGrad<float>, float>(\n        nthreads, input, output, output_grad, input_channels,\n        input_height, input_width, output_height, output_width, ksize_height,\n        ksize_width, stride_height, stride_width, padding_height, padding_width,\n        pool_process, exclusive, input_grad, channel_last);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  return 0;\n}"}}
{"kernel_name": "pool", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n#include <sycl/sycl.hpp>\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\n\n\ntemplate <typename T>\nclass k;\n\ntemplate <typename T>\nclass k_warmup;\n\ntemplate <typename PoolProcess, typename T>\nvoid KernelPool2DGrad(\n    sycl::nd_item<1> &item,\n    const int nthreads,\n    const T*__restrict input_data,\n    const T*__restrict output_data,\n    const T*__restrict output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    const int ksize_height,\n    const int ksize_width,\n    const int stride_height,\n    const int stride_width,\n    const int padding_height,\n    const int padding_width,\n    PoolProcess pool_process,\n    bool exclusive,\n    T*__restrict input_grad,\n    bool channel_last = false)\n{\n  for (int index = item.get_global_id(0); index < nthreads;\n           index += item.get_group_range(0) * item.get_local_range(0)) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = sycl::min(h_offset / stride_height + 1, output_height);\n    pwend = sycl::min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict output_data_t = output_data + output_stride;\n    const T *__restrict output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = sycl::min(hstart + ksize_height, input_height);\n        int wend = sycl::min(wstart + ksize_width, input_width);\n        hstart = sycl::max(hstart, 0);\n        wstart = sycl::max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 0;\n  const int padding_width = 0;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n    input_grad_ref[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_input = sycl::malloc_device<float>(input_numel, q);\n  float *d_input_grad = sycl::malloc_device<float>(input_numel, q);\n  float *d_output = sycl::malloc_device<float>(output_numel, q);\n  float *d_output_grad = sycl::malloc_device<float>(output_numel, q);\n  q.memcpy(d_input, input, input_numel * sizeof(float));\n  q.memcpy(d_output, output, output_numel * sizeof(float));\n  q.memcpy(d_output_grad, output_grad, output_numel * sizeof(float));\n\n  int blocks = (nthreads + BSIZE - 1) / BSIZE;\n  sycl::range<1> gws (blocks * BSIZE);\n  sycl::range<1> lws (BSIZE);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k<float>>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        KernelPool2DGrad<AvgPoolGrad<float>, float>(\n          item, nthreads, d_input, d_output, d_output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, d_input_grad, channel_last);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(input_grad, d_input_grad, input_numel * sizeof(float)).wait();\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  sycl::free(d_input, q);\n  sycl::free(d_input_grad, q);\n  sycl::free(d_output, q);\n  sycl::free(d_output_grad, q);\n  return 0;\n}\n"}}
{"kernel_name": "qem", "parallel_api": "cuda", "code": {"gpu_solver.cu": "#include <algorithm>\n#include <cuda.h>\n#include <stdio.h>\n\n\n\n\n\ncudaError_t checkCuda(cudaError_t result) {\n#if defined(DEBUG) || defined(_DEBUG)\n  if (result != cudaSuccess) {\n    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n  }\n#endif\n  return result;\n}\n\n__global__ void QRdel(int n, const float *A, const float *B, const float *C,\n                      const float *D, float *__restrict__ b,\n                      float *__restrict__ c, float *__restrict__ d,\n                      float *__restrict__ Q, float *__restrict__ R,\n                      float *__restrict__ Qint, float *__restrict__ Rint,\n                      float *__restrict__ del) {\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) {\n\n    b[i] = 0.75f * (B[i] / A[i]);\n    c[i] = 0.50f * (C[i] / A[i]);\n    d[i] = 0.25f * (D[i] / A[i]);\n\n    Q[i] = (c[i] / 3.f) - ((b[i] * b[i]) / 9.f);\n    R[i] = (b[i] * c[i]) / 6.f - (b[i] * b[i] * b[i]) / 27.f - 0.5f * d[i];\n\n    \n\n    Q[i] = roundf(Q[i] * 1E5f) / 1E5f;\n    R[i] = roundf(R[i] * 1E5f) / 1E5f;\n\n    Qint[i] = (Q[i] * Q[i] * Q[i]);\n    Rint[i] = (R[i] * R[i]);\n\n    del[i] = Rint[i] + Qint[i];\n    \n\n    \n\n  }\n}\n\n__global__ void QuarticSolver(int n, const float *A, const float *B,\n                              const float *C, const float *D, const float *b,\n                              const float *Q, const float *R, const float *del,\n                              float *__restrict__ theta,\n                              float *__restrict__ sqrtQ, float *__restrict__ x1,\n                              float *__restrict__ x2, float *__restrict__ x3,\n                              float *__restrict__ temp,\n                              float *__restrict__ min) {\n  \n\n  \n\n\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) {\n    \n\n    \n\n    if (del[i] <= 1E-5f) { \n\n\n      \n\n\n      theta[i] = acosf((R[i] / sqrtf(-(Q[i] * Q[i] * Q[i]))));\n      sqrtQ[i] = 2.f * sqrtf(-Q[i]);\n\n      x1[i] = ((sqrtQ[i] * cosf((theta[i]) / 3.f)) - (b[i] / 3.f));\n      x2[i] = ((sqrtQ[i] * cosf((theta[i] + 2.f * 3.1415927f) / 3.f)) -\n               (b[i] / 3.f));\n      x3[i] = ((sqrtQ[i] * cosf((theta[i] + 4.f * 3.1415927f) / 3.f)) -\n               (b[i] / 3.f));\n\n      \n\n      if (x1[i] < x2[i]) {\n        temp[i] = x1[i];\n        x1[i] = x2[i];\n        x2[i] = temp[i];\n      } \n\n      if (x2[i] < x3[i]) {\n        temp[i] = x2[i];\n        x2[i] = x3[i];\n        x3[i] = temp[i];\n      } \n\n      if (x1[i] < x2[i]) {\n        temp[i] = x1[i];\n        x1[i] = x2[i];\n        x2[i] = temp[i];\n      } \n\n\n      min[i] =\n          A[i] *\n                          ((x1[i] * x1[i] * x1[i] * x1[i]) -\n                           (x3[i] * x3[i] * x3[i] * x3[i])) /\n                          4.f +\n                      B[i] *\n                          ((x1[i] * x1[i] * x1[i]) - (x3[i] * x3[i] * x3[i])) /\n                          3.f +\n                      C[i] * ((x1[i] * x1[i]) - (x3[i] * x3[i])) / 2.f +\n                      D[i] * (x1[i] - x3[i]) <=\n                  0.f\n              ? x1[i]\n              : x3[i];\n\n    }\n\n    \n\n    else {\n\n      \n\n\n      x1[i] = cbrtf((R[i] + sqrtf(del[i]))) + cbrtf((R[i] - sqrtf(del[i]))) -\n              (b[i] / 3.f); \n\n\n      \n\n\n      x2[i] = 0;\n      x3[i] = 0;\n\n      min[i] = x1[i];\n    }\n  }\n}\n\nvoid QuarticMinimumGPU(int N, float *A, float *B, float *C, float *D, float *E,\n                       float *min) {\n\n  float *d_A, *d_B, *d_C, *d_D, *d_E, *d_bi, *d_ci, *d_di, *d_theta, *d_sqrtQ,\n      *d_Q, *d_R, *d_Qint, *d_Rint, *d_del, *d_x1, *d_x2, *d_x3, *d_min,\n      *d_temp;\n\n  \n\n  const int block_dim = 64;\n\n  \n\n  checkCuda(cudaMalloc(&d_A, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_B, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_C, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_D, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_E, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_bi, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_ci, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_di, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_theta, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_sqrtQ, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_Q, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_R, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_Qint, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_Rint, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_del, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_x1, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_x2, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_x3, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_min, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_temp, N * sizeof(float)));\n\n  cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_C, C, N * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_D, D, N * sizeof(float), cudaMemcpyHostToDevice);\n\n  QRdel<<<(N + block_dim - 1) / block_dim, block_dim>>>(\n      N, d_A, d_B, d_C, d_D, d_bi, d_ci, d_di, d_Q, d_R, d_Qint, d_Rint, d_del);\n\n  QuarticSolver<<<(N + block_dim - 1) / block_dim, block_dim>>>(\n      N, d_A, d_B, d_C, d_D, d_bi, d_Q, d_R, d_del, d_theta, d_sqrtQ, d_x1,\n      d_x2, d_x3, d_temp, d_min);\n\n  cudaMemcpy(min, d_min, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n  checkCuda(cudaFree(d_A));\n  checkCuda(cudaFree(d_B));\n  checkCuda(cudaFree(d_C));\n  checkCuda(cudaFree(d_D));\n  checkCuda(cudaFree(d_E));\n\n  checkCuda(cudaFree(d_bi));\n  checkCuda(cudaFree(d_ci));\n  checkCuda(cudaFree(d_di));\n  checkCuda(cudaFree(d_theta));\n  checkCuda(cudaFree(d_sqrtQ));\n\n  checkCuda(cudaFree(d_Q));\n  checkCuda(cudaFree(d_R));\n  checkCuda(cudaFree(d_Qint));\n  checkCuda(cudaFree(d_Rint));\n  checkCuda(cudaFree(d_del));\n\n  checkCuda(cudaFree(d_x1));\n  checkCuda(cudaFree(d_x2));\n  checkCuda(cudaFree(d_x3));\n\n  checkCuda(cudaFree(d_min));\n  checkCuda(cudaFree(d_temp));\n}\n\nvoid QuarticMinimumGPUStreams(int N, float *A, float *B, float *C, float *D,\n                              float *E, float *min) {\n\n  float *d_A, *d_B, *d_C, *d_D, *d_E, *d_bi, *d_ci, *d_di, *d_theta, *d_sqrtQ,\n      *d_Q, *d_R, *d_Qint, *d_Rint, *d_del, *d_x1, *d_x2, *d_x3, *d_min,\n      *d_temp;\n\n  \n\n  const int block_dim = 64;\n\n  \n\n  const int nStreams = 4;\n  const int streamSize = N / nStreams;\n  const int streamBytes = streamSize * sizeof(float);\n\n  cudaStream_t stream[nStreams + 1];\n\n  for (int i = 0; i <= nStreams; ++i) {\n    checkCuda(cudaStreamCreate(&stream[i]));\n  }\n\n  int offset = 0;\n\n  \n\n  checkCuda(cudaMalloc(&d_A, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_B, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_C, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_D, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_E, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_bi, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_ci, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_di, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_theta, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_sqrtQ, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_Q, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_R, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_Qint, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_Rint, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_del, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_x1, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_x2, N * sizeof(float)));\n  checkCuda(cudaMalloc(&d_x3, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_min, N * sizeof(float)));\n\n  checkCuda(cudaMalloc(&d_temp, N * sizeof(float)));\n\n  for (int i = 0; i < nStreams; ++i) {\n    offset = i * streamSize;\n    cudaMemcpyAsync(&d_A[offset], &A[offset], streamBytes,\n                    cudaMemcpyHostToDevice, stream[i]);\n    cudaMemcpyAsync(&d_B[offset], &B[offset], streamBytes,\n                    cudaMemcpyHostToDevice, stream[i]);\n    cudaMemcpyAsync(&d_C[offset], &C[offset], streamBytes,\n                    cudaMemcpyHostToDevice, stream[i]);\n    cudaMemcpyAsync(&d_D[offset], &D[offset], streamBytes,\n                    cudaMemcpyHostToDevice, stream[i]);\n\n    QRdel<<<(streamSize + block_dim - 1) / block_dim, block_dim, 0,\n            stream[i]>>>(streamSize, &d_A[offset], &d_B[offset], &d_C[offset],\n                         &d_D[offset], &d_bi[offset], &d_ci[offset],\n                         &d_di[offset], &d_Q[offset], &d_R[offset],\n                         &d_Qint[offset], &d_Rint[offset], &d_del[offset]);\n\n    QuarticSolver<<<(streamSize + block_dim - 1) / block_dim, block_dim, 0,\n                    stream[i]>>>(\n        streamSize, &d_A[offset], &d_B[offset], &d_C[offset], &d_D[offset],\n        &d_bi[offset], &d_Q[offset], &d_R[offset], &d_del[offset],\n        &d_theta[offset], &d_sqrtQ[offset], &d_x1[offset], &d_x2[offset],\n        &d_x3[offset], &d_temp[offset], &d_min[offset]);\n\n    cudaMemcpyAsync(&min[offset], &d_min[offset], streamBytes,\n                    cudaMemcpyDeviceToHost, stream[i]);\n  }\n\n  const int resstreamSize = N % nStreams;\n  const int resstreamBytes = resstreamSize * sizeof(float);\n  if (resstreamSize != 0) {\n\n                           \n\n    offset = nStreams * streamSize;\n\n    cudaMemcpyAsync(&d_A[offset], &A[offset], resstreamBytes,\n                    cudaMemcpyHostToDevice, stream[nStreams]);\n    cudaMemcpyAsync(&d_B[offset], &B[offset], resstreamBytes,\n                    cudaMemcpyHostToDevice, stream[nStreams]);\n    cudaMemcpyAsync(&d_C[offset], &C[offset], resstreamBytes,\n                    cudaMemcpyHostToDevice, stream[nStreams]);\n    cudaMemcpyAsync(&d_D[offset], &D[offset], resstreamBytes,\n                    cudaMemcpyHostToDevice, stream[nStreams]);\n\n    QRdel<<<(resstreamSize + block_dim - 1) / block_dim, block_dim, 0,\n            stream[nStreams]>>>(\n        resstreamSize, &d_A[offset], &d_B[offset], &d_C[offset], &d_D[offset],\n        &d_bi[offset], &d_ci[offset], &d_di[offset], &d_Q[offset], &d_R[offset],\n        &d_Qint[offset], &d_Rint[offset], &d_del[offset]);\n\n    QuarticSolver<<<(resstreamSize + block_dim - 1) / block_dim, block_dim, 0,\n                    stream[nStreams]>>>(\n        resstreamSize, &d_A[offset], &d_B[offset], &d_C[offset], &d_D[offset],\n        &d_bi[offset], &d_Q[offset], &d_R[offset], &d_del[offset],\n        &d_theta[offset], &d_sqrtQ[offset], &d_x1[offset], &d_x2[offset],\n        &d_x3[offset], &d_temp[offset], &d_min[offset]);\n\n    cudaMemcpyAsync(&min[offset], &d_min[offset], resstreamBytes,\n                    cudaMemcpyDeviceToHost, stream[nStreams]);\n  }\n\n  cudaDeviceSynchronize();\n\n  checkCuda(cudaFree(d_A));\n  checkCuda(cudaFree(d_B));\n  checkCuda(cudaFree(d_C));\n  checkCuda(cudaFree(d_D));\n  checkCuda(cudaFree(d_E));\n\n  checkCuda(cudaFree(d_bi));\n  checkCuda(cudaFree(d_ci));\n  checkCuda(cudaFree(d_di));\n  checkCuda(cudaFree(d_theta));\n  checkCuda(cudaFree(d_sqrtQ));\n\n  checkCuda(cudaFree(d_Q));\n  checkCuda(cudaFree(d_R));\n  checkCuda(cudaFree(d_Qint));\n  checkCuda(cudaFree(d_Rint));\n  checkCuda(cudaFree(d_del));\n\n  checkCuda(cudaFree(d_x1));\n  checkCuda(cudaFree(d_x2));\n  checkCuda(cudaFree(d_x3));\n\n  checkCuda(cudaFree(d_min));\n  checkCuda(cudaFree(d_temp));\n\n  for (int i = 0; i <= nStreams; ++i) {\n    checkCuda(cudaStreamDestroy(stream[i]));\n  }\n}\n", "main.cu": "#include <algorithm>\n#include <chrono> \n\n#include <cstdio>\n#include <random>\n\n#include \"reference.h\"\n#include \"gpu_solver.h\"\n\nvoid generate_data(int size, int min, int max, float *data) {\n  std::mt19937_64 generator{1993764};\n  std::uniform_int_distribution<> dist{min, max};\n  for (int i = 0; i < size; ++i) {\n    data[i] = dist(generator);\n  }\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int repeat = atoi(argv[1]);\n\n  \n\n  int N = 1999999;\n  printf(\"N = %d\\n\", N);\n\n  float *A, *B, *C, *D, *E;\n  float *minimum_ref, *minimum;\n\n  checkCuda(cudaMallocHost((void **)&A, N * sizeof(float)));\n  checkCuda(cudaMallocHost((void **)&B, N * sizeof(float)));\n  checkCuda(cudaMallocHost((void **)&C, N * sizeof(float)));\n  checkCuda(cudaMallocHost((void **)&D, N * sizeof(float)));\n  checkCuda(cudaMallocHost((void **)&E, N * sizeof(float)));\n  checkCuda(cudaMallocHost((void **)&minimum_ref, N * sizeof(float)));\n  checkCuda(cudaMallocHost((void **)&minimum, N * sizeof(float)));\n\n  printf(\"generating data...\\n\");\n\n  generate_data(N, -100, 100, A);\n  generate_data(N, -100, 100, B);\n  generate_data(N, -100, 100, C);\n  generate_data(N, -100, 100, D);\n  generate_data(N, -100, 100, E);\n\n  for (int i = 0; i < N; i++) {\n    if (A[i] == 0) {\n      A[i] = 1;\n    } \n\n  }\n\n  float dur = 0;\n  float avg = 0;\n  bool ok;\n\n  printf(\"####################### Reference #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumCPU(N, A, B, C, D, E, minimum_ref);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n\n  avg = 0;\n\n  printf(\"####################### GPU (no streams) #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumGPU(N, A, B, C, D, E, minimum);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n\n  ok = true;\n  for (int i = 0; i < N; i++) {\n    if (fabsf(minimum[i] - minimum_ref[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  avg = 0;\n\n  printf(\"####################### GPU (streams) #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumGPUStreams(N, A, B, C, D, E, minimum);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n\n  ok = true;\n  for (int i = 0; i < N; i++) {\n    if (fabsf(minimum[i] - minimum_ref[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  checkCuda(cudaFreeHost(A));\n  checkCuda(cudaFreeHost(B));\n  checkCuda(cudaFreeHost(C));\n  checkCuda(cudaFreeHost(D));\n  checkCuda(cudaFreeHost(E));\n  checkCuda(cudaFreeHost(minimum_ref));\n  checkCuda(cudaFreeHost(minimum));\n\n  return 0;\n}\n"}}
{"kernel_name": "qem", "parallel_api": "hip", "code": {"gpu_solver.cu": "#include <algorithm>\n#include <stdio.h>\n#include <hip/hip_runtime.h>\n\n\n\n\n\nhipError_t checkHip(hipError_t result) {\n#if defined(DEBUG) || defined(_DEBUG)\n  if (result != hipSuccess) {\n    fprintf(stderr, \"HIP Runtime Error: %s\\n\", hipGetErrorString(result));\n  }\n#endif\n  return result;\n}\n\n__global__ void QRdel(int n, const float *A, const float *B, const float *C,\n                      const float *D, float *__restrict__ b,\n                      float *__restrict__ c, float *__restrict__ d,\n                      float *__restrict__ Q, float *__restrict__ R,\n                      float *__restrict__ Qint, float *__restrict__ Rint,\n                      float *__restrict__ del) {\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) {\n\n    b[i] = 0.75f * (B[i] / A[i]);\n    c[i] = 0.50f * (C[i] / A[i]);\n    d[i] = 0.25f * (D[i] / A[i]);\n\n    Q[i] = (c[i] / 3.f) - ((b[i] * b[i]) / 9.f);\n    R[i] = (b[i] * c[i]) / 6.f - (b[i] * b[i] * b[i]) / 27.f - 0.5f * d[i];\n\n    \n\n    Q[i] = roundf(Q[i] * 1E5f) / 1E5f;\n    R[i] = roundf(R[i] * 1E5f) / 1E5f;\n\n    Qint[i] = (Q[i] * Q[i] * Q[i]);\n    Rint[i] = (R[i] * R[i]);\n\n    del[i] = Rint[i] + Qint[i];\n    \n\n    \n\n  }\n}\n\n__global__ void QuarticSolver(int n, const float *A, const float *B,\n                              const float *C, const float *D, const float *b,\n                              const float *Q, const float *R, const float *del,\n                              float *__restrict__ theta,\n                              float *__restrict__ sqrtQ, float *__restrict__ x1,\n                              float *__restrict__ x2, float *__restrict__ x3,\n                              float *__restrict__ temp,\n                              float *__restrict__ min) {\n  \n\n  \n\n\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) {\n    \n\n    \n\n    if (del[i] <= 1E-5f) { \n\n\n      \n\n\n      theta[i] = acosf((R[i] / sqrtf(-(Q[i] * Q[i] * Q[i]))));\n      sqrtQ[i] = 2.f * sqrtf(-Q[i]);\n\n      x1[i] = ((sqrtQ[i] * cosf((theta[i]) / 3.f)) - (b[i] / 3.f));\n      x2[i] = ((sqrtQ[i] * cosf((theta[i] + 2.f * 3.1415927f) / 3.f)) -\n               (b[i] / 3.f));\n      x3[i] = ((sqrtQ[i] * cosf((theta[i] + 4.f * 3.1415927f) / 3.f)) -\n               (b[i] / 3.f));\n\n      \n\n      if (x1[i] < x2[i]) {\n        temp[i] = x1[i];\n        x1[i] = x2[i];\n        x2[i] = temp[i];\n      } \n\n      if (x2[i] < x3[i]) {\n        temp[i] = x2[i];\n        x2[i] = x3[i];\n        x3[i] = temp[i];\n      } \n\n      if (x1[i] < x2[i]) {\n        temp[i] = x1[i];\n        x1[i] = x2[i];\n        x2[i] = temp[i];\n      } \n\n\n      min[i] =\n          A[i] *\n                          ((x1[i] * x1[i] * x1[i] * x1[i]) -\n                           (x3[i] * x3[i] * x3[i] * x3[i])) /\n                          4.f +\n                      B[i] *\n                          ((x1[i] * x1[i] * x1[i]) - (x3[i] * x3[i] * x3[i])) /\n                          3.f +\n                      C[i] * ((x1[i] * x1[i]) - (x3[i] * x3[i])) / 2.f +\n                      D[i] * (x1[i] - x3[i]) <=\n                  0.f\n              ? x1[i]\n              : x3[i];\n\n    }\n\n    \n\n    else {\n\n      \n\n\n      x1[i] = cbrtf((R[i] + sqrtf(del[i]))) + cbrtf((R[i] - sqrtf(del[i]))) -\n              (b[i] / 3.f); \n\n\n      \n\n\n      x2[i] = 0;\n      x3[i] = 0;\n\n      min[i] = x1[i];\n    }\n  }\n}\n\nvoid QuarticMinimumGPU(int N, float *A, float *B, float *C, float *D, float *E,\n                       float *min) {\n\n  float *d_A, *d_B, *d_C, *d_D, *d_E, *d_bi, *d_ci, *d_di, *d_theta, *d_sqrtQ,\n      *d_Q, *d_R, *d_Qint, *d_Rint, *d_del, *d_x1, *d_x2, *d_x3, *d_min,\n      *d_temp;\n\n  \n\n  const int block_dim = 64;\n\n  \n\n  checkHip(hipMalloc(&d_A, N * sizeof(float)));\n  checkHip(hipMalloc(&d_B, N * sizeof(float)));\n  checkHip(hipMalloc(&d_C, N * sizeof(float)));\n  checkHip(hipMalloc(&d_D, N * sizeof(float)));\n  checkHip(hipMalloc(&d_E, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_bi, N * sizeof(float)));\n  checkHip(hipMalloc(&d_ci, N * sizeof(float)));\n  checkHip(hipMalloc(&d_di, N * sizeof(float)));\n  checkHip(hipMalloc(&d_theta, N * sizeof(float)));\n  checkHip(hipMalloc(&d_sqrtQ, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_Q, N * sizeof(float)));\n  checkHip(hipMalloc(&d_R, N * sizeof(float)));\n  checkHip(hipMalloc(&d_Qint, N * sizeof(float)));\n  checkHip(hipMalloc(&d_Rint, N * sizeof(float)));\n  checkHip(hipMalloc(&d_del, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_x1, N * sizeof(float)));\n  checkHip(hipMalloc(&d_x2, N * sizeof(float)));\n  checkHip(hipMalloc(&d_x3, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_min, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_temp, N * sizeof(float)));\n\n  hipMemcpy(d_A, A, N * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(d_B, B, N * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(d_C, C, N * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(d_D, D, N * sizeof(float), hipMemcpyHostToDevice);\n\n  QRdel<<<(N + block_dim - 1) / block_dim, block_dim>>>(\n      N, d_A, d_B, d_C, d_D, d_bi, d_ci, d_di, d_Q, d_R, d_Qint, d_Rint, d_del);\n\n  QuarticSolver<<<(N + block_dim - 1) / block_dim, block_dim>>>(\n      N, d_A, d_B, d_C, d_D, d_bi, d_Q, d_R, d_del, d_theta, d_sqrtQ, d_x1,\n      d_x2, d_x3, d_temp, d_min);\n\n  hipMemcpy(min, d_min, N * sizeof(float), hipMemcpyDeviceToHost);\n\n  checkHip(hipFree(d_A));\n  checkHip(hipFree(d_B));\n  checkHip(hipFree(d_C));\n  checkHip(hipFree(d_D));\n  checkHip(hipFree(d_E));\n\n  checkHip(hipFree(d_bi));\n  checkHip(hipFree(d_ci));\n  checkHip(hipFree(d_di));\n  checkHip(hipFree(d_theta));\n  checkHip(hipFree(d_sqrtQ));\n\n  checkHip(hipFree(d_Q));\n  checkHip(hipFree(d_R));\n  checkHip(hipFree(d_Qint));\n  checkHip(hipFree(d_Rint));\n  checkHip(hipFree(d_del));\n\n  checkHip(hipFree(d_x1));\n  checkHip(hipFree(d_x2));\n  checkHip(hipFree(d_x3));\n\n  checkHip(hipFree(d_min));\n  checkHip(hipFree(d_temp));\n}\n\nvoid QuarticMinimumGPUStreams(int N, float *A, float *B, float *C, float *D,\n                              float *E, float *min) {\n\n  float *d_A, *d_B, *d_C, *d_D, *d_E, *d_bi, *d_ci, *d_di, *d_theta, *d_sqrtQ,\n      *d_Q, *d_R, *d_Qint, *d_Rint, *d_del, *d_x1, *d_x2, *d_x3, *d_min,\n      *d_temp;\n\n  \n\n  const int block_dim = 64;\n\n  \n\n  const int nStreams = 4;\n  const int streamSize = N / nStreams;\n  const int streamBytes = streamSize * sizeof(float);\n\n  hipStream_t stream[nStreams + 1];\n\n  for (int i = 0; i <= nStreams; ++i) {\n    checkHip(hipStreamCreate(&stream[i]));\n  }\n\n  int offset = 0;\n\n  \n\n  checkHip(hipMalloc(&d_A, N * sizeof(float)));\n  checkHip(hipMalloc(&d_B, N * sizeof(float)));\n  checkHip(hipMalloc(&d_C, N * sizeof(float)));\n  checkHip(hipMalloc(&d_D, N * sizeof(float)));\n  checkHip(hipMalloc(&d_E, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_bi, N * sizeof(float)));\n  checkHip(hipMalloc(&d_ci, N * sizeof(float)));\n  checkHip(hipMalloc(&d_di, N * sizeof(float)));\n  checkHip(hipMalloc(&d_theta, N * sizeof(float)));\n  checkHip(hipMalloc(&d_sqrtQ, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_Q, N * sizeof(float)));\n  checkHip(hipMalloc(&d_R, N * sizeof(float)));\n  checkHip(hipMalloc(&d_Qint, N * sizeof(float)));\n  checkHip(hipMalloc(&d_Rint, N * sizeof(float)));\n  checkHip(hipMalloc(&d_del, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_x1, N * sizeof(float)));\n  checkHip(hipMalloc(&d_x2, N * sizeof(float)));\n  checkHip(hipMalloc(&d_x3, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_min, N * sizeof(float)));\n\n  checkHip(hipMalloc(&d_temp, N * sizeof(float)));\n\n  for (int i = 0; i < nStreams; ++i) {\n    offset = i * streamSize;\n    hipMemcpyAsync(&d_A[offset], &A[offset], streamBytes,\n                    hipMemcpyHostToDevice, stream[i]);\n    hipMemcpyAsync(&d_B[offset], &B[offset], streamBytes,\n                    hipMemcpyHostToDevice, stream[i]);\n    hipMemcpyAsync(&d_C[offset], &C[offset], streamBytes,\n                    hipMemcpyHostToDevice, stream[i]);\n    hipMemcpyAsync(&d_D[offset], &D[offset], streamBytes,\n                    hipMemcpyHostToDevice, stream[i]);\n\n    QRdel<<<(streamSize + block_dim - 1) / block_dim, block_dim, 0,\n            stream[i]>>>(streamSize, &d_A[offset], &d_B[offset], &d_C[offset],\n                         &d_D[offset], &d_bi[offset], &d_ci[offset],\n                         &d_di[offset], &d_Q[offset], &d_R[offset],\n                         &d_Qint[offset], &d_Rint[offset], &d_del[offset]);\n\n    QuarticSolver<<<(streamSize + block_dim - 1) / block_dim, block_dim, 0,\n                    stream[i]>>>(\n        streamSize, &d_A[offset], &d_B[offset], &d_C[offset], &d_D[offset],\n        &d_bi[offset], &d_Q[offset], &d_R[offset], &d_del[offset],\n        &d_theta[offset], &d_sqrtQ[offset], &d_x1[offset], &d_x2[offset],\n        &d_x3[offset], &d_temp[offset], &d_min[offset]);\n\n    hipMemcpyAsync(&min[offset], &d_min[offset], streamBytes,\n                    hipMemcpyDeviceToHost, stream[i]);\n  }\n\n  const int resstreamSize = N % nStreams;\n  const int resstreamBytes = resstreamSize * sizeof(float);\n  if (resstreamSize != 0) {\n\n                           \n\n    offset = nStreams * streamSize;\n\n    hipMemcpyAsync(&d_A[offset], &A[offset], resstreamBytes,\n                    hipMemcpyHostToDevice, stream[nStreams]);\n    hipMemcpyAsync(&d_B[offset], &B[offset], resstreamBytes,\n                    hipMemcpyHostToDevice, stream[nStreams]);\n    hipMemcpyAsync(&d_C[offset], &C[offset], resstreamBytes,\n                    hipMemcpyHostToDevice, stream[nStreams]);\n    hipMemcpyAsync(&d_D[offset], &D[offset], resstreamBytes,\n                    hipMemcpyHostToDevice, stream[nStreams]);\n\n    QRdel<<<(resstreamSize + block_dim - 1) / block_dim, block_dim, 0,\n            stream[nStreams]>>>(\n        resstreamSize, &d_A[offset], &d_B[offset], &d_C[offset], &d_D[offset],\n        &d_bi[offset], &d_ci[offset], &d_di[offset], &d_Q[offset], &d_R[offset],\n        &d_Qint[offset], &d_Rint[offset], &d_del[offset]);\n\n    QuarticSolver<<<(resstreamSize + block_dim - 1) / block_dim, block_dim, 0,\n                    stream[nStreams]>>>(\n        resstreamSize, &d_A[offset], &d_B[offset], &d_C[offset], &d_D[offset],\n        &d_bi[offset], &d_Q[offset], &d_R[offset], &d_del[offset],\n        &d_theta[offset], &d_sqrtQ[offset], &d_x1[offset], &d_x2[offset],\n        &d_x3[offset], &d_temp[offset], &d_min[offset]);\n\n    hipMemcpyAsync(&min[offset], &d_min[offset], resstreamBytes,\n                    hipMemcpyDeviceToHost, stream[nStreams]);\n  }\n\n  hipDeviceSynchronize();\n\n  checkHip(hipFree(d_A));\n  checkHip(hipFree(d_B));\n  checkHip(hipFree(d_C));\n  checkHip(hipFree(d_D));\n  checkHip(hipFree(d_E));\n\n  checkHip(hipFree(d_bi));\n  checkHip(hipFree(d_ci));\n  checkHip(hipFree(d_di));\n  checkHip(hipFree(d_theta));\n  checkHip(hipFree(d_sqrtQ));\n\n  checkHip(hipFree(d_Q));\n  checkHip(hipFree(d_R));\n  checkHip(hipFree(d_Qint));\n  checkHip(hipFree(d_Rint));\n  checkHip(hipFree(d_del));\n\n  checkHip(hipFree(d_x1));\n  checkHip(hipFree(d_x2));\n  checkHip(hipFree(d_x3));\n\n  checkHip(hipFree(d_min));\n  checkHip(hipFree(d_temp));\n\n  for (int i = 0; i <= nStreams; ++i) {\n    checkHip(hipStreamDestroy(stream[i]));\n  }\n}\n", "main.cu": "#include <algorithm>\n#include <chrono> \n\n#include <cstdio>\n#include <random>\n\n#include \"reference.h\"\n#include \"gpu_solver.h\"\n\nvoid generate_data(int size, int min, int max, float *data) {\n  std::mt19937_64 generator{1993764};\n  std::uniform_int_distribution<> dist{min, max};\n  for (int i = 0; i < size; ++i) {\n    data[i] = dist(generator);\n  }\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int repeat = atoi(argv[1]);\n\n  \n\n  int N = 1999999;\n  printf(\"N = %d\\n\", N);\n\n  float *A, *B, *C, *D, *E;\n  float *minimum_ref, *minimum;\n\n  checkHip(hipHostMalloc((void **)&A, N * sizeof(float)));\n  checkHip(hipHostMalloc((void **)&B, N * sizeof(float)));\n  checkHip(hipHostMalloc((void **)&C, N * sizeof(float)));\n  checkHip(hipHostMalloc((void **)&D, N * sizeof(float)));\n  checkHip(hipHostMalloc((void **)&E, N * sizeof(float)));\n  checkHip(hipHostMalloc((void **)&minimum_ref, N * sizeof(float)));\n  checkHip(hipHostMalloc((void **)&minimum, N * sizeof(float)));\n\n  printf(\"generating data...\\n\");\n\n  generate_data(N, -100, 100, A);\n  generate_data(N, -100, 100, B);\n  generate_data(N, -100, 100, C);\n  generate_data(N, -100, 100, D);\n  generate_data(N, -100, 100, E);\n\n  for (int i = 0; i < N; i++) {\n    if (A[i] == 0) {\n      A[i] = 1;\n    } \n\n  }\n\n  float dur = 0;\n  float avg = 0;\n  bool ok;\n\n  printf(\"####################### Reference #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumCPU(N, A, B, C, D, E, minimum_ref);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n\n  avg = 0;\n\n  printf(\"####################### GPU (no streams) #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumGPU(N, A, B, C, D, E, minimum);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n\n  ok = true;\n  for (int i = 0; i < N; i++) {\n    if (fabsf(minimum[i] - minimum_ref[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  avg = 0;\n\n  printf(\"####################### GPU (streams) #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumGPUStreams(N, A, B, C, D, E, minimum);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n  ok = true;\n  for (int i = 0; i < N; i++) {\n    if (fabsf(minimum[i] - minimum_ref[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  checkHip(hipHostFree(A));\n  checkHip(hipHostFree(B));\n  checkHip(hipHostFree(C));\n  checkHip(hipHostFree(D));\n  checkHip(hipHostFree(E));\n  checkHip(hipHostFree(minimum));\n  checkHip(hipHostFree(minimum_ref));\n\n  return 0;\n}\n"}}
{"kernel_name": "qem", "parallel_api": "sycl", "code": {"gpu_solver.cpp": "#include <algorithm>\n#include <stdio.h>\n#include <sycl/sycl.hpp>\n\nvoid QRdel(int n, const float *A, const float *B, const float *C,\n           const float *D, float *__restrict__ b, float *__restrict__ c,\n           float *__restrict__ d, float *__restrict__ Q, float *__restrict__ R,\n           float *__restrict__ Qint, float *__restrict__ Rint,\n           float *__restrict__ del, const sycl::nd_item<1> &item) {\n  int i = item.get_global_id(0);\n  if (i < n) {\n\n    b[i] = 0.75f * (B[i] / A[i]);\n    c[i] = 0.50f * (C[i] / A[i]);\n    d[i] = 0.25f * (D[i] / A[i]);\n\n    Q[i] = (c[i] / 3.f) - ((b[i] * b[i]) / 9.f);\n    R[i] = (b[i] * c[i]) / 6.f - (b[i] * b[i] * b[i]) / 27.f - 0.5f * d[i];\n\n    \n\n    Q[i] = sycl::round(Q[i] * 1E5f) / 1E5f;\n    R[i] = sycl::round(R[i] * 1E5f) / 1E5f;\n\n    Qint[i] = (Q[i] * Q[i] * Q[i]);\n    Rint[i] = (R[i] * R[i]);\n\n    del[i] = Rint[i] + Qint[i];\n    \n\n    \n\n  }\n}\n\nvoid QuarticSolver(int n, const float *A, const float *B, const float *C,\n                   const float *D, const float *b, const float *Q,\n                   const float *R, const float *del, float *__restrict__ theta,\n                   float *__restrict__ sqrtQ, float *__restrict__ x1,\n                   float *__restrict__ x2, float *__restrict__ x3,\n                   float *__restrict__ temp, float *__restrict__ min,\n                   const sycl::nd_item<1> &item) {\n  \n\n  \n\n\n  int i = item.get_global_id(0);\n  if (i < n) {\n    \n\n    \n\n    if (del[i] <= 1E-5f) { \n\n\n      \n\n\n      theta[i] = sycl::acos((R[i] / sycl::sqrt(-(Q[i] * Q[i] * Q[i]))));\n      sqrtQ[i] = 2.f * sycl::sqrt(-Q[i]);\n\n      x1[i] = ((sqrtQ[i] * sycl::cos((theta[i]) / 3.f)) - (b[i] / 3.f));\n      x2[i] = ((sqrtQ[i] * sycl::cos((theta[i] + 2.f * 3.1415927f) / 3.f)) -\n               (b[i] / 3.f));\n      x3[i] = ((sqrtQ[i] * sycl::cos((theta[i] + 4.f * 3.1415927f) / 3.f)) -\n               (b[i] / 3.f));\n\n      \n\n      if (x1[i] < x2[i]) {\n        temp[i] = x1[i];\n        x1[i] = x2[i];\n        x2[i] = temp[i];\n      } \n\n      if (x2[i] < x3[i]) {\n        temp[i] = x2[i];\n        x2[i] = x3[i];\n        x3[i] = temp[i];\n      } \n\n      if (x1[i] < x2[i]) {\n        temp[i] = x1[i];\n        x1[i] = x2[i];\n        x2[i] = temp[i];\n      } \n\n\n      min[i] =\n          A[i] *\n                          ((x1[i] * x1[i] * x1[i] * x1[i]) -\n                           (x3[i] * x3[i] * x3[i] * x3[i])) /\n                          4.f +\n                      B[i] *\n                          ((x1[i] * x1[i] * x1[i]) - (x3[i] * x3[i] * x3[i])) /\n                          3.f +\n                      C[i] * ((x1[i] * x1[i]) - (x3[i] * x3[i])) / 2.f +\n                      D[i] * (x1[i] - x3[i]) <=\n                  0.f\n              ? x1[i]\n              : x3[i];\n\n    }\n\n    \n\n    else {\n\n      \n\n\n      x1[i] = sycl::cbrt((R[i] + sycl::sqrt((float)(del[i])))) +\n              sycl::cbrt((R[i] - sycl::sqrt((float)(del[i])))) -\n              (b[i] / 3.f); \n\n\n      \n\n\n      x2[i] = 0;\n      x3[i] = 0;\n\n      min[i] = x1[i];\n    }\n  }\n}\n\nvoid QuarticMinimumGPU(sycl::queue &q, int N, float *A, float *B, float *C,\n                       float *D, float *E, float *min) {\n\n  float *d_A, *d_B, *d_C, *d_D, *d_E, *d_bi, *d_ci, *d_di, *d_theta, *d_sqrtQ,\n      *d_Q, *d_R, *d_Qint, *d_Rint, *d_del, *d_x1, *d_x2, *d_x3, *d_min,\n      *d_temp;\n\n  \n\n  const int block_dim = 64;\n\n  \n\n  d_A = sycl::malloc_device<float>(N, q);\n  d_B = sycl::malloc_device<float>(N, q);\n  d_C = sycl::malloc_device<float>(N, q);\n  d_D = sycl::malloc_device<float>(N, q);\n  d_E = sycl::malloc_device<float>(N, q);\n\n  d_bi = sycl::malloc_device<float>(N, q);\n  d_ci = sycl::malloc_device<float>(N, q);\n  d_di = sycl::malloc_device<float>(N, q);\n  d_theta = sycl::malloc_device<float>(N, q);\n  d_sqrtQ = sycl::malloc_device<float>(N, q);\n\n  d_Q = sycl::malloc_device<float>(N, q);\n  d_R = sycl::malloc_device<float>(N, q);\n  d_Qint = sycl::malloc_device<float>(N, q);\n  d_Rint = sycl::malloc_device<float>(N, q);\n  d_del = sycl::malloc_device<float>(N, q);\n\n  d_x1 = sycl::malloc_device<float>(N, q);\n  d_x2 = sycl::malloc_device<float>(N, q);\n  d_x3 = sycl::malloc_device<float>(N, q);\n\n  d_min = sycl::malloc_device<float>(N, q);\n\n  d_temp = sycl::malloc_device<float>(N, q);\n\n  q.memcpy(d_A, A, N * sizeof(float));\n  q.memcpy(d_B, B, N * sizeof(float));\n  q.memcpy(d_C, C, N * sizeof(float));\n  q.memcpy(d_D, D, N * sizeof(float));\n\n  sycl::range<1> gws((N + block_dim - 1) / block_dim * block_dim);\n  sycl::range<1> lws(block_dim);\n\n  q.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n    QRdel(N, d_A, d_B, d_C, d_D, d_bi, d_ci, d_di, d_Q, d_R, d_Qint, d_Rint,\n          d_del, item);\n  });\n\n  q.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n    QuarticSolver(N, d_A, d_B, d_C, d_D, d_bi, d_Q, d_R, d_del, d_theta,\n                  d_sqrtQ, d_x1, d_x2, d_x3, d_temp, d_min, item);\n  });\n\n  q.memcpy(min, d_min, N * sizeof(float)).wait();\n\n  sycl::free(d_A, q);\n  sycl::free(d_B, q);\n  sycl::free(d_C, q);\n  sycl::free(d_D, q);\n  sycl::free(d_E, q);\n\n  sycl::free(d_bi, q);\n  sycl::free(d_ci, q);\n  sycl::free(d_di, q);\n  sycl::free(d_theta, q);\n  sycl::free(d_sqrtQ, q);\n\n  sycl::free(d_Q, q);\n  sycl::free(d_R, q);\n  sycl::free(d_Qint, q);\n  sycl::free(d_Rint, q);\n  sycl::free(d_del, q);\n\n  sycl::free(d_x1, q);\n  sycl::free(d_x2, q);\n  sycl::free(d_x3, q);\n\n  sycl::free(d_min, q);\n  sycl::free(d_temp, q);\n}\n\nvoid QuarticMinimumGPUStreams(sycl::queue &q, int N, float *A, float *B,\n                              float *C, float *D, float *E, float *min) {\n\n  float *d_A, *d_B, *d_C, *d_D, *d_E, *d_bi, *d_ci, *d_di, *d_theta, *d_sqrtQ,\n      *d_Q, *d_R, *d_Qint, *d_Rint, *d_del, *d_x1, *d_x2, *d_x3, *d_min,\n      *d_temp;\n\n  \n\n  const int block_dim = 64;\n\n  \n\n  const int nStreams = 4;\n  const int streamSize = N / nStreams;\n  const int streamBytes = streamSize * sizeof(float);\n\n  sycl::queue stream[nStreams + 1];\n\n  for (int i = 0; i <= nStreams; ++i) {\n#ifdef USE_GPU\n    stream[i] =\n        sycl::queue(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n    stream[i] =\n        sycl::queue(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n  }\n\n  int offset = 0;\n\n  \n\n  d_A = sycl::malloc_device<float>(N, q);\n  d_B = sycl::malloc_device<float>(N, q);\n  d_C = sycl::malloc_device<float>(N, q);\n  d_D = sycl::malloc_device<float>(N, q);\n  d_E = sycl::malloc_device<float>(N, q);\n\n  d_bi = sycl::malloc_device<float>(N, q);\n  d_ci = sycl::malloc_device<float>(N, q);\n  d_di = sycl::malloc_device<float>(N, q);\n  d_theta = sycl::malloc_device<float>(N, q);\n  d_sqrtQ = sycl::malloc_device<float>(N, q);\n\n  d_Q = sycl::malloc_device<float>(N, q);\n  d_R = sycl::malloc_device<float>(N, q);\n  d_Qint = sycl::malloc_device<float>(N, q);\n  d_Rint = sycl::malloc_device<float>(N, q);\n  d_del = sycl::malloc_device<float>(N, q);\n\n  d_x1 = sycl::malloc_device<float>(N, q);\n  d_x2 = sycl::malloc_device<float>(N, q);\n  d_x3 = sycl::malloc_device<float>(N, q);\n\n  d_min = sycl::malloc_device<float>(N, q);\n\n  d_temp = sycl::malloc_device<float>(N, q);\n\n  for (int i = 0; i < nStreams; ++i) {\n    offset = i * streamSize;\n    stream[i].memcpy(&d_A[offset], &A[offset], streamBytes);\n    stream[i].memcpy(&d_B[offset], &B[offset], streamBytes);\n    stream[i].memcpy(&d_C[offset], &C[offset], streamBytes);\n    stream[i].memcpy(&d_D[offset], &D[offset], streamBytes);\n\n    float *d_A_offset = &d_A[offset];\n    float *d_B_offset = &d_B[offset];\n    float *d_C_offset = &d_C[offset];\n    float *d_D_offset = &d_D[offset];\n    float *d_bi_offset = &d_bi[offset];\n    float *d_ci_offset = &d_ci[offset];\n    float *d_di_offset = &d_di[offset];\n    float *d_Q_offset = &d_Q[offset];\n    float *d_R_offset = &d_R[offset];\n    float *d_Qint_offset = &d_Qint[offset];\n    float *d_Rint_offset = &d_Rint[offset];\n    float *d_del_offset = &d_del[offset];\n    float *d_theta_offset = &d_theta[offset];\n    float *d_sqrtQ_offset = &d_sqrtQ[offset];\n    float *d_x1_offset = &d_x1[offset];\n    float *d_x2_offset = &d_x2[offset];\n    float *d_x3_offset = &d_x3[offset];\n    float *d_temp_offset = &d_temp[offset];\n    float *d_min_offset = &d_min[offset];\n\n    sycl::range<1> gws((streamSize + block_dim - 1) / block_dim * block_dim);\n    sycl::range<1> lws(block_dim);\n\n    stream[i].submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        QRdel(streamSize, d_A_offset, d_B_offset, d_C_offset, d_D_offset,\n              d_bi_offset, d_ci_offset, d_di_offset, d_Q_offset, d_R_offset,\n              d_Qint_offset, d_Rint_offset, d_del_offset, item);\n      });\n    });\n\n    stream[i].submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        QuarticSolver(streamSize, d_A_offset, d_B_offset, d_C_offset,\n                      d_D_offset, d_bi_offset, d_Q_offset, d_R_offset,\n                      d_del_offset, d_theta_offset, d_sqrtQ_offset, d_x1_offset,\n                      d_x2_offset, d_x3_offset, d_temp_offset, d_min_offset,\n                      item);\n      });\n    });\n\n    stream[i].memcpy(&min[offset], &d_min[offset], streamBytes);\n  }\n\n  const int resstreamSize = N % nStreams;\n  const int resstreamBytes = resstreamSize * sizeof(float);\n  if (resstreamSize != 0) {\n\n                           \n\n    offset = nStreams * streamSize;\n\n    stream[nStreams].memcpy(&d_A[offset], &A[offset], resstreamBytes);\n    stream[nStreams].memcpy(&d_B[offset], &B[offset], resstreamBytes);\n    stream[nStreams].memcpy(&d_C[offset], &C[offset], resstreamBytes);\n    stream[nStreams].memcpy(&d_D[offset], &D[offset], resstreamBytes);\n\n    float *d_A_offset = &d_A[offset];\n    float *d_B_offset = &d_B[offset];\n    float *d_C_offset = &d_C[offset];\n    float *d_D_offset = &d_D[offset];\n    float *d_bi_offset = &d_bi[offset];\n    float *d_ci_offset = &d_ci[offset];\n    float *d_di_offset = &d_di[offset];\n    float *d_Q_offset = &d_Q[offset];\n    float *d_R_offset = &d_R[offset];\n    float *d_Qint_offset = &d_Qint[offset];\n    float *d_Rint_offset = &d_Rint[offset];\n    float *d_del_offset = &d_del[offset];\n    float *d_theta_offset = &d_theta[offset];\n    float *d_sqrtQ_offset = &d_sqrtQ[offset];\n    float *d_x1_offset = &d_x1[offset];\n    float *d_x2_offset = &d_x2[offset];\n    float *d_x3_offset = &d_x3[offset];\n    float *d_temp_offset = &d_temp[offset];\n    float *d_min_offset = &d_min[offset];\n\n    sycl::range<1> gws((resstreamSize + block_dim - 1) / block_dim * block_dim);\n    sycl::range<1> lws(block_dim);\n\n    stream[nStreams].submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        QRdel(resstreamSize, d_A_offset, d_B_offset, d_C_offset, d_D_offset,\n              d_bi_offset, d_ci_offset, d_di_offset, d_Q_offset, d_R_offset,\n              d_Qint_offset, d_Rint_offset, d_del_offset, item);\n      });\n    });\n\n    stream[nStreams].submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        QuarticSolver(resstreamSize, d_A_offset, d_B_offset, d_C_offset,\n                      d_D_offset, d_bi_offset, d_Q_offset, d_R_offset,\n                      d_del_offset, d_theta_offset, d_sqrtQ_offset, d_x1_offset,\n                      d_x2_offset, d_x3_offset, d_temp_offset, d_min_offset,\n                      item);\n      });\n    });\n\n    stream[nStreams]\n        .memcpy(&min[offset], &d_min[offset], resstreamBytes)\n        .wait();\n  }\n\n  for (int i = 0; i < nStreams; i++) {\n    stream[i].wait();\n  }\n\n  sycl::free(d_A, q);\n  sycl::free(d_B, q);\n  sycl::free(d_C, q);\n  sycl::free(d_D, q);\n  sycl::free(d_E, q);\n\n  sycl::free(d_bi, q);\n  sycl::free(d_ci, q);\n  sycl::free(d_di, q);\n  sycl::free(d_theta, q);\n  sycl::free(d_sqrtQ, q);\n\n  sycl::free(d_Q, q);\n  sycl::free(d_R, q);\n  sycl::free(d_Qint, q);\n  sycl::free(d_Rint, q);\n  sycl::free(d_del, q);\n\n  sycl::free(d_x1, q);\n  sycl::free(d_x2, q);\n  sycl::free(d_x3, q);\n\n  sycl::free(d_min, q);\n  sycl::free(d_temp, q);\n}\n", "main.cpp": "#include <algorithm>\n#include <chrono> \n\n#include <cstdio>\n#include <random>\n\n#include \"gpu_solver.h\"\n#include \"reference.h\"\n\nvoid generate_data(int size, int min, int max, float *data) {\n  std::mt19937_64 generator{1993764};\n  std::uniform_int_distribution<> dist{min, max};\n  for (int i = 0; i < size; ++i) {\n    data[i] = dist(generator);\n  }\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int repeat = atoi(argv[1]);\n\n  \n\n  int N = 1999999;\n  printf(\"N = %d\\n\", N);\n\n  float *A, *B, *C, *D, *E;\n  float *minimum_ref, *minimum;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  A = sycl::malloc_host<float>(N, q);\n  B = sycl::malloc_host<float>(N, q);\n  C = sycl::malloc_host<float>(N, q);\n  D = sycl::malloc_host<float>(N, q);\n  E = sycl::malloc_host<float>(N, q);\n  minimum_ref = sycl::malloc_host<float>(N, q);\n  minimum = sycl::malloc_host<float>(N, q);\n\n  printf(\"generating data...\\n\");\n\n  generate_data(N, -100, 100, A);\n  generate_data(N, -100, 100, B);\n  generate_data(N, -100, 100, C);\n  generate_data(N, -100, 100, D);\n  generate_data(N, -100, 100, E);\n\n  for (int i = 0; i < N; i++) {\n    if (A[i] == 0) {\n      A[i] = 1;\n    } \n\n  }\n\n  float dur = 0;\n  float avg = 0;\n  bool ok;\n\n  printf(\"####################### Reference #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumCPU(N, A, B, C, D, E, minimum_ref);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n\n  avg = 0;\n\n  printf(\"####################### GPU (no streams) #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumGPU(q, N, A, B, C, D, E, minimum);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n\n  ok = true;\n  for (int i = 0; i < N; i++) {\n    if (fabsf(minimum[i] - minimum_ref[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  avg = 0;\n\n  printf(\"####################### GPU (streams) #############\\n\");\n\n  for (int k = 0; k < repeat; ++k) {\n\n    auto start = std::chrono::high_resolution_clock::now();\n\n    QuarticMinimumGPUStreams(q, N, A, B, C, D, E, minimum);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    std::chrono::duration<float> elapsed = end - start;\n    dur = elapsed.count() * 1000;\n    \n\n    avg += dur;\n  }\n\n  printf(\"Execution time (ms): %f\\n\", avg / repeat);\n\n  ok = true;\n  for (int i = 0; i < N; i++) {\n    if (fabsf(minimum[i] - minimum_ref[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(A, q);\n  sycl::free(B, q);\n  sycl::free(C, q);\n  sycl::free(D, q);\n  sycl::free(E, q);\n  sycl::free(minimum_ref, q);\n  sycl::free(minimum, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "qkv", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include \"common.h\"\n\n\n\n\n\n\nvoid matmul_forward_cpu(float* out,\n                    const float* inp, const float* weight, const float* bias,\n                    int B, int T, int C, int OC) {\n    \n\n    \n\n    \n\n    #pragma omp parallel for collapse(2)\n    for (int b = 0; b < B; b++) {\n        for (int t = 0; t < T; t++) {\n            float* out_bt = out + b * T * OC + t * OC;\n            const float* inp_bt = inp + b * T * C + t * C;\n            for (int o = 0; o < OC; o++) {\n                float val = (bias != NULL) ? bias[o] : 0.0f;\n                const float* wrow = weight + o*C;\n                for (int i = 0; i < C; i++) {\n                    val += inp_bt[i] * wrow[i];\n                }\n                out_bt[o] = val;\n            }\n        }\n    }\n}\n\n\n\n\n\n\n\n\n__global__ void matmul_forward_kernel1(float* out,\n                                       const float* inp, const float* weight, const float* bias,\n                                       int BT, int C, int OC) {\n    \n\n    \n\n    \n\n    int bt = blockIdx.x * blockDim.x + threadIdx.x;\n    int oc = blockIdx.y * blockDim.y + threadIdx.y;\n    if (bt < BT && oc < OC) {\n        float val = (bias != NULL) ? bias[oc] : 0.0f;\n        const float* wrow = weight + oc * C;\n        const float* inp_bt = inp + bt * C;\n        for (int i = 0; i < C; i++) {\n            val += inp_bt[i] * wrow[i];\n        }\n        out[bt * OC + oc] = val;\n    }\n}\n\n\n\n\n\n\n\n__global__ void add_bias(float* out, const float* bias, int B, int T, int OC) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n    for (int i = idx; i < B * T * OC; i += stride) {\n        int col = i % OC;\n        out[i] += bias[col];\n    }\n}\n\n\n\n\n\n__device__ float4 ld_vec(const float* address) {\n    return *reinterpret_cast<const float4*>(address);\n}\n\n__device__ void st_vec(float* address, float4 val) {\n    *reinterpret_cast<float4*>(address) = val;\n}\n\n__global__ void __launch_bounds__(16*16) \nmatmul_forward_kernel4(float* out, const float* inp,\n                       const float* weight, const float* bias, int C, int OC) {\n    \n\n    \n\n    \n\n    int oc = 8*(blockIdx.y * blockDim.y + threadIdx.y);\n\n    \n\n    __shared__ float lhs_s[128][32];\n    __shared__ float rhs_s[128][32];\n\n    \n\n    inp += 128 * blockIdx.x * C;\n    weight += 128 * blockIdx.y * C;\n    out += 128 * blockIdx.x * OC + 128 * blockIdx.y;\n\n    float vals[8][8] = {};\n    if(bias != NULL) {\n        for (int i = 0; i < 8; i++) {\n            for (int j = 0; j < 8; j += 4) {\n                float4 b = ld_vec(bias + oc + j);\n                vals[i][j+0] = b.x;\n                vals[i][j+1] = b.y;\n                vals[i][j+2] = b.z;\n                vals[i][j+3] = b.w;\n            }\n        }\n    }\n\n    int si_start = 4*(16 * threadIdx.y + threadIdx.x);\n    for (int so = 0; so < C; so += 32) {\n        __syncthreads();\n        int xmod8 = threadIdx.x % 8;\n        int xby8 = threadIdx.x / 8;\n        int xo = 4 * xmod8;\n        for(int y = 2 * threadIdx.y + xby8; y < 128; y += 32) {\n            st_vec(&lhs_s[y][xo], ld_vec(inp + y * C + so + xo));\n            st_vec(&rhs_s[y][xo], ld_vec(weight + y * C + so + xo));\n        }\n        __syncthreads();\n\n        for (int si = si_start; si < si_start + 32; si += 4) {\n            float4 rhs[8];\n            for (int u = 0; u < 8; ++u) {\n                rhs[u] = ld_vec(&rhs_s[u + 8 * threadIdx.y][si % 32]);\n            }\n\n            for (int ii = 0; ii < 8; ++ii) {\n                float4 lhs = ld_vec(&lhs_s[ii + 8 * threadIdx.x][si % 32]);\n                for (int ji = 0; ji < 8; ++ji) {\n                    vals[ii][ji] += lhs.x * rhs[ji].x;\n                    vals[ii][ji] += lhs.y * rhs[ji].y;\n                    vals[ii][ji] += lhs.z * rhs[ji].z;\n                    vals[ii][ji] += lhs.w * rhs[ji].w;\n                }\n            }\n        }\n    }\n\n    for (int i = 0; i < 8; ++i) {\n        for (int j = 0; j < 8; j += 4) {\n            float4 result;\n            result.x = vals[i][j + 0];\n            result.y = vals[i][j + 1];\n            result.z = vals[i][j + 2];\n            result.w = vals[i][j + 3];\n            st_vec(out + (8*threadIdx.x+i) * OC + 8*threadIdx.y + j, result);\n        }\n    }\n}\n\n\n\n\n\n\n\n\nvoid matmul_forward1(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    int sqrt_block_size = 16;\n    \n\n    \n\n    dim3 gridDim(ceil_div(B * T, sqrt_block_size), ceil_div(OC, sqrt_block_size));\n    dim3 blockDim(sqrt_block_size, sqrt_block_size);\n    matmul_forward_kernel1<<<gridDim, blockDim>>>(out, inp, weight, bias, B*T, C, OC);\n    cudaCheck(cudaDeviceSynchronize());\n}\n\n\n\nvoid matmul_forward2(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    const float alpha = 1.0f;\n    const float beta = 0.0f;\n    int sqrt_block_size = 16;\n    cublasCheck(cublasSgemm(cublas_handle, CUBLAS_OP_T, CUBLAS_OP_N, OC, B*T, C, &alpha, weight, C, inp, C, &beta, out, OC));\n    \n\n    if (bias != NULL) {\n        int block_size = sqrt_block_size * sqrt_block_size;\n        int grid_size = ceil_div(OC * B * T, block_size);\n        add_bias<<<grid_size, block_size>>>(out, bias, B, T, OC);\n    }\n    cudaCheck(cudaDeviceSynchronize());\n}\n\n\n\n\n\n\n\nvoid matmul_forward3(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    int has_bias = (bias != NULL);\n    int has_gelu = 0;\n\n    \n\n    if(((uintptr_t)bias % 16) != 0) {\n        printf(\"Bias pointer is not aligned (cuBLASLt requirement)!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    int returnedResults = 0;\n    cublasLtMatmulDesc_t operationDesc;\n    cublasLtMatmulPreference_t preference;\n    cublasLtMatrixLayout_t weightLayout;\n    cublasLtMatrixLayout_t inputLayout;\n    cublasLtMatrixLayout_t outputLayout;\n    cublasLtMatrixLayout_t biasLayout;\n    cublasLtMatmulHeuristicResult_t heuristic;\n\n    \n\n    cublasOperation_t opNoTranspose = CUBLAS_OP_N;\n    cublasOperation_t opTranspose = CUBLAS_OP_T;\n    cublasLtEpilogue_t epilogueBias = CUBLASLT_EPILOGUE_DEFAULT;\n    if (has_bias && has_gelu) {\n        epilogueBias = CUBLASLT_EPILOGUE_GELU_BIAS;\n    } else if (has_bias) {\n        epilogueBias = CUBLASLT_EPILOGUE_BIAS;\n    } else if (has_gelu) {\n        epilogueBias = CUBLASLT_EPILOGUE_GELU;\n    }\n    cublasCheck(cublasLtMatmulDescCreate(&operationDesc, cublas_compute_type, CUDA_R_32F));\n    cublasCheck(cublasLtMatmulDescSetAttribute(operationDesc, CUBLASLT_MATMUL_DESC_TRANSA, &opTranspose, sizeof(opTranspose)));\n    cublasCheck(cublasLtMatmulDescSetAttribute(operationDesc, CUBLASLT_MATMUL_DESC_TRANSB, &opNoTranspose, sizeof(opNoTranspose)));\n    cublasCheck(cublasLtMatmulDescSetAttribute(operationDesc, CUBLASLT_MATMUL_DESC_EPILOGUE, &epilogueBias, sizeof(epilogueBias)));\n    cublasCheck(cublasLtMatmulDescSetAttribute(operationDesc, CUBLASLT_MATMUL_DESC_BIAS_POINTER, &bias, sizeof(bias)));\n\n    \n\n    cublasCheck(cublasLtMatrixLayoutCreate(&weightLayout, CUDA_R_32F, C, OC, C));\n    cublasCheck(cublasLtMatrixLayoutCreate(&inputLayout, CUDA_R_32F, C, B*T, C));\n    cublasCheck(cublasLtMatrixLayoutCreate(&outputLayout, CUDA_R_32F, OC, B*T, OC));\n    cublasCheck(cublasLtMatrixLayoutCreate(&biasLayout, CUDA_R_32F, OC, 1, OC));\n\n    \n\n    cublasCheck(cublasLtMatmulPreferenceCreate(&preference));\n    cublasCheck(cublasLtMatmulPreferenceSetAttribute(preference,\n        CUBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES,\n        &cublaslt_workspace_size, sizeof(cublaslt_workspace_size)));\n\n    \n\n    cublasCheck(cublasLtMatmulAlgoGetHeuristic(cublaslt_handle, operationDesc,\n        weightLayout, inputLayout, outputLayout, outputLayout,\n        preference, 1, &heuristic, &returnedResults));\n    if (returnedResults == 0) {\n        printf(\"No cuBLASLt algorithm: B: %d, T: %d, C: %d, OC: %d, bias: %d, gelu: %d\\n\",\n            B, T, C, OC, has_bias, has_gelu);\n        exit(EXIT_FAILURE);\n    }\n\n    \n\n    const float alpha = 1.0f, beta = 0.0f;\n    cublasCheck(cublasLtMatmul(cublaslt_handle, operationDesc,\n        &alpha, weight, weightLayout, inp, inputLayout, &beta,\n        out, outputLayout, out, outputLayout, &heuristic.algo,\n        cublaslt_workspace, cublaslt_workspace_size, 0));\n\n    \n\n    cudaCheck(cudaDeviceSynchronize());\n\n    \n\n    cublasCheck(cublasLtMatmulPreferenceDestroy(preference));\n    cublasCheck(cublasLtMatmulDescDestroy(operationDesc));\n    cublasCheck(cublasLtMatrixLayoutDestroy(weightLayout));\n    cublasCheck(cublasLtMatrixLayoutDestroy(inputLayout));\n    cublasCheck(cublasLtMatrixLayoutDestroy(outputLayout));\n    cublasCheck(cublasLtMatrixLayoutDestroy(biasLayout));\n}\n\n\n\nvoid matmul_forward4(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    \n\n    \n\n    int sqrt_block_size = 16;\n\n    dim3 gridDim(ceil_div(B * T, 8*sqrt_block_size), ceil_div(OC, 8*sqrt_block_size));\n    dim3 blockDim(sqrt_block_size, sqrt_block_size);\n    matmul_forward_kernel4<<<gridDim, blockDim>>>(out, inp, weight, bias, C, OC);\n    cudaCheck(cudaDeviceSynchronize());\n}\n\n\n\nvoid matmul_forward(int kernel_num,\n                    float* out,\n                    const float* inp, const float* weight, const float* bias,\n                    int B, int T, int C, int OC) {\n    switch (kernel_num) {\n        case 1:\n            matmul_forward1(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 2:\n            matmul_forward2(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 3:\n            matmul_forward3(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 4:\n            matmul_forward4(out, inp, weight, bias, B, T, C, OC);\n            break;\n        default:\n            printf(\"Invalid kernel number\\n\");\n            exit(1);\n    }\n}\n\n\n\n\nint main(int argc, char **argv) {\n    srand(0);\n\n    int B = 4;\n    int T = 1024;\n    int C = 768;\n    int OC = 768 * 3;\n\n    \n\n    int deviceIdx = 0;\n    cudaCheck(cudaSetDevice(deviceIdx));\n    cudaDeviceProp deviceProp;\n    cudaGetDeviceProperties(&deviceProp, deviceIdx);\n    printf(\"Device %d: %s\\n\", deviceIdx, deviceProp.name);\n\n    \n\n    cublasCheck(cublasCreate(&cublas_handle));\n    cublasCheck(cublasLtCreate(&cublaslt_handle));\n    \n\n    \n\n    int enable_tf32 = 0;\n    printf(\"enable_tf32: %d\\n\", enable_tf32);\n    cublas_compute_type = enable_tf32 ? CUBLAS_COMPUTE_32F_FAST_TF32 : CUBLAS_COMPUTE_32F;\n    cublasMath_t cublas_math_mode = enable_tf32 ? CUBLAS_TF32_TENSOR_OP_MATH : CUBLAS_DEFAULT_MATH;\n    cublasCheck(cublasSetMathMode(cublas_handle, cublas_math_mode));\n    \n\n    cudaCheck(cudaMalloc(&cublaslt_workspace, cublaslt_workspace_size));\n\n    \n\n    float* out = (float*)malloc(B * T * OC * sizeof(float));\n    float* inp = make_random_float(B * T * C);\n    float* weight = make_random_float(OC * C);\n    float* bias = make_random_float(OC);\n\n    \n\n    float* d_out;\n    float* d_inp;\n    float* d_weight;\n    float* d_bias;\n    cudaCheck(cudaMalloc(&d_out, B * T * OC * sizeof(float)));\n    cudaCheck(cudaMalloc(&d_inp, B * T * C * sizeof(float)));\n    cudaCheck(cudaMalloc(&d_weight, C * OC * sizeof(float)));\n    cudaCheck(cudaMalloc(&d_bias, OC * sizeof(float)));\n    cudaCheck(cudaMemcpy(d_inp, inp, B * T * C * sizeof(float), cudaMemcpyHostToDevice));\n    cudaCheck(cudaMemcpy(d_weight, weight, C * OC * sizeof(float), cudaMemcpyHostToDevice));\n    cudaCheck(cudaMemcpy(d_bias, bias, OC * sizeof(float), cudaMemcpyHostToDevice));\n\n    \n\n    int kernel_num = 1;\n    if (argc > 1) {\n        kernel_num = atoi(argv[1]);\n    }\n    printf(\"Using kernel %d\\n\", kernel_num);\n\n    \n\n    matmul_forward_cpu(out, inp, weight, bias, B, T, C, OC);\n\n    matmul_forward(kernel_num, d_out, d_inp, d_weight, d_bias, B, T, C, OC);\n    validate_result(d_out, out, \"out\", B * T * OC, 1e-1f);\n\n    printf(\"All results match. Starting benchmarks.\\n\\n\");\n\n    int repeat_times = 100;\n    float elapsed_time = benchmark_kernel(repeat_times, matmul_forward,\n                                          kernel_num, d_out, d_inp, d_weight, d_bias,\n                                          B, T, C, OC);\n\n    float tflops = (float)B * T * C * OC * 2 / elapsed_time * 1e3f / 1e12f;\n    printf(\"time %.4f ms | tflops %.2f\\n\", elapsed_time, tflops);\n\n    \n\n    free(out);\n    free(inp);\n    free(weight);\n    free(bias);\n    cudaCheck(cudaFree(d_out));\n    cudaCheck(cudaFree(d_inp));\n    cudaCheck(cudaFree(d_weight));\n    cudaCheck(cudaFree(d_bias));\n    cudaCheck(cudaFree(cublaslt_workspace));\n    cublasCheck(cublasDestroy(cublas_handle));\n    cublasCheck(cublasLtDestroy(cublaslt_handle));\n    return 0;\n}\n"}}
{"kernel_name": "qkv", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include \"common.h\"\n\n\n\n\n\n\nvoid matmul_forward_cpu(float* out,\n                    const float* inp, const float* weight, const float* bias,\n                    int B, int T, int C, int OC) {\n    \n\n    \n\n    \n\n    #pragma omp parallel for collapse(2)\n    for (int b = 0; b < B; b++) {\n        for (int t = 0; t < T; t++) {\n            float* out_bt = out + b * T * OC + t * OC;\n            const float* inp_bt = inp + b * T * C + t * C;\n            for (int o = 0; o < OC; o++) {\n                float val = (bias != NULL) ? bias[o] : 0.0f;\n                const float* wrow = weight + o*C;\n                for (int i = 0; i < C; i++) {\n                    val += inp_bt[i] * wrow[i];\n                }\n                out_bt[o] = val;\n            }\n        }\n    }\n}\n\n\n\n\n\n\n\n\n__global__ void matmul_forward_kernel1(float* out,\n                                       const float* inp, const float* weight, const float* bias,\n                                       int BT, int C, int OC) {\n    \n\n    \n\n    \n\n    int bt = blockIdx.x * blockDim.x + threadIdx.x;\n    int oc = blockIdx.y * blockDim.y + threadIdx.y;\n    if (bt < BT && oc < OC) {\n        float val = (bias != NULL) ? bias[oc] : 0.0f;\n        const float* wrow = weight + oc * C;\n        const float* inp_bt = inp + bt * C;\n        for (int i = 0; i < C; i++) {\n            val += inp_bt[i] * wrow[i];\n        }\n        out[bt * OC + oc] = val;\n    }\n}\n\n\n\n\n\n\n\n__global__ void add_bias(float* out, const float* bias, int B, int T, int OC) {\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n    for (int i = idx; i < B * T * OC; i += stride) {\n        int col = i % OC;\n        out[i] += bias[col];\n    }\n}\n\n\n\n\n\n__device__ float4 ld_vec(const float* address) {\n    return *reinterpret_cast<const float4*>(address);\n}\n\n__device__ void st_vec(float* address, float4 val) {\n    *reinterpret_cast<float4*>(address) = val;\n}\n\n__global__ void __launch_bounds__(16*16) \nmatmul_forward_kernel4(float* out, const float* inp,\n                       const float* weight, const float* bias, int C, int OC) {\n    \n\n    \n\n    \n\n    int oc = 8*(blockIdx.y * blockDim.y + threadIdx.y);\n\n    \n\n    __shared__ float lhs_s[128][32];\n    __shared__ float rhs_s[128][32];\n\n    \n\n    inp += 128 * blockIdx.x * C;\n    weight += 128 * blockIdx.y * C;\n    out += 128 * blockIdx.x * OC + 128 * blockIdx.y;\n\n    float vals[8][8] = {};\n    if(bias != NULL) {\n        for (int i = 0; i < 8; i++) {\n            for (int j = 0; j < 8; j += 4) {\n                float4 b = ld_vec(bias + oc + j);\n                vals[i][j+0] = b.x;\n                vals[i][j+1] = b.y;\n                vals[i][j+2] = b.z;\n                vals[i][j+3] = b.w;\n            }\n        }\n    }\n\n    int si_start = 4*(16 * threadIdx.y + threadIdx.x);\n    for (int so = 0; so < C; so += 32) {\n        __syncthreads();\n        int xmod8 = threadIdx.x % 8;\n        int xby8 = threadIdx.x / 8;\n        int xo = 4 * xmod8;\n        for(int y = 2 * threadIdx.y + xby8; y < 128; y += 32) {\n            st_vec(&lhs_s[y][xo], ld_vec(inp + y * C + so + xo));\n            st_vec(&rhs_s[y][xo], ld_vec(weight + y * C + so + xo));\n        }\n        __syncthreads();\n\n        for (int si = si_start; si < si_start + 32; si += 4) {\n            float4 rhs[8];\n            for (int u = 0; u < 8; ++u) {\n                rhs[u] = ld_vec(&rhs_s[u + 8 * threadIdx.y][si % 32]);\n            }\n\n            for (int ii = 0; ii < 8; ++ii) {\n                float4 lhs = ld_vec(&lhs_s[ii + 8 * threadIdx.x][si % 32]);\n                for (int ji = 0; ji < 8; ++ji) {\n                    vals[ii][ji] += lhs.x * rhs[ji].x;\n                    vals[ii][ji] += lhs.y * rhs[ji].y;\n                    vals[ii][ji] += lhs.z * rhs[ji].z;\n                    vals[ii][ji] += lhs.w * rhs[ji].w;\n                }\n            }\n        }\n    }\n\n    for (int i = 0; i < 8; ++i) {\n        for (int j = 0; j < 8; j += 4) {\n            float4 result;\n            result.x = vals[i][j + 0];\n            result.y = vals[i][j + 1];\n            result.z = vals[i][j + 2];\n            result.w = vals[i][j + 3];\n            st_vec(out + (8*threadIdx.x+i) * OC + 8*threadIdx.y + j, result);\n        }\n    }\n}\n\n\n\n\n\n\n\n\nvoid matmul_forward1(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    int sqrt_block_size = 16;\n    \n\n    \n\n    dim3 gridDim(ceil_div(B * T, sqrt_block_size), ceil_div(OC, sqrt_block_size));\n    dim3 blockDim(sqrt_block_size, sqrt_block_size);\n    matmul_forward_kernel1<<<gridDim, blockDim>>>(out, inp, weight, bias, B*T, C, OC);\n    hipCheck(hipDeviceSynchronize());\n}\n\n\n\nvoid matmul_forward2(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    const float alpha = 1.0f;\n    const float beta = 0.0f;\n    int sqrt_block_size = 16;\n    hipblasCheck(hipblasSgemm(hipblas_handle, HIPBLAS_OP_T, HIPBLAS_OP_N, OC, B*T, C, &alpha, weight, C, inp, C, &beta, out, OC));\n    \n\n    if (bias != NULL) {\n        int block_size = sqrt_block_size * sqrt_block_size;\n        int grid_size = ceil_div(OC * B * T, block_size);\n        add_bias<<<grid_size, block_size>>>(out, bias, B, T, OC);\n    }\n    hipCheck(hipDeviceSynchronize());\n}\n\n\n\nvoid matmul_forward3(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    int has_bias = (bias != NULL);\n    int has_gelu = 0;\n\n    \n\n    if(((uintptr_t)bias % 16) != 0) {\n        printf(\"Bias pointer is not aligned (hipBLASLt requirement)!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    int returnedResults = 0;\n    hipblasLtMatmulDesc_t operationDesc;\n    hipblasLtMatmulPreference_t preference;\n    hipblasLtMatrixLayout_t weightLayout;\n    hipblasLtMatrixLayout_t inputLayout;\n    hipblasLtMatrixLayout_t outputLayout;\n    hipblasLtMatrixLayout_t biasLayout;\n    hipblasLtMatmulHeuristicResult_t heuristic;\n\n    \n\n    hipblasOperation_t opNoTranspose = HIPBLAS_OP_N;\n    hipblasOperation_t opTranspose = HIPBLAS_OP_T;\n    hipblasLtEpilogue_t epilogueBias = HIPBLASLT_EPILOGUE_DEFAULT;\n    if (has_bias && has_gelu) {\n        epilogueBias = HIPBLASLT_EPILOGUE_GELU_BIAS;\n    } else if (has_bias) {\n        epilogueBias = HIPBLASLT_EPILOGUE_BIAS;\n    } else if (has_gelu) {\n        epilogueBias = HIPBLASLT_EPILOGUE_GELU;\n    }\n    hipblasCheck(hipblasLtMatmulDescCreate(&operationDesc, hipblas_compute_type, HIP_R_32F));\n    hipblasCheck(hipblasLtMatmulDescSetAttribute(operationDesc, HIPBLASLT_MATMUL_DESC_TRANSA, &opTranspose, sizeof(opTranspose)));\n    hipblasCheck(hipblasLtMatmulDescSetAttribute(operationDesc, HIPBLASLT_MATMUL_DESC_TRANSB, &opNoTranspose, sizeof(opNoTranspose)));\n    hipblasCheck(hipblasLtMatmulDescSetAttribute(operationDesc, HIPBLASLT_MATMUL_DESC_EPILOGUE, &epilogueBias, sizeof(epilogueBias)));\n    hipblasCheck(hipblasLtMatmulDescSetAttribute(operationDesc, HIPBLASLT_MATMUL_DESC_BIAS_POINTER, &bias, sizeof(bias)));\n\n    \n\n    hipblasCheck(hipblasLtMatrixLayoutCreate(&weightLayout, HIP_R_32F, C, OC, C));\n    hipblasCheck(hipblasLtMatrixLayoutCreate(&inputLayout, HIP_R_32F, C, B*T, C));\n    hipblasCheck(hipblasLtMatrixLayoutCreate(&outputLayout, HIP_R_32F, OC, B*T, OC));\n    hipblasCheck(hipblasLtMatrixLayoutCreate(&biasLayout, HIP_R_32F, OC, 1, OC));\n\n    \n\n    hipblasCheck(hipblasLtMatmulPreferenceCreate(&preference));\n    hipblasCheck(hipblasLtMatmulPreferenceSetAttribute(preference,\n        HIPBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES,\n        &hipblaslt_workspace_size, sizeof(hipblaslt_workspace_size)));\n\n    \n\n    hipblasCheck(hipblasLtMatmulAlgoGetHeuristic(hipblaslt_handle, operationDesc,\n        weightLayout, inputLayout, outputLayout, outputLayout,\n        preference, 1, &heuristic, &returnedResults));\n    if (returnedResults == 0) {\n        printf(\"No hipBLASLt algorithm: B: %d, T: %d, C: %d, OC: %d, bias: %d, gelu: %d\\n\",\n            B, T, C, OC, has_bias, has_gelu);\n        exit(EXIT_FAILURE);\n    }\n\n    \n\n    const float alpha = 1.0f, beta = 0.0f;\n    hipblasCheck(hipblasLtMatmul(hipblaslt_handle, operationDesc,\n        &alpha, weight, weightLayout, inp, inputLayout, &beta,\n        out, outputLayout, out, outputLayout, &heuristic.algo,\n        hipblaslt_workspace, hipblaslt_workspace_size, 0));\n\n    \n\n    hipCheck(hipDeviceSynchronize());\n\n    \n\n    hipblasCheck(hipblasLtMatmulPreferenceDestroy(preference));\n    hipblasCheck(hipblasLtMatmulDescDestroy(operationDesc));\n    hipblasCheck(hipblasLtMatrixLayoutDestroy(weightLayout));\n    hipblasCheck(hipblasLtMatrixLayoutDestroy(inputLayout));\n    hipblasCheck(hipblasLtMatrixLayoutDestroy(outputLayout));\n    hipblasCheck(hipblasLtMatrixLayoutDestroy(biasLayout));\n}\n\n\n\nvoid matmul_forward4(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    \n\n    \n\n    int sqrt_block_size = 16;\n\n    dim3 gridDim(ceil_div(B * T, 8*sqrt_block_size), ceil_div(OC, 8*sqrt_block_size));\n    dim3 blockDim(sqrt_block_size, sqrt_block_size);\n    matmul_forward_kernel4<<<gridDim, blockDim>>>(out, inp, weight, bias, C, OC);\n    hipCheck(hipDeviceSynchronize());\n}\n\n\n\nvoid matmul_forward(int kernel_num,\n                    float* out,\n                    const float* inp, const float* weight, const float* bias,\n                    int B, int T, int C, int OC) {\n    switch (kernel_num) {\n        case 1:\n            matmul_forward1(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 2:\n            matmul_forward2(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 3:\n            matmul_forward3(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 4:\n            matmul_forward4(out, inp, weight, bias, B, T, C, OC);\n            break;\n        default:\n            printf(\"Invalid kernel number\\n\");\n            exit(1);\n    }\n}\n\n\n\n\nint main(int argc, char **argv) {\n    srand(0);\n\n    int B = 4;\n    int T = 1024;\n    int C = 768;\n    int OC = 768 * 3;\n\n    \n\n    int deviceIdx = 0;\n    hipCheck(hipSetDevice(deviceIdx));\n    hipDeviceProp_t deviceProp;\n    hipGetDeviceProperties(&deviceProp, deviceIdx);\n    printf(\"Device %d: %s\\n\", deviceIdx, deviceProp.name);\n\n    \n\n    hipblasCheck(hipblasCreate(&hipblas_handle));\n    hipblasCheck(hipblasLtCreate(&hipblaslt_handle));\n    \n\n    int enable_tf32 = 0;\n    printf(\"enable_tf32: %d\\n\", enable_tf32);\n    hipblas_compute_type = enable_tf32 ? HIPBLAS_COMPUTE_32F_FAST_TF32 : HIPBLAS_COMPUTE_32F;\n    hipblasMath_t hipblas_math_mode = enable_tf32 ? HIPBLAS_TF32_TENSOR_OP_MATH : HIPBLAS_DEFAULT_MATH;\n    hipblasCheck(hipblasSetMathMode(hipblas_handle, hipblas_math_mode));\n    \n\n    hipCheck(hipMalloc(&hipblaslt_workspace, hipblaslt_workspace_size));\n\n    \n\n    float* out = (float*)malloc(B * T * OC * sizeof(float));\n    float* inp = make_random_float(B * T * C);\n    float* weight = make_random_float(OC * C);\n    float* bias = make_random_float(OC);\n\n    \n\n    float* d_out;\n    float* d_inp;\n    float* d_weight;\n    float* d_bias;\n    hipCheck(hipMalloc(&d_out, B * T * OC * sizeof(float)));\n    hipCheck(hipMalloc(&d_inp, B * T * C * sizeof(float)));\n    hipCheck(hipMalloc(&d_weight, C * OC * sizeof(float)));\n    hipCheck(hipMalloc(&d_bias, OC * sizeof(float)));\n    hipCheck(hipMemcpy(d_inp, inp, B * T * C * sizeof(float), hipMemcpyHostToDevice));\n    hipCheck(hipMemcpy(d_weight, weight, C * OC * sizeof(float), hipMemcpyHostToDevice));\n    hipCheck(hipMemcpy(d_bias, bias, OC * sizeof(float), hipMemcpyHostToDevice));\n\n    \n\n    int kernel_num = 1;\n    if (argc > 1) {\n        kernel_num = atoi(argv[1]);\n    }\n    printf(\"Using kernel %d\\n\", kernel_num);\n\n    \n\n    matmul_forward_cpu(out, inp, weight, bias, B, T, C, OC);\n\n    matmul_forward(kernel_num, d_out, d_inp, d_weight, d_bias, B, T, C, OC);\n    validate_result(d_out, out, \"out\", B * T * OC, 1e-1f);\n\n    printf(\"All results match. Starting benchmarks.\\n\\n\");\n\n    int repeat_times = 100;\n    float elapsed_time = benchmark_kernel(repeat_times, matmul_forward,\n                                          kernel_num, d_out, d_inp, d_weight, d_bias,\n                                          B, T, C, OC);\n\n    float tflops = (float)B * T * C * OC * 2 / elapsed_time * 1e3f / 1e12f;\n    printf(\"time %.4f ms | tflops %.2f\\n\", elapsed_time, tflops);\n\n    \n\n    free(out);\n    free(inp);\n    free(weight);\n    free(bias);\n    hipCheck(hipFree(d_out));\n    hipCheck(hipFree(d_inp));\n    hipCheck(hipFree(d_weight));\n    hipCheck(hipFree(d_bias));\n    hipCheck(hipFree(hipblaslt_workspace));\n    hipblasCheck(hipblasDestroy(hipblas_handle));\n    hipblasCheck(hipblasLtDestroy(hipblaslt_handle));\n    return 0;\n}\n"}}
{"kernel_name": "qkv", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <oneapi/mkl.hpp>\n#include <oneapi/dnnl/dnnl.hpp>\n#include <oneapi/dnnl/dnnl_sycl.hpp>\n\n#include \"common.hpp\"\n\nauto MKL_OP_T = oneapi::mkl::transpose::trans;\nauto MKL_OP_N = oneapi::mkl::transpose::nontrans;\n\n\n\n\n\n\nvoid matmul_forward_cpu(float* out,\n                        const float* inp, const float* weight, const float* bias,\n                        int B, int T, int C, int OC) {\n    \n\n    \n\n    \n\n#pragma omp parallel for collapse(2)\n    for (int b = 0; b < B; b++) {\n        for (int t = 0; t < T; t++) {\n            float* out_bt = out + b * T * OC + t * OC;\n            const float* inp_bt = inp + b * T * C + t * C;\n            for (int o = 0; o < OC; o++) {\n                float val = (bias != NULL) ? bias[o] : 0.0f;\n                const float* wrow = weight + o*C;\n                for (int i = 0; i < C; i++) {\n                    val += inp_bt[i] * wrow[i];\n                }\n                out_bt[o] = val;\n            }\n        }\n    }\n}\n\n\n\n\n\n\n\n\nvoid matmul_forward_kernel1(sycl::nd_item<2> id, float* out,\n                            const float* inp, const float* weight, const float* bias,\n                            int BT, int C, int OC) {\n    \n\n    \n\n    \n\n    int bt = id.get_global_id(1);\n    int oc = id.get_global_id(0);\n    if (bt < BT && oc < OC) {\n        float val = (bias != NULL) ? bias[oc] : 0.0f;\n        const float* wrow = weight + oc*C;\n        const float* inp_bt = inp + bt * C;\n        for (int i = 0; i < C; i++) {\n            val += inp_bt[i] * wrow[i];\n        }\n        out[bt * OC + oc] = val;\n    }\n}\n\n\n\n\n\n\n\nvoid add_bias(sycl::nd_item<1> id, float* out, const float* bias, int B, int T, int OC) {\n    int idx = id.get_global_id(0);\n    int stride = id.get_global_range(0);\n    for (int i = idx; i < B * T * OC; i += stride) {\n        int col = i % OC;\n        out[i] += bias[col];\n    }\n}\n\n\n\n\n\nsycl::float4 ld_vec(const float* address) {\n    return *reinterpret_cast<const sycl::float4*>(address);\n}\n\nvoid st_vec(float* address, sycl::float4 val) {\n    *reinterpret_cast<sycl::float4*>(address) = val;\n}\n\nvoid matmul_forward_kernel4(sycl::nd_item<2> id, float* out, const float* inp, const float* weight, const float* bias,\n                                                     int C, int OC,\n                            sycl::multi_ptr<float[128][32][2], sycl::access::address_space::local_space> local_mem_ptr) {\n    int blockIdx_x = id.get_group(1);\n    int blockIdx_y = id.get_group(0);\n\n    int threadIdx_x = id.get_local_id(1);\n    int threadIdx_y = id.get_local_id(0);\n\n    int blockDim_y = id.get_local_range(0);\n\n    float *shared = (float*) local_mem_ptr.get_raw();\n    float (*lhs_s)[32] = (float (*)[32]) shared;\n    float (*rhs_s)[32] = (float (*)[32]) (shared + 128 * 32);\n\n    \n\n    \n\n    \n\n    int oc = 8*(blockIdx_y * blockDim_y + threadIdx_y);\n\n    \n\n    inp += 128 * blockIdx_x * C;\n    weight += 128 * blockIdx_y * C;\n    out += 128 * blockIdx_x * OC + 128 * blockIdx_y;\n\n    float vals[8][8] = {};\n    if(bias != nullptr) {\n        for (int i = 0; i < 8; i++) {\n            for (int j = 0; j < 8; j += 4) {\n                sycl::float4 b = ld_vec(bias + oc + j);\n                vals[i][j+0] = b.x();\n                vals[i][j+1] = b.y();\n                vals[i][j+2] = b.z();\n                vals[i][j+3] = b.w();\n            }\n        }\n    }\n\n    int si_start = 4*(16 * threadIdx_y + threadIdx_x);\n    for (int so = 0; so < C; so += 32) {\n        id.barrier(sycl::access::fence_space::local_space);\n        int xmod8 = threadIdx_x % 8;\n        int xby8 = threadIdx_x / 8;\n        int xo = 4 * xmod8;\n        for(int y = 2 * threadIdx_y + xby8; y < 128; y += 32) {\n            st_vec(&lhs_s[y][xo], ld_vec(inp + y * C + so + xo));\n            st_vec(&rhs_s[y][xo], ld_vec(weight + y * C + so + xo));\n        }\n        id.barrier(sycl::access::fence_space::local_space);\n\n        for (int si = si_start; si < si_start + 32; si += 4) {\n            sycl::float4 rhs[8];\n            for (int u = 0; u < 8; ++u) {\n                rhs[u] = ld_vec(&rhs_s[u + 8 * threadIdx_y][si % 32]);\n            }\n\n            for (int ii = 0; ii < 8; ++ii) {\n                sycl::float4 lhs = ld_vec(&lhs_s[ii + 8 * threadIdx_x][si % 32]);\n                for (int ji = 0; ji < 8; ++ji) {\n                    vals[ii][ji] += lhs.x() * rhs[ji].x();\n                    vals[ii][ji] += lhs.y() * rhs[ji].y();\n                    vals[ii][ji] += lhs.z() * rhs[ji].z();\n                    vals[ii][ji] += lhs.w() * rhs[ji].w();\n                }\n            }\n        }\n    }\n\n    for (int i = 0; i < 8; ++i) {\n        for (int j = 0; j < 8; j += 4) {\n            sycl::float4 result;\n            result.x() = vals[i][j + 0];\n            result.y() = vals[i][j + 1];\n            result.z() = vals[i][j + 2];\n            result.w() = vals[i][j + 3];\n            st_vec(out + (8*threadIdx_x+i) * OC + 8*threadIdx_y + j, result);\n        }\n    }\n}\n\n\n\n\n\n\n\n\nvoid matmul_forward1(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    \n\n    \n\n    int sqrt_block_size = 16;\n    sycl::nd_range<2> grid = sycl::nd_range<2>(sycl::range<2>(ceil_div(OC, sqrt_block_size) * sqrt_block_size,\n                                                              ceil_div(B*T, sqrt_block_size) * sqrt_block_size),\n                                               sycl::range<2>(sqrt_block_size, sqrt_block_size));\n    q.parallel_for(grid, [=](sycl::nd_item<2> id) {\n        matmul_forward_kernel1(id, out, inp, weight, bias, B*T, C, OC);\n    }).wait();\n}\n\n\n\nvoid matmul_forward2(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    const float alpha = 1.0f;\n    const float beta = 0.0f;\n    int sqrt_block_size = 16;\n\n    oneapi::mkl::blas::column_major::gemm(q,\n                                          MKL_OP_T, MKL_OP_N,\n                                          OC, B*T, C,\n                                          &alpha,\n                                          weight, C,\n                                          inp, C,\n                                          &beta,\n                                          out, OC\n    );\n    \n\n    if (bias != nullptr) {\n        int block_size = sqrt_block_size * sqrt_block_size;\n        int grid_size = ceil_div(OC * B * T, block_size);\n\n        q.parallel_for(sycl::nd_range<1>(grid_size * block_size, block_size), [=](sycl::nd_item<1> id) {\n            add_bias(id, out, bias, B, T, OC);\n        });\n    }\n    q.wait();\n}\n\nvoid matmul_forward3(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    bool has_bias = (bias != nullptr);\n    bool has_gelu = false;\n\n    \n\n    auto inp_md = dnnl::memory::desc({B*T, C}, dnnl::memory::data_type::f32, dnnl::memory::format_tag::ab);\n    auto weight_md = dnnl::memory::desc({C, OC}, dnnl::memory::data_type::f32, dnnl::memory::format_tag::ba);\n    auto out_md = dnnl::memory::desc({B*T, OC}, dnnl::memory::data_type::f32, dnnl::memory::format_tag::ab);\n    auto bias_md = dnnl::memory::desc({1, OC}, dnnl::memory::data_type::f32, dnnl::memory::format_tag::ab);\n\n    \n\n    auto inp_mem = dnnl::sycl_interop::make_memory(inp_md, engine, dnnl::sycl_interop::memory_kind::usm, const_cast<float *>(inp));\n    auto weight_mem = dnnl::sycl_interop::make_memory(weight_md, engine, dnnl::sycl_interop::memory_kind::usm, const_cast<float *>(weight));\n    auto out_mem = dnnl::sycl_interop::make_memory(out_md, engine, dnnl::sycl_interop::memory_kind::usm, out);\n    auto bias_mem = dnnl::sycl_interop::make_memory(bias_md, engine, dnnl::sycl_interop::memory_kind::usm, const_cast<float *>(bias));\n\n    \n\n    dnnl::primitive_attr matmul_attr;\n    if (has_gelu) {\n        dnnl::post_ops po;\n        po.append_eltwise(dnnl::algorithm::eltwise_gelu_tanh, 1.0f, 0.0f);\n        matmul_attr.set_post_ops(po);\n    }\n\n    \n\n    dnnl::matmul::primitive_desc matmul_pd;\n    if (has_bias) {\n        matmul_pd = dnnl::matmul::primitive_desc(engine, inp_md, weight_md, bias_md, out_md, matmul_attr);\n    }\n    else {\n        matmul_pd = dnnl::matmul::primitive_desc(engine, inp_md, weight_md, out_md, matmul_attr);\n    }\n\n    \n\n    auto matmul_prim = dnnl::matmul(matmul_pd);\n\n    \n\n    if (has_bias) {\n        matmul_prim.execute(stream, {\n                {DNNL_ARG_SRC, inp_mem},\n                {DNNL_ARG_WEIGHTS, weight_mem},\n                {DNNL_ARG_BIAS, bias_mem},\n                {DNNL_ARG_DST, out_mem}\n        });\n    }\n    else {\n        matmul_prim.execute(stream, {\n                {DNNL_ARG_SRC, inp_mem},\n                {DNNL_ARG_WEIGHTS, weight_mem},\n                {DNNL_ARG_DST, out_mem}\n        });\n    }\n    stream.wait();\n}\n\n\n\nvoid matmul_forward4(float* out,\n                     const float* inp, const float* weight, const float* bias,\n                     int B, int T, int C, int OC) {\n    \n\n    \n\n    int sqrt_block_size = 16;\n\n    sycl::nd_range<2> grid = sycl::nd_range<2>(sycl::range<2>(ceil_div(OC, 8*sqrt_block_size) * sqrt_block_size,\n                                                              ceil_div(B*T, 8*sqrt_block_size) * sqrt_block_size),\n                                               sycl::range<2>(sqrt_block_size, sqrt_block_size));\n\n    q.parallel_for(grid, [=](sycl::nd_item<2> id) {\n        auto local_mem_ptr = sycl::ext::oneapi::group_local_memory_for_overwrite<float[128][32][2]>(\n                id.get_group());\n        matmul_forward_kernel4(id, out, inp, weight, bias, C, OC, local_mem_ptr);\n    }).wait();\n}\n\n\n\nvoid matmul_forward(int kernel_num,\n                    float* out,\n                    const float* inp, const float* weight, const float* bias,\n                    int B, int T, int C, int OC) {\n    switch (kernel_num) {\n        case 1:\n            matmul_forward1(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 2:\n            matmul_forward2(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 3:\n            matmul_forward3(out, inp, weight, bias, B, T, C, OC);\n            break;\n        case 4:\n            matmul_forward4(out, inp, weight, bias, B, T, C, OC);\n            break;\n        default:\n            printf(\"Invalid kernel number\\n\");\n            exit(1);\n    }\n}\n\n\n\n\nint main(int argc, char **argv) {\n    srand(0);\n\n    int B = 4;\n    int T = 1024;\n    int C = 768;\n    int OC = 768 * 3; \n\n\n#ifdef USE_GPU\n    q = sycl::queue(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n    q = sycl::queue(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n    \n\n    float* out = (float*)malloc(B * T * OC * sizeof(float));\n    float* inp = make_random_float(B * T * C);\n    float* weight = make_random_float(OC * C);\n    float* bias = make_random_float(OC);\n\n    \n\n    float* d_out;\n    float* d_inp;\n    float* d_weight;\n    float* d_bias;\n    d_out = sycl::malloc_device<float>(B * T * OC, q);\n    d_inp = sycl::malloc_device<float>(B * T * C, q);\n    d_weight = sycl::malloc_device<float>(OC * C, q);\n    d_bias = sycl::malloc_device<float>(OC, q);\n\n    q.memcpy(d_inp, inp, B * T * C * sizeof(float));\n    q.memcpy(d_weight, weight, OC * C * sizeof(float));\n    q.memcpy(d_bias, bias, OC * sizeof(float));\n    q.wait();\n\n    \n\n    int kernel_num = 1;\n    if (argc > 1) {\n        kernel_num = atoi(argv[1]);\n    }\n    printf(\"Using kernel %d\\n\", kernel_num);\n\n    \n\n    matmul_forward_cpu(out, inp, weight, bias, B, T, C, OC);\n\n    matmul_forward(kernel_num, d_out, d_inp, d_weight, d_bias, B, T, C, OC);\n    validate_result(d_out, out, \"out\", B * T * OC, 1e-1f);\n\n    printf(\"All results match. Starting benchmarks.\\n\\n\");\n\n    int repeat_times = 100;\n    float elapsed_time = benchmark_kernel(repeat_times, matmul_forward,\n                                          kernel_num, d_out, d_inp, d_weight, d_bias,\n                                          B, T, C, OC);\n\n    float tflops = (float)B * T * C * OC * 2 / elapsed_time * 1e3f / 1e12f;\n    printf(\"time %.4f ms | tflops %.2f\\n\", elapsed_time, tflops);\n\n    \n\n    free(out);\n    free(inp);\n    free(weight);\n    free(bias);\n\n    sycl::free(d_out, q);\n    sycl::free(d_inp, q);\n    sycl::free(d_weight, q);\n    sycl::free(d_bias, q);\n\n    return 0;\n}\n"}}
{"kernel_name": "reverse2D", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <random>\n#include \"reverse.cuh\"\n\ntemplate <typename T>\nvoid eval_case(T* d_in, T* h_in, T* d_out, T* h_out, \n               bool rowMajor, bool alongRows,\n               int nrows, int ncols, const int repeat)\n{ \n  \n\n  printf(\"\\nInput matrix is %s major and reverse along %s\\n\",\n         rowMajor ? \"row\" : \"column\", alongRows ? \"rows\" : \"columns\" );\n\n  const size_t matrix_size = (size_t)nrows * ncols;\n  const size_t elem_size = sizeof(T) * matrix_size;\n  cudaMemcpy(d_in, h_in, elem_size, cudaMemcpyHostToDevice);\n\n  long time = 0;\n  for (int i = 0; i < repeat; i++)\n    time += reverse(d_out, d_in, nrows, ncols, rowMajor, alongRows, 0);\n  printf(\"Average kernel execution time: %f (ms)\\n\", time * 1e-6f / repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(h_out, d_out, elem_size, cudaMemcpyDeviceToHost);\n  for (size_t i = 1; i <= matrix_size; i++) {\n    printf(\"%d \", h_out[i-1]);\n    if (i % ncols == 0) printf(\"\\n\");\n  }\n#endif\n}\n\ntemplate <typename T>\nvoid eval(const int nrows, const int ncols, const int repeat)\n{\n  const size_t matrix_size = (size_t)nrows * ncols;\n  const size_t elem_size = sizeof(T) * matrix_size;\n\n  T *d_in, *d_out;\n  T *h_in = (T*) malloc (elem_size);\n  T *h_out = (T*) malloc (elem_size);\n  cudaMalloc((void**)&d_in, elem_size);\n  cudaMalloc((void**)&d_out, elem_size);\n\n  std::default_random_engine generator (123);\n  std::uniform_int_distribution<int> distribution(0, 255);\n \n#ifdef DEBUG\n  printf(\"Input matrix:\\n\");\n#endif\n  for (size_t i = 1; i <= matrix_size; i++) {\n    h_in[i-1] = static_cast<T>(distribution(generator));\n#ifdef DEBUG\n    printf(\"%d \", h_in[i-1]);\n    if (i % ncols == 0) printf(\"\\n\");\n#endif\n  }\n \n  \n\n  eval_case(d_in, h_in, d_out, h_out, true, true, nrows, ncols, repeat); \n  eval_case(d_in, h_in, d_out, h_out, true, false, nrows, ncols, repeat); \n  eval_case(d_in, h_in, d_out, h_out, false, true, nrows, ncols, repeat); \n  eval_case(d_in, h_in, d_out, h_out, false, false, nrows, ncols, repeat); \n  \n  free(h_in);\n  free(h_out);\n  cudaFree(d_in);\n  cudaFree(d_out);\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <nrows> <ncols> <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"\\nThe size of each matrix element is %zu byte\\n\", sizeof(unsigned char));\n  eval<unsigned char>(nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(ushort));\n  eval<ushort>(nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(uint));\n  eval<uint>(nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(ulong));\n  eval<ulong>(nrows, ncols, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "reverse2D", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <random>\n#include \"reverse.cuh\"\n\ntemplate <typename T>\nvoid eval_case(T* d_in, T* h_in, T* d_out, T* h_out, \n               bool rowMajor, bool alongRows,\n               int nrows, int ncols, const int repeat)\n{ \n  \n\n  printf(\"\\nInput matrix is %s major and reverse along %s\\n\",\n         rowMajor ? \"row\" : \"column\", alongRows ? \"rows\" : \"columns\" );\n\n  const size_t matrix_size = (size_t)nrows * ncols;\n  const size_t elem_size = sizeof(T) * matrix_size;\n  hipMemcpy(d_in, h_in, elem_size, hipMemcpyHostToDevice);\n\n  long time = 0;\n  for (int i = 0; i < repeat; i++)\n    time += reverse(d_out, d_in, nrows, ncols, rowMajor, alongRows, 0);\n  printf(\"Average kernel execution time: %f (ms)\\n\", time * 1e-6f / repeat);\n\n#ifdef DEBUG\n  hipMemcpy(h_out, d_out, elem_size, hipMemcpyDeviceToHost);\n  for (size_t i = 1; i <= matrix_size; i++) {\n    printf(\"%d \", h_out[i-1]);\n    if (i % ncols == 0) printf(\"\\n\");\n  }\n#endif\n}\n\ntemplate <typename T>\nvoid eval(const int nrows, const int ncols, const int repeat)\n{\n  const size_t matrix_size = (size_t)nrows * ncols;\n  const size_t elem_size = sizeof(T) * matrix_size;\n\n  T *d_in, *d_out;\n  T *h_in = (T*) malloc (elem_size);\n  T *h_out = (T*) malloc (elem_size);\n  hipMalloc((void**)&d_in, elem_size);\n  hipMalloc((void**)&d_out, elem_size);\n\n  std::default_random_engine generator (123);\n  std::uniform_int_distribution<int> distribution(0, 255);\n \n#ifdef DEBUG\n  printf(\"Input matrix:\\n\");\n#endif\n  for (size_t i = 1; i <= matrix_size; i++) {\n    \n\n#ifdef DEBUG\n    printf(\"%d \", h_in[i-1]);\n    if (i % ncols == 0) printf(\"\\n\");\n#endif\n  }\n \n  \n\n  eval_case(d_in, h_in, d_out, h_out, true, true, nrows, ncols, repeat); \n  eval_case(d_in, h_in, d_out, h_out, true, false, nrows, ncols, repeat); \n  eval_case(d_in, h_in, d_out, h_out, false, true, nrows, ncols, repeat); \n  eval_case(d_in, h_in, d_out, h_out, false, false, nrows, ncols, repeat); \n  \n  free(h_in);\n  free(h_out);\n  hipFree(d_in);\n  hipFree(d_out);\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <nrows> <ncols> <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  printf(\"\\nThe size of each matrix element is %zu byte\\n\", sizeof(unsigned char));\n  eval<unsigned char>(nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(ushort));\n  eval<ushort>(nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(uint));\n  eval<uint>(nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(ulong));\n  eval<ulong>(nrows, ncols, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "reverse2D", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <random>\n#include \"reverse.hpp\"\n\ntemplate <typename T>\nvoid eval_case(sycl::queue &q, T* d_in, T* h_in, T* d_out, T* h_out, \n               bool rowMajor, bool alongRows,\n               int nrows, int ncols, const int repeat)\n{\n  \n\n  printf(\"\\nInput matrix is %s major and reverse along %s\\n\",\n         rowMajor ? \"row\" : \"column\", alongRows ? \"rows\" : \"columns\" );\n\n  const size_t matrix_size = (size_t)nrows * ncols;\n  const size_t elem_size = sizeof(T) * matrix_size;\n  q.memcpy(d_in, h_in, elem_size).wait();\n\n  long time = 0;\n  for (int i = 0; i < repeat; i++)\n    time += reverse(d_out, d_in, nrows, ncols, rowMajor, alongRows, q);\n  printf(\"Average kernel execution time: %f (ms)\\n\", time * 1e-6f / repeat);\n\n#ifdef DEBUG\n  q.memcpy(h_out, d_out, elem_size).wait();\n  for (size_t i = 1; i <= matrix_size; i++) {\n    printf(\"%d \", h_out[i-1]);\n    if (i % ncols == 0) printf(\"\\n\");\n  }\n#endif\n}\n\ntemplate <typename T>\nvoid eval(sycl::queue &q, const int nrows, const int ncols, const int repeat)\n{\n  const size_t matrix_size = (size_t)nrows * ncols;\n  const size_t elem_size = sizeof(T) * matrix_size;\n\n  T *h_in = (T*) malloc (elem_size);\n  T *h_out = (T*) malloc (elem_size);\n  T *d_in = (T *)sycl::malloc_device(elem_size, q);\n  T *d_out = (T *)sycl::malloc_device(elem_size, q);\n\n  std::default_random_engine generator (123);\n  std::uniform_int_distribution<int> distribution(0, 255);\n \n#ifdef DEBUG\n  printf(\"Input matrix:\\n\");\n#endif\n  for (size_t i = 1; i <= matrix_size; i++) {\n    h_in[i-1] = static_cast<T>(distribution(generator));\n#ifdef DEBUG\n    printf(\"%d \", h_in[i-1]);\n    if (i % ncols == 0) printf(\"\\n\");\n#endif\n  }\n \n  \n\n  eval_case(q, d_in, h_in, d_out, h_out, true, true, nrows, ncols, repeat); \n  eval_case(q, d_in, h_in, d_out, h_out, true, false, nrows, ncols, repeat); \n  eval_case(q, d_in, h_in, d_out, h_out, false, true, nrows, ncols, repeat); \n  eval_case(q, d_in, h_in, d_out, h_out, false, false, nrows, ncols, repeat); \n  \n  free(h_in);\n  free(h_out);\n  sycl::free(d_in, q);\n  sycl::free(d_out, q);\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 4) {\n    printf(\"Usage: ./%s <nrows> <ncols> <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  printf(\"\\nThe size of each matrix element is %zu byte\\n\", sizeof(unsigned char));\n  eval<unsigned char>(q, nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(ushort));\n  eval<ushort>(q, nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(uint));\n  eval<uint>(q, nrows, ncols, repeat);\n  printf(\"\\nThe size of each matrix element is %zu bytes\\n\", sizeof(ulong));\n  eval<ulong>(q, nrows, ncols, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "rowwiseMoments", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <type_traits>\n#include <cuda.h>\n#include <thrust/tuple.h>\n#include \"utils.h\"\n\ntemplate <typename T>\n__global__\nvoid RowwiseMomentsKernel(\n    int64_t N,\n    T eps,\n    const T* X,\n    T* mean,\n    T* rstd) \n{\n  using T_ACC = T;\n  using WelfordType = WelfordData<T_ACC, int64_t>;\n  using WelfordOp =\n    WelfordOps<T_ACC, T_ACC, int64_t, thrust::pair<T_ACC, T_ACC>>;\n\n  const int64_t i = blockIdx.x;\n  WelfordOp welford_op = {\n0, \nfalse};\n  WelfordType val(0, 0, 0, 0);\n  for (int64_t j = threadIdx.x; j < N; j += blockDim.x) {\n    const int64_t index = i * N + j;\n    val = welford_op.reduce(val, static_cast<T_ACC>(X[index]), index);\n  }\n\n  \n\n  \n\n  __shared__ typename std::aligned_storage<\n    sizeof(WelfordType),\n    alignof(WelfordType)>::type val_shared[WARP_SIZE];\n\n  WelfordType* val_shared_ptr = reinterpret_cast<WelfordType*>(val_shared);\n  val = BlockReduce(\n      val,\n      welford_op,\n      \nWelfordType(0, 0, 0, 0),\n      val_shared_ptr);\n\n  if (threadIdx.x == 0) {\n    T_ACC m1;\n    T_ACC m2;\n    thrust::tie(m1, m2) = welford_op.project(val);\n    rstd[i] = rsqrt(m1 + static_cast<T_ACC>(eps));\n    mean[i] = m2;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 7) {\n    printf(\"Usage: %s <batch> <channel> <width> <height> <group> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int N = atoi(argv[1]);\n  const int C = atoi(argv[2]);\n  const int W = atoi(argv[3]);\n  const int H = atoi(argv[4]);\n  const int G = atoi(argv[5]);\n  const int repeat = atoi(argv[6]);\n\n  const int64_t D = C / G;\n\n  double eps = 1e-6;\n\n  size_t input_size = (size_t)N * C * W * H; \n  size_t input_size_bytes = input_size * sizeof(float);\n\n  size_t output_size = N * G;\n  size_t output_size_bytes = output_size * sizeof(float);\n\n  float* h_X = (float*) malloc (input_size_bytes);\n  float* h_mean = (float*) malloc (output_size_bytes);\n  float* h_rstd = (float*) malloc (output_size_bytes);\n\n  srand(123);\n  for (size_t i = 0; i < input_size; i++) {\n    h_X[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *d_X;\n  cudaMalloc((void**)&d_X, input_size_bytes);\n  cudaMemcpy(d_X, h_X, input_size_bytes, cudaMemcpyHostToDevice); \n\n  float* d_mean, *d_rstd;\n  cudaMalloc((void**)&d_mean, output_size_bytes);\n  cudaMalloc((void**)&d_rstd, output_size_bytes);\n\n  dim3 grid (N * G);\n  dim3 block (kNumThreads);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    RowwiseMomentsKernel<float><<<grid, block>>>(\n        D * H * W, eps, d_X, d_mean, d_rstd);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of RowwiseMoments kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_mean, d_mean, output_size_bytes, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_rstd, d_rstd, output_size_bytes, cudaMemcpyDeviceToHost);\n\n  double avg_rstd = 0.0, avg_mean = 0.0;\n  for (size_t i = 0; i < output_size; i++) {\n    avg_mean += h_mean[i];\n    avg_rstd += h_rstd[i];\n  }\n  avg_rstd /= output_size;\n  avg_mean /= output_size;\n\n  printf(\"Checksum: mean = %lf and rstd = %lf\\n\", avg_mean, avg_rstd);\n\n  cudaFree(d_X);\n  cudaFree(d_mean);\n  cudaFree(d_rstd);\n\n  free(h_X);\n  free(h_mean);\n  free(h_rstd);\n  return 0;\n}\n"}}
{"kernel_name": "rowwiseMoments", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <type_traits>\n#include <hip/hip_runtime.h>\n#include <thrust/tuple.h>\n#include \"utils.h\"\n\ntemplate <typename T>\n__global__\nvoid RowwiseMomentsKernel(\n    int64_t N,\n    T eps,\n    const T* X,\n    T* mean,\n    T* rstd) \n{\n  using T_ACC = T;\n  using WelfordType = WelfordData<T_ACC, int64_t>;\n  using WelfordOp =\n    WelfordOps<T_ACC, T_ACC, int64_t, thrust::pair<T_ACC, T_ACC>>;\n\n  const int64_t i = blockIdx.x;\n  WelfordOp welford_op = {\n0, \nfalse};\n  WelfordType val(0, 0, 0, 0);\n  for (int64_t j = threadIdx.x; j < N; j += blockDim.x) {\n    const int64_t index = i * N + j;\n    val = welford_op.reduce(val, static_cast<T_ACC>(X[index]), index);\n  }\n\n  \n\n  \n\n  __shared__ typename std::aligned_storage<\n    sizeof(WelfordType),\n    alignof(WelfordType)>::type val_shared[WARP_SIZE];\n\n  WelfordType* val_shared_ptr = reinterpret_cast<WelfordType*>(val_shared);\n  val = BlockReduce(\n      val,\n      welford_op,\n      \nWelfordType(0, 0, 0, 0),\n      val_shared_ptr);\n\n  if (threadIdx.x == 0) {\n    T_ACC m1;\n    T_ACC m2;\n    thrust::tie(m1, m2) = welford_op.project(val);\n    rstd[i] = rsqrt(m1 + static_cast<T_ACC>(eps));\n    mean[i] = m2;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 7) {\n    printf(\"Usage: %s <batch> <channel> <width> <height> <group> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int N = atoi(argv[1]);\n  const int C = atoi(argv[2]);\n  const int W = atoi(argv[3]);\n  const int H = atoi(argv[4]);\n  const int G = atoi(argv[5]);\n  const int repeat = atoi(argv[6]);\n\n  const int64_t D = C / G;\n\n  double eps = 1e-6;\n\n  size_t input_size = (size_t)N * C * W * H; \n  size_t input_size_bytes = input_size * sizeof(float);\n\n  size_t output_size = N * G;\n  size_t output_size_bytes = output_size * sizeof(float);\n\n  float* h_X = (float*) malloc (input_size_bytes);\n  float* h_mean = (float*) malloc (output_size_bytes);\n  float* h_rstd = (float*) malloc (output_size_bytes);\n\n  srand(123);\n  for (size_t i = 0; i < input_size; i++) {\n    h_X[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *d_X;\n  hipMalloc((void**)&d_X, input_size_bytes);\n  hipMemcpy(d_X, h_X, input_size_bytes, hipMemcpyHostToDevice); \n\n  float* d_mean, *d_rstd;\n  hipMalloc((void**)&d_mean, output_size_bytes);\n  hipMalloc((void**)&d_rstd, output_size_bytes);\n\n  dim3 grid (N * G);\n  dim3 block (kNumThreads);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    RowwiseMomentsKernel<float><<<grid, block>>>(\n        D * H * W, eps, d_X, d_mean, d_rstd);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of RowwiseMoments kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_mean, d_mean, output_size_bytes, hipMemcpyDeviceToHost);\n  hipMemcpy(h_rstd, d_rstd, output_size_bytes, hipMemcpyDeviceToHost);\n\n  double avg_rstd = 0.0, avg_mean = 0.0;\n  for (size_t i = 0; i < output_size; i++) {\n    avg_mean += h_mean[i];\n    avg_rstd += h_rstd[i];\n  }\n  avg_rstd /= output_size;\n  avg_mean /= output_size;\n\n  printf(\"Checksum: mean = %lf and rstd = %lf\\n\", avg_mean, avg_rstd);\n\n  hipFree(d_X);\n  hipFree(d_mean);\n  hipFree(d_rstd);\n\n  free(h_X);\n  free(h_mean);\n  free(h_rstd);\n  return 0;\n}\n"}}
{"kernel_name": "rowwiseMoments", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <type_traits>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n\ntemplate <typename T>\nvoid RowwiseMomentsKernel(\n    int64_t N,\n    T eps,\n    const T* X,\n    T* mean,\n    T* rstd,\n    const sycl::nd_item<1> &item)\n{\n  using T_ACC = T;\n  using WelfordType = WelfordData<T_ACC, int64_t>;\n  using WelfordOp = WelfordOps<T_ACC, T_ACC, int64_t, std::pair<T_ACC, T_ACC>>;\n\n  sycl::multi_ptr<typename std::aligned_storage<\n                  sizeof(WelfordType), alignof(WelfordType)>::type[WARP_SIZE],\n                  sycl::access::address_space::local_space>\n    localPtr = sycl::ext::oneapi::group_local_memory_for_overwrite<\n        typename std::aligned_storage<sizeof(WelfordType), alignof(WelfordType)>::type[WARP_SIZE]>(item.get_group());\n  WelfordType* val_shared_ptr = reinterpret_cast<WelfordType*>(*localPtr);\n\n  const int64_t i = item.get_group(0);\n  WelfordOp welford_op = {\n0, \nfalse};\n  WelfordType val(0, 0, 0, 0);\n  for (int64_t j = item.get_local_id(0); j < N; j += item.get_local_range(0)) {\n    const int64_t index = i * N + j;\n    val = welford_op.reduce(val, static_cast<T_ACC>(X[index]), index);\n  }\n\n  val = BlockReduce(\n      val, welford_op,\n      \nWelfordType(0, 0, 0, 0),\n      val_shared_ptr, item);\n\n  if (item.get_local_id(0) == 0) {\n    T_ACC m1;\n    T_ACC m2;\n    std::tie(m1, m2) = welford_op.project(val);\n    rstd[i] = sycl::rsqrt(m1 + static_cast<T_ACC>(eps));\n    mean[i] = m2;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 7) {\n    printf(\"Usage: %s <batch> <channel> <width> <height> <group> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int N = atoi(argv[1]);\n  const int C = atoi(argv[2]);\n  const int W = atoi(argv[3]);\n  const int H = atoi(argv[4]);\n  const int G = atoi(argv[5]);\n  const int repeat = atoi(argv[6]);\n\n  const int64_t D = C / G;\n\n  double eps = 1e-6;\n\n  size_t input_size = (size_t)N * C * W * H;\n  size_t input_size_bytes = input_size * sizeof(float);\n\n  size_t output_size = N * G;\n  size_t output_size_bytes = output_size * sizeof(float);\n\n  float* h_X = (float*) malloc (input_size_bytes);\n  float* h_mean = (float*) malloc (output_size_bytes);\n  float* h_rstd = (float*) malloc (output_size_bytes);\n\n  srand(123);\n  for (size_t i = 0; i < input_size; i++) {\n    h_X[i] = rand() / (float)RAND_MAX;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_X;\n  d_X = (float *)sycl::malloc_device(input_size_bytes, q);\n  q.memcpy(d_X, h_X, input_size_bytes);\n\n  float* d_mean, *d_rstd;\n  d_mean = (float *)sycl::malloc_device(output_size_bytes, q);\n  d_rstd = (float *)sycl::malloc_device(output_size_bytes, q);\n\n  sycl::range<1> gws (N * G * kNumThreads);\n  sycl::range<1> lws (kNumThreads);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws),\n          [=](sycl::nd_item<1> item) [[intel::reqd_sub_group_size(32)]] {\n        RowwiseMomentsKernel<float>(D * H * W, eps, d_X, d_mean, d_rstd, item);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of RowwiseMoments kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  q.memcpy(h_mean, d_mean, output_size_bytes);\n  q.memcpy(h_rstd, d_rstd, output_size_bytes);\n  q.wait();\n\n  double avg_rstd = 0.0, avg_mean = 0.0;\n  for (size_t i = 0; i < output_size; i++) {\n    avg_mean += h_mean[i];\n    avg_rstd += h_rstd[i];\n  }\n  avg_rstd /= output_size;\n  avg_mean /= output_size;\n\n  printf(\"Checksum: mean = %lf and rstd = %lf\\n\", avg_mean, avg_rstd);\n\n  sycl::free(d_X, q);\n  sycl::free(d_mean, q);\n  sycl::free(d_rstd, q);\n\n  free(h_X);\n  free(h_mean);\n  free(h_rstd);\n  return 0;\n}\n"}}
{"kernel_name": "scan3", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cuda.h>\n#include <thrust/scan.h>\n#include <thrust/device_vector.h>\n#include <cub/cub.cuh>\n#include \"scan.h\"\n\n\n\nvoid scanLargeArraysCPUReference(\n    float * output,\n    float * input,\n    const unsigned int length)\n{\n  output[0] = 0;\n\n  for(unsigned int i = 1; i < length; ++i)\n  {\n    output[i] = input[i-1] + output[i-1];\n  }\n}\n\n\nint main(int argc, char * argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <repeat> <input length>\\n\";\n    return 1;\n  }\n  int iterations = atoi(argv[1]);\n  int length = atoi(argv[2]);\n\n  if(iterations < 1)\n  {\n    std::cout << \"Error, iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n  if(!isPowerOf2(length))\n  {\n    length = roundToPowerOf2(length);\n  }\n\n  \n\n  unsigned int sizeBytes = length * sizeof(float);\n\n  float* input = (float*) malloc (sizeBytes);\n\n  \n\n  float* output = (float*) malloc (sizeBytes);\n\n  \n\n  fillRandom<float>(input, length, 1, 0, 255);\n\n  \n\n  float* verificationOutput = (float*)malloc(sizeBytes);\n  memset(verificationOutput, 0, sizeBytes);\n\n  \n\n  scanLargeArraysCPUReference(verificationOutput, input, length);\n\n  \n\n  float* inputBuffer;\n  cudaMalloc((void**)&inputBuffer, sizeBytes);\n  cudaMemcpy(inputBuffer, input, sizeBytes, cudaMemcpyHostToDevice);\n\n  \n\n  float* outputBuffer;\n  cudaMalloc((void**)&outputBuffer, sizeBytes);\n\n  thrust::device_ptr<float> ibuf(inputBuffer);\n  thrust::device_ptr<float> obuf(outputBuffer);\n\n  std::cout << \"Executing kernel for \" << iterations << \" iterations\\n\";\n  std::cout << \"-------------------------------------------\\n\";\n\n  \n\n  thrust::exclusive_scan(ibuf, ibuf + length, obuf, 0.f);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    thrust::exclusive_scan(ibuf, ibuf + length, obuf, 0.f);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of CUDA Thrust exclusive scan: \"\n            << time * 1e-3f / iterations << \" (us)\\n\";\n\n  cudaMemcpy(output, outputBuffer, sizeBytes, cudaMemcpyDeviceToHost);\n\n  \n\n  if (compare<float>(output, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  \n\n  start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    \n\n    void     *d_temp_storage = nullptr;\n    size_t   temp_storage_bytes = 0;\n    cub::DeviceScan::ExclusiveScan(\n      d_temp_storage, temp_storage_bytes,\n      inputBuffer, outputBuffer, cub::Sum(), 0.f, length);\n    \n    \n\n    cudaMalloc(&d_temp_storage, temp_storage_bytes);\n    \n    cub::DeviceScan::ExclusiveScan(\n      d_temp_storage, temp_storage_bytes,\n      inputBuffer, outputBuffer, cub::Sum(), 0.f, length);\n\n    cudaFree(d_temp_storage);\n  }\n\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of CUDA CUB exclusive scan: \"\n            << time * 1e-3f / iterations << \" (us)\\n\";\n\n  cudaMemcpy(output, outputBuffer, sizeBytes, cudaMemcpyDeviceToHost);\n\n  \n\n  if (compare<float>(output, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  cudaFree(inputBuffer);\n  cudaFree(outputBuffer);\n\n  free(input);\n  free(output);\n  free(verificationOutput);\n  return 0;\n}\n"}}
{"kernel_name": "scan3", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <hip/hip_runtime.h>\n#include <thrust/scan.h>\n#include <thrust/device_vector.h>\n#include <hipcub/hipcub.hpp>\n#include \"scan.h\"\n\n\n\nvoid scanLargeArraysCPUReference(\n    float * output,\n    float * input,\n    const unsigned int length)\n{\n  output[0] = 0;\n\n  for(unsigned int i = 1; i < length; ++i)\n  {\n    output[i] = input[i-1] + output[i-1];\n  }\n}\n\n\nint main(int argc, char * argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <repeat> <input length>\\n\";\n    return 1;\n  }\n  int iterations = atoi(argv[1]);\n  int length = atoi(argv[2]);\n\n  if(iterations < 1)\n  {\n    std::cout << \"Error, iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n  if(!isPowerOf2(length))\n  {\n    length = roundToPowerOf2(length);\n  }\n\n  \n\n  unsigned int sizeBytes = length * sizeof(float);\n\n  float* input = (float*) malloc (sizeBytes);\n\n  \n\n  float* output = (float*) malloc (sizeBytes);\n\n  \n\n  fillRandom<float>(input, length, 1, 0, 255);\n\n  \n\n  float* verificationOutput = (float*)malloc(sizeBytes);\n  memset(verificationOutput, 0, sizeBytes);\n\n  \n\n  scanLargeArraysCPUReference(verificationOutput, input, length);\n\n  \n\n  float* inputBuffer;\n  hipMalloc((void**)&inputBuffer, sizeBytes);\n  hipMemcpy(inputBuffer, input, sizeBytes, hipMemcpyHostToDevice);\n\n  \n\n  float* outputBuffer;\n  hipMalloc((void**)&outputBuffer, sizeBytes);\n\n  thrust::device_ptr<float> ibuf(inputBuffer);\n  thrust::device_ptr<float> obuf(outputBuffer);\n\n  std::cout << \"Executing kernel for \" << iterations << \" iterations\\n\";\n  std::cout << \"-------------------------------------------\\n\";\n\n  \n\n  thrust::exclusive_scan(ibuf, ibuf + length, obuf, 0.f);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    thrust::exclusive_scan(ibuf, ibuf + length, obuf, 0.f);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of HIP Thrust exclusive scan: \"\n            << time * 1e-3f / iterations << \" (us)\\n\";\n\n  hipMemcpy(output, outputBuffer, sizeBytes, hipMemcpyDeviceToHost);\n\n  \n\n  if (compare<float>(output, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  \n\n  start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    \n\n    void     *d_temp_storage = nullptr;\n    size_t   temp_storage_bytes = 0;\n    hipcub::DeviceScan::ExclusiveScan(\n      d_temp_storage, temp_storage_bytes,\n      inputBuffer, outputBuffer, hipcub::Sum(), 0.f, length);\n    \n    \n\n    hipMalloc(&d_temp_storage, temp_storage_bytes);\n    \n    hipcub::DeviceScan::ExclusiveScan(\n      d_temp_storage, temp_storage_bytes,\n      inputBuffer, outputBuffer, hipcub::Sum(), 0.f, length);\n\n    hipFree(d_temp_storage);\n  }\n\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of HIP CUB exclusive scan: \"\n            << time * 1e-3f / iterations << \" (us)\\n\";\n\n  hipMemcpy(output, outputBuffer, sizeBytes, hipMemcpyDeviceToHost);\n\n  \n\n  if (compare<float>(output, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  hipFree(inputBuffer);\n  hipFree(outputBuffer);\n\n  free(input);\n  free(output);\n  free(verificationOutput);\n  return 0;\n}\n"}}
{"kernel_name": "scan3", "parallel_api": "sycl", "code": {"main.cpp": "#include <oneapi/dpl/execution>\n#include <oneapi/dpl/algorithm>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"scan.h\"\n\n\n\nvoid scanLargeArraysCPUReference(\n    float * output,\n    float * input,\n    const unsigned int length)\n{\n  output[0] = 0;\n\n  for(unsigned int i = 1; i < length; ++i)\n  {\n    output[i] = input[i-1] + output[i-1];\n  }\n}\n\n\nint main(int argc, char * argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <repeat> <input length>\\n\";\n    return 1;\n  }\n  int iterations = atoi(argv[1]);\n  int length = atoi(argv[2]);\n\n  if(iterations < 1)\n  {\n    std::cout << \"Error, iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n  if(!isPowerOf2(length))\n  {\n    length = roundToPowerOf2(length);\n  }\n\n  \n\n  unsigned int sizeBytes = length * sizeof(float);\n\n  float* input = (float*) malloc (sizeBytes);\n\n  \n\n  float* output = (float*) malloc (sizeBytes);\n\n  \n\n  fillRandom<float>(input, length, 1, 0, 255);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  sycl::buffer<float, 1> inputBuffer (input, length);\n\n  \n\n  sycl::buffer<float, 1> outputBuffer (length);\n\n  std::cout << \"Executing kernel for \" << iterations << \" iterations\\n\";\n  std::cout << \"-------------------------------------------\\n\";\n\n  auto policy = oneapi::dpl::execution::make_device_policy(q);\n  auto ibuf_beg = oneapi::dpl::begin(inputBuffer, sycl::read_only);\n  auto ibuf_end = oneapi::dpl::end(inputBuffer, sycl::read_only);\n  auto obuf_beg = oneapi::dpl::begin(outputBuffer, sycl::write_only, sycl::no_init);\n\n  \n\n  oneapi::dpl::exclusive_scan(policy, ibuf_beg, ibuf_end, obuf_beg, 0.f);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for(int n = 0; n < iterations; n++)\n  {\n    oneapi::dpl::exclusive_scan(policy, ibuf_beg, ibuf_end, obuf_beg, 0.f);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of oneDPL exclusive scan: \"\n            << time * 1e-3f / iterations << \" (us)\\n\";\n\n  q.submit([&] (sycl::handler &cgh) {\n    auto acc = outputBuffer.get_access<sycl::access::mode::read>(cgh);\n    cgh.copy(acc, output);\n  }).wait();\n\n  \n\n  float* verificationOutput = (float*)malloc(sizeBytes);\n  memset(verificationOutput, 0, sizeBytes);\n\n  \n\n  scanLargeArraysCPUReference(verificationOutput, input, length);\n\n  \n\n  if (compare<float>(output, verificationOutput, length, (float)0.001))\n    std::cout << \"PASS\" << std::endl;\n  else\n    std::cout << \"FAIL\" << std::endl;\n\n  free(input);\n  free(output);\n  free(verificationOutput);\n  return 0;\n}\n"}}
{"kernel_name": "slu", "parallel_api": "hip", "code": {"numeric.cu": "#include <iostream>\n#include <cmath>\n#include <hip/hip_runtime.h>\n#include \"symbolic.h\"\n#include \"Timer.h\"\n\nusing namespace std;\n\n#define TMPMEMNUM  10353\n#define  Nstreams  16\n\n__global__ void RL(\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned* __restrict__ csr_r_ptr_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const int* __restrict__ level_idx_dev,\n    REAL* __restrict__ tmpMem,\n    const unsigned n,\n    const int levelHead,\n    const int inLevPos)\n{\n  const int tid = threadIdx.x;\n  const int bid = blockIdx.x;\n  const int wid = threadIdx.x / 32;\n\n  const unsigned currentCol = level_idx_dev[levelHead+inLevPos+bid];\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  extern __shared__ REAL s[];\n\n  \n\n\n  int offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n      val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n      tmpMem[bid*n + ridx]= val_dev[currentLPos + offset];\n    }\n    offset += blockDim.x;\n  }\n  __syncthreads();\n\n  \n\n  const unsigned subColPos = csr_diag_ptr_dev[currentCol] + wid + 1;\n  const unsigned subMatSize = csr_r_ptr_dev[currentCol + 1] - csr_diag_ptr_dev[currentCol] - 1;\n  unsigned subCol;\n  const int tidInWarp = threadIdx.x % 32;\n  unsigned subColElem = 0;\n\n  int woffset = 0;\n  while (subMatSize > woffset)\n  {\n    if (wid + woffset < subMatSize)\n    {\n      offset = 0;\n      subCol = csr_c_idx_dev[subColPos + woffset];\n      while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n      {\n        if (tidInWarp + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n        {\n\n          subColElem = sym_c_ptr_dev[subCol] + tidInWarp + offset;\n          unsigned ridx = sym_r_idx_dev[subColElem];\n\n          if (ridx == currentCol)\n          {\n            s[wid] = val_dev[subColElem];\n          }\n          \n\n          \n\n          if (ridx > currentCol)\n          {\n            \n\n            \n\n            atomicAdd(&val_dev[subColElem], -tmpMem[ridx+n*bid]*s[wid]);\n          }\n        }\n        offset += 32;\n      }\n    }\n    woffset += blockDim.x/32;\n  }\n\n  __syncthreads();\n  \n\n  offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n      tmpMem[bid*n + ridx]= 0;\n    }\n    offset += blockDim.x;\n  }\n}\n\n__global__ void RL_perturb(\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned* __restrict__ csr_r_ptr_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const int* __restrict__ level_idx_dev,\n    REAL* __restrict__ tmpMem,\n    const unsigned n,\n    const int levelHead,\n    const int inLevPos,\n    const float pert)\n{\n  const int tid = threadIdx.x;\n  const int bid = blockIdx.x;\n  const int wid = threadIdx.x / 32;\n\n  const unsigned currentCol = level_idx_dev[levelHead+inLevPos+bid];\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  extern __shared__ REAL s[];\n\n  \n\n\n  int offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n      if (abs(val_dev[l_col_ptr_dev[currentCol]]) < pert)\n        val_dev[l_col_ptr_dev[currentCol]] = pert;\n\n      val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n      tmpMem[bid*n + ridx]= val_dev[currentLPos + offset];\n    }\n    offset += blockDim.x;\n  }\n  __syncthreads();\n\n  \n\n  const unsigned subColPos = csr_diag_ptr_dev[currentCol] + wid + 1;\n  const unsigned subMatSize = csr_r_ptr_dev[currentCol + 1] - csr_diag_ptr_dev[currentCol] - 1;\n  unsigned subCol;\n  const int tidInWarp = threadIdx.x % 32;\n  unsigned subColElem = 0;\n\n  int woffset = 0;\n  while (subMatSize > woffset)\n  {\n    if (wid + woffset < subMatSize)\n    {\n      offset = 0;\n      subCol = csr_c_idx_dev[subColPos + woffset];\n      while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n      {\n        if (tidInWarp + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n        {\n\n          subColElem = sym_c_ptr_dev[subCol] + tidInWarp + offset;\n          unsigned ridx = sym_r_idx_dev[subColElem];\n\n          if (ridx == currentCol)\n          {\n            s[wid] = val_dev[subColElem];\n          }\n          \n\n          \n\n          if (ridx > currentCol)\n          {\n            \n\n            \n\n            atomicAdd(&val_dev[subColElem], -tmpMem[ridx+n*bid]*s[wid]);\n          }\n        }\n        offset += 32;\n      }\n    }\n    woffset += blockDim.x/32;\n  }\n\n  __syncthreads();\n  \n\n  offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n      tmpMem[bid*n + ridx]= 0;\n    }\n    offset += blockDim.x;\n  }\n}\n\n__global__ void RL_onecol_factorizeCurrentCol(\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  const int tid = threadIdx.x;\n\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  \n\n\n  int offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n      val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n      tmpMem[stream * n + ridx]= val_dev[currentLPos + offset];\n    }\n    offset += blockDim.x;\n  }\n}\n\n__global__ void RL_onecol_factorizeCurrentCol_perturb(\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n,\n    const float pert)\n{\n  const int tid = threadIdx.x;\n\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  \n\n\n  int offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n      if (abs(val_dev[l_col_ptr_dev[currentCol]]) < pert)\n        val_dev[l_col_ptr_dev[currentCol]] = pert;\n\n      val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n      tmpMem[stream * n + ridx]= val_dev[currentLPos + offset];\n    }\n    offset += blockDim.x;\n  }\n}\n\n__global__ void RL_onecol_updateSubmat(\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  const int tid = threadIdx.x;\n  const int bid = blockIdx.x;\n  __shared__ REAL s;\n\n  \n\n  const unsigned subColPos = csr_diag_ptr_dev[currentCol] + bid + 1;\n  unsigned subCol;\n  unsigned subColElem = 0;\n\n  int offset = 0;\n  subCol = csr_c_idx_dev[subColPos];\n  while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n  {\n    if (tid + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n    {\n      subColElem = sym_c_ptr_dev[subCol] + tid + offset;\n      unsigned ridx = sym_r_idx_dev[subColElem];\n\n      if (ridx == currentCol)\n      {\n        s = val_dev[subColElem];\n      }\n      __syncthreads();\n      if (ridx > currentCol)\n      {\n        atomicAdd(&val_dev[subColElem], -tmpMem[stream * n + ridx] * s);\n      }\n    }\n    offset += blockDim.x;\n  }\n}\n\n__global__ void RL_onecol_cleartmpMem(\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  const int tid = threadIdx.x;\n\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  unsigned offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n      tmpMem[stream * n + ridx]= 0;\n    }\n    offset += blockDim.x;\n  }\n}\n\nvoid LUonDevice(Symbolic_Matrix &A_sym, ostream &out, ostream &err, bool PERTURB)\n{\n  unsigned n = A_sym.n;\n  unsigned nnz = A_sym.nnz;\n  unsigned num_lev = A_sym.num_lev;\n  unsigned *sym_c_ptr_dev, *sym_r_idx_dev, *l_col_ptr_dev;\n  REAL *val_dev, *tmpMem;\n  unsigned *csr_r_ptr_dev, *csr_c_idx_dev, *csr_diag_ptr_dev;\n  int *level_idx_dev;\n\n  hipMalloc((void**)&sym_c_ptr_dev, (n + 1) * sizeof(unsigned));\n  hipMalloc((void**)&sym_r_idx_dev, nnz * sizeof(unsigned));\n  hipMalloc((void**)&val_dev, nnz * sizeof(REAL));\n  hipMalloc((void**)&l_col_ptr_dev, n * sizeof(unsigned));\n  hipMalloc((void**)&csr_r_ptr_dev, (n + 1) * sizeof(unsigned));\n  hipMalloc((void**)&csr_c_idx_dev, nnz * sizeof(unsigned));\n  hipMalloc((void**)&csr_diag_ptr_dev, n * sizeof(unsigned));\n  hipMalloc((void**)&level_idx_dev, n * sizeof(int));\n\n  hipMemcpy(sym_c_ptr_dev, &(A_sym.sym_c_ptr[0]), (n + 1) * sizeof(unsigned), hipMemcpyHostToDevice);\n  hipMemcpy(sym_r_idx_dev, &(A_sym.sym_r_idx[0]), nnz * sizeof(unsigned), hipMemcpyHostToDevice);\n  hipMemcpy(val_dev, &(A_sym.val[0]), nnz * sizeof(REAL), hipMemcpyHostToDevice);\n  hipMemcpy(l_col_ptr_dev, &(A_sym.l_col_ptr[0]), n * sizeof(unsigned), hipMemcpyHostToDevice);\n  hipMemcpy(csr_r_ptr_dev, &(A_sym.csr_r_ptr[0]), (n + 1) * sizeof(unsigned), hipMemcpyHostToDevice);\n  hipMemcpy(csr_c_idx_dev, &(A_sym.csr_c_idx[0]), nnz * sizeof(unsigned), hipMemcpyHostToDevice);\n  hipMemcpy(csr_diag_ptr_dev, &(A_sym.csr_diag_ptr[0]), n * sizeof(unsigned), hipMemcpyHostToDevice);\n  hipMemcpy(level_idx_dev, &(A_sym.level_idx[0]), n * sizeof(int), hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&tmpMem, TMPMEMNUM*n*sizeof(REAL));\n  hipMemset(tmpMem, 0, TMPMEMNUM*n*sizeof(REAL));\n\n  \n\n  float pert = 0;\n  if (PERTURB)\n  {\n    float norm_A = 0;\n    for (unsigned i = 0; i < n; ++i)\n    {\n      float tmp = 0;\n      for (unsigned j = A_sym.sym_c_ptr[i]; j < A_sym.sym_c_ptr[i+1]; ++j)\n        tmp += abs(A_sym.val[j]);\n      if (norm_A < tmp)\n        norm_A = tmp;\n    }\n    pert = 3.45e-4 * norm_A;\n    out << \"Gaussian elimination with static pivoting (GESP)...\" << endl;\n    out << \"1-Norm of A matrix is \" << norm_A << \", Perturbation value is \" << pert << endl;\n  }\n\n  hipDeviceSynchronize();\n\n  Timer t;\n  double utime;\n  t.start();\n  for (unsigned i = 0; i < num_lev; ++i)\n  {\n    int lev_size = A_sym.level_ptr[i + 1] - A_sym.level_ptr[i];\n\n    if (lev_size > 896) { \n\n      unsigned WarpsPerBlock = 2;\n      dim3 dimBlock(WarpsPerBlock * 32, 1);\n      size_t MemSize = WarpsPerBlock * sizeof(REAL);\n\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        dim3 dimGrid(restCol, 1);\n        if (!PERTURB)\n          hipLaunchKernelGGL(RL, dimGrid, dimBlock, MemSize, 0, sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              A_sym.level_ptr[i],\n              j*TMPMEMNUM);\n        else\n          hipLaunchKernelGGL(RL_perturb, dimGrid, dimBlock, MemSize, 0, sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              A_sym.level_ptr[i],\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else if (lev_size > 448) {\n      unsigned WarpsPerBlock = 4;\n      dim3 dimBlock(WarpsPerBlock * 32, 1);\n      size_t MemSize = WarpsPerBlock * sizeof(REAL);\n\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        dim3 dimGrid(restCol, 1);\n        if (!PERTURB)\n          hipLaunchKernelGGL(RL, dimGrid, dimBlock, MemSize, 0, sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              A_sym.level_ptr[i],\n              j*TMPMEMNUM);\n        else\n          hipLaunchKernelGGL(RL_perturb, dimGrid, dimBlock, MemSize, 0, sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              A_sym.level_ptr[i],\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else if (lev_size > Nstreams) {\n      dim3 dimBlock(256, 1);\n      size_t MemSize = 32 * sizeof(REAL);\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        dim3 dimGrid(restCol, 1);\n        if (!PERTURB)\n          hipLaunchKernelGGL(RL, dimGrid, dimBlock, MemSize, 0, sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              A_sym.level_ptr[i],\n              j*TMPMEMNUM);\n        else\n          hipLaunchKernelGGL(RL_perturb, dimGrid, dimBlock, MemSize, 0, sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              A_sym.level_ptr[i],\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else { \n\n      for (int offset = 0; offset < lev_size; offset += Nstreams) {\n        for (int j = 0; j < Nstreams; j++) {\n          if (j + offset < lev_size) {\n            const unsigned currentCol = A_sym.level_idx[A_sym.level_ptr[i] + j + offset];\n            const unsigned subMatSize = A_sym.csr_r_ptr[currentCol + 1]\n              - A_sym.csr_diag_ptr[currentCol] - 1;\n\n            if (!PERTURB)\n              hipLaunchKernelGGL(RL_onecol_factorizeCurrentCol, dim3(1), dim3(256), 0, 0, sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  l_col_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n);\n            else\n              hipLaunchKernelGGL(RL_onecol_factorizeCurrentCol_perturb, dim3(1), dim3(256), 0, 0, sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  l_col_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n,\n                  pert);\n            if (subMatSize > 0)\n              hipLaunchKernelGGL(RL_onecol_updateSubmat, dim3(subMatSize), dim3(256), 0, 0, sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  csr_c_idx_dev,\n                  csr_diag_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n);\n            hipLaunchKernelGGL(RL_onecol_cleartmpMem, dim3(1), dim3(256), 0, 0, sym_c_ptr_dev,\n                sym_r_idx_dev,\n                l_col_ptr_dev,\n                currentCol,\n                tmpMem,\n                j,\n                n);\n          }\n        }\n      }\n    }\n  }\n  hipDeviceSynchronize();\n  t.elapsedUserTime(utime);\n  out << \"Total LU kernel execution time: \" << utime << \" ms\" << std::endl;\n\n  \n\n  hipMemcpy(&(A_sym.val[0]), val_dev, nnz * sizeof(REAL), hipMemcpyDeviceToHost);\n\n#ifdef VERIFY\n  \n\n  unsigned err_find = 0;\n  for(unsigned i = 0; i < nnz; i++)\n    if(isnan(A_sym.val[i]) || isinf(A_sym.val[i])) \n      err_find++;\n\n  if (err_find != 0)\n    err << \"LU data check: NaN found!!\" << std::endl;\n#endif\n\n  hipFree(sym_c_ptr_dev);\n  hipFree(sym_r_idx_dev);\n  hipFree(val_dev);\n  hipFree(l_col_ptr_dev);\n  hipFree(csr_c_idx_dev);\n  hipFree(csr_r_ptr_dev);\n  hipFree(csr_diag_ptr_dev);\n  hipFree(level_idx_dev);\n  hipFree(tmpMem);\n}\n"}}
{"kernel_name": "slu", "parallel_api": "omp", "code": {"numeric.cpp": "#include <iostream>\n#include <cmath>\n#include <omp.h>\n#include \"symbolic.h\"\n#include \"Timer.h\"\n\nusing namespace std;\n\n#define TMPMEMNUM  10353\n#define Nstreams   16\n\nvoid RL(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned* __restrict__ csr_r_ptr_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const int* __restrict__ level_idx_dev,\n    REAL* __restrict__ tmpMem,\n    const unsigned n,\n    const int levelHead,\n    const int inLevPos)\n{\n  #pragma omp target teams num_teams(nteams) thread_limit(nthreads)\n  {\n    REAL s[32];\n    #pragma omp parallel \n    {\n      const int tid = omp_get_thread_num();\n      const int bid = omp_get_team_num();\n      const int wid = omp_get_thread_num() / 32;\n\n      const unsigned currentCol = level_idx_dev[levelHead+inLevPos+bid];\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      \n\n\n      int offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n          val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n          tmpMem[bid*n + ridx]= val_dev[currentLPos + offset];\n        }\n        offset += omp_get_num_threads();\n      }\n      #pragma omp barrier\n\n      \n\n      const unsigned subColPos = csr_diag_ptr_dev[currentCol] + wid + 1;\n      const unsigned subMatSize = csr_r_ptr_dev[currentCol + 1] - csr_diag_ptr_dev[currentCol] - 1;\n      unsigned subCol;\n      const int tidInWarp = omp_get_thread_num() % 32;\n      unsigned subColElem = 0;\n\n      int woffset = 0;\n      while (subMatSize > woffset)\n      {\n        if (wid + woffset < subMatSize)\n        {\n          offset = 0;\n          subCol = csr_c_idx_dev[subColPos + woffset];\n          while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n          {\n            if (tidInWarp + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n            {\n\n              subColElem = sym_c_ptr_dev[subCol] + tidInWarp + offset;\n              unsigned ridx = sym_r_idx_dev[subColElem];\n\n              if (ridx == currentCol)\n              {\n                s[wid] = val_dev[subColElem];\n              }\n              \n\n              \n\n              if (ridx > currentCol)\n              {\n                \n\n                \n\n                #pragma omp atomic update\n                val_dev[subColElem] += -tmpMem[ridx+n*bid]*s[wid];\n              }\n            }\n            offset += 32;\n          }\n        }\n        woffset += omp_get_num_threads()/32;\n      }\n\n      #pragma omp barrier\n      \n\n      offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n          tmpMem[bid*n + ridx]= 0;\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_perturb(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned* __restrict__ csr_r_ptr_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const int* __restrict__ level_idx_dev,\n    REAL* __restrict__ tmpMem,\n    const unsigned n,\n    const int levelHead,\n    const int inLevPos,\n    const float pert)\n{\n  #pragma omp target teams num_teams(nteams) thread_limit(nthreads)\n  {\n    REAL s[32];\n    #pragma omp parallel \n    {\n      const int tid = omp_get_thread_num();\n      const int bid = omp_get_team_num();\n      const int wid = omp_get_thread_num() / 32;\n\n      const unsigned currentCol = level_idx_dev[levelHead+inLevPos+bid];\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      \n\n\n      int offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n          if (abs(val_dev[l_col_ptr_dev[currentCol]]) < pert)\n            val_dev[l_col_ptr_dev[currentCol]] = pert;\n\n          val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n          tmpMem[bid*n + ridx]= val_dev[currentLPos + offset];\n        }\n        offset += omp_get_num_threads();\n      }\n      #pragma omp barrier\n\n      \n\n      const unsigned subColPos = csr_diag_ptr_dev[currentCol] + wid + 1;\n      const unsigned subMatSize = csr_r_ptr_dev[currentCol + 1] - csr_diag_ptr_dev[currentCol] - 1;\n      unsigned subCol;\n      const int tidInWarp = omp_get_thread_num() % 32;\n      unsigned subColElem = 0;\n\n      int woffset = 0;\n      while (subMatSize > woffset)\n      {\n        if (wid + woffset < subMatSize)\n        {\n          offset = 0;\n          subCol = csr_c_idx_dev[subColPos + woffset];\n          while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n          {\n            if (tidInWarp + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n            {\n\n              subColElem = sym_c_ptr_dev[subCol] + tidInWarp + offset;\n              unsigned ridx = sym_r_idx_dev[subColElem];\n\n              if (ridx == currentCol)\n              {\n                s[wid] = val_dev[subColElem];\n              }\n              \n\n              \n\n              if (ridx > currentCol)\n              {\n                \n\n                \n\n                #pragma omp atomic update\n                val_dev[subColElem] += -tmpMem[ridx+n*bid]*s[wid];\n              }\n            }\n            offset += 32;\n          }\n        }\n        woffset += omp_get_num_threads()/32;\n      }\n\n      #pragma omp barrier\n      \n\n      offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n          tmpMem[bid*n + ridx]= 0;\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_onecol_factorizeCurrentCol(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  #pragma omp target teams num_teams(nteams) thread_limit(nthreads)\n  {\n    #pragma omp parallel \n    {\n      const int tid = omp_get_thread_num();\n\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      \n\n\n      int offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n          val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n          tmpMem[stream * n + ridx]= val_dev[currentLPos + offset];\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_onecol_factorizeCurrentCol_perturb(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n,\n    const float pert)\n{\n  #pragma omp target teams num_teams(nteams) thread_limit(nthreads)\n  {\n    #pragma omp parallel \n    {\n      const int tid = omp_get_thread_num();\n\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      \n\n\n      int offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n          if (abs(val_dev[l_col_ptr_dev[currentCol]]) < pert)\n            val_dev[l_col_ptr_dev[currentCol]] = pert;\n\n          val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n          tmpMem[stream * n + ridx]= val_dev[currentLPos + offset];\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_onecol_updateSubmat(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  #pragma omp target teams num_teams(nteams) thread_limit(nthreads)\n  {\n    REAL s;\n    #pragma omp parallel \n    {\n      const int tid = omp_get_thread_num();\n      const int bid = omp_get_team_num();\n\n      \n\n      const unsigned subColPos = csr_diag_ptr_dev[currentCol] + bid + 1;\n      unsigned subColElem = 0;\n      unsigned ridx;\n\n      int offset = 0;\n      unsigned subCol = csr_c_idx_dev[subColPos];\n      const int range = sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol];\n      while(offset < range)\n      {\n        if (tid + offset < range)\n        {\n          subColElem = sym_c_ptr_dev[subCol] + tid + offset;\n          ridx = sym_r_idx_dev[subColElem];\n\n          if (ridx == currentCol)\n          {\n            s = val_dev[subColElem];\n          }\n        }\n        #pragma omp barrier\n\n        if (tid + offset < range)\n        {\n          if (ridx > currentCol)\n          {\n            #pragma omp atomic update\n            val_dev[subColElem] += -tmpMem[stream * n + ridx] * s;\n          }\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_onecol_cleartmpMem(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  #pragma omp target teams num_teams(nteams) thread_limit(nthreads)\n  {\n    #pragma omp parallel \n    {\n      const int tid = omp_get_thread_num();\n\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      unsigned offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n          tmpMem[stream * n + ridx]= 0;\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid LUonDevice(Symbolic_Matrix &A_sym, ostream &out, ostream &err, bool PERTURB)\n{\n  unsigned n = A_sym.n;\n  unsigned nnz = A_sym.nnz;\n  unsigned num_lev = A_sym.num_lev;\n\n  unsigned *sym_c_ptr_dev = &(A_sym.sym_c_ptr[0]);\n  unsigned *sym_r_idx_dev = &(A_sym.sym_r_idx[0]);\n  REAL *val_dev = &(A_sym.val[0]);\n  unsigned *l_col_ptr_dev = &(A_sym.l_col_ptr[0]);\n  unsigned *csr_r_ptr_dev = &(A_sym.csr_r_ptr[0]);\n  unsigned *csr_c_idx_dev = &(A_sym.csr_c_idx[0]);\n  unsigned *csr_diag_ptr_dev = &(A_sym.csr_diag_ptr[0]);\n  int *level_idx_dev = &(A_sym.level_idx[0]);\n  REAL *tmpMem = (REAL*) malloc (TMPMEMNUM*n*sizeof(REAL));\n\n  #pragma omp target data map(to: sym_c_ptr_dev[0:n+1],\\\n                                  sym_r_idx_dev[0:nnz],\\\n                                  val_dev[0:nnz],\\\n                                  l_col_ptr_dev[0:n],\\\n                                  csr_r_ptr_dev[0:n+1],\\\n                                  csr_c_idx_dev[0:nnz],\\\n                                  csr_diag_ptr_dev[0:n],\\\n                                  level_idx_dev[0:n]) \\\n                          map(alloc: tmpMem[0:TMPMEMNUM*n])\n  {\n\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < TMPMEMNUM*n; i++)\n    tmpMem[i] = (REAL)0;\n\n  \n\n  float pert = 0;\n  if (PERTURB)\n  {\n    float norm_A = 0;\n    for (unsigned i = 0; i < n; ++i)\n    {\n      float tmp = 0;\n      for (unsigned j = A_sym.sym_c_ptr[i]; j < A_sym.sym_c_ptr[i+1]; ++j)\n        tmp += abs(A_sym.val[j]);\n      if (norm_A < tmp)\n        norm_A = tmp;\n    }\n    pert = 3.45e-4 * norm_A;\n    out << \"Gaussian elimination with static pivoting (GESP)...\" << endl;\n    out << \"1-Norm of A matrix is \" << norm_A << \", Perturbation value is \" << pert << endl;\n  }\n\n  Timer t;\n  double utime;\n  t.start();\n  for (unsigned i = 0; i < num_lev; ++i)\n  {\n    int l = A_sym.level_ptr[i];\n    int lev_size = A_sym.level_ptr[i + 1] - l;\n\n    if (lev_size > 896) { \n\n      int dimBlock = 64;\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        int dimGrid = restCol;\n        if (!PERTURB)\n          RL(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM);\n        else\n          RL_perturb(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else if (lev_size > 448) {\n      int dimBlock = 128;\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        int dimGrid = restCol;\n        if (!PERTURB)\n          RL(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM);\n        else\n          RL_perturb(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else if (lev_size > Nstreams) {\n      int dimBlock = 256;\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        int dimGrid = restCol;\n        if (!PERTURB)\n          RL(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM);\n        else\n          RL_perturb(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else { \n\n      for (int offset = 0; offset < lev_size; offset += Nstreams) {\n        for (int j = 0; j < Nstreams; j++) {\n          if (j + offset < lev_size) {\n            const unsigned currentCol = A_sym.level_idx[A_sym.level_ptr[i] + j + offset];\n            const unsigned subMatSize = A_sym.csr_r_ptr[currentCol + 1]\n              - A_sym.csr_diag_ptr[currentCol] - 1;\n\n            if (!PERTURB)\n              RL_onecol_factorizeCurrentCol(\n                  1, 256,\n                  sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  l_col_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n);\n            else\n              RL_onecol_factorizeCurrentCol_perturb(\n                  1, 256,\n                  sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  l_col_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n,\n                  pert);\n            if (subMatSize > 0)\n              RL_onecol_updateSubmat(\n                  subMatSize, 256,\n                  sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  csr_c_idx_dev,\n                  csr_diag_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n);\n            RL_onecol_cleartmpMem(\n                1, 256,\n                sym_c_ptr_dev,\n                sym_r_idx_dev,\n                l_col_ptr_dev,\n                currentCol,\n                tmpMem,\n                j,\n                n);\n          }\n        }\n      }\n    }\n  }\n  t.elapsedUserTime(utime);\n  out << \"Total LU kernel execution time: \" << utime << \" ms\" << std::endl;\n\n  #pragma omp target update from (val_dev[0:nnz])\n\n#ifdef VERIFY\n  \n\n  unsigned err_find = 0;\n  for(unsigned i = 0; i < nnz; i++)\n    if(isnan(A_sym.val[i]) || isinf(A_sym.val[i])) \n      err_find++;\n\n  if (err_find != 0)\n    err << \"LU data check: NaN found!!\" << std::endl;\n#endif\n\n  } \n\n  free(tmpMem);\n}\n"}}
{"kernel_name": "slu", "parallel_api": "serial", "code": {"numeric.cpp": "#include <iostream>\n#include <cmath>\n#include \"symbolic.h\"\n#include \"Timer.h\"\n\nusing namespace std;\n\n#define TMPMEMNUM  10353\n#define Nstreams   16\n\nvoid RL(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned* __restrict__ csr_r_ptr_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const int* __restrict__ level_idx_dev,\n    REAL* __restrict__ tmpMem,\n    const unsigned n,\n    const int levelHead,\n    const int inLevPos)\n{\n    {\n    REAL s[32];\n        {\n      const int tid = omp_get_thread_num();\n      const int bid = omp_get_team_num();\n      const int wid = omp_get_thread_num() / 32;\n\n      const unsigned currentCol = level_idx_dev[levelHead+inLevPos+bid];\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      \n\n\n      int offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n          val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n          tmpMem[bid*n + ridx]= val_dev[currentLPos + offset];\n        }\n        offset += omp_get_num_threads();\n      }\n      \n      \n\n      const unsigned subColPos = csr_diag_ptr_dev[currentCol] + wid + 1;\n      const unsigned subMatSize = csr_r_ptr_dev[currentCol + 1] - csr_diag_ptr_dev[currentCol] - 1;\n      unsigned subCol;\n      const int tidInWarp = omp_get_thread_num() % 32;\n      unsigned subColElem = 0;\n\n      int woffset = 0;\n      while (subMatSize > woffset)\n      {\n        if (wid + woffset < subMatSize)\n        {\n          offset = 0;\n          subCol = csr_c_idx_dev[subColPos + woffset];\n          while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n          {\n            if (tidInWarp + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n            {\n\n              subColElem = sym_c_ptr_dev[subCol] + tidInWarp + offset;\n              unsigned ridx = sym_r_idx_dev[subColElem];\n\n              if (ridx == currentCol)\n              {\n                s[wid] = val_dev[subColElem];\n              }\n              \n\n              \n\n              if (ridx > currentCol)\n              {\n                \n\n                \n\n                                val_dev[subColElem] += -tmpMem[ridx+n*bid]*s[wid];\n              }\n            }\n            offset += 32;\n          }\n        }\n        woffset += omp_get_num_threads()/32;\n      }\n\n            \n\n      offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n          tmpMem[bid*n + ridx]= 0;\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_perturb(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned* __restrict__ csr_r_ptr_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const int* __restrict__ level_idx_dev,\n    REAL* __restrict__ tmpMem,\n    const unsigned n,\n    const int levelHead,\n    const int inLevPos,\n    const float pert)\n{\n    {\n    REAL s[32];\n        {\n      const int tid = omp_get_thread_num();\n      const int bid = omp_get_team_num();\n      const int wid = omp_get_thread_num() / 32;\n\n      const unsigned currentCol = level_idx_dev[levelHead+inLevPos+bid];\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      \n\n\n      int offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n          if (abs(val_dev[l_col_ptr_dev[currentCol]]) < pert)\n            val_dev[l_col_ptr_dev[currentCol]] = pert;\n\n          val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n          tmpMem[bid*n + ridx]= val_dev[currentLPos + offset];\n        }\n        offset += omp_get_num_threads();\n      }\n      \n      \n\n      const unsigned subColPos = csr_diag_ptr_dev[currentCol] + wid + 1;\n      const unsigned subMatSize = csr_r_ptr_dev[currentCol + 1] - csr_diag_ptr_dev[currentCol] - 1;\n      unsigned subCol;\n      const int tidInWarp = omp_get_thread_num() % 32;\n      unsigned subColElem = 0;\n\n      int woffset = 0;\n      while (subMatSize > woffset)\n      {\n        if (wid + woffset < subMatSize)\n        {\n          offset = 0;\n          subCol = csr_c_idx_dev[subColPos + woffset];\n          while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n          {\n            if (tidInWarp + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n            {\n\n              subColElem = sym_c_ptr_dev[subCol] + tidInWarp + offset;\n              unsigned ridx = sym_r_idx_dev[subColElem];\n\n              if (ridx == currentCol)\n              {\n                s[wid] = val_dev[subColElem];\n              }\n              \n\n              \n\n              if (ridx > currentCol)\n              {\n                \n\n                \n\n                                val_dev[subColElem] += -tmpMem[ridx+n*bid]*s[wid];\n              }\n            }\n            offset += 32;\n          }\n        }\n        woffset += omp_get_num_threads()/32;\n      }\n\n            \n\n      offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n          tmpMem[bid*n + ridx]= 0;\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_onecol_factorizeCurrentCol(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n    {\n        {\n      const int tid = omp_get_thread_num();\n\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      \n\n\n      int offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n          val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n          tmpMem[stream * n + ridx]= val_dev[currentLPos + offset];\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_onecol_factorizeCurrentCol_perturb(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n,\n    const float pert)\n{\n    {\n        {\n      const int tid = omp_get_thread_num();\n\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      \n\n\n      int offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n          if (abs(val_dev[l_col_ptr_dev[currentCol]]) < pert)\n            val_dev[l_col_ptr_dev[currentCol]] = pert;\n\n          val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n          tmpMem[stream * n + ridx]= val_dev[currentLPos + offset];\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_onecol_updateSubmat(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n    {\n    REAL s;\n        {\n      const int tid = omp_get_thread_num();\n      const int bid = omp_get_team_num();\n\n      \n\n      const unsigned subColPos = csr_diag_ptr_dev[currentCol] + bid + 1;\n      unsigned subColElem = 0;\n      unsigned ridx;\n\n      int offset = 0;\n      unsigned subCol = csr_c_idx_dev[subColPos];\n      const int range = sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol];\n      while(offset < range)\n      {\n        if (tid + offset < range)\n        {\n          subColElem = sym_c_ptr_dev[subCol] + tid + offset;\n          ridx = sym_r_idx_dev[subColElem];\n\n          if (ridx == currentCol)\n          {\n            s = val_dev[subColElem];\n          }\n        }\n        \n        if (tid + offset < range)\n        {\n          if (ridx > currentCol)\n          {\n                        val_dev[subColElem] += -tmpMem[stream * n + ridx] * s;\n          }\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid RL_onecol_cleartmpMem(\n    const int nteams,\n    const int nthreads,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n    {\n        {\n      const int tid = omp_get_thread_num();\n\n      const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n      const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n      unsigned offset = 0;\n      while (currentLColSize > offset)\n      {\n        if (tid + offset < currentLColSize)\n        {\n          unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n          tmpMem[stream * n + ridx]= 0;\n        }\n        offset += omp_get_num_threads();\n      }\n    }\n  }\n}\n\nvoid LUonDevice(Symbolic_Matrix &A_sym, ostream &out, ostream &err, bool PERTURB)\n{\n  unsigned n = A_sym.n;\n  unsigned nnz = A_sym.nnz;\n  unsigned num_lev = A_sym.num_lev;\n\n  unsigned *sym_c_ptr_dev = &(A_sym.sym_c_ptr[0]);\n  unsigned *sym_r_idx_dev = &(A_sym.sym_r_idx[0]);\n  REAL *val_dev = &(A_sym.val[0]);\n  unsigned *l_col_ptr_dev = &(A_sym.l_col_ptr[0]);\n  unsigned *csr_r_ptr_dev = &(A_sym.csr_r_ptr[0]);\n  unsigned *csr_c_idx_dev = &(A_sym.csr_c_idx[0]);\n  unsigned *csr_diag_ptr_dev = &(A_sym.csr_diag_ptr[0]);\n  int *level_idx_dev = &(A_sym.level_idx[0]);\n  REAL *tmpMem = (REAL*) malloc (TMPMEMNUM*n*sizeof(REAL));\n\n    {\n\n    for (int i = 0; i < TMPMEMNUM*n; i++)\n    tmpMem[i] = (REAL)0;\n\n  \n\n  float pert = 0;\n  if (PERTURB)\n  {\n    float norm_A = 0;\n    for (unsigned i = 0; i < n; ++i)\n    {\n      float tmp = 0;\n      for (unsigned j = A_sym.sym_c_ptr[i]; j < A_sym.sym_c_ptr[i+1]; ++j)\n        tmp += abs(A_sym.val[j]);\n      if (norm_A < tmp)\n        norm_A = tmp;\n    }\n    pert = 3.45e-4 * norm_A;\n    out << \"Gaussian elimination with static pivoting (GESP)...\" << endl;\n    out << \"1-Norm of A matrix is \" << norm_A << \", Perturbation value is \" << pert << endl;\n  }\n\n  Timer t;\n  double utime;\n  t.start();\n  for (unsigned i = 0; i < num_lev; ++i)\n  {\n    int l = A_sym.level_ptr[i];\n    int lev_size = A_sym.level_ptr[i + 1] - l;\n\n    if (lev_size > 896) { \n\n      int dimBlock = 64;\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        int dimGrid = restCol;\n        if (!PERTURB)\n          RL(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM);\n        else\n          RL_perturb(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else if (lev_size > 448) {\n      int dimBlock = 128;\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        int dimGrid = restCol;\n        if (!PERTURB)\n          RL(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM);\n        else\n          RL_perturb(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else if (lev_size > Nstreams) {\n      int dimBlock = 256;\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        int dimGrid = restCol;\n        if (!PERTURB)\n          RL(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM);\n        else\n          RL_perturb(\n              dimGrid, dimBlock,\n              sym_c_ptr_dev,\n              sym_r_idx_dev,\n              val_dev,\n              l_col_ptr_dev,\n              csr_r_ptr_dev,\n              csr_c_idx_dev,\n              csr_diag_ptr_dev,\n              level_idx_dev,\n              tmpMem,\n              n,\n              l,\n              j*TMPMEMNUM,\n              pert);\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else { \n\n      for (int offset = 0; offset < lev_size; offset += Nstreams) {\n        for (int j = 0; j < Nstreams; j++) {\n          if (j + offset < lev_size) {\n            const unsigned currentCol = A_sym.level_idx[A_sym.level_ptr[i] + j + offset];\n            const unsigned subMatSize = A_sym.csr_r_ptr[currentCol + 1]\n              - A_sym.csr_diag_ptr[currentCol] - 1;\n\n            if (!PERTURB)\n              RL_onecol_factorizeCurrentCol(\n                  1, 256,\n                  sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  l_col_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n);\n            else\n              RL_onecol_factorizeCurrentCol_perturb(\n                  1, 256,\n                  sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  l_col_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n,\n                  pert);\n            if (subMatSize > 0)\n              RL_onecol_updateSubmat(\n                  subMatSize, 256,\n                  sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  val_dev,\n                  csr_c_idx_dev,\n                  csr_diag_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n);\n            RL_onecol_cleartmpMem(\n                1, 256,\n                sym_c_ptr_dev,\n                sym_r_idx_dev,\n                l_col_ptr_dev,\n                currentCol,\n                tmpMem,\n                j,\n                n);\n          }\n        }\n      }\n    }\n  }\n  t.elapsedUserTime(utime);\n  out << \"Total LU kernel execution time: \" << utime << \" ms\" << std::endl;\n\n  \n#ifdef VERIFY\n  \n\n  unsigned err_find = 0;\n  for(unsigned i = 0; i < nnz; i++)\n    if(isnan(A_sym.val[i]) || isinf(A_sym.val[i])) \n      err_find++;\n\n  if (err_find != 0)\n    err << \"LU data check: NaN found!!\" << std::endl;\n#endif\n\n  } \n\n  free(tmpMem);\n}"}}
{"kernel_name": "slu", "parallel_api": "sycl", "code": {"numeric.cpp": "#include <iostream>\n#include <cmath>\n#include \"symbolic.h\"\n#include \"Timer.h\"\n#include <sycl/sycl.hpp>\n\n#define TMPMEMNUM  10353\n\n#define Nstreams 16\n\nvoid RL(\n    sycl::nd_item<1> &item,\n    REAL* __restrict__ s,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned* __restrict__ csr_r_ptr_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const int* __restrict__ level_idx_dev,\n    REAL* __restrict__ tmpMem,\n    const unsigned n,\n    const int levelHead,\n    const int inLevPos)\n{\n  const int tid = item.get_local_id(0);\n  const int bid = item.get_group(0);\n  const int wid = item.get_local_id(0) / 32;\n\n  const unsigned currentCol = level_idx_dev[levelHead+inLevPos+bid];\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n\n  \n\n\n  int offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n      val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n      tmpMem[bid*n + ridx]= val_dev[currentLPos + offset];\n    }\n    offset += item.get_local_range(0);\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  const unsigned subColPos = csr_diag_ptr_dev[currentCol] + wid + 1;\n  const unsigned subMatSize = csr_r_ptr_dev[currentCol + 1] - csr_diag_ptr_dev[currentCol] - 1;\n  unsigned subCol;\n  const int tidInWarp = item.get_local_id(0) % 32;\n  unsigned subColElem = 0;\n\n  int woffset = 0;\n  while (subMatSize > woffset)\n  {\n    if (wid + woffset < subMatSize)\n    {\n      offset = 0;\n      subCol = csr_c_idx_dev[subColPos + woffset];\n      while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n      {\n        if (tidInWarp + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n        {\n\n          subColElem = sym_c_ptr_dev[subCol] + tidInWarp + offset;\n          unsigned ridx = sym_r_idx_dev[subColElem];\n\n          if (ridx == currentCol)\n          {\n            s[wid] = val_dev[subColElem];\n          }\n          \n\n          \n\n          if (ridx > currentCol)\n          {\n            \n\n            \n\n            auto val_ref = sycl::atomic_ref<REAL,\n                           sycl::memory_order::relaxed,\n                           sycl::memory_scope::device,\n                           sycl::access::address_space::global_space> (val_dev[subColElem]);\n            val_ref.fetch_add(-tmpMem[ridx+n*bid]*s[wid]);\n          }\n        }\n        offset += 32;\n      }\n    }\n    woffset += item.get_local_range(0)/32;\n  }\n\n  item.barrier(sycl::access::fence_space::local_space);\n  \n\n  offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n      tmpMem[bid*n + ridx]= 0;\n    }\n    offset += item.get_local_range(0);\n  }\n}\n\nvoid RL_perturb(\n    sycl::nd_item<1> &item,\n    REAL* __restrict__ s,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned* __restrict__ csr_r_ptr_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const int* __restrict__ level_idx_dev,\n    REAL* __restrict__ tmpMem,\n    const unsigned n,\n    const int levelHead,\n    const int inLevPos,\n    const float pert)\n{\n  const int tid = item.get_local_id(0);\n  const int bid = item.get_group(0);\n  const int wid = item.get_local_id(0) / 32;\n\n  const unsigned currentCol = level_idx_dev[levelHead+inLevPos+bid];\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  \n\n\n  int offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n      if (abs(val_dev[l_col_ptr_dev[currentCol]]) < pert)\n        val_dev[l_col_ptr_dev[currentCol]] = pert;\n\n      val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n      tmpMem[bid*n + ridx]= val_dev[currentLPos + offset];\n    }\n    offset += item.get_local_range(0);\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  const unsigned subColPos = csr_diag_ptr_dev[currentCol] + wid + 1;\n  const unsigned subMatSize = csr_r_ptr_dev[currentCol + 1] - csr_diag_ptr_dev[currentCol] - 1;\n  unsigned subCol;\n  const int tidInWarp = item.get_local_id(0) % 32;\n  unsigned subColElem = 0;\n\n  int woffset = 0;\n  while (subMatSize > woffset)\n  {\n    if (wid + woffset < subMatSize)\n    {\n      offset = 0;\n      subCol = csr_c_idx_dev[subColPos + woffset];\n      while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n      {\n        if (tidInWarp + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n        {\n\n          subColElem = sym_c_ptr_dev[subCol] + tidInWarp + offset;\n          unsigned ridx = sym_r_idx_dev[subColElem];\n\n          if (ridx == currentCol)\n          {\n            s[wid] = val_dev[subColElem];\n          }\n          \n\n          \n\n          if (ridx > currentCol)\n          {\n            \n\n            \n\n            auto val_ref = sycl::atomic_ref<REAL,\n                           sycl::memory_order::relaxed,\n                           sycl::memory_scope::device,\n                           sycl::access::address_space::global_space> (val_dev[subColElem]);\n            val_ref.fetch_add(-tmpMem[ridx+n*bid]*s[wid]);\n          }\n        }\n        offset += 32;\n      }\n    }\n    woffset += item.get_local_range(0)/32;\n  }\n\n  item.barrier(sycl::access::fence_space::local_space);\n  \n\n  offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n      tmpMem[bid*n + ridx]= 0;\n    }\n    offset += item.get_local_range(0);\n  }\n}\n\nvoid RL_onecol_factorizeCurrentCol(\n    sycl::nd_item<1> &item,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  const int tid = item.get_local_id(0);\n\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  \n\n\n  int offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n      val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n      tmpMem[stream * n + ridx]= val_dev[currentLPos + offset];\n    }\n    offset += item.get_local_range(0);\n  }\n}\n\nvoid RL_onecol_factorizeCurrentCol_perturb(\n    sycl::nd_item<1> &item,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n,\n    const float pert)\n{\n  const int tid = item.get_local_id(0);\n\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  \n\n\n  int offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n\n      if (abs(val_dev[l_col_ptr_dev[currentCol]]) < pert)\n        val_dev[l_col_ptr_dev[currentCol]] = pert;\n\n      val_dev[currentLPos + offset] /= val_dev[l_col_ptr_dev[currentCol]];\n      tmpMem[stream * n + ridx]= val_dev[currentLPos + offset];\n    }\n    offset += item.get_local_range(0);\n  }\n}\n\nvoid RL_onecol_updateSubmat(\n    sycl::nd_item<1> &item,\n    REAL* __restrict__ s,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    REAL* __restrict__ val_dev,\n    const unsigned* __restrict__ csr_c_idx_dev,\n    const unsigned* __restrict__ csr_diag_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  const int tid = item.get_local_id(0);\n  const int bid = item.get_group(0);\n\n  \n\n  const unsigned subColPos = csr_diag_ptr_dev[currentCol] + bid + 1;\n  unsigned subCol;\n  unsigned subColElem = 0;\n\n  int offset = 0;\n  subCol = csr_c_idx_dev[subColPos];\n  while(offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n  {\n    if (tid + offset < sym_c_ptr_dev[subCol + 1] - sym_c_ptr_dev[subCol])\n    {\n      subColElem = sym_c_ptr_dev[subCol] + tid + offset;\n      unsigned ridx = sym_r_idx_dev[subColElem];\n\n      if (ridx == currentCol)\n      {\n        s[0] = val_dev[subColElem];\n      }\n      item.barrier(sycl::access::fence_space::local_space);\n      if (ridx > currentCol)\n      {\n        auto val_ref = sycl::atomic_ref<REAL,\n                       sycl::memory_order::relaxed,\n                       sycl::memory_scope::device,\n                       sycl::access::address_space::global_space> (val_dev[subColElem]);\n        val_ref.fetch_add(-tmpMem[stream * n + ridx]*s[0]);\n      }\n    }\n    offset += item.get_local_range(0);\n  }\n}\n\nvoid RL_onecol_cleartmpMem(\n    sycl::nd_item<1> &item,\n    const unsigned* __restrict__ sym_c_ptr_dev,\n    const unsigned* __restrict__ sym_r_idx_dev,\n    const unsigned* __restrict__ l_col_ptr_dev,\n    const unsigned currentCol,\n    REAL* __restrict__ tmpMem,\n    const int stream,\n    const unsigned n)\n{\n  const int tid = item.get_local_id(0);\n\n  const unsigned currentLColSize = sym_c_ptr_dev[currentCol + 1] - l_col_ptr_dev[currentCol] - 1;\n  const unsigned currentLPos = l_col_ptr_dev[currentCol] + tid + 1;\n\n  unsigned offset = 0;\n  while (currentLColSize > offset)\n  {\n    if (tid + offset < currentLColSize)\n    {\n      unsigned ridx = sym_r_idx_dev[currentLPos + offset];\n      tmpMem[stream * n + ridx]= 0;\n    }\n    offset += item.get_local_range(0);\n  }\n}\n\nvoid LUonDevice(Symbolic_Matrix &A_sym, std::ostream &out, std::ostream &err, bool PERTURB)\n{\n  unsigned n = A_sym.n;\n  unsigned nnz = A_sym.nnz;\n  unsigned num_lev = A_sym.num_lev;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  unsigned *sym_c_ptr_dev = sycl::malloc_device<unsigned>(n + 1, q);\n  unsigned *sym_r_idx_dev = sycl::malloc_device<unsigned>(nnz, q );\n      REAL *      val_dev = sycl::malloc_device<REAL>(nnz, q);\n  unsigned *l_col_ptr_dev = sycl::malloc_device<unsigned>(n, q);\n  unsigned *csr_r_ptr_dev = sycl::malloc_device<unsigned>(n + 1, q);\n  unsigned *csr_c_idx_dev = sycl::malloc_device<unsigned>(nnz, q);\n  unsigned *csr_diag_ptr_dev = sycl::malloc_device<unsigned>(n, q);\n       int *level_idx_dev = sycl::malloc_device<int>(n, q);\n\n  q.memcpy(sym_c_ptr_dev, &(A_sym.sym_c_ptr[0]), (n + 1) * sizeof(unsigned));\n  q.memcpy(sym_r_idx_dev, &(A_sym.sym_r_idx[0]), nnz * sizeof(unsigned));\n  q.memcpy(val_dev, &(A_sym.val[0]), nnz * sizeof(REAL));\n  q.memcpy(l_col_ptr_dev, &(A_sym.l_col_ptr[0]), n * sizeof(unsigned));\n  q.memcpy(csr_r_ptr_dev, &(A_sym.csr_r_ptr[0]), (n + 1) * sizeof(unsigned));\n  q.memcpy(csr_c_idx_dev, &(A_sym.csr_c_idx[0]), nnz * sizeof(unsigned));\n  q.memcpy(csr_diag_ptr_dev, &(A_sym.csr_diag_ptr[0]), n * sizeof(unsigned));\n  q.memcpy(level_idx_dev, &(A_sym.level_idx[0]), n * sizeof(int));\n\n  REAL *tmpMem = sycl::malloc_device<REAL>(TMPMEMNUM * n, q);\n  q.memset(tmpMem, 0, TMPMEMNUM*n*sizeof(REAL));\n\n  \n\n  float pert = 0;\n  if (PERTURB)\n  {\n    float norm_A = 0;\n    for (unsigned i = 0; i < n; ++i)\n    {\n      float tmp = 0;\n      for (unsigned j = A_sym.sym_c_ptr[i]; j < A_sym.sym_c_ptr[i+1]; ++j)\n        tmp += abs(A_sym.val[j]);\n      if (norm_A < tmp)\n        norm_A = tmp;\n    }\n    pert = 3.45e-4 * norm_A;\n    out << \"Gaussian elimination with static pivoting (GESP)...\" << std::endl;\n    out << \"1-Norm of A matrix is \" << norm_A << \", Perturbation value is \" << pert << std::endl;\n  }\n\n  q.wait();\n\n  Timer t;\n  double utime;\n  t.start();\n  for (unsigned i = 0; i < num_lev; ++i)\n  {\n    \n\n    \n\n    int l = A_sym.level_ptr[i];\n\n    int lev_size = A_sym.level_ptr[i + 1] - l;\n\n    if (lev_size > 896) { \n\n      unsigned WarpsPerBlock = 2;\n      sycl::range<1> lws (WarpsPerBlock * 32);\n\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        sycl::range<1> gws (restCol * WarpsPerBlock * 32);\n        if (!PERTURB)\n          q.submit([&] (sycl::handler &cgh) {\n            sycl::local_accessor<REAL> sm (sycl::range<1>(WarpsPerBlock), cgh);\n            cgh.parallel_for<class RLk>(\n              sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n              RL(item,\n                 sm.get_pointer(),\n                 sym_c_ptr_dev,\n                 sym_r_idx_dev,\n                 val_dev,\n                 l_col_ptr_dev,\n                 csr_r_ptr_dev,\n                 csr_c_idx_dev,\n                 csr_diag_ptr_dev,\n                 level_idx_dev,\n                 tmpMem,\n                 n,\n                 l,\n                 j*TMPMEMNUM);\n            });\n          });\n        else\n          q.submit([&] (sycl::handler &cgh) {\n            sycl::local_accessor<REAL> sm (sycl::range<1>(WarpsPerBlock), cgh);\n            cgh.parallel_for<class RL_pk>(\n              sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n              RL_perturb(\n                item,\n                sm.get_pointer(),\n                sym_c_ptr_dev,\n                sym_r_idx_dev,\n                val_dev,\n                l_col_ptr_dev,\n                csr_r_ptr_dev,\n                csr_c_idx_dev,\n                csr_diag_ptr_dev,\n                level_idx_dev,\n                tmpMem,\n                n,\n                l,\n                j*TMPMEMNUM,\n                pert);\n            });\n          });\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else if (lev_size > 448) {\n      unsigned WarpsPerBlock = 4;\n      sycl::range<1> lws (WarpsPerBlock * 32);\n\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        sycl::range<1> gws (restCol * WarpsPerBlock * 32);\n        if (!PERTURB)\n          q.submit([&] (sycl::handler &cgh) {\n            sycl::local_accessor<REAL> sm (sycl::range<1>(WarpsPerBlock), cgh);\n            cgh.parallel_for<class RLk2>(\n              sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n              RL(item,\n                 sm.get_pointer(),\n                 sym_c_ptr_dev,\n                 sym_r_idx_dev,\n                 val_dev,\n                 l_col_ptr_dev,\n                 csr_r_ptr_dev,\n                 csr_c_idx_dev,\n                 csr_diag_ptr_dev,\n                 level_idx_dev,\n                 tmpMem,\n                 n,\n                 l,\n                 j*TMPMEMNUM);\n            });\n          });\n        else\n          q.submit([&] (sycl::handler &cgh) {\n            sycl::local_accessor<REAL> sm (sycl::range<1>(WarpsPerBlock), cgh);\n            cgh.parallel_for<class RL_pk2>(\n              sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n              RL_perturb(\n                item,\n                sm.get_pointer(),\n                sym_c_ptr_dev,\n                sym_r_idx_dev,\n                val_dev,\n                l_col_ptr_dev,\n                csr_r_ptr_dev,\n                csr_c_idx_dev,\n                csr_diag_ptr_dev,\n                level_idx_dev,\n                tmpMem,\n                n,\n                l,\n                j*TMPMEMNUM,\n                pert);\n            });\n          });\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else if (lev_size > Nstreams) {\n      unsigned WarpsPerBlock = 32;\n      sycl::range<1> lws (256);\n      unsigned j = 0;\n      while(lev_size > 0) {\n        unsigned restCol = lev_size > TMPMEMNUM ? TMPMEMNUM : lev_size;\n        sycl::range<1> gws (restCol * 256);\n        if (!PERTURB)\n          q.submit([&] (sycl::handler &cgh) {\n            sycl::local_accessor<REAL> sm (sycl::range<1>(WarpsPerBlock), cgh);\n            cgh.parallel_for<class RLk3>(\n              sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n              RL(item,\n                 sm.get_pointer(),\n                 sym_c_ptr_dev,\n                 sym_r_idx_dev,\n                 val_dev,\n                 l_col_ptr_dev,\n                 csr_r_ptr_dev,\n                 csr_c_idx_dev,\n                 csr_diag_ptr_dev,\n                 level_idx_dev,\n                 tmpMem,\n                 n,\n                 l,\n                 j*TMPMEMNUM);\n            });\n          });\n        else\n          q.submit([&] (sycl::handler &cgh) {\n            sycl::local_accessor<REAL> sm (sycl::range<1>(WarpsPerBlock), cgh);\n            cgh.parallel_for<class RL_pk3>(\n              sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n              RL_perturb(\n                item,\n                sm.get_pointer(),\n                sym_c_ptr_dev,\n                sym_r_idx_dev,\n                val_dev,\n                l_col_ptr_dev,\n                csr_r_ptr_dev,\n                csr_c_idx_dev,\n                csr_diag_ptr_dev,\n                level_idx_dev,\n                tmpMem,\n                n,\n                l,\n                j*TMPMEMNUM,\n                pert);\n             });\n           });\n        j++;\n        lev_size -= TMPMEMNUM;\n      }\n    }\n    else { \n\n      for (int offset = 0; offset < lev_size; offset += Nstreams) {\n        for (int j = 0; j < Nstreams; j++) {\n          if (j + offset < lev_size) {\n            const unsigned currentCol = A_sym.level_idx[A_sym.level_ptr[i] + j + offset];\n            const unsigned subMatSize = A_sym.csr_r_ptr[currentCol + 1]\n              - A_sym.csr_diag_ptr[currentCol] - 1;\n\n            if (!PERTURB)\n              q.submit([&] (sycl::handler &cgh) {\n                cgh.parallel_for<class factorizeCol>(\n                  sycl::nd_range<1>(256, 256), [=] (sycl::nd_item<1> item) {\n                  RL_onecol_factorizeCurrentCol(\n                    item,\n                    sym_c_ptr_dev,\n                    sym_r_idx_dev,\n                    val_dev,\n                    l_col_ptr_dev,\n                    currentCol,\n                    tmpMem,\n                    j,\n                    n);\n                });\n              });\n            else\n              q.submit([&] (sycl::handler &cgh) {\n                cgh.parallel_for<class factorizeColPerturb>(\n                  sycl::nd_range<1>(256, 256), [=] (sycl::nd_item<1> item) {\n                  RL_onecol_factorizeCurrentCol_perturb(\n                    item,\n                    sym_c_ptr_dev,\n                    sym_r_idx_dev,\n                    val_dev,\n                    l_col_ptr_dev,\n                    currentCol,\n                    tmpMem,\n                    j,\n                    n,\n                    pert);\n                });\n              });\n\n            if (subMatSize > 0)\n              q.submit([&] (sycl::handler &cgh) {\n                sycl::local_accessor<REAL> sm (1, cgh);\n                cgh.parallel_for<class update>(\n                  sycl::nd_range<1>(256*subMatSize, 256), [=] (sycl::nd_item<1> item) {\n                  RL_onecol_updateSubmat(\n                    item,\n                    sm.get_pointer(),\n                    sym_c_ptr_dev,\n                    sym_r_idx_dev,\n                    val_dev,\n                    csr_c_idx_dev,\n                    csr_diag_ptr_dev,\n                    currentCol,\n                    tmpMem,\n                    j,\n                    n);\n                });\n              });\n\n            q.submit([&] (sycl::handler &cgh) {\n              cgh.parallel_for<class clearMem>(\n                sycl::nd_range<1>(256, 256), [=] (sycl::nd_item<1> item) {\n                RL_onecol_cleartmpMem(\n                  item,\n                  sym_c_ptr_dev,\n                  sym_r_idx_dev,\n                  l_col_ptr_dev,\n                  currentCol,\n                  tmpMem,\n                  j,\n                  n);\n              });\n            });\n          }\n        }\n      }\n    }\n  }\n\n  q.wait();\n  t.elapsedUserTime(utime);\n  out << \"Total LU kernel execution time: \" << utime << \" ms\" << std::endl;\n\n  \n\n  q.memcpy(&(A_sym.val[0]), val_dev, nnz * sizeof(REAL)).wait();\n\n#ifdef VERIFY\n  \n\n  unsigned err_find = 0;\n  for(unsigned i = 0; i < nnz; i++)\n    if(std::isnan(A_sym.val[i]) || std::isinf(A_sym.val[i]))\n      err_find++;\n\n  if (err_find != 0)\n    err << \"LU data check: NaN found!!\" << std::endl;\n#endif\n\n  sycl::free(sym_c_ptr_dev, q);\n  sycl::free(sym_r_idx_dev, q);\n  sycl::free(val_dev, q);\n  sycl::free(l_col_ptr_dev, q);\n  sycl::free(csr_c_idx_dev, q);\n  sycl::free(csr_r_ptr_dev, q);\n  sycl::free(csr_diag_ptr_dev, q);\n  sycl::free(level_idx_dev, q);\n  sycl::free(tmpMem, q);\n}\n"}}
{"kernel_name": "spmv", "parallel_api": "cuda", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include \"mv.h\"\n\nint main(int argc, char *argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage %s <number of non-zero elements> <number of rows in a square matrix> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  size_t nnz = atol(argv[1]);\n  assert(nnz > 0);\n\n  size_t num_rows = atol(argv[2]);\n  assert(num_rows > 0);\n\n  int repeat = atoi(argv[3]);\n\n  size_t num_elems = num_rows * num_rows;\n  assert(nnz <= num_elems);\n\n  size_t vector_size_bytes = num_rows * sizeof(REAL);\n  size_t matrix_size_bytes = num_elems * sizeof(REAL);\n  size_t value_size_bytes  = nnz * sizeof(REAL);\n\n  REAL *values = (REAL *) malloc (value_size_bytes);\n  REAL *x = (REAL *) malloc (vector_size_bytes);\n  REAL *y_ref = (REAL *) malloc (vector_size_bytes);\n  REAL *y = (REAL *) malloc (vector_size_bytes);\n  REAL *matrix = (REAL *) malloc (matrix_size_bytes);\n\n  srand48(1<<12);\n  init_matrix(matrix, num_rows, nnz);\n  init_vector(x, num_rows);\n\n  long elapsed = reference(repeat, num_rows, x, matrix, y_ref);  \n\n  printf(\"Number of non-zero elements: %lu\\n\", nnz);\n  printf(\"Number of rows in a square matrix: %lu\\n\", num_rows);\n  printf(\"Sparsity: %lf%%\\n\", (num_elems - nnz) * 1.0 / num_elems * 100.0);\n\n  elapsed = spmv_csr(repeat, num_rows, x, nnz, matrix, y);\n  printf(\"Average kernel (CSR) execution time (ms): %lf\\n\", elapsed * 1e-6 / repeat);\n  printf(\"Error rate: %f\\n\", check(y, y_ref, num_rows));\n\n  elapsed = spmv_coo(repeat, num_rows, x, nnz, matrix, y);\n  printf(\"Average kernel (COO) execution time (ms): %lf\\n\", elapsed * 1e-6 / repeat);\n  printf(\"Error rate: %f\\n\", check(y, y_ref, num_rows));\n\n  free(values);\n  free(x);\n  free(y);\n  free(y_ref);\n  free(matrix);\n  return 0;\n}\n", "kernels.cu": "#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n#include <cusparse.h>\n#include \"mv.h\"\n\n\n\n__global__ void mv_dense(const size_t num_rows, const REAL* matrix, const REAL* x, REAL* y)\n{\n  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < num_rows) {\n    REAL temp = 0;\n    for (size_t j = 0; j < num_rows; j++) {\n      if (matrix[i * num_rows + j] != (REAL)0) \n        temp += matrix[i * num_rows + j] * x[j];\n    }\n    y[i] = temp;\n  }\n}\n\nlong reference(const int repeat,\n               const size_t num_rows,\n               const REAL* x,\n               REAL* matrix,\n               REAL* y)\n{\n  REAL *d_x, *d_matrix, *d_y;\n  cudaMalloc(&d_x, num_rows*sizeof(REAL));\n  cudaMalloc(&d_matrix, num_rows * num_rows * sizeof(REAL));\n  cudaMalloc(&d_y, num_rows*sizeof(REAL));\n\n  cudaMemcpy(d_x, x, num_rows*sizeof(REAL), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_matrix, matrix, num_rows*num_rows*sizeof(REAL), cudaMemcpyHostToDevice);\n\n  dim3 grids ((num_rows + 256 - 1) / 256);\n  dim3 blocks (256);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    mv_dense<<<grids, blocks>>>(num_rows, d_matrix, d_x, d_y);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  cudaMemcpy(y, d_y, num_rows*sizeof(REAL), cudaMemcpyDeviceToHost);\n\n  cudaFree(d_x);\n  cudaFree(d_y);\n  cudaFree(d_matrix);\n\n  return time;\n}\n\n#define CHECK_CUSPARSE(func)                                                   \\\n{                                                                              \\\n    cusparseStatus_t status = (func);                                          \\\n    if (status != CUSPARSE_STATUS_SUCCESS) {                                   \\\n        printf(\"CUSPARSE API failed at line %d with error: %s (%d)\\n\",         \\\n               __LINE__, cusparseGetErrorString(status), status);              \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\nlong spmv_csr(const int repeat,\n              const size_t num_rows,\n              const REAL* x,\n              const size_t nnz,\n              REAL* matrix,\n              REAL* y)\n{\n  size_t *row_indices = (size_t *) malloc((num_rows+1) * sizeof(size_t));\n  size_t *col_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  REAL *values = (REAL *) malloc(nnz * sizeof(REAL));\n\n  \n\n  init_csr(row_indices, values, col_indices, matrix, num_rows, nnz);\n\n  size_t *d_row_indices;\n  size_t *d_col_indices;\n  REAL *d_values, *d_x, *d_y;\n\n  cudaMalloc(&d_row_indices, (num_rows+1)*sizeof(size_t));\n  cudaMalloc(&d_col_indices, nnz*sizeof(size_t));\n\n  cudaMalloc(&d_values, nnz*sizeof(REAL));\n  cudaMalloc(&d_x, num_rows*sizeof(REAL));\n  cudaMalloc(&d_y, num_rows*sizeof(REAL));\n\n  cudaMemcpy(d_row_indices, row_indices, (num_rows+1)*sizeof(size_t), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_col_indices, col_indices, nnz*sizeof(size_t), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_values, values, nnz*sizeof(REAL), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_x, x, num_rows*sizeof(REAL), cudaMemcpyHostToDevice);\n\n  cusparseHandle_t     handle = NULL;\n  cusparseSpMatDescr_t matA;\n  cusparseDnVecDescr_t vecX, vecY;\n  const cudaDataType DT = (sizeof(REAL) == 4) ? CUDA_R_32F : CUDA_R_64F;\n \n  void*                dBuffer    = NULL;\n  size_t               bufferSize = 0;\n  REAL                 alpha      = 1.f;\n  REAL                 beta       = 0.f;\n  CHECK_CUSPARSE( cusparseCreate(&handle) )\n\n  \n\n  CHECK_CUSPARSE( cusparseCreateCsr(&matA, num_rows, num_rows, nnz,\n                                    d_row_indices, d_col_indices, d_values,\n                                    CUSPARSE_INDEX_64I, CUSPARSE_INDEX_64I,\n                                    CUSPARSE_INDEX_BASE_ZERO, DT) )\n  \n\n  CHECK_CUSPARSE( cusparseCreateDnVec(&vecX, num_rows, d_x, DT) )\n  \n\n  CHECK_CUSPARSE( cusparseCreateDnVec(&vecY, num_rows, d_y, DT) )\n  \n\n  CHECK_CUSPARSE( cusparseSpMV_bufferSize(\n                               handle, CUSPARSE_OPERATION_NON_TRANSPOSE,\n                               &alpha, matA, vecX, &beta, vecY, DT,\n                               CUSPARSE_SPMV_ALG_DEFAULT, &bufferSize) )\n  cudaMalloc(&dBuffer, bufferSize);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    CHECK_CUSPARSE( cusparseSpMV(handle, CUSPARSE_OPERATION_NON_TRANSPOSE,\n                                 &alpha, matA, vecX, &beta, vecY, DT,\n                                 CUSPARSE_SPMV_ALG_DEFAULT, dBuffer) )\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  \n\n  CHECK_CUSPARSE( cusparseDestroySpMat(matA) )\n  CHECK_CUSPARSE( cusparseDestroyDnVec(vecX) )\n  CHECK_CUSPARSE( cusparseDestroyDnVec(vecY) )\n  CHECK_CUSPARSE( cusparseDestroy(handle) )\n\n  cudaMemcpy(y, d_y, num_rows*sizeof(REAL), cudaMemcpyDeviceToHost);\n\n  free(values);\n  free(row_indices);\n  free(col_indices);\n\n  cudaFree(d_row_indices);\n  cudaFree(d_col_indices);\n  cudaFree(d_values);\n  cudaFree(d_x);\n  cudaFree(d_y);\n\n  return time;\n}\n\nlong spmv_coo(const int repeat,\n              const size_t num_rows,\n              const REAL* x,\n              const size_t nnz,\n              REAL* matrix,\n              REAL* y)\n{\n  size_t *row_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  size_t *col_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  REAL *values = (REAL *) malloc(nnz * sizeof(REAL));\n\n  \n\n  init_coo(row_indices, values, col_indices, matrix, num_rows, nnz);\n\n  size_t *d_row_indices;\n  size_t *d_col_indices;\n  REAL *d_values, *d_x, *d_y;\n\n  cudaMalloc(&d_row_indices, nnz*sizeof(size_t));\n  cudaMalloc(&d_col_indices, nnz*sizeof(size_t));\n\n  cudaMalloc(&d_values, nnz*sizeof(REAL));\n  cudaMalloc(&d_x, num_rows*sizeof(REAL));\n  cudaMalloc(&d_y, num_rows*sizeof(REAL));\n\n  cudaMemcpy(d_row_indices, row_indices, nnz*sizeof(size_t), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_col_indices, col_indices, nnz*sizeof(size_t), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_values, values, nnz*sizeof(REAL), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_x, x, num_rows*sizeof(REAL), cudaMemcpyHostToDevice);\n\n  cusparseHandle_t     handle = NULL;\n  cusparseSpMatDescr_t matA;\n  cusparseDnVecDescr_t vecX, vecY;\n  const cudaDataType DT = (sizeof(REAL) == 4) ? CUDA_R_32F : CUDA_R_64F;\n \n  void*                dBuffer    = NULL;\n  size_t               bufferSize = 0;\n  REAL                 alpha      = 1.f;\n  REAL                 beta       = 0.f;\n  CHECK_CUSPARSE( cusparseCreate(&handle) )\n\n  \n\n  CHECK_CUSPARSE( cusparseCreateCoo(&matA, num_rows, num_rows, nnz,\n                                    d_row_indices, d_col_indices, d_values,\n                                    CUSPARSE_INDEX_64I,\n                                    CUSPARSE_INDEX_BASE_ZERO, DT) )\n  \n\n  CHECK_CUSPARSE( cusparseCreateDnVec(&vecX, num_rows, d_x, DT) )\n  \n\n  CHECK_CUSPARSE( cusparseCreateDnVec(&vecY, num_rows, d_y, DT) )\n  \n\n  CHECK_CUSPARSE( cusparseSpMV_bufferSize(\n                               handle, CUSPARSE_OPERATION_NON_TRANSPOSE,\n                               &alpha, matA, vecX, &beta, vecY, DT,\n                               CUSPARSE_SPMV_ALG_DEFAULT, &bufferSize) )\n  cudaMalloc(&dBuffer, bufferSize);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    CHECK_CUSPARSE( cusparseSpMV(handle, CUSPARSE_OPERATION_NON_TRANSPOSE,\n                                 &alpha, matA, vecX, &beta, vecY, DT,\n                                 CUSPARSE_SPMV_ALG_DEFAULT, dBuffer) )\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  \n\n  CHECK_CUSPARSE( cusparseDestroySpMat(matA) )\n  CHECK_CUSPARSE( cusparseDestroyDnVec(vecX) )\n  CHECK_CUSPARSE( cusparseDestroyDnVec(vecY) )\n  CHECK_CUSPARSE( cusparseDestroy(handle) )\n\n  cudaMemcpy(y, d_y, num_rows*sizeof(REAL), cudaMemcpyDeviceToHost);\n\n  free(values);\n  free(row_indices);\n  free(col_indices);\n\n  cudaFree(d_row_indices);\n  cudaFree(d_col_indices);\n  cudaFree(d_values);\n  cudaFree(d_x);\n  cudaFree(d_y);\n\n  return time;\n}\n"}}
{"kernel_name": "spmv", "parallel_api": "hip", "code": {"kernels.cu": "#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include <hipsparse/hipsparse.h>\n#include \"mv.h\"\n\n\n\n__global__ void mv_dense(const size_t num_rows, const REAL* matrix, const REAL* x, REAL* y)\n{\n  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < num_rows) {\n    REAL temp = 0;\n    for (size_t j = 0; j < num_rows; j++) {\n      if (matrix[i * num_rows + j] != (REAL)0) \n        temp += matrix[i * num_rows + j] * x[j];\n    }\n    y[i] = temp;\n  }\n}\n\nlong reference(const int repeat,\n               const size_t num_rows,\n               const REAL* x,\n               REAL* matrix,\n               REAL* y)\n{\n  REAL *d_x, *d_matrix, *d_y;\n  hipMalloc(&d_x, num_rows*sizeof(REAL));\n  hipMalloc(&d_matrix, num_rows * num_rows * sizeof(REAL));\n  hipMalloc(&d_y, num_rows*sizeof(REAL));\n\n  hipMemcpy(d_x, x, num_rows*sizeof(REAL), hipMemcpyHostToDevice);\n  hipMemcpy(d_matrix, matrix, num_rows*num_rows*sizeof(REAL), hipMemcpyHostToDevice);\n\n  dim3 grids ((num_rows + 256 - 1) / 256);\n  dim3 blocks (256);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    mv_dense<<<grids, blocks>>>(num_rows, d_matrix, d_x, d_y);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  hipMemcpy(y, d_y, num_rows*sizeof(REAL), hipMemcpyDeviceToHost);\n\n  hipFree(d_x);\n  hipFree(d_y);\n  hipFree(d_matrix);\n\n  return time;\n}\n\n\n#define CHECK_HIPSPARSE(func)                                                   \\\n{                                                                              \\\n    hipsparseStatus_t status = (func);                                         \\\n    if (status != HIPSPARSE_STATUS_SUCCESS) {                                  \\\n        printf(\"HIPSPARSE API failed at line %d with error: %s (%d)\\n\",        \\\n               __LINE__, hipsparseGetErrorString(status), status);             \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\nlong spmv_csr(const int repeat,\n              const size_t num_rows,\n              const REAL* x,\n              const size_t nnz,\n              REAL* matrix,\n              REAL* y)\n{\n  size_t *row_indices = (size_t *) malloc((num_rows+1) * sizeof(size_t));\n  size_t *col_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  REAL *values = (REAL *) malloc(nnz * sizeof(REAL));\n\n  \n\n  init_csr(row_indices, values, col_indices, matrix, num_rows, nnz);\n\n  size_t *d_row_indices;\n  size_t *d_col_indices;\n  REAL *d_values, *d_x, *d_y;\n\n  hipMalloc(&d_row_indices, (num_rows+1)*sizeof(size_t));\n  hipMalloc(&d_col_indices, nnz*sizeof(size_t));\n\n  hipMalloc(&d_values, nnz*sizeof(REAL));\n  hipMalloc(&d_x, num_rows*sizeof(REAL));\n  hipMalloc(&d_y, num_rows*sizeof(REAL));\n\n  hipMemcpy(d_row_indices, row_indices, (num_rows+1)*sizeof(size_t), hipMemcpyHostToDevice);\n  hipMemcpy(d_col_indices, col_indices, nnz*sizeof(size_t), hipMemcpyHostToDevice);\n  hipMemcpy(d_values, values, nnz*sizeof(REAL), hipMemcpyHostToDevice);\n  hipMemcpy(d_x, x, num_rows*sizeof(REAL), hipMemcpyHostToDevice);\n\n  hipsparseHandle_t     handle = NULL;\n  hipsparseSpMatDescr_t matA;\n  hipsparseDnVecDescr_t vecX, vecY;\n  const hipDataType DT = (sizeof(REAL) == 4) ? HIP_R_32F : HIP_R_64F;\n \n  void*                dBuffer    = NULL;\n  size_t               bufferSize = 0;\n  REAL                 alpha      = 1.f;\n  REAL                 beta       = 0.f;\n  CHECK_HIPSPARSE( hipsparseCreate(&handle) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateCsr(&matA, num_rows, num_rows, nnz,\n                                    d_row_indices, d_col_indices, d_values,\n                                    HIPSPARSE_INDEX_64I, HIPSPARSE_INDEX_64I,\n                                    HIPSPARSE_INDEX_BASE_ZERO, DT) )\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateDnVec(&vecX, num_rows, d_x, DT) )\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateDnVec(&vecY, num_rows, d_y, DT) )\n  \n\n  CHECK_HIPSPARSE( hipsparseSpMV_bufferSize(\n                               handle, HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                               &alpha, matA, vecX, &beta, vecY, DT,\n                               HIPSPARSE_SPMV_ALG_DEFAULT, &bufferSize) )\n  hipMalloc(&dBuffer, bufferSize);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    CHECK_HIPSPARSE( hipsparseSpMV(handle, HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                                 &alpha, matA, vecX, &beta, vecY, DT,\n                                 HIPSPARSE_SPMV_ALG_DEFAULT, dBuffer) )\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  \n\n  CHECK_HIPSPARSE( hipsparseDestroySpMat(matA) )\n  CHECK_HIPSPARSE( hipsparseDestroyDnVec(vecX) )\n  CHECK_HIPSPARSE( hipsparseDestroyDnVec(vecY) )\n  CHECK_HIPSPARSE( hipsparseDestroy(handle) )\n\n  hipMemcpy(y, d_y, num_rows*sizeof(REAL), hipMemcpyDeviceToHost);\n\n  free(values);\n  free(row_indices);\n  free(col_indices);\n\n  hipFree(d_row_indices);\n  hipFree(d_col_indices);\n  hipFree(d_values);\n  hipFree(d_x);\n  hipFree(d_y);\n\n  return time;\n}\n\nlong spmv_coo(const int repeat,\n              const size_t num_rows,\n              const REAL* x,\n              const size_t nnz,\n              REAL* matrix,\n              REAL* y)\n{\n  size_t *row_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  size_t *col_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  REAL *values = (REAL *) malloc(nnz * sizeof(REAL));\n\n  \n\n  init_coo(row_indices, values, col_indices, matrix, num_rows, nnz);\n\n  size_t *d_row_indices;\n  size_t *d_col_indices;\n  REAL *d_values, *d_x, *d_y;\n\n  hipMalloc(&d_row_indices, nnz*sizeof(size_t));\n  hipMalloc(&d_col_indices, nnz*sizeof(size_t));\n\n  hipMalloc(&d_values, nnz*sizeof(REAL));\n  hipMalloc(&d_x, num_rows*sizeof(REAL));\n  hipMalloc(&d_y, num_rows*sizeof(REAL));\n\n  hipMemcpy(d_row_indices, row_indices, nnz*sizeof(size_t), hipMemcpyHostToDevice);\n  hipMemcpy(d_col_indices, col_indices, nnz*sizeof(size_t), hipMemcpyHostToDevice);\n  hipMemcpy(d_values, values, nnz*sizeof(REAL), hipMemcpyHostToDevice);\n  hipMemcpy(d_x, x, num_rows*sizeof(REAL), hipMemcpyHostToDevice);\n\n  hipsparseHandle_t     handle = NULL;\n  hipsparseSpMatDescr_t matA;\n  hipsparseDnVecDescr_t vecX, vecY;\n  const hipDataType DT = (sizeof(REAL) == 4) ? HIP_R_32F : HIP_R_64F;\n \n  void*                dBuffer    = NULL;\n  size_t               bufferSize = 0;\n  REAL                 alpha      = 1.f;\n  REAL                 beta       = 0.f;\n  CHECK_HIPSPARSE( hipsparseCreate(&handle) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateCoo(&matA, num_rows, num_rows, nnz,\n                                    d_row_indices, d_col_indices, d_values,\n                                    HIPSPARSE_INDEX_64I,\n                                    HIPSPARSE_INDEX_BASE_ZERO, DT) )\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateDnVec(&vecX, num_rows, d_x, DT) )\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateDnVec(&vecY, num_rows, d_y, DT) )\n  \n\n  CHECK_HIPSPARSE( hipsparseSpMV_bufferSize(\n                               handle, HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                               &alpha, matA, vecX, &beta, vecY, DT,\n                               HIPSPARSE_SPMV_ALG_DEFAULT, &bufferSize) )\n  hipMalloc(&dBuffer, bufferSize);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    CHECK_HIPSPARSE( hipsparseSpMV(handle, HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                                 &alpha, matA, vecX, &beta, vecY, DT,\n                                 HIPSPARSE_SPMV_ALG_DEFAULT, dBuffer) )\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  \n\n  CHECK_HIPSPARSE( hipsparseDestroySpMat(matA) )\n  CHECK_HIPSPARSE( hipsparseDestroyDnVec(vecX) )\n  CHECK_HIPSPARSE( hipsparseDestroyDnVec(vecY) )\n  CHECK_HIPSPARSE( hipsparseDestroy(handle) )\n\n  hipMemcpy(y, d_y, num_rows*sizeof(REAL), hipMemcpyDeviceToHost);\n\n  free(values);\n  free(row_indices);\n  free(col_indices);\n\n  hipFree(d_row_indices);\n  hipFree(d_col_indices);\n  hipFree(d_values);\n  hipFree(d_x);\n  hipFree(d_y);\n\n  return time;\n}\n"}}
{"kernel_name": "spmv", "parallel_api": "sycl", "code": {"kernels.cpp": "#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include <oneapi/mkl.hpp>\n#include \"mv.h\"\n\n\n\nvoid mv_dense(sycl::nd_item<1> &item,\n              const size_t num_rows,\n              const REAL* matrix,\n              const REAL* x, REAL* y)\n{\n  size_t i = item.get_global_id(0);\n  if (i < num_rows) {\n    REAL temp = 0;\n    for (size_t j = 0; j < num_rows; j++) {\n      if (matrix[i * num_rows + j] != (REAL)0)\n        temp += matrix[i * num_rows + j] * x[j];\n    }\n    y[i] = temp;\n  }\n}\n\nlong reference(const int repeat,\n               const size_t num_rows,\n               const REAL* x,\n               REAL* matrix,\n               REAL* y)\n{\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  size_t num_elems = num_rows * num_rows;\n\n  REAL *d_x, *d_matrix, *d_y;\n  d_x = sycl::malloc_device<REAL>(num_rows, q);\n  d_matrix = sycl::malloc_device<REAL>(num_elems, q);\n  d_y = sycl::malloc_device<REAL>(num_rows, q);\n\n  q.memcpy(d_x, x, num_rows*sizeof(REAL));\n  q.memcpy(d_matrix, matrix, num_elems*sizeof(REAL));\n\n  sycl::range<1> gws ((num_rows + 256 - 1) / 256 * 256);\n  sycl::range<1> lws (256);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class dmvm>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        mv_dense(item, num_rows, d_matrix, d_x, d_y);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  q.memcpy(y, d_y, num_rows*sizeof(REAL)).wait();\n\n  sycl::free(d_x, q);\n  sycl::free(d_y, q);\n  sycl::free(d_matrix, q);\n\n  return time;\n}\n\nlong spmv_csr(const int repeat,\n              const size_t num_rows,\n              const REAL* x,\n              const size_t nnz,\n              REAL* matrix,\n              REAL* y)\n{\n  size_t *row_indices = (size_t *) malloc((num_rows+1) * sizeof(size_t));\n  size_t *col_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  REAL *values = (REAL *) malloc(nnz * sizeof(REAL));\n\n  \n\n  init_csr((size_t*)row_indices, values, (size_t*)col_indices, matrix, num_rows, nnz);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  size_t *d_row_indices = sycl::malloc_device<size_t>(num_rows+1, q);\n  size_t *d_col_indices = sycl::malloc_device<size_t>(nnz, q);\n  REAL *d_values = sycl::malloc_device<REAL>(nnz, q);\n  REAL *d_x = sycl::malloc_device<REAL>(num_rows, q);\n  REAL *d_y = sycl::malloc_device<REAL>(num_rows, q);\n\n  q.memcpy(d_row_indices, row_indices, (num_rows+1)*sizeof(size_t));\n  q.memcpy(d_col_indices, col_indices, nnz*sizeof(size_t));\n  q.memcpy(d_values, values, nnz*sizeof(REAL));\n  q.memcpy(d_x, x, num_rows*sizeof(REAL));\n\n  \n\n  oneapi::mkl::sparse::matrix_handle_t handle = nullptr;\n  oneapi::mkl::sparse::init_matrix_handle(&handle);\n\n  REAL alpha = 1.f;\n  REAL beta = 0.f;\n\n  \n\n  oneapi::mkl::sparse::set_csr_data(q, handle, num_rows, num_rows, \n                                    oneapi::mkl::index_base::zero,\n                                    (int64_t*)d_row_indices, (int64_t*)d_col_indices, d_values);\n\n  \n\n  \n\n  optimize_gemv(q, oneapi::mkl::transpose::nontrans, handle).wait();\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    oneapi::mkl::sparse::gemv(q, oneapi::mkl::transpose::nontrans, alpha,\n                              handle, d_x, beta, d_y);\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  q.memcpy(y, d_y, num_rows*sizeof(REAL)).wait();\n\n  oneapi::mkl::sparse::release_matrix_handle(q, &handle).wait();\n\n  free(values);\n  free(row_indices);\n  free(col_indices);\n\n  sycl::free(d_row_indices, q);\n  sycl::free(d_col_indices, q);\n  sycl::free(d_values, q);\n  sycl::free(d_x, q);\n  sycl::free(d_y, q);\n\n  return time;\n}\n\nlong spmv_coo(const int repeat,\n              const size_t num_rows,\n              const REAL* x,\n              const size_t nnz,\n              REAL* matrix,\n              REAL* y)\n{\n  size_t *row_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  size_t *col_indices = (size_t *) malloc(nnz * sizeof(size_t));\n  REAL *values = (REAL *) malloc(nnz * sizeof(REAL));\n\n  \n\n  init_coo(row_indices, values, col_indices, matrix, num_rows, nnz);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  size_t *d_row_indices = sycl::malloc_device<size_t>(nnz, q);\n  size_t *d_col_indices = sycl::malloc_device<size_t>(nnz, q);\n  REAL *d_values = sycl::malloc_device<REAL>(nnz, q);\n  REAL *d_x = sycl::malloc_device<REAL>(num_rows, q);\n  REAL *d_y = sycl::malloc_device<REAL>(num_rows, q);\n\n  q.memcpy(d_row_indices, row_indices, nnz*sizeof(size_t));\n  q.memcpy(d_col_indices, col_indices, nnz*sizeof(size_t));\n  q.memcpy(d_values, values, nnz*sizeof(REAL));\n  q.memcpy(d_x, x, num_rows*sizeof(REAL));\n\n  \n\n  oneapi::mkl::sparse::matrix_handle_t handle = nullptr;\n  oneapi::mkl::sparse::init_matrix_handle(&handle);\n\n  REAL alpha = 1.f;\n  REAL beta = 0.f;\n\n  \n\n  oneapi::mkl::sparse::set_coo_data(q, handle, num_rows, num_rows, nnz,\n                                    oneapi::mkl::index_base::zero,\n                                    (int64_t*)d_row_indices, (int64_t*)d_col_indices, d_values);\n\n  \n\n  \n\n  optimize_gemv(q, oneapi::mkl::transpose::nontrans, handle).wait();\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    oneapi::mkl::sparse::gemv(q, oneapi::mkl::transpose::nontrans, alpha,\n                              handle, d_x, beta, d_y);\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  q.memcpy(y, d_y, num_rows*sizeof(REAL)).wait();\n\n  oneapi::mkl::sparse::release_matrix_handle(q, &handle).wait();\n\n  free(values);\n  free(row_indices);\n  free(col_indices);\n\n  sycl::free(d_row_indices, q);\n  sycl::free(d_col_indices, q);\n  sycl::free(d_values, q);\n  sycl::free(d_x, q);\n  sycl::free(d_y, q);\n\n  return time;\n}\n"}}
{"kernel_name": "spnnz", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>            \n\n#include <stdlib.h>           \n\n#include <chrono>\n#include <cuda_runtime_api.h> \n\n#include <cusparse.h>         \n\n#include \"utils.h\"\n\n#define CHECK_CUDA(func)                                                       \\\n{                                                                              \\\n    cudaError_t status = (func);                                               \\\n    if (status != cudaSuccess) {                                               \\\n        printf(\"CUDA API failed at line %d with error: %s (%d)\\n\",             \\\n               __LINE__, cudaGetErrorString(status), status);                  \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\n#define CHECK_CUSPARSE(func)                                                   \\\n{                                                                              \\\n    cusparseStatus_t status = (func);                                          \\\n    if (status != CUSPARSE_STATUS_SUCCESS) {                                   \\\n        printf(\"CUSPARSE API failed at line %d with error: %s (%d)\\n\",         \\\n               __LINE__, cusparseGetErrorString(status), status);              \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  \n\n\n  if (argc != 5) {\n    printf(\"This function computes the number of nonzero elements per row or column\");\n    printf(\" and the total number of nonzero elements in a dense matrix.\\n\");\n    printf(\"Usage %s <M> <N> <nnz> <repeat>\\n\", argv[0]);\n    printf(\"nnz is the number of non-zero elements\\n\");\n    return 1;\n  }\n\n  int64_t m, n, h_nnz;\n\n  m = atol(argv[1]);\n  n = atol(argv[2]);\n  h_nnz = atol(argv[3]);\n  repeat = atoi(argv[4]);\n\n  \n\n  const int64_t num_rows = m;\n  const int64_t num_cols = n;\n  const int64_t lda = num_cols;\n  const int64_t dense_size = m * n;\n  const int64_t dense_size_bytes = dense_size * sizeof(float);\n  const int64_t nnzRowCol_size_bytes = num_rows * sizeof(int);\n\n  float *h_dense = (float*) malloc (dense_size_bytes);\n\n  printf(\"Initializing host matrices..\\n\");\n  init_matrix(h_dense, num_rows, num_cols, h_nnz);\n\n  \n\n  int* nnzPerRowColumn = (int*) malloc (nnzRowCol_size_bytes);\n\n  \n\n  int *d_nnzPerRowColumn;\n  float *d_dense;\n  CHECK_CUDA( cudaMalloc((void**) &d_nnzPerRowColumn, nnzRowCol_size_bytes)) \n  CHECK_CUDA( cudaMalloc((void**) &d_dense, dense_size_bytes))\n  CHECK_CUDA( cudaMemcpy(d_dense, h_dense, dense_size_bytes,\n                         cudaMemcpyHostToDevice) )\n  \n\n  \n\n  cusparseHandle_t   handle = NULL;\n  cusparseMatDescr_t descr = 0;\n\n  int nnzTotal = 0;\n\n  CHECK_CUSPARSE( cusparseCreate(&handle) )\n  CHECK_CUSPARSE( cusparseCreateMatDescr(&descr) )\n  CHECK_CUSPARSE( cusparseSetMatType(descr, CUSPARSE_MATRIX_TYPE_GENERAL) )\n  CHECK_CUSPARSE( cusparseSetMatIndexBase(descr, CUSPARSE_INDEX_BASE_ZERO) )\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    CHECK_CUSPARSE( cusparseSnnz(handle,\n                                 CUSPARSE_DIRECTION_COLUMN,\n                                 num_rows,\n                                 num_cols,\n                                 descr,\n                                 d_dense,\n                                 lda,\n                                 d_nnzPerRowColumn,\n                                 &nnzTotal) )\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of cusparseSnnz : %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  CHECK_CUSPARSE( cusparseDestroyMatDescr(descr) )\n  CHECK_CUSPARSE( cusparseDestroy(handle) )\n  \n\n  \n\n  CHECK_CUDA( cudaMemcpy(nnzPerRowColumn, d_nnzPerRowColumn, nnzRowCol_size_bytes,\n                         cudaMemcpyDeviceToHost) )\n  int correct = 1; \n  if (h_nnz != nnzTotal) {\n    printf(\"nnz: %d != %d\\n\", (int)h_nnz, nnzTotal);\n    correct = 0;\n    goto print_error;\n  }\n\n  for (int64_t i = 0; i < num_rows; i++) {\n    int nnz = 0; \n\n    for (int64_t j = 0; j < num_cols; j++) {\n      if (h_dense[i*num_cols+j] != 0) nnz++; \n    }\n    if (nnz != nnzPerRowColumn[i]) {\n      printf(\"@row %ld %d != %d\\n\", i, nnz, nnzPerRowColumn[i]);\n      correct = 0;\n      goto print_error;\n    }\n  }\n\n  print_error:\n  if (correct)\n      printf(\"sparse_nnz_example test PASSED\\n\");\n  else\n      printf(\"sparse_nnz_example test FAILED: wrong result\\n\");\n  \n\n  \n\n  CHECK_CUDA( cudaFree(d_nnzPerRowColumn) )\n  CHECK_CUDA( cudaFree(d_dense) )\n  free(h_dense);\n  free(nnzPerRowColumn);\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "spnnz", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>            \n\n#include <stdlib.h>           \n\n#include <chrono>\n#include <hip/hip_runtime_api.h> \n\n#include <hipsparse/hipsparse.h>\n#include \"utils.h\"\n\n#define CHECK_HIP(func)                                                      \\\n{                                                                            \\\n    hipError_t status = (func);                                              \\\n    if (status != hipSuccess) {                                              \\\n        printf(\"HIP API failed at line %d with error: %s (%d)\\n\",            \\\n               __LINE__, hipGetErrorString(status), status);                 \\\n        return EXIT_FAILURE;                                                 \\\n    }                                                                        \\\n}\n\n#define CHECK_HIPSPARSE_ERROR_CASE__(token_) \\\n    case token_:                             \\\n        fprintf(stderr, \"HIPSPARSE API failed at line %d with error: %s\\n\",         \\\n               __LINE__, #token_); \\\n        break\n\n#define CHECK_HIPSPARSE(error)                                                      \\\n    {                                                                                     \\\n        auto local_error = (error);                                                       \\\n        if(local_error != HIPSPARSE_STATUS_SUCCESS)                                       \\\n        {                                                                                 \\\n            fprintf(stderr, \"hipSPARSE error: \");                                         \\\n            switch(local_error)                                                           \\\n            {                                                                             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_SUCCESS);                   \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_NOT_INITIALIZED);           \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ALLOC_FAILED);              \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INVALID_VALUE);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ARCH_MISMATCH);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_MAPPING_ERROR);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_EXECUTION_FAILED);          \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INTERNAL_ERROR);            \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_MATRIX_TYPE_NOT_SUPPORTED); \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ZERO_PIVOT);                \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_NOT_SUPPORTED);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INSUFFICIENT_RESOURCES);    \\\n            }                                                                             \\\n            fprintf(stderr, \"\\n\");                                                        \\\n            return local_error;                                                           \\\n        }                                                                                 \\\n    }                                                                                     \n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  \n\n\n  if (argc != 5) {\n    printf(\"This function computes the number of nonzero elements per row or column\");\n    printf(\" and the total number of nonzero elements in a dense matrix.\\n\");\n    printf(\"Usage %s <M> <N> <nnz> <repeat>\\n\", argv[0]);\n    printf(\"nnz is the number of non-zero elements\\n\");\n    return 1;\n  }\n\n  int64_t m, n, h_nnz;\n\n  m = atol(argv[1]);\n  n = atol(argv[2]);\n  h_nnz = atol(argv[3]);\n  repeat = atoi(argv[4]);\n\n  \n\n  const int64_t num_rows = m;\n  const int64_t num_cols = n;\n  const int64_t lda = num_cols;\n  const int64_t dense_size = m * n;\n  const int64_t dense_size_bytes = dense_size * sizeof(float);\n  const int64_t nnzRowCol_size_bytes = num_rows * sizeof(int);\n\n  float *h_dense = (float*) malloc (dense_size_bytes);\n\n  printf(\"Initializing host matrices..\\n\");\n  init_matrix(h_dense, num_rows, num_cols, h_nnz);\n\n  \n\n  int* nnzPerRowColumn = (int*) malloc (nnzRowCol_size_bytes);\n\n  \n\n  int *d_nnzPerRowColumn;\n  float *d_dense;\n  CHECK_HIP( hipMalloc((void**) &d_nnzPerRowColumn, nnzRowCol_size_bytes)) \n  CHECK_HIP( hipMalloc((void**) &d_dense, dense_size_bytes))\n  CHECK_HIP( hipMemcpy(d_dense, h_dense, dense_size_bytes,\n                       hipMemcpyHostToDevice) )\n  \n\n  \n\n  hipsparseHandle_t   handle = NULL;\n  hipsparseMatDescr_t descr = 0;\n\n  int nnzTotal = 0;\n\n  CHECK_HIPSPARSE( hipsparseCreate(&handle) )\n  CHECK_HIPSPARSE( hipsparseCreateMatDescr(&descr) )\n  CHECK_HIPSPARSE( hipsparseSetMatType(descr, HIPSPARSE_MATRIX_TYPE_GENERAL) )\n  CHECK_HIPSPARSE( hipsparseSetMatIndexBase(descr, HIPSPARSE_INDEX_BASE_ZERO) )\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    CHECK_HIPSPARSE( hipsparseSnnz(handle,\n                                   HIPSPARSE_DIRECTION_COLUMN,\n                                   num_rows,\n                                   num_cols,\n                                   descr,\n                                   d_dense,\n                                   lda,\n                                   d_nnzPerRowColumn,\n                                   &nnzTotal) )\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of hipsparseSnnz : %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  CHECK_HIPSPARSE( hipsparseDestroyMatDescr(descr) )\n  CHECK_HIPSPARSE( hipsparseDestroy(handle) )\n  \n\n  \n\n  CHECK_HIP( hipMemcpy(nnzPerRowColumn, d_nnzPerRowColumn, nnzRowCol_size_bytes,\n                       hipMemcpyDeviceToHost) )\n  int correct = 1; \n  if (h_nnz != nnzTotal) {\n    printf(\"nnz: %d != %d\\n\", (int)h_nnz, nnzTotal);\n    correct = 0;\n    goto print_error;\n  }\n\n  for (int64_t i = 0; i < num_rows; i++) {\n    int nnz = 0; \n\n    for (int64_t j = 0; j < num_cols; j++) {\n      if (h_dense[i*num_cols+j] != 0) nnz++; \n    }\n    if (nnz != nnzPerRowColumn[i]) {\n      printf(\"@row %ld %d != %d\\n\", i, nnz, nnzPerRowColumn[i]);\n      correct = 0;\n      goto print_error;\n    }\n  }\n\n  print_error:\n  if (correct)\n      printf(\"sparse_nnz_example test PASSED\\n\");\n  else\n      printf(\"sparse_nnz_example test FAILED: wrong result\\n\");\n  \n\n  \n\n  CHECK_HIP( hipFree(d_nnzPerRowColumn) )\n  CHECK_HIP( hipFree(d_dense) )\n  free(h_dense);\n  free(nnzPerRowColumn);\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "sps2d", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <stdio.h>            \n\n#include <stdlib.h>           \n\n#include <chrono>\n#include <cuda_runtime_api.h> \n\n#include <cusparse.h>         \n\n#include \"utils.h\"\n\n#define CHECK_CUDA(func)                                                       \\\n{                                                                              \\\n    cudaError_t status = (func);                                               \\\n    if (status != cudaSuccess) {                                               \\\n        printf(\"CUDA API failed at line %d with error: %s (%d)\\n\",             \\\n               __LINE__, cudaGetErrorString(status), status);                  \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\n#define CHECK_CUSPARSE(func)                                                   \\\n{                                                                              \\\n    cusparseStatus_t status = (func);                                          \\\n    if (status != CUSPARSE_STATUS_SUCCESS) {                                   \\\n        printf(\"CUSPARSE API failed at line %d with error: %s (%d)\\n\",         \\\n               __LINE__, cusparseGetErrorString(status), status);              \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  if (argc != 5) {\n    printf(\"The function converts a sparse matrix into a MxN dense matrix\\n\");\n    printf(\"The sparse matrix is represented in CSR (Compressed Sparse Row) storage format\\n\");\n    printf(\"Usage %s <M> <N> <nnz> <repeat>\\n\", argv[0]);\n    printf(\"nnz is the number of non-zero elements\\n\");\n    return 1;\n  }\n\n  int64_t m, n, h_nnz;\n\n  m = atol(argv[1]);\n  n = atol(argv[2]);\n  h_nnz = atol(argv[3]);\n  repeat = atoi(argv[4]);\n\n  \n\n  const int64_t num_rows = m;\n  const int64_t num_cols = n;\n  const int64_t dense_size = m * n;\n\n  const int64_t dense_size_bytes  = dense_size * sizeof(float);\n  const int64_t value_size_bytes  = h_nnz * sizeof(float);\n  const int64_t colidx_size_bytes = h_nnz * sizeof(int64_t);\n  const int64_t rowidx_size_bytes = (num_rows + 1) * sizeof(int64_t);\n\n  \n\n  float *h_dense = (float*) malloc (dense_size_bytes);\n\n  \n\n  float *h_dense_result = (float*) malloc (dense_size_bytes);\n\n  float *h_csr_values = (float*) malloc (value_size_bytes);\n  int64_t *h_csr_columns = (int64_t*) malloc (colidx_size_bytes);\n  int64_t *h_csr_offsets = (int64_t*) malloc (rowidx_size_bytes);\n\n  printf(\"Initializing host matrices..\\n\");\n  init_matrix(h_dense, num_rows, num_cols, h_nnz);\n\n  init_csr(h_csr_offsets, h_csr_values, h_csr_columns,\n           h_dense, num_rows, num_cols, h_nnz);\n  \n\n  \n\n  int64_t *d_csr_offsets, *d_csr_columns;\n  float *d_csr_values, *d_dense;\n\n  CHECK_CUDA( cudaMalloc((void**) &d_dense, dense_size_bytes))\n  CHECK_CUDA( cudaMemset(d_dense, 0, dense_size_bytes))\n\n  \n\n  CHECK_CUDA( cudaMalloc((void**) &d_csr_columns, h_nnz * sizeof(int64_t)) )\n  CHECK_CUDA( cudaMalloc((void**) &d_csr_values,  h_nnz * sizeof(float)) )\n  CHECK_CUDA( cudaMalloc((void**) &d_csr_offsets,\n                         (num_rows + 1) * sizeof(int64_t)) )\n\n  CHECK_CUDA( cudaMemcpy(d_csr_offsets, h_csr_offsets,\n                         (num_rows + 1) * sizeof(int64_t),\n                         cudaMemcpyHostToDevice) )\n  CHECK_CUDA( cudaMemcpy(d_csr_columns, h_csr_columns, h_nnz * sizeof(int64_t),\n                         cudaMemcpyHostToDevice) )\n  CHECK_CUDA( cudaMemcpy(d_csr_values, h_csr_values, h_nnz * sizeof(float),\n                         cudaMemcpyHostToDevice) )\n\n  \n\n  \n\n  cusparseHandle_t     handle = NULL;\n  cusparseSpMatDescr_t matA;\n  cusparseDnMatDescr_t matB;\n  void*                dBuffer    = NULL;\n  size_t               bufferSize = 0;\n  CHECK_CUSPARSE( cusparseCreate(&handle) )\n\n  \n\n  CHECK_CUSPARSE( cusparseCreateCsr(&matA, num_rows, num_cols, h_nnz,\n                                    d_csr_offsets, d_csr_columns, d_csr_values,\n                                    CUSPARSE_INDEX_64I, CUSPARSE_INDEX_64I,\n                                    CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F) )\n\n  \n\n  CHECK_CUSPARSE( cusparseCreateDnMat(&matB, num_rows, num_cols, num_cols, d_dense,\n                                      CUDA_R_32F, CUSPARSE_ORDER_ROW) )\n\n  \n\n  CHECK_CUSPARSE( cusparseSparseToDense_bufferSize(\n                                      handle, matA, matB,\n                                      CUSPARSE_SPARSETODENSE_ALG_DEFAULT,\n                                      &bufferSize) )\n  CHECK_CUDA( cudaMalloc(&dBuffer, bufferSize) )\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    CHECK_CUSPARSE( cusparseSparseToDense(handle, matA, matB,\n                                          CUSPARSE_SPARSETODENSE_ALG_DEFAULT,\n                                          dBuffer) )\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SparseToDense_convert : %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  CHECK_CUSPARSE( cusparseDestroySpMat(matA) )\n  CHECK_CUSPARSE( cusparseDestroyDnMat(matB) )\n  CHECK_CUSPARSE( cusparseDestroy(handle) )\n  \n\n  \n\n\n  CHECK_CUDA( cudaMemcpy(h_dense_result, d_dense, dense_size_bytes,\n                         cudaMemcpyDeviceToHost) )\n\n  int correct = 1; \n  int64_t nnz = 0;\n  for (int64_t i = 0; i < dense_size; i++) {\n    if (h_dense_result[i] != 0) nnz++;\n\n    if (h_dense[i] != h_dense_result[i]) {\n      printf(\"@%ld: %f != %f\\n\", i, h_dense[i], h_dense_result[i]);\n      correct = 0;\n      goto print_error;\n    }\n  }\n\n  if (nnz != h_nnz) {\n    printf(\"nnz: %ld != %ld\\n\", h_nnz, nnz);\n    correct = 0;\n  }\n\n  print_error:\n  if (correct)\n      printf(\"sparse2dense_csr_example test PASSED\\n\");\n  else                    \n      printf(\"sparse2dense_csr_example test FAILED: wrong result\\n\");\n  \n\n  \n\n  CHECK_CUDA( cudaFree(dBuffer) )\n  CHECK_CUDA( cudaFree(d_csr_offsets) )\n  CHECK_CUDA( cudaFree(d_csr_columns) )\n  CHECK_CUDA( cudaFree(d_csr_values) )\n  CHECK_CUDA( cudaFree(d_dense) )\n  free(h_dense);\n  free(h_dense_result);\n  free(h_csr_values);\n  free(h_csr_columns);\n  free(h_csr_offsets);\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "sps2d", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <stdio.h>            \n\n#include <stdlib.h>           \n\n#include <chrono>\n#include <hip/hip_runtime_api.h> \n\n#include <hipsparse/hipsparse.h>\n#include \"utils.h\"\n\n#define CHECK_HIP(func)                                                      \\\n{                                                                            \\\n    hipError_t status = (func);                                              \\\n    if (status != hipSuccess) {                                              \\\n        printf(\"HIP API failed at line %d with error: %s (%d)\\n\",            \\\n               __LINE__, hipGetErrorString(status), status);                 \\\n        return EXIT_FAILURE;                                                 \\\n    }                                                                        \\\n}\n\n#define CHECK_HIPSPARSE_ERROR_CASE__(token_) \\\n    case token_:                             \\\n        fprintf(stderr, \"HIPSPARSE API failed at line %d with error: %s\\n\",         \\\n               __LINE__, #token_); \\\n        break\n\n#define CHECK_HIPSPARSE(error)                                                      \\\n    {                                                                                     \\\n        auto local_error = (error);                                                       \\\n        if(local_error != HIPSPARSE_STATUS_SUCCESS)                                       \\\n        {                                                                                 \\\n            fprintf(stderr, \"hipSPARSE error: \");                                         \\\n            switch(local_error)                                                           \\\n            {                                                                             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_SUCCESS);                   \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_NOT_INITIALIZED);           \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ALLOC_FAILED);              \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INVALID_VALUE);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ARCH_MISMATCH);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_MAPPING_ERROR);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_EXECUTION_FAILED);          \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INTERNAL_ERROR);            \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_MATRIX_TYPE_NOT_SUPPORTED); \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ZERO_PIVOT);                \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_NOT_SUPPORTED);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INSUFFICIENT_RESOURCES);    \\\n            }                                                                             \\\n            fprintf(stderr, \"\\n\");                                                        \\\n            return local_error;                                                           \\\n        }                                                                                 \\\n    }                                                                                     \n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  if (argc != 5) {\n    printf(\"The function converts a sparse matrix into a MxN dense matrix\\n\");\n    printf(\"The sparse matrix is represented in CSR (Compressed Sparse Row) storage format\\n\");\n    printf(\"Usage %s <M> <N> <nnz> <repeat>\\n\", argv[0]);\n    printf(\"nnz is the number of non-zero elements\\n\");\n    return 1;\n  }\n\n  int64_t m, n, h_nnz;\n\n  m = atol(argv[1]);\n  n = atol(argv[2]);\n  h_nnz = atol(argv[3]);\n  repeat = atoi(argv[4]);\n\n  \n\n  const int64_t num_rows = m;\n  const int64_t num_cols = n;\n  const int64_t dense_size = m * n;\n\n  const int64_t dense_size_bytes  = dense_size * sizeof(float);\n  const int64_t value_size_bytes  = h_nnz * sizeof(float);\n  const int64_t colidx_size_bytes = h_nnz * sizeof(int64_t);\n  const int64_t rowidx_size_bytes = (num_rows + 1) * sizeof(int64_t);\n\n  \n\n  float *h_dense = (float*) malloc (dense_size_bytes);\n\n  \n\n  float *h_dense_result = (float*) malloc (dense_size_bytes);\n\n  float *h_csr_values = (float*) malloc (value_size_bytes);\n  int64_t *h_csr_columns = (int64_t*) malloc (colidx_size_bytes);\n  int64_t *h_csr_offsets = (int64_t*) malloc (rowidx_size_bytes);\n\n  printf(\"Initializing host matrices..\\n\");\n  init_matrix(h_dense, num_rows, num_cols, h_nnz);\n\n  init_csr(h_csr_offsets, h_csr_values, h_csr_columns,\n           h_dense, num_rows, num_cols, h_nnz);\n  \n\n  \n\n  int64_t *d_csr_offsets, *d_csr_columns;\n  float *d_csr_values, *d_dense;\n\n  CHECK_HIP( hipMalloc((void**) &d_dense, dense_size_bytes))\n  CHECK_HIP( hipMemset(d_dense, 0, dense_size_bytes))\n\n  \n\n  CHECK_HIP( hipMalloc((void**) &d_csr_columns, h_nnz * sizeof(int64_t)) )\n  CHECK_HIP( hipMalloc((void**) &d_csr_values,  h_nnz * sizeof(float)) )\n  CHECK_HIP( hipMalloc((void**) &d_csr_offsets,\n                       (num_rows + 1) * sizeof(int64_t)) )\n\n  CHECK_HIP( hipMemcpy(d_csr_offsets, h_csr_offsets,\n                       (num_rows + 1) * sizeof(int64_t),\n                       hipMemcpyHostToDevice) )\n  CHECK_HIP( hipMemcpy(d_csr_columns, h_csr_columns, h_nnz * sizeof(int64_t),\n                       hipMemcpyHostToDevice) )\n  CHECK_HIP( hipMemcpy(d_csr_values, h_csr_values, h_nnz * sizeof(float),\n                       hipMemcpyHostToDevice) )\n\n  \n\n  \n\n  hipsparseHandle_t     handle = NULL;\n  hipsparseSpMatDescr_t matA;\n  hipsparseDnMatDescr_t matB;\n  void*                 dBuffer    = NULL;\n  size_t                bufferSize = 0;\n  CHECK_HIPSPARSE( hipsparseCreate(&handle) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateCsr(&matA, num_rows, num_cols, h_nnz,\n                                      d_csr_offsets, d_csr_columns, d_csr_values,\n                                      HIPSPARSE_INDEX_64I, HIPSPARSE_INDEX_64I,\n                                      HIPSPARSE_INDEX_BASE_ZERO, HIP_R_32F) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateDnMat(&matB, num_rows, num_cols, num_cols, d_dense,\n                                        HIP_R_32F, HIPSPARSE_ORDER_ROW) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseSparseToDense_bufferSize(\n                                      handle, matA, matB,\n                                      HIPSPARSE_SPARSETODENSE_ALG_DEFAULT,\n                                      &bufferSize) )\n  CHECK_HIP( hipMalloc(&dBuffer, bufferSize) )\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    CHECK_HIPSPARSE( hipsparseSparseToDense(handle, matA, matB,\n                                            HIPSPARSE_SPARSETODENSE_ALG_DEFAULT,\n                                            dBuffer) )\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SparseToDense_convert : %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  CHECK_HIPSPARSE( hipsparseDestroySpMat(matA) )\n  CHECK_HIPSPARSE( hipsparseDestroyDnMat(matB) )\n  CHECK_HIPSPARSE( hipsparseDestroy(handle) )\n  \n\n  \n\n\n  CHECK_HIP( hipMemcpy(h_dense_result, d_dense, dense_size_bytes,\n                         hipMemcpyDeviceToHost) )\n\n  int correct = 1; \n  int64_t nnz = 0;\n  for (int64_t i = 0; i < dense_size; i++) {\n    if (h_dense_result[i] != 0) nnz++;\n\n    if (h_dense[i] != h_dense_result[i]) {\n      printf(\"@%ld: %f != %f\\n\", i, h_dense[i], h_dense_result[i]);\n      correct = 0;\n      goto print_error;\n    }\n  }\n\n  if (nnz != h_nnz) {\n    printf(\"nnz: %ld != %ld\\n\", h_nnz, nnz);\n    correct = 0;\n  }\n\n  print_error:\n  if (correct)\n      printf(\"sparse2dense_csr_example test PASSED\\n\");\n  else                    \n      printf(\"sparse2dense_csr_example test FAILED: wrong result\\n\");\n  \n\n  \n\n  CHECK_HIP( hipFree(dBuffer) )\n  CHECK_HIP( hipFree(d_csr_offsets) )\n  CHECK_HIP( hipFree(d_csr_columns) )\n  CHECK_HIP( hipFree(d_csr_values) )\n  CHECK_HIP( hipFree(d_dense) )\n  free(h_dense);\n  free(h_dense_result);\n  free(h_csr_values);\n  free(h_csr_columns);\n  free(h_csr_offsets);\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "stddev", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType>\n__global__ void sampleKernel (Type *std, IdxType D, IdxType N) {\n  IdxType i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i < D) std[i] = sqrtf(std[i] / N);\n}\n\n\n\ntemplate <typename Type, typename IdxType, int TPB, int ColsPerBlk = 32>\n__global__ void sopKernel(\n        Type *__restrict__ std, \n  const Type *__restrict__ data, \n  IdxType D, \n  IdxType N) \n{\n  const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n  IdxType thisColId = threadIdx.x % ColsPerBlk;\n  IdxType thisRowId = threadIdx.x / ColsPerBlk;\n  IdxType colId = thisColId + ((IdxType)blockIdx.y * ColsPerBlk);\n  IdxType rowId = thisRowId + ((IdxType)blockIdx.x * RowsPerBlkPerIter);\n  Type thread_data = Type(0);\n  const IdxType stride = RowsPerBlkPerIter * gridDim.x;\n  for (IdxType i = rowId; i < N; i += stride) {\n    Type val = (colId < D) ? data[i * D + colId] : Type(0);\n    thread_data += val * val;\n  }\n  __shared__ Type sstd[ColsPerBlk];\n  if (threadIdx.x < ColsPerBlk) sstd[threadIdx.x] = Type(0);\n  __syncthreads();\n\n  atomicAdd(sstd + thisColId, thread_data);\n  __syncthreads();\n\n  if (threadIdx.x < ColsPerBlk) atomicAdd(std + colId, sstd[thisColId]);\n}\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(Type *std, const Type *data, IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n  dim3 grid((N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk, \n            (D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk);\n  dim3 block(TPB);\n\n  cudaMemset(std, 0, sizeof(Type) * D); \n\n\n  sopKernel<Type, IdxType, TPB, ColsPerBlk> <<<grid, block>>>(std, data, D, N);\n\n  IdxType sampleSize = sample ? N-1 : N;\n  sampleKernel<Type, IdxType> <<<(D+TPB-1)/TPB, TPB>>>(std, D, sampleSize);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++) \n      data[i*D + j] = rand() / (float)RAND_MAX; \n\n  float *d_data;\n  cudaMalloc((void**)&d_data, inputSizeByte);\n  cudaMemcpy(d_data, data, inputSizeByte, cudaMemcpyHostToDevice);\n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n  float *d_std;\n  cudaMalloc((void**)&d_std, outputSizeByte);\n\n  \n\n  stddev(d_std, d_data, D, N, sample);\n\n  \n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    stddev(d_std, d_data, D, N, sample);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(std, d_std, outputSizeByte, cudaMemcpyDeviceToHost);\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  cudaFree(d_std);\n  cudaFree(d_data);\n  return 0;\n}\n"}}
{"kernel_name": "stddev", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType>\n__global__ void sampleKernel (Type *std, IdxType D, IdxType N) {\n  IdxType i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i < D) std[i] = sqrtf(std[i] / N);\n}\n\n\n\ntemplate <typename Type, typename IdxType, int TPB, int ColsPerBlk = 32>\n__global__ void sopKernel(\n        Type *__restrict__ std, \n  const Type *__restrict__ data, \n  IdxType D, \n  IdxType N) \n{\n  const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n  IdxType thisColId = threadIdx.x % ColsPerBlk;\n  IdxType thisRowId = threadIdx.x / ColsPerBlk;\n  IdxType colId = thisColId + ((IdxType)blockIdx.y * ColsPerBlk);\n  IdxType rowId = thisRowId + ((IdxType)blockIdx.x * RowsPerBlkPerIter);\n  Type thread_data = Type(0);\n  const IdxType stride = RowsPerBlkPerIter * gridDim.x;\n  for (IdxType i = rowId; i < N; i += stride) {\n    Type val = (colId < D) ? data[i * D + colId] : Type(0);\n    thread_data += val * val;\n  }\n  __shared__ Type sstd[ColsPerBlk];\n  if (threadIdx.x < ColsPerBlk) sstd[threadIdx.x] = Type(0);\n  __syncthreads();\n\n  atomicAdd(sstd + thisColId, thread_data);\n  __syncthreads();\n\n  if (threadIdx.x < ColsPerBlk) atomicAdd(std + colId, sstd[thisColId]);\n}\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(Type *std, const Type *data, IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n  dim3 grid((N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk, \n            (D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk);\n  dim3 block(TPB);\n\n  hipMemset(std, 0, sizeof(Type) * D); \n\n\n  hipLaunchKernelGGL(HIP_KERNEL_NAME(sopKernel<Type, IdxType, TPB, ColsPerBlk>), grid, block, 0, 0, std, data, D, N);\n\n  IdxType sampleSize = sample ? N-1 : N;\n  sampleKernel<Type, IdxType> <<<(D+TPB-1)/TPB, TPB>>>(std, D, sampleSize);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++) \n      data[i*D + j] = rand() / (float)RAND_MAX; \n\n  float *d_data;\n  hipMalloc((void**)&d_data, inputSizeByte);\n  hipMemcpy(d_data, data, inputSizeByte, hipMemcpyHostToDevice);\n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n  float *d_std;\n  hipMalloc((void**)&d_std, outputSizeByte);\n\n  \n\n  stddev(d_std, d_data, D, N, sample);\n\n  \n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    stddev(d_std, d_data, D, N, sample);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(std, d_std, outputSizeByte, hipMemcpyDeviceToHost);\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  hipFree(d_std);\n  hipFree(d_data);\n  return 0;\n}\n"}}
{"kernel_name": "stddev", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(Type *std, const Type *data, IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n\n  static const int TeamX = (N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk;\n  static const int TeamY = (D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk;\n  static const int Teams = TeamX * TeamY;\n\n  \n\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < D; i++)\n    std[i] = (Type)0;\n\n  #pragma omp target teams num_teams(Teams) thread_limit(TPB)\n  {\n    Type sstd[ColsPerBlk];\n    #pragma omp parallel\n    {\n      int tx = omp_get_thread_num();\n      int bx = omp_get_team_num() % TeamX;\n      int by = omp_get_team_num() / TeamX;\n      int gridDim_x = TeamX;\n \n      const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n      IdxType thisColId = tx % ColsPerBlk;\n      IdxType thisRowId = tx / ColsPerBlk;\n      IdxType colId = thisColId + ((IdxType)by * ColsPerBlk);\n      IdxType rowId = thisRowId + ((IdxType)bx * RowsPerBlkPerIter);\n      Type thread_data = Type(0);\n      const IdxType stride = RowsPerBlkPerIter * gridDim_x;\n      for (IdxType i = rowId; i < N; i += stride) {\n        Type val = (colId < D) ? data[i * D + colId] : Type(0);\n        thread_data += val * val;\n      }\n      if (tx < ColsPerBlk) sstd[tx] = Type(0);\n      #pragma omp barrier\n\n      #pragma omp atomic update\n      sstd[thisColId] += thread_data;\n\n      #pragma omp barrier\n\n      if (tx < ColsPerBlk) {\n        #pragma omp atomic update\n        std[colId] += sstd[thisColId];\n      }\n    }\n  }\n\n  IdxType sampleSize = sample ? N-1 : N;\n  #pragma omp target teams distribute parallel for thread_limit(TPB)\n  for (int i = 0; i < D; i++)\n    std[i] = sqrtf(std[i] / sampleSize);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++) \n      data[i*D + j] = rand() / (float)RAND_MAX; \n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n\n  #pragma omp target data map (to: data[0:inputSize]) map (from: std[0:outputSize])\n  {\n    \n\n    stddev(std, data, D, N, sample);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      stddev(std, data, D, N, sample);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  return 0;\n}\n"}}
{"kernel_name": "stddev", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(Type *std, const Type *data, IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n\n  static const int TeamX = (N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk;\n  static const int TeamY = (D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk;\n  static const int Teams = TeamX * TeamY;\n\n  \n\n    for (int i = 0; i < D; i++)\n    std[i] = (Type)0;\n\n    {\n    Type sstd[ColsPerBlk];\n        {\n      int tx = omp_get_thread_num();\n      int bx = omp_get_team_num() % TeamX;\n      int by = omp_get_team_num() / TeamX;\n      int gridDim_x = TeamX;\n \n      const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n      IdxType thisColId = tx % ColsPerBlk;\n      IdxType thisRowId = tx / ColsPerBlk;\n      IdxType colId = thisColId + ((IdxType)by * ColsPerBlk);\n      IdxType rowId = thisRowId + ((IdxType)bx * RowsPerBlkPerIter);\n      Type thread_data = Type(0);\n      const IdxType stride = RowsPerBlkPerIter * gridDim_x;\n      for (IdxType i = rowId; i < N; i += stride) {\n        Type val = (colId < D) ? data[i * D + colId] : Type(0);\n        thread_data += val * val;\n      }\n      if (tx < ColsPerBlk) sstd[tx] = Type(0);\n      \n            sstd[thisColId] += thread_data;\n\n      \n      if (tx < ColsPerBlk) {\n                std[colId] += sstd[thisColId];\n      }\n    }\n  }\n\n  IdxType sampleSize = sample ? N-1 : N;\n    for (int i = 0; i < D; i++)\n    std[i] = sqrtf(std[i] / sampleSize);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++) \n      data[i*D + j] = rand() / (float)RAND_MAX; \n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n\n    {\n    \n\n    stddev(std, data, D, N, sample);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      stddev(std, data, D, N, sample);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  return 0;\n}"}}
{"kernel_name": "stddev", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType>\nclass sampleKernel;\n\n\n\ntemplate <typename Type, typename IdxType, int TPB, int ColsPerBlk = 32>\nclass sopKernel;\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(sycl::queue &q,\n            Type *d_std,\n            const Type *d_data,\n            IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n\n  sycl::range<2> gws ((D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk ,\n                      (N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk * TPB);\n\n  sycl::range<2> lws (1, TPB);\n\n  \n\n  q.memset(d_std, 0, sizeof(Type) * D); \n\n\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<Type, 1> sstd (sycl::range<1>(ColsPerBlk), cgh);\n    cgh.parallel_for<class sopKernel<Type, IdxType, TPB, ColsPerBlk>>(\n      sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n      int tx = item.get_local_id(1);\n      int bx = item.get_group(1);\n      int by = item.get_group(0);\n      int gridDim_x = item.get_group_range(1);\n\n      const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n      IdxType thisColId = tx % ColsPerBlk;\n      IdxType thisRowId = tx / ColsPerBlk;\n      IdxType colId = thisColId + ((IdxType)by * ColsPerBlk);\n      IdxType rowId = thisRowId + ((IdxType)bx * RowsPerBlkPerIter);\n      Type thread_data = Type(0);\n      const IdxType stride = RowsPerBlkPerIter * gridDim_x;\n      for (IdxType i = rowId; i < N; i += stride) {\n        Type val = (colId < D) ? d_data[i * D + colId] : Type(0);\n        thread_data += val * val;\n      }\n      if (tx < ColsPerBlk) sstd[tx] = Type(0);\n      item.barrier(sycl::access::fence_space::local_space);\n\n      \n\n      auto atomic_local = sycl::atomic_ref<Type,\n                          sycl::memory_order::relaxed,\n                          sycl::memory_scope::work_group,\n                          sycl::access::address_space::local_space> (sstd[thisColId]);\n          atomic_local.fetch_add(thread_data);\n\n      item.barrier(sycl::access::fence_space::local_space);\n\n      if (tx < ColsPerBlk) {\n        \n\n        auto atomic_global = sycl::atomic_ref<Type,\n                             sycl::memory_order::relaxed,\n                             sycl::memory_scope::device,\n                             sycl::access::address_space::global_space> (d_std[colId]);\n        atomic_global.fetch_add(sstd[thisColId]);\n      }\n    });\n  });\n\n  sycl::range<1> gws2 ((D+TPB-1)/TPB*TPB);\n  sycl::range<1> lws2 (TPB);\n  IdxType sampleSize = sample ? N-1 : N;\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class sampleKernel<Type, IdxType>>(\n      sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n      IdxType i = item.get_global_id(0);\n      if (i < D) d_std[i] = sycl::sqrt(d_std[i] / sampleSize);\n    });\n  });\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++)\n      data[i*D + j] = rand() / (float)RAND_MAX;\n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_data = sycl::malloc_device<float>(inputSize, q);\n  q.memcpy(d_data, data, inputSizeByte);\n\n  float *d_std = sycl::malloc_device<float>(outputSize, q);\n\n  \n\n  stddev(q, d_std, d_data, D, N, sample);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++)\n    stddev(q, d_std, d_data, D, N, sample);\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(std, d_std, outputSizeByte).wait();\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  sycl::free(d_std, q);\n  sycl::free(d_data, q);\n  return 0;\n}\n\n"}}
{"kernel_name": "stencil1d", "parallel_api": "cuda", "code": {"stencil_1d.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\n__global__\nvoid stencil_1d(const int *__restrict__ in, int *__restrict__ out)\n{\n  __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n  int gindex = threadIdx.x + blockIdx.x * blockDim.x;\n  int lindex = threadIdx.x + RADIUS;\n\n  \n\n  temp[lindex] = in[gindex];\n\n  \n\n  if (threadIdx.x < RADIUS) {\n    temp[lindex - RADIUS] = (gindex < RADIUS) ? 0 : in[gindex - RADIUS];\n    temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n  }\n\n  \n\n  __syncthreads();\n\n  \n\n  int result = 0;\n  for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n    result += temp[lindex + offset];\n\n  \n\n  out[gindex] = result; \n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int size = length * sizeof(int);\n  int pad_size = (length + RADIUS) * sizeof(int);\n\n  int *a, *b;\n  \n\n  a = (int *)malloc(pad_size); \n  b = (int *)malloc(size);\n\n  for (int i = 0; i < length+RADIUS; i++) a[i] = i;\n\n  int *d_a, *d_b;\n  \n\n  cudaMalloc((void **)&d_a, pad_size);\n  cudaMalloc((void **)&d_b, size);\n\n  \n\n  cudaMemcpy(d_a, a, pad_size, cudaMemcpyHostToDevice);\n\n  dim3 grids (length/BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++)\n    stencil_1d <<< grids, blocks >>> (d_a, d_b);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  cudaMemcpy(b, d_b, size, cudaMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b); \n  cudaFree(d_a); \n  cudaFree(d_b); \n  return 0;\n}\n"}}
{"kernel_name": "stencil1d", "parallel_api": "hip", "code": {"stencil_1d.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\n__global__\nvoid stencil_1d(const int *__restrict__ in, int *__restrict__ out)\n{\n  __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n  int gindex = threadIdx.x + blockIdx.x * blockDim.x;\n  int lindex = threadIdx.x + RADIUS;\n\n  \n\n  temp[lindex] = in[gindex];\n\n  \n\n  if (threadIdx.x < RADIUS) {\n    temp[lindex - RADIUS] = (gindex < RADIUS) ? 0 : in[gindex - RADIUS];\n    temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n  }\n\n  \n\n  __syncthreads();\n\n  \n\n  int result = 0;\n  for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n    result += temp[lindex + offset];\n\n  \n\n  out[gindex] = result; \n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int size = length * sizeof(int);\n  int pad_size = (length + RADIUS) * sizeof(int);\n\n  int *a, *b;\n  \n\n  a = (int *)malloc(pad_size); \n  b = (int *)malloc(size);\n\n  for (int i = 0; i < length+RADIUS; i++) a[i] = i;\n\n  int *d_a, *d_b;\n  \n\n  hipMalloc((void **)&d_a, pad_size);\n  hipMalloc((void **)&d_b, size);\n\n  \n\n  hipMemcpy(d_a, a, pad_size, hipMemcpyHostToDevice);\n\n  dim3 grids (length/BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(stencil_1d, grids, blocks , 0, 0, d_a, d_b);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  hipMemcpy(b, d_b, size, hipMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b); \n  hipFree(d_a); \n  hipFree(d_b); \n  return 0;\n}\n"}}
{"kernel_name": "stencil1d", "parallel_api": "omp", "code": {"stencil_1d.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <omp.h>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int size = length;\n  int pad_size = (length + RADIUS);\n\n  \n\n  int* a = (int *)malloc(pad_size*sizeof(int)); \n  int* b = (int *)malloc(size*sizeof(int));\n\n  for (int i = 0; i < length+RADIUS; i++) a[i] = i;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams distribute map(to: a[0:pad_size]) map(from:b[0:size]) \n    for (int i = 0; i < length; i = i + BLOCK_SIZE) {\n      int temp[BLOCK_SIZE + 2 * RADIUS];\n      #pragma omp parallel for schedule(static,1)\n      for (int j = 0; j < BLOCK_SIZE; j++) {\n        int gindex = i+j;\n        temp[j+RADIUS] = a[gindex]; \n        if (j < RADIUS) {\n          temp[j] = (gindex < RADIUS) ? 0 : a[gindex - RADIUS];\n          temp[j + RADIUS + BLOCK_SIZE] = a[gindex + BLOCK_SIZE];\n        }\n      }\n\n      #pragma omp parallel for schedule(static,1)\n      for (int j = 0; j < BLOCK_SIZE; j++) {\n        int result = 0;\n        for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n          result += temp[j+RADIUS+offset];\n        b[i+j] = result; \n      }\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b); \n  return 0;\n}\n"}}
{"kernel_name": "stencil1d", "parallel_api": "serial", "code": {"stencil_1d.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int size = length;\n  int pad_size = (length + RADIUS);\n\n  \n\n  int* a = (int *)malloc(pad_size*sizeof(int)); \n  int* b = (int *)malloc(size*sizeof(int));\n\n  for (int i = 0; i < length+RADIUS; i++) a[i] = i;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n        for (int i = 0; i < length; i = i + BLOCK_SIZE) {\n      int temp[BLOCK_SIZE + 2 * RADIUS];\n            for (int j = 0; j < BLOCK_SIZE; j++) {\n        int gindex = i+j;\n        temp[j+RADIUS] = a[gindex]; \n        if (j < RADIUS) {\n          temp[j] = (gindex < RADIUS) ? 0 : a[gindex - RADIUS];\n          temp[j + RADIUS + BLOCK_SIZE] = a[gindex + BLOCK_SIZE];\n        }\n      }\n\n            for (int j = 0; j < BLOCK_SIZE; j++) {\n        int result = 0;\n        for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n          result += temp[j+RADIUS+offset];\n        b[i+j] = result; \n      }\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b); \n  return 0;\n}"}}
{"kernel_name": "stencil1d", "parallel_api": "sycl", "code": {"stencil_1d.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int pad_size = (length + RADIUS);\n\n  const size_t input_size_bytes = pad_size * sizeof(int);\n  const size_t output_size_bytes = length * sizeof(int);\n\n  \n\n  int* a = (int *)malloc(input_size_bytes);\n  int* b = (int *)malloc(output_size_bytes);\n\n  for (int i = 0; i < pad_size; i++) a[i] = i;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_in = sycl::malloc_device<int>(pad_size, q);\n  q.memcpy(d_in, a, input_size_bytes);\n\n  int *d_out = sycl::malloc_device<int>(length, q);\n\n  sycl::range<1> gws (length);\n  sycl::range<1> lws (BLOCK_SIZE);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler& cgh) {\n      sycl::local_accessor <int, 1> temp (sycl::range<1>(BLOCK_SIZE + 2 * RADIUS), cgh);\n      cgh.parallel_for<class stencil1D>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int gindex = item.get_global_id(0);\n        int lindex = item.get_local_id(0) + RADIUS;\n\n        \n\n        temp[lindex] = d_in[gindex];\n\n        \n\n        if (item.get_local_id(0) < RADIUS) {\n          temp[lindex - RADIUS] = (gindex < RADIUS) ? 0 : d_in[gindex - RADIUS];\n          temp[lindex + BLOCK_SIZE] = d_in[gindex + BLOCK_SIZE];\n        }\n\n        \n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        \n\n        int result = 0;\n        for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n          result += temp[lindex + offset];\n\n        \n\n        d_out[gindex] = result;\n\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  q.memcpy(b, d_out, output_size_bytes);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b);\n  sycl::free(d_in, q);\n  sycl::free(d_out, q);\n  return 0;\n}\n"}}
{"kernel_name": "su3", "parallel_api": "cuda", "code": {"su3_nn_bench.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/resource.h>\n#include <math.h>\n#include <vector>\n#include <iostream>\n#include <string>\n#include <cassert>\n#include <cmath>\n#include <complex>\n#include <chrono>\ntypedef std::chrono::system_clock Clock;\n\n#ifndef ITERATIONS\n#  define ITERATIONS 100\n#endif\n#ifndef LDIM\n#  define LDIM 32       \n\n#endif\n#ifndef PRECISION\n#  define PRECISION 1  \n\n#endif\n\n\n\nunsigned int verbose=1;\nint          warmups=1;\n\n\nint  g_argc;\nchar **g_argv;\n\n#include \"lattice.hpp\"\n\n#ifndef MILC_COMPLEX\ntemplate<class T>\nbool almost_equal(thrust::complex<T> x, thrust::complex<T> y, double tol)\n{\n  if (std::isnan(x.real()) || std::isnan(x.imag())\n  ||  std::isnan(y.real()) || std::isnan(y.imag()) )\n\t  return (0);\n  return thrust::abs( x - y ) < tol ;\n}\n#else\ntemplate<class T>\nbool almost_equal(T x, T y, double tol)\n{\n  if (std::isnan(x) || std::isnan(y))\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n\n\n\ntemplate<class T>\nbool almost_equal(std::complex<T> x, std::complex<T> y, double tol)\n{\n  if (std::isnan(x.real()) || std::isnan(x.imag())\n  ||  std::isnan(y.real()) || std::isnan(y.imag()) )\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n#endif\n\n\n\nvoid init_link(su3_matrix *s, Complx val) {\n  for(int j=0; j<4; ++j) for(int k=0; k<3; ++k) for(int l=0; l<3; ++l) {\n    s[j].e[k][l] = val;\n  }\n}\n\n\n\nvoid make_lattice(site *s, size_t n, Complx val) {\n  int nx=n;\n  int ny=n;\n  int nz=n;\n  int nt=n;\n  for(int t=0;t<nt;t++) {\n    int i=t*nz*ny*nx;\n    for(int z=0;z<nz;z++)for(int y=0;y<ny;y++)for(int x=0;x<nx;x++,i++){\n      s[i].x=x; s[i].y=y; s[i].z=z; s[i].t=t;\n      s[i].index = x+nx*(y+ny*(z+nz*t));\n      if( (x+y+z+t)%2 == 0)\n        s[i].parity=EVEN;\n      else\n        s[i].parity=ODD;\n      init_link(&s[i].link[0], val);\n    }\n  }\n}\n\n\n\n#ifdef USE_THRUST\n#include <thrust/host_vector.h>\n#endif\n#include \"mat_nn_cuda.hpp\"\n\n\n\nint main(int argc, char **argv)\n{\n  int iterations = ITERATIONS;\n  size_t ldim = LDIM;\n  int threads_per_group = 128; \n\n  int device = -1;             \n\n\n  int opt;\n  g_argc = argc;\n  g_argv = argv;\n  \n\n\t\n\n  \n\n  \n\n  \n\n  while ((opt=getopt(argc, argv, \":hi:l:t:v:d:w:n:\")) != -1) {\n    switch (opt) {\n    case 'i':\n      iterations = atoi(optarg);\n      break;\n    case 'l':\n      ldim = atoi(optarg);\n      break;\n    case 't':\n      threads_per_group = atoi(optarg);\n      break;\n    case 'v':\n      verbose = atoi(optarg);\n      break;\n    case 'd':\n      device = atoi(optarg);\n      break;\n    case 'w':\n      warmups = atoi(optarg);\n      break;\n    case 'h':\n      fprintf(stderr, \"Usage: %s [-i iterations] [-l lattice dimension] \\\n[-t threads per workgroup] [-d device] [-v verbosity level [0,1,2,3]] [-w warmups]\\n\", argv[0]);\n      exit (1);\n    }\n  }\n\n  \n\n  size_t total_sites = ldim*ldim*ldim*ldim;\n#ifdef MILC_COMPLEX\n  std::vector<site> a(total_sites);\n  std::vector<su3_matrix> b(4);\n  std::vector<site> c(total_sites);\n#else\n  thrust::host_vector<site> a(total_sites);\n  thrust::host_vector<su3_matrix> b(4);\n  thrust::host_vector<site> c(total_sites);\n#endif\n\n  \n\n  make_lattice(a.data(), ldim, Complx{1.0,0.0});\n  init_link(b.data(), Complx{1.0/3.0,0.0});\n\n  if (verbose >= 1) {\n    printf(\"Number of sites = %zu^4\\n\", ldim);\n    printf(\"Executing %d iterations with %d warmups\\n\", iterations, warmups);\n    if (threads_per_group != 0)\n      printf(\"Threads per group = %d\\n\", threads_per_group);\n  }\n\n  \n\n  const double ttotal = su3_mat_nn(a, b, c, total_sites, iterations, threads_per_group, device);\n  if (verbose >= 1)\n    printf(\"Total kernel execution time = %f (s)\\n\", ttotal);\n\n  \n\n  \n\n  const double tflop = (double)iterations * total_sites * 864.0;\n  printf(\"Total GFLOP/s = %.3f\\n\", tflop / ttotal / 1.0e9);\n\n  const double memory_usage = (double)sizeof(site)*(a.capacity()+c.capacity())+sizeof(su3_matrix)*b.capacity();\n  printf(\"Total GByte/s (GPU memory)  = %.3f\\n\", iterations * memory_usage / ttotal / 1.0e9);\n  fflush(stdout);\n\n  \n\n  for (size_t i=0;i<total_sites;++i) for(int j=0;j<4;++j)  for(int k=0;k<3;++k)  for(int l=0;l<3;++l) {\n    Complx cc = {0.0, 0.0};\n    for(int m=0;m<3;m++) {\n      #ifdef MILC_COMPLEX\n        CMULSUM( a[i].link[j].e[k][m], b[j].e[m][l], cc)\n      #else\n        cc += a[i].link[j].e[k][m] * b[j].e[m][l];\n      #endif\n    }\n\n    #ifdef MILC_COMPLEX\n       assert(almost_equal(c[i].link[j].e[k][l].real, cc.real, 1E-6));\n       assert(almost_equal(c[i].link[j].e[k][l].imag, cc.imag, 1E-6));\n    #else\n       assert(almost_equal(c[i].link[j].e[k][l], cc, 1E-6));\n    #endif\n  }\n\n  \n\n  if (verbose >= 2) {\n    printf(\"Total allocation for matrices = %.3f MiB\\n\", memory_usage / 1048576.0);\n    struct rusage usage;\n    if (getrusage(RUSAGE_SELF, &usage) == 0)\n      printf(\"Approximate memory usage = %.3f MiB\\n\", (float)usage.ru_maxrss/1024.0);\n  }\n}\n"}}
{"kernel_name": "su3", "parallel_api": "hip", "code": {"su3_nn_bench.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/resource.h>\n#include <math.h>\n#include <vector>\n#include <iostream>\n#include <string>\n#include <cassert>\n#include <cmath>\n#include <complex>\n#include <chrono>\ntypedef std::chrono::system_clock Clock;\n\n#ifndef ITERATIONS\n#  define ITERATIONS 100\n#endif\n#ifndef LDIM\n#  define LDIM 32       \n\n#endif\n#ifndef PRECISION\n#  define PRECISION 2  \n\n#endif\n\n\n\nunsigned int verbose=1;\nint          warmups=1;\n\n\nint  g_argc;\nchar **g_argv;\n\n#include \"lattice.hpp\"\n\n#ifndef MILC_COMPLEX\ntemplate<class T>\nbool almost_equal(thrust::complex<T> x, thrust::complex<T> y, double tol)\n{\n  if (std::isnan(x.real()) || std::isnan(x.imag())\n  ||  std::isnan(y.real()) || std::isnan(y.imag()) )\n\t  return (0);\n  return thrust::abs( x - y ) < tol ;\n}\n#else\ntemplate<class T>\nbool almost_equal(T x, T y, double tol)\n{\n  if (std::isnan(x) || std::isnan(y))\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n\n\n\ntemplate<class T>\nbool almost_equal(std::complex<T> x, std::complex<T> y, double tol)\n{\n  if (std::isnan(x.real()) || std::isnan(x.imag())\n  ||  std::isnan(y.real()) || std::isnan(y.imag()) )\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n#endif\n\n\n\nvoid init_link(su3_matrix *s, Complx val) {\n  for(int j=0; j<4; ++j) for(int k=0; k<3; ++k) for(int l=0; l<3; ++l) {\n    s[j].e[k][l] = val;\n  }\n}\n\n\n\nvoid make_lattice(site *s, size_t n, Complx val) {\n  int nx=n;\n  int ny=n;\n  int nz=n;\n  int nt=n;\n  for(int t=0;t<nt;t++) {\n    int i=t*nz*ny*nx;\n    for(int z=0;z<nz;z++)for(int y=0;y<ny;y++)for(int x=0;x<nx;x++,i++){\n      s[i].x=x; s[i].y=y; s[i].z=z; s[i].t=t;\n      s[i].index = x+nx*(y+ny*(z+nz*t));\n      if( (x+y+z+t)%2 == 0)\n        s[i].parity=EVEN;\n      else\n        s[i].parity=ODD;\n      init_link(&s[i].link[0], val);\n    }\n  }\n}\n\n\n\n#ifdef USE_THRUST\n#include <thrust/host_vector.h>\n#endif\n#include \"mat_nn_cuda.hpp\"\n\n\n\nint main(int argc, char **argv)\n{\n  int iterations = ITERATIONS;\n  size_t ldim = LDIM;\n  int threads_per_group = 128; \n\n  int device = -1;             \n\n\n  int opt;\n  g_argc = argc;\n  g_argv = argv;\n  \n\n\t\n\n  \n\n  \n\n  \n\n  while ((opt=getopt(argc, argv, \":hi:l:t:v:d:w:n:\")) != -1) {\n    switch (opt) {\n    case 'i':\n      iterations = atoi(optarg);\n      break;\n    case 'l':\n      ldim = atoi(optarg);\n      break;\n    case 't':\n      threads_per_group = atoi(optarg);\n      break;\n    case 'v':\n      verbose = atoi(optarg);\n      break;\n    case 'd':\n      device = atoi(optarg);\n      break;\n    case 'w':\n      warmups = atoi(optarg);\n      break;\n    case 'h':\n      fprintf(stderr, \"Usage: %s [-i iterations] [-l lattice dimension] \\\n[-t threads per workgroup] [-d device] [-v verbosity level [0,1,2,3]] [-w warmups]\\n\", argv[0]);\n      exit (1);\n    }\n  }\n\n  \n\n  size_t total_sites = ldim*ldim*ldim*ldim;\n#ifdef MILC_COMPLEX\n  std::vector<site> a(total_sites);\n  std::vector<su3_matrix> b(4);\n  std::vector<site> c(total_sites);\n#else\n  thrust::host_vector<site> a(total_sites);\n  thrust::host_vector<su3_matrix> b(4);\n  thrust::host_vector<site> c(total_sites);\n#endif\n\n  \n\n  make_lattice(a.data(), ldim, Complx{1.0,0.0});\n  init_link(b.data(), Complx{1.0/3.0,0.0});\n\n  if (verbose >= 1) {\n    printf(\"Number of sites = %zu^4\\n\", ldim);\n    printf(\"Executing %d iterations with %d warmups\\n\", iterations, warmups);\n    if (threads_per_group != 0)\n      printf(\"Threads per group = %d\\n\", threads_per_group);\n  }\n\n  \n\n  const double ttotal = su3_mat_nn(a, b, c, total_sites, iterations, threads_per_group, device);\n  if (verbose >= 1)\n    printf(\"Total kernel execution time = %f (s)\\n\", ttotal);\n  \n\n  \n\n  const double tflop = (double)iterations * total_sites * 864.0;\n  printf(\"Total GFLOP/s = %.3f\\n\", tflop / ttotal / 1.0e9);\n\n  const double memory_usage = (double)sizeof(site)*(a.capacity()+c.capacity())+sizeof(su3_matrix)*b.capacity();\n  printf(\"Total GByte/s (GPU memory)  = %.3f\\n\", iterations * memory_usage / ttotal / 1.0e9);\n  fflush(stdout);\n\n  \n\n  for (size_t i=0;i<total_sites;++i) for(int j=0;j<4;++j)  for(int k=0;k<3;++k)  for(int l=0;l<3;++l) {\n    Complx cc = {0.0, 0.0};\n    for(int m=0;m<3;m++) {\n      #ifdef MILC_COMPLEX\n        CMULSUM( a[i].link[j].e[k][m], b[j].e[m][l], cc)\n      #else\n        cc += a[i].link[j].e[k][m] * b[j].e[m][l];\n      #endif\n    }\n\n    #ifdef MILC_COMPLEX\n       assert(almost_equal(c[i].link[j].e[k][l].real, cc.real, 1E-6));\n       assert(almost_equal(c[i].link[j].e[k][l].imag, cc.imag, 1E-6));\n    #else\n       assert(almost_equal(c[i].link[j].e[k][l], cc, 1E-6));\n    #endif\n  }\n\n  \n\n  if (verbose >= 2) {\n    printf(\"Total allocation for matrices = %.3f MiB\\n\", memory_usage / 1048576.0);\n    struct rusage usage;\n    if (getrusage(RUSAGE_SELF, &usage) == 0)\n      printf(\"Approximate memory usage = %.3f MiB\\n\", (float)usage.ru_maxrss/1024.0);\n  }\n}\n\n"}}
{"kernel_name": "su3", "parallel_api": "omp", "code": {"su3_nn_bench.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/resource.h>\n#include <math.h>\n#include <vector>\n#include <iostream>\n#include <string>\n#include <cassert>\n#include <cmath>\n#include <complex>\n#include <chrono>\ntypedef std::chrono::system_clock Clock;\n\n#ifndef ITERATIONS\n#  define ITERATIONS 100\n#endif\n#ifndef LDIM\n#  define LDIM 32       \n\n#endif\n#ifndef PRECISION\n#  define PRECISION 2  \n\n#endif\n\n\n\nunsigned int verbose=1;\nsize_t       warmups=1;\n\n\nint  g_argc;\nchar **g_argv;\n\n#include \"lattice.hpp\"\n\ntemplate<class T>\nbool almost_equal(T x, T y, double tol)\n{\n  if (std::isnan(x) || std::isnan(y))\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n\n\n\ntemplate<class T>\nbool almost_equal(std::complex<T> x, std::complex<T> y, double tol)\n{\n  if (std::isnan(x.real()) || std::isnan(x.imag())\n  ||  std::isnan(y.real()) || std::isnan(y.imag()) )\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n\n\n\nvoid init_link(su3_matrix *s, Complx val) {\n  for(int j=0; j<4; ++j) for(int k=0; k<3; ++k) for(int l=0; l<3; ++l) {\n    s[j].e[k][l] = val;\n  }\n}\n\n\n\nvoid make_lattice(site *s, size_t n, Complx val) {\n  int nx=n;\n  int ny=n;\n  int nz=n;\n  int nt=n;\n  for(int t=0;t<nt;t++) {\n    int i=t*nz*ny*nx;\n    for(int z=0;z<nz;z++)for(int y=0;y<ny;y++)for(int x=0;x<nx;x++,i++){\n      s[i].x=x; s[i].y=y; s[i].z=z; s[i].t=t;\n      s[i].index = x+nx*(y+ny*(z+nz*t));\n      if( (x+y+z+t)%2 == 0)\n        s[i].parity=EVEN;\n      else\n        s[i].parity=ODD;\n      init_link(&s[i].link[0], val);\n    }\n  }\n}\n\n\n\n#include \"mat_nn_openmp.hpp\"\n\n\n\nint main(int argc, char **argv)\n{\n  size_t iterations = ITERATIONS;\n  size_t ldim = LDIM;\n  size_t threads_per_group = 128; \n\n  int device = -1;                \n\n\n  int opt;\n  g_argc = argc;\n  g_argv = argv;\n  \n\n\t\n\n  \n\n  \n\n  \n\n  while ((opt=getopt(argc, argv, \":hi:l:t:v:d:w:n:\")) != -1) {\n    switch (opt) {\n    case 'i':\n      iterations = atoi(optarg);\n      break;\n    case 'l':\n      ldim = atoi(optarg);\n      break;\n    case 't':\n      threads_per_group = atoi(optarg);\n      break;\n    case 'v':\n      verbose = atoi(optarg);\n      break;\n    case 'd':\n      device = atoi(optarg);\n      break;\n    case 'w':\n      warmups = atoi(optarg);\n      break;\n    case 'h':\n      fprintf(stderr, \"Usage: %s [-i iterations] [-l lattice dimension] \\\n[-t threads per workgroup] [-d device] [-v verbosity level [0,1,2,3]] [-w warmups]\\n\", argv[0]);\n      exit (1);\n    }\n  }\n\n  \n\n  size_t total_sites = ldim*ldim*ldim*ldim;\n  std::vector<site> a(total_sites);\n  std::vector<su3_matrix> b(4);\n  std::vector<site> c(total_sites);\n\n  \n\n  make_lattice(a.data(), ldim, Complx{1.0,0.0});\n  init_link(b.data(), Complx{1.0/3.0,0.0});\n\n  if (verbose >= 1) {\n    printf(\"Number of sites = %zu^4\\n\", ldim);\n    printf(\"Executing %zu iterations with %zu warmups\\n\", iterations, warmups);\n    if (threads_per_group != 0)\n      printf(\"Threads per group = %zu\\n\", threads_per_group);\n  }\n\n  \n\n  const double ttotal = su3_mat_nn(a, b, c, total_sites, iterations, threads_per_group, device);\n  if (verbose >= 1)\n    printf(\"Total kernel execution time = %f (s)\\n\", ttotal);\n  \n\n  \n\n  const double tflop = (double)iterations * total_sites * 864.0;\n  printf(\"Total GFLOP/s = %.3f\\n\", tflop / ttotal / 1.0e9);\n\n  const double memory_usage = (double)sizeof(site)*(a.capacity()+c.capacity())+sizeof(su3_matrix)*b.capacity();\n  printf(\"Total GByte/s (GPU memory)  = %.3f\\n\", iterations * memory_usage / ttotal / 1.0e9);\n  fflush(stdout);\n\n  \n\n  for (int i=0;i<total_sites;++i) for(int j=0;j<4;++j)  for(int k=0;k<3;++k)  for(int l=0;l<3;++l) {\n    Complx cc = {0.0, 0.0};\n    for(int m=0;m<3;m++) {\n      #ifdef MILC_COMPLEX\n        CMULSUM( a[i].link[j].e[k][m], b[j].e[m][l], cc)\n      #else\n        cc += a[i].link[j].e[k][m] * b[j].e[m][l];\n      #endif\n    }\n\n    #ifdef MILC_COMPLEX\n       assert(almost_equal(c[i].link[j].e[k][l].real, cc.real, 1E-6));\n       assert(almost_equal(c[i].link[j].e[k][l].imag, cc.imag, 1E-6));\n    #else\n       assert(almost_equal(c[i].link[j].e[k][l], cc, 1E-6));\n    #endif\n  }\n\n  \n\n  if (verbose >= 2) {\n    printf(\"Total allocation for matrices = %.3f MiB\\n\", memory_usage / 1048576.0);\n    struct rusage usage;\n    if (getrusage(RUSAGE_SELF, &usage) == 0)\n      printf(\"Approximate memory usage = %.3f MiB\\n\", (float)usage.ru_maxrss/1024.0);\n  }\n}\n\n"}}
{"kernel_name": "su3", "parallel_api": "serial", "code": {"su3_nn_bench.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/resource.h>\n#include <math.h>\n#include <vector>\n#include <iostream>\n#include <string>\n#include <cassert>\n#include <cmath>\n#include <complex>\n#include <chrono>\ntypedef std::chrono::system_clock Clock;\n\n#ifndef ITERATIONS\n#  define ITERATIONS 100\n#endif\n#ifndef LDIM\n#  define LDIM 32       \n\n#endif\n#ifndef PRECISION\n#  define PRECISION 2  \n\n#endif\n\n\n\nunsigned int verbose=1;\nsize_t       warmups=1;\n\n\nint  g_argc;\nchar **g_argv;\n\n#include \"lattice.hpp\"\n\ntemplate<class T>\nbool almost_equal(T x, T y, double tol)\n{\n  if (std::isnan(x) || std::isnan(y))\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n\n\n\ntemplate<class T>\nbool almost_equal(std::complex<T> x, std::complex<T> y, double tol)\n{\n  if (std::isnan(x.real()) || std::isnan(x.imag())\n  ||  std::isnan(y.real()) || std::isnan(y.imag()) )\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n\n\n\nvoid init_link(su3_matrix *s, Complx val) {\n  for(int j=0; j<4; ++j) for(int k=0; k<3; ++k) for(int l=0; l<3; ++l) {\n    s[j].e[k][l] = val;\n  }\n}\n\n\n\nvoid make_lattice(site *s, size_t n, Complx val) {\n  int nx=n;\n  int ny=n;\n  int nz=n;\n  int nt=n;\n  for(int t=0;t<nt;t++) {\n    int i=t*nz*ny*nx;\n    for(int z=0;z<nz;z++)for(int y=0;y<ny;y++)for(int x=0;x<nx;x++,i++){\n      s[i].x=x; s[i].y=y; s[i].z=z; s[i].t=t;\n      s[i].index = x+nx*(y+ny*(z+nz*t));\n      if( (x+y+z+t)%2 == 0)\n        s[i].parity=EVEN;\n      else\n        s[i].parity=ODD;\n      init_link(&s[i].link[0], val);\n    }\n  }\n}\n\n\n\n#include \"mat_nn_openmp.hpp\"\n\n\n\nint main(int argc, char **argv)\n{\n  size_t iterations = ITERATIONS;\n  size_t ldim = LDIM;\n  size_t threads_per_group = 128; \n\n  int device = -1;                \n\n\n  int opt;\n  g_argc = argc;\n  g_argv = argv;\n  \n\n\t\n\n  \n\n  \n\n  \n\n  while ((opt=getopt(argc, argv, \":hi:l:t:v:d:w:n:\")) != -1) {\n    switch (opt) {\n    case 'i':\n      iterations = atoi(optarg);\n      break;\n    case 'l':\n      ldim = atoi(optarg);\n      break;\n    case 't':\n      threads_per_group = atoi(optarg);\n      break;\n    case 'v':\n      verbose = atoi(optarg);\n      break;\n    case 'd':\n      device = atoi(optarg);\n      break;\n    case 'w':\n      warmups = atoi(optarg);\n      break;\n    case 'h':\n      fprintf(stderr, \"Usage: %s [-i iterations] [-l lattice dimension] \\\n[-t threads per workgroup] [-d device] [-v verbosity level [0,1,2,3]] [-w warmups]\\n\", argv[0]);\n      exit (1);\n    }\n  }\n\n  \n\n  size_t total_sites = ldim*ldim*ldim*ldim;\n  std::vector<site> a(total_sites);\n  std::vector<su3_matrix> b(4);\n  std::vector<site> c(total_sites);\n\n  \n\n  make_lattice(a.data(), ldim, Complx{1.0,0.0});\n  init_link(b.data(), Complx{1.0/3.0,0.0});\n\n  if (verbose >= 1) {\n    printf(\"Number of sites = %zu^4\\n\", ldim);\n    printf(\"Executing %zu iterations with %zu warmups\\n\", iterations, warmups);\n    if (threads_per_group != 0)\n      printf(\"Threads per group = %zu\\n\", threads_per_group);\n  }\n\n  \n\n  const double ttotal = su3_mat_nn(a, b, c, total_sites, iterations, threads_per_group, device);\n  if (verbose >= 1)\n    printf(\"Total kernel execution time = %f (s)\\n\", ttotal);\n  \n\n  \n\n  const double tflop = (double)iterations * total_sites * 864.0;\n  printf(\"Total GFLOP/s = %.3f\\n\", tflop / ttotal / 1.0e9);\n\n  const double memory_usage = (double)sizeof(site)*(a.capacity()+c.capacity())+sizeof(su3_matrix)*b.capacity();\n  printf(\"Total GByte/s (GPU memory)  = %.3f\\n\", iterations * memory_usage / ttotal / 1.0e9);\n  fflush(stdout);\n\n  \n\n  for (int i=0;i<total_sites;++i) for(int j=0;j<4;++j)  for(int k=0;k<3;++k)  for(int l=0;l<3;++l) {\n    Complx cc = {0.0, 0.0};\n    for(int m=0;m<3;m++) {\n      #ifdef MILC_COMPLEX\n        CMULSUM( a[i].link[j].e[k][m], b[j].e[m][l], cc)\n      #else\n        cc += a[i].link[j].e[k][m] * b[j].e[m][l];\n      #endif\n    }\n\n    #ifdef MILC_COMPLEX\n       assert(almost_equal(c[i].link[j].e[k][l].real, cc.real, 1E-6));\n       assert(almost_equal(c[i].link[j].e[k][l].imag, cc.imag, 1E-6));\n    #else\n       assert(almost_equal(c[i].link[j].e[k][l], cc, 1E-6));\n    #endif\n  }\n\n  \n\n  if (verbose >= 2) {\n    printf(\"Total allocation for matrices = %.3f MiB\\n\", memory_usage / 1048576.0);\n    struct rusage usage;\n    if (getrusage(RUSAGE_SELF, &usage) == 0)\n      printf(\"Approximate memory usage = %.3f MiB\\n\", (float)usage.ru_maxrss/1024.0);\n  }\n}\n"}}
{"kernel_name": "su3", "parallel_api": "sycl", "code": {"su3_nn_bench.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/resource.h>\n#include <math.h>\n#include <vector>\n#include <iostream>\n#include <string>\n#include <cassert>\n#include <cmath>\n#include <complex>\n#include <chrono>\ntypedef std::chrono::system_clock Clock;\n\n#ifndef ITERATIONS\n#  define ITERATIONS 100\n#endif\n#ifndef LDIM\n#  define LDIM 32       \n\n#endif\n#ifndef PRECISION\n#  define PRECISION 2  \n\n#endif\n\n\n\nunsigned int verbose=1;\nsize_t       warmups=1;\n\n\nint  g_argc;\nchar **g_argv;\n\n#include \"lattice.hpp\"\n\ntemplate<class T>\nbool almost_equal(T x, T y, double tol)\n{\n  if (std::isnan(x) || std::isnan(y))\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n\n\n\ntemplate<class T>\nbool almost_equal(std::complex<T> x, std::complex<T> y, double tol)\n{\n  if (std::isnan(x.real()) || std::isnan(x.imag())\n  ||  std::isnan(y.real()) || std::isnan(y.imag()) )\n\t  return (0);\n  return std::abs( x - y ) < tol ;\n}\n\n\n\n\nvoid init_link(su3_matrix *s, Complx val) {\n  for(int j=0; j<4; ++j) for(int k=0; k<3; ++k) for(int l=0; l<3; ++l) {\n    s[j].e[k][l] = val;\n  }\n}\n\n\n\nvoid make_lattice(site *s, size_t n, Complx val) {\n  int nx=n;\n  int ny=n;\n  int nz=n;\n  int nt=n;\n  for(int t=0;t<nt;t++) {\n    int i=t*nz*ny*nx;\n    for(int z=0;z<nz;z++)for(int y=0;y<ny;y++)for(int x=0;x<nx;x++,i++){\n      s[i].x=x; s[i].y=y; s[i].z=z; s[i].t=t;\n      s[i].index = x+nx*(y+ny*(z+nz*t));\n      if( (x+y+z+t)%2 == 0)\n        s[i].parity=EVEN;\n      else\n        s[i].parity=ODD;\n      init_link(&s[i].link[0], val);\n    }\n  }\n}\n\n\n\n#include \"mat_nn_sycl.hpp\"\n\n\n\nint main(int argc, char **argv)\n{\n  size_t iterations = ITERATIONS;\n  size_t ldim = LDIM;\n  size_t threads_per_group = 128; \n\n  int device = -1;                \n\n\n  int opt;\n  g_argc = argc;\n  g_argv = argv;\n  \n\n\t\n\n  \n\n  \n\n  \n\n  while ((opt=getopt(argc, argv, \":hi:l:t:v:d:w:n:\")) != -1) {\n    switch (opt) {\n    case 'i':\n      iterations = atoi(optarg);\n      break;\n    case 'l':\n      ldim = atoi(optarg);\n      break;\n    case 't':\n      threads_per_group = atoi(optarg);\n      break;\n    case 'v':\n      verbose = atoi(optarg);\n      break;\n    case 'd':\n      device = atoi(optarg);\n      break;\n    case 'w':\n      warmups = atoi(optarg);\n      break;\n    case 'h':\n      fprintf(stderr, \"Usage: %s [-i iterations] [-l lattice dimension] \\\n[-t threads per workgroup] [-d device] [-v verbosity level [0,1,2,3]] [-w warmups]\\n\", argv[0]);\n      exit (1);\n    }\n  }\n\n  \n\n  size_t total_sites = ldim*ldim*ldim*ldim;\n  std::vector<site> a(total_sites);\n  std::vector<su3_matrix> b(4);\n  std::vector<site> c(total_sites);\n\n  \n\n  make_lattice(a.data(), ldim, Complx{1.0,0.0});\n  init_link(b.data(), Complx{1.0/3.0,0.0});\n\n  if (verbose >= 1) {\n    printf(\"Number of sites = %zu^4\\n\", ldim);\n    printf(\"Executing %zu iterations with %zu warmups\\n\", iterations, warmups);\n    if (threads_per_group != 0)\n      printf(\"Threads per group = %zu\\n\", threads_per_group);\n  }\n\n  \n\n  const double ttotal = su3_mat_nn(a, b, c, total_sites, iterations, threads_per_group, device);\n  if (verbose >= 1)\n    printf(\"Total kernel execution time = %f (s)\\n\", ttotal);\n  \n\n  \n\n  const double tflop = (double)iterations * total_sites * 864.0;\n  printf(\"Total GFLOP/s = %.3f\\n\", tflop / ttotal / 1.0e9);\n\n  const double memory_usage = (double)sizeof(site)*(a.capacity()+c.capacity())+sizeof(su3_matrix)*b.capacity();\n  printf(\"Total GByte/s (GPU memory)  = %.3f\\n\", iterations * memory_usage / ttotal / 1.0e9);\n  fflush(stdout);\n\n  \n\n  for (int i=0;i<total_sites;++i) for(int j=0;j<4;++j)  for(int k=0;k<3;++k)  for(int l=0;l<3;++l) {\n    Complx cc = {0.0, 0.0};\n    for(int m=0;m<3;m++) {\n      #ifdef MILC_COMPLEX\n        CMULSUM( a[i].link[j].e[k][m], b[j].e[m][l], cc)\n      #else\n        cc += a[i].link[j].e[k][m] * b[j].e[m][l];\n      #endif\n    }\n\n    #ifdef MILC_COMPLEX\n       assert(almost_equal(c[i].link[j].e[k][l].real, cc.real, 1E-6));\n       assert(almost_equal(c[i].link[j].e[k][l].imag, cc.imag, 1E-6));\n    #else\n       assert(almost_equal(c[i].link[j].e[k][l], cc, 1E-6));\n    #endif\n  }\n\n  \n\n  if (verbose >= 2) {\n    printf(\"Total allocation for matrices = %.3f MiB\\n\", memory_usage / 1048576.0);\n    struct rusage usage;\n    if (getrusage(RUSAGE_SELF, &usage) == 0)\n      printf(\"Approximate memory usage = %.3f MiB\\n\", (float)usage.ru_maxrss/1024.0);\n  }\n}\n\n"}}
{"kernel_name": "tpacf", "parallel_api": "hip", "code": {"compute.cu": "\n\n\n#ifndef _GPU_COMPUTE_H_\n#define _GPU_COMPUTE_H_\n\n#include <hip/hip_runtime.h>\n#include <sys/time.h>\n#include \"kernel.h\"\n#include \"ACF_kernel.cu\"\n#include \"histogram_kernel.cu\"\n#include \"model_io.cu\"\n#include \"args.h\"\n\n#define TDIFF(ts, te) (te.tv_sec - ts.tv_sec + (te.tv_usec - ts.tv_usec) * 1e-6)\n\n#define GRID_SIZE  (1 << LOG2_GRID_SIZE)\n\nconst dim3 grid(128, 128, 1);\nconst dim3 threads(128, 1, 1);\n\n\n\ncartesian d_idata1;\ncartesian d_idata2;\nunsigned int* d_odata1;\n\n\n\ncartesian h_idata1;\ncartesian h_idata2;\n\n\n\nstruct timeval t1, t0;\nfloat t_Compute = 0.0f;\n\n\n\nvoid writeBoundaries(double *binbs) {\n  hipMemcpyToSymbol(HIP_SYMBOL(binbounds), (void*)binbs, (NUMBINS-1)*sizeof(double));\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvoid tileComputeSymm(int type, int size, int njk, int* jkSizes, int nBins, long long* histo, hipStream_t &stream) {\n  \n\n  unsigned int* subHistoTemp = (unsigned int*)malloc(njk*nBins*sizeof(unsigned int));\n\n  \n\n  int nkernels = iDivUp(size, GRID_SIZE);\n\n  \n\n  int index;\n\n  for(int i=0; i<nkernels; i++) {\n    if(type == 0) {\n      hipMemcpyAsync(d_idata1.x, &h_idata1.x[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      hipMemcpyAsync(d_idata1.y, &h_idata1.y[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      hipMemcpyAsync(d_idata1.z, &h_idata1.z[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n    }\n    else {\n      hipMemcpyAsync(d_idata1.x, &h_idata2.x[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      hipMemcpyAsync(d_idata1.y, &h_idata2.y[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      hipMemcpyAsync(d_idata1.z, &h_idata2.z[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n    }\n    hipLaunchKernelGGL(ACFKernelSymm, grid, threads, 128*sizeof(double3), stream, d_idata1, d_odata1);\n    index = 0;\n    memset(subHistoTemp, 0, njk*nBins*sizeof(unsigned int));\n    for(int k=0; k<njk; k++) {\n      if(jkSizes[i*njk + k] != 0) {\n        GPUHistogram(&subHistoTemp[nBins*k], &d_odata1[index], jkSizes[i*njk + k]*GRID_SIZE, stream);\n        index += jkSizes[i*njk + k] * (GRID_SIZE >> 2);\n      }\n    }\n    for(int k=0; k<njk*nBins; k++) {\n      histo[k] += subHistoTemp[k];\n    }\n\n    for(int j=i+1; j<nkernels; j++) {\n      if(type == 0) {\n        hipMemcpyAsync(d_idata2.x, &h_idata1.x[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n        hipMemcpyAsync(d_idata2.y, &h_idata1.y[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n        hipMemcpyAsync(d_idata2.z, &h_idata1.z[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      }\n      else {\n        hipMemcpyAsync(d_idata2.x, &h_idata2.x[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n        hipMemcpyAsync(d_idata2.y, &h_idata2.y[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n        hipMemcpyAsync(d_idata2.z, &h_idata2.z[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      }\n      hipLaunchKernelGGL(ACFKernel, grid, threads, 128*sizeof(double3), stream, d_idata1, d_idata2, d_odata1);\n      index = 0;\n      memset(subHistoTemp, 0, njk*nBins*sizeof(unsigned int));\n      for(int k=0; k<njk; k++) {\n        if(jkSizes[i*njk + k] != 0) {\n          GPUHistogram(&subHistoTemp[nBins*k], &d_odata1[index], jkSizes[i*njk + k]*GRID_SIZE, stream);\n          index += jkSizes[i*njk + k] * (GRID_SIZE >> 2);\n        }\n      }\n      for(int k=0; k<njk*nBins; k++) {\n        histo[k] += subHistoTemp[k];\n      }\n    }\n  }\n}\n\n\n\n\n\n\n\n\n\nvoid tileCompute(int dataSize, int randomSize, int njk, int* jkSizes, int nBins, long long* histo, hipStream_t &stream) {\n  unsigned int* subHistoTemp = (unsigned int*)malloc(njk*nBins*sizeof(unsigned int));\n\n  int ndkernels = iDivUp(dataSize, GRID_SIZE);\n  int nrkernels = iDivUp(randomSize, GRID_SIZE);\n\n  int index;\n\n  for(int i=0; i<ndkernels; i++) {\n    hipMemcpyAsync(d_idata1.x, &h_idata1.x[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n    hipMemcpyAsync(d_idata1.y, &h_idata1.y[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n    hipMemcpyAsync(d_idata1.z, &h_idata1.z[i*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n    for(int j=0; j<nrkernels; j++) {\n      hipMemcpyAsync(d_idata2.x, &h_idata2.x[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      hipMemcpyAsync(d_idata2.y, &h_idata2.y[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      hipMemcpyAsync(d_idata2.z, &h_idata2.z[j*GRID_SIZE], GRID_SIZE*sizeof(double), hipMemcpyHostToDevice, stream);\n      hipLaunchKernelGGL(ACFKernel, grid, threads, 128*sizeof(double3), stream, d_idata1, d_idata2, d_odata1);\n      index = 0;\n      memset(subHistoTemp, 0, njk*nBins*sizeof(unsigned int));\n      for(int k=0; k<njk; k++) {\n        if(jkSizes[i*njk + k] != 0) {\n          GPUHistogram(&subHistoTemp[nBins*k], &d_odata1[index], jkSizes[i*njk + k]*GRID_SIZE, stream);\n          index += jkSizes[i*njk + k] * (GRID_SIZE >> 2);\n        }\n      }\n      for(int k=0; k<njk*nBins; k++) {\n        histo[k] += subHistoTemp[k];\n      }\n    }\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvoid doComputeGPU(char* dataName, char* randomNames, int nr, int dataSize, int randomSize, int njk, int* jkSizes, \n    int nBins, int zeroBin, long long** DDs, long long** DRs, long long** RRs) {\n  \n\n  *DDs = (long long*)malloc(nBins*njk*sizeof(long long));\n  *DRs = (long long*)malloc(nBins*njk*nr*sizeof(long long));\n  *RRs = (long long*)malloc(nBins*nr*sizeof(long long));\n  memset(*DDs, 0, nBins*njk*sizeof(long long));\n  memset(*DRs, 0, nBins*njk*nr*sizeof(long long));\n  memset(*RRs, 0, nBins*nr*sizeof(long long));\n\n  int ndkernels = iDivUp(dataSize, GRID_SIZE);\n  int nrkernels = iDivUp(randomSize, GRID_SIZE);\n  int* dkerneljkSizes = (int*)malloc(njk*ndkernels*sizeof(int));\n  int* rkerneljkSizes = (int*)malloc(njk*nrkernels*sizeof(int));\n  memset(dkerneljkSizes, 0, njk*ndkernels*sizeof(int));\n  memset(rkerneljkSizes, 0, njk*nrkernels*sizeof(int));\n\n  int currentjk = 0;\n  int numwrittencurrentjk = 0;\n  for(int i=0; i<ndkernels; i++) {\n    int remainder = GRID_SIZE;\n    while(remainder > 0 && currentjk < njk) {\n      if(remainder < jkSizes[currentjk] - numwrittencurrentjk) {\n        dkerneljkSizes[i*njk + currentjk] += remainder;\n        numwrittencurrentjk += remainder;\n        remainder = 0;\n      }\n      else {\n        remainder = remainder - (jkSizes[currentjk] - numwrittencurrentjk);\n        dkerneljkSizes[i*njk + currentjk] += (jkSizes[currentjk] - numwrittencurrentjk);\n        currentjk++;\n        numwrittencurrentjk = 0;\n      }\n    }\n  }\n\n  for(int i=0; i<nrkernels-1; i++) {\n    rkerneljkSizes[i*njk] += GRID_SIZE;\n  }\n  rkerneljkSizes[(nrkernels-1)*njk] += (randomSize % GRID_SIZE == 0) ? GRID_SIZE : randomSize % GRID_SIZE;\n\n  \n\n  int dataSizePadded = dataSize + ((GRID_SIZE - (dataSize % GRID_SIZE)) % GRID_SIZE);\n  int randomSizePadded = randomSize + ((GRID_SIZE - (randomSize % GRID_SIZE)) % GRID_SIZE);\n\n  \n\n  hipHostMalloc((void**)&h_idata1.x, dataSizePadded*sizeof(double));\n  hipHostMalloc((void**)&h_idata1.y, dataSizePadded*sizeof(double));\n  hipHostMalloc((void**)&h_idata1.z, dataSizePadded*sizeof(double));\n  h_idata1.jk = (int*)malloc(dataSize*sizeof(int));\n\n  hipHostMalloc((void**)&h_idata2.x, randomSizePadded*sizeof(double));\n  hipHostMalloc((void**)&h_idata2.y, randomSizePadded*sizeof(double));\n  hipHostMalloc((void**)&h_idata2.z, randomSizePadded*sizeof(double));\n  h_idata2.jk = (int*)malloc(randomSize*sizeof(int));\n\n  \n\n  for(int i=dataSize; i<dataSizePadded; i++) {\n    h_idata1.x[i] = double(0.0);\n    h_idata1.y[i] = double(0.0);\n    h_idata1.z[i] = double(0.0);\n  }\n  for(int i=randomSize; i<randomSizePadded; i++) {\n    h_idata2.x[i] = double(0.0);\n    h_idata2.y[i] = double(0.0);\n    h_idata2.z[i] = double(0.0);\n  }\n\n  \n\n  hipMalloc((void**)&d_idata1.x, GRID_SIZE*sizeof(double));\n  hipMalloc((void**)&d_idata1.y, GRID_SIZE*sizeof(double));\n  hipMalloc((void**)&d_idata1.z, GRID_SIZE*sizeof(double));\n  d_idata1.jk = NULL;\n  hipMalloc((void**)&d_idata2.x, GRID_SIZE*sizeof(double));\n  hipMalloc((void**)&d_idata2.y, GRID_SIZE*sizeof(double));\n  hipMalloc((void**)&d_idata2.z, GRID_SIZE*sizeof(double));\n  d_idata2.jk = NULL;\n  hipMalloc((void**)&d_odata1, GRID_SIZE*GRID_SIZE*sizeof(unsigned int)/4);\n\n  histoInit();\n\n  hipStream_t stream;\n  hipStreamCreate(&stream);\n\n  struct timeval t3, t2, t1, t0;\n  float t_computeDD=0, t_computeRRS=0, t_computeDRS=0, t_fileIO=0;\n\n  gettimeofday(&t0, NULL);\n\n  char fname[256];\n  readdatafile(dataName, h_idata1, dataSize);\n\n  gettimeofday(&t1, NULL);\n\n  \n\n  tileComputeSymm(0, dataSize, njk, dkerneljkSizes, nBins, *DDs, stream);\n\n  gettimeofday(&t2, NULL);\n\n  t_fileIO += TDIFF(t0, t1);\n  t_computeDD = TDIFF(t1, t2);\n\n  for(int i=0; i<nr; i++) {\n    sprintf(fname, \"%s.%i\", randomNames, i+1);\n    gettimeofday(&t0, NULL);\n\n    readdatafile(fname, h_idata2, randomSize);\n    gettimeofday(&t1, NULL);\n\n    \n\n    tileCompute(dataSize, randomSize, njk, dkerneljkSizes, nBins, &(*DRs)[njk*nBins*i], stream);\n    gettimeofday(&t2, NULL);\n\n    \n\n    tileComputeSymm(1, randomSize, njk, rkerneljkSizes, nBins, &(*RRs)[nBins*i], stream);\n    gettimeofday(&t3, NULL);\n\n    t_fileIO += TDIFF(t0, t1);  \n    t_computeDRS += TDIFF(t1, t2);\n    t_computeRRS += TDIFF(t2, t3);\n  }\n\n  \n\n  int padfactor = randomSizePadded - randomSize;\n  for(int i=0; i<nr; i++) {\n    (*RRs)[nBins*i + zeroBin] -= padfactor*randomSize;\n    for(int j=0; j<njk; j++) {\n      (*DRs)[nBins*njk*i + nBins*j + zeroBin] -= padfactor*jkSizes[j];\n    }\n  }\n  for(int i=0; i<njk; i++) {\n    (*DDs)[nBins*i + zeroBin] -= padfactor*jkSizes[i];\n  }\n\n  \n\n  hipStreamDestroy(stream);\n  histoClose();\n  hipFree(d_idata1.x);\n  hipFree(d_idata1.y);\n  hipFree(d_idata1.z);\n  hipFree(d_idata2.x);\n  hipFree(d_idata2.y);\n  hipFree(d_idata2.z);\n  hipFree(d_odata1);\n  hipHostFree(h_idata1.x);\n  hipHostFree(h_idata1.y);\n  hipHostFree(h_idata1.z);\n  free(h_idata1.jk);\n  hipHostFree(h_idata2.x);\n  hipHostFree(h_idata2.y);\n  hipHostFree(h_idata2.z);\n  free(h_idata2.jk);\n\n  printf(\"================================================\\n\");\n  printf(\"Time to compute DD: %.4f sec\\n\", t_computeDD);\n  printf(\"Time to compute RRS: %.4f sec\\n\", t_computeRRS);\n  printf(\"Time to compute DRS: %.4f sec\\n\", t_computeDRS);\n  printf(\"Time to load data files: %.4f sec\\n\", t_fileIO);\n  printf(\"Time to compute DD, RRS, & DRS: %.4f sec\\n\", t_computeDD+t_computeRRS+t_computeDRS);\n  printf(\"TOTAL time (DD+RRS+DRS+IO): %.4f sec\\n\", t_computeDD+t_computeRRS+t_computeDRS+t_fileIO);\n  printf(\"================================================\\n\");  \n}\n\nvoid compileHistograms(long long* DDs, long long* DRs, long long* RRs, long long*** DD, long long*** DR, \n    long long*** RR, options *args) {\n  *DD = (long long**)malloc(((*args).njk+1)*sizeof(long long*));\n  *DR = (long long**)malloc(((*args).njk+1)*sizeof(long long*));\n  *RR = (long long**)malloc(1*sizeof(long long*));\n  for(int i=0; i<=(*args).njk; i++) {\n    (*DD)[i] = (long long*)malloc(NUMBINS*sizeof(long long));\n    (*DR)[i] = (long long*)malloc(NUMBINS*sizeof(long long));\n    memset((*DD)[i], 0, NUMBINS*sizeof(long long));\n    memset((*DR)[i], 0, NUMBINS*sizeof(long long));\n  }\n  (*RR)[0] = (long long*)malloc(NUMBINS*sizeof(long long));\n  memset((*RR)[0], 0, NUMBINS*sizeof(long long));\n\n  for(int i=0; i<NUMBINS; i++) {\n    for(int k=0; k<(*args).njk; k++) {\n      (*DD)[0][i] += DDs[NUMBINS*k + i];\n    }\n    for(int j=0; j<(*args).random_count; j++) {\n      for(int k=0; k<(*args).njk; k++) {\n        (*DR)[0][i] += DRs[(j*(*args).njk + k)*NUMBINS + i];\n      }\n      (*RR)[0][i] += RRs[j*NUMBINS + i];\n    }\n  }\n\n  for(int k=1; k<=(*args).njk; k++) {\n    for(int i=0; i<NUMBINS; i++) {\n      (*DD)[k][i] = (*DD)[0][i] - DDs[(k-1)*NUMBINS + i];\n      (*DR)[k][i] = (*DR)[0][i];\n      for(int j=0; j<(*args).random_count; j++) {\n        (*DR)[k][i] -= DRs[(j*(*args).njk + k - 1)*NUMBINS + i];\n      }\n    }\n  }\n}  \n\n#endif\n\n\n\n", "ACF_kernel.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#ifndef _ACF_KERNEL_H_\n#define _ACF_KERNEL_H_\n\n#define LOG2_GRID_SIZE 14\n\n__device__ __constant__ double binbounds[NUMBINS-1];\n\n\n\n\n\n__global__ void ACFKernelSymm(cartesian g_idata1, unsigned int* g_odata)\n{\n  extern __shared__ double3 sdata[];\n  int tx = (blockIdx.x<<7) + threadIdx.x;\n  int by = (blockIdx.y<<7);\n  if(blockIdx.x < blockIdx.y) {    \n\n    by <<= (LOG2_GRID_SIZE - 2);\n    by += tx;\n#pragma unroll\n    for(int i=0; i<128; i+=4) {\n      g_odata[by+(i<<(LOG2_GRID_SIZE - 2))] = 2088533116; \n\n    }\n  }\n  else if(blockIdx.x > blockIdx.y) {  \n\n    double temp;\n    unsigned int temp2;\n    double3 vec1, vec2;\n\n    vec1.x = g_idata1.x[tx];\n    vec1.y = g_idata1.y[tx];\n    vec1.z = g_idata1.z[tx];\n    sdata[threadIdx.x].x = g_idata1.x[by+threadIdx.x];\n    sdata[threadIdx.x].y = g_idata1.y[by+threadIdx.x];\n    sdata[threadIdx.x].z = g_idata1.z[by+threadIdx.x];\n\n    __syncthreads();\n\n    by <<= (LOG2_GRID_SIZE - 2);\n    by += tx;\n\n#pragma unroll\n    for(int i=0; i<128; i+=4) {\n      temp2 = 0;\n#pragma unroll\n      for(int j=0; j<4; j++) {\n        vec2 = sdata[i+j];\n        temp = vec1.x*vec2.x + vec1.y*vec2.y + vec1.z*vec2.z;\n        if(temp < binbounds[30]) temp2 += (124<<(j<<3));\n        else if(temp < binbounds[29]) temp2 += (120<<(j<<3));\n        else if(temp < binbounds[28]) temp2 += (116<<(j<<3));\n        else if(temp < binbounds[27]) temp2 += (112<<(j<<3));\n        else if(temp < binbounds[26]) temp2 += (108<<(j<<3));\n        else if(temp < binbounds[25]) temp2 += (104<<(j<<3));\n        else if(temp < binbounds[24]) temp2 += (100<<(j<<3));\n        else if(temp < binbounds[23]) temp2 += (96<<(j<<3));\n        else if(temp < binbounds[22]) temp2 += (92<<(j<<3));\n        else if(temp < binbounds[21]) temp2 += (88<<(j<<3));\n        else if(temp < binbounds[20]) temp2 += (84<<(j<<3));\n        else if(temp < binbounds[19]) temp2 += (80<<(j<<3));\n        else if(temp < binbounds[18]) temp2 += (76<<(j<<3));\n        else if(temp < binbounds[17]) temp2 += (72<<(j<<3));\n        else if(temp < binbounds[16]) temp2 += (68<<(j<<3));\n        else if(temp < binbounds[15]) temp2 += (64<<(j<<3));\n        else if(temp < binbounds[14]) temp2 += (60<<(j<<3));\n        else if(temp < binbounds[13]) temp2 += (56<<(j<<3));\n        else if(temp < binbounds[12]) temp2 += (52<<(j<<3));\n        else if(temp < binbounds[11]) temp2 += (48<<(j<<3));\n        else if(temp < binbounds[10]) temp2 += (44<<(j<<3));\n        else if(temp < binbounds[9]) temp2 += (40<<(j<<3));\n        else if(temp < binbounds[8]) temp2 += (36<<(j<<3));\n        else if(temp < binbounds[7]) temp2 += (32<<(j<<3));\n        else if(temp < binbounds[6]) temp2 += (28<<(j<<3));\n        else if(temp < binbounds[5]) temp2 += (24<<(j<<3));\n        else if(temp < binbounds[4]) temp2 += (20<<(j<<3));\n        else if(temp < binbounds[3]) temp2 += (16<<(j<<3));\n        else if(temp < binbounds[2]) temp2 += (12<<(j<<3));\n        else if(temp < binbounds[1]) temp2 += (8<<(j<<3));\n        else if(temp < binbounds[0]) temp2 += (4<<(j<<3));\n        else temp2 += (0<<(j<<3));\n      }\n      g_odata[by+(i<<(LOG2_GRID_SIZE - 2))] = temp2;\n    }\n  }\n  else {  \n\n    double temp;\n    unsigned int temp2;\n    double3 vec1, vec2;\n\n    vec1.x = g_idata1.x[tx];\n    vec1.y = g_idata1.y[tx];\n    vec1.z = g_idata1.z[tx];\n    sdata[threadIdx.x].x = g_idata1.x[by+threadIdx.x];\n    sdata[threadIdx.x].y = g_idata1.y[by+threadIdx.x];\n    sdata[threadIdx.x].z = g_idata1.z[by+threadIdx.x];\n\n    __syncthreads();\n\n    by <<= (LOG2_GRID_SIZE - 2);\n    by += tx;\n\n#pragma unroll\n    for(int i=0; i<128; i+=4) {\n      temp2 = 0;\n#pragma unroll\n      for(int j=0; j<4; j++) {\n        if(threadIdx.x <= i+j) temp2 += (124<<(j<<3));\n        else { \n          vec2 = sdata[i+j];\n          temp = vec1.x*vec2.x + vec1.y*vec2.y + vec1.z*vec2.z;\n          if(temp < binbounds[30]) temp2 += (124<<(j<<3));\n          else if(temp < binbounds[29]) temp2 += (120<<(j<<3));\n          else if(temp < binbounds[28]) temp2 += (116<<(j<<3));\n          else if(temp < binbounds[27]) temp2 += (112<<(j<<3));\n          else if(temp < binbounds[26]) temp2 += (108<<(j<<3));\n          else if(temp < binbounds[25]) temp2 += (104<<(j<<3));\n          else if(temp < binbounds[24]) temp2 += (100<<(j<<3));\n          else if(temp < binbounds[23]) temp2 += (96<<(j<<3));\n          else if(temp < binbounds[22]) temp2 += (92<<(j<<3));\n          else if(temp < binbounds[21]) temp2 += (88<<(j<<3));\n          else if(temp < binbounds[20]) temp2 += (84<<(j<<3));\n          else if(temp < binbounds[19]) temp2 += (80<<(j<<3));\n          else if(temp < binbounds[18]) temp2 += (76<<(j<<3));\n          else if(temp < binbounds[17]) temp2 += (72<<(j<<3));\n          else if(temp < binbounds[16]) temp2 += (68<<(j<<3));\n          else if(temp < binbounds[15]) temp2 += (64<<(j<<3));\n          else if(temp < binbounds[14]) temp2 += (60<<(j<<3));\n          else if(temp < binbounds[13]) temp2 += (56<<(j<<3));\n          else if(temp < binbounds[12]) temp2 += (52<<(j<<3));\n          else if(temp < binbounds[11]) temp2 += (48<<(j<<3));\n          else if(temp < binbounds[10]) temp2 += (44<<(j<<3));\n          else if(temp < binbounds[9]) temp2 += (40<<(j<<3));\n          else if(temp < binbounds[8]) temp2 += (36<<(j<<3));\n          else if(temp < binbounds[7]) temp2 += (32<<(j<<3));\n          else if(temp < binbounds[6]) temp2 += (28<<(j<<3));\n          else if(temp < binbounds[5]) temp2 += (24<<(j<<3));\n          else if(temp < binbounds[4]) temp2 += (20<<(j<<3));\n          else if(temp < binbounds[3]) temp2 += (16<<(j<<3));\n          else if(temp < binbounds[2]) temp2 += (12<<(j<<3));\n          else if(temp < binbounds[1]) temp2 += (8<<(j<<3));\n          else if(temp < binbounds[0]) temp2 += (4<<(j<<3));\n          else temp2 += (0<<(j<<3));\n        }\n      }\n      g_odata[by+(i<<(LOG2_GRID_SIZE - 2))] = temp2;\n    }\n  }\n}\n\n\n__global__ void ACFKernel(cartesian g_idata1, cartesian g_idata2, unsigned int* g_odata) \n{\n  \n\n  extern __shared__ double3 sdata[];\n  double temp;\n  unsigned int temp2;\n  double3 vec1, vec2;\n  \n\n  int tx = (blockIdx.x<<7) + threadIdx.x;\n  \n\n  int by = (blockIdx.y<<7);\n\n  \n\n  vec1.x = g_idata2.x[tx];\n  vec1.y = g_idata2.y[tx];\n  vec1.z = g_idata2.z[tx];\n  \n\n  \n\n  sdata[threadIdx.x].x = g_idata1.x[by+threadIdx.x];\n  sdata[threadIdx.x].y = g_idata1.y[by+threadIdx.x];\n  sdata[threadIdx.x].z = g_idata1.z[by+threadIdx.x];\n  \n\n\n  \n\n  __syncthreads();\n\n  \n\n  by <<= (LOG2_GRID_SIZE - 2);\n  by += tx;\n\n  \n\n#pragma unroll\n  for(int i=0; i<128; i+=4) {   \n\n    temp2 = 0;\n#pragma unroll\n    for(int j=0; j<4; j++) {    \n\n      \n\n      vec2 = sdata[i+j];\n      temp = vec1.x*vec2.x + vec1.y*vec2.y + vec1.z*vec2.z;\n      \n\n      \n\n      if(temp < binbounds[30]) temp2 += (124<<(j<<3));\n      else if(temp < binbounds[29]) temp2 += (120<<(j<<3));\n      else if(temp < binbounds[28]) temp2 += (116<<(j<<3));\n      else if(temp < binbounds[27]) temp2 += (112<<(j<<3));\n      else if(temp < binbounds[26]) temp2 += (108<<(j<<3));\n      else if(temp < binbounds[25]) temp2 += (104<<(j<<3));\n      else if(temp < binbounds[24]) temp2 += (100<<(j<<3));\n      else if(temp < binbounds[23]) temp2 += (96<<(j<<3));\n      else if(temp < binbounds[22]) temp2 += (92<<(j<<3));\n      else if(temp < binbounds[21]) temp2 += (88<<(j<<3));\n      else if(temp < binbounds[20]) temp2 += (84<<(j<<3));\n      else if(temp < binbounds[19]) temp2 += (80<<(j<<3));\n      else if(temp < binbounds[18]) temp2 += (76<<(j<<3));\n      else if(temp < binbounds[17]) temp2 += (72<<(j<<3));\n      else if(temp < binbounds[16]) temp2 += (68<<(j<<3));\n      else if(temp < binbounds[15]) temp2 += (64<<(j<<3));\n      else if(temp < binbounds[14]) temp2 += (60<<(j<<3));\n      else if(temp < binbounds[13]) temp2 += (56<<(j<<3));\n      else if(temp < binbounds[12]) temp2 += (52<<(j<<3));\n      else if(temp < binbounds[11]) temp2 += (48<<(j<<3));\n      else if(temp < binbounds[10]) temp2 += (44<<(j<<3));\n      else if(temp < binbounds[9]) temp2 += (40<<(j<<3));\n      else if(temp < binbounds[8]) temp2 += (36<<(j<<3));\n      else if(temp < binbounds[7]) temp2 += (32<<(j<<3));\n      else if(temp < binbounds[6]) temp2 += (28<<(j<<3));\n      else if(temp < binbounds[5]) temp2 += (24<<(j<<3));\n      else if(temp < binbounds[4]) temp2 += (20<<(j<<3));\n      else if(temp < binbounds[3]) temp2 += (16<<(j<<3));\n      else if(temp < binbounds[2]) temp2 += (12<<(j<<3));\n      else if(temp < binbounds[1]) temp2 += (8<<(j<<3));\n      else if(temp < binbounds[0]) temp2 += (4<<(j<<3));\n      else temp2 += (0<<(j<<3));\n    }\n    g_odata[by+(i<<(LOG2_GRID_SIZE - 2))] = temp2;\n  }\n}\n\n#endif\n", "histogram_kernel.cu": "\n\n\n#ifndef _HISTOGRAM_KERNEL_H_\n#define _HISTOGRAM_KERNEL_H_\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#define   NUMTHREADS    128\n#define   MAXNUMBLOCKS  16384\n#define   MAXBLOCKSEND  32\n#define   DATAPERBLOCK  (NUMTHREADS * 63)\n#define   MEMPERBLOCK   (NUMTHREADS * NUMBINS)\n#define   HISTOSIZE     (NUMBINS * sizeof(unsigned int))\n\n\n\nunsigned int *d_odata;\nunsigned int *h_odata;\n\n\n\nint iDivUp(int a, int b);\n\n\n__global__ void histoKernel(unsigned int*__restrict__ g_odata, unsigned int*__restrict__ g_idata, int size);\n\n\n__global__ void mergeKernel(unsigned int* g_iodata, int numBlocks);\n\n\n\n\n\n\n\n\nvoid histoInit(void) {\n  hipHostMalloc((void**)&h_odata, HISTOSIZE * MAXBLOCKSEND);\n  hipMalloc((void **)&d_odata, MAXNUMBLOCKS * HISTOSIZE);\n}\n\n\n\nvoid histoClose(void) {\n  hipFree(d_odata);\n  hipHostFree(h_odata);\n}\n\n\n\n\n\n\n\n\n\nvoid GPUHistogram(unsigned int* h_result, unsigned int* d_idata, int num, hipStream_t &stream) {\n  \n\n  const int numBlocks = iDivUp(num >> 2, DATAPERBLOCK);\n  if(numBlocks > MAXNUMBLOCKS) {\n    printf(\"Data set too large for GPU Histogram.\");\n    return;\n  }\n  \n\n  dim3 grid(numBlocks, 1, 1);\n  dim3 threads(NUMTHREADS, 1, 1);\n  hipLaunchKernelGGL(histoKernel, grid, threads, 0, stream , d_odata, d_idata, num >> 2);\n\n  \n\n  const int endNumBlocks = min(MAXBLOCKSEND, numBlocks);\n  if(MAXBLOCKSEND < numBlocks){\n    \n\n    dim3 merge_grid (MAXBLOCKSEND, 1, 1);\n    dim3 merge_threads (NUMBINS, 1, 1);\n    hipLaunchKernelGGL(mergeKernel, merge_grid, merge_threads, 0, stream , d_odata, numBlocks);\n  }\n  \n\n  hipMemcpyAsync(h_odata, d_odata, endNumBlocks * HISTOSIZE, hipMemcpyDeviceToHost, stream);\n  hipStreamSynchronize(stream);\n  \n\n  for(int i = 1; i < endNumBlocks; i++){\n    for(int j = 0; j < NUMBINS; j++)\n      h_odata[j] += h_odata[i * NUMBINS + j];\n  }\n  \n\n  for(int i = 0; i < NUMBINS; i++) {\n    h_result[i] = h_odata[i];\n  }\n}\n\nint iDivUp(int a, int b){\n  return (a%b != 0) ? (a/b + 1) : (a/b);\n}\n\n\n\n\n\n__global__ void histoKernel(unsigned int*__restrict__ g_odata, unsigned int*__restrict__ g_idata, int size) {\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  const int threadPos = (threadIdx.x & (~63)) | ((threadIdx.x & 15) << 2) | ((threadIdx.x & 48) >> 4);\n\n  \n\n  __shared__ unsigned char s_Hist[MEMPERBLOCK];\n\n  \n\n  for(int pos = threadIdx.x; pos < (MEMPERBLOCK >> 2); pos += blockDim.x)\n    ((unsigned int *)s_Hist)[pos] = 0;\n\n  __syncthreads();\n\n  \n\n  const int gStart = __mul24(blockIdx.x, DATAPERBLOCK);\n  \n\n  const int blockData = min(size - gStart, DATAPERBLOCK);\n\n  unsigned int dataTemp;\n  for(int pos = threadIdx.x; pos < blockData; pos += blockDim.x){\n    \n\n    dataTemp = g_idata[gStart + pos];\n    s_Hist[threadPos + __mul24( (dataTemp >>  2) & 63, NUMTHREADS)]++;\n    s_Hist[threadPos + __mul24( (dataTemp >> 10) & 63, NUMTHREADS)]++;\n    s_Hist[threadPos + __mul24( (dataTemp >> 18) & 63, NUMTHREADS)]++;\n    s_Hist[threadPos + __mul24( (dataTemp >> 26) & 63, NUMTHREADS)]++;\n  }\n\n  __syncthreads();\n\n  \n\n  if(threadIdx.x < NUMBINS){\n    unsigned int sum = 0;\n    \n\n    const int tid = threadIdx.x;\n    \n\n    const int hStart = __mul24(tid, NUMTHREADS);\n    \n\n    const int accumStart = (threadIdx.x & 15) * 4;\n\n    \n\n    for(int i = 0, accum = accumStart; i < NUMTHREADS; i++){\n      sum += s_Hist[hStart + accum];\n      if(++accum == NUMTHREADS) accum = 0;\n    }\n    \n\n    g_odata[blockIdx.x * NUMBINS + tid] = sum;\n  }\n}\n\n\n\n\n\n__global__ void mergeKernel(unsigned int* d_iodata, int numBlocks) {\n  \n\n  const int size = numBlocks * NUMBINS;\n  \n\n  const int gPos = blockIdx.x * NUMBINS + threadIdx.x;\n  \n\n  const int numThreads = gridDim.x * blockDim.x;\n  unsigned int sum = 0;\n\n  \n\n  for(int pos = gPos; pos < size; pos += numThreads)\n    sum += d_iodata[pos];\n\n  \n\n  d_iodata[gPos] = sum;\n}\n\n#endif\n"}}
{"kernel_name": "vanGenuchten", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n__global__ \nvoid vanGenuchten(\n  const double *__restrict__ Ksat,\n  const double *__restrict__ psi,\n        double *__restrict__ C,\n        double *__restrict__ theta,\n        double *__restrict__ K,\n  const int size)\n{\n  double Se, _theta, _psi, lambda, m, t;\n\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if (i < size)\n  {\n    lambda = n - 1.0;\n    m = lambda/n;\n\n    \n\n    _psi = psi[i] * 100.0;\n    if ( _psi < 0.0 )\n      _theta = (theta_S - theta_R) / pow(1.0 + pow((alpha*(-_psi)),n), m) + theta_R;\n    else\n      _theta = theta_S;\n\n    theta[i] = _theta;\n\n    \n\n    Se = (_theta - theta_R)/(theta_S - theta_R);\n\n    \n\n    t = 1.0 - pow(1.0-pow(Se,1.0/m), m);\n    K[i] = Ksat[i] * sqrt(Se) * t * t;\n\n  \n\n  \n\n  if (_psi < 0.0)\n    C[i] = 100.0 * alpha * n * (1.0/n-1.0)*pow(alpha*abs(_psi), n-1.0)\n      * (theta_R-theta_S) * pow(pow(alpha*abs(_psi), n)+1.0, 1.0/n-2.0);\n  else\n    C[i] = 0.0;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s <dimX> <dimY> <dimZ> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int dimX = atoi(argv[1]);\n  const int dimY = atoi(argv[2]);\n  const int dimZ = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int size = dimX * dimY * dimZ;\n  const int size_byte = size * sizeof(double);\n\n  double *Ksat, *psi, *C, *theta, *K;\n  double *C_ref, *theta_ref, *K_ref;\n  \n  Ksat = new double[size];\n  psi = new double[size];\n  C = new double[size];\n  theta = new double[size];\n  K = new double[size];\n\n  C_ref = new double[size];\n  theta_ref = new double[size];\n  K_ref = new double[size];\n\n  \n\n  for (int i = 0; i < size; i++) {\n    Ksat[i] = 1e-6 +  (1.0 - 1e-6) * i / size; \n    psi[i] = -100.0 + 101.0 * i / size;\n  }\n\n  \n\n  reference(Ksat, psi, C_ref, theta_ref, K_ref, size);\n\n  double *d_Ksat, *d_psi, *d_C, *d_theta, *d_K;\n  cudaMalloc((void**)&d_Ksat, size_byte); \n  cudaMalloc((void**)&d_psi, size_byte); \n  cudaMalloc((void**)&d_C, size_byte); \n  cudaMalloc((void**)&d_theta, size_byte); \n  cudaMalloc((void**)&d_K, size_byte); \n\n  cudaMemcpy(d_Ksat, Ksat, size_byte, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_psi, psi, size_byte, cudaMemcpyHostToDevice);\n\n  dim3 grids ((size+255)/256);\n  dim3 blocks (256);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    vanGenuchten <<< grids, blocks >>> (d_Ksat, d_psi, d_C, d_theta, d_K, size);\n\n  cudaDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(C, d_C, size_byte, cudaMemcpyDeviceToHost);\n  cudaMemcpy(theta, d_theta, size_byte, cudaMemcpyDeviceToHost);\n  cudaMemcpy(K, d_K, size_byte, cudaMemcpyDeviceToHost);\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (fabs(C[i] - C_ref[i]) > 1e-3 || \n        fabs(theta[i] - theta_ref[i]) > 1e-3 ||\n        fabs(K[i] - K_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_Ksat);\n  cudaFree(d_psi);\n  cudaFree(d_C);\n  cudaFree(d_theta);\n  cudaFree(d_K);\n\n  delete(Ksat);\n  delete(psi);\n  delete(C);\n  delete(theta);\n  delete(K);\n  delete(C_ref);\n  delete(theta_ref);\n  delete(K_ref);\n\n  return 0;\n}\n"}}
{"kernel_name": "vanGenuchten", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n__global__ \nvoid vanGenuchten(\n  const double *__restrict__ Ksat,\n  const double *__restrict__ psi,\n        double *__restrict__ C,\n        double *__restrict__ theta,\n        double *__restrict__ K,\n  const int size)\n{\n  double Se, _theta, _psi, lambda, m, t;\n\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if (i < size)\n  {\n    lambda = n - 1.0;\n    m = lambda/n;\n\n    \n\n    _psi = psi[i] * 100.0;\n    if ( _psi < 0.0 )\n      _theta = (theta_S - theta_R) / pow(1.0 + pow((alpha*(-_psi)),n), m) + theta_R;\n    else\n      _theta = theta_S;\n\n    theta[i] = _theta;\n\n    \n\n    Se = (_theta - theta_R)/(theta_S - theta_R);\n\n    \n\n    t = 1.0 - pow(1.0-pow(Se,1.0/m), m);\n    K[i] = Ksat[i] * sqrt(Se) * t * t;\n\n    \n\n    \n\n    if (_psi < 0.0)\n      C[i] = 100.0 * alpha * n * (1.0/n-1.0)*pow(alpha*abs(_psi), n-1.0)\n        * (theta_R-theta_S) * pow(pow(alpha*abs(_psi), n)+1.0, 1.0/n-2.0);\n    else\n      C[i] = 0.0;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s <dimX> <dimY> <dimZ> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int dimX = atoi(argv[1]);\n  const int dimY = atoi(argv[2]);\n  const int dimZ = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int size = dimX * dimY * dimZ;\n  const int size_byte = size * sizeof(double);\n\n  double *Ksat, *psi, *C, *theta, *K;\n  double *C_ref, *theta_ref, *K_ref;\n  \n  Ksat = new double[size];\n  psi = new double[size];\n  C = new double[size];\n  theta = new double[size];\n  K = new double[size];\n\n  C_ref = new double[size];\n  theta_ref = new double[size];\n  K_ref = new double[size];\n\n  \n\n  for (int i = 0; i < size; i++) {\n    Ksat[i] = 1e-6 +  (1.0 - 1e-6) * i / size; \n    psi[i] = -100.0 + 101.0 * i / size;\n  }\n\n  \n\n  reference(Ksat, psi, C_ref, theta_ref, K_ref, size);\n\n  double *d_Ksat, *d_psi, *d_C, *d_theta, *d_K;\n  hipMalloc((void**)&d_Ksat, size_byte); \n  hipMalloc((void**)&d_psi, size_byte); \n  hipMalloc((void**)&d_C, size_byte); \n  hipMalloc((void**)&d_theta, size_byte); \n  hipMalloc((void**)&d_K, size_byte); \n\n  hipMemcpy(d_Ksat, Ksat, size_byte, hipMemcpyHostToDevice);\n  hipMemcpy(d_psi, psi, size_byte, hipMemcpyHostToDevice);\n\n  dim3 grids ((size+255)/256);\n  dim3 blocks (256);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(vanGenuchten, grids, blocks , 0, 0, d_Ksat, d_psi, d_C, d_theta, d_K, size);\n\n  hipDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(C, d_C, size_byte, hipMemcpyDeviceToHost);\n  hipMemcpy(theta, d_theta, size_byte, hipMemcpyDeviceToHost);\n  hipMemcpy(K, d_K, size_byte, hipMemcpyDeviceToHost);\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (fabs(C[i] - C_ref[i]) > 1e-3 || \n        fabs(theta[i] - theta_ref[i]) > 1e-3 ||\n        fabs(K[i] - K_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_Ksat);\n  hipFree(d_psi);\n  hipFree(d_C);\n  hipFree(d_theta);\n  hipFree(d_K);\n\n  delete(Ksat);\n  delete(psi);\n  delete(C);\n  delete(theta);\n  delete(K);\n  delete(C_ref);\n  delete(theta_ref);\n  delete(K_ref);\n\n  return 0;\n}\n"}}
{"kernel_name": "vanGenuchten", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\nvoid vanGenuchten(\n  const double *__restrict Ksat,\n  const double *__restrict psi,\n        double *__restrict C,\n        double *__restrict theta,\n        double *__restrict K,\n  const int size)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < size; i++) {\n\n    double Se, _theta, _psi, lambda, m, t;\n\n    lambda = n - 1.0;\n    m = lambda/n;\n\n    \n\n    _psi = psi[i] * 100.0;\n    if ( _psi < 0.0 )\n      _theta = (theta_S - theta_R) / pow(1.0 + pow((alpha*(-_psi)),n), m) + theta_R;\n    else\n      _theta = theta_S;\n\n    theta[i] = _theta;\n\n    \n\n    Se = (_theta - theta_R)/(theta_S - theta_R);\n\n    \n\n    t = 1.0 - pow(1.0-pow(Se,1.0/m), m);\n    K[i] = Ksat[i] * sqrt(Se) * t * t;\n\n    \n\n    \n\n    if (_psi < 0.0)\n      C[i] = 100 * alpha * n * (1.0/n-1.0)*pow(alpha*abs(_psi), n-1.0)\n        * (theta_R-theta_S) * pow(pow(alpha*abs(_psi), n)+1.0, 1.0/n-2.0);\n    else\n      C[i] = 0.0;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s <dimX> <dimY> <dimZ> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int dimX = atoi(argv[1]);\n  const int dimY = atoi(argv[2]);\n  const int dimZ = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int size = dimX * dimY * dimZ;\n\n  double *Ksat, *psi, *C, *theta, *K;\n  double *C_ref, *theta_ref, *K_ref;\n  \n  Ksat = new double[size];\n  psi = new double[size];\n  C = new double[size];\n  theta = new double[size];\n  K = new double[size];\n\n  C_ref = new double[size];\n  theta_ref = new double[size];\n  K_ref = new double[size];\n\n  \n\n  for (int i = 0; i < size; i++) {\n    Ksat[i] = 1e-6 +  (1.0 - 1e-6) * i / size; \n    psi[i] = -100.0 + 101.0 * i / size;\n  }\n\n  \n\n  reference(Ksat, psi, C_ref, theta_ref, K_ref, size);\n\n  #pragma omp target data map(to: Ksat[0:size], psi[0:size]) \\\n                          map(from: C[0:size], theta[0:size], K[0:size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      vanGenuchten(Ksat, psi, C, theta, K, size);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (fabs(C[i] - C_ref[i]) > 1e-3 || \n        fabs(theta[i] - theta_ref[i]) > 1e-3 ||\n        fabs(K[i] - K_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete(Ksat);\n  delete(psi);\n  delete(C);\n  delete(theta);\n  delete(K);\n  delete(C_ref);\n  delete(theta_ref);\n  delete(K_ref);\n\n  return 0;\n}\n"}}
{"kernel_name": "vanGenuchten", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\nvoid vanGenuchten(\n  const double *__restrict Ksat,\n  const double *__restrict psi,\n        double *__restrict C,\n        double *__restrict theta,\n        double *__restrict K,\n  const int size)\n{\n    for (int i = 0; i < size; i++) {\n\n    double Se, _theta, _psi, lambda, m, t;\n\n    lambda = n - 1.0;\n    m = lambda/n;\n\n    \n\n    _psi = psi[i] * 100.0;\n    if ( _psi < 0.0 )\n      _theta = (theta_S - theta_R) / pow(1.0 + pow((alpha*(-_psi)),n), m) + theta_R;\n    else\n      _theta = theta_S;\n\n    theta[i] = _theta;\n\n    \n\n    Se = (_theta - theta_R)/(theta_S - theta_R);\n\n    \n\n    t = 1.0 - pow(1.0-pow(Se,1.0/m), m);\n    K[i] = Ksat[i] * sqrt(Se) * t * t;\n\n    \n\n    \n\n    if (_psi < 0.0)\n      C[i] = 100 * alpha * n * (1.0/n-1.0)*pow(alpha*abs(_psi), n-1.0)\n        * (theta_R-theta_S) * pow(pow(alpha*abs(_psi), n)+1.0, 1.0/n-2.0);\n    else\n      C[i] = 0.0;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s <dimX> <dimY> <dimZ> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int dimX = atoi(argv[1]);\n  const int dimY = atoi(argv[2]);\n  const int dimZ = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int size = dimX * dimY * dimZ;\n\n  double *Ksat, *psi, *C, *theta, *K;\n  double *C_ref, *theta_ref, *K_ref;\n  \n  Ksat = new double[size];\n  psi = new double[size];\n  C = new double[size];\n  theta = new double[size];\n  K = new double[size];\n\n  C_ref = new double[size];\n  theta_ref = new double[size];\n  K_ref = new double[size];\n\n  \n\n  for (int i = 0; i < size; i++) {\n    Ksat[i] = 1e-6 +  (1.0 - 1e-6) * i / size; \n    psi[i] = -100.0 + 101.0 * i / size;\n  }\n\n  \n\n  reference(Ksat, psi, C_ref, theta_ref, K_ref, size);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      vanGenuchten(Ksat, psi, C, theta, K, size);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (fabs(C[i] - C_ref[i]) > 1e-3 || \n        fabs(theta[i] - theta_ref[i]) > 1e-3 ||\n        fabs(K[i] - K_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete(Ksat);\n  delete(psi);\n  delete(C);\n  delete(theta);\n  delete(K);\n  delete(C_ref);\n  delete(theta_ref);\n  delete(K_ref);\n\n  return 0;\n}"}}
{"kernel_name": "vanGenuchten", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nvoid vanGenuchten(\n  const double *__restrict__ Ksat,\n  const double *__restrict__ psi,\n        double *__restrict__ C,\n        double *__restrict__ theta,\n        double *__restrict__ K,\n  const int size,\n  sycl::nd_item<1> &item)\n{\n  double Se, _theta, _psi, lambda, m;\n\n  int i = item.get_global_id(0);\n  if (i < size)\n  {\n    lambda = n - 1.0;\n    m = lambda/n;\n\n    \n\n    _psi = psi[i] * 100.0;\n    if ( _psi < 0.0 )\n      _theta = (theta_S - theta_R) / sycl::pow(\n               1.0 + sycl::pow((alpha * (-_psi)), n), m) + theta_R;\n    else\n      _theta = theta_S;\n\n    theta[i] = _theta;\n\n   \n\n   Se = (_theta - theta_R)/(theta_S - theta_R);\n\n   \n\n   double t = 1.0 - sycl::pow(1.0 - sycl::pow(Se, 1.0 / m), m);\n   K[i] = Ksat[i] * sycl::sqrt(Se) * t * t;\n\n   \n\n   \n\n   if (_psi < 0.0)\n     C[i] = 100.0 * alpha * n * (1.0 / n - 1.0) *\n            sycl::pow(alpha * sycl::fabs(_psi), n - 1.0) *\n            (theta_R - theta_S) *\n            sycl::pow(sycl::pow(alpha * sycl::fabs(_psi), n) + 1.0,\n                           1.0 / n - 2.0);\n   else\n     C[i] = 0.0;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s <dimX> <dimY> <dimZ> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int dimX = atoi(argv[1]);\n  const int dimY = atoi(argv[2]);\n  const int dimZ = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int size = dimX * dimY * dimZ;\n  const int size_byte = size * sizeof(double);\n\n  double *Ksat, *psi, *C, *theta, *K;\n  double *C_ref, *theta_ref, *K_ref;\n\n  Ksat = new double[size];\n  psi = new double[size];\n  C = new double[size];\n  theta = new double[size];\n  K = new double[size];\n\n  C_ref = new double[size];\n  theta_ref = new double[size];\n  K_ref = new double[size];\n\n  \n\n  for (int i = 0; i < size; i++) {\n    Ksat[i] = 1e-6 +  (1.0 - 1e-6) * i / size;\n    psi[i] = -100.0 + 101.0 * i / size;\n  }\n\n  \n\n  reference(Ksat, psi, C_ref, theta_ref, K_ref, size);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double *d_Ksat, *d_psi, *d_C, *d_theta, *d_K;\n  d_Ksat = (double *)sycl::malloc_device(size_byte, q);\n  d_psi = (double *)sycl::malloc_device(size_byte, q);\n  d_C = (double *)sycl::malloc_device(size_byte, q);\n  d_theta = (double *)sycl::malloc_device(size_byte, q);\n  d_K = (double *)sycl::malloc_device(size_byte, q);\n\n  q.memcpy(d_Ksat, Ksat, size_byte);\n  q.memcpy(d_psi, psi, size_byte);\n\n  sycl::range<1> gws ((size + 255) / 256 * 256);\n  sycl::range<1> lws (256);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        vanGenuchten(d_Ksat, d_psi, d_C, d_theta, d_K, size, item);\n      });\n    });\n\n  q.wait();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(C, d_C, size_byte);\n  q.memcpy(theta, d_theta, size_byte);\n  q.memcpy(K, d_K, size_byte);\n\n  q.wait();\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (fabs(C[i] - C_ref[i]) > 1e-3 ||\n        fabs(theta[i] - theta_ref[i]) > 1e-3 ||\n        fabs(K[i] - K_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_Ksat, q);\n  sycl::free(d_psi, q);\n  sycl::free(d_C, q);\n  sycl::free(d_theta, q);\n  sycl::free(d_K, q);\n\n  delete(Ksat);\n  delete(psi);\n  delete(C);\n  delete(theta);\n  delete(K);\n  delete(C_ref);\n  delete(theta_ref);\n  delete(K_ref);\n\n  return 0;\n}\n"}}
{"kernel_name": "winograd", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cuda.h>\n#include \"utils.h\"\n\n__global__ void winograd_conv2d(\n    const DATA_TYPE *__restrict__ input,\n    const DATA_TYPE *__restrict__ transformed_filter ,\n    DATA_TYPE *__restrict__ output,\n    const int offset_i,\n    const int offset_j)\n{\n  int tile_i = blockIdx.x * blockDim.x + threadIdx.x + offset_i;\n  int tile_j = blockIdx.y * blockDim.y + threadIdx.y + offset_j;\n\n  \n\n\n  DATA_TYPE input_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n  for (int i = 0; i < 4; i ++) {\n    for (int j = 0; j < 4; j ++) { \n      int x = 2 * tile_i + i;\n      int y = 2 * tile_j + j;\n      if (x >= MAP_SIZE || y >= MAP_SIZE) {\n        input_tile[i][j] = 0;\n        continue;\n      }\n      input_tile[i][j] = input[x * MAP_SIZE + y];\n    }\n  } \n\n  \n\n  for (int j = 0; j < 4; j ++) {\n    tmp_tile[0][j] = input_tile[0][j] - input_tile[2][j];\n    tmp_tile[1][j] = input_tile[1][j] + input_tile[2][j];\n    tmp_tile[2][j] = -input_tile[1][j] + input_tile[2][j];\n    tmp_tile[3][j] = input_tile[1][j] - input_tile[3][j];\n  }\n  \n\n  for (int i = 0; i < 4; i ++) {\n    transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n    transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n    transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n    transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n  }\n\n  \n\n\n  DATA_TYPE multiplied_tile[4][4];\n  for (int i = 0; i < 4; i ++) {\n    for (int j = 0; j < 4; j ++) {\n      multiplied_tile[i][j] = transformed_tile[i][j] * transformed_filter[i * 4 + j];\n    }\n  }\n\n  \n\n\n  DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n  \n\n  for (int j = 0; j < 4; j ++) {\n    tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n    tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n  }\n  \n\n  for (int i = 0; i < 2; i ++) {\n    final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n    final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n  }\n\n  for (int i = 0; i < 2; i ++) {\n    for (int j = 0; j < 2; j ++) {\n      int x = 2 * tile_i + i;\n      int y = 2 * tile_j + j;\n      if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n        continue;\n      }\n      output[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n\n  double start = rtclock();\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B_outputFromGpu = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n  DATA_TYPE *d_A;\n  cudaMalloc((void**)&d_A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  cudaMemcpy(d_A, A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n  DATA_TYPE *d_B;\n  cudaMalloc((void**)&d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE));\n\n  DATA_TYPE *d_C;\n  cudaMalloc((void**)&d_C, 16 * sizeof(DATA_TYPE));\n  cudaMemcpy(d_C, C, 16 * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n  int global_offset[2];\n\n  bool pass = true;\n\n  \n\n  double co_time = 0.0;\n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) \n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    global_offset[0] = cpu_global_size[0];\n    global_offset[1] = 0;\n\n    dim3 grid(gpu_global_size[0] / localWorkSize[0], gpu_global_size[1] / localWorkSize[1]);\n    dim3 block(localWorkSize[0], localWorkSize[1]);\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n      winograd_conv2d<<<grid, block>>>(d_A, d_C, d_B, global_offset[0], global_offset[1]);\n    }\n\n    if (cpu_run) {\n      \n\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      cudaMemcpy(d_B, B, gpu_run ? global_offset[0]*2*(MAP_SIZE-2)*sizeof(DATA_TYPE) : \n          (MAP_SIZE-2)*(MAP_SIZE-2)*sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n    }\n\n    cudaMemcpy(B_outputFromGpu, d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE), cudaMemcpyDeviceToHost);\n\n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B, C);\n    pass &= compareResults(B, B_outputFromGpu);\n\n  } \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_A);\n  cudaFree(d_B);\n  cudaFree(d_C);\n  free(A);\n  free(B);\n  free(B_outputFromGpu);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}\n"}}
{"kernel_name": "winograd", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"utils.h\"\n\n__global__ void winograd_conv2d(\n    const DATA_TYPE *__restrict__ input,\n    const DATA_TYPE *__restrict__ transformed_filter ,\n    DATA_TYPE *__restrict__ output,\n    const int offset_i,\n    const int offset_j)\n{\n  int tile_i = blockIdx.x * blockDim.x + threadIdx.x + offset_i;\n  int tile_j = blockIdx.y * blockDim.y + threadIdx.y + offset_j;\n\n  \n\n\n  DATA_TYPE input_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n  for (int i = 0; i < 4; i ++) {\n    for (int j = 0; j < 4; j ++) { \n      int x = 2 * tile_i + i;\n      int y = 2 * tile_j + j;\n      if (x >= MAP_SIZE || y >= MAP_SIZE) {\n        input_tile[i][j] = 0;\n        continue;\n      }\n      input_tile[i][j] = input[x * MAP_SIZE + y];\n    }\n  } \n\n  \n\n  for (int j = 0; j < 4; j ++) {\n    tmp_tile[0][j] = input_tile[0][j] - input_tile[2][j];\n    tmp_tile[1][j] = input_tile[1][j] + input_tile[2][j];\n    tmp_tile[2][j] = -input_tile[1][j] + input_tile[2][j];\n    tmp_tile[3][j] = input_tile[1][j] - input_tile[3][j];\n  }\n  \n\n  for (int i = 0; i < 4; i ++) {\n    transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n    transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n    transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n    transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n  }\n\n  \n\n\n  DATA_TYPE multiplied_tile[4][4];\n  for (int i = 0; i < 4; i ++) {\n    for (int j = 0; j < 4; j ++) {\n      multiplied_tile[i][j] = transformed_tile[i][j] * transformed_filter[i * 4 + j];\n    }\n  }\n\n  \n\n\n  DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n  \n\n  for (int j = 0; j < 4; j ++) {\n    tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n    tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n  }\n  \n\n  for (int i = 0; i < 2; i ++) {\n    final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n    final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n  }\n\n  for (int i = 0; i < 2; i ++) {\n    for (int j = 0; j < 2; j ++) {\n      int x = 2 * tile_i + i;\n      int y = 2 * tile_j + j;\n      if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n        continue;\n      }\n      output[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n\n  double start = rtclock();\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B_outputFromGpu = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n  DATA_TYPE *d_A;\n  hipMalloc((void**)&d_A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  hipMemcpy(d_A, A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE), hipMemcpyHostToDevice);\n\n  DATA_TYPE *d_B;\n  hipMalloc((void**)&d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE));\n\n  DATA_TYPE *d_C;\n  hipMalloc((void**)&d_C, 16 * sizeof(DATA_TYPE));\n  hipMemcpy(d_C, C, 16 * sizeof(DATA_TYPE), hipMemcpyHostToDevice);\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n  int global_offset[2];\n\n  bool pass = true;\n\n  \n\n  double co_time = 0.0;\n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) \n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    global_offset[0] = cpu_global_size[0];\n    global_offset[1] = 0;\n\n    dim3 grid(gpu_global_size[0] / localWorkSize[0], gpu_global_size[1] / localWorkSize[1]);\n    dim3 block(localWorkSize[0], localWorkSize[1]);\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n      hipLaunchKernelGGL(winograd_conv2d, grid, block, 0, 0, d_A, d_C, d_B, global_offset[0], global_offset[1]);\n    }\n\n    if (cpu_run) {\n      \n\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      hipMemcpy(d_B, B, gpu_run ? global_offset[0]*2*(MAP_SIZE-2)*sizeof(DATA_TYPE) : \n          (MAP_SIZE-2)*(MAP_SIZE-2)*sizeof(DATA_TYPE), hipMemcpyHostToDevice);\n    }\n\n    hipMemcpy(B_outputFromGpu, d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE), hipMemcpyDeviceToHost);\n\n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B, C);\n    pass &= compareResults(B, B_outputFromGpu);\n\n  } \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_A);\n  hipFree(d_B);\n  hipFree(d_C);\n  free(A);\n  free(B);\n  free(B_outputFromGpu);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}\n"}}
{"kernel_name": "winograd", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <omp.h>\n#include \"utils.h\"\n\nint main(int argc, char* argv[]) {\n\n  double start = rtclock();\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B_host = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n  size_t global_offset[2];\n\n  bool pass = true;\n\n  double co_time = 0.0;\n\n#pragma omp target data map (to: A[0:MAP_SIZE * MAP_SIZE],C[0:16]), \\\n                        map (alloc: B[0:(MAP_SIZE-2) * (MAP_SIZE-2)])\n\n{\n  \n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) \n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    global_offset[0] = cpu_global_size[0];\n    global_offset[1] = 0;\n\n    const int tile_i_size = gpu_global_size[0];\n    const int tile_j_size = gpu_global_size[1];\n    const int offset_i = global_offset[0];\n    const int offset_j = global_offset[1];\n    const int thread_size = localWorkSize[1] * localWorkSize[0];\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(thread_size)\n      for (int tile_j = 0; tile_j < tile_j_size; tile_j++) {\n        for (int tile_i = 0; tile_i < tile_i_size; tile_i++) {\n          \n\n\n          DATA_TYPE input_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) { \n              int x = 2 * (tile_i + offset_i) + i;\n              int y = 2 * (tile_j + offset_j) + j;\n              if (x >= MAP_SIZE || y >= MAP_SIZE) {\n                input_tile[i][j] = 0;\n                continue;\n              }\n              input_tile[i][j] = A[x * MAP_SIZE + y];\n            }\n          } \n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile[0][j] = input_tile[0][j] - input_tile[2][j];\n            tmp_tile[1][j] = input_tile[1][j] + input_tile[2][j];\n            tmp_tile[2][j] = -input_tile[1][j] + input_tile[2][j];\n            tmp_tile[3][j] = input_tile[1][j] - input_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 4; i ++) {\n            transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n            transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n          }\n\n          \n\n\n          DATA_TYPE multiplied_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) {\n              multiplied_tile[i][j] = transformed_tile[i][j] * C[i * 4 + j];\n            }\n          }\n\n          \n\n\n          DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n            tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 2; i ++) {\n            final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n            final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n          }\n\n          for (int i = 0; i < 2; i ++) {\n            for (int j = 0; j < 2; j ++) {\n              int x = 2 * (tile_i + offset_i) + i;\n              int y = 2 * (tile_j + offset_j) + j;\n              if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n                continue;\n              }\n              B[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n            }\n          }\n        }\n      }\n    }\n\n    if (cpu_run) {\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      if (gpu_run) {\n        #pragma omp target update to (B[0:offset_i*2*(MAP_SIZE-2)])\n      }\n      else {\n        #pragma omp target update to (B[0:(MAP_SIZE-2)*(MAP_SIZE-2)])\n      }\n    }\n\n    #pragma omp target update from (B[0:(MAP_SIZE-2)*(MAP_SIZE-2)])\n\n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B_host, C);\n    pass &= compareResults(B_host, B);\n\n  } \n\n}  \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  free(A);\n  free(B);\n  free(B_host);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}\n"}}
{"kernel_name": "winograd", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include \"utils.h\"\n\nint main(int argc, char* argv[]) {\n\n  double start = rtclock();\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B_host = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n  size_t global_offset[2];\n\n  bool pass = true;\n\n  double co_time = 0.0;\n\n\n{\n  \n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) \n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    global_offset[0] = cpu_global_size[0];\n    global_offset[1] = 0;\n\n    const int tile_i_size = gpu_global_size[0];\n    const int tile_j_size = gpu_global_size[1];\n    const int offset_i = global_offset[0];\n    const int offset_j = global_offset[1];\n    const int thread_size = localWorkSize[1] * localWorkSize[0];\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n            for (int tile_j = 0; tile_j < tile_j_size; tile_j++) {\n        for (int tile_i = 0; tile_i < tile_i_size; tile_i++) {\n          \n\n\n          DATA_TYPE input_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) { \n              int x = 2 * (tile_i + offset_i) + i;\n              int y = 2 * (tile_j + offset_j) + j;\n              if (x >= MAP_SIZE || y >= MAP_SIZE) {\n                input_tile[i][j] = 0;\n                continue;\n              }\n              input_tile[i][j] = A[x * MAP_SIZE + y];\n            }\n          } \n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile[0][j] = input_tile[0][j] - input_tile[2][j];\n            tmp_tile[1][j] = input_tile[1][j] + input_tile[2][j];\n            tmp_tile[2][j] = -input_tile[1][j] + input_tile[2][j];\n            tmp_tile[3][j] = input_tile[1][j] - input_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 4; i ++) {\n            transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n            transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n          }\n\n          \n\n\n          DATA_TYPE multiplied_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) {\n              multiplied_tile[i][j] = transformed_tile[i][j] * C[i * 4 + j];\n            }\n          }\n\n          \n\n\n          DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n            tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 2; i ++) {\n            final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n            final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n          }\n\n          for (int i = 0; i < 2; i ++) {\n            for (int j = 0; j < 2; j ++) {\n              int x = 2 * (tile_i + offset_i) + i;\n              int y = 2 * (tile_j + offset_j) + j;\n              if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n                continue;\n              }\n              B[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n            }\n          }\n        }\n      }\n    }\n\n    if (cpu_run) {\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      if (gpu_run) {\n              }\n      else {\n              }\n    }\n\n    \n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B_host, C);\n    pass &= compareResults(B_host, B);\n\n  } \n\n}  \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  free(A);\n  free(B);\n  free(B_host);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}"}}
{"kernel_name": "winograd", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n\nint main(int argc, char* argv[]) {\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B_outputFromGpu = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double start = rtclock();\n\n  DATA_TYPE *d_A = sycl::malloc_device<DATA_TYPE>(MAP_SIZE * MAP_SIZE, q);\n  q.memcpy(d_A, A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n\n  DATA_TYPE *d_B = sycl::malloc_device<DATA_TYPE>((MAP_SIZE-2) * (MAP_SIZE-2), q);\n\n  DATA_TYPE *d_C = sycl::malloc_device<DATA_TYPE>(16, q);\n  q.memcpy(d_C, C, 16 * sizeof(DATA_TYPE));\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n\n  bool pass = true;\n\n  \n\n  double co_time = 0.0;\n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X))\n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    const int offset_j = cpu_global_size[0];\n    const int offset_i = 0;\n\n    sycl::range<2> gpu_gws(gpu_global_size[1], gpu_global_size[0]);\n    sycl::range<2> cpu_gws(cpu_global_size[1], cpu_global_size[0]);\n    sycl::range<2> lws(localWorkSize[1], localWorkSize[0]);\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class winograd_conv2d>(\n          sycl::nd_range<2>(gpu_gws, lws), [=] (sycl::nd_item<2> item) {\n\n          int tile_j = item.get_global_id(0) + offset_j;\n          int tile_i = item.get_global_id(1) + offset_i;\n\n          \n\n\n          DATA_TYPE d_A_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) {\n              int x = 2 * tile_i + i;\n              int y = 2 * tile_j + j;\n              if (x >= MAP_SIZE || y >= MAP_SIZE) {\n                d_A_tile[i][j] = 0;\n                continue;\n              }\n              d_A_tile[i][j] = d_A[x * MAP_SIZE + y];\n            }\n          }\n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile[0][j] = d_A_tile[0][j] - d_A_tile[2][j];\n            tmp_tile[1][j] = d_A_tile[1][j] + d_A_tile[2][j];\n            tmp_tile[2][j] = -d_A_tile[1][j] + d_A_tile[2][j];\n            tmp_tile[3][j] = d_A_tile[1][j] - d_A_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 4; i ++) {\n            transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n            transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n          }\n\n          \n\n\n          DATA_TYPE multiplied_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) {\n              multiplied_tile[i][j] = transformed_tile[i][j] * d_C[i * 4 + j];\n            }\n          }\n\n          \n\n\n          DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n            tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 2; i ++) {\n            final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n            final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n          }\n\n          for (int i = 0; i < 2; i ++) {\n            for (int j = 0; j < 2; j ++) {\n              int x = 2 * tile_i + i;\n              int y = 2 * tile_j + j;\n              if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n                continue;\n              }\n              d_B[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n            }\n          }\n        });\n      });\n\n    }\n\n    if (cpu_run) {\n\n      \n\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      q.memcpy(d_B, B, gpu_run ? cpu_global_size[0]*2*(MAP_SIZE-2)*sizeof(DATA_TYPE) : \n               (MAP_SIZE-2)*(MAP_SIZE-2)*sizeof(DATA_TYPE));\n    }\n\n    q.memcpy(B_outputFromGpu, d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE)).wait();\n\n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B, C);\n    pass &= compareResults(B, B_outputFromGpu);\n\n  } \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_A, q);\n  sycl::free(d_B, q);\n  sycl::free(d_C, q);\n  free(A);\n  free(B);\n  free(B_outputFromGpu);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}\n"}}
{"kernel_name": "wsm5", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"utils.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  float *th, *pii, *q;\n  float *qc, *qi, *qr, *qs;\n  float *den, *p, *delz;\n  float *rain,*rainncv;\n  float *sr;\n  float *snow, *snowncv;\n\n  float delt = 10.f;\n  int ims = 0, ime = 59, jms = 0, jme = 45, kms = 0, kme = 2;\n  int ips = 0, ipe = 59, jps = 0, jpe = 45, kps = 0, kpe = 2;\n  int d3 = (ime-ims+1) * (jme-jms+1) * (kme-kms+1) ;\n  int d2 = (ime-ims+1) * (jme-jms+1) ;\n\n  int dips = 0 ; int dipe = (ipe-ips+1) ;\n  int djps = 0 ; int djpe = (jpe-jps+1) ;\n  int dkps = 0 ; int dkpe = (kpe-kps+1) ;\n\n  int remx = (ipe-ips+1) % XXX != 0 ? 1 : 0 ;\n  int remy = (jpe-jps+1) % YYY != 0 ? 1 : 0 ;\n\n  dim3 dimBlock( XXX , YYY ) ;\n  dim3 dimGrid ( (ipe-ips+1) / XXX + remx , (jpe-jps+1) / YYY + remy ) ;\n\n  float rain_sum = 0, snow_sum = 0;\n\n  long time = 0;\n  for (int i = 0; i < repeat; i++) {\n    \n\n    TODEV3(pii) ;\n    TODEV3(den) ;\n    TODEV3(p) ;\n    TODEV3(delz) ;\n\n    TODEV3(th) ;\n    TODEV3(q) ;\n    TODEV3(qc) ;\n    TODEV3(qi) ;\n    TODEV3(qr) ;\n    TODEV3(qs) ;\n    TODEV2(rain) ;\n    TODEV2(rainncv) ;\n    TODEV2(sr) ;\n    TODEV2(snow) ;\n    TODEV2(snowncv) ;\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    wsm <<< dimGrid, dimBlock >>> (\n      th_d, pii_d, q_d, qc_d, qi_d, qr_d, qs_d, den_d, p_d, delz_d,\n      rain_d, rainncv_d,\n      sr_d,\n      snow_d, snowncv_d,\n      delt,\n      dips+1 , (ipe-ips+1) , \n\n      djps+1 , (jpe-jps+1) , \n\n      dkps+1 , (kpe-kps+1),  \n\n      dips+1 , dipe ,        \n\n      djps+1 , djpe ,        \n\n      dkps+1 , dkpe,         \n\n      dips+1 , dipe ,        \n\n      djps+1 , djpe ,        \n\n      dkps+1 , dkpe) ;       \n\n\n    cudaDeviceSynchronize() ;\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    FROMDEV2(rain) ;\n    FROMDEV2(snow) ;\n\n    rain_sum = snow_sum = 0;\n    for (int i = 0; i < d2; i++) {\n      rain_sum += rain[i];\n      snow_sum += snow[i];\n    }\n\n    FREE(pii) ;\n    FREE(den) ;\n    FREE(p) ;\n    FREE(delz) ;\n    FREE(th) ;\n    FREE(q) ;\n    FREE(qc) ;\n    FREE(qi) ;\n    FREE(qr) ;\n    FREE(qs) ;\n    FREE(rain) ;\n    FREE(rainncv) ;\n    FREE(sr) ;\n    FREE(snow) ;\n    FREE(snowncv) ;\n  }\n\n  printf(\"Average kernel execution time: %lf (ms)\\n\", (time * 1e-6) / repeat);\n  printf(\"Checksum: rain = %f snow = %f\\n\", rain_sum, snow_sum);\n\n  return(0) ;\n}\n"}}
{"kernel_name": "wsm5", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"utils.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  float *th, *pii, *q;\n  float *qc, *qi, *qr, *qs;\n  float *den, *p, *delz;\n  float *rain,*rainncv;\n  float *sr;\n  float *snow, *snowncv;\n\n  float delt = 10.f;\n  int ims = 0, ime = 59, jms = 0, jme = 45, kms = 0, kme = 2;\n  int ips = 0, ipe = 59, jps = 0, jpe = 45, kps = 0, kpe = 2;\n  int d3 = (ime-ims+1) * (jme-jms+1) * (kme-kms+1) ;\n  int d2 = (ime-ims+1) * (jme-jms+1) ;\n\n  int dips = 0 ; int dipe = (ipe-ips+1) ;\n  int djps = 0 ; int djpe = (jpe-jps+1) ;\n  int dkps = 0 ; int dkpe = (kpe-kps+1) ;\n\n  int remx = (ipe-ips+1) % XXX != 0 ? 1 : 0 ;\n  int remy = (jpe-jps+1) % YYY != 0 ? 1 : 0 ;\n\n  dim3 dimBlock( XXX , YYY ) ;\n  dim3 dimGrid ( (ipe-ips+1) / XXX + remx , (jpe-jps+1) / YYY + remy ) ;\n\n  float rain_sum = 0, snow_sum = 0;\n\n  long time = 0;\n  for (int i = 0; i < repeat; i++) {\n    \n\n    TODEV3(pii) ;\n    TODEV3(den) ;\n    TODEV3(p) ;\n    TODEV3(delz) ;\n\n    TODEV3(th) ;\n    TODEV3(q) ;\n    TODEV3(qc) ;\n    TODEV3(qi) ;\n    TODEV3(qr) ;\n    TODEV3(qs) ;\n    TODEV2(rain) ;\n    TODEV2(rainncv) ;\n    TODEV2(sr) ;\n    TODEV2(snow) ;\n    TODEV2(snowncv) ;\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    wsm <<< dimGrid, dimBlock >>> (\n      th_d, pii_d, q_d, qc_d, qi_d, qr_d, qs_d, den_d, p_d, delz_d,\n      rain_d, rainncv_d,\n      sr_d,\n      snow_d, snowncv_d,\n      delt,\n      dips+1 , (ipe-ips+1) , \n\n      djps+1 , (jpe-jps+1) , \n\n      dkps+1 , (kpe-kps+1),  \n\n      dips+1 , dipe ,        \n\n      djps+1 , djpe ,        \n\n      dkps+1 , dkpe,         \n\n      dips+1 , dipe ,        \n\n      djps+1 , djpe ,        \n\n      dkps+1 , dkpe) ;       \n\n\n    hipDeviceSynchronize() ;\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    FROMDEV2(rain) ;\n    FROMDEV2(snow) ;\n\n    rain_sum = snow_sum = 0;\n    for (int i = 0; i < d2; i++) {\n      rain_sum += rain[i];\n      snow_sum += snow[i];\n    }\n\n    FREE(pii) ;\n    FREE(den) ;\n    FREE(p) ;\n    FREE(delz) ;\n    FREE(th) ;\n    FREE(q) ;\n    FREE(qc) ;\n    FREE(qi) ;\n    FREE(qr) ;\n    FREE(qs) ;\n    FREE(rain) ;\n    FREE(rainncv) ;\n    FREE(sr) ;\n    FREE(snow) ;\n    FREE(snowncv) ;\n  }\n\n  printf(\"Average kernel execution time: %lf (ms)\\n\", (time * 1e-6) / repeat);\n  printf(\"Checksum: rain = %f snow = %f\\n\", rain_sum, snow_sum);\n\n  return(0) ;\n}\n"}}
{"kernel_name": "wsm5", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"utils.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  float *th, *pii, *q;\n  float *qc, *qi, *qr, *qs;\n  float *den, *p, *delz;\n  float *rain,*rainncv;\n  float *sr;\n  float *snow, *snowncv;\n\n  float delt = 10.f;\n  int ims = 0, ime = 59, jms = 0, jme = 45, kms = 0, kme = 2;\n  int ips = 0, ipe = 59, jps = 0, jpe = 45, kps = 0, kpe = 2;\n  int d3 = (ime-ims+1) * (jme-jms+1) * (kme-kms+1) ;\n  int d2 = (ime-ims+1) * (jme-jms+1) ;\n\n  int dips = 0 ; int dipe = (ipe-ips+1) ;\n  int djps = 0 ; int djpe = (jpe-jps+1) ;\n  int dkps = 0 ; int dkpe = (kpe-kps+1) ;\n\n  float rain_sum = 0, snow_sum = 0;\n\n  long time = 0;\n  for (int i = 0; i < repeat; i++) {\n    ALLOC3(th) ;\n    ALLOC3(pii) ;\n    ALLOC3(q) ;\n    ALLOC3(qc) ;\n    ALLOC3(qi) ;\n    ALLOC3(qr) ;\n    ALLOC3(qs) ;\n    ALLOC3(den) ;\n    ALLOC3(p) ;\n    ALLOC3(delz) ;\n    ALLOC2(rain) ;\n    ALLOC2(rainncv) ;\n    ALLOC2(sr) ;\n    ALLOC2(snow) ;\n    ALLOC2(snowncv) ;\n\n    int remx = (ipe-ips+1) % XXX != 0 ? 1 : 0 ;\n    int remy = (jpe-jps+1) % YYY != 0 ? 1 : 0 ;\n\n    const int teamX = (ipe-ips+1) / XXX + remx;\n    const int teamY = (jpe-jps+1) / YYY + remy;\n\n    #pragma omp target data map(to: th[0:d3], \\\n                                    pii[0:d3], \\\n                                    q[0:d3], \\\n                                    qc[0:d3], \\\n                                    qi[0:d3], \\\n                                    qr[0:d3], \\\n                                    qs[0:d3], \\\n                                    den[0:d3], \\\n                                    p[0:d3], \\\n                                    delz[0:d3], \\\n                                    rainncv[0:d2], \\\n                                    snowncv[0:d2], \\\n                                    sr[0:d2]) \\\n                            map(tofrom: rain[0:d2],\\\n                                        snow[0:d2])\n    {\n      auto start = std::chrono::steady_clock::now();\n\n      wsm(th, pii, q, qc, qi, qr, qs, den, p, delz,\n        rain, rainncv,\n        sr,\n        snow, snowncv,\n        delt,\n        dips+1 , (ipe-ips+1) , \n\n        djps+1 , (jpe-jps+1) , \n\n        dkps+1 , (kpe-kps+1),  \n\n        dips+1 , dipe ,        \n\n        djps+1 , djpe ,        \n\n        dkps+1 , dkpe ,        \n\n        dips+1 , dipe ,        \n\n        djps+1 , djpe ,        \n\n        dkps+1 , dkpe ,        \n\n        teamX , teamY );\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    }\n\n    rain_sum = snow_sum = 0;\n    for (int i = 0; i < d2; i++) {\n      rain_sum += rain[i];\n      snow_sum += snow[i];\n    }\n\n    FREE(th) ;\n    FREE(pii) ;\n    FREE(q) ;\n    FREE(qc) ;\n    FREE(qi) ;\n    FREE(qr) ;\n    FREE(qs) ;\n    FREE(den) ;\n    FREE(p) ;\n    FREE(delz) ;\n    FREE(rain) ;\n    FREE(rainncv) ;\n    FREE(sr) ;\n    FREE(snow) ;\n    FREE(snowncv) ;\n  }\n\n  printf(\"Average kernel execution time: %lf (ms)\\n\", (time * 1e-6) / repeat);\n  printf(\"Checksum: rain = %f snow = %f\\n\", rain_sum, snow_sum);\n  return(0) ;\n}\n"}}
{"kernel_name": "wsm5", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"utils.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  float *th, *pii, *q;\n  float *qc, *qi, *qr, *qs;\n  float *den, *p, *delz;\n  float *rain,*rainncv;\n  float *sr;\n  float *snow, *snowncv;\n\n  float delt = 10.f;\n  int ims = 0, ime = 59, jms = 0, jme = 45, kms = 0, kme = 2;\n  int ips = 0, ipe = 59, jps = 0, jpe = 45, kps = 0, kpe = 2;\n  int d3 = (ime-ims+1) * (jme-jms+1) * (kme-kms+1) ;\n  int d2 = (ime-ims+1) * (jme-jms+1) ;\n\n  int dips = 0 ; int dipe = (ipe-ips+1) ;\n  int djps = 0 ; int djpe = (jpe-jps+1) ;\n  int dkps = 0 ; int dkpe = (kpe-kps+1) ;\n\n  float rain_sum = 0, snow_sum = 0;\n\n  long time = 0;\n  for (int i = 0; i < repeat; i++) {\n    ALLOC3(th) ;\n    ALLOC3(pii) ;\n    ALLOC3(q) ;\n    ALLOC3(qc) ;\n    ALLOC3(qi) ;\n    ALLOC3(qr) ;\n    ALLOC3(qs) ;\n    ALLOC3(den) ;\n    ALLOC3(p) ;\n    ALLOC3(delz) ;\n    ALLOC2(rain) ;\n    ALLOC2(rainncv) ;\n    ALLOC2(sr) ;\n    ALLOC2(snow) ;\n    ALLOC2(snowncv) ;\n\n    int remx = (ipe-ips+1) % XXX != 0 ? 1 : 0 ;\n    int remy = (jpe-jps+1) % YYY != 0 ? 1 : 0 ;\n\n    const int teamX = (ipe-ips+1) / XXX + remx;\n    const int teamY = (jpe-jps+1) / YYY + remy;\n\n        {\n      auto start = std::chrono::steady_clock::now();\n\n      wsm(th, pii, q, qc, qi, qr, qs, den, p, delz,\n        rain, rainncv,\n        sr,\n        snow, snowncv,\n        delt,\n        dips+1 , (ipe-ips+1) , \n\n        djps+1 , (jpe-jps+1) , \n\n        dkps+1 , (kpe-kps+1),  \n\n        dips+1 , dipe ,        \n\n        djps+1 , djpe ,        \n\n        dkps+1 , dkpe ,        \n\n        dips+1 , dipe ,        \n\n        djps+1 , djpe ,        \n\n        dkps+1 , dkpe ,        \n\n        teamX , teamY );\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    }\n\n    rain_sum = snow_sum = 0;\n    for (int i = 0; i < d2; i++) {\n      rain_sum += rain[i];\n      snow_sum += snow[i];\n    }\n\n    FREE(th) ;\n    FREE(pii) ;\n    FREE(q) ;\n    FREE(qc) ;\n    FREE(qi) ;\n    FREE(qr) ;\n    FREE(qs) ;\n    FREE(den) ;\n    FREE(p) ;\n    FREE(delz) ;\n    FREE(rain) ;\n    FREE(rainncv) ;\n    FREE(sr) ;\n    FREE(snow) ;\n    FREE(snowncv) ;\n  }\n\n  printf(\"Average kernel execution time: %lf (ms)\\n\", (time * 1e-6) / repeat);\n  printf(\"Checksum: rain = %f snow = %f\\n\", rain_sum, snow_sum);\n  return(0) ;\n}"}}
{"kernel_name": "wsm5", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  float *th, *pii, *q;\n  float *qc, *qi, *qr, *qs;\n  float *den, *p, *delz;\n  float *rain,*rainncv;\n  float *sr;\n  float *snow, *snowncv;\n\n  float delt = 10.f;\n  int ims = 0, ime = 59, jms = 0, jme = 45, kms = 0, kme = 2;\n  int ips = 0, ipe = 59, jps = 0, jpe = 45, kps = 0, kpe = 2;\n  int d3 = (ime-ims+1) * (jme-jms+1) * (kme-kms+1) ;\n  int d2 = (ime-ims+1) * (jme-jms+1) ;\n\n  int dips = 0 ; int dipe = (ipe-ips+1) ;\n  int djps = 0 ; int djpe = (jpe-jps+1) ;\n  int dkps = 0 ; int dkpe = (kpe-kps+1) ;\n\n#ifdef USE_GPU\n  sycl::queue Q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue Q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float rain_sum = 0, snow_sum = 0;\n\n  long time = 0;\n  for (int i = 0; i < repeat; i++) {\n    TODEV3(th) ;\n    TODEV3(pii) ;\n    TODEV3(q) ;\n    TODEV3(qc) ;\n    TODEV3(qi) ;\n    TODEV3(qr) ;\n    TODEV3(qs) ;\n    TODEV3(den) ;\n    TODEV3(p) ;\n    TODEV3(delz) ;\n    TODEV2(rain) ;\n    TODEV2(rainncv) ;\n    TODEV2(sr) ;\n    TODEV2(snow) ;\n    TODEV2(snowncv) ;\n\n    int remx = (ipe-ips+1) % XXX != 0 ? 1 : 0 ;\n    int remy = (jpe-jps+1) % YYY != 0 ? 1 : 0 ;\n\n    sycl::range<2> lws ( YYY, XXX ) ;\n    sycl::range<2> gws ( YYY * ((jpe-jps+1) / YYY + remy),\n                         XXX * ((ipe-ips+1) / XXX + remx) );\n\n    Q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    Q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class weather>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        wsm (item,\n             th_d,\n             pii_d,\n             q_d,\n             qc_d,\n             qi_d,\n             qr_d,\n             qs_d,\n             den_d,\n             p_d,\n             delz_d,\n             rain_d,\n             rainncv_d,\n             sr_d,\n             snow_d,\n             snowncv_d,\n             delt,\n             dips+1 , (ipe-ips+1) , \n\n             djps+1 , (jpe-jps+1) , \n\n             dkps+1 , (kpe-kps+1),  \n\n             dips+1 , dipe ,        \n\n             djps+1 , djpe ,        \n\n             dkps+1 , dkpe,         \n\n             dips+1 , dipe ,        \n\n             djps+1 , djpe ,        \n\n             dkps+1 , dkpe) ;       \n\n      });\n    });\n\n    Q.wait();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    FROMDEV2(rain) ;\n    FROMDEV2(snow) ;\n\n    rain_sum = snow_sum = 0;\n    for (int i = 0; i < d2; i++) {\n      rain_sum += rain[i];\n      snow_sum += snow[i];\n    }\n\n    FREE(th) ;\n    FREE(pii) ;\n    FREE(q) ;\n    FREE(qc) ;\n    FREE(qi) ;\n    FREE(qr) ;\n    FREE(qs) ;\n    FREE(den) ;\n    FREE(p) ;\n    FREE(delz) ;\n    FREE(rain) ;\n    FREE(rainncv) ;\n    FREE(sr) ;\n    FREE(snow) ;\n    FREE(snowncv) ;\n  }\n\n  printf(\"Average kernel execution time: %lf (ms)\\n\", (time * 1e-6) / repeat);\n  printf(\"Checksum: rain = %f snow = %f\\n\", rain_sum, snow_sum);\n  return(0) ;\n}\n"}}
{"kernel_name": "xsbench", "parallel_api": "hip", "code": {"Simulation.cu": "#include <hip/hip_runtime.h>\n#include \"XSbench_header.h\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__global__ void lookup (\n    const int *__restrict__ num_nucs,\n    const double *__restrict__ concs,\n    const int *__restrict__ mats,\n    const NuclideGridPoint *__restrict__ nuclide_grid,\n    int*__restrict__  verification,\n    const double *__restrict__ unionized_energy_array,\n    const int *__restrict__ index_grid,\n    const int n_lookups,\n    const long n_isotopes,\n    const long n_gridpoints,\n    const int grid_type,\n    const int hash_bins,\n    const int max_num_nucs ) {\n\n  \n\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n  if (i < n_lookups) {\n\n    \n\n    uint64_t seed = STARTING_SEED;\n\n    \n\n    seed = fast_forward_LCG(seed, 2*i);\n\n    \n\n    double p_energy = LCG_random_double(&seed);\n    int mat         = pick_mat(&seed);\n\n    \n\n    \n\n\n    double macro_xs_vector[5] = {0};\n\n    \n\n    calculate_macro_xs(\n        p_energy,     \n\n        mat,          \n\n        n_isotopes,   \n\n        n_gridpoints, \n\n        num_nucs,     \n\n        concs,        \n\n        unionized_energy_array, \n\n        index_grid,   \n\n        nuclide_grid, \n\n        mats,         \n\n        macro_xs_vector, \n\n        grid_type,    \n\n        hash_bins,    \n\n        max_num_nucs  \n\n     );\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    double max = -1.0;\n    int max_idx = 0;\n    for(int j = 0; j < 5; j++ )\n    {\n      if( macro_xs_vector[j] > max )\n      {\n        max = macro_xs_vector[j];\n        max_idx = j;\n      }\n    }\n    verification[i] = max_idx+1;\n  }\n}\n\nvoid lookup_reference (\n    const int *__restrict__ num_nucs,\n    const double *__restrict__ concs,\n    const int *__restrict__ mats,\n    const NuclideGridPoint *__restrict__ nuclide_grid,\n    int*__restrict__  verification,\n    const double *__restrict__ unionized_energy_array,\n    const int *__restrict__ index_grid,\n    const int n_lookups,\n    const long n_isotopes,\n    const long n_gridpoints,\n    const int grid_type,\n    const int hash_bins,\n    const int max_num_nucs ) {\n\n  #pragma omp parallel for\n  for (int i = 0; i < n_lookups; i++) {\n\n    \n\n    uint64_t seed = STARTING_SEED;\n\n    \n\n    seed = fast_forward_LCG(seed, 2*i);\n\n    \n\n    double p_energy = LCG_random_double(&seed);\n    int mat         = pick_mat(&seed);\n\n    \n\n    \n\n\n    double macro_xs_vector[5] = {0};\n\n    \n\n    calculate_macro_xs(\n        p_energy,     \n\n        mat,          \n\n        n_isotopes,   \n\n        n_gridpoints, \n\n        num_nucs,     \n\n        concs,        \n\n        unionized_energy_array, \n\n        index_grid,   \n\n        nuclide_grid, \n\n        mats,         \n\n        macro_xs_vector, \n\n        grid_type,    \n\n        hash_bins,    \n\n        max_num_nucs  \n\n     );\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    double max = -1.0;\n    int max_idx = 0;\n    for(int j = 0; j < 5; j++ )\n    {\n      if( macro_xs_vector[j] > max )\n      {\n        max = macro_xs_vector[j];\n        max_idx = j;\n      }\n    }\n    verification[i] = max_idx+1;\n  }\n}\n\n\n\nunsigned long long\nrun_event_based_simulation(Inputs in, SimulationData SD, int mype)\n{\n  if(mype==0) printf(\"Beginning event based simulation on the host for verification...\\n\");\n\n  int * verification_h = (int *) malloc(in.lookups * sizeof(int));\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( SD.length_unionized_energy_array == 0 )\n  {\n    SD.length_unionized_energy_array = 1;\n    SD.unionized_energy_array = (double *) malloc(sizeof(double));\n  }\n\n  if( SD.length_index_grid == 0 )\n  {\n    SD.length_index_grid = 1;\n    SD.index_grid = (int *) malloc(sizeof(int));\n  }\n\n  lookup_reference (\n      SD.num_nucs, SD.concs, SD.mats,\n      SD.nuclide_grid, verification_h, SD.unionized_energy_array,\n      SD.index_grid, in.lookups, in.n_isotopes, in.n_gridpoints,\n      in.grid_type, in.hash_bins, SD.max_num_nucs );\n\n  \n\n  unsigned long long verification_scalar = 0;\n  for( int i = 0; i < in.lookups; i++ )\n    verification_scalar += verification_h[i];\n\n  if( SD.length_unionized_energy_array == 0 ) free(SD.unionized_energy_array);\n  if( SD.length_index_grid == 0 ) free(SD.index_grid);\n  free(verification_h);\n\n  return verification_scalar;\n}\n\n\n\nunsigned long long\nrun_event_based_simulation(Inputs in, SimulationData SD,\n                           int mype, double *kernel_time)\n{\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  if(mype==0) printf(\"Beginning event based simulation...\\n\");\n\n  \n\n  if( mype == 0 )\n     printf(\"Allocating an additional %.1lf MB of memory for verification arrays...\\n\",\n            in.lookups * sizeof(int) /1024.0/1024.0);\n\n  int * verification_h = (int *) malloc(in.lookups * sizeof(int));\n\n  hipDeviceProp_t devProp;\n  hipGetDeviceProperties(&devProp, 0);\n  if(mype == 0 ) printf(\"Running on: %s\\n\", devProp.name);\n  if(mype == 0 ) printf(\"Initializing device buffers and JIT compiling kernel...\\n\");\n\n  \n\n  \n\n  \n\n\n  int *verification_d = nullptr;\n  int *mats_d = nullptr ;\n  int *num_nucs_d = nullptr;\n  double *concs_d = nullptr;\n  NuclideGridPoint *nuclide_grid_d = nullptr;\n\n  \n\n  hipMalloc((void**)&num_nucs_d, sizeof(int) * SD.length_num_nucs);\n  hipMemcpy(num_nucs_d, SD.num_nucs, sizeof(int) * SD.length_num_nucs, hipMemcpyHostToDevice);\n\n  \n\n  hipMalloc((void**)&concs_d, sizeof(double) * SD.length_concs);\n  hipMemcpy(concs_d, SD.concs, sizeof(double) * SD.length_concs, hipMemcpyHostToDevice);\n\n  \n\n  hipMalloc((void**)&mats_d, sizeof(int) * SD.length_mats);\n  hipMemcpy(mats_d, SD.mats, sizeof(int) * SD.length_mats, hipMemcpyHostToDevice);\n\n  \n\n  hipMalloc((void**)&nuclide_grid_d, sizeof(NuclideGridPoint) * SD.length_nuclide_grid);\n  hipMemcpy(nuclide_grid_d, SD.nuclide_grid, sizeof(NuclideGridPoint) * SD.length_nuclide_grid, hipMemcpyHostToDevice);\n\n  \n\n  hipMalloc((void**)&verification_d, sizeof(int) * in.lookups);\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( SD.length_unionized_energy_array == 0 )\n  {\n    SD.length_unionized_energy_array = 1;\n    SD.unionized_energy_array = (double *) malloc(sizeof(double));\n  }\n  \n\n  double *unionized_energy_array_d = nullptr;\n  hipMalloc((void**)&unionized_energy_array_d, sizeof(double) * SD.length_unionized_energy_array);\n  hipMemcpy(unionized_energy_array_d, SD.unionized_energy_array,\n      sizeof(double) * SD.length_unionized_energy_array, hipMemcpyHostToDevice);\n\n  if( SD.length_index_grid == 0 )\n  {\n    SD.length_index_grid = 1;\n    SD.index_grid = (int *) malloc(sizeof(int));\n  }\n\n  \n\n  int *index_grid_d = nullptr;\n  hipMalloc((void**)&index_grid_d, sizeof(int) * (unsigned long long)SD.length_index_grid);\n  hipMemcpy(index_grid_d, SD.index_grid, sizeof(int) * (unsigned long long )SD.length_index_grid, hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n\n  \n\n  \n\n  \n\n  dim3 grids  ((in.lookups + 255) / 256);\n  dim3 blocks (256);\n\n  double kstart = get_time();\n\n  for (int i = 0; i < in.kernel_repeat; i++) {\n    lookup<<< grids, blocks >>> (\n        num_nucs_d, concs_d, mats_d,\n        nuclide_grid_d, verification_d, unionized_energy_array_d,\n        index_grid_d, in.lookups, in.n_isotopes, in.n_gridpoints,\n        in.grid_type, in.hash_bins, SD.max_num_nucs );\n  }\n\n  hipDeviceSynchronize();\n  double kstop = get_time();\n  *kernel_time = (kstop - kstart) / in.kernel_repeat;\n\n  hipMemcpy(verification_h, verification_d, sizeof(int) * in.lookups, hipMemcpyDeviceToHost);\n\n  hipFree(verification_d);\n  hipFree(mats_d);\n  hipFree(num_nucs_d);\n  hipFree(concs_d);\n  hipFree(nuclide_grid_d);\n  hipFree(unionized_energy_array_d);\n  hipFree(index_grid_d);\n\n  \n\n  unsigned long long verification_scalar = 0;\n  for( int i = 0; i < in.lookups; i++ )\n    verification_scalar += verification_h[i];\n\n  if( SD.length_unionized_energy_array == 0 ) free(SD.unionized_energy_array);\n  if( SD.length_index_grid == 0 ) free(SD.index_grid);\n  free(verification_h);\n\n  return verification_scalar;\n}\n\n\n\n\n\n\ntemplate <class T>\n__host__ __device__\nlong grid_search( long n, double quarry, T A)\n{\n  long lowerLimit = 0;\n  long upperLimit = n-1;\n  long examinationPoint;\n  long length = upperLimit - lowerLimit;\n\n  while( length > 1 )\n  {\n    examinationPoint = lowerLimit + ( length / 2 );\n\n    if( A[examinationPoint] > quarry )\n      upperLimit = examinationPoint;\n    else\n      lowerLimit = examinationPoint;\n\n    length = upperLimit - lowerLimit;\n  }\n\n  return lowerLimit;\n}\n\n\n\ntemplate <class Double_Type, class Int_Type, class NGP_Type>\n__host__ __device__\nvoid calculate_micro_xs(   double p_energy, int nuc, long n_isotopes,\n    long n_gridpoints,\n    Double_Type  egrid, Int_Type  index_data,\n    NGP_Type  nuclide_grids,\n    long idx, double *  xs_vector, int grid_type, int hash_bins ){\n  \n\n  double f;\n  NuclideGridPoint low, high;\n  long low_idx, high_idx;\n\n  \n\n  \n\n  if( grid_type == NUCLIDE )\n  {\n    \n\n    long offset = nuc * n_gridpoints;\n    idx = grid_search_nuclide( n_gridpoints, p_energy, nuclide_grids, offset, offset + n_gridpoints-1);\n\n    \n\n    \n\n    if( idx == n_gridpoints - 1 )\n      low_idx = idx - 1;\n    else\n      low_idx = idx;\n  }\n  else if( grid_type == UNIONIZED) \n\n  {\n    \n\n    \n\n    if( index_data[idx * n_isotopes + nuc] == n_gridpoints - 1 )\n      low_idx = nuc*n_gridpoints + index_data[idx * n_isotopes + nuc] - 1;\n    else\n    {\n      low_idx = nuc*n_gridpoints + index_data[idx * n_isotopes + nuc];\n    }\n  }\n  else \n\n  {\n    \n\n    int u_low = index_data[idx * n_isotopes + nuc];\n\n    \n\n    int u_high;\n    if( idx == hash_bins - 1 )\n      u_high = n_gridpoints - 1;\n    else\n      u_high = index_data[(idx+1)*n_isotopes + nuc] + 1;\n\n    \n\n    \n\n    \n\n    double e_low  = nuclide_grids[nuc*n_gridpoints + u_low].energy;\n    double e_high = nuclide_grids[nuc*n_gridpoints + u_high].energy;\n    long lower;\n    if( p_energy <= e_low )\n      lower = nuc*n_gridpoints;\n    else if( p_energy >= e_high )\n      lower = nuc*n_gridpoints + n_gridpoints - 1;\n    else\n    {\n      long offset = nuc*n_gridpoints;\n      lower = grid_search_nuclide( n_gridpoints, p_energy, nuclide_grids, offset+u_low, offset+u_high);\n    }\n\n    if( (lower % n_gridpoints) == n_gridpoints - 1 )\n      low_idx = lower - 1;\n    else\n      low_idx = lower;\n  }\n\n  high_idx = low_idx + 1;\n  low = nuclide_grids[low_idx];\n  high = nuclide_grids[high_idx];\n\n  \n\n  f = (high.energy - p_energy) / (high.energy - low.energy);\n\n  \n\n  xs_vector[0] = high.total_xs - f * (high.total_xs - low.total_xs);\n\n  \n\n  xs_vector[1] = high.elastic_xs - f * (high.elastic_xs - low.elastic_xs);\n\n  \n\n  xs_vector[2] = high.absorbtion_xs - f * (high.absorbtion_xs - low.absorbtion_xs);\n\n  \n\n  xs_vector[3] = high.fission_xs - f * (high.fission_xs - low.fission_xs);\n\n  \n\n  xs_vector[4] = high.nu_fission_xs - f * (high.nu_fission_xs - low.nu_fission_xs);\n}\n\n\n\ntemplate <class Double_Type, class Int_Type, class NGP_Type, class E_GRID_TYPE, class INDEX_TYPE>\n__host__ __device__\nvoid calculate_macro_xs( double p_energy, int mat, long n_isotopes,\n    long n_gridpoints, Int_Type  num_nucs,\n    Double_Type  concs,\n    E_GRID_TYPE  egrid, INDEX_TYPE  index_data,\n    NGP_Type  nuclide_grids,\n    Int_Type  mats,\n    double * macro_xs_vector, int grid_type, int hash_bins, int max_num_nucs ){\n  int p_nuc; \n\n  long idx = -1;\n  double conc; \n\n\n  \n\n  for( int k = 0; k < 5; k++ )\n    macro_xs_vector[k] = 0;\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( grid_type == UNIONIZED )\n    idx = grid_search( n_isotopes * n_gridpoints, p_energy, egrid);\n  else if( grid_type == HASH )\n  {\n    double du = 1.0 / hash_bins;\n    idx = p_energy / du;\n  }\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  for( int j = 0; j < num_nucs[mat]; j++ )\n  {\n    double xs_vector[5];\n    p_nuc = mats[mat*max_num_nucs + j];\n    conc = concs[mat*max_num_nucs + j];\n    calculate_micro_xs( p_energy, p_nuc, n_isotopes,\n        n_gridpoints, egrid, index_data,\n        nuclide_grids, idx, xs_vector, grid_type, hash_bins );\n    for( int k = 0; k < 5; k++ )\n      macro_xs_vector[k] += xs_vector[k] * conc;\n  }\n}\n\n\n\n__host__ __device__\nint pick_mat( unsigned long * seed )\n{\n  \n\n  \n\n  \n\n  \n\n\n  \n\n  \n\n\n  double dist[12];\n  dist[0]  = 0.140;  \n\n  dist[1]  = 0.052;  \n\n  dist[2]  = 0.275;  \n\n  dist[3]  = 0.134;  \n\n  dist[4]  = 0.154;  \n\n  dist[5]  = 0.064;  \n\n  dist[6]  = 0.066;  \n\n  dist[7]  = 0.055;  \n\n  dist[8]  = 0.008;  \n\n  dist[9]  = 0.015;  \n\n  dist[10] = 0.025;  \n\n  dist[11] = 0.013;  \n\n\n  double roll = LCG_random_double(seed);\n\n  \n\n  for( int i = 0; i < 12; i++ )\n  {\n    double running = 0;\n    for( int j = i; j > 0; j-- )\n      running += dist[j];\n    if( roll < running )\n      return i;\n  }\n\n  return 0;\n}\n\n__host__ __device__\ndouble LCG_random_double(uint64_t * seed)\n{\n  \n\n  const uint64_t m = 9223372036854775808ULL; \n\n  const uint64_t a = 2806196910506780709ULL;\n  const uint64_t c = 1ULL;\n  *seed = (a * (*seed) + c) % m;\n  return (double) (*seed) / (double) m;\n}\n\n__host__ __device__\nuint64_t fast_forward_LCG(uint64_t seed, uint64_t n)\n{\n  \n\n  const uint64_t m = 9223372036854775808ULL; \n\n  uint64_t a = 2806196910506780709ULL;\n  uint64_t c = 1ULL;\n\n  n = n % m;\n\n  uint64_t a_new = 1;\n  uint64_t c_new = 0;\n\n  while(n > 0)\n  {\n    if(n & 1)\n    {\n      a_new *= a;\n      c_new = c_new * a + c;\n    }\n    c *= (a + 1);\n    a *= a;\n\n    n >>= 1;\n  }\n\n  return (a_new * seed + c_new) % m;\n}\n"}}
{"kernel_name": "xsbench", "parallel_api": "omp", "code": {"Simulation.cpp": "#include <omp.h>\n#include \"XSbench_header.h\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunsigned long long\nrun_event_based_simulation(Inputs in, SimulationData SD, int mype)\n{\n  if(mype==0) printf(\"Beginning event based simulation on the host for verification...\\n\");\n\n  int * verification = (int *) malloc(in.lookups * sizeof(int));\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( SD.length_unionized_energy_array == 0 )\n  {\n    SD.length_unionized_energy_array = 1;\n    SD.unionized_energy_array = (double *) malloc(sizeof(double));\n  }\n\n  if( SD.length_index_grid == 0 )\n  {\n    SD.length_index_grid = 1;\n    SD.index_grid = (int *) malloc(sizeof(int));\n  }\n\n  #pragma omp parallel for\n  for( int i = 0; i < in.lookups; i++ )\n  {\n    \n\n    uint64_t seed = STARTING_SEED;\n\n    \n\n    seed = fast_forward_LCG(seed, 2*i);\n\n    \n\n    double p_energy = LCG_random_double(&seed);\n    int mat         = pick_mat(&seed);\n\n    \n\n    \n\n\n    double macro_xs_vector[5] = {0};\n\n    \n\n    calculate_macro_xs(\n        p_energy,        \n\n        mat,             \n\n        in.n_isotopes,   \n\n        in.n_gridpoints, \n\n        SD.num_nucs,     \n\n        SD.concs,        \n\n        SD.unionized_energy_array, \n\n        SD.index_grid,   \n\n        SD.nuclide_grid, \n\n        SD.mats,         \n\n        macro_xs_vector, \n\n        in.grid_type,    \n\n        in.hash_bins,    \n\n        SD.max_num_nucs  \n\n    );\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    double max = -1.0;\n    int max_idx = 0;\n    for(int j = 0; j < 5; j++ )\n    {\n      if( macro_xs_vector[j] > max )\n      {\n        max = macro_xs_vector[j];\n        max_idx = j;\n      }\n    }\n    verification[i] = max_idx+1;\n  }\n\n  \n\n  unsigned long long verification_scalar = 0;\n  for( int i = 0; i < in.lookups; i++ )\n    verification_scalar += verification[i];\n\n  if( SD.length_unionized_energy_array == 0 ) free(SD.unionized_energy_array);\n  if( SD.length_index_grid == 0 ) free(SD.index_grid);\n  free(verification);\n\n  return verification_scalar;\n}\n\nunsigned long long\nrun_event_based_simulation(Inputs in, SimulationData SD,\n                           int mype, double *kernel_time)\n{\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  if( mype == 0)\n    printf(\"Beginning event based simulation...\\n\");\n\n  if( mype == 0 )\n     printf(\"Allocating an additional %.1lf MB of memory for verification arrays...\\n\",\n            in.lookups * sizeof(int) /1024.0/1024.0);\n\n  if( SD.length_unionized_energy_array == 0 )\n  {\n    SD.length_unionized_energy_array = 1;\n    SD.unionized_energy_array = (double *) malloc(sizeof(double));\n  }\n\n  if( SD.length_index_grid == 0 )\n  {\n    SD.length_index_grid = 1;\n    SD.index_grid = (int *) malloc(sizeof(int));\n  }\n\n  \n\n  \n\n  \n\n  int *verification = (int *) malloc(in.lookups * sizeof(int));\n\n  const int SD_max_num_nucs = SD.max_num_nucs;\n  const int *SD_num_nucs = SD.num_nucs;\n  const double *SD_concs = SD.concs;\n  const int *SD_mats = SD.mats;\n  const NuclideGridPoint *SD_nuclide_grid  = SD.nuclide_grid;\n  const double *SD_unionized_energy_array = SD.unionized_energy_array;\n  const    int *SD_index_grid = SD.index_grid;\n\n\n  #pragma omp target data \\\n    map(to: SD_num_nucs[:SD.length_num_nucs])\\\n    map(to: SD_concs[:SD.length_concs])\\\n    map(to: SD_mats[:SD.length_mats])\\\n    map(to: SD_unionized_energy_array[:SD.length_unionized_energy_array])\\\n    map(to: SD_index_grid[:SD.length_index_grid])\\\n    map(to: SD_nuclide_grid[:SD.length_nuclide_grid])\\\n    map(from: verification[:in.lookups])\n  {\n\n    double kstart = get_time();\n\n    for (int n = 0; n < in.kernel_repeat; n++) {\n\n      #pragma omp target teams distribute parallel for \\\n       map(to:in) firstprivate(SD_max_num_nucs) thread_limit(256)\n      for( int i = 0; i < in.lookups; i++ )\n      {\n        \n\n        uint64_t seed = STARTING_SEED;\n\n        \n\n        seed = fast_forward_LCG(seed, 2*i);\n\n        \n\n        double p_energy = LCG_random_double(&seed);\n        int mat         = pick_mat(&seed);\n\n        \n\n        \n\n\n        double macro_xs_vector[5] = {0};\n\n        \n\n        calculate_macro_xs(\n            p_energy,        \n\n            mat,             \n\n            in.n_isotopes,   \n\n            in.n_gridpoints, \n\n            SD_num_nucs,     \n\n            SD_concs,        \n\n            SD_unionized_energy_array, \n\n            SD_index_grid,   \n\n            SD_nuclide_grid, \n\n            SD_mats,         \n\n            macro_xs_vector, \n\n            in.grid_type,    \n\n            in.hash_bins,    \n\n            SD_max_num_nucs  \n\n        );\n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        double max = -1.0;\n        int max_idx = 0;\n        for(int j = 0; j < 5; j++ )\n        {\n          if( macro_xs_vector[j] > max )\n          {\n            max = macro_xs_vector[j];\n            max_idx = j;\n          }\n        }\n        verification[i] = max_idx+1;\n      }\n    }\n\n    double kstop = get_time();\n    *kernel_time = (kstop - kstart) / in.kernel_repeat;\n\n  } \n\n\n  \n\n  unsigned long long verification_scalar = 0;\n  for( int i = 0; i < in.lookups; i++ )\n    verification_scalar += verification[i];\n\n  if( SD.length_unionized_energy_array == 0 ) free(SD.unionized_energy_array);\n  if( SD.length_index_grid == 0 ) free(SD.index_grid);\n  free(verification);\n\n  return verification_scalar;\n}\n\n#pragma omp declare target\n\n\n\n\n\ntemplate <class T>\nlong grid_search( long n, double quarry, T A)\n{\n  long lowerLimit = 0;\n  long upperLimit = n-1;\n  long examinationPoint;\n  long length = upperLimit - lowerLimit;\n\n  while( length > 1 )\n  {\n    examinationPoint = lowerLimit + ( length / 2 );\n\n    if( A[examinationPoint] > quarry )\n      upperLimit = examinationPoint;\n    else\n      lowerLimit = examinationPoint;\n\n    length = upperLimit - lowerLimit;\n  }\n\n  return lowerLimit;\n}\n\n\n\ntemplate <class Double_Type, class Int_Type, class NGP_Type>\nvoid calculate_micro_xs(   double p_energy, int nuc, long n_isotopes,\n    long n_gridpoints,\n    Double_Type  egrid, Int_Type  index_data,\n    NGP_Type  nuclide_grids,\n    long idx, double *  xs_vector, int grid_type, int hash_bins ){\n  \n\n  double f;\n  NuclideGridPoint low, high;\n  long low_idx, high_idx;\n\n  \n\n  \n\n  if( grid_type == NUCLIDE )\n  {\n    \n\n    long offset = nuc * n_gridpoints;\n    idx = grid_search_nuclide( n_gridpoints, p_energy, nuclide_grids, offset, offset + n_gridpoints-1);\n\n    \n\n    \n\n    if( idx == n_gridpoints - 1 )\n      low_idx = idx - 1;\n    else\n      low_idx = idx;\n  }\n  else if( grid_type == UNIONIZED) \n\n  {\n    \n\n    \n\n    if( index_data[idx * n_isotopes + nuc] == n_gridpoints - 1 )\n      low_idx = nuc*n_gridpoints + index_data[idx * n_isotopes + nuc] - 1;\n    else\n    {\n      low_idx = nuc*n_gridpoints + index_data[idx * n_isotopes + nuc];\n    }\n  }\n  else \n\n  {\n    \n\n    int u_low = index_data[idx * n_isotopes + nuc];\n\n    \n\n    int u_high;\n    if( idx == hash_bins - 1 )\n      u_high = n_gridpoints - 1;\n    else\n      u_high = index_data[(idx+1)*n_isotopes + nuc] + 1;\n\n    \n\n    \n\n    \n\n    double e_low  = nuclide_grids[nuc*n_gridpoints + u_low].energy;\n    double e_high = nuclide_grids[nuc*n_gridpoints + u_high].energy;\n    long lower;\n    if( p_energy <= e_low )\n      lower = nuc*n_gridpoints;\n    else if( p_energy >= e_high )\n      lower = nuc*n_gridpoints + n_gridpoints - 1;\n    else\n    {\n      long offset = nuc*n_gridpoints;\n      lower = grid_search_nuclide( n_gridpoints, p_energy, nuclide_grids, offset+u_low, offset+u_high);\n    }\n\n    if( (lower % n_gridpoints) == n_gridpoints - 1 )\n      low_idx = lower - 1;\n    else\n      low_idx = lower;\n  }\n\n  high_idx = low_idx + 1;\n  low = nuclide_grids[low_idx];\n  high = nuclide_grids[high_idx];\n\n  \n\n  f = (high.energy - p_energy) / (high.energy - low.energy);\n\n  \n\n  xs_vector[0] = high.total_xs - f * (high.total_xs - low.total_xs);\n\n  \n\n  xs_vector[1] = high.elastic_xs - f * (high.elastic_xs - low.elastic_xs);\n\n  \n\n  xs_vector[2] = high.absorbtion_xs - f * (high.absorbtion_xs - low.absorbtion_xs);\n\n  \n\n  xs_vector[3] = high.fission_xs - f * (high.fission_xs - low.fission_xs);\n\n  \n\n  xs_vector[4] = high.nu_fission_xs - f * (high.nu_fission_xs - low.nu_fission_xs);\n}\n\n\n\ntemplate <class Double_Type, class Int_Type, class NGP_Type, class E_GRID_TYPE, class INDEX_TYPE>\nvoid calculate_macro_xs( double p_energy, int mat, long n_isotopes,\n    long n_gridpoints, Int_Type  num_nucs,\n    Double_Type  concs,\n    E_GRID_TYPE  egrid, INDEX_TYPE  index_data,\n    NGP_Type  nuclide_grids,\n    Int_Type  mats,\n    double * macro_xs_vector, int grid_type, int hash_bins, int max_num_nucs ){\n  int p_nuc; \n\n  long idx = -1;\n  double conc; \n\n\n  \n\n  for( int k = 0; k < 5; k++ )\n    macro_xs_vector[k] = 0;\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( grid_type == UNIONIZED )\n    idx = grid_search( n_isotopes * n_gridpoints, p_energy, egrid);\n  else if( grid_type == HASH )\n  {\n    double du = 1.0 / hash_bins;\n    idx = p_energy / du;\n  }\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  for( int j = 0; j < num_nucs[mat]; j++ )\n  {\n    double xs_vector[5];\n    p_nuc = mats[mat*max_num_nucs + j];\n    conc = concs[mat*max_num_nucs + j];\n    calculate_micro_xs( p_energy, p_nuc, n_isotopes,\n        n_gridpoints, egrid, index_data,\n        nuclide_grids, idx, xs_vector, grid_type, hash_bins );\n    for( int k = 0; k < 5; k++ )\n      macro_xs_vector[k] += xs_vector[k] * conc;\n  }\n}\n\n\n\nint pick_mat( unsigned long * seed )\n{\n  \n\n  \n\n  \n\n  \n\n\n  \n\n  \n\n\n  double dist[12];\n  dist[0]  = 0.140;  \n\n  dist[1]  = 0.052;  \n\n  dist[2]  = 0.275;  \n\n  dist[3]  = 0.134;  \n\n  dist[4]  = 0.154;  \n\n  dist[5]  = 0.064;  \n\n  dist[6]  = 0.066;  \n\n  dist[7]  = 0.055;  \n\n  dist[8]  = 0.008;  \n\n  dist[9]  = 0.015;  \n\n  dist[10] = 0.025;  \n\n  dist[11] = 0.013;  \n\n\n  double roll = LCG_random_double(seed);\n\n  \n\n  for( int i = 0; i < 12; i++ )\n  {\n    double running = 0;\n    for( int j = i; j > 0; j-- )\n      running += dist[j];\n    if( roll < running )\n      return i;\n  }\n\n  return 0;\n}\n\ndouble LCG_random_double(uint64_t * seed)\n{\n  \n\n  const uint64_t m = 9223372036854775808ULL; \n\n  const uint64_t a = 2806196910506780709ULL;\n  const uint64_t c = 1ULL;\n  *seed = (a * (*seed) + c) % m;\n  return (double) (*seed) / (double) m;\n}\n\nuint64_t fast_forward_LCG(uint64_t seed, uint64_t n)\n{\n  \n\n  const uint64_t m = 9223372036854775808ULL; \n\n  uint64_t a = 2806196910506780709ULL;\n  uint64_t c = 1ULL;\n\n  n = n % m;\n\n  uint64_t a_new = 1;\n  uint64_t c_new = 0;\n\n  while(n > 0)\n  {\n    if(n & 1)\n    {\n      a_new *= a;\n      c_new = c_new * a + c;\n    }\n    c *= (a + 1);\n    a *= a;\n\n    n >>= 1;\n  }\n\n  return (a_new * seed + c_new) % m;\n}\n\n#pragma omp end declare target\n"}}
{"kernel_name": "xsbench", "parallel_api": "serial", "code": {"Simulation.cpp": "#include \"XSbench_header.h\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunsigned long long\nrun_event_based_simulation(Inputs in, SimulationData SD, int mype)\n{\n  if(mype==0) printf(\"Beginning event based simulation on the host for verification...\\n\");\n\n  int * verification = (int *) malloc(in.lookups * sizeof(int));\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( SD.length_unionized_energy_array == 0 )\n  {\n    SD.length_unionized_energy_array = 1;\n    SD.unionized_energy_array = (double *) malloc(sizeof(double));\n  }\n\n  if( SD.length_index_grid == 0 )\n  {\n    SD.length_index_grid = 1;\n    SD.index_grid = (int *) malloc(sizeof(int));\n  }\n\n    for( int i = 0; i < in.lookups; i++ )\n  {\n    \n\n    uint64_t seed = STARTING_SEED;\n\n    \n\n    seed = fast_forward_LCG(seed, 2*i);\n\n    \n\n    double p_energy = LCG_random_double(&seed);\n    int mat         = pick_mat(&seed);\n\n    \n\n    \n\n\n    double macro_xs_vector[5] = {0};\n\n    \n\n    calculate_macro_xs(\n        p_energy,        \n\n        mat,             \n\n        in.n_isotopes,   \n\n        in.n_gridpoints, \n\n        SD.num_nucs,     \n\n        SD.concs,        \n\n        SD.unionized_energy_array, \n\n        SD.index_grid,   \n\n        SD.nuclide_grid, \n\n        SD.mats,         \n\n        macro_xs_vector, \n\n        in.grid_type,    \n\n        in.hash_bins,    \n\n        SD.max_num_nucs  \n\n    );\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    double max = -1.0;\n    int max_idx = 0;\n    for(int j = 0; j < 5; j++ )\n    {\n      if( macro_xs_vector[j] > max )\n      {\n        max = macro_xs_vector[j];\n        max_idx = j;\n      }\n    }\n    verification[i] = max_idx+1;\n  }\n\n  \n\n  unsigned long long verification_scalar = 0;\n  for( int i = 0; i < in.lookups; i++ )\n    verification_scalar += verification[i];\n\n  if( SD.length_unionized_energy_array == 0 ) free(SD.unionized_energy_array);\n  if( SD.length_index_grid == 0 ) free(SD.index_grid);\n  free(verification);\n\n  return verification_scalar;\n}\n\nunsigned long long\nrun_event_based_simulation(Inputs in, SimulationData SD,\n                           int mype, double *kernel_time)\n{\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  if( mype == 0)\n    printf(\"Beginning event based simulation...\\n\");\n\n  if( mype == 0 )\n     printf(\"Allocating an additional %.1lf MB of memory for verification arrays...\\n\",\n            in.lookups * sizeof(int) /1024.0/1024.0);\n\n  if( SD.length_unionized_energy_array == 0 )\n  {\n    SD.length_unionized_energy_array = 1;\n    SD.unionized_energy_array = (double *) malloc(sizeof(double));\n  }\n\n  if( SD.length_index_grid == 0 )\n  {\n    SD.length_index_grid = 1;\n    SD.index_grid = (int *) malloc(sizeof(int));\n  }\n\n  \n\n  \n\n  \n\n  int *verification = (int *) malloc(in.lookups * sizeof(int));\n\n  const int SD_max_num_nucs = SD.max_num_nucs;\n  const int *SD_num_nucs = SD.num_nucs;\n  const double *SD_concs = SD.concs;\n  const int *SD_mats = SD.mats;\n  const NuclideGridPoint *SD_nuclide_grid  = SD.nuclide_grid;\n  const double *SD_unionized_energy_array = SD.unionized_energy_array;\n  const    int *SD_index_grid = SD.index_grid;\n\n\n    {\n\n    double kstart = get_time();\n\n    for (int n = 0; n < in.kernel_repeat; n++) {\n\n            for( int i = 0; i < in.lookups; i++ )\n      {\n        \n\n        uint64_t seed = STARTING_SEED;\n\n        \n\n        seed = fast_forward_LCG(seed, 2*i);\n\n        \n\n        double p_energy = LCG_random_double(&seed);\n        int mat         = pick_mat(&seed);\n\n        \n\n        \n\n\n        double macro_xs_vector[5] = {0};\n\n        \n\n        calculate_macro_xs(\n            p_energy,        \n\n            mat,             \n\n            in.n_isotopes,   \n\n            in.n_gridpoints, \n\n            SD_num_nucs,     \n\n            SD_concs,        \n\n            SD_unionized_energy_array, \n\n            SD_index_grid,   \n\n            SD_nuclide_grid, \n\n            SD_mats,         \n\n            macro_xs_vector, \n\n            in.grid_type,    \n\n            in.hash_bins,    \n\n            SD_max_num_nucs  \n\n        );\n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        double max = -1.0;\n        int max_idx = 0;\n        for(int j = 0; j < 5; j++ )\n        {\n          if( macro_xs_vector[j] > max )\n          {\n            max = macro_xs_vector[j];\n            max_idx = j;\n          }\n        }\n        verification[i] = max_idx+1;\n      }\n    }\n\n    double kstop = get_time();\n    *kernel_time = (kstop - kstart) / in.kernel_repeat;\n\n  } \n\n\n  \n\n  unsigned long long verification_scalar = 0;\n  for( int i = 0; i < in.lookups; i++ )\n    verification_scalar += verification[i];\n\n  if( SD.length_unionized_energy_array == 0 ) free(SD.unionized_energy_array);\n  if( SD.length_index_grid == 0 ) free(SD.index_grid);\n  free(verification);\n\n  return verification_scalar;\n}\n\n\n\n\n\n\ntemplate <class T>\nlong grid_search( long n, double quarry, T A)\n{\n  long lowerLimit = 0;\n  long upperLimit = n-1;\n  long examinationPoint;\n  long length = upperLimit - lowerLimit;\n\n  while( length > 1 )\n  {\n    examinationPoint = lowerLimit + ( length / 2 );\n\n    if( A[examinationPoint] > quarry )\n      upperLimit = examinationPoint;\n    else\n      lowerLimit = examinationPoint;\n\n    length = upperLimit - lowerLimit;\n  }\n\n  return lowerLimit;\n}\n\n\n\ntemplate <class Double_Type, class Int_Type, class NGP_Type>\nvoid calculate_micro_xs(   double p_energy, int nuc, long n_isotopes,\n    long n_gridpoints,\n    Double_Type  egrid, Int_Type  index_data,\n    NGP_Type  nuclide_grids,\n    long idx, double *  xs_vector, int grid_type, int hash_bins ){\n  \n\n  double f;\n  NuclideGridPoint low, high;\n  long low_idx, high_idx;\n\n  \n\n  \n\n  if( grid_type == NUCLIDE )\n  {\n    \n\n    long offset = nuc * n_gridpoints;\n    idx = grid_search_nuclide( n_gridpoints, p_energy, nuclide_grids, offset, offset + n_gridpoints-1);\n\n    \n\n    \n\n    if( idx == n_gridpoints - 1 )\n      low_idx = idx - 1;\n    else\n      low_idx = idx;\n  }\n  else if( grid_type == UNIONIZED) \n\n  {\n    \n\n    \n\n    if( index_data[idx * n_isotopes + nuc] == n_gridpoints - 1 )\n      low_idx = nuc*n_gridpoints + index_data[idx * n_isotopes + nuc] - 1;\n    else\n    {\n      low_idx = nuc*n_gridpoints + index_data[idx * n_isotopes + nuc];\n    }\n  }\n  else \n\n  {\n    \n\n    int u_low = index_data[idx * n_isotopes + nuc];\n\n    \n\n    int u_high;\n    if( idx == hash_bins - 1 )\n      u_high = n_gridpoints - 1;\n    else\n      u_high = index_data[(idx+1)*n_isotopes + nuc] + 1;\n\n    \n\n    \n\n    \n\n    double e_low  = nuclide_grids[nuc*n_gridpoints + u_low].energy;\n    double e_high = nuclide_grids[nuc*n_gridpoints + u_high].energy;\n    long lower;\n    if( p_energy <= e_low )\n      lower = nuc*n_gridpoints;\n    else if( p_energy >= e_high )\n      lower = nuc*n_gridpoints + n_gridpoints - 1;\n    else\n    {\n      long offset = nuc*n_gridpoints;\n      lower = grid_search_nuclide( n_gridpoints, p_energy, nuclide_grids, offset+u_low, offset+u_high);\n    }\n\n    if( (lower % n_gridpoints) == n_gridpoints - 1 )\n      low_idx = lower - 1;\n    else\n      low_idx = lower;\n  }\n\n  high_idx = low_idx + 1;\n  low = nuclide_grids[low_idx];\n  high = nuclide_grids[high_idx];\n\n  \n\n  f = (high.energy - p_energy) / (high.energy - low.energy);\n\n  \n\n  xs_vector[0] = high.total_xs - f * (high.total_xs - low.total_xs);\n\n  \n\n  xs_vector[1] = high.elastic_xs - f * (high.elastic_xs - low.elastic_xs);\n\n  \n\n  xs_vector[2] = high.absorbtion_xs - f * (high.absorbtion_xs - low.absorbtion_xs);\n\n  \n\n  xs_vector[3] = high.fission_xs - f * (high.fission_xs - low.fission_xs);\n\n  \n\n  xs_vector[4] = high.nu_fission_xs - f * (high.nu_fission_xs - low.nu_fission_xs);\n}\n\n\n\ntemplate <class Double_Type, class Int_Type, class NGP_Type, class E_GRID_TYPE, class INDEX_TYPE>\nvoid calculate_macro_xs( double p_energy, int mat, long n_isotopes,\n    long n_gridpoints, Int_Type  num_nucs,\n    Double_Type  concs,\n    E_GRID_TYPE  egrid, INDEX_TYPE  index_data,\n    NGP_Type  nuclide_grids,\n    Int_Type  mats,\n    double * macro_xs_vector, int grid_type, int hash_bins, int max_num_nucs ){\n  int p_nuc; \n\n  long idx = -1;\n  double conc; \n\n\n  \n\n  for( int k = 0; k < 5; k++ )\n    macro_xs_vector[k] = 0;\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( grid_type == UNIONIZED )\n    idx = grid_search( n_isotopes * n_gridpoints, p_energy, egrid);\n  else if( grid_type == HASH )\n  {\n    double du = 1.0 / hash_bins;\n    idx = p_energy / du;\n  }\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  for( int j = 0; j < num_nucs[mat]; j++ )\n  {\n    double xs_vector[5];\n    p_nuc = mats[mat*max_num_nucs + j];\n    conc = concs[mat*max_num_nucs + j];\n    calculate_micro_xs( p_energy, p_nuc, n_isotopes,\n        n_gridpoints, egrid, index_data,\n        nuclide_grids, idx, xs_vector, grid_type, hash_bins );\n    for( int k = 0; k < 5; k++ )\n      macro_xs_vector[k] += xs_vector[k] * conc;\n  }\n}\n\n\n\nint pick_mat( unsigned long * seed )\n{\n  \n\n  \n\n  \n\n  \n\n\n  \n\n  \n\n\n  double dist[12];\n  dist[0]  = 0.140;  \n\n  dist[1]  = 0.052;  \n\n  dist[2]  = 0.275;  \n\n  dist[3]  = 0.134;  \n\n  dist[4]  = 0.154;  \n\n  dist[5]  = 0.064;  \n\n  dist[6]  = 0.066;  \n\n  dist[7]  = 0.055;  \n\n  dist[8]  = 0.008;  \n\n  dist[9]  = 0.015;  \n\n  dist[10] = 0.025;  \n\n  dist[11] = 0.013;  \n\n\n  double roll = LCG_random_double(seed);\n\n  \n\n  for( int i = 0; i < 12; i++ )\n  {\n    double running = 0;\n    for( int j = i; j > 0; j-- )\n      running += dist[j];\n    if( roll < running )\n      return i;\n  }\n\n  return 0;\n}\n\ndouble LCG_random_double(uint64_t * seed)\n{\n  \n\n  const uint64_t m = 9223372036854775808ULL; \n\n  const uint64_t a = 2806196910506780709ULL;\n  const uint64_t c = 1ULL;\n  *seed = (a * (*seed) + c) % m;\n  return (double) (*seed) / (double) m;\n}\n\nuint64_t fast_forward_LCG(uint64_t seed, uint64_t n)\n{\n  \n\n  const uint64_t m = 9223372036854775808ULL; \n\n  uint64_t a = 2806196910506780709ULL;\n  uint64_t c = 1ULL;\n\n  n = n % m;\n\n  uint64_t a_new = 1;\n  uint64_t c_new = 0;\n\n  while(n > 0)\n  {\n    if(n & 1)\n    {\n      a_new *= a;\n      c_new = c_new * a + c;\n    }\n    c *= (a + 1);\n    a *= a;\n\n    n >>= 1;\n  }\n\n  return (a_new * seed + c_new) % m;\n}\n"}}
{"kernel_name": "xsbench", "parallel_api": "sycl", "code": {"Simulation.cpp": "#include <sycl/sycl.hpp>\n#include \"XSbench_header.h\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvoid lookup (\n    const int *__restrict__ num_nucs,\n    const double *__restrict__ concs,\n    const int *__restrict__ mats,\n    const NuclideGridPoint *__restrict__ nuclide_grid,\n    int*__restrict__  verification,\n    const double *__restrict__ unionized_energy_array,\n    const int *__restrict__ index_grid,\n    const int n_lookups,\n    const long n_isotopes,\n    const long n_gridpoints,\n    const int grid_type,\n    const int hash_bins,\n    const int max_num_nucs ,\n    const sycl::nd_item<1> &item) {\n\n  \n\n  int i = item.get_global_id(0);\n\n  if (i < n_lookups) {\n\n    \n\n    uint64_t seed = STARTING_SEED;\n\n    \n\n    seed = fast_forward_LCG(seed, 2*i);\n\n    \n\n    double p_energy = LCG_random_double(&seed);\n    int mat         = pick_mat(&seed);\n\n    \n\n    \n\n\n    double macro_xs_vector[5] = {0};\n\n    \n\n    calculate_macro_xs(\n        p_energy,     \n\n        mat,          \n\n        n_isotopes,   \n\n        n_gridpoints, \n\n        num_nucs,     \n\n        concs,        \n\n        unionized_energy_array, \n\n        index_grid,   \n\n        nuclide_grid, \n\n        mats,         \n\n        macro_xs_vector, \n\n        grid_type,    \n\n        hash_bins,    \n\n        max_num_nucs  \n\n     );\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    double max = -1.0;\n    int max_idx = 0;\n    for(int j = 0; j < 5; j++ )\n    {\n      if( macro_xs_vector[j] > max )\n      {\n        max = macro_xs_vector[j];\n        max_idx = j;\n      }\n    }\n    verification[i] = max_idx+1;\n  }\n}\n\nvoid lookup_reference (\n    const int *__restrict__ num_nucs,\n    const double *__restrict__ concs,\n    const int *__restrict__ mats,\n    const NuclideGridPoint *__restrict__ nuclide_grid,\n    int*__restrict__  verification,\n    const double *__restrict__ unionized_energy_array,\n    const int *__restrict__ index_grid,\n    const int n_lookups,\n    const long n_isotopes,\n    const long n_gridpoints,\n    const int grid_type,\n    const int hash_bins,\n    const int max_num_nucs ) {\n\n  #pragma omp parallel for\n  for (int i = 0; i < n_lookups; i++) {\n\n    \n\n    uint64_t seed = STARTING_SEED;\n\n    \n\n    seed = fast_forward_LCG(seed, 2*i);\n\n    \n\n    double p_energy = LCG_random_double(&seed);\n    int mat         = pick_mat(&seed);\n\n    \n\n    \n\n\n    double macro_xs_vector[5] = {0};\n\n    \n\n    calculate_macro_xs(\n        p_energy,     \n\n        mat,          \n\n        n_isotopes,   \n\n        n_gridpoints, \n\n        num_nucs,     \n\n        concs,        \n\n        unionized_energy_array, \n\n        index_grid,   \n\n        nuclide_grid, \n\n        mats,         \n\n        macro_xs_vector, \n\n        grid_type,    \n\n        hash_bins,    \n\n        max_num_nucs  \n\n     );\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    double max = -1.0;\n    int max_idx = 0;\n    for(int j = 0; j < 5; j++ )\n    {\n      if( macro_xs_vector[j] > max )\n      {\n        max = macro_xs_vector[j];\n        max_idx = j;\n      }\n    }\n    verification[i] = max_idx+1;\n  }\n}\n\n\n\n\nunsigned long long\nrun_event_based_simulation(Inputs in, SimulationData SD, int mype)\n{\n  if(mype==0) printf(\"Beginning event based simulation on the host for verification...\\n\");\n\n  int * verification_h = (int *) malloc(in.lookups * sizeof(int));\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( SD.length_unionized_energy_array == 0 )\n  {\n    SD.length_unionized_energy_array = 1;\n    SD.unionized_energy_array = (double *) malloc(sizeof(double));\n  }\n\n  if( SD.length_index_grid == 0 )\n  {\n    SD.length_index_grid = 1;\n    SD.index_grid = (int *) malloc(sizeof(int));\n  }\n\n  lookup_reference (\n      SD.num_nucs, SD.concs, SD.mats,\n      SD.nuclide_grid, verification_h, SD.unionized_energy_array,\n      SD.index_grid, in.lookups, in.n_isotopes, in.n_gridpoints,\n      in.grid_type, in.hash_bins, SD.max_num_nucs );\n\n  \n\n  unsigned long long verification_scalar = 0;\n  for( int i = 0; i < in.lookups; i++ )\n    verification_scalar += verification_h[i];\n\n  if( SD.length_unionized_energy_array == 0 ) free(SD.unionized_energy_array);\n  if( SD.length_index_grid == 0 ) free(SD.index_grid);\n  free(verification_h);\n\n  return verification_scalar;\n}\n\nunsigned long long\nrun_event_based_simulation(Inputs in, SimulationData SD,\n                           int mype, double *kernel_time)\n{\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  if(mype==0) printf(\"Beginning event based simulation...\\n\");\n\n  \n\n  if( mype == 0 )\n     printf(\"Allocating an additional %.1lf MB of memory for verification arrays...\\n\",\n            in.lookups * sizeof(int) /1024.0/1024.0);\n\n  int * verification_h = (int *) malloc(in.lookups * sizeof(int));\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  if (mype == 0) {\n    printf(\"Running on: %s\\n\", q.get_device().get_info<sycl::info::device::name>().c_str());\n    printf(\"Initializing device buffers and JIT compiling kernel...\\n\");\n  }\n\n  \n\n  \n\n  \n\n\n  int *num_nucs_d = sycl::malloc_device<int>(SD.length_num_nucs, q);\n  q.memcpy(num_nucs_d, SD.num_nucs, sizeof(int) * SD.length_num_nucs);\n\n  double *concs_d = sycl::malloc_device<double>(SD.length_concs, q);\n  q.memcpy(concs_d, SD.concs, sizeof(double) * SD.length_concs);\n\n  int *mats_d = sycl::malloc_device<int>(SD.length_mats, q);\n  q.memcpy(mats_d, SD.mats, sizeof(int) * SD.length_mats);\n\n  NuclideGridPoint *nuclide_grid_d =\n      sycl::malloc_device<NuclideGridPoint>(SD.length_nuclide_grid, q);\n  q.memcpy(nuclide_grid_d, SD.nuclide_grid,\n           sizeof(NuclideGridPoint) * SD.length_nuclide_grid);\n\n  int *verification_d = sycl::malloc_device<int>(in.lookups, q);\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( SD.length_unionized_energy_array == 0 )\n  {\n    SD.length_unionized_energy_array = 1;\n    SD.unionized_energy_array = (double *) malloc(sizeof(double));\n  }\n\n  double *unionized_energy_array_d =\n      sycl::malloc_device<double>(SD.length_unionized_energy_array, q);\n  q.memcpy(unionized_energy_array_d, SD.unionized_energy_array,\n           sizeof(double) * SD.length_unionized_energy_array);\n\n  if( SD.length_index_grid == 0 )\n  {\n    SD.length_index_grid = 1;\n    SD.index_grid = (int *) malloc(sizeof(int));\n  }\n\n  \n\n  int *index_grid_d = (int *)sycl::malloc_device(\n      sizeof(int) * (unsigned long long)SD.length_index_grid, q);\n  q.memcpy(index_grid_d, SD.index_grid,\n           sizeof(int) * (unsigned long long)SD.length_index_grid);\n\n  q.wait();\n\n  \n\n  \n\n  \n\n  sycl::range<1> gws ((in.lookups + 255)/256*256);\n  sycl::range<1> lws (256);\n\n  double kstart = get_time();\n\n  for (int i = 0; i < in.kernel_repeat; i++) {\n    q.parallel_for<class kernel>(sycl::nd_range<1>(gws, lws),\n      [=](sycl::nd_item<1> item) {\n        lookup(num_nucs_d, concs_d, mats_d, nuclide_grid_d, verification_d,\n               unionized_energy_array_d, index_grid_d, in.lookups,\n               in.n_isotopes, in.n_gridpoints, in.grid_type, in.hash_bins,\n               SD.max_num_nucs, item);\n    });\n  }\n\n  q.wait();\n  double kstop = get_time();\n  *kernel_time = (kstop - kstart) / in.kernel_repeat;\n\n  q.memcpy(verification_h, verification_d, sizeof(int) * in.lookups).wait();\n\n  sycl::free(verification_d, q);\n  sycl::free(mats_d, q);\n  sycl::free(num_nucs_d, q);\n  sycl::free(concs_d, q);\n  sycl::free(nuclide_grid_d, q);\n  sycl::free(unionized_energy_array_d, q);\n  sycl::free(index_grid_d, q);\n\n  \n\n  unsigned long long verification_scalar = 0;\n  for( int i = 0; i < in.lookups; i++ )\n    verification_scalar += verification_h[i];\n\n  if( SD.length_unionized_energy_array == 0 ) free(SD.unionized_energy_array);\n  if( SD.length_index_grid == 0 ) free(SD.index_grid);\n  free(verification_h);\n\n  return verification_scalar;\n}\n\n\n\n\n\n\ntemplate <class T>\n\nlong grid_search( long n, double quarry, T A)\n{\n  long lowerLimit = 0;\n  long upperLimit = n-1;\n  long examinationPoint;\n  long length = upperLimit - lowerLimit;\n\n  while( length > 1 )\n  {\n    examinationPoint = lowerLimit + ( length / 2 );\n\n    if( A[examinationPoint] > quarry )\n      upperLimit = examinationPoint;\n    else\n      lowerLimit = examinationPoint;\n\n    length = upperLimit - lowerLimit;\n  }\n\n  return lowerLimit;\n}\n\n\n\ntemplate <class Double_Type, class Int_Type, class NGP_Type>\n\n\n\nvoid calculate_micro_xs(double p_energy, int nuc, long n_isotopes,\n                        long n_gridpoints, Double_Type egrid,\n                        Int_Type index_data, NGP_Type nuclide_grids, long idx,\n                        double *xs_vector, int grid_type, int hash_bins) {\n  \n\n  double f;\n  NuclideGridPoint low, high;\n  long low_idx, high_idx;\n\n  \n\n  \n\n  if( grid_type == NUCLIDE )\n  {\n    \n\n    long offset = nuc * n_gridpoints;\n    idx = grid_search_nuclide( n_gridpoints, p_energy, nuclide_grids, offset, offset + n_gridpoints-1);\n\n    \n\n    \n\n    if( idx == n_gridpoints - 1 )\n      low_idx = idx - 1;\n    else\n      low_idx = idx;\n  }\n  else if( grid_type == UNIONIZED) \n\n  {\n    \n\n    \n\n    if( index_data[idx * n_isotopes + nuc] == n_gridpoints - 1 )\n      low_idx = nuc*n_gridpoints + index_data[idx * n_isotopes + nuc] - 1;\n    else\n    {\n      low_idx = nuc*n_gridpoints + index_data[idx * n_isotopes + nuc];\n    }\n  }\n  else \n\n  {\n    \n\n    int u_low = index_data[idx * n_isotopes + nuc];\n\n    \n\n    int u_high;\n    if( idx == hash_bins - 1 )\n      u_high = n_gridpoints - 1;\n    else\n      u_high = index_data[(idx+1)*n_isotopes + nuc] + 1;\n\n    \n\n    \n\n    \n\n    double e_low  = nuclide_grids[nuc*n_gridpoints + u_low].energy;\n    double e_high = nuclide_grids[nuc*n_gridpoints + u_high].energy;\n    long lower;\n    if( p_energy <= e_low )\n      lower = nuc*n_gridpoints;\n    else if( p_energy >= e_high )\n      lower = nuc*n_gridpoints + n_gridpoints - 1;\n    else\n    {\n      long offset = nuc*n_gridpoints;\n      lower = grid_search_nuclide( n_gridpoints, p_energy, nuclide_grids, offset+u_low, offset+u_high);\n    }\n\n    if( (lower % n_gridpoints) == n_gridpoints - 1 )\n      low_idx = lower - 1;\n    else\n      low_idx = lower;\n  }\n\n  high_idx = low_idx + 1;\n  low = nuclide_grids[low_idx];\n  high = nuclide_grids[high_idx];\n\n  \n\n  f = (high.energy - p_energy) / (high.energy - low.energy);\n\n  \n\n  xs_vector[0] = high.total_xs - f * (high.total_xs - low.total_xs);\n\n  \n\n  xs_vector[1] = high.elastic_xs - f * (high.elastic_xs - low.elastic_xs);\n\n  \n\n  xs_vector[2] = high.absorbtion_xs - f * (high.absorbtion_xs - low.absorbtion_xs);\n\n  \n\n  xs_vector[3] = high.fission_xs - f * (high.fission_xs - low.fission_xs);\n\n  \n\n  xs_vector[4] = high.nu_fission_xs - f * (high.nu_fission_xs - low.nu_fission_xs);\n}\n\n\n\ntemplate <class Double_Type, class Int_Type, class NGP_Type, class E_GRID_TYPE, class INDEX_TYPE>\n\nvoid calculate_macro_xs( double p_energy, int mat, long n_isotopes,\n    long n_gridpoints, Int_Type  num_nucs,\n    Double_Type  concs,\n    E_GRID_TYPE  egrid, INDEX_TYPE  index_data,\n    NGP_Type  nuclide_grids,\n    Int_Type  mats,\n    double * macro_xs_vector, int grid_type, int hash_bins, int max_num_nucs ){\n  int p_nuc; \n\n  long idx = -1;\n  double conc; \n\n\n  \n\n  for( int k = 0; k < 5; k++ )\n    macro_xs_vector[k] = 0;\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  if( grid_type == UNIONIZED )\n    idx = grid_search( n_isotopes * n_gridpoints, p_energy, egrid);\n  else if( grid_type == HASH )\n  {\n    double du = 1.0 / hash_bins;\n    idx = p_energy / du;\n  }\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  for( int j = 0; j < num_nucs[mat]; j++ )\n  {\n    double xs_vector[5];\n    p_nuc = mats[mat*max_num_nucs + j];\n    conc = concs[mat*max_num_nucs + j];\n    calculate_micro_xs( p_energy, p_nuc, n_isotopes,\n        n_gridpoints, egrid, index_data,\n        nuclide_grids, idx, xs_vector, grid_type, hash_bins );\n    for( int k = 0; k < 5; k++ )\n      macro_xs_vector[k] += xs_vector[k] * conc;\n  }\n}\n\n\n\n\nint pick_mat( unsigned long * seed )\n{\n  \n\n  \n\n  \n\n  \n\n\n  \n\n  \n\n\n  double dist[12];\n  dist[0]  = 0.140;  \n\n  dist[1]  = 0.052;  \n\n  dist[2]  = 0.275;  \n\n  dist[3]  = 0.134;  \n\n  dist[4]  = 0.154;  \n\n  dist[5]  = 0.064;  \n\n  dist[6]  = 0.066;  \n\n  dist[7]  = 0.055;  \n\n  dist[8]  = 0.008;  \n\n  dist[9]  = 0.015;  \n\n  dist[10] = 0.025;  \n\n  dist[11] = 0.013;  \n\n\n  double roll = LCG_random_double(seed);\n\n  \n\n  for( int i = 0; i < 12; i++ )\n  {\n    double running = 0;\n    for( int j = i; j > 0; j-- )\n      running += dist[j];\n    if( roll < running )\n      return i;\n  }\n\n  return 0;\n}\n\n\ndouble LCG_random_double(uint64_t * seed)\n{\n  \n\n  const uint64_t m = 9223372036854775808ULL; \n\n  const uint64_t a = 2806196910506780709ULL;\n  const uint64_t c = 1ULL;\n  *seed = (a * (*seed) + c) % m;\n  return (double) (*seed) / (double) m;\n}\n\n\nuint64_t fast_forward_LCG(uint64_t seed, uint64_t n)\n{\n  \n\n  const uint64_t m = 9223372036854775808ULL; \n\n  uint64_t a = 2806196910506780709ULL;\n  uint64_t c = 1ULL;\n\n  n = n % m;\n\n  uint64_t a_new = 1;\n  uint64_t c_new = 0;\n\n  while(n > 0)\n  {\n    if(n & 1)\n    {\n      a_new *= a;\n      c_new = c_new * a + c;\n    }\n    c *= (a + 1);\n    a *= a;\n\n    n >>= 1;\n  }\n\n  return (a_new * seed + c_new) % m;\n}\n"}}
{"kernel_name": "zmddft", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <cuda.h>\n#include <chrono>\n#include <random>\n\n__device__ const double D3[512] = {\n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 0.98078528040323043, (-0.19509032201612825), \n  0.99518472667219693, (-0.098017140329560604), 0.95694033573220882, (-0.29028467725446233), \n  0.99969881869620425, (-0.024541228522912288), 0.97570213003852857, (-0.2191012401568698), \n  0.99247953459870997, (-0.1224106751992162), 0.94952818059303667, (-0.31368174039889152), \n  0.99879545620517241, (-0.049067674327418015), 0.97003125319454397, (-0.24298017990326387), \n  0.98917650996478101, (-0.14673047445536175), 0.94154406518302081, (-0.33688985339222005), \n  0.99729045667869021, (-0.073564563599667426), 0.96377606579543984, (-0.26671275747489837), \n  0.98527764238894122, (-0.17096188876030122), 0.93299279883473896, (-0.35989503653498811), \n  1.0, 0.0, 0.92387953251128674, (-0.38268343236508978), \n  0.98078528040323043, (-0.19509032201612825), 0.83146961230254524, (-0.55557023301960218), \n  0.99879545620517241, (-0.049067674327418015), 0.90398929312344334, (-0.42755509343028208), \n  0.97003125319454397, (-0.24298017990326387), 0.80320753148064494, (-0.59569930449243336), \n  0.99518472667219693, (-0.098017140329560604), 0.88192126434835505, (-0.47139673682599764), \n  0.95694033573220882, (-0.29028467725446233), 0.77301045336273699, (-0.63439328416364549), \n  0.98917650996478101, (-0.14673047445536175), 0.85772861000027212, (-0.51410274419322166), \n  0.94154406518302081, (-0.33688985339222005), 0.74095112535495922, (-0.67155895484701833), \n  1.0, 0.0, 0.83146961230254524, (-0.55557023301960218), \n  0.95694033573220882, (-0.29028467725446233), 0.63439328416364549, (-0.77301045336273699), \n  0.99729045667869021, (-0.073564563599667426), 0.78834642762660623, (-0.61523159058062682), \n  0.93299279883473896, (-0.35989503653498811), 0.57580819141784534, (-0.81758481315158371), \n  0.98917650996478101, (-0.14673047445536175), 0.74095112535495922, (-0.67155895484701833), \n  0.90398929312344334, (-0.42755509343028208), 0.51410274419322166, (-0.85772861000027212), \n  0.97570213003852857, (-0.2191012401568698), 0.68954054473706683, (-0.724247082951467), \n  0.87008699110871146, (-0.49289819222978404), 0.44961132965460654, (-0.89322430119551532), \n  1.0, 0.0, 0.70710678118654757, (-0.70710678118654757), \n  0.92387953251128674, (-0.38268343236508978), 0.38268343236508978, (-0.92387953251128674), \n  0.99518472667219693, (-0.098017140329560604), 0.63439328416364549, (-0.77301045336273699), \n  0.88192126434835505, (-0.47139673682599764), 0.29028467725446233, (-0.95694033573220882), \n  0.98078528040323043, (-0.19509032201612825), 0.55557023301960218, (-0.83146961230254524), \n  0.83146961230254524, (-0.55557023301960218), 0.19509032201612825, (-0.98078528040323043), \n  0.95694033573220882, (-0.29028467725446233), 0.47139673682599764, (-0.88192126434835505), \n  0.77301045336273699, (-0.63439328416364549), 0.098017140329560604, (-0.99518472667219693), \n  1.0, 0.0, 0.55557023301960218, (-0.83146961230254524), \n  0.88192126434835505, (-0.47139673682599764), 0.098017140329560604, (-0.99518472667219693), \n  0.99247953459870997, (-0.1224106751992162), 0.44961132965460654, (-0.89322430119551532), \n  0.81758481315158371, (-0.57580819141784534), (-0.024541228522912288), (-0.99969881869620425), \n  0.97003125319454397, (-0.24298017990326387), 0.33688985339222005, (-0.94154406518302081), \n  0.74095112535495922, (-0.67155895484701833), (-0.14673047445536175), (-0.98917650996478101), \n  0.93299279883473896, (-0.35989503653498811), 0.2191012401568698, (-0.97570213003852857), \n  0.65317284295377676, (-0.75720884650648457), (-0.26671275747489837), (-0.96377606579543984), \n  1.0, 0.0, 0.38268343236508978, (-0.92387953251128674), \n  0.83146961230254524, (-0.55557023301960218), (-0.19509032201612825), (-0.98078528040323043), \n  0.98917650996478101, (-0.14673047445536175), 0.24298017990326387, (-0.97003125319454397), \n  0.74095112535495922, (-0.67155895484701833), (-0.33688985339222005), (-0.94154406518302081), \n  0.95694033573220882, (-0.29028467725446233), 0.098017140329560604, (-0.99518472667219693), \n  0.63439328416364549, (-0.77301045336273699), (-0.47139673682599764), (-0.88192126434835505), \n  0.90398929312344334, (-0.42755509343028208), (-0.049067674327418015), (-0.99879545620517241), \n  0.51410274419322166, (-0.85772861000027212), (-0.59569930449243336), (-0.80320753148064494), \n  1.0, 0.0, 0.19509032201612825, (-0.98078528040323043), \n  0.77301045336273699, (-0.63439328416364549), (-0.47139673682599764), (-0.88192126434835505), \n  0.98527764238894122, (-0.17096188876030122), 0.024541228522912288, (-0.99969881869620425), \n  0.65317284295377676, (-0.75720884650648457), (-0.61523159058062682), (-0.78834642762660623), \n  0.94154406518302081, (-0.33688985339222005), (-0.14673047445536175), (-0.98917650996478101), \n  0.51410274419322166, (-0.85772861000027212), (-0.74095112535495922), (-0.67155895484701833), \n  0.87008699110871146, (-0.49289819222978404), (-0.31368174039889152), (-0.94952818059303667), \n  0.35989503653498811, (-0.93299279883473896), (-0.84485356524970712), (-0.53499761988709715), \n  1.0, 0.0, 0.0, (-1.0), \n  0.70710678118654757, (-0.70710678118654757), (-0.70710678118654757), (-0.70710678118654757), \n  0.98078528040323043, (-0.19509032201612825), (-0.19509032201612825), (-0.98078528040323043), \n  0.55557023301960218, (-0.83146961230254524), (-0.83146961230254524), (-0.55557023301960218), \n  0.92387953251128674, (-0.38268343236508978), (-0.38268343236508978), (-0.92387953251128674), \n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), (-0.38268343236508978), \n  0.83146961230254524, (-0.55557023301960218), (-0.55557023301960218), (-0.83146961230254524), \n  0.19509032201612825, (-0.98078528040323043), (-0.98078528040323043), (-0.19509032201612825), \n  1.0, 0.0, (-0.19509032201612825), (-0.98078528040323043), \n  0.63439328416364549, (-0.77301045336273699), (-0.88192126434835505), (-0.47139673682599764), \n  0.97570213003852857, (-0.2191012401568698), (-0.40524131400498986), (-0.91420975570353069), \n  0.44961132965460654, (-0.89322430119551532), (-0.96377606579543984), (-0.26671275747489837), \n  0.90398929312344334, (-0.42755509343028208), (-0.59569930449243336), (-0.80320753148064494), \n  0.24298017990326387, (-0.97003125319454397), (-0.99879545620517241), (-0.049067674327418015), \n  0.78834642762660623, (-0.61523159058062682), (-0.75720884650648457), (-0.65317284295377676), \n  0.024541228522912288, (-0.99969881869620425), (-0.98527764238894122), 0.17096188876030122, \n  1.0, 0.0, (-0.38268343236508978), (-0.92387953251128674), \n  0.55557023301960218, (-0.83146961230254524), (-0.98078528040323043), (-0.19509032201612825), \n  0.97003125319454397, (-0.24298017990326387), (-0.59569930449243336), (-0.80320753148064494), \n  0.33688985339222005, (-0.94154406518302081), (-0.99879545620517241), 0.049067674327418015, \n  0.88192126434835505, (-0.47139673682599764), (-0.77301045336273699), (-0.63439328416364549), \n  0.098017140329560604, (-0.99518472667219693), (-0.95694033573220882), 0.29028467725446233, \n  0.74095112535495922, (-0.67155895484701833), (-0.90398929312344334), (-0.42755509343028208), \n  (-0.14673047445536175), (-0.98917650996478101), (-0.85772861000027212), 0.51410274419322166, \n  1.0, 0.0, (-0.55557023301960218), (-0.83146961230254524), \n  0.47139673682599764, (-0.88192126434835505), (-0.99518472667219693), 0.098017140329560604, \n  0.96377606579543984, (-0.26671275747489837), (-0.75720884650648457), (-0.65317284295377676), \n  0.2191012401568698, (-0.97570213003852857), (-0.93299279883473896), 0.35989503653498811, \n  0.85772861000027212, (-0.51410274419322166), (-0.90398929312344334), (-0.42755509343028208), \n  (-0.049067674327418015), (-0.99879545620517241), (-0.80320753148064494), 0.59569930449243336, \n  0.68954054473706683, (-0.724247082951467), (-0.98527764238894122), (-0.17096188876030122), \n  (-0.31368174039889152), (-0.94952818059303667), (-0.61523159058062682), 0.78834642762660623, \n  1.0, 0.0, (-0.70710678118654757), (-0.70710678118654757), \n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), 0.38268343236508978, \n  0.95694033573220882, (-0.29028467725446233), (-0.88192126434835505), (-0.47139673682599764), \n  0.098017140329560604, (-0.99518472667219693), (-0.77301045336273699), 0.63439328416364549, \n  0.83146961230254524, (-0.55557023301960218), (-0.98078528040323043), (-0.19509032201612825), \n  (-0.19509032201612825), (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524, \n  0.63439328416364549, (-0.77301045336273699), (-0.99518472667219693), 0.098017140329560604, \n  (-0.47139673682599764), (-0.88192126434835505), (-0.29028467725446233), 0.95694033573220882, \n  1.0, 0.0, (-0.83146961230254524), (-0.55557023301960218), \n  0.29028467725446233, (-0.95694033573220882), (-0.77301045336273699), 0.63439328416364549, \n  0.94952818059303667, (-0.31368174039889152), (-0.96377606579543984), (-0.26671275747489837), \n  (-0.024541228522912288), (-0.99969881869620425), (-0.53499761988709715), 0.84485356524970712, \n  0.80320753148064494, (-0.59569930449243336), (-0.99879545620517241), 0.049067674327418015, \n  (-0.33688985339222005), (-0.94154406518302081), (-0.24298017990326387), 0.97003125319454397, \n  0.57580819141784534, (-0.81758481315158371), (-0.93299279883473896), 0.35989503653498811, \n  (-0.61523159058062682), (-0.78834642762660623), 0.073564563599667426, 0.99729045667869021, \n  1.0, 0.0, (-0.92387953251128674), (-0.38268343236508978), \n  0.19509032201612825, (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524, \n  0.94154406518302081, (-0.33688985339222005), (-0.99879545620517241), (-0.049067674327418015), \n  (-0.14673047445536175), (-0.98917650996478101), (-0.24298017990326387), 0.97003125319454397, \n  0.77301045336273699, (-0.63439328416364549), (-0.95694033573220882), 0.29028467725446233, \n  (-0.47139673682599764), (-0.88192126434835505), 0.098017140329560604, 0.99518472667219693, \n  0.51410274419322166, (-0.85772861000027212), (-0.80320753148064494), 0.59569930449243336, \n  (-0.74095112535495922), (-0.67155895484701833), 0.42755509343028208, 0.90398929312344334, \n  1.0, 0.0, (-0.98078528040323043), (-0.19509032201612825), \n  0.098017140329560604, (-0.99518472667219693), (-0.29028467725446233), 0.95694033573220882, \n  0.93299279883473896, (-0.35989503653498811), (-0.98527764238894122), 0.17096188876030122, \n  (-0.26671275747489837), (-0.96377606579543984), 0.073564563599667426, 0.99729045667869021, \n  0.74095112535495922, (-0.67155895484701833), (-0.85772861000027212), 0.51410274419322166, \n  (-0.59569930449243336), (-0.80320753148064494), 0.42755509343028208, 0.90398929312344334, \n  0.44961132965460654, (-0.89322430119551532), (-0.61523159058062682), 0.78834642762660623, \n  (-0.84485356524970712), (-0.53499761988709715), 0.724247082951467, 0.68954054473706683};\n\n__global__\nvoid ker_zmddft_fwd_256x256x256_cu0(const double *X, double *P1)\n{\n  __shared__ double T3[2048];\n  double a495, a496, a497, a498, a499, a500, a501, a502, \n         s145, s146, s147, s148, s149, s150, s151, s152, \n         s153, s154, s155, s156, s157, s158, s159, s160, \n         s161, s162, s163, s164, s165, s166, s167, s168, \n         s169, s170, s171, s172, s173, s174, s175, s176, \n         s177, s178, s179, s180, s181, s182, s183, s184, \n         s185, s186, s187, s188, s189, s190, s191, s192, \n         t538, t539, t540, t541, t542, t543, t544, t545, \n         t546, t547, t548, t549, t550, t551, t552, t553, \n         t554, t555, t556, t557, t558, t559, t560, t561, \n         t562, t563, t564, t565, t566, t567, t568, t569, \n         t570, t571, t572, t573, t574, t575, t576, t577, \n         t578, t579, t580, t581, t582, t583, t584, t585, \n         t586, t587, t588, t589, t590, t591, t592, t593, \n         t594, t595, t596, t597, t598, t599, t600, t601, \n         t602, t603, t604, t605, t606, t607, t608, t609, \n         t610, t611, t612, t613, t614, t615, t616, t617, \n         t618, t619, t620, t621, t622, t623, t624, t625;\n  int a492, a493, a494, a503;\n  a492 = (512*(threadIdx.x / 16));\n  a493 = (threadIdx.x % 16);\n  a494 = ((2048*blockIdx.x) + a492 + (2*a493));\n  s145 = X[a494];\n  s146 = X[(a494 + 1)];\n  s147 = X[(a494 + 256)];\n  s148 = X[(a494 + 257)];\n  t538 = (s145 + s147);\n  t539 = (s146 + s148);\n  t540 = (s145 - s147);\n  t541 = (s146 - s148);\n  s149 = X[(a494 + 128)];\n  s150 = X[(a494 + 129)];\n  s151 = X[(a494 + 384)];\n  s152 = X[(a494 + 385)];\n  t542 = (s149 + s151);\n  t543 = (s150 + s152);\n  t544 = (s149 - s151);\n  t545 = (s150 - s152);\n  t546 = (t538 + t542);\n  t547 = (t539 + t543);\n  t548 = (t538 - t542);\n  t549 = (t539 - t543);\n  t550 = (t540 + t545);\n  t551 = (t541 - t544);\n  t552 = (t540 - t545);\n  t553 = (t541 + t544);\n  s153 = X[(a494 + 32)];\n  s154 = X[(a494 + 33)];\n  s155 = X[(a494 + 288)];\n  s156 = X[(a494 + 289)];\n  t554 = (s153 + s155);\n  t555 = (s154 + s156);\n  t556 = (s153 - s155);\n  t557 = (s154 - s156);\n  s157 = X[(a494 + 160)];\n  s158 = X[(a494 + 161)];\n  s159 = X[(a494 + 416)];\n  s160 = X[(a494 + 417)];\n  t558 = (s157 + s159);\n  t559 = (s158 + s160);\n  t560 = (s157 - s159);\n  t561 = (s158 - s160);\n  t562 = (t554 + t558);\n  t563 = (t555 + t559);\n  a495 = (0.70710678118654757*(t554 - t558));\n  a496 = (0.70710678118654757*(t555 - t559));\n  s161 = (a495 + a496);\n  s162 = (a496 - a495);\n  t564 = (t556 + t561);\n  t565 = (t557 - t560);\n  t566 = (t556 - t561);\n  t567 = (t557 + t560);\n  s163 = ((0.92387953251128674*t564) + (0.38268343236508978*t565));\n  s164 = ((0.92387953251128674*t565) - (0.38268343236508978*t564));\n  s165 = ((0.38268343236508978*t566) + (0.92387953251128674*t567));\n  s166 = ((0.38268343236508978*t567) - (0.92387953251128674*t566));\n  s167 = X[(a494 + 64)];\n  s168 = X[(a494 + 65)];\n  s169 = X[(a494 + 320)];\n  s170 = X[(a494 + 321)];\n  t568 = (s167 + s169);\n  t569 = (s168 + s170);\n  t570 = (s167 - s169);\n  t571 = (s168 - s170);\n  s171 = X[(a494 + 192)];\n  s172 = X[(a494 + 193)];\n  s173 = X[(a494 + 448)];\n  s174 = X[(a494 + 449)];\n  t572 = (s171 + s173);\n  t573 = (s172 + s174);\n  t574 = (s171 - s173);\n  t575 = (s172 - s174);\n  t576 = (t568 + t572);\n  t577 = (t569 + t573);\n  t578 = (t568 - t572);\n  t579 = (t569 - t573);\n  a497 = (0.70710678118654757*(t570 + t575));\n  a498 = (0.70710678118654757*(t571 - t574));\n  s175 = (a497 + a498);\n  s176 = (a498 - a497);\n  a499 = (0.70710678118654757*(t571 + t574));\n  a500 = (0.70710678118654757*(t570 - t575));\n  s177 = (a499 - a500);\n  s178 = (a500 + a499);\n  s179 = X[(a494 + 96)];\n  s180 = X[(a494 + 97)];\n  s181 = X[(a494 + 352)];\n  s182 = X[(a494 + 353)];\n  t580 = (s179 + s181);\n  t581 = (s180 + s182);\n  t582 = (s179 - s181);\n  t583 = (s180 - s182);\n  s183 = X[(a494 + 224)];\n  s184 = X[(a494 + 225)];\n  s185 = X[(a494 + 480)];\n  s186 = X[(a494 + 481)];\n  t584 = (s183 + s185);\n  t585 = (s184 + s186);\n  t586 = (s183 - s185);\n  t587 = (s184 - s186);\n  t588 = (t580 + t584);\n  t589 = (t581 + t585);\n  a501 = (0.70710678118654757*(t581 - t585));\n  a502 = (0.70710678118654757*(t580 - t584));\n  s187 = (a501 - a502);\n  s188 = (a502 + a501);\n  t590 = (t582 + t587);\n  t591 = (t583 - t586);\n  t592 = (t582 - t587);\n  t593 = (t583 + t586);\n  s189 = ((0.38268343236508978*t590) + (0.92387953251128674*t591));\n  s190 = ((0.38268343236508978*t591) - (0.92387953251128674*t590));\n  s191 = ((0.92387953251128674*t592) + (0.38268343236508978*t593));\n  s192 = ((0.38268343236508978*t592) - (0.92387953251128674*t593));\n  t594 = (t546 + t576);\n  t595 = (t547 + t577);\n  t596 = (t546 - t576);\n  t597 = (t547 - t577);\n  t598 = (t562 + t588);\n  t599 = (t563 + t589);\n  t600 = (t562 - t588);\n  t601 = (t563 - t589);\n  a503 = (a492 + (32*a493));\n  T3[a503] = (t594 + t598);\n  T3[(a503 + 1)] = (t595 + t599);\n  T3[(a503 + 16)] = (t594 - t598);\n  T3[(a503 + 17)] = (t595 - t599);\n  T3[(a503 + 8)] = (t596 + t601);\n  T3[(a503 + 9)] = (t597 - t600);\n  T3[(a503 + 24)] = (t596 - t601);\n  T3[(a503 + 25)] = (t597 + t600);\n  t602 = (t550 + s175);\n  t603 = (t551 + s176);\n  t604 = (t550 - s175);\n  t605 = (t551 - s176);\n  t606 = (s163 + s189);\n  t607 = (s164 + s190);\n  t608 = (s163 - s189);\n  t609 = (s164 - s190);\n  T3[(a503 + 2)] = (t602 + t606);\n  T3[(a503 + 3)] = (t603 + t607);\n  T3[(a503 + 18)] = (t602 - t606);\n  T3[(a503 + 19)] = (t603 - t607);\n  T3[(a503 + 10)] = (t604 + t609);\n  T3[(a503 + 11)] = (t605 - t608);\n  T3[(a503 + 26)] = (t604 - t609);\n  T3[(a503 + 27)] = (t605 + t608);\n  t610 = (t548 + t579);\n  t611 = (t549 - t578);\n  t612 = (t548 - t579);\n  t613 = (t549 + t578);\n  t614 = (s161 + s187);\n  t615 = (s162 - s188);\n  t616 = (s161 - s187);\n  t617 = (s162 + s188);\n  T3[(a503 + 4)] = (t610 + t614);\n  T3[(a503 + 5)] = (t611 + t615);\n  T3[(a503 + 20)] = (t610 - t614);\n  T3[(a503 + 21)] = (t611 - t615);\n  T3[(a503 + 12)] = (t612 + t617);\n  T3[(a503 + 13)] = (t613 - t616);\n  T3[(a503 + 28)] = (t612 - t617);\n  T3[(a503 + 29)] = (t613 + t616);\n  t618 = (t552 + s177);\n  t619 = (t553 - s178);\n  t620 = (t552 - s177);\n  t621 = (t553 + s178);\n  t622 = (s165 - s191);\n  t623 = (s166 + s192);\n  t624 = (s165 + s191);\n  t625 = (s166 - s192);\n  T3[(a503 + 6)] = (t618 + t622);\n  T3[(a503 + 7)] = (t619 + t623);\n  T3[(a503 + 22)] = (t618 - t622);\n  T3[(a503 + 23)] = (t619 - t623);\n  T3[(a503 + 14)] = (t620 + t625);\n  T3[(a503 + 15)] = (t621 - t624);\n  T3[(a503 + 30)] = (t620 - t625);\n  T3[(a503 + 31)] = (t621 + t624);\n  __syncthreads();\n  double a1478, a1479, a1480, a1481, a1482, a1483, a1484, a1485, \n         a1486, a1487, a1488, a1489, a1490, a1491, a1492, a1493, \n         a1494, a1495, a1496, a1497, a1498, a1499, a1500, a1501, \n         a1502, a1503, a1504, a1505, a1506, a1507, a1508, a1509, \n         a1510, a1511, a1512, a1513, a1514, a1515, a1516, a1517, \n         s434, s435, s436, s437, s438, s439, s440, s441, \n         s442, s443, s444, s445, s446, s447, s448, s449, \n         s450, s451, s452, s453, s454, s455, s456, s457, \n         s458, s459, s460, s461, s462, s463, s464, s465, \n         s466, s467, s468, s469, s470, s471, s472, s473, \n         s474, s475, s476, s477, s478, s479, s480, s481, \n         s482, s483, s484, s485, s486, s487, s488, s489, \n         s490, s491, s492, s493, s494, s495, s496, s497, \n         s498, s499, s500, s501, s502, s503, s504, s505, \n         s506, s507, s508, s509, s510, s511, s512, s513, \n         t1000, t1001, t1002, t1003, t1004, t1005, t1006, t1007, \n         t1008, t1009, t1010, t1011, t1012, t1013, t1014, t1015, \n         t1016, t1017, t1018, t1019, t1020, t1021, t1022, t1023, \n         t1024, t1025, t1026, t1027, t1028, t1029, t1030, t1031, \n         t1032, t1033, t1034, t1035, t1036, t1037, t1038, t1039, \n         t1040, t1041, t1042, t1043, t1044, t1045, t1046, t1047, \n         t1048, t1049, t1050, t1051, t1052, t1053, t1054, t1055, \n         t1056, t1057, t970, t971, t972, t973, t974, t975, \n         t976, t977, t978, t979, t980, t981, t982, t983, \n         t984, t985, t986, t987, t988, t989, t990, t991, \n         t992, t993, t994, t995, t996, t997, t998, t999;\n  int a1474, a1475, a1476, a1477, a1518;\n  a1474 = (threadIdx.x / 16);\n  a1475 = (threadIdx.x % 16);\n  a1476 = ((512*a1474) + (2*a1475));\n  s434 = T3[a1476];\n  s435 = T3[(a1476 + 1)];\n  s436 = T3[(a1476 + 256)];\n  s437 = T3[(a1476 + 257)];\n  a1477 = (32*a1475);\n  a1478 = D3[a1477];\n  a1479 = D3[(a1477 + 1)];\n  s438 = ((a1478*s434) - (a1479*s435));\n  s439 = ((a1479*s434) + (a1478*s435));\n  a1480 = D3[(a1477 + 2)];\n  a1481 = D3[(a1477 + 3)];\n  s440 = ((a1480*s436) - (a1481*s437));\n  s441 = ((a1481*s436) + (a1480*s437));\n  t970 = (s438 + s440);\n  t971 = (s439 + s441);\n  t972 = (s438 - s440);\n  t973 = (s439 - s441);\n  s442 = T3[(a1476 + 128)];\n  s443 = T3[(a1476 + 129)];\n  s444 = T3[(a1476 + 384)];\n  s445 = T3[(a1476 + 385)];\n  a1482 = D3[(4 + a1477)];\n  a1483 = D3[(5 + a1477)];\n  s446 = ((a1482*s442) - (a1483*s443));\n  s447 = ((a1483*s442) + (a1482*s443));\n  a1484 = D3[(6 + a1477)];\n  a1485 = D3[(7 + a1477)];\n  s448 = ((a1484*s444) - (a1485*s445));\n  s449 = ((a1485*s444) + (a1484*s445));\n  t974 = (s446 + s448);\n  t975 = (s447 + s449);\n  t976 = (s446 - s448);\n  t977 = (s447 - s449);\n  t978 = (t970 + t974);\n  t979 = (t971 + t975);\n  t980 = (t970 - t974);\n  t981 = (t971 - t975);\n  t982 = (t972 + t977);\n  t983 = (t973 - t976);\n  t984 = (t972 - t977);\n  t985 = (t973 + t976);\n  s450 = T3[(a1476 + 32)];\n  s451 = T3[(a1476 + 33)];\n  s452 = T3[(a1476 + 288)];\n  s453 = T3[(a1476 + 289)];\n  a1486 = D3[(a1477 + 8)];\n  a1487 = D3[(9 + a1477)];\n  s454 = ((a1486*s450) - (a1487*s451));\n  s455 = ((a1487*s450) + (a1486*s451));\n  a1488 = D3[(10 + a1477)];\n  a1489 = D3[(11 + a1477)];\n  s456 = ((a1488*s452) - (a1489*s453));\n  s457 = ((a1489*s452) + (a1488*s453));\n  t986 = (s454 + s456);\n  t987 = (s455 + s457);\n  t988 = (s454 - s456);\n  t989 = (s455 - s457);\n  s458 = T3[(a1476 + 160)];\n  s459 = T3[(a1476 + 161)];\n  s460 = T3[(a1476 + 416)];\n  s461 = T3[(a1476 + 417)];\n  a1490 = D3[(12 + a1477)];\n  a1491 = D3[(13 + a1477)];\n  s462 = ((a1490*s458) - (a1491*s459));\n  s463 = ((a1491*s458) + (a1490*s459));\n  a1492 = D3[(14 + a1477)];\n  a1493 = D3[(15 + a1477)];\n  s464 = ((a1492*s460) - (a1493*s461));\n  s465 = ((a1493*s460) + (a1492*s461));\n  t990 = (s462 + s464);\n  t991 = (s463 + s465);\n  t992 = (s462 - s464);\n  t993 = (s463 - s465);\n  t994 = (t986 + t990);\n  t995 = (t987 + t991);\n  a1494 = (0.70710678118654757*(t986 - t990));\n  a1495 = (0.70710678118654757*(t987 - t991));\n  s466 = (a1494 + a1495);\n  s467 = (a1495 - a1494);\n  t996 = (t988 + t993);\n  t997 = (t989 - t992);\n  t998 = (t988 - t993);\n  t999 = (t989 + t992);\n  s468 = ((0.92387953251128674*t996) + (0.38268343236508978*t997));\n  s469 = ((0.92387953251128674*t997) - (0.38268343236508978*t996));\n  s470 = ((0.38268343236508978*t998) + (0.92387953251128674*t999));\n  s471 = ((0.38268343236508978*t999) - (0.92387953251128674*t998));\n  s472 = T3[(a1476 + 64)];\n  s473 = T3[(a1476 + 65)];\n  s474 = T3[(a1476 + 320)];\n  s475 = T3[(a1476 + 321)];\n  a1496 = D3[(a1477 + 16)];\n  a1497 = D3[(17 + a1477)];\n  s476 = ((a1496*s472) - (a1497*s473));\n  s477 = ((a1497*s472) + (a1496*s473));\n  a1498 = D3[(18 + a1477)];\n  a1499 = D3[(19 + a1477)];\n  s478 = ((a1498*s474) - (a1499*s475));\n  s479 = ((a1499*s474) + (a1498*s475));\n  t1000 = (s476 + s478);\n  t1001 = (s477 + s479);\n  t1002 = (s476 - s478);\n  t1003 = (s477 - s479);\n  s480 = T3[(a1476 + 192)];\n  s481 = T3[(a1476 + 193)];\n  s482 = T3[(a1476 + 448)];\n  s483 = T3[(a1476 + 449)];\n  a1500 = D3[(20 + a1477)];\n  a1501 = D3[(21 + a1477)];\n  s484 = ((a1500*s480) - (a1501*s481));\n  s485 = ((a1501*s480) + (a1500*s481));\n  a1502 = D3[(22 + a1477)];\n  a1503 = D3[(23 + a1477)];\n  s486 = ((a1502*s482) - (a1503*s483));\n  s487 = ((a1503*s482) + (a1502*s483));\n  t1004 = (s484 + s486);\n  t1005 = (s485 + s487);\n  t1006 = (s484 - s486);\n  t1007 = (s485 - s487);\n  t1008 = (t1000 + t1004);\n  t1009 = (t1001 + t1005);\n  t1010 = (t1000 - t1004);\n  t1011 = (t1001 - t1005);\n  a1504 = (0.70710678118654757*(t1002 + t1007));\n  a1505 = (0.70710678118654757*(t1003 - t1006));\n  s488 = (a1504 + a1505);\n  s489 = (a1505 - a1504);\n  a1506 = (0.70710678118654757*(t1003 + t1006));\n  a1507 = (0.70710678118654757*(t1002 - t1007));\n  s490 = (a1506 - a1507);\n  s491 = (a1507 + a1506);\n  s492 = T3[(a1476 + 96)];\n  s493 = T3[(a1476 + 97)];\n  s494 = T3[(a1476 + 352)];\n  s495 = T3[(a1476 + 353)];\n  a1508 = D3[(a1477 + 24)];\n  a1509 = D3[(25 + a1477)];\n  s496 = ((a1508*s492) - (a1509*s493));\n  s497 = ((a1509*s492) + (a1508*s493));\n  a1510 = D3[(26 + a1477)];\n  a1511 = D3[(27 + a1477)];\n  s498 = ((a1510*s494) - (a1511*s495));\n  s499 = ((a1511*s494) + (a1510*s495));\n  t1012 = (s496 + s498);\n  t1013 = (s497 + s499);\n  t1014 = (s496 - s498);\n  t1015 = (s497 - s499);\n  s500 = T3[(a1476 + 224)];\n  s501 = T3[(a1476 + 225)];\n  s502 = T3[(a1476 + 480)];\n  s503 = T3[(a1476 + 481)];\n  a1512 = D3[(28 + a1477)];\n  a1513 = D3[(29 + a1477)];\n  s504 = ((a1512*s500) - (a1513*s501));\n  s505 = ((a1513*s500) + (a1512*s501));\n  a1514 = D3[(30 + a1477)];\n  a1515 = D3[(31 + a1477)];\n  s506 = ((a1514*s502) - (a1515*s503));\n  s507 = ((a1515*s502) + (a1514*s503));\n  t1016 = (s504 + s506);\n  t1017 = (s505 + s507);\n  t1018 = (s504 - s506);\n  t1019 = (s505 - s507);\n  t1020 = (t1012 + t1016);\n  t1021 = (t1013 + t1017);\n  a1516 = (0.70710678118654757*(t1013 - t1017));\n  a1517 = (0.70710678118654757*(t1012 - t1016));\n  s508 = (a1516 - a1517);\n  s509 = (a1517 + a1516);\n  t1022 = (t1014 + t1019);\n  t1023 = (t1015 - t1018);\n  t1024 = (t1014 - t1019);\n  t1025 = (t1015 + t1018);\n  s510 = ((0.38268343236508978*t1022) + (0.92387953251128674*t1023));\n  s511 = ((0.38268343236508978*t1023) - (0.92387953251128674*t1022));\n  s512 = ((0.92387953251128674*t1024) + (0.38268343236508978*t1025));\n  s513 = ((0.38268343236508978*t1024) - (0.92387953251128674*t1025));\n  t1026 = (t978 + t1008);\n  t1027 = (t979 + t1009);\n  t1028 = (t978 - t1008);\n  t1029 = (t979 - t1009);\n  t1030 = (t994 + t1020);\n  t1031 = (t995 + t1021);\n  t1032 = (t994 - t1020);\n  t1033 = (t995 - t1021);\n  a1518 = ((8*blockIdx.x) + (131072*a1475) + (2*a1474));\n  P1[a1518] = (t1026 + t1030);\n  P1[(a1518 + 1)] = (t1027 + t1031);\n  P1[(a1518 + 16777216)] = (t1026 - t1030);\n  P1[(a1518 + 16777217)] = (t1027 - t1031);\n  P1[(a1518 + 8388608)] = (t1028 + t1033);\n  P1[(a1518 + 8388609)] = (t1029 - t1032);\n  P1[(a1518 + 25165824)] = (t1028 - t1033);\n  P1[(a1518 + 25165825)] = (t1029 + t1032);\n  t1034 = (t982 + s488);\n  t1035 = (t983 + s489);\n  t1036 = (t982 - s488);\n  t1037 = (t983 - s489);\n  t1038 = (s468 + s510);\n  t1039 = (s469 + s511);\n  t1040 = (s468 - s510);\n  t1041 = (s469 - s511);\n  P1[(a1518 + 2097152)] = (t1034 + t1038);\n  P1[(a1518 + 2097153)] = (t1035 + t1039);\n  P1[(a1518 + 18874368)] = (t1034 - t1038);\n  P1[(a1518 + 18874369)] = (t1035 - t1039);\n  P1[(a1518 + 10485760)] = (t1036 + t1041);\n  P1[(a1518 + 10485761)] = (t1037 - t1040);\n  P1[(a1518 + 27262976)] = (t1036 - t1041);\n  P1[(a1518 + 27262977)] = (t1037 + t1040);\n  t1042 = (t980 + t1011);\n  t1043 = (t981 - t1010);\n  t1044 = (t980 - t1011);\n  t1045 = (t981 + t1010);\n  t1046 = (s466 + s508);\n  t1047 = (s467 - s509);\n  t1048 = (s466 - s508);\n  t1049 = (s467 + s509);\n  P1[(a1518 + 4194304)] = (t1042 + t1046);\n  P1[(a1518 + 4194305)] = (t1043 + t1047);\n  P1[(a1518 + 20971520)] = (t1042 - t1046);\n  P1[(a1518 + 20971521)] = (t1043 - t1047);\n  P1[(a1518 + 12582912)] = (t1044 + t1049);\n  P1[(a1518 + 12582913)] = (t1045 - t1048);\n  P1[(a1518 + 29360128)] = (t1044 - t1049);\n  P1[(a1518 + 29360129)] = (t1045 + t1048);\n  t1050 = (t984 + s490);\n  t1051 = (t985 - s491);\n  t1052 = (t984 - s490);\n  t1053 = (t985 + s491);\n  t1054 = (s470 - s512);\n  t1055 = (s471 + s513);\n  t1056 = (s470 + s512);\n  t1057 = (s471 - s513);\n  P1[(a1518 + 6291456)] = (t1050 + t1054);\n  P1[(a1518 + 6291457)] = (t1051 + t1055);\n  P1[(a1518 + 23068672)] = (t1050 - t1054);\n  P1[(a1518 + 23068673)] = (t1051 - t1055);\n  P1[(a1518 + 14680064)] = (t1052 + t1057);\n  P1[(a1518 + 14680065)] = (t1053 - t1056);\n  P1[(a1518 + 31457280)] = (t1052 - t1057);\n  P1[(a1518 + 31457281)] = (t1053 + t1056);\n  __syncthreads();\n}\n\n__global__\nvoid ker_zmddft_fwd_256x256x256_cu1(const double *P1, double *P2)\n{\n  __shared__ double T33[2048];\n  double a2012, a2013, a2014, a2015, a2016, a2017, a2018, a2019, \n         s658, s659, s660, s661, s662, s663, s664, s665, \n         s666, s667, s668, s669, s670, s671, s672, s673, \n         s674, s675, s676, s677, s678, s679, s680, s681, \n         s682, s683, s684, s685, s686, s687, s688, s689, \n         s690, s691, s692, s693, s694, s695, s696, s697, \n         s698, s699, s700, s701, s702, s703, s704, s705, \n         t1402, t1403, t1404, t1405, t1406, t1407, t1408, t1409, \n         t1410, t1411, t1412, t1413, t1414, t1415, t1416, t1417, \n         t1418, t1419, t1420, t1421, t1422, t1423, t1424, t1425, \n         t1426, t1427, t1428, t1429, t1430, t1431, t1432, t1433, \n         t1434, t1435, t1436, t1437, t1438, t1439, t1440, t1441, \n         t1442, t1443, t1444, t1445, t1446, t1447, t1448, t1449, \n         t1450, t1451, t1452, t1453, t1454, t1455, t1456, t1457, \n         t1458, t1459, t1460, t1461, t1462, t1463, t1464, t1465, \n         t1466, t1467, t1468, t1469, t1470, t1471, t1472, t1473, \n         t1474, t1475, t1476, t1477, t1478, t1479, t1480, t1481, \n         t1482, t1483, t1484, t1485, t1486, t1487, t1488, t1489;\n  int a2009, a2010, a2011, a2020;\n  a2009 = (512*(threadIdx.x / 16));\n  a2010 = (threadIdx.x % 16);\n  a2011 = ((2048*blockIdx.x) + a2009 + (2*a2010));\n  s658 = P1[a2011];\n  s659 = P1[(a2011 + 1)];\n  s660 = P1[(a2011 + 256)];\n  s661 = P1[(a2011 + 257)];\n  t1402 = (s658 + s660);\n  t1403 = (s659 + s661);\n  t1404 = (s658 - s660);\n  t1405 = (s659 - s661);\n  s662 = P1[(a2011 + 128)];\n  s663 = P1[(a2011 + 129)];\n  s664 = P1[(a2011 + 384)];\n  s665 = P1[(a2011 + 385)];\n  t1406 = (s662 + s664);\n  t1407 = (s663 + s665);\n  t1408 = (s662 - s664);\n  t1409 = (s663 - s665);\n  t1410 = (t1402 + t1406);\n  t1411 = (t1403 + t1407);\n  t1412 = (t1402 - t1406);\n  t1413 = (t1403 - t1407);\n  t1414 = (t1404 + t1409);\n  t1415 = (t1405 - t1408);\n  t1416 = (t1404 - t1409);\n  t1417 = (t1405 + t1408);\n  s666 = P1[(a2011 + 32)];\n  s667 = P1[(a2011 + 33)];\n  s668 = P1[(a2011 + 288)];\n  s669 = P1[(a2011 + 289)];\n  t1418 = (s666 + s668);\n  t1419 = (s667 + s669);\n  t1420 = (s666 - s668);\n  t1421 = (s667 - s669);\n  s670 = P1[(a2011 + 160)];\n  s671 = P1[(a2011 + 161)];\n  s672 = P1[(a2011 + 416)];\n  s673 = P1[(a2011 + 417)];\n  t1422 = (s670 + s672);\n  t1423 = (s671 + s673);\n  t1424 = (s670 - s672);\n  t1425 = (s671 - s673);\n  t1426 = (t1418 + t1422);\n  t1427 = (t1419 + t1423);\n  a2012 = (0.70710678118654757*(t1418 - t1422));\n  a2013 = (0.70710678118654757*(t1419 - t1423));\n  s674 = (a2012 + a2013);\n  s675 = (a2013 - a2012);\n  t1428 = (t1420 + t1425);\n  t1429 = (t1421 - t1424);\n  t1430 = (t1420 - t1425);\n  t1431 = (t1421 + t1424);\n  s676 = ((0.92387953251128674*t1428) + (0.38268343236508978*t1429));\n  s677 = ((0.92387953251128674*t1429) - (0.38268343236508978*t1428));\n  s678 = ((0.38268343236508978*t1430) + (0.92387953251128674*t1431));\n  s679 = ((0.38268343236508978*t1431) - (0.92387953251128674*t1430));\n  s680 = P1[(a2011 + 64)];\n  s681 = P1[(a2011 + 65)];\n  s682 = P1[(a2011 + 320)];\n  s683 = P1[(a2011 + 321)];\n  t1432 = (s680 + s682);\n  t1433 = (s681 + s683);\n  t1434 = (s680 - s682);\n  t1435 = (s681 - s683);\n  s684 = P1[(a2011 + 192)];\n  s685 = P1[(a2011 + 193)];\n  s686 = P1[(a2011 + 448)];\n  s687 = P1[(a2011 + 449)];\n  t1436 = (s684 + s686);\n  t1437 = (s685 + s687);\n  t1438 = (s684 - s686);\n  t1439 = (s685 - s687);\n  t1440 = (t1432 + t1436);\n  t1441 = (t1433 + t1437);\n  t1442 = (t1432 - t1436);\n  t1443 = (t1433 - t1437);\n  a2014 = (0.70710678118654757*(t1434 + t1439));\n  a2015 = (0.70710678118654757*(t1435 - t1438));\n  s688 = (a2014 + a2015);\n  s689 = (a2015 - a2014);\n  a2016 = (0.70710678118654757*(t1435 + t1438));\n  a2017 = (0.70710678118654757*(t1434 - t1439));\n  s690 = (a2016 - a2017);\n  s691 = (a2017 + a2016);\n  s692 = P1[(a2011 + 96)];\n  s693 = P1[(a2011 + 97)];\n  s694 = P1[(a2011 + 352)];\n  s695 = P1[(a2011 + 353)];\n  t1444 = (s692 + s694);\n  t1445 = (s693 + s695);\n  t1446 = (s692 - s694);\n  t1447 = (s693 - s695);\n  s696 = P1[(a2011 + 224)];\n  s697 = P1[(a2011 + 225)];\n  s698 = P1[(a2011 + 480)];\n  s699 = P1[(a2011 + 481)];\n  t1448 = (s696 + s698);\n  t1449 = (s697 + s699);\n  t1450 = (s696 - s698);\n  t1451 = (s697 - s699);\n  t1452 = (t1444 + t1448);\n  t1453 = (t1445 + t1449);\n  a2018 = (0.70710678118654757*(t1445 - t1449));\n  a2019 = (0.70710678118654757*(t1444 - t1448));\n  s700 = (a2018 - a2019);\n  s701 = (a2019 + a2018);\n  t1454 = (t1446 + t1451);\n  t1455 = (t1447 - t1450);\n  t1456 = (t1446 - t1451);\n  t1457 = (t1447 + t1450);\n  s702 = ((0.38268343236508978*t1454) + (0.92387953251128674*t1455));\n  s703 = ((0.38268343236508978*t1455) - (0.92387953251128674*t1454));\n  s704 = ((0.92387953251128674*t1456) + (0.38268343236508978*t1457));\n  s705 = ((0.38268343236508978*t1456) - (0.92387953251128674*t1457));\n  t1458 = (t1410 + t1440);\n  t1459 = (t1411 + t1441);\n  t1460 = (t1410 - t1440);\n  t1461 = (t1411 - t1441);\n  t1462 = (t1426 + t1452);\n  t1463 = (t1427 + t1453);\n  t1464 = (t1426 - t1452);\n  t1465 = (t1427 - t1453);\n  a2020 = (a2009 + (32*a2010));\n  T33[a2020] = (t1458 + t1462);\n  T33[(a2020 + 1)] = (t1459 + t1463);\n  T33[(a2020 + 16)] = (t1458 - t1462);\n  T33[(a2020 + 17)] = (t1459 - t1463);\n  T33[(a2020 + 8)] = (t1460 + t1465);\n  T33[(a2020 + 9)] = (t1461 - t1464);\n  T33[(a2020 + 24)] = (t1460 - t1465);\n  T33[(a2020 + 25)] = (t1461 + t1464);\n  t1466 = (t1414 + s688);\n  t1467 = (t1415 + s689);\n  t1468 = (t1414 - s688);\n  t1469 = (t1415 - s689);\n  t1470 = (s676 + s702);\n  t1471 = (s677 + s703);\n  t1472 = (s676 - s702);\n  t1473 = (s677 - s703);\n  T33[(a2020 + 2)] = (t1466 + t1470);\n  T33[(a2020 + 3)] = (t1467 + t1471);\n  T33[(a2020 + 18)] = (t1466 - t1470);\n  T33[(a2020 + 19)] = (t1467 - t1471);\n  T33[(a2020 + 10)] = (t1468 + t1473);\n  T33[(a2020 + 11)] = (t1469 - t1472);\n  T33[(a2020 + 26)] = (t1468 - t1473);\n  T33[(a2020 + 27)] = (t1469 + t1472);\n  t1474 = (t1412 + t1443);\n  t1475 = (t1413 - t1442);\n  t1476 = (t1412 - t1443);\n  t1477 = (t1413 + t1442);\n  t1478 = (s674 + s700);\n  t1479 = (s675 - s701);\n  t1480 = (s674 - s700);\n  t1481 = (s675 + s701);\n  T33[(a2020 + 4)] = (t1474 + t1478);\n  T33[(a2020 + 5)] = (t1475 + t1479);\n  T33[(a2020 + 20)] = (t1474 - t1478);\n  T33[(a2020 + 21)] = (t1475 - t1479);\n  T33[(a2020 + 12)] = (t1476 + t1481);\n  T33[(a2020 + 13)] = (t1477 - t1480);\n  T33[(a2020 + 28)] = (t1476 - t1481);\n  T33[(a2020 + 29)] = (t1477 + t1480);\n  t1482 = (t1416 + s690);\n  t1483 = (t1417 - s691);\n  t1484 = (t1416 - s690);\n  t1485 = (t1417 + s691);\n  t1486 = (s678 - s704);\n  t1487 = (s679 + s705);\n  t1488 = (s678 + s704);\n  t1489 = (s679 - s705);\n  T33[(a2020 + 6)] = (t1482 + t1486);\n  T33[(a2020 + 7)] = (t1483 + t1487);\n  T33[(a2020 + 22)] = (t1482 - t1486);\n  T33[(a2020 + 23)] = (t1483 - t1487);\n  T33[(a2020 + 14)] = (t1484 + t1489);\n  T33[(a2020 + 15)] = (t1485 - t1488);\n  T33[(a2020 + 30)] = (t1484 - t1489);\n  T33[(a2020 + 31)] = (t1485 + t1488);\n  __syncthreads();\n  double a2995, a2996, a2997, a2998, a2999, a3000, a3001, a3002, \n         a3003, a3004, a3005, a3006, a3007, a3008, a3009, a3010, \n         a3011, a3012, a3013, a3014, a3015, a3016, a3017, a3018, \n         a3019, a3020, a3021, a3022, a3023, a3024, a3025, a3026, \n         a3027, a3028, a3029, a3030, a3031, a3032, a3033, a3034, \n         s1000, s1001, s1002, s1003, s1004, s1005, s1006, s1007, \n         s1008, s1009, s1010, s1011, s1012, s1013, s1014, s1015, \n         s1016, s1017, s1018, s1019, s1020, s1021, s1022, s1023, \n         s1024, s1025, s946, s947, s948, s949, s950, s951, \n         s952, s953, s954, s955, s956, s957, s958, s959, \n         s960, s961, s962, s963, s964, s965, s966, s967, \n         s968, s969, s970, s971, s972, s973, s974, s975, \n         s976, s977, s978, s979, s980, s981, s982, s983, \n         s984, s985, s986, s987, s988, s989, s990, s991, \n         s992, s993, s994, s995, s996, s997, s998, s999, \n         t1834, t1835, t1836, t1837, t1838, t1839, t1840, t1841, \n         t1842, t1843, t1844, t1845, t1846, t1847, t1848, t1849, \n         t1850, t1851, t1852, t1853, t1854, t1855, t1856, t1857, \n         t1858, t1859, t1860, t1861, t1862, t1863, t1864, t1865, \n         t1866, t1867, t1868, t1869, t1870, t1871, t1872, t1873, \n         t1874, t1875, t1876, t1877, t1878, t1879, t1880, t1881, \n         t1882, t1883, t1884, t1885, t1886, t1887, t1888, t1889, \n         t1890, t1891, t1892, t1893, t1894, t1895, t1896, t1897, \n         t1898, t1899, t1900, t1901, t1902, t1903, t1904, t1905, \n         t1906, t1907, t1908, t1909, t1910, t1911, t1912, t1913, \n         t1914, t1915, t1916, t1917, t1918, t1919, t1920, t1921;\n  int a2991, a2992, a2993, a2994, a3035;\n  a2991 = (threadIdx.x / 16);\n  a2992 = (threadIdx.x % 16);\n  a2993 = ((512*a2991) + (2*a2992));\n  s946 = T33[a2993];\n  s947 = T33[(a2993 + 1)];\n  s948 = T33[(a2993 + 256)];\n  s949 = T33[(a2993 + 257)];\n  a2994 = (32*a2992);\n  a2995 = D3[a2994];\n  a2996 = D3[(a2994 + 1)];\n  s950 = ((a2995*s946) - (a2996*s947));\n  s951 = ((a2996*s946) + (a2995*s947));\n  a2997 = D3[(a2994 + 2)];\n  a2998 = D3[(a2994 + 3)];\n  s952 = ((a2997*s948) - (a2998*s949));\n  s953 = ((a2998*s948) + (a2997*s949));\n  t1834 = (s950 + s952);\n  t1835 = (s951 + s953);\n  t1836 = (s950 - s952);\n  t1837 = (s951 - s953);\n  s954 = T33[(a2993 + 128)];\n  s955 = T33[(a2993 + 129)];\n  s956 = T33[(a2993 + 384)];\n  s957 = T33[(a2993 + 385)];\n  a2999 = D3[(4 + a2994)];\n  a3000 = D3[(5 + a2994)];\n  s958 = ((a2999*s954) - (a3000*s955));\n  s959 = ((a3000*s954) + (a2999*s955));\n  a3001 = D3[(6 + a2994)];\n  a3002 = D3[(7 + a2994)];\n  s960 = ((a3001*s956) - (a3002*s957));\n  s961 = ((a3002*s956) + (a3001*s957));\n  t1838 = (s958 + s960);\n  t1839 = (s959 + s961);\n  t1840 = (s958 - s960);\n  t1841 = (s959 - s961);\n  t1842 = (t1834 + t1838);\n  t1843 = (t1835 + t1839);\n  t1844 = (t1834 - t1838);\n  t1845 = (t1835 - t1839);\n  t1846 = (t1836 + t1841);\n  t1847 = (t1837 - t1840);\n  t1848 = (t1836 - t1841);\n  t1849 = (t1837 + t1840);\n  s962 = T33[(a2993 + 32)];\n  s963 = T33[(a2993 + 33)];\n  s964 = T33[(a2993 + 288)];\n  s965 = T33[(a2993 + 289)];\n  a3003 = D3[(a2994 + 8)];\n  a3004 = D3[(9 + a2994)];\n  s966 = ((a3003*s962) - (a3004*s963));\n  s967 = ((a3004*s962) + (a3003*s963));\n  a3005 = D3[(10 + a2994)];\n  a3006 = D3[(11 + a2994)];\n  s968 = ((a3005*s964) - (a3006*s965));\n  s969 = ((a3006*s964) + (a3005*s965));\n  t1850 = (s966 + s968);\n  t1851 = (s967 + s969);\n  t1852 = (s966 - s968);\n  t1853 = (s967 - s969);\n  s970 = T33[(a2993 + 160)];\n  s971 = T33[(a2993 + 161)];\n  s972 = T33[(a2993 + 416)];\n  s973 = T33[(a2993 + 417)];\n  a3007 = D3[(12 + a2994)];\n  a3008 = D3[(13 + a2994)];\n  s974 = ((a3007*s970) - (a3008*s971));\n  s975 = ((a3008*s970) + (a3007*s971));\n  a3009 = D3[(14 + a2994)];\n  a3010 = D3[(15 + a2994)];\n  s976 = ((a3009*s972) - (a3010*s973));\n  s977 = ((a3010*s972) + (a3009*s973));\n  t1854 = (s974 + s976);\n  t1855 = (s975 + s977);\n  t1856 = (s974 - s976);\n  t1857 = (s975 - s977);\n  t1858 = (t1850 + t1854);\n  t1859 = (t1851 + t1855);\n  a3011 = (0.70710678118654757*(t1850 - t1854));\n  a3012 = (0.70710678118654757*(t1851 - t1855));\n  s978 = (a3011 + a3012);\n  s979 = (a3012 - a3011);\n  t1860 = (t1852 + t1857);\n  t1861 = (t1853 - t1856);\n  t1862 = (t1852 - t1857);\n  t1863 = (t1853 + t1856);\n  s980 = ((0.92387953251128674*t1860) + (0.38268343236508978*t1861));\n  s981 = ((0.92387953251128674*t1861) - (0.38268343236508978*t1860));\n  s982 = ((0.38268343236508978*t1862) + (0.92387953251128674*t1863));\n  s983 = ((0.38268343236508978*t1863) - (0.92387953251128674*t1862));\n  s984 = T33[(a2993 + 64)];\n  s985 = T33[(a2993 + 65)];\n  s986 = T33[(a2993 + 320)];\n  s987 = T33[(a2993 + 321)];\n  a3013 = D3[(a2994 + 16)];\n  a3014 = D3[(17 + a2994)];\n  s988 = ((a3013*s984) - (a3014*s985));\n  s989 = ((a3014*s984) + (a3013*s985));\n  a3015 = D3[(18 + a2994)];\n  a3016 = D3[(19 + a2994)];\n  s990 = ((a3015*s986) - (a3016*s987));\n  s991 = ((a3016*s986) + (a3015*s987));\n  t1864 = (s988 + s990);\n  t1865 = (s989 + s991);\n  t1866 = (s988 - s990);\n  t1867 = (s989 - s991);\n  s992 = T33[(a2993 + 192)];\n  s993 = T33[(a2993 + 193)];\n  s994 = T33[(a2993 + 448)];\n  s995 = T33[(a2993 + 449)];\n  a3017 = D3[(20 + a2994)];\n  a3018 = D3[(21 + a2994)];\n  s996 = ((a3017*s992) - (a3018*s993));\n  s997 = ((a3018*s992) + (a3017*s993));\n  a3019 = D3[(22 + a2994)];\n  a3020 = D3[(23 + a2994)];\n  s998 = ((a3019*s994) - (a3020*s995));\n  s999 = ((a3020*s994) + (a3019*s995));\n  t1868 = (s996 + s998);\n  t1869 = (s997 + s999);\n  t1870 = (s996 - s998);\n  t1871 = (s997 - s999);\n  t1872 = (t1864 + t1868);\n  t1873 = (t1865 + t1869);\n  t1874 = (t1864 - t1868);\n  t1875 = (t1865 - t1869);\n  a3021 = (0.70710678118654757*(t1866 + t1871));\n  a3022 = (0.70710678118654757*(t1867 - t1870));\n  s1000 = (a3021 + a3022);\n  s1001 = (a3022 - a3021);\n  a3023 = (0.70710678118654757*(t1867 + t1870));\n  a3024 = (0.70710678118654757*(t1866 - t1871));\n  s1002 = (a3023 - a3024);\n  s1003 = (a3024 + a3023);\n  s1004 = T33[(a2993 + 96)];\n  s1005 = T33[(a2993 + 97)];\n  s1006 = T33[(a2993 + 352)];\n  s1007 = T33[(a2993 + 353)];\n  a3025 = D3[(a2994 + 24)];\n  a3026 = D3[(25 + a2994)];\n  s1008 = ((a3025*s1004) - (a3026*s1005));\n  s1009 = ((a3026*s1004) + (a3025*s1005));\n  a3027 = D3[(26 + a2994)];\n  a3028 = D3[(27 + a2994)];\n  s1010 = ((a3027*s1006) - (a3028*s1007));\n  s1011 = ((a3028*s1006) + (a3027*s1007));\n  t1876 = (s1008 + s1010);\n  t1877 = (s1009 + s1011);\n  t1878 = (s1008 - s1010);\n  t1879 = (s1009 - s1011);\n  s1012 = T33[(a2993 + 224)];\n  s1013 = T33[(a2993 + 225)];\n  s1014 = T33[(a2993 + 480)];\n  s1015 = T33[(a2993 + 481)];\n  a3029 = D3[(28 + a2994)];\n  a3030 = D3[(29 + a2994)];\n  s1016 = ((a3029*s1012) - (a3030*s1013));\n  s1017 = ((a3030*s1012) + (a3029*s1013));\n  a3031 = D3[(30 + a2994)];\n  a3032 = D3[(31 + a2994)];\n  s1018 = ((a3031*s1014) - (a3032*s1015));\n  s1019 = ((a3032*s1014) + (a3031*s1015));\n  t1880 = (s1016 + s1018);\n  t1881 = (s1017 + s1019);\n  t1882 = (s1016 - s1018);\n  t1883 = (s1017 - s1019);\n  t1884 = (t1876 + t1880);\n  t1885 = (t1877 + t1881);\n  a3033 = (0.70710678118654757*(t1877 - t1881));\n  a3034 = (0.70710678118654757*(t1876 - t1880));\n  s1020 = (a3033 - a3034);\n  s1021 = (a3034 + a3033);\n  t1886 = (t1878 + t1883);\n  t1887 = (t1879 - t1882);\n  t1888 = (t1878 - t1883);\n  t1889 = (t1879 + t1882);\n  s1022 = ((0.38268343236508978*t1886) + (0.92387953251128674*t1887));\n  s1023 = ((0.38268343236508978*t1887) - (0.92387953251128674*t1886));\n  s1024 = ((0.92387953251128674*t1888) + (0.38268343236508978*t1889));\n  s1025 = ((0.38268343236508978*t1888) - (0.92387953251128674*t1889));\n  t1890 = (t1842 + t1872);\n  t1891 = (t1843 + t1873);\n  t1892 = (t1842 - t1872);\n  t1893 = (t1843 - t1873);\n  t1894 = (t1858 + t1884);\n  t1895 = (t1859 + t1885);\n  t1896 = (t1858 - t1884);\n  t1897 = (t1859 - t1885);\n  a3035 = ((8*blockIdx.x) + (131072*a2992) + (2*a2991));\n  P2[a3035] = (t1890 + t1894);\n  P2[(a3035 + 1)] = (t1891 + t1895);\n  P2[(a3035 + 16777216)] = (t1890 - t1894);\n  P2[(a3035 + 16777217)] = (t1891 - t1895);\n  P2[(a3035 + 8388608)] = (t1892 + t1897);\n  P2[(a3035 + 8388609)] = (t1893 - t1896);\n  P2[(a3035 + 25165824)] = (t1892 - t1897);\n  P2[(a3035 + 25165825)] = (t1893 + t1896);\n  t1898 = (t1846 + s1000);\n  t1899 = (t1847 + s1001);\n  t1900 = (t1846 - s1000);\n  t1901 = (t1847 - s1001);\n  t1902 = (s980 + s1022);\n  t1903 = (s981 + s1023);\n  t1904 = (s980 - s1022);\n  t1905 = (s981 - s1023);\n  P2[(a3035 + 2097152)] = (t1898 + t1902);\n  P2[(a3035 + 2097153)] = (t1899 + t1903);\n  P2[(a3035 + 18874368)] = (t1898 - t1902);\n  P2[(a3035 + 18874369)] = (t1899 - t1903);\n  P2[(a3035 + 10485760)] = (t1900 + t1905);\n  P2[(a3035 + 10485761)] = (t1901 - t1904);\n  P2[(a3035 + 27262976)] = (t1900 - t1905);\n  P2[(a3035 + 27262977)] = (t1901 + t1904);\n  t1906 = (t1844 + t1875);\n  t1907 = (t1845 - t1874);\n  t1908 = (t1844 - t1875);\n  t1909 = (t1845 + t1874);\n  t1910 = (s978 + s1020);\n  t1911 = (s979 - s1021);\n  t1912 = (s978 - s1020);\n  t1913 = (s979 + s1021);\n  P2[(a3035 + 4194304)] = (t1906 + t1910);\n  P2[(a3035 + 4194305)] = (t1907 + t1911);\n  P2[(a3035 + 20971520)] = (t1906 - t1910);\n  P2[(a3035 + 20971521)] = (t1907 - t1911);\n  P2[(a3035 + 12582912)] = (t1908 + t1913);\n  P2[(a3035 + 12582913)] = (t1909 - t1912);\n  P2[(a3035 + 29360128)] = (t1908 - t1913);\n  P2[(a3035 + 29360129)] = (t1909 + t1912);\n  t1914 = (t1848 + s1002);\n  t1915 = (t1849 - s1003);\n  t1916 = (t1848 - s1002);\n  t1917 = (t1849 + s1003);\n  t1918 = (s982 - s1024);\n  t1919 = (s983 + s1025);\n  t1920 = (s982 + s1024);\n  t1921 = (s983 - s1025);\n  P2[(a3035 + 6291456)] = (t1914 + t1918);\n  P2[(a3035 + 6291457)] = (t1915 + t1919);\n  P2[(a3035 + 23068672)] = (t1914 - t1918);\n  P2[(a3035 + 23068673)] = (t1915 - t1919);\n  P2[(a3035 + 14680064)] = (t1916 + t1921);\n  P2[(a3035 + 14680065)] = (t1917 - t1920);\n  P2[(a3035 + 31457280)] = (t1916 - t1921);\n  P2[(a3035 + 31457281)] = (t1917 + t1920);\n  __syncthreads();\n}\n\n__global__\nvoid ker_zmddft_fwd_256x256x256_cu2(const double *P2, double *Y)\n{\n  __shared__ double T63[2048];\n  double a3529, a3530, a3531, a3532, a3533, a3534, a3535, a3536, \n         s1170, s1171, s1172, s1173, s1174, s1175, s1176, s1177, \n         s1178, s1179, s1180, s1181, s1182, s1183, s1184, s1185, \n         s1186, s1187, s1188, s1189, s1190, s1191, s1192, s1193, \n         s1194, s1195, s1196, s1197, s1198, s1199, s1200, s1201, \n         s1202, s1203, s1204, s1205, s1206, s1207, s1208, s1209, \n         s1210, s1211, s1212, s1213, s1214, s1215, s1216, s1217, \n         t2266, t2267, t2268, t2269, t2270, t2271, t2272, t2273, \n         t2274, t2275, t2276, t2277, t2278, t2279, t2280, t2281, \n         t2282, t2283, t2284, t2285, t2286, t2287, t2288, t2289, \n         t2290, t2291, t2292, t2293, t2294, t2295, t2296, t2297, \n         t2298, t2299, t2300, t2301, t2302, t2303, t2304, t2305, \n         t2306, t2307, t2308, t2309, t2310, t2311, t2312, t2313, \n         t2314, t2315, t2316, t2317, t2318, t2319, t2320, t2321, \n         t2322, t2323, t2324, t2325, t2326, t2327, t2328, t2329, \n         t2330, t2331, t2332, t2333, t2334, t2335, t2336, t2337, \n         t2338, t2339, t2340, t2341, t2342, t2343, t2344, t2345, \n         t2346, t2347, t2348, t2349, t2350, t2351, t2352, t2353;\n  int a3526, a3527, a3528, a3537;\n  a3526 = (512*(threadIdx.x / 16));\n  a3527 = (threadIdx.x % 16);\n  a3528 = ((2048*blockIdx.x) + a3526 + (2*a3527));\n  s1170 = P2[a3528];\n  s1171 = P2[(a3528 + 1)];\n  s1172 = P2[(a3528 + 256)];\n  s1173 = P2[(a3528 + 257)];\n  t2266 = (s1170 + s1172);\n  t2267 = (s1171 + s1173);\n  t2268 = (s1170 - s1172);\n  t2269 = (s1171 - s1173);\n  s1174 = P2[(a3528 + 128)];\n  s1175 = P2[(a3528 + 129)];\n  s1176 = P2[(a3528 + 384)];\n  s1177 = P2[(a3528 + 385)];\n  t2270 = (s1174 + s1176);\n  t2271 = (s1175 + s1177);\n  t2272 = (s1174 - s1176);\n  t2273 = (s1175 - s1177);\n  t2274 = (t2266 + t2270);\n  t2275 = (t2267 + t2271);\n  t2276 = (t2266 - t2270);\n  t2277 = (t2267 - t2271);\n  t2278 = (t2268 + t2273);\n  t2279 = (t2269 - t2272);\n  t2280 = (t2268 - t2273);\n  t2281 = (t2269 + t2272);\n  s1178 = P2[(a3528 + 32)];\n  s1179 = P2[(a3528 + 33)];\n  s1180 = P2[(a3528 + 288)];\n  s1181 = P2[(a3528 + 289)];\n  t2282 = (s1178 + s1180);\n  t2283 = (s1179 + s1181);\n  t2284 = (s1178 - s1180);\n  t2285 = (s1179 - s1181);\n  s1182 = P2[(a3528 + 160)];\n  s1183 = P2[(a3528 + 161)];\n  s1184 = P2[(a3528 + 416)];\n  s1185 = P2[(a3528 + 417)];\n  t2286 = (s1182 + s1184);\n  t2287 = (s1183 + s1185);\n  t2288 = (s1182 - s1184);\n  t2289 = (s1183 - s1185);\n  t2290 = (t2282 + t2286);\n  t2291 = (t2283 + t2287);\n  a3529 = (0.70710678118654757*(t2282 - t2286));\n  a3530 = (0.70710678118654757*(t2283 - t2287));\n  s1186 = (a3529 + a3530);\n  s1187 = (a3530 - a3529);\n  t2292 = (t2284 + t2289);\n  t2293 = (t2285 - t2288);\n  t2294 = (t2284 - t2289);\n  t2295 = (t2285 + t2288);\n  s1188 = ((0.92387953251128674*t2292) + (0.38268343236508978*t2293));\n  s1189 = ((0.92387953251128674*t2293) - (0.38268343236508978*t2292));\n  s1190 = ((0.38268343236508978*t2294) + (0.92387953251128674*t2295));\n  s1191 = ((0.38268343236508978*t2295) - (0.92387953251128674*t2294));\n  s1192 = P2[(a3528 + 64)];\n  s1193 = P2[(a3528 + 65)];\n  s1194 = P2[(a3528 + 320)];\n  s1195 = P2[(a3528 + 321)];\n  t2296 = (s1192 + s1194);\n  t2297 = (s1193 + s1195);\n  t2298 = (s1192 - s1194);\n  t2299 = (s1193 - s1195);\n  s1196 = P2[(a3528 + 192)];\n  s1197 = P2[(a3528 + 193)];\n  s1198 = P2[(a3528 + 448)];\n  s1199 = P2[(a3528 + 449)];\n  t2300 = (s1196 + s1198);\n  t2301 = (s1197 + s1199);\n  t2302 = (s1196 - s1198);\n  t2303 = (s1197 - s1199);\n  t2304 = (t2296 + t2300);\n  t2305 = (t2297 + t2301);\n  t2306 = (t2296 - t2300);\n  t2307 = (t2297 - t2301);\n  a3531 = (0.70710678118654757*(t2298 + t2303));\n  a3532 = (0.70710678118654757*(t2299 - t2302));\n  s1200 = (a3531 + a3532);\n  s1201 = (a3532 - a3531);\n  a3533 = (0.70710678118654757*(t2299 + t2302));\n  a3534 = (0.70710678118654757*(t2298 - t2303));\n  s1202 = (a3533 - a3534);\n  s1203 = (a3534 + a3533);\n  s1204 = P2[(a3528 + 96)];\n  s1205 = P2[(a3528 + 97)];\n  s1206 = P2[(a3528 + 352)];\n  s1207 = P2[(a3528 + 353)];\n  t2308 = (s1204 + s1206);\n  t2309 = (s1205 + s1207);\n  t2310 = (s1204 - s1206);\n  t2311 = (s1205 - s1207);\n  s1208 = P2[(a3528 + 224)];\n  s1209 = P2[(a3528 + 225)];\n  s1210 = P2[(a3528 + 480)];\n  s1211 = P2[(a3528 + 481)];\n  t2312 = (s1208 + s1210);\n  t2313 = (s1209 + s1211);\n  t2314 = (s1208 - s1210);\n  t2315 = (s1209 - s1211);\n  t2316 = (t2308 + t2312);\n  t2317 = (t2309 + t2313);\n  a3535 = (0.70710678118654757*(t2309 - t2313));\n  a3536 = (0.70710678118654757*(t2308 - t2312));\n  s1212 = (a3535 - a3536);\n  s1213 = (a3536 + a3535);\n  t2318 = (t2310 + t2315);\n  t2319 = (t2311 - t2314);\n  t2320 = (t2310 - t2315);\n  t2321 = (t2311 + t2314);\n  s1214 = ((0.38268343236508978*t2318) + (0.92387953251128674*t2319));\n  s1215 = ((0.38268343236508978*t2319) - (0.92387953251128674*t2318));\n  s1216 = ((0.92387953251128674*t2320) + (0.38268343236508978*t2321));\n  s1217 = ((0.38268343236508978*t2320) - (0.92387953251128674*t2321));\n  t2322 = (t2274 + t2304);\n  t2323 = (t2275 + t2305);\n  t2324 = (t2274 - t2304);\n  t2325 = (t2275 - t2305);\n  t2326 = (t2290 + t2316);\n  t2327 = (t2291 + t2317);\n  t2328 = (t2290 - t2316);\n  t2329 = (t2291 - t2317);\n  a3537 = (a3526 + (32*a3527));\n  T63[a3537] = (t2322 + t2326);\n  T63[(a3537 + 1)] = (t2323 + t2327);\n  T63[(a3537 + 16)] = (t2322 - t2326);\n  T63[(a3537 + 17)] = (t2323 - t2327);\n  T63[(a3537 + 8)] = (t2324 + t2329);\n  T63[(a3537 + 9)] = (t2325 - t2328);\n  T63[(a3537 + 24)] = (t2324 - t2329);\n  T63[(a3537 + 25)] = (t2325 + t2328);\n  t2330 = (t2278 + s1200);\n  t2331 = (t2279 + s1201);\n  t2332 = (t2278 - s1200);\n  t2333 = (t2279 - s1201);\n  t2334 = (s1188 + s1214);\n  t2335 = (s1189 + s1215);\n  t2336 = (s1188 - s1214);\n  t2337 = (s1189 - s1215);\n  T63[(a3537 + 2)] = (t2330 + t2334);\n  T63[(a3537 + 3)] = (t2331 + t2335);\n  T63[(a3537 + 18)] = (t2330 - t2334);\n  T63[(a3537 + 19)] = (t2331 - t2335);\n  T63[(a3537 + 10)] = (t2332 + t2337);\n  T63[(a3537 + 11)] = (t2333 - t2336);\n  T63[(a3537 + 26)] = (t2332 - t2337);\n  T63[(a3537 + 27)] = (t2333 + t2336);\n  t2338 = (t2276 + t2307);\n  t2339 = (t2277 - t2306);\n  t2340 = (t2276 - t2307);\n  t2341 = (t2277 + t2306);\n  t2342 = (s1186 + s1212);\n  t2343 = (s1187 - s1213);\n  t2344 = (s1186 - s1212);\n  t2345 = (s1187 + s1213);\n  T63[(a3537 + 4)] = (t2338 + t2342);\n  T63[(a3537 + 5)] = (t2339 + t2343);\n  T63[(a3537 + 20)] = (t2338 - t2342);\n  T63[(a3537 + 21)] = (t2339 - t2343);\n  T63[(a3537 + 12)] = (t2340 + t2345);\n  T63[(a3537 + 13)] = (t2341 - t2344);\n  T63[(a3537 + 28)] = (t2340 - t2345);\n  T63[(a3537 + 29)] = (t2341 + t2344);\n  t2346 = (t2280 + s1202);\n  t2347 = (t2281 - s1203);\n  t2348 = (t2280 - s1202);\n  t2349 = (t2281 + s1203);\n  t2350 = (s1190 - s1216);\n  t2351 = (s1191 + s1217);\n  t2352 = (s1190 + s1216);\n  t2353 = (s1191 - s1217);\n  T63[(a3537 + 6)] = (t2346 + t2350);\n  T63[(a3537 + 7)] = (t2347 + t2351);\n  T63[(a3537 + 22)] = (t2346 - t2350);\n  T63[(a3537 + 23)] = (t2347 - t2351);\n  T63[(a3537 + 14)] = (t2348 + t2353);\n  T63[(a3537 + 15)] = (t2349 - t2352);\n  T63[(a3537 + 30)] = (t2348 - t2353);\n  T63[(a3537 + 31)] = (t2349 + t2352);\n  __syncthreads();\n  double a4512, a4513, a4514, a4515, a4516, a4517, a4518, a4519, \n         a4520, a4521, a4522, a4523, a4524, a4525, a4526, a4527, \n         a4528, a4529, a4530, a4531, a4532, a4533, a4534, a4535, \n         a4536, a4537, a4538, a4539, a4540, a4541, a4542, a4543, \n         a4544, a4545, a4546, a4547, a4548, a4549, a4550, a4551, \n         s1458, s1459, s1460, s1461, s1462, s1463, s1464, s1465, \n         s1466, s1467, s1468, s1469, s1470, s1471, s1472, s1473, \n         s1474, s1475, s1476, s1477, s1478, s1479, s1480, s1481, \n         s1482, s1483, s1484, s1485, s1486, s1487, s1488, s1489, \n         s1490, s1491, s1492, s1493, s1494, s1495, s1496, s1497, \n         s1498, s1499, s1500, s1501, s1502, s1503, s1504, s1505, \n         s1506, s1507, s1508, s1509, s1510, s1511, s1512, s1513, \n         s1514, s1515, s1516, s1517, s1518, s1519, s1520, s1521, \n         s1522, s1523, s1524, s1525, s1526, s1527, s1528, s1529, \n         s1530, s1531, s1532, s1533, s1534, s1535, s1536, s1537, \n         t2698, t2699, t2700, t2701, t2702, t2703, t2704, t2705, \n         t2706, t2707, t2708, t2709, t2710, t2711, t2712, t2713, \n         t2714, t2715, t2716, t2717, t2718, t2719, t2720, t2721, \n         t2722, t2723, t2724, t2725, t2726, t2727, t2728, t2729, \n         t2730, t2731, t2732, t2733, t2734, t2735, t2736, t2737, \n         t2738, t2739, t2740, t2741, t2742, t2743, t2744, t2745, \n         t2746, t2747, t2748, t2749, t2750, t2751, t2752, t2753, \n         t2754, t2755, t2756, t2757, t2758, t2759, t2760, t2761, \n         t2762, t2763, t2764, t2765, t2766, t2767, t2768, t2769, \n         t2770, t2771, t2772, t2773, t2774, t2775, t2776, t2777, \n         t2778, t2779, t2780, t2781, t2782, t2783, t2784, t2785;\n  int a4508, a4509, a4510, a4511, a4552;\n  a4508 = (threadIdx.x / 16);\n  a4509 = (threadIdx.x % 16);\n  a4510 = ((512*a4508) + (2*a4509));\n  s1458 = T63[a4510];\n  s1459 = T63[(a4510 + 1)];\n  s1460 = T63[(a4510 + 256)];\n  s1461 = T63[(a4510 + 257)];\n  a4511 = (32*a4509);\n  a4512 = D3[a4511];\n  a4513 = D3[(a4511 + 1)];\n  s1462 = ((a4512*s1458) - (a4513*s1459));\n  s1463 = ((a4513*s1458) + (a4512*s1459));\n  a4514 = D3[(a4511 + 2)];\n  a4515 = D3[(a4511 + 3)];\n  s1464 = ((a4514*s1460) - (a4515*s1461));\n  s1465 = ((a4515*s1460) + (a4514*s1461));\n  t2698 = (s1462 + s1464);\n  t2699 = (s1463 + s1465);\n  t2700 = (s1462 - s1464);\n  t2701 = (s1463 - s1465);\n  s1466 = T63[(a4510 + 128)];\n  s1467 = T63[(a4510 + 129)];\n  s1468 = T63[(a4510 + 384)];\n  s1469 = T63[(a4510 + 385)];\n  a4516 = D3[(4 + a4511)];\n  a4517 = D3[(5 + a4511)];\n  s1470 = ((a4516*s1466) - (a4517*s1467));\n  s1471 = ((a4517*s1466) + (a4516*s1467));\n  a4518 = D3[(6 + a4511)];\n  a4519 = D3[(7 + a4511)];\n  s1472 = ((a4518*s1468) - (a4519*s1469));\n  s1473 = ((a4519*s1468) + (a4518*s1469));\n  t2702 = (s1470 + s1472);\n  t2703 = (s1471 + s1473);\n  t2704 = (s1470 - s1472);\n  t2705 = (s1471 - s1473);\n  t2706 = (t2698 + t2702);\n  t2707 = (t2699 + t2703);\n  t2708 = (t2698 - t2702);\n  t2709 = (t2699 - t2703);\n  t2710 = (t2700 + t2705);\n  t2711 = (t2701 - t2704);\n  t2712 = (t2700 - t2705);\n  t2713 = (t2701 + t2704);\n  s1474 = T63[(a4510 + 32)];\n  s1475 = T63[(a4510 + 33)];\n  s1476 = T63[(a4510 + 288)];\n  s1477 = T63[(a4510 + 289)];\n  a4520 = D3[(a4511 + 8)];\n  a4521 = D3[(9 + a4511)];\n  s1478 = ((a4520*s1474) - (a4521*s1475));\n  s1479 = ((a4521*s1474) + (a4520*s1475));\n  a4522 = D3[(10 + a4511)];\n  a4523 = D3[(11 + a4511)];\n  s1480 = ((a4522*s1476) - (a4523*s1477));\n  s1481 = ((a4523*s1476) + (a4522*s1477));\n  t2714 = (s1478 + s1480);\n  t2715 = (s1479 + s1481);\n  t2716 = (s1478 - s1480);\n  t2717 = (s1479 - s1481);\n  s1482 = T63[(a4510 + 160)];\n  s1483 = T63[(a4510 + 161)];\n  s1484 = T63[(a4510 + 416)];\n  s1485 = T63[(a4510 + 417)];\n  a4524 = D3[(12 + a4511)];\n  a4525 = D3[(13 + a4511)];\n  s1486 = ((a4524*s1482) - (a4525*s1483));\n  s1487 = ((a4525*s1482) + (a4524*s1483));\n  a4526 = D3[(14 + a4511)];\n  a4527 = D3[(15 + a4511)];\n  s1488 = ((a4526*s1484) - (a4527*s1485));\n  s1489 = ((a4527*s1484) + (a4526*s1485));\n  t2718 = (s1486 + s1488);\n  t2719 = (s1487 + s1489);\n  t2720 = (s1486 - s1488);\n  t2721 = (s1487 - s1489);\n  t2722 = (t2714 + t2718);\n  t2723 = (t2715 + t2719);\n  a4528 = (0.70710678118654757*(t2714 - t2718));\n  a4529 = (0.70710678118654757*(t2715 - t2719));\n  s1490 = (a4528 + a4529);\n  s1491 = (a4529 - a4528);\n  t2724 = (t2716 + t2721);\n  t2725 = (t2717 - t2720);\n  t2726 = (t2716 - t2721);\n  t2727 = (t2717 + t2720);\n  s1492 = ((0.92387953251128674*t2724) + (0.38268343236508978*t2725));\n  s1493 = ((0.92387953251128674*t2725) - (0.38268343236508978*t2724));\n  s1494 = ((0.38268343236508978*t2726) + (0.92387953251128674*t2727));\n  s1495 = ((0.38268343236508978*t2727) - (0.92387953251128674*t2726));\n  s1496 = T63[(a4510 + 64)];\n  s1497 = T63[(a4510 + 65)];\n  s1498 = T63[(a4510 + 320)];\n  s1499 = T63[(a4510 + 321)];\n  a4530 = D3[(a4511 + 16)];\n  a4531 = D3[(17 + a4511)];\n  s1500 = ((a4530*s1496) - (a4531*s1497));\n  s1501 = ((a4531*s1496) + (a4530*s1497));\n  a4532 = D3[(18 + a4511)];\n  a4533 = D3[(19 + a4511)];\n  s1502 = ((a4532*s1498) - (a4533*s1499));\n  s1503 = ((a4533*s1498) + (a4532*s1499));\n  t2728 = (s1500 + s1502);\n  t2729 = (s1501 + s1503);\n  t2730 = (s1500 - s1502);\n  t2731 = (s1501 - s1503);\n  s1504 = T63[(a4510 + 192)];\n  s1505 = T63[(a4510 + 193)];\n  s1506 = T63[(a4510 + 448)];\n  s1507 = T63[(a4510 + 449)];\n  a4534 = D3[(20 + a4511)];\n  a4535 = D3[(21 + a4511)];\n  s1508 = ((a4534*s1504) - (a4535*s1505));\n  s1509 = ((a4535*s1504) + (a4534*s1505));\n  a4536 = D3[(22 + a4511)];\n  a4537 = D3[(23 + a4511)];\n  s1510 = ((a4536*s1506) - (a4537*s1507));\n  s1511 = ((a4537*s1506) + (a4536*s1507));\n  t2732 = (s1508 + s1510);\n  t2733 = (s1509 + s1511);\n  t2734 = (s1508 - s1510);\n  t2735 = (s1509 - s1511);\n  t2736 = (t2728 + t2732);\n  t2737 = (t2729 + t2733);\n  t2738 = (t2728 - t2732);\n  t2739 = (t2729 - t2733);\n  a4538 = (0.70710678118654757*(t2730 + t2735));\n  a4539 = (0.70710678118654757*(t2731 - t2734));\n  s1512 = (a4538 + a4539);\n  s1513 = (a4539 - a4538);\n  a4540 = (0.70710678118654757*(t2731 + t2734));\n  a4541 = (0.70710678118654757*(t2730 - t2735));\n  s1514 = (a4540 - a4541);\n  s1515 = (a4541 + a4540);\n  s1516 = T63[(a4510 + 96)];\n  s1517 = T63[(a4510 + 97)];\n  s1518 = T63[(a4510 + 352)];\n  s1519 = T63[(a4510 + 353)];\n  a4542 = D3[(a4511 + 24)];\n  a4543 = D3[(25 + a4511)];\n  s1520 = ((a4542*s1516) - (a4543*s1517));\n  s1521 = ((a4543*s1516) + (a4542*s1517));\n  a4544 = D3[(26 + a4511)];\n  a4545 = D3[(27 + a4511)];\n  s1522 = ((a4544*s1518) - (a4545*s1519));\n  s1523 = ((a4545*s1518) + (a4544*s1519));\n  t2740 = (s1520 + s1522);\n  t2741 = (s1521 + s1523);\n  t2742 = (s1520 - s1522);\n  t2743 = (s1521 - s1523);\n  s1524 = T63[(a4510 + 224)];\n  s1525 = T63[(a4510 + 225)];\n  s1526 = T63[(a4510 + 480)];\n  s1527 = T63[(a4510 + 481)];\n  a4546 = D3[(28 + a4511)];\n  a4547 = D3[(29 + a4511)];\n  s1528 = ((a4546*s1524) - (a4547*s1525));\n  s1529 = ((a4547*s1524) + (a4546*s1525));\n  a4548 = D3[(30 + a4511)];\n  a4549 = D3[(31 + a4511)];\n  s1530 = ((a4548*s1526) - (a4549*s1527));\n  s1531 = ((a4549*s1526) + (a4548*s1527));\n  t2744 = (s1528 + s1530);\n  t2745 = (s1529 + s1531);\n  t2746 = (s1528 - s1530);\n  t2747 = (s1529 - s1531);\n  t2748 = (t2740 + t2744);\n  t2749 = (t2741 + t2745);\n  a4550 = (0.70710678118654757*(t2741 - t2745));\n  a4551 = (0.70710678118654757*(t2740 - t2744));\n  s1532 = (a4550 - a4551);\n  s1533 = (a4551 + a4550);\n  t2750 = (t2742 + t2747);\n  t2751 = (t2743 - t2746);\n  t2752 = (t2742 - t2747);\n  t2753 = (t2743 + t2746);\n  s1534 = ((0.38268343236508978*t2750) + (0.92387953251128674*t2751));\n  s1535 = ((0.38268343236508978*t2751) - (0.92387953251128674*t2750));\n  s1536 = ((0.92387953251128674*t2752) + (0.38268343236508978*t2753));\n  s1537 = ((0.38268343236508978*t2752) - (0.92387953251128674*t2753));\n  t2754 = (t2706 + t2736);\n  t2755 = (t2707 + t2737);\n  t2756 = (t2706 - t2736);\n  t2757 = (t2707 - t2737);\n  t2758 = (t2722 + t2748);\n  t2759 = (t2723 + t2749);\n  t2760 = (t2722 - t2748);\n  t2761 = (t2723 - t2749);\n  a4552 = ((8*blockIdx.x) + (131072*a4509) + (2*a4508));\n  Y[a4552] = (t2754 + t2758);\n  Y[(a4552 + 1)] = (t2755 + t2759);\n  Y[(a4552 + 16777216)] = (t2754 - t2758);\n  Y[(a4552 + 16777217)] = (t2755 - t2759);\n  Y[(a4552 + 8388608)] = (t2756 + t2761);\n  Y[(a4552 + 8388609)] = (t2757 - t2760);\n  Y[(a4552 + 25165824)] = (t2756 - t2761);\n  Y[(a4552 + 25165825)] = (t2757 + t2760);\n  t2762 = (t2710 + s1512);\n  t2763 = (t2711 + s1513);\n  t2764 = (t2710 - s1512);\n  t2765 = (t2711 - s1513);\n  t2766 = (s1492 + s1534);\n  t2767 = (s1493 + s1535);\n  t2768 = (s1492 - s1534);\n  t2769 = (s1493 - s1535);\n  Y[(a4552 + 2097152)] = (t2762 + t2766);\n  Y[(a4552 + 2097153)] = (t2763 + t2767);\n  Y[(a4552 + 18874368)] = (t2762 - t2766);\n  Y[(a4552 + 18874369)] = (t2763 - t2767);\n  Y[(a4552 + 10485760)] = (t2764 + t2769);\n  Y[(a4552 + 10485761)] = (t2765 - t2768);\n  Y[(a4552 + 27262976)] = (t2764 - t2769);\n  Y[(a4552 + 27262977)] = (t2765 + t2768);\n  t2770 = (t2708 + t2739);\n  t2771 = (t2709 - t2738);\n  t2772 = (t2708 - t2739);\n  t2773 = (t2709 + t2738);\n  t2774 = (s1490 + s1532);\n  t2775 = (s1491 - s1533);\n  t2776 = (s1490 - s1532);\n  t2777 = (s1491 + s1533);\n  Y[(a4552 + 4194304)] = (t2770 + t2774);\n  Y[(a4552 + 4194305)] = (t2771 + t2775);\n  Y[(a4552 + 20971520)] = (t2770 - t2774);\n  Y[(a4552 + 20971521)] = (t2771 - t2775);\n  Y[(a4552 + 12582912)] = (t2772 + t2777);\n  Y[(a4552 + 12582913)] = (t2773 - t2776);\n  Y[(a4552 + 29360128)] = (t2772 - t2777);\n  Y[(a4552 + 29360129)] = (t2773 + t2776);\n  t2778 = (t2712 + s1514);\n  t2779 = (t2713 - s1515);\n  t2780 = (t2712 - s1514);\n  t2781 = (t2713 + s1515);\n  t2782 = (s1494 - s1536);\n  t2783 = (s1495 + s1537);\n  t2784 = (s1494 + s1536);\n  t2785 = (s1495 - s1537);\n  Y[(a4552 + 6291456)] = (t2778 + t2782);\n  Y[(a4552 + 6291457)] = (t2779 + t2783);\n  Y[(a4552 + 23068672)] = (t2778 - t2782);\n  Y[(a4552 + 23068673)] = (t2779 - t2783);\n  Y[(a4552 + 14680064)] = (t2780 + t2785);\n  Y[(a4552 + 14680065)] = (t2781 - t2784);\n  Y[(a4552 + 31457280)] = (t2780 - t2785);\n  Y[(a4552 + 31457281)] = (t2781 + t2784);\n  __syncthreads();\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 256*256*256*2;\n  size_t dat_size = n * sizeof(double);\n  size_t tmp_size = 33554432 * sizeof(double);\n\n  std::mt19937 engine(n);\n  std::uniform_real_distribution<double> dist(0.0, 1.0);\n  double *x = (double*) malloc (dat_size);\n  for (int i = 0; i < n; i++) x[i] = dist(engine);\n\n  double *y = (double*) malloc (dat_size);\n\n  double *Y,  *X;\n\n  cudaMalloc((void**)&X, dat_size);\n  cudaMemcpy(X, x, dat_size, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&Y, dat_size);\n\n  double *P1, *P2;\n  cudaMalloc((void**)&P1, tmp_size);\n\n  cudaMalloc((void**)&P2, tmp_size);\n\n  dim3 b1(64), b2(64), b3(64);\n  dim3 g1(16384), g2(16384), g3(16384);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ker_zmddft_fwd_256x256x256_cu0<<<g1, b1>>>(X, P1);\n    ker_zmddft_fwd_256x256x256_cu1<<<g2, b2>>>(P1, P2);\n    ker_zmddft_fwd_256x256x256_cu2<<<g3, b3>>>(P2, Y);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %.3f (ms)\\n\", time * 1e-6f / repeat);\n\n  cudaMemcpy(y, Y, dat_size, cudaMemcpyDeviceToHost);\n\n  double checksum = 0;\n  for (int i = 0; i < n; i++) checksum += y[i];\n  printf(\"checksum = %lf\\n\", checksum);\n\n  cudaFree(X);\n  cudaFree(Y);\n  cudaFree(P1);\n  cudaFree(P2);\n  free(x);\n  free(y);\n\n  return 0;\n}\n"}}
{"kernel_name": "zmddft", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <hip/hip_runtime.h>\n#include <chrono>\n#include <random>\n\n__device__ const double D3[512] = {\n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 0.98078528040323043, (-0.19509032201612825), \n  0.99518472667219693, (-0.098017140329560604), 0.95694033573220882, (-0.29028467725446233), \n  0.99969881869620425, (-0.024541228522912288), 0.97570213003852857, (-0.2191012401568698), \n  0.99247953459870997, (-0.1224106751992162), 0.94952818059303667, (-0.31368174039889152), \n  0.99879545620517241, (-0.049067674327418015), 0.97003125319454397, (-0.24298017990326387), \n  0.98917650996478101, (-0.14673047445536175), 0.94154406518302081, (-0.33688985339222005), \n  0.99729045667869021, (-0.073564563599667426), 0.96377606579543984, (-0.26671275747489837), \n  0.98527764238894122, (-0.17096188876030122), 0.93299279883473896, (-0.35989503653498811), \n  1.0, 0.0, 0.92387953251128674, (-0.38268343236508978), \n  0.98078528040323043, (-0.19509032201612825), 0.83146961230254524, (-0.55557023301960218), \n  0.99879545620517241, (-0.049067674327418015), 0.90398929312344334, (-0.42755509343028208), \n  0.97003125319454397, (-0.24298017990326387), 0.80320753148064494, (-0.59569930449243336), \n  0.99518472667219693, (-0.098017140329560604), 0.88192126434835505, (-0.47139673682599764), \n  0.95694033573220882, (-0.29028467725446233), 0.77301045336273699, (-0.63439328416364549), \n  0.98917650996478101, (-0.14673047445536175), 0.85772861000027212, (-0.51410274419322166), \n  0.94154406518302081, (-0.33688985339222005), 0.74095112535495922, (-0.67155895484701833), \n  1.0, 0.0, 0.83146961230254524, (-0.55557023301960218), \n  0.95694033573220882, (-0.29028467725446233), 0.63439328416364549, (-0.77301045336273699), \n  0.99729045667869021, (-0.073564563599667426), 0.78834642762660623, (-0.61523159058062682), \n  0.93299279883473896, (-0.35989503653498811), 0.57580819141784534, (-0.81758481315158371), \n  0.98917650996478101, (-0.14673047445536175), 0.74095112535495922, (-0.67155895484701833), \n  0.90398929312344334, (-0.42755509343028208), 0.51410274419322166, (-0.85772861000027212), \n  0.97570213003852857, (-0.2191012401568698), 0.68954054473706683, (-0.724247082951467), \n  0.87008699110871146, (-0.49289819222978404), 0.44961132965460654, (-0.89322430119551532), \n  1.0, 0.0, 0.70710678118654757, (-0.70710678118654757), \n  0.92387953251128674, (-0.38268343236508978), 0.38268343236508978, (-0.92387953251128674), \n  0.99518472667219693, (-0.098017140329560604), 0.63439328416364549, (-0.77301045336273699), \n  0.88192126434835505, (-0.47139673682599764), 0.29028467725446233, (-0.95694033573220882), \n  0.98078528040323043, (-0.19509032201612825), 0.55557023301960218, (-0.83146961230254524), \n  0.83146961230254524, (-0.55557023301960218), 0.19509032201612825, (-0.98078528040323043), \n  0.95694033573220882, (-0.29028467725446233), 0.47139673682599764, (-0.88192126434835505), \n  0.77301045336273699, (-0.63439328416364549), 0.098017140329560604, (-0.99518472667219693), \n  1.0, 0.0, 0.55557023301960218, (-0.83146961230254524), \n  0.88192126434835505, (-0.47139673682599764), 0.098017140329560604, (-0.99518472667219693), \n  0.99247953459870997, (-0.1224106751992162), 0.44961132965460654, (-0.89322430119551532), \n  0.81758481315158371, (-0.57580819141784534), (-0.024541228522912288), (-0.99969881869620425), \n  0.97003125319454397, (-0.24298017990326387), 0.33688985339222005, (-0.94154406518302081), \n  0.74095112535495922, (-0.67155895484701833), (-0.14673047445536175), (-0.98917650996478101), \n  0.93299279883473896, (-0.35989503653498811), 0.2191012401568698, (-0.97570213003852857), \n  0.65317284295377676, (-0.75720884650648457), (-0.26671275747489837), (-0.96377606579543984), \n  1.0, 0.0, 0.38268343236508978, (-0.92387953251128674), \n  0.83146961230254524, (-0.55557023301960218), (-0.19509032201612825), (-0.98078528040323043), \n  0.98917650996478101, (-0.14673047445536175), 0.24298017990326387, (-0.97003125319454397), \n  0.74095112535495922, (-0.67155895484701833), (-0.33688985339222005), (-0.94154406518302081), \n  0.95694033573220882, (-0.29028467725446233), 0.098017140329560604, (-0.99518472667219693), \n  0.63439328416364549, (-0.77301045336273699), (-0.47139673682599764), (-0.88192126434835505), \n  0.90398929312344334, (-0.42755509343028208), (-0.049067674327418015), (-0.99879545620517241), \n  0.51410274419322166, (-0.85772861000027212), (-0.59569930449243336), (-0.80320753148064494), \n  1.0, 0.0, 0.19509032201612825, (-0.98078528040323043), \n  0.77301045336273699, (-0.63439328416364549), (-0.47139673682599764), (-0.88192126434835505), \n  0.98527764238894122, (-0.17096188876030122), 0.024541228522912288, (-0.99969881869620425), \n  0.65317284295377676, (-0.75720884650648457), (-0.61523159058062682), (-0.78834642762660623), \n  0.94154406518302081, (-0.33688985339222005), (-0.14673047445536175), (-0.98917650996478101), \n  0.51410274419322166, (-0.85772861000027212), (-0.74095112535495922), (-0.67155895484701833), \n  0.87008699110871146, (-0.49289819222978404), (-0.31368174039889152), (-0.94952818059303667), \n  0.35989503653498811, (-0.93299279883473896), (-0.84485356524970712), (-0.53499761988709715), \n  1.0, 0.0, 0.0, (-1.0), \n  0.70710678118654757, (-0.70710678118654757), (-0.70710678118654757), (-0.70710678118654757), \n  0.98078528040323043, (-0.19509032201612825), (-0.19509032201612825), (-0.98078528040323043), \n  0.55557023301960218, (-0.83146961230254524), (-0.83146961230254524), (-0.55557023301960218), \n  0.92387953251128674, (-0.38268343236508978), (-0.38268343236508978), (-0.92387953251128674), \n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), (-0.38268343236508978), \n  0.83146961230254524, (-0.55557023301960218), (-0.55557023301960218), (-0.83146961230254524), \n  0.19509032201612825, (-0.98078528040323043), (-0.98078528040323043), (-0.19509032201612825), \n  1.0, 0.0, (-0.19509032201612825), (-0.98078528040323043), \n  0.63439328416364549, (-0.77301045336273699), (-0.88192126434835505), (-0.47139673682599764), \n  0.97570213003852857, (-0.2191012401568698), (-0.40524131400498986), (-0.91420975570353069), \n  0.44961132965460654, (-0.89322430119551532), (-0.96377606579543984), (-0.26671275747489837), \n  0.90398929312344334, (-0.42755509343028208), (-0.59569930449243336), (-0.80320753148064494), \n  0.24298017990326387, (-0.97003125319454397), (-0.99879545620517241), (-0.049067674327418015), \n  0.78834642762660623, (-0.61523159058062682), (-0.75720884650648457), (-0.65317284295377676), \n  0.024541228522912288, (-0.99969881869620425), (-0.98527764238894122), 0.17096188876030122, \n  1.0, 0.0, (-0.38268343236508978), (-0.92387953251128674), \n  0.55557023301960218, (-0.83146961230254524), (-0.98078528040323043), (-0.19509032201612825), \n  0.97003125319454397, (-0.24298017990326387), (-0.59569930449243336), (-0.80320753148064494), \n  0.33688985339222005, (-0.94154406518302081), (-0.99879545620517241), 0.049067674327418015, \n  0.88192126434835505, (-0.47139673682599764), (-0.77301045336273699), (-0.63439328416364549), \n  0.098017140329560604, (-0.99518472667219693), (-0.95694033573220882), 0.29028467725446233, \n  0.74095112535495922, (-0.67155895484701833), (-0.90398929312344334), (-0.42755509343028208), \n  (-0.14673047445536175), (-0.98917650996478101), (-0.85772861000027212), 0.51410274419322166, \n  1.0, 0.0, (-0.55557023301960218), (-0.83146961230254524), \n  0.47139673682599764, (-0.88192126434835505), (-0.99518472667219693), 0.098017140329560604, \n  0.96377606579543984, (-0.26671275747489837), (-0.75720884650648457), (-0.65317284295377676), \n  0.2191012401568698, (-0.97570213003852857), (-0.93299279883473896), 0.35989503653498811, \n  0.85772861000027212, (-0.51410274419322166), (-0.90398929312344334), (-0.42755509343028208), \n  (-0.049067674327418015), (-0.99879545620517241), (-0.80320753148064494), 0.59569930449243336, \n  0.68954054473706683, (-0.724247082951467), (-0.98527764238894122), (-0.17096188876030122), \n  (-0.31368174039889152), (-0.94952818059303667), (-0.61523159058062682), 0.78834642762660623, \n  1.0, 0.0, (-0.70710678118654757), (-0.70710678118654757), \n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), 0.38268343236508978, \n  0.95694033573220882, (-0.29028467725446233), (-0.88192126434835505), (-0.47139673682599764), \n  0.098017140329560604, (-0.99518472667219693), (-0.77301045336273699), 0.63439328416364549, \n  0.83146961230254524, (-0.55557023301960218), (-0.98078528040323043), (-0.19509032201612825), \n  (-0.19509032201612825), (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524, \n  0.63439328416364549, (-0.77301045336273699), (-0.99518472667219693), 0.098017140329560604, \n  (-0.47139673682599764), (-0.88192126434835505), (-0.29028467725446233), 0.95694033573220882, \n  1.0, 0.0, (-0.83146961230254524), (-0.55557023301960218), \n  0.29028467725446233, (-0.95694033573220882), (-0.77301045336273699), 0.63439328416364549, \n  0.94952818059303667, (-0.31368174039889152), (-0.96377606579543984), (-0.26671275747489837), \n  (-0.024541228522912288), (-0.99969881869620425), (-0.53499761988709715), 0.84485356524970712, \n  0.80320753148064494, (-0.59569930449243336), (-0.99879545620517241), 0.049067674327418015, \n  (-0.33688985339222005), (-0.94154406518302081), (-0.24298017990326387), 0.97003125319454397, \n  0.57580819141784534, (-0.81758481315158371), (-0.93299279883473896), 0.35989503653498811, \n  (-0.61523159058062682), (-0.78834642762660623), 0.073564563599667426, 0.99729045667869021, \n  1.0, 0.0, (-0.92387953251128674), (-0.38268343236508978), \n  0.19509032201612825, (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524, \n  0.94154406518302081, (-0.33688985339222005), (-0.99879545620517241), (-0.049067674327418015), \n  (-0.14673047445536175), (-0.98917650996478101), (-0.24298017990326387), 0.97003125319454397, \n  0.77301045336273699, (-0.63439328416364549), (-0.95694033573220882), 0.29028467725446233, \n  (-0.47139673682599764), (-0.88192126434835505), 0.098017140329560604, 0.99518472667219693, \n  0.51410274419322166, (-0.85772861000027212), (-0.80320753148064494), 0.59569930449243336, \n  (-0.74095112535495922), (-0.67155895484701833), 0.42755509343028208, 0.90398929312344334, \n  1.0, 0.0, (-0.98078528040323043), (-0.19509032201612825), \n  0.098017140329560604, (-0.99518472667219693), (-0.29028467725446233), 0.95694033573220882, \n  0.93299279883473896, (-0.35989503653498811), (-0.98527764238894122), 0.17096188876030122, \n  (-0.26671275747489837), (-0.96377606579543984), 0.073564563599667426, 0.99729045667869021, \n  0.74095112535495922, (-0.67155895484701833), (-0.85772861000027212), 0.51410274419322166, \n  (-0.59569930449243336), (-0.80320753148064494), 0.42755509343028208, 0.90398929312344334, \n  0.44961132965460654, (-0.89322430119551532), (-0.61523159058062682), 0.78834642762660623, \n  (-0.84485356524970712), (-0.53499761988709715), 0.724247082951467, 0.68954054473706683};\n\n__global__\nvoid ker_zmddft_fwd_256x256x256_cu0(const double *X, double *P1)\n{\n  __shared__ double T3[2048];\n  double a495, a496, a497, a498, a499, a500, a501, a502, \n         s145, s146, s147, s148, s149, s150, s151, s152, \n         s153, s154, s155, s156, s157, s158, s159, s160, \n         s161, s162, s163, s164, s165, s166, s167, s168, \n         s169, s170, s171, s172, s173, s174, s175, s176, \n         s177, s178, s179, s180, s181, s182, s183, s184, \n         s185, s186, s187, s188, s189, s190, s191, s192, \n         t538, t539, t540, t541, t542, t543, t544, t545, \n         t546, t547, t548, t549, t550, t551, t552, t553, \n         t554, t555, t556, t557, t558, t559, t560, t561, \n         t562, t563, t564, t565, t566, t567, t568, t569, \n         t570, t571, t572, t573, t574, t575, t576, t577, \n         t578, t579, t580, t581, t582, t583, t584, t585, \n         t586, t587, t588, t589, t590, t591, t592, t593, \n         t594, t595, t596, t597, t598, t599, t600, t601, \n         t602, t603, t604, t605, t606, t607, t608, t609, \n         t610, t611, t612, t613, t614, t615, t616, t617, \n         t618, t619, t620, t621, t622, t623, t624, t625;\n  int a492, a493, a494, a503;\n  a492 = (512*(threadIdx.x / 16));\n  a493 = (threadIdx.x % 16);\n  a494 = ((2048*blockIdx.x) + a492 + (2*a493));\n  s145 = X[a494];\n  s146 = X[(a494 + 1)];\n  s147 = X[(a494 + 256)];\n  s148 = X[(a494 + 257)];\n  t538 = (s145 + s147);\n  t539 = (s146 + s148);\n  t540 = (s145 - s147);\n  t541 = (s146 - s148);\n  s149 = X[(a494 + 128)];\n  s150 = X[(a494 + 129)];\n  s151 = X[(a494 + 384)];\n  s152 = X[(a494 + 385)];\n  t542 = (s149 + s151);\n  t543 = (s150 + s152);\n  t544 = (s149 - s151);\n  t545 = (s150 - s152);\n  t546 = (t538 + t542);\n  t547 = (t539 + t543);\n  t548 = (t538 - t542);\n  t549 = (t539 - t543);\n  t550 = (t540 + t545);\n  t551 = (t541 - t544);\n  t552 = (t540 - t545);\n  t553 = (t541 + t544);\n  s153 = X[(a494 + 32)];\n  s154 = X[(a494 + 33)];\n  s155 = X[(a494 + 288)];\n  s156 = X[(a494 + 289)];\n  t554 = (s153 + s155);\n  t555 = (s154 + s156);\n  t556 = (s153 - s155);\n  t557 = (s154 - s156);\n  s157 = X[(a494 + 160)];\n  s158 = X[(a494 + 161)];\n  s159 = X[(a494 + 416)];\n  s160 = X[(a494 + 417)];\n  t558 = (s157 + s159);\n  t559 = (s158 + s160);\n  t560 = (s157 - s159);\n  t561 = (s158 - s160);\n  t562 = (t554 + t558);\n  t563 = (t555 + t559);\n  a495 = (0.70710678118654757*(t554 - t558));\n  a496 = (0.70710678118654757*(t555 - t559));\n  s161 = (a495 + a496);\n  s162 = (a496 - a495);\n  t564 = (t556 + t561);\n  t565 = (t557 - t560);\n  t566 = (t556 - t561);\n  t567 = (t557 + t560);\n  s163 = ((0.92387953251128674*t564) + (0.38268343236508978*t565));\n  s164 = ((0.92387953251128674*t565) - (0.38268343236508978*t564));\n  s165 = ((0.38268343236508978*t566) + (0.92387953251128674*t567));\n  s166 = ((0.38268343236508978*t567) - (0.92387953251128674*t566));\n  s167 = X[(a494 + 64)];\n  s168 = X[(a494 + 65)];\n  s169 = X[(a494 + 320)];\n  s170 = X[(a494 + 321)];\n  t568 = (s167 + s169);\n  t569 = (s168 + s170);\n  t570 = (s167 - s169);\n  t571 = (s168 - s170);\n  s171 = X[(a494 + 192)];\n  s172 = X[(a494 + 193)];\n  s173 = X[(a494 + 448)];\n  s174 = X[(a494 + 449)];\n  t572 = (s171 + s173);\n  t573 = (s172 + s174);\n  t574 = (s171 - s173);\n  t575 = (s172 - s174);\n  t576 = (t568 + t572);\n  t577 = (t569 + t573);\n  t578 = (t568 - t572);\n  t579 = (t569 - t573);\n  a497 = (0.70710678118654757*(t570 + t575));\n  a498 = (0.70710678118654757*(t571 - t574));\n  s175 = (a497 + a498);\n  s176 = (a498 - a497);\n  a499 = (0.70710678118654757*(t571 + t574));\n  a500 = (0.70710678118654757*(t570 - t575));\n  s177 = (a499 - a500);\n  s178 = (a500 + a499);\n  s179 = X[(a494 + 96)];\n  s180 = X[(a494 + 97)];\n  s181 = X[(a494 + 352)];\n  s182 = X[(a494 + 353)];\n  t580 = (s179 + s181);\n  t581 = (s180 + s182);\n  t582 = (s179 - s181);\n  t583 = (s180 - s182);\n  s183 = X[(a494 + 224)];\n  s184 = X[(a494 + 225)];\n  s185 = X[(a494 + 480)];\n  s186 = X[(a494 + 481)];\n  t584 = (s183 + s185);\n  t585 = (s184 + s186);\n  t586 = (s183 - s185);\n  t587 = (s184 - s186);\n  t588 = (t580 + t584);\n  t589 = (t581 + t585);\n  a501 = (0.70710678118654757*(t581 - t585));\n  a502 = (0.70710678118654757*(t580 - t584));\n  s187 = (a501 - a502);\n  s188 = (a502 + a501);\n  t590 = (t582 + t587);\n  t591 = (t583 - t586);\n  t592 = (t582 - t587);\n  t593 = (t583 + t586);\n  s189 = ((0.38268343236508978*t590) + (0.92387953251128674*t591));\n  s190 = ((0.38268343236508978*t591) - (0.92387953251128674*t590));\n  s191 = ((0.92387953251128674*t592) + (0.38268343236508978*t593));\n  s192 = ((0.38268343236508978*t592) - (0.92387953251128674*t593));\n  t594 = (t546 + t576);\n  t595 = (t547 + t577);\n  t596 = (t546 - t576);\n  t597 = (t547 - t577);\n  t598 = (t562 + t588);\n  t599 = (t563 + t589);\n  t600 = (t562 - t588);\n  t601 = (t563 - t589);\n  a503 = (a492 + (32*a493));\n  T3[a503] = (t594 + t598);\n  T3[(a503 + 1)] = (t595 + t599);\n  T3[(a503 + 16)] = (t594 - t598);\n  T3[(a503 + 17)] = (t595 - t599);\n  T3[(a503 + 8)] = (t596 + t601);\n  T3[(a503 + 9)] = (t597 - t600);\n  T3[(a503 + 24)] = (t596 - t601);\n  T3[(a503 + 25)] = (t597 + t600);\n  t602 = (t550 + s175);\n  t603 = (t551 + s176);\n  t604 = (t550 - s175);\n  t605 = (t551 - s176);\n  t606 = (s163 + s189);\n  t607 = (s164 + s190);\n  t608 = (s163 - s189);\n  t609 = (s164 - s190);\n  T3[(a503 + 2)] = (t602 + t606);\n  T3[(a503 + 3)] = (t603 + t607);\n  T3[(a503 + 18)] = (t602 - t606);\n  T3[(a503 + 19)] = (t603 - t607);\n  T3[(a503 + 10)] = (t604 + t609);\n  T3[(a503 + 11)] = (t605 - t608);\n  T3[(a503 + 26)] = (t604 - t609);\n  T3[(a503 + 27)] = (t605 + t608);\n  t610 = (t548 + t579);\n  t611 = (t549 - t578);\n  t612 = (t548 - t579);\n  t613 = (t549 + t578);\n  t614 = (s161 + s187);\n  t615 = (s162 - s188);\n  t616 = (s161 - s187);\n  t617 = (s162 + s188);\n  T3[(a503 + 4)] = (t610 + t614);\n  T3[(a503 + 5)] = (t611 + t615);\n  T3[(a503 + 20)] = (t610 - t614);\n  T3[(a503 + 21)] = (t611 - t615);\n  T3[(a503 + 12)] = (t612 + t617);\n  T3[(a503 + 13)] = (t613 - t616);\n  T3[(a503 + 28)] = (t612 - t617);\n  T3[(a503 + 29)] = (t613 + t616);\n  t618 = (t552 + s177);\n  t619 = (t553 - s178);\n  t620 = (t552 - s177);\n  t621 = (t553 + s178);\n  t622 = (s165 - s191);\n  t623 = (s166 + s192);\n  t624 = (s165 + s191);\n  t625 = (s166 - s192);\n  T3[(a503 + 6)] = (t618 + t622);\n  T3[(a503 + 7)] = (t619 + t623);\n  T3[(a503 + 22)] = (t618 - t622);\n  T3[(a503 + 23)] = (t619 - t623);\n  T3[(a503 + 14)] = (t620 + t625);\n  T3[(a503 + 15)] = (t621 - t624);\n  T3[(a503 + 30)] = (t620 - t625);\n  T3[(a503 + 31)] = (t621 + t624);\n  __syncthreads();\n  double a1478, a1479, a1480, a1481, a1482, a1483, a1484, a1485, \n         a1486, a1487, a1488, a1489, a1490, a1491, a1492, a1493, \n         a1494, a1495, a1496, a1497, a1498, a1499, a1500, a1501, \n         a1502, a1503, a1504, a1505, a1506, a1507, a1508, a1509, \n         a1510, a1511, a1512, a1513, a1514, a1515, a1516, a1517, \n         s434, s435, s436, s437, s438, s439, s440, s441, \n         s442, s443, s444, s445, s446, s447, s448, s449, \n         s450, s451, s452, s453, s454, s455, s456, s457, \n         s458, s459, s460, s461, s462, s463, s464, s465, \n         s466, s467, s468, s469, s470, s471, s472, s473, \n         s474, s475, s476, s477, s478, s479, s480, s481, \n         s482, s483, s484, s485, s486, s487, s488, s489, \n         s490, s491, s492, s493, s494, s495, s496, s497, \n         s498, s499, s500, s501, s502, s503, s504, s505, \n         s506, s507, s508, s509, s510, s511, s512, s513, \n         t1000, t1001, t1002, t1003, t1004, t1005, t1006, t1007, \n         t1008, t1009, t1010, t1011, t1012, t1013, t1014, t1015, \n         t1016, t1017, t1018, t1019, t1020, t1021, t1022, t1023, \n         t1024, t1025, t1026, t1027, t1028, t1029, t1030, t1031, \n         t1032, t1033, t1034, t1035, t1036, t1037, t1038, t1039, \n         t1040, t1041, t1042, t1043, t1044, t1045, t1046, t1047, \n         t1048, t1049, t1050, t1051, t1052, t1053, t1054, t1055, \n         t1056, t1057, t970, t971, t972, t973, t974, t975, \n         t976, t977, t978, t979, t980, t981, t982, t983, \n         t984, t985, t986, t987, t988, t989, t990, t991, \n         t992, t993, t994, t995, t996, t997, t998, t999;\n  int a1474, a1475, a1476, a1477, a1518;\n  a1474 = (threadIdx.x / 16);\n  a1475 = (threadIdx.x % 16);\n  a1476 = ((512*a1474) + (2*a1475));\n  s434 = T3[a1476];\n  s435 = T3[(a1476 + 1)];\n  s436 = T3[(a1476 + 256)];\n  s437 = T3[(a1476 + 257)];\n  a1477 = (32*a1475);\n  a1478 = D3[a1477];\n  a1479 = D3[(a1477 + 1)];\n  s438 = ((a1478*s434) - (a1479*s435));\n  s439 = ((a1479*s434) + (a1478*s435));\n  a1480 = D3[(a1477 + 2)];\n  a1481 = D3[(a1477 + 3)];\n  s440 = ((a1480*s436) - (a1481*s437));\n  s441 = ((a1481*s436) + (a1480*s437));\n  t970 = (s438 + s440);\n  t971 = (s439 + s441);\n  t972 = (s438 - s440);\n  t973 = (s439 - s441);\n  s442 = T3[(a1476 + 128)];\n  s443 = T3[(a1476 + 129)];\n  s444 = T3[(a1476 + 384)];\n  s445 = T3[(a1476 + 385)];\n  a1482 = D3[(4 + a1477)];\n  a1483 = D3[(5 + a1477)];\n  s446 = ((a1482*s442) - (a1483*s443));\n  s447 = ((a1483*s442) + (a1482*s443));\n  a1484 = D3[(6 + a1477)];\n  a1485 = D3[(7 + a1477)];\n  s448 = ((a1484*s444) - (a1485*s445));\n  s449 = ((a1485*s444) + (a1484*s445));\n  t974 = (s446 + s448);\n  t975 = (s447 + s449);\n  t976 = (s446 - s448);\n  t977 = (s447 - s449);\n  t978 = (t970 + t974);\n  t979 = (t971 + t975);\n  t980 = (t970 - t974);\n  t981 = (t971 - t975);\n  t982 = (t972 + t977);\n  t983 = (t973 - t976);\n  t984 = (t972 - t977);\n  t985 = (t973 + t976);\n  s450 = T3[(a1476 + 32)];\n  s451 = T3[(a1476 + 33)];\n  s452 = T3[(a1476 + 288)];\n  s453 = T3[(a1476 + 289)];\n  a1486 = D3[(a1477 + 8)];\n  a1487 = D3[(9 + a1477)];\n  s454 = ((a1486*s450) - (a1487*s451));\n  s455 = ((a1487*s450) + (a1486*s451));\n  a1488 = D3[(10 + a1477)];\n  a1489 = D3[(11 + a1477)];\n  s456 = ((a1488*s452) - (a1489*s453));\n  s457 = ((a1489*s452) + (a1488*s453));\n  t986 = (s454 + s456);\n  t987 = (s455 + s457);\n  t988 = (s454 - s456);\n  t989 = (s455 - s457);\n  s458 = T3[(a1476 + 160)];\n  s459 = T3[(a1476 + 161)];\n  s460 = T3[(a1476 + 416)];\n  s461 = T3[(a1476 + 417)];\n  a1490 = D3[(12 + a1477)];\n  a1491 = D3[(13 + a1477)];\n  s462 = ((a1490*s458) - (a1491*s459));\n  s463 = ((a1491*s458) + (a1490*s459));\n  a1492 = D3[(14 + a1477)];\n  a1493 = D3[(15 + a1477)];\n  s464 = ((a1492*s460) - (a1493*s461));\n  s465 = ((a1493*s460) + (a1492*s461));\n  t990 = (s462 + s464);\n  t991 = (s463 + s465);\n  t992 = (s462 - s464);\n  t993 = (s463 - s465);\n  t994 = (t986 + t990);\n  t995 = (t987 + t991);\n  a1494 = (0.70710678118654757*(t986 - t990));\n  a1495 = (0.70710678118654757*(t987 - t991));\n  s466 = (a1494 + a1495);\n  s467 = (a1495 - a1494);\n  t996 = (t988 + t993);\n  t997 = (t989 - t992);\n  t998 = (t988 - t993);\n  t999 = (t989 + t992);\n  s468 = ((0.92387953251128674*t996) + (0.38268343236508978*t997));\n  s469 = ((0.92387953251128674*t997) - (0.38268343236508978*t996));\n  s470 = ((0.38268343236508978*t998) + (0.92387953251128674*t999));\n  s471 = ((0.38268343236508978*t999) - (0.92387953251128674*t998));\n  s472 = T3[(a1476 + 64)];\n  s473 = T3[(a1476 + 65)];\n  s474 = T3[(a1476 + 320)];\n  s475 = T3[(a1476 + 321)];\n  a1496 = D3[(a1477 + 16)];\n  a1497 = D3[(17 + a1477)];\n  s476 = ((a1496*s472) - (a1497*s473));\n  s477 = ((a1497*s472) + (a1496*s473));\n  a1498 = D3[(18 + a1477)];\n  a1499 = D3[(19 + a1477)];\n  s478 = ((a1498*s474) - (a1499*s475));\n  s479 = ((a1499*s474) + (a1498*s475));\n  t1000 = (s476 + s478);\n  t1001 = (s477 + s479);\n  t1002 = (s476 - s478);\n  t1003 = (s477 - s479);\n  s480 = T3[(a1476 + 192)];\n  s481 = T3[(a1476 + 193)];\n  s482 = T3[(a1476 + 448)];\n  s483 = T3[(a1476 + 449)];\n  a1500 = D3[(20 + a1477)];\n  a1501 = D3[(21 + a1477)];\n  s484 = ((a1500*s480) - (a1501*s481));\n  s485 = ((a1501*s480) + (a1500*s481));\n  a1502 = D3[(22 + a1477)];\n  a1503 = D3[(23 + a1477)];\n  s486 = ((a1502*s482) - (a1503*s483));\n  s487 = ((a1503*s482) + (a1502*s483));\n  t1004 = (s484 + s486);\n  t1005 = (s485 + s487);\n  t1006 = (s484 - s486);\n  t1007 = (s485 - s487);\n  t1008 = (t1000 + t1004);\n  t1009 = (t1001 + t1005);\n  t1010 = (t1000 - t1004);\n  t1011 = (t1001 - t1005);\n  a1504 = (0.70710678118654757*(t1002 + t1007));\n  a1505 = (0.70710678118654757*(t1003 - t1006));\n  s488 = (a1504 + a1505);\n  s489 = (a1505 - a1504);\n  a1506 = (0.70710678118654757*(t1003 + t1006));\n  a1507 = (0.70710678118654757*(t1002 - t1007));\n  s490 = (a1506 - a1507);\n  s491 = (a1507 + a1506);\n  s492 = T3[(a1476 + 96)];\n  s493 = T3[(a1476 + 97)];\n  s494 = T3[(a1476 + 352)];\n  s495 = T3[(a1476 + 353)];\n  a1508 = D3[(a1477 + 24)];\n  a1509 = D3[(25 + a1477)];\n  s496 = ((a1508*s492) - (a1509*s493));\n  s497 = ((a1509*s492) + (a1508*s493));\n  a1510 = D3[(26 + a1477)];\n  a1511 = D3[(27 + a1477)];\n  s498 = ((a1510*s494) - (a1511*s495));\n  s499 = ((a1511*s494) + (a1510*s495));\n  t1012 = (s496 + s498);\n  t1013 = (s497 + s499);\n  t1014 = (s496 - s498);\n  t1015 = (s497 - s499);\n  s500 = T3[(a1476 + 224)];\n  s501 = T3[(a1476 + 225)];\n  s502 = T3[(a1476 + 480)];\n  s503 = T3[(a1476 + 481)];\n  a1512 = D3[(28 + a1477)];\n  a1513 = D3[(29 + a1477)];\n  s504 = ((a1512*s500) - (a1513*s501));\n  s505 = ((a1513*s500) + (a1512*s501));\n  a1514 = D3[(30 + a1477)];\n  a1515 = D3[(31 + a1477)];\n  s506 = ((a1514*s502) - (a1515*s503));\n  s507 = ((a1515*s502) + (a1514*s503));\n  t1016 = (s504 + s506);\n  t1017 = (s505 + s507);\n  t1018 = (s504 - s506);\n  t1019 = (s505 - s507);\n  t1020 = (t1012 + t1016);\n  t1021 = (t1013 + t1017);\n  a1516 = (0.70710678118654757*(t1013 - t1017));\n  a1517 = (0.70710678118654757*(t1012 - t1016));\n  s508 = (a1516 - a1517);\n  s509 = (a1517 + a1516);\n  t1022 = (t1014 + t1019);\n  t1023 = (t1015 - t1018);\n  t1024 = (t1014 - t1019);\n  t1025 = (t1015 + t1018);\n  s510 = ((0.38268343236508978*t1022) + (0.92387953251128674*t1023));\n  s511 = ((0.38268343236508978*t1023) - (0.92387953251128674*t1022));\n  s512 = ((0.92387953251128674*t1024) + (0.38268343236508978*t1025));\n  s513 = ((0.38268343236508978*t1024) - (0.92387953251128674*t1025));\n  t1026 = (t978 + t1008);\n  t1027 = (t979 + t1009);\n  t1028 = (t978 - t1008);\n  t1029 = (t979 - t1009);\n  t1030 = (t994 + t1020);\n  t1031 = (t995 + t1021);\n  t1032 = (t994 - t1020);\n  t1033 = (t995 - t1021);\n  a1518 = ((8*blockIdx.x) + (131072*a1475) + (2*a1474));\n  P1[a1518] = (t1026 + t1030);\n  P1[(a1518 + 1)] = (t1027 + t1031);\n  P1[(a1518 + 16777216)] = (t1026 - t1030);\n  P1[(a1518 + 16777217)] = (t1027 - t1031);\n  P1[(a1518 + 8388608)] = (t1028 + t1033);\n  P1[(a1518 + 8388609)] = (t1029 - t1032);\n  P1[(a1518 + 25165824)] = (t1028 - t1033);\n  P1[(a1518 + 25165825)] = (t1029 + t1032);\n  t1034 = (t982 + s488);\n  t1035 = (t983 + s489);\n  t1036 = (t982 - s488);\n  t1037 = (t983 - s489);\n  t1038 = (s468 + s510);\n  t1039 = (s469 + s511);\n  t1040 = (s468 - s510);\n  t1041 = (s469 - s511);\n  P1[(a1518 + 2097152)] = (t1034 + t1038);\n  P1[(a1518 + 2097153)] = (t1035 + t1039);\n  P1[(a1518 + 18874368)] = (t1034 - t1038);\n  P1[(a1518 + 18874369)] = (t1035 - t1039);\n  P1[(a1518 + 10485760)] = (t1036 + t1041);\n  P1[(a1518 + 10485761)] = (t1037 - t1040);\n  P1[(a1518 + 27262976)] = (t1036 - t1041);\n  P1[(a1518 + 27262977)] = (t1037 + t1040);\n  t1042 = (t980 + t1011);\n  t1043 = (t981 - t1010);\n  t1044 = (t980 - t1011);\n  t1045 = (t981 + t1010);\n  t1046 = (s466 + s508);\n  t1047 = (s467 - s509);\n  t1048 = (s466 - s508);\n  t1049 = (s467 + s509);\n  P1[(a1518 + 4194304)] = (t1042 + t1046);\n  P1[(a1518 + 4194305)] = (t1043 + t1047);\n  P1[(a1518 + 20971520)] = (t1042 - t1046);\n  P1[(a1518 + 20971521)] = (t1043 - t1047);\n  P1[(a1518 + 12582912)] = (t1044 + t1049);\n  P1[(a1518 + 12582913)] = (t1045 - t1048);\n  P1[(a1518 + 29360128)] = (t1044 - t1049);\n  P1[(a1518 + 29360129)] = (t1045 + t1048);\n  t1050 = (t984 + s490);\n  t1051 = (t985 - s491);\n  t1052 = (t984 - s490);\n  t1053 = (t985 + s491);\n  t1054 = (s470 - s512);\n  t1055 = (s471 + s513);\n  t1056 = (s470 + s512);\n  t1057 = (s471 - s513);\n  P1[(a1518 + 6291456)] = (t1050 + t1054);\n  P1[(a1518 + 6291457)] = (t1051 + t1055);\n  P1[(a1518 + 23068672)] = (t1050 - t1054);\n  P1[(a1518 + 23068673)] = (t1051 - t1055);\n  P1[(a1518 + 14680064)] = (t1052 + t1057);\n  P1[(a1518 + 14680065)] = (t1053 - t1056);\n  P1[(a1518 + 31457280)] = (t1052 - t1057);\n  P1[(a1518 + 31457281)] = (t1053 + t1056);\n  __syncthreads();\n}\n\n__global__\nvoid ker_zmddft_fwd_256x256x256_cu1(const double *P1, double *P2)\n{\n  __shared__ double T33[2048];\n  double a2012, a2013, a2014, a2015, a2016, a2017, a2018, a2019, \n         s658, s659, s660, s661, s662, s663, s664, s665, \n         s666, s667, s668, s669, s670, s671, s672, s673, \n         s674, s675, s676, s677, s678, s679, s680, s681, \n         s682, s683, s684, s685, s686, s687, s688, s689, \n         s690, s691, s692, s693, s694, s695, s696, s697, \n         s698, s699, s700, s701, s702, s703, s704, s705, \n         t1402, t1403, t1404, t1405, t1406, t1407, t1408, t1409, \n         t1410, t1411, t1412, t1413, t1414, t1415, t1416, t1417, \n         t1418, t1419, t1420, t1421, t1422, t1423, t1424, t1425, \n         t1426, t1427, t1428, t1429, t1430, t1431, t1432, t1433, \n         t1434, t1435, t1436, t1437, t1438, t1439, t1440, t1441, \n         t1442, t1443, t1444, t1445, t1446, t1447, t1448, t1449, \n         t1450, t1451, t1452, t1453, t1454, t1455, t1456, t1457, \n         t1458, t1459, t1460, t1461, t1462, t1463, t1464, t1465, \n         t1466, t1467, t1468, t1469, t1470, t1471, t1472, t1473, \n         t1474, t1475, t1476, t1477, t1478, t1479, t1480, t1481, \n         t1482, t1483, t1484, t1485, t1486, t1487, t1488, t1489;\n  int a2009, a2010, a2011, a2020;\n  a2009 = (512*(threadIdx.x / 16));\n  a2010 = (threadIdx.x % 16);\n  a2011 = ((2048*blockIdx.x) + a2009 + (2*a2010));\n  s658 = P1[a2011];\n  s659 = P1[(a2011 + 1)];\n  s660 = P1[(a2011 + 256)];\n  s661 = P1[(a2011 + 257)];\n  t1402 = (s658 + s660);\n  t1403 = (s659 + s661);\n  t1404 = (s658 - s660);\n  t1405 = (s659 - s661);\n  s662 = P1[(a2011 + 128)];\n  s663 = P1[(a2011 + 129)];\n  s664 = P1[(a2011 + 384)];\n  s665 = P1[(a2011 + 385)];\n  t1406 = (s662 + s664);\n  t1407 = (s663 + s665);\n  t1408 = (s662 - s664);\n  t1409 = (s663 - s665);\n  t1410 = (t1402 + t1406);\n  t1411 = (t1403 + t1407);\n  t1412 = (t1402 - t1406);\n  t1413 = (t1403 - t1407);\n  t1414 = (t1404 + t1409);\n  t1415 = (t1405 - t1408);\n  t1416 = (t1404 - t1409);\n  t1417 = (t1405 + t1408);\n  s666 = P1[(a2011 + 32)];\n  s667 = P1[(a2011 + 33)];\n  s668 = P1[(a2011 + 288)];\n  s669 = P1[(a2011 + 289)];\n  t1418 = (s666 + s668);\n  t1419 = (s667 + s669);\n  t1420 = (s666 - s668);\n  t1421 = (s667 - s669);\n  s670 = P1[(a2011 + 160)];\n  s671 = P1[(a2011 + 161)];\n  s672 = P1[(a2011 + 416)];\n  s673 = P1[(a2011 + 417)];\n  t1422 = (s670 + s672);\n  t1423 = (s671 + s673);\n  t1424 = (s670 - s672);\n  t1425 = (s671 - s673);\n  t1426 = (t1418 + t1422);\n  t1427 = (t1419 + t1423);\n  a2012 = (0.70710678118654757*(t1418 - t1422));\n  a2013 = (0.70710678118654757*(t1419 - t1423));\n  s674 = (a2012 + a2013);\n  s675 = (a2013 - a2012);\n  t1428 = (t1420 + t1425);\n  t1429 = (t1421 - t1424);\n  t1430 = (t1420 - t1425);\n  t1431 = (t1421 + t1424);\n  s676 = ((0.92387953251128674*t1428) + (0.38268343236508978*t1429));\n  s677 = ((0.92387953251128674*t1429) - (0.38268343236508978*t1428));\n  s678 = ((0.38268343236508978*t1430) + (0.92387953251128674*t1431));\n  s679 = ((0.38268343236508978*t1431) - (0.92387953251128674*t1430));\n  s680 = P1[(a2011 + 64)];\n  s681 = P1[(a2011 + 65)];\n  s682 = P1[(a2011 + 320)];\n  s683 = P1[(a2011 + 321)];\n  t1432 = (s680 + s682);\n  t1433 = (s681 + s683);\n  t1434 = (s680 - s682);\n  t1435 = (s681 - s683);\n  s684 = P1[(a2011 + 192)];\n  s685 = P1[(a2011 + 193)];\n  s686 = P1[(a2011 + 448)];\n  s687 = P1[(a2011 + 449)];\n  t1436 = (s684 + s686);\n  t1437 = (s685 + s687);\n  t1438 = (s684 - s686);\n  t1439 = (s685 - s687);\n  t1440 = (t1432 + t1436);\n  t1441 = (t1433 + t1437);\n  t1442 = (t1432 - t1436);\n  t1443 = (t1433 - t1437);\n  a2014 = (0.70710678118654757*(t1434 + t1439));\n  a2015 = (0.70710678118654757*(t1435 - t1438));\n  s688 = (a2014 + a2015);\n  s689 = (a2015 - a2014);\n  a2016 = (0.70710678118654757*(t1435 + t1438));\n  a2017 = (0.70710678118654757*(t1434 - t1439));\n  s690 = (a2016 - a2017);\n  s691 = (a2017 + a2016);\n  s692 = P1[(a2011 + 96)];\n  s693 = P1[(a2011 + 97)];\n  s694 = P1[(a2011 + 352)];\n  s695 = P1[(a2011 + 353)];\n  t1444 = (s692 + s694);\n  t1445 = (s693 + s695);\n  t1446 = (s692 - s694);\n  t1447 = (s693 - s695);\n  s696 = P1[(a2011 + 224)];\n  s697 = P1[(a2011 + 225)];\n  s698 = P1[(a2011 + 480)];\n  s699 = P1[(a2011 + 481)];\n  t1448 = (s696 + s698);\n  t1449 = (s697 + s699);\n  t1450 = (s696 - s698);\n  t1451 = (s697 - s699);\n  t1452 = (t1444 + t1448);\n  t1453 = (t1445 + t1449);\n  a2018 = (0.70710678118654757*(t1445 - t1449));\n  a2019 = (0.70710678118654757*(t1444 - t1448));\n  s700 = (a2018 - a2019);\n  s701 = (a2019 + a2018);\n  t1454 = (t1446 + t1451);\n  t1455 = (t1447 - t1450);\n  t1456 = (t1446 - t1451);\n  t1457 = (t1447 + t1450);\n  s702 = ((0.38268343236508978*t1454) + (0.92387953251128674*t1455));\n  s703 = ((0.38268343236508978*t1455) - (0.92387953251128674*t1454));\n  s704 = ((0.92387953251128674*t1456) + (0.38268343236508978*t1457));\n  s705 = ((0.38268343236508978*t1456) - (0.92387953251128674*t1457));\n  t1458 = (t1410 + t1440);\n  t1459 = (t1411 + t1441);\n  t1460 = (t1410 - t1440);\n  t1461 = (t1411 - t1441);\n  t1462 = (t1426 + t1452);\n  t1463 = (t1427 + t1453);\n  t1464 = (t1426 - t1452);\n  t1465 = (t1427 - t1453);\n  a2020 = (a2009 + (32*a2010));\n  T33[a2020] = (t1458 + t1462);\n  T33[(a2020 + 1)] = (t1459 + t1463);\n  T33[(a2020 + 16)] = (t1458 - t1462);\n  T33[(a2020 + 17)] = (t1459 - t1463);\n  T33[(a2020 + 8)] = (t1460 + t1465);\n  T33[(a2020 + 9)] = (t1461 - t1464);\n  T33[(a2020 + 24)] = (t1460 - t1465);\n  T33[(a2020 + 25)] = (t1461 + t1464);\n  t1466 = (t1414 + s688);\n  t1467 = (t1415 + s689);\n  t1468 = (t1414 - s688);\n  t1469 = (t1415 - s689);\n  t1470 = (s676 + s702);\n  t1471 = (s677 + s703);\n  t1472 = (s676 - s702);\n  t1473 = (s677 - s703);\n  T33[(a2020 + 2)] = (t1466 + t1470);\n  T33[(a2020 + 3)] = (t1467 + t1471);\n  T33[(a2020 + 18)] = (t1466 - t1470);\n  T33[(a2020 + 19)] = (t1467 - t1471);\n  T33[(a2020 + 10)] = (t1468 + t1473);\n  T33[(a2020 + 11)] = (t1469 - t1472);\n  T33[(a2020 + 26)] = (t1468 - t1473);\n  T33[(a2020 + 27)] = (t1469 + t1472);\n  t1474 = (t1412 + t1443);\n  t1475 = (t1413 - t1442);\n  t1476 = (t1412 - t1443);\n  t1477 = (t1413 + t1442);\n  t1478 = (s674 + s700);\n  t1479 = (s675 - s701);\n  t1480 = (s674 - s700);\n  t1481 = (s675 + s701);\n  T33[(a2020 + 4)] = (t1474 + t1478);\n  T33[(a2020 + 5)] = (t1475 + t1479);\n  T33[(a2020 + 20)] = (t1474 - t1478);\n  T33[(a2020 + 21)] = (t1475 - t1479);\n  T33[(a2020 + 12)] = (t1476 + t1481);\n  T33[(a2020 + 13)] = (t1477 - t1480);\n  T33[(a2020 + 28)] = (t1476 - t1481);\n  T33[(a2020 + 29)] = (t1477 + t1480);\n  t1482 = (t1416 + s690);\n  t1483 = (t1417 - s691);\n  t1484 = (t1416 - s690);\n  t1485 = (t1417 + s691);\n  t1486 = (s678 - s704);\n  t1487 = (s679 + s705);\n  t1488 = (s678 + s704);\n  t1489 = (s679 - s705);\n  T33[(a2020 + 6)] = (t1482 + t1486);\n  T33[(a2020 + 7)] = (t1483 + t1487);\n  T33[(a2020 + 22)] = (t1482 - t1486);\n  T33[(a2020 + 23)] = (t1483 - t1487);\n  T33[(a2020 + 14)] = (t1484 + t1489);\n  T33[(a2020 + 15)] = (t1485 - t1488);\n  T33[(a2020 + 30)] = (t1484 - t1489);\n  T33[(a2020 + 31)] = (t1485 + t1488);\n  __syncthreads();\n  double a2995, a2996, a2997, a2998, a2999, a3000, a3001, a3002, \n         a3003, a3004, a3005, a3006, a3007, a3008, a3009, a3010, \n         a3011, a3012, a3013, a3014, a3015, a3016, a3017, a3018, \n         a3019, a3020, a3021, a3022, a3023, a3024, a3025, a3026, \n         a3027, a3028, a3029, a3030, a3031, a3032, a3033, a3034, \n         s1000, s1001, s1002, s1003, s1004, s1005, s1006, s1007, \n         s1008, s1009, s1010, s1011, s1012, s1013, s1014, s1015, \n         s1016, s1017, s1018, s1019, s1020, s1021, s1022, s1023, \n         s1024, s1025, s946, s947, s948, s949, s950, s951, \n         s952, s953, s954, s955, s956, s957, s958, s959, \n         s960, s961, s962, s963, s964, s965, s966, s967, \n         s968, s969, s970, s971, s972, s973, s974, s975, \n         s976, s977, s978, s979, s980, s981, s982, s983, \n         s984, s985, s986, s987, s988, s989, s990, s991, \n         s992, s993, s994, s995, s996, s997, s998, s999, \n         t1834, t1835, t1836, t1837, t1838, t1839, t1840, t1841, \n         t1842, t1843, t1844, t1845, t1846, t1847, t1848, t1849, \n         t1850, t1851, t1852, t1853, t1854, t1855, t1856, t1857, \n         t1858, t1859, t1860, t1861, t1862, t1863, t1864, t1865, \n         t1866, t1867, t1868, t1869, t1870, t1871, t1872, t1873, \n         t1874, t1875, t1876, t1877, t1878, t1879, t1880, t1881, \n         t1882, t1883, t1884, t1885, t1886, t1887, t1888, t1889, \n         t1890, t1891, t1892, t1893, t1894, t1895, t1896, t1897, \n         t1898, t1899, t1900, t1901, t1902, t1903, t1904, t1905, \n         t1906, t1907, t1908, t1909, t1910, t1911, t1912, t1913, \n         t1914, t1915, t1916, t1917, t1918, t1919, t1920, t1921;\n  int a2991, a2992, a2993, a2994, a3035;\n  a2991 = (threadIdx.x / 16);\n  a2992 = (threadIdx.x % 16);\n  a2993 = ((512*a2991) + (2*a2992));\n  s946 = T33[a2993];\n  s947 = T33[(a2993 + 1)];\n  s948 = T33[(a2993 + 256)];\n  s949 = T33[(a2993 + 257)];\n  a2994 = (32*a2992);\n  a2995 = D3[a2994];\n  a2996 = D3[(a2994 + 1)];\n  s950 = ((a2995*s946) - (a2996*s947));\n  s951 = ((a2996*s946) + (a2995*s947));\n  a2997 = D3[(a2994 + 2)];\n  a2998 = D3[(a2994 + 3)];\n  s952 = ((a2997*s948) - (a2998*s949));\n  s953 = ((a2998*s948) + (a2997*s949));\n  t1834 = (s950 + s952);\n  t1835 = (s951 + s953);\n  t1836 = (s950 - s952);\n  t1837 = (s951 - s953);\n  s954 = T33[(a2993 + 128)];\n  s955 = T33[(a2993 + 129)];\n  s956 = T33[(a2993 + 384)];\n  s957 = T33[(a2993 + 385)];\n  a2999 = D3[(4 + a2994)];\n  a3000 = D3[(5 + a2994)];\n  s958 = ((a2999*s954) - (a3000*s955));\n  s959 = ((a3000*s954) + (a2999*s955));\n  a3001 = D3[(6 + a2994)];\n  a3002 = D3[(7 + a2994)];\n  s960 = ((a3001*s956) - (a3002*s957));\n  s961 = ((a3002*s956) + (a3001*s957));\n  t1838 = (s958 + s960);\n  t1839 = (s959 + s961);\n  t1840 = (s958 - s960);\n  t1841 = (s959 - s961);\n  t1842 = (t1834 + t1838);\n  t1843 = (t1835 + t1839);\n  t1844 = (t1834 - t1838);\n  t1845 = (t1835 - t1839);\n  t1846 = (t1836 + t1841);\n  t1847 = (t1837 - t1840);\n  t1848 = (t1836 - t1841);\n  t1849 = (t1837 + t1840);\n  s962 = T33[(a2993 + 32)];\n  s963 = T33[(a2993 + 33)];\n  s964 = T33[(a2993 + 288)];\n  s965 = T33[(a2993 + 289)];\n  a3003 = D3[(a2994 + 8)];\n  a3004 = D3[(9 + a2994)];\n  s966 = ((a3003*s962) - (a3004*s963));\n  s967 = ((a3004*s962) + (a3003*s963));\n  a3005 = D3[(10 + a2994)];\n  a3006 = D3[(11 + a2994)];\n  s968 = ((a3005*s964) - (a3006*s965));\n  s969 = ((a3006*s964) + (a3005*s965));\n  t1850 = (s966 + s968);\n  t1851 = (s967 + s969);\n  t1852 = (s966 - s968);\n  t1853 = (s967 - s969);\n  s970 = T33[(a2993 + 160)];\n  s971 = T33[(a2993 + 161)];\n  s972 = T33[(a2993 + 416)];\n  s973 = T33[(a2993 + 417)];\n  a3007 = D3[(12 + a2994)];\n  a3008 = D3[(13 + a2994)];\n  s974 = ((a3007*s970) - (a3008*s971));\n  s975 = ((a3008*s970) + (a3007*s971));\n  a3009 = D3[(14 + a2994)];\n  a3010 = D3[(15 + a2994)];\n  s976 = ((a3009*s972) - (a3010*s973));\n  s977 = ((a3010*s972) + (a3009*s973));\n  t1854 = (s974 + s976);\n  t1855 = (s975 + s977);\n  t1856 = (s974 - s976);\n  t1857 = (s975 - s977);\n  t1858 = (t1850 + t1854);\n  t1859 = (t1851 + t1855);\n  a3011 = (0.70710678118654757*(t1850 - t1854));\n  a3012 = (0.70710678118654757*(t1851 - t1855));\n  s978 = (a3011 + a3012);\n  s979 = (a3012 - a3011);\n  t1860 = (t1852 + t1857);\n  t1861 = (t1853 - t1856);\n  t1862 = (t1852 - t1857);\n  t1863 = (t1853 + t1856);\n  s980 = ((0.92387953251128674*t1860) + (0.38268343236508978*t1861));\n  s981 = ((0.92387953251128674*t1861) - (0.38268343236508978*t1860));\n  s982 = ((0.38268343236508978*t1862) + (0.92387953251128674*t1863));\n  s983 = ((0.38268343236508978*t1863) - (0.92387953251128674*t1862));\n  s984 = T33[(a2993 + 64)];\n  s985 = T33[(a2993 + 65)];\n  s986 = T33[(a2993 + 320)];\n  s987 = T33[(a2993 + 321)];\n  a3013 = D3[(a2994 + 16)];\n  a3014 = D3[(17 + a2994)];\n  s988 = ((a3013*s984) - (a3014*s985));\n  s989 = ((a3014*s984) + (a3013*s985));\n  a3015 = D3[(18 + a2994)];\n  a3016 = D3[(19 + a2994)];\n  s990 = ((a3015*s986) - (a3016*s987));\n  s991 = ((a3016*s986) + (a3015*s987));\n  t1864 = (s988 + s990);\n  t1865 = (s989 + s991);\n  t1866 = (s988 - s990);\n  t1867 = (s989 - s991);\n  s992 = T33[(a2993 + 192)];\n  s993 = T33[(a2993 + 193)];\n  s994 = T33[(a2993 + 448)];\n  s995 = T33[(a2993 + 449)];\n  a3017 = D3[(20 + a2994)];\n  a3018 = D3[(21 + a2994)];\n  s996 = ((a3017*s992) - (a3018*s993));\n  s997 = ((a3018*s992) + (a3017*s993));\n  a3019 = D3[(22 + a2994)];\n  a3020 = D3[(23 + a2994)];\n  s998 = ((a3019*s994) - (a3020*s995));\n  s999 = ((a3020*s994) + (a3019*s995));\n  t1868 = (s996 + s998);\n  t1869 = (s997 + s999);\n  t1870 = (s996 - s998);\n  t1871 = (s997 - s999);\n  t1872 = (t1864 + t1868);\n  t1873 = (t1865 + t1869);\n  t1874 = (t1864 - t1868);\n  t1875 = (t1865 - t1869);\n  a3021 = (0.70710678118654757*(t1866 + t1871));\n  a3022 = (0.70710678118654757*(t1867 - t1870));\n  s1000 = (a3021 + a3022);\n  s1001 = (a3022 - a3021);\n  a3023 = (0.70710678118654757*(t1867 + t1870));\n  a3024 = (0.70710678118654757*(t1866 - t1871));\n  s1002 = (a3023 - a3024);\n  s1003 = (a3024 + a3023);\n  s1004 = T33[(a2993 + 96)];\n  s1005 = T33[(a2993 + 97)];\n  s1006 = T33[(a2993 + 352)];\n  s1007 = T33[(a2993 + 353)];\n  a3025 = D3[(a2994 + 24)];\n  a3026 = D3[(25 + a2994)];\n  s1008 = ((a3025*s1004) - (a3026*s1005));\n  s1009 = ((a3026*s1004) + (a3025*s1005));\n  a3027 = D3[(26 + a2994)];\n  a3028 = D3[(27 + a2994)];\n  s1010 = ((a3027*s1006) - (a3028*s1007));\n  s1011 = ((a3028*s1006) + (a3027*s1007));\n  t1876 = (s1008 + s1010);\n  t1877 = (s1009 + s1011);\n  t1878 = (s1008 - s1010);\n  t1879 = (s1009 - s1011);\n  s1012 = T33[(a2993 + 224)];\n  s1013 = T33[(a2993 + 225)];\n  s1014 = T33[(a2993 + 480)];\n  s1015 = T33[(a2993 + 481)];\n  a3029 = D3[(28 + a2994)];\n  a3030 = D3[(29 + a2994)];\n  s1016 = ((a3029*s1012) - (a3030*s1013));\n  s1017 = ((a3030*s1012) + (a3029*s1013));\n  a3031 = D3[(30 + a2994)];\n  a3032 = D3[(31 + a2994)];\n  s1018 = ((a3031*s1014) - (a3032*s1015));\n  s1019 = ((a3032*s1014) + (a3031*s1015));\n  t1880 = (s1016 + s1018);\n  t1881 = (s1017 + s1019);\n  t1882 = (s1016 - s1018);\n  t1883 = (s1017 - s1019);\n  t1884 = (t1876 + t1880);\n  t1885 = (t1877 + t1881);\n  a3033 = (0.70710678118654757*(t1877 - t1881));\n  a3034 = (0.70710678118654757*(t1876 - t1880));\n  s1020 = (a3033 - a3034);\n  s1021 = (a3034 + a3033);\n  t1886 = (t1878 + t1883);\n  t1887 = (t1879 - t1882);\n  t1888 = (t1878 - t1883);\n  t1889 = (t1879 + t1882);\n  s1022 = ((0.38268343236508978*t1886) + (0.92387953251128674*t1887));\n  s1023 = ((0.38268343236508978*t1887) - (0.92387953251128674*t1886));\n  s1024 = ((0.92387953251128674*t1888) + (0.38268343236508978*t1889));\n  s1025 = ((0.38268343236508978*t1888) - (0.92387953251128674*t1889));\n  t1890 = (t1842 + t1872);\n  t1891 = (t1843 + t1873);\n  t1892 = (t1842 - t1872);\n  t1893 = (t1843 - t1873);\n  t1894 = (t1858 + t1884);\n  t1895 = (t1859 + t1885);\n  t1896 = (t1858 - t1884);\n  t1897 = (t1859 - t1885);\n  a3035 = ((8*blockIdx.x) + (131072*a2992) + (2*a2991));\n  P2[a3035] = (t1890 + t1894);\n  P2[(a3035 + 1)] = (t1891 + t1895);\n  P2[(a3035 + 16777216)] = (t1890 - t1894);\n  P2[(a3035 + 16777217)] = (t1891 - t1895);\n  P2[(a3035 + 8388608)] = (t1892 + t1897);\n  P2[(a3035 + 8388609)] = (t1893 - t1896);\n  P2[(a3035 + 25165824)] = (t1892 - t1897);\n  P2[(a3035 + 25165825)] = (t1893 + t1896);\n  t1898 = (t1846 + s1000);\n  t1899 = (t1847 + s1001);\n  t1900 = (t1846 - s1000);\n  t1901 = (t1847 - s1001);\n  t1902 = (s980 + s1022);\n  t1903 = (s981 + s1023);\n  t1904 = (s980 - s1022);\n  t1905 = (s981 - s1023);\n  P2[(a3035 + 2097152)] = (t1898 + t1902);\n  P2[(a3035 + 2097153)] = (t1899 + t1903);\n  P2[(a3035 + 18874368)] = (t1898 - t1902);\n  P2[(a3035 + 18874369)] = (t1899 - t1903);\n  P2[(a3035 + 10485760)] = (t1900 + t1905);\n  P2[(a3035 + 10485761)] = (t1901 - t1904);\n  P2[(a3035 + 27262976)] = (t1900 - t1905);\n  P2[(a3035 + 27262977)] = (t1901 + t1904);\n  t1906 = (t1844 + t1875);\n  t1907 = (t1845 - t1874);\n  t1908 = (t1844 - t1875);\n  t1909 = (t1845 + t1874);\n  t1910 = (s978 + s1020);\n  t1911 = (s979 - s1021);\n  t1912 = (s978 - s1020);\n  t1913 = (s979 + s1021);\n  P2[(a3035 + 4194304)] = (t1906 + t1910);\n  P2[(a3035 + 4194305)] = (t1907 + t1911);\n  P2[(a3035 + 20971520)] = (t1906 - t1910);\n  P2[(a3035 + 20971521)] = (t1907 - t1911);\n  P2[(a3035 + 12582912)] = (t1908 + t1913);\n  P2[(a3035 + 12582913)] = (t1909 - t1912);\n  P2[(a3035 + 29360128)] = (t1908 - t1913);\n  P2[(a3035 + 29360129)] = (t1909 + t1912);\n  t1914 = (t1848 + s1002);\n  t1915 = (t1849 - s1003);\n  t1916 = (t1848 - s1002);\n  t1917 = (t1849 + s1003);\n  t1918 = (s982 - s1024);\n  t1919 = (s983 + s1025);\n  t1920 = (s982 + s1024);\n  t1921 = (s983 - s1025);\n  P2[(a3035 + 6291456)] = (t1914 + t1918);\n  P2[(a3035 + 6291457)] = (t1915 + t1919);\n  P2[(a3035 + 23068672)] = (t1914 - t1918);\n  P2[(a3035 + 23068673)] = (t1915 - t1919);\n  P2[(a3035 + 14680064)] = (t1916 + t1921);\n  P2[(a3035 + 14680065)] = (t1917 - t1920);\n  P2[(a3035 + 31457280)] = (t1916 - t1921);\n  P2[(a3035 + 31457281)] = (t1917 + t1920);\n  __syncthreads();\n}\n\n__global__\nvoid ker_zmddft_fwd_256x256x256_cu2(const double *P2, double *Y)\n{\n  __shared__ double T63[2048];\n  double a3529, a3530, a3531, a3532, a3533, a3534, a3535, a3536, \n         s1170, s1171, s1172, s1173, s1174, s1175, s1176, s1177, \n         s1178, s1179, s1180, s1181, s1182, s1183, s1184, s1185, \n         s1186, s1187, s1188, s1189, s1190, s1191, s1192, s1193, \n         s1194, s1195, s1196, s1197, s1198, s1199, s1200, s1201, \n         s1202, s1203, s1204, s1205, s1206, s1207, s1208, s1209, \n         s1210, s1211, s1212, s1213, s1214, s1215, s1216, s1217, \n         t2266, t2267, t2268, t2269, t2270, t2271, t2272, t2273, \n         t2274, t2275, t2276, t2277, t2278, t2279, t2280, t2281, \n         t2282, t2283, t2284, t2285, t2286, t2287, t2288, t2289, \n         t2290, t2291, t2292, t2293, t2294, t2295, t2296, t2297, \n         t2298, t2299, t2300, t2301, t2302, t2303, t2304, t2305, \n         t2306, t2307, t2308, t2309, t2310, t2311, t2312, t2313, \n         t2314, t2315, t2316, t2317, t2318, t2319, t2320, t2321, \n         t2322, t2323, t2324, t2325, t2326, t2327, t2328, t2329, \n         t2330, t2331, t2332, t2333, t2334, t2335, t2336, t2337, \n         t2338, t2339, t2340, t2341, t2342, t2343, t2344, t2345, \n         t2346, t2347, t2348, t2349, t2350, t2351, t2352, t2353;\n  int a3526, a3527, a3528, a3537;\n  a3526 = (512*(threadIdx.x / 16));\n  a3527 = (threadIdx.x % 16);\n  a3528 = ((2048*blockIdx.x) + a3526 + (2*a3527));\n  s1170 = P2[a3528];\n  s1171 = P2[(a3528 + 1)];\n  s1172 = P2[(a3528 + 256)];\n  s1173 = P2[(a3528 + 257)];\n  t2266 = (s1170 + s1172);\n  t2267 = (s1171 + s1173);\n  t2268 = (s1170 - s1172);\n  t2269 = (s1171 - s1173);\n  s1174 = P2[(a3528 + 128)];\n  s1175 = P2[(a3528 + 129)];\n  s1176 = P2[(a3528 + 384)];\n  s1177 = P2[(a3528 + 385)];\n  t2270 = (s1174 + s1176);\n  t2271 = (s1175 + s1177);\n  t2272 = (s1174 - s1176);\n  t2273 = (s1175 - s1177);\n  t2274 = (t2266 + t2270);\n  t2275 = (t2267 + t2271);\n  t2276 = (t2266 - t2270);\n  t2277 = (t2267 - t2271);\n  t2278 = (t2268 + t2273);\n  t2279 = (t2269 - t2272);\n  t2280 = (t2268 - t2273);\n  t2281 = (t2269 + t2272);\n  s1178 = P2[(a3528 + 32)];\n  s1179 = P2[(a3528 + 33)];\n  s1180 = P2[(a3528 + 288)];\n  s1181 = P2[(a3528 + 289)];\n  t2282 = (s1178 + s1180);\n  t2283 = (s1179 + s1181);\n  t2284 = (s1178 - s1180);\n  t2285 = (s1179 - s1181);\n  s1182 = P2[(a3528 + 160)];\n  s1183 = P2[(a3528 + 161)];\n  s1184 = P2[(a3528 + 416)];\n  s1185 = P2[(a3528 + 417)];\n  t2286 = (s1182 + s1184);\n  t2287 = (s1183 + s1185);\n  t2288 = (s1182 - s1184);\n  t2289 = (s1183 - s1185);\n  t2290 = (t2282 + t2286);\n  t2291 = (t2283 + t2287);\n  a3529 = (0.70710678118654757*(t2282 - t2286));\n  a3530 = (0.70710678118654757*(t2283 - t2287));\n  s1186 = (a3529 + a3530);\n  s1187 = (a3530 - a3529);\n  t2292 = (t2284 + t2289);\n  t2293 = (t2285 - t2288);\n  t2294 = (t2284 - t2289);\n  t2295 = (t2285 + t2288);\n  s1188 = ((0.92387953251128674*t2292) + (0.38268343236508978*t2293));\n  s1189 = ((0.92387953251128674*t2293) - (0.38268343236508978*t2292));\n  s1190 = ((0.38268343236508978*t2294) + (0.92387953251128674*t2295));\n  s1191 = ((0.38268343236508978*t2295) - (0.92387953251128674*t2294));\n  s1192 = P2[(a3528 + 64)];\n  s1193 = P2[(a3528 + 65)];\n  s1194 = P2[(a3528 + 320)];\n  s1195 = P2[(a3528 + 321)];\n  t2296 = (s1192 + s1194);\n  t2297 = (s1193 + s1195);\n  t2298 = (s1192 - s1194);\n  t2299 = (s1193 - s1195);\n  s1196 = P2[(a3528 + 192)];\n  s1197 = P2[(a3528 + 193)];\n  s1198 = P2[(a3528 + 448)];\n  s1199 = P2[(a3528 + 449)];\n  t2300 = (s1196 + s1198);\n  t2301 = (s1197 + s1199);\n  t2302 = (s1196 - s1198);\n  t2303 = (s1197 - s1199);\n  t2304 = (t2296 + t2300);\n  t2305 = (t2297 + t2301);\n  t2306 = (t2296 - t2300);\n  t2307 = (t2297 - t2301);\n  a3531 = (0.70710678118654757*(t2298 + t2303));\n  a3532 = (0.70710678118654757*(t2299 - t2302));\n  s1200 = (a3531 + a3532);\n  s1201 = (a3532 - a3531);\n  a3533 = (0.70710678118654757*(t2299 + t2302));\n  a3534 = (0.70710678118654757*(t2298 - t2303));\n  s1202 = (a3533 - a3534);\n  s1203 = (a3534 + a3533);\n  s1204 = P2[(a3528 + 96)];\n  s1205 = P2[(a3528 + 97)];\n  s1206 = P2[(a3528 + 352)];\n  s1207 = P2[(a3528 + 353)];\n  t2308 = (s1204 + s1206);\n  t2309 = (s1205 + s1207);\n  t2310 = (s1204 - s1206);\n  t2311 = (s1205 - s1207);\n  s1208 = P2[(a3528 + 224)];\n  s1209 = P2[(a3528 + 225)];\n  s1210 = P2[(a3528 + 480)];\n  s1211 = P2[(a3528 + 481)];\n  t2312 = (s1208 + s1210);\n  t2313 = (s1209 + s1211);\n  t2314 = (s1208 - s1210);\n  t2315 = (s1209 - s1211);\n  t2316 = (t2308 + t2312);\n  t2317 = (t2309 + t2313);\n  a3535 = (0.70710678118654757*(t2309 - t2313));\n  a3536 = (0.70710678118654757*(t2308 - t2312));\n  s1212 = (a3535 - a3536);\n  s1213 = (a3536 + a3535);\n  t2318 = (t2310 + t2315);\n  t2319 = (t2311 - t2314);\n  t2320 = (t2310 - t2315);\n  t2321 = (t2311 + t2314);\n  s1214 = ((0.38268343236508978*t2318) + (0.92387953251128674*t2319));\n  s1215 = ((0.38268343236508978*t2319) - (0.92387953251128674*t2318));\n  s1216 = ((0.92387953251128674*t2320) + (0.38268343236508978*t2321));\n  s1217 = ((0.38268343236508978*t2320) - (0.92387953251128674*t2321));\n  t2322 = (t2274 + t2304);\n  t2323 = (t2275 + t2305);\n  t2324 = (t2274 - t2304);\n  t2325 = (t2275 - t2305);\n  t2326 = (t2290 + t2316);\n  t2327 = (t2291 + t2317);\n  t2328 = (t2290 - t2316);\n  t2329 = (t2291 - t2317);\n  a3537 = (a3526 + (32*a3527));\n  T63[a3537] = (t2322 + t2326);\n  T63[(a3537 + 1)] = (t2323 + t2327);\n  T63[(a3537 + 16)] = (t2322 - t2326);\n  T63[(a3537 + 17)] = (t2323 - t2327);\n  T63[(a3537 + 8)] = (t2324 + t2329);\n  T63[(a3537 + 9)] = (t2325 - t2328);\n  T63[(a3537 + 24)] = (t2324 - t2329);\n  T63[(a3537 + 25)] = (t2325 + t2328);\n  t2330 = (t2278 + s1200);\n  t2331 = (t2279 + s1201);\n  t2332 = (t2278 - s1200);\n  t2333 = (t2279 - s1201);\n  t2334 = (s1188 + s1214);\n  t2335 = (s1189 + s1215);\n  t2336 = (s1188 - s1214);\n  t2337 = (s1189 - s1215);\n  T63[(a3537 + 2)] = (t2330 + t2334);\n  T63[(a3537 + 3)] = (t2331 + t2335);\n  T63[(a3537 + 18)] = (t2330 - t2334);\n  T63[(a3537 + 19)] = (t2331 - t2335);\n  T63[(a3537 + 10)] = (t2332 + t2337);\n  T63[(a3537 + 11)] = (t2333 - t2336);\n  T63[(a3537 + 26)] = (t2332 - t2337);\n  T63[(a3537 + 27)] = (t2333 + t2336);\n  t2338 = (t2276 + t2307);\n  t2339 = (t2277 - t2306);\n  t2340 = (t2276 - t2307);\n  t2341 = (t2277 + t2306);\n  t2342 = (s1186 + s1212);\n  t2343 = (s1187 - s1213);\n  t2344 = (s1186 - s1212);\n  t2345 = (s1187 + s1213);\n  T63[(a3537 + 4)] = (t2338 + t2342);\n  T63[(a3537 + 5)] = (t2339 + t2343);\n  T63[(a3537 + 20)] = (t2338 - t2342);\n  T63[(a3537 + 21)] = (t2339 - t2343);\n  T63[(a3537 + 12)] = (t2340 + t2345);\n  T63[(a3537 + 13)] = (t2341 - t2344);\n  T63[(a3537 + 28)] = (t2340 - t2345);\n  T63[(a3537 + 29)] = (t2341 + t2344);\n  t2346 = (t2280 + s1202);\n  t2347 = (t2281 - s1203);\n  t2348 = (t2280 - s1202);\n  t2349 = (t2281 + s1203);\n  t2350 = (s1190 - s1216);\n  t2351 = (s1191 + s1217);\n  t2352 = (s1190 + s1216);\n  t2353 = (s1191 - s1217);\n  T63[(a3537 + 6)] = (t2346 + t2350);\n  T63[(a3537 + 7)] = (t2347 + t2351);\n  T63[(a3537 + 22)] = (t2346 - t2350);\n  T63[(a3537 + 23)] = (t2347 - t2351);\n  T63[(a3537 + 14)] = (t2348 + t2353);\n  T63[(a3537 + 15)] = (t2349 - t2352);\n  T63[(a3537 + 30)] = (t2348 - t2353);\n  T63[(a3537 + 31)] = (t2349 + t2352);\n  __syncthreads();\n  double a4512, a4513, a4514, a4515, a4516, a4517, a4518, a4519, \n         a4520, a4521, a4522, a4523, a4524, a4525, a4526, a4527, \n         a4528, a4529, a4530, a4531, a4532, a4533, a4534, a4535, \n         a4536, a4537, a4538, a4539, a4540, a4541, a4542, a4543, \n         a4544, a4545, a4546, a4547, a4548, a4549, a4550, a4551, \n         s1458, s1459, s1460, s1461, s1462, s1463, s1464, s1465, \n         s1466, s1467, s1468, s1469, s1470, s1471, s1472, s1473, \n         s1474, s1475, s1476, s1477, s1478, s1479, s1480, s1481, \n         s1482, s1483, s1484, s1485, s1486, s1487, s1488, s1489, \n         s1490, s1491, s1492, s1493, s1494, s1495, s1496, s1497, \n         s1498, s1499, s1500, s1501, s1502, s1503, s1504, s1505, \n         s1506, s1507, s1508, s1509, s1510, s1511, s1512, s1513, \n         s1514, s1515, s1516, s1517, s1518, s1519, s1520, s1521, \n         s1522, s1523, s1524, s1525, s1526, s1527, s1528, s1529, \n         s1530, s1531, s1532, s1533, s1534, s1535, s1536, s1537, \n         t2698, t2699, t2700, t2701, t2702, t2703, t2704, t2705, \n         t2706, t2707, t2708, t2709, t2710, t2711, t2712, t2713, \n         t2714, t2715, t2716, t2717, t2718, t2719, t2720, t2721, \n         t2722, t2723, t2724, t2725, t2726, t2727, t2728, t2729, \n         t2730, t2731, t2732, t2733, t2734, t2735, t2736, t2737, \n         t2738, t2739, t2740, t2741, t2742, t2743, t2744, t2745, \n         t2746, t2747, t2748, t2749, t2750, t2751, t2752, t2753, \n         t2754, t2755, t2756, t2757, t2758, t2759, t2760, t2761, \n         t2762, t2763, t2764, t2765, t2766, t2767, t2768, t2769, \n         t2770, t2771, t2772, t2773, t2774, t2775, t2776, t2777, \n         t2778, t2779, t2780, t2781, t2782, t2783, t2784, t2785;\n  int a4508, a4509, a4510, a4511, a4552;\n  a4508 = (threadIdx.x / 16);\n  a4509 = (threadIdx.x % 16);\n  a4510 = ((512*a4508) + (2*a4509));\n  s1458 = T63[a4510];\n  s1459 = T63[(a4510 + 1)];\n  s1460 = T63[(a4510 + 256)];\n  s1461 = T63[(a4510 + 257)];\n  a4511 = (32*a4509);\n  a4512 = D3[a4511];\n  a4513 = D3[(a4511 + 1)];\n  s1462 = ((a4512*s1458) - (a4513*s1459));\n  s1463 = ((a4513*s1458) + (a4512*s1459));\n  a4514 = D3[(a4511 + 2)];\n  a4515 = D3[(a4511 + 3)];\n  s1464 = ((a4514*s1460) - (a4515*s1461));\n  s1465 = ((a4515*s1460) + (a4514*s1461));\n  t2698 = (s1462 + s1464);\n  t2699 = (s1463 + s1465);\n  t2700 = (s1462 - s1464);\n  t2701 = (s1463 - s1465);\n  s1466 = T63[(a4510 + 128)];\n  s1467 = T63[(a4510 + 129)];\n  s1468 = T63[(a4510 + 384)];\n  s1469 = T63[(a4510 + 385)];\n  a4516 = D3[(4 + a4511)];\n  a4517 = D3[(5 + a4511)];\n  s1470 = ((a4516*s1466) - (a4517*s1467));\n  s1471 = ((a4517*s1466) + (a4516*s1467));\n  a4518 = D3[(6 + a4511)];\n  a4519 = D3[(7 + a4511)];\n  s1472 = ((a4518*s1468) - (a4519*s1469));\n  s1473 = ((a4519*s1468) + (a4518*s1469));\n  t2702 = (s1470 + s1472);\n  t2703 = (s1471 + s1473);\n  t2704 = (s1470 - s1472);\n  t2705 = (s1471 - s1473);\n  t2706 = (t2698 + t2702);\n  t2707 = (t2699 + t2703);\n  t2708 = (t2698 - t2702);\n  t2709 = (t2699 - t2703);\n  t2710 = (t2700 + t2705);\n  t2711 = (t2701 - t2704);\n  t2712 = (t2700 - t2705);\n  t2713 = (t2701 + t2704);\n  s1474 = T63[(a4510 + 32)];\n  s1475 = T63[(a4510 + 33)];\n  s1476 = T63[(a4510 + 288)];\n  s1477 = T63[(a4510 + 289)];\n  a4520 = D3[(a4511 + 8)];\n  a4521 = D3[(9 + a4511)];\n  s1478 = ((a4520*s1474) - (a4521*s1475));\n  s1479 = ((a4521*s1474) + (a4520*s1475));\n  a4522 = D3[(10 + a4511)];\n  a4523 = D3[(11 + a4511)];\n  s1480 = ((a4522*s1476) - (a4523*s1477));\n  s1481 = ((a4523*s1476) + (a4522*s1477));\n  t2714 = (s1478 + s1480);\n  t2715 = (s1479 + s1481);\n  t2716 = (s1478 - s1480);\n  t2717 = (s1479 - s1481);\n  s1482 = T63[(a4510 + 160)];\n  s1483 = T63[(a4510 + 161)];\n  s1484 = T63[(a4510 + 416)];\n  s1485 = T63[(a4510 + 417)];\n  a4524 = D3[(12 + a4511)];\n  a4525 = D3[(13 + a4511)];\n  s1486 = ((a4524*s1482) - (a4525*s1483));\n  s1487 = ((a4525*s1482) + (a4524*s1483));\n  a4526 = D3[(14 + a4511)];\n  a4527 = D3[(15 + a4511)];\n  s1488 = ((a4526*s1484) - (a4527*s1485));\n  s1489 = ((a4527*s1484) + (a4526*s1485));\n  t2718 = (s1486 + s1488);\n  t2719 = (s1487 + s1489);\n  t2720 = (s1486 - s1488);\n  t2721 = (s1487 - s1489);\n  t2722 = (t2714 + t2718);\n  t2723 = (t2715 + t2719);\n  a4528 = (0.70710678118654757*(t2714 - t2718));\n  a4529 = (0.70710678118654757*(t2715 - t2719));\n  s1490 = (a4528 + a4529);\n  s1491 = (a4529 - a4528);\n  t2724 = (t2716 + t2721);\n  t2725 = (t2717 - t2720);\n  t2726 = (t2716 - t2721);\n  t2727 = (t2717 + t2720);\n  s1492 = ((0.92387953251128674*t2724) + (0.38268343236508978*t2725));\n  s1493 = ((0.92387953251128674*t2725) - (0.38268343236508978*t2724));\n  s1494 = ((0.38268343236508978*t2726) + (0.92387953251128674*t2727));\n  s1495 = ((0.38268343236508978*t2727) - (0.92387953251128674*t2726));\n  s1496 = T63[(a4510 + 64)];\n  s1497 = T63[(a4510 + 65)];\n  s1498 = T63[(a4510 + 320)];\n  s1499 = T63[(a4510 + 321)];\n  a4530 = D3[(a4511 + 16)];\n  a4531 = D3[(17 + a4511)];\n  s1500 = ((a4530*s1496) - (a4531*s1497));\n  s1501 = ((a4531*s1496) + (a4530*s1497));\n  a4532 = D3[(18 + a4511)];\n  a4533 = D3[(19 + a4511)];\n  s1502 = ((a4532*s1498) - (a4533*s1499));\n  s1503 = ((a4533*s1498) + (a4532*s1499));\n  t2728 = (s1500 + s1502);\n  t2729 = (s1501 + s1503);\n  t2730 = (s1500 - s1502);\n  t2731 = (s1501 - s1503);\n  s1504 = T63[(a4510 + 192)];\n  s1505 = T63[(a4510 + 193)];\n  s1506 = T63[(a4510 + 448)];\n  s1507 = T63[(a4510 + 449)];\n  a4534 = D3[(20 + a4511)];\n  a4535 = D3[(21 + a4511)];\n  s1508 = ((a4534*s1504) - (a4535*s1505));\n  s1509 = ((a4535*s1504) + (a4534*s1505));\n  a4536 = D3[(22 + a4511)];\n  a4537 = D3[(23 + a4511)];\n  s1510 = ((a4536*s1506) - (a4537*s1507));\n  s1511 = ((a4537*s1506) + (a4536*s1507));\n  t2732 = (s1508 + s1510);\n  t2733 = (s1509 + s1511);\n  t2734 = (s1508 - s1510);\n  t2735 = (s1509 - s1511);\n  t2736 = (t2728 + t2732);\n  t2737 = (t2729 + t2733);\n  t2738 = (t2728 - t2732);\n  t2739 = (t2729 - t2733);\n  a4538 = (0.70710678118654757*(t2730 + t2735));\n  a4539 = (0.70710678118654757*(t2731 - t2734));\n  s1512 = (a4538 + a4539);\n  s1513 = (a4539 - a4538);\n  a4540 = (0.70710678118654757*(t2731 + t2734));\n  a4541 = (0.70710678118654757*(t2730 - t2735));\n  s1514 = (a4540 - a4541);\n  s1515 = (a4541 + a4540);\n  s1516 = T63[(a4510 + 96)];\n  s1517 = T63[(a4510 + 97)];\n  s1518 = T63[(a4510 + 352)];\n  s1519 = T63[(a4510 + 353)];\n  a4542 = D3[(a4511 + 24)];\n  a4543 = D3[(25 + a4511)];\n  s1520 = ((a4542*s1516) - (a4543*s1517));\n  s1521 = ((a4543*s1516) + (a4542*s1517));\n  a4544 = D3[(26 + a4511)];\n  a4545 = D3[(27 + a4511)];\n  s1522 = ((a4544*s1518) - (a4545*s1519));\n  s1523 = ((a4545*s1518) + (a4544*s1519));\n  t2740 = (s1520 + s1522);\n  t2741 = (s1521 + s1523);\n  t2742 = (s1520 - s1522);\n  t2743 = (s1521 - s1523);\n  s1524 = T63[(a4510 + 224)];\n  s1525 = T63[(a4510 + 225)];\n  s1526 = T63[(a4510 + 480)];\n  s1527 = T63[(a4510 + 481)];\n  a4546 = D3[(28 + a4511)];\n  a4547 = D3[(29 + a4511)];\n  s1528 = ((a4546*s1524) - (a4547*s1525));\n  s1529 = ((a4547*s1524) + (a4546*s1525));\n  a4548 = D3[(30 + a4511)];\n  a4549 = D3[(31 + a4511)];\n  s1530 = ((a4548*s1526) - (a4549*s1527));\n  s1531 = ((a4549*s1526) + (a4548*s1527));\n  t2744 = (s1528 + s1530);\n  t2745 = (s1529 + s1531);\n  t2746 = (s1528 - s1530);\n  t2747 = (s1529 - s1531);\n  t2748 = (t2740 + t2744);\n  t2749 = (t2741 + t2745);\n  a4550 = (0.70710678118654757*(t2741 - t2745));\n  a4551 = (0.70710678118654757*(t2740 - t2744));\n  s1532 = (a4550 - a4551);\n  s1533 = (a4551 + a4550);\n  t2750 = (t2742 + t2747);\n  t2751 = (t2743 - t2746);\n  t2752 = (t2742 - t2747);\n  t2753 = (t2743 + t2746);\n  s1534 = ((0.38268343236508978*t2750) + (0.92387953251128674*t2751));\n  s1535 = ((0.38268343236508978*t2751) - (0.92387953251128674*t2750));\n  s1536 = ((0.92387953251128674*t2752) + (0.38268343236508978*t2753));\n  s1537 = ((0.38268343236508978*t2752) - (0.92387953251128674*t2753));\n  t2754 = (t2706 + t2736);\n  t2755 = (t2707 + t2737);\n  t2756 = (t2706 - t2736);\n  t2757 = (t2707 - t2737);\n  t2758 = (t2722 + t2748);\n  t2759 = (t2723 + t2749);\n  t2760 = (t2722 - t2748);\n  t2761 = (t2723 - t2749);\n  a4552 = ((8*blockIdx.x) + (131072*a4509) + (2*a4508));\n  Y[a4552] = (t2754 + t2758);\n  Y[(a4552 + 1)] = (t2755 + t2759);\n  Y[(a4552 + 16777216)] = (t2754 - t2758);\n  Y[(a4552 + 16777217)] = (t2755 - t2759);\n  Y[(a4552 + 8388608)] = (t2756 + t2761);\n  Y[(a4552 + 8388609)] = (t2757 - t2760);\n  Y[(a4552 + 25165824)] = (t2756 - t2761);\n  Y[(a4552 + 25165825)] = (t2757 + t2760);\n  t2762 = (t2710 + s1512);\n  t2763 = (t2711 + s1513);\n  t2764 = (t2710 - s1512);\n  t2765 = (t2711 - s1513);\n  t2766 = (s1492 + s1534);\n  t2767 = (s1493 + s1535);\n  t2768 = (s1492 - s1534);\n  t2769 = (s1493 - s1535);\n  Y[(a4552 + 2097152)] = (t2762 + t2766);\n  Y[(a4552 + 2097153)] = (t2763 + t2767);\n  Y[(a4552 + 18874368)] = (t2762 - t2766);\n  Y[(a4552 + 18874369)] = (t2763 - t2767);\n  Y[(a4552 + 10485760)] = (t2764 + t2769);\n  Y[(a4552 + 10485761)] = (t2765 - t2768);\n  Y[(a4552 + 27262976)] = (t2764 - t2769);\n  Y[(a4552 + 27262977)] = (t2765 + t2768);\n  t2770 = (t2708 + t2739);\n  t2771 = (t2709 - t2738);\n  t2772 = (t2708 - t2739);\n  t2773 = (t2709 + t2738);\n  t2774 = (s1490 + s1532);\n  t2775 = (s1491 - s1533);\n  t2776 = (s1490 - s1532);\n  t2777 = (s1491 + s1533);\n  Y[(a4552 + 4194304)] = (t2770 + t2774);\n  Y[(a4552 + 4194305)] = (t2771 + t2775);\n  Y[(a4552 + 20971520)] = (t2770 - t2774);\n  Y[(a4552 + 20971521)] = (t2771 - t2775);\n  Y[(a4552 + 12582912)] = (t2772 + t2777);\n  Y[(a4552 + 12582913)] = (t2773 - t2776);\n  Y[(a4552 + 29360128)] = (t2772 - t2777);\n  Y[(a4552 + 29360129)] = (t2773 + t2776);\n  t2778 = (t2712 + s1514);\n  t2779 = (t2713 - s1515);\n  t2780 = (t2712 - s1514);\n  t2781 = (t2713 + s1515);\n  t2782 = (s1494 - s1536);\n  t2783 = (s1495 + s1537);\n  t2784 = (s1494 + s1536);\n  t2785 = (s1495 - s1537);\n  Y[(a4552 + 6291456)] = (t2778 + t2782);\n  Y[(a4552 + 6291457)] = (t2779 + t2783);\n  Y[(a4552 + 23068672)] = (t2778 - t2782);\n  Y[(a4552 + 23068673)] = (t2779 - t2783);\n  Y[(a4552 + 14680064)] = (t2780 + t2785);\n  Y[(a4552 + 14680065)] = (t2781 - t2784);\n  Y[(a4552 + 31457280)] = (t2780 - t2785);\n  Y[(a4552 + 31457281)] = (t2781 + t2784);\n  __syncthreads();\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 256*256*256*2;\n  size_t dat_size = n * sizeof(double);\n  size_t tmp_size = 33554432 * sizeof(double);\n\n  std::mt19937 engine(n);\n  std::uniform_real_distribution<double> dist(0.0, 1.0);\n  double *x = (double*) malloc (dat_size);\n  for (int i = 0; i < n; i++) x[i] = dist(engine);\n\n  double *y = (double*) malloc (dat_size);\n\n  double *Y, *X;\n\n  hipMalloc((void**)&X, dat_size);\n  hipMemcpy(X, x, dat_size, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&Y, dat_size);\n\n  double *P1, *P2;\n  hipMalloc((void**)&P1, tmp_size);\n  hipMalloc((void**)&P2, tmp_size);\n\n  dim3 b1(64), b2(64), b3(64);\n  dim3 g1(16384), g2(16384), g3(16384);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ker_zmddft_fwd_256x256x256_cu0<<<g1, b1>>>(X, P1);\n    ker_zmddft_fwd_256x256x256_cu1<<<g2, b2>>>(P1, P2);\n    ker_zmddft_fwd_256x256x256_cu2<<<g3, b3>>>(P2, Y);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %.3f (ms)\\n\", time * 1e-6f / repeat);\n\n  hipMemcpy(y, Y, dat_size, hipMemcpyDeviceToHost);\n\n  double checksum = 0;\n  for (int i = 0; i < n; i++) checksum += y[i];\n  printf(\"checksum = %lf\\n\", checksum);\n\n  hipFree(X);\n  hipFree(Y);\n  hipFree(P1);\n  hipFree(P2);\n  free(x);\n  free(y);\n\n  return 0;\n}\n"}}
{"kernel_name": "zmddft", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <chrono>\n#include <random>\n\nconst double d[512] = {\n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 0.98078528040323043, (-0.19509032201612825), \n  0.99518472667219693, (-0.098017140329560604), 0.95694033573220882, (-0.29028467725446233), \n  0.99969881869620425, (-0.024541228522912288), 0.97570213003852857, (-0.2191012401568698), \n  0.99247953459870997, (-0.1224106751992162), 0.94952818059303667, (-0.31368174039889152), \n  0.99879545620517241, (-0.049067674327418015), 0.97003125319454397, (-0.24298017990326387), \n  0.98917650996478101, (-0.14673047445536175), 0.94154406518302081, (-0.33688985339222005), \n  0.99729045667869021, (-0.073564563599667426), 0.96377606579543984, (-0.26671275747489837), \n  0.98527764238894122, (-0.17096188876030122), 0.93299279883473896, (-0.35989503653498811), \n  1.0, 0.0, 0.92387953251128674, (-0.38268343236508978), \n  0.98078528040323043, (-0.19509032201612825), 0.83146961230254524, (-0.55557023301960218), \n  0.99879545620517241, (-0.049067674327418015), 0.90398929312344334, (-0.42755509343028208), \n  0.97003125319454397, (-0.24298017990326387), 0.80320753148064494, (-0.59569930449243336), \n  0.99518472667219693, (-0.098017140329560604), 0.88192126434835505, (-0.47139673682599764), \n  0.95694033573220882, (-0.29028467725446233), 0.77301045336273699, (-0.63439328416364549), \n  0.98917650996478101, (-0.14673047445536175), 0.85772861000027212, (-0.51410274419322166), \n  0.94154406518302081, (-0.33688985339222005), 0.74095112535495922, (-0.67155895484701833), \n  1.0, 0.0, 0.83146961230254524, (-0.55557023301960218), \n  0.95694033573220882, (-0.29028467725446233), 0.63439328416364549, (-0.77301045336273699), \n  0.99729045667869021, (-0.073564563599667426), 0.78834642762660623, (-0.61523159058062682), \n  0.93299279883473896, (-0.35989503653498811), 0.57580819141784534, (-0.81758481315158371), \n  0.98917650996478101, (-0.14673047445536175), 0.74095112535495922, (-0.67155895484701833), \n  0.90398929312344334, (-0.42755509343028208), 0.51410274419322166, (-0.85772861000027212), \n  0.97570213003852857, (-0.2191012401568698), 0.68954054473706683, (-0.724247082951467), \n  0.87008699110871146, (-0.49289819222978404), 0.44961132965460654, (-0.89322430119551532), \n  1.0, 0.0, 0.70710678118654757, (-0.70710678118654757), \n  0.92387953251128674, (-0.38268343236508978), 0.38268343236508978, (-0.92387953251128674), \n  0.99518472667219693, (-0.098017140329560604), 0.63439328416364549, (-0.77301045336273699), \n  0.88192126434835505, (-0.47139673682599764), 0.29028467725446233, (-0.95694033573220882), \n  0.98078528040323043, (-0.19509032201612825), 0.55557023301960218, (-0.83146961230254524), \n  0.83146961230254524, (-0.55557023301960218), 0.19509032201612825, (-0.98078528040323043), \n  0.95694033573220882, (-0.29028467725446233), 0.47139673682599764, (-0.88192126434835505), \n  0.77301045336273699, (-0.63439328416364549), 0.098017140329560604, (-0.99518472667219693), \n  1.0, 0.0, 0.55557023301960218, (-0.83146961230254524), \n  0.88192126434835505, (-0.47139673682599764), 0.098017140329560604, (-0.99518472667219693), \n  0.99247953459870997, (-0.1224106751992162), 0.44961132965460654, (-0.89322430119551532), \n  0.81758481315158371, (-0.57580819141784534), (-0.024541228522912288), (-0.99969881869620425), \n  0.97003125319454397, (-0.24298017990326387), 0.33688985339222005, (-0.94154406518302081), \n  0.74095112535495922, (-0.67155895484701833), (-0.14673047445536175), (-0.98917650996478101), \n  0.93299279883473896, (-0.35989503653498811), 0.2191012401568698, (-0.97570213003852857), \n  0.65317284295377676, (-0.75720884650648457), (-0.26671275747489837), (-0.96377606579543984), \n  1.0, 0.0, 0.38268343236508978, (-0.92387953251128674), \n  0.83146961230254524, (-0.55557023301960218), (-0.19509032201612825), (-0.98078528040323043), \n  0.98917650996478101, (-0.14673047445536175), 0.24298017990326387, (-0.97003125319454397), \n  0.74095112535495922, (-0.67155895484701833), (-0.33688985339222005), (-0.94154406518302081), \n  0.95694033573220882, (-0.29028467725446233), 0.098017140329560604, (-0.99518472667219693), \n  0.63439328416364549, (-0.77301045336273699), (-0.47139673682599764), (-0.88192126434835505), \n  0.90398929312344334, (-0.42755509343028208), (-0.049067674327418015), (-0.99879545620517241), \n  0.51410274419322166, (-0.85772861000027212), (-0.59569930449243336), (-0.80320753148064494), \n  1.0, 0.0, 0.19509032201612825, (-0.98078528040323043), \n  0.77301045336273699, (-0.63439328416364549), (-0.47139673682599764), (-0.88192126434835505), \n  0.98527764238894122, (-0.17096188876030122), 0.024541228522912288, (-0.99969881869620425), \n  0.65317284295377676, (-0.75720884650648457), (-0.61523159058062682), (-0.78834642762660623), \n  0.94154406518302081, (-0.33688985339222005), (-0.14673047445536175), (-0.98917650996478101), \n  0.51410274419322166, (-0.85772861000027212), (-0.74095112535495922), (-0.67155895484701833), \n  0.87008699110871146, (-0.49289819222978404), (-0.31368174039889152), (-0.94952818059303667), \n  0.35989503653498811, (-0.93299279883473896), (-0.84485356524970712), (-0.53499761988709715), \n  1.0, 0.0, 0.0, (-1.0), \n  0.70710678118654757, (-0.70710678118654757), (-0.70710678118654757), (-0.70710678118654757), \n  0.98078528040323043, (-0.19509032201612825), (-0.19509032201612825), (-0.98078528040323043), \n  0.55557023301960218, (-0.83146961230254524), (-0.83146961230254524), (-0.55557023301960218), \n  0.92387953251128674, (-0.38268343236508978), (-0.38268343236508978), (-0.92387953251128674), \n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), (-0.38268343236508978), \n  0.83146961230254524, (-0.55557023301960218), (-0.55557023301960218), (-0.83146961230254524), \n  0.19509032201612825, (-0.98078528040323043), (-0.98078528040323043), (-0.19509032201612825), \n  1.0, 0.0, (-0.19509032201612825), (-0.98078528040323043), \n  0.63439328416364549, (-0.77301045336273699), (-0.88192126434835505), (-0.47139673682599764), \n  0.97570213003852857, (-0.2191012401568698), (-0.40524131400498986), (-0.91420975570353069), \n  0.44961132965460654, (-0.89322430119551532), (-0.96377606579543984), (-0.26671275747489837), \n  0.90398929312344334, (-0.42755509343028208), (-0.59569930449243336), (-0.80320753148064494), \n  0.24298017990326387, (-0.97003125319454397), (-0.99879545620517241), (-0.049067674327418015), \n  0.78834642762660623, (-0.61523159058062682), (-0.75720884650648457), (-0.65317284295377676), \n  0.024541228522912288, (-0.99969881869620425), (-0.98527764238894122), 0.17096188876030122, \n  1.0, 0.0, (-0.38268343236508978), (-0.92387953251128674), \n  0.55557023301960218, (-0.83146961230254524), (-0.98078528040323043), (-0.19509032201612825), \n  0.97003125319454397, (-0.24298017990326387), (-0.59569930449243336), (-0.80320753148064494), \n  0.33688985339222005, (-0.94154406518302081), (-0.99879545620517241), 0.049067674327418015, \n  0.88192126434835505, (-0.47139673682599764), (-0.77301045336273699), (-0.63439328416364549), \n  0.098017140329560604, (-0.99518472667219693), (-0.95694033573220882), 0.29028467725446233, \n  0.74095112535495922, (-0.67155895484701833), (-0.90398929312344334), (-0.42755509343028208), \n  (-0.14673047445536175), (-0.98917650996478101), (-0.85772861000027212), 0.51410274419322166, \n  1.0, 0.0, (-0.55557023301960218), (-0.83146961230254524), \n  0.47139673682599764, (-0.88192126434835505), (-0.99518472667219693), 0.098017140329560604, \n  0.96377606579543984, (-0.26671275747489837), (-0.75720884650648457), (-0.65317284295377676), \n  0.2191012401568698, (-0.97570213003852857), (-0.93299279883473896), 0.35989503653498811, \n  0.85772861000027212, (-0.51410274419322166), (-0.90398929312344334), (-0.42755509343028208), \n  (-0.049067674327418015), (-0.99879545620517241), (-0.80320753148064494), 0.59569930449243336, \n  0.68954054473706683, (-0.724247082951467), (-0.98527764238894122), (-0.17096188876030122), \n  (-0.31368174039889152), (-0.94952818059303667), (-0.61523159058062682), 0.78834642762660623, \n  1.0, 0.0, (-0.70710678118654757), (-0.70710678118654757), \n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), 0.38268343236508978, \n  0.95694033573220882, (-0.29028467725446233), (-0.88192126434835505), (-0.47139673682599764), \n  0.098017140329560604, (-0.99518472667219693), (-0.77301045336273699), 0.63439328416364549, \n  0.83146961230254524, (-0.55557023301960218), (-0.98078528040323043), (-0.19509032201612825), \n  (-0.19509032201612825), (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524, \n  0.63439328416364549, (-0.77301045336273699), (-0.99518472667219693), 0.098017140329560604, \n  (-0.47139673682599764), (-0.88192126434835505), (-0.29028467725446233), 0.95694033573220882, \n  1.0, 0.0, (-0.83146961230254524), (-0.55557023301960218), \n  0.29028467725446233, (-0.95694033573220882), (-0.77301045336273699), 0.63439328416364549, \n  0.94952818059303667, (-0.31368174039889152), (-0.96377606579543984), (-0.26671275747489837), \n  (-0.024541228522912288), (-0.99969881869620425), (-0.53499761988709715), 0.84485356524970712, \n  0.80320753148064494, (-0.59569930449243336), (-0.99879545620517241), 0.049067674327418015, \n  (-0.33688985339222005), (-0.94154406518302081), (-0.24298017990326387), 0.97003125319454397, \n  0.57580819141784534, (-0.81758481315158371), (-0.93299279883473896), 0.35989503653498811, \n  (-0.61523159058062682), (-0.78834642762660623), 0.073564563599667426, 0.99729045667869021, \n  1.0, 0.0, (-0.92387953251128674), (-0.38268343236508978), \n  0.19509032201612825, (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524, \n  0.94154406518302081, (-0.33688985339222005), (-0.99879545620517241), (-0.049067674327418015), \n  (-0.14673047445536175), (-0.98917650996478101), (-0.24298017990326387), 0.97003125319454397, \n  0.77301045336273699, (-0.63439328416364549), (-0.95694033573220882), 0.29028467725446233, \n  (-0.47139673682599764), (-0.88192126434835505), 0.098017140329560604, 0.99518472667219693, \n  0.51410274419322166, (-0.85772861000027212), (-0.80320753148064494), 0.59569930449243336, \n  (-0.74095112535495922), (-0.67155895484701833), 0.42755509343028208, 0.90398929312344334, \n  1.0, 0.0, (-0.98078528040323043), (-0.19509032201612825), \n  0.098017140329560604, (-0.99518472667219693), (-0.29028467725446233), 0.95694033573220882, \n  0.93299279883473896, (-0.35989503653498811), (-0.98527764238894122), 0.17096188876030122, \n  (-0.26671275747489837), (-0.96377606579543984), 0.073564563599667426, 0.99729045667869021, \n  0.74095112535495922, (-0.67155895484701833), (-0.85772861000027212), 0.51410274419322166, \n  (-0.59569930449243336), (-0.80320753148064494), 0.42755509343028208, 0.90398929312344334, \n  0.44961132965460654, (-0.89322430119551532), (-0.61523159058062682), 0.78834642762660623, \n  (-0.84485356524970712), (-0.53499761988709715), 0.724247082951467, 0.68954054473706683};\n\nvoid ker_zmddft_fwd_256x256x256_cu0(const double *D3, const double *X, double *P1) {\n  #pragma omp target teams num_teams(16384) thread_limit(64)\n  {\n    double T3[2048];\n    #pragma omp parallel \n    {\n      double a495, a496, a497, a498, a499, a500, a501, a502, \n             s145, s146, s147, s148, s149, s150, s151, s152, \n             s153, s154, s155, s156, s157, s158, s159, s160, \n             s161, s162, s163, s164, s165, s166, s167, s168, \n             s169, s170, s171, s172, s173, s174, s175, s176, \n             s177, s178, s179, s180, s181, s182, s183, s184, \n             s185, s186, s187, s188, s189, s190, s191, s192, \n             t538, t539, t540, t541, t542, t543, t544, t545, \n             t546, t547, t548, t549, t550, t551, t552, t553, \n             t554, t555, t556, t557, t558, t559, t560, t561, \n             t562, t563, t564, t565, t566, t567, t568, t569, \n             t570, t571, t572, t573, t574, t575, t576, t577, \n             t578, t579, t580, t581, t582, t583, t584, t585, \n             t586, t587, t588, t589, t590, t591, t592, t593, \n             t594, t595, t596, t597, t598, t599, t600, t601, \n             t602, t603, t604, t605, t606, t607, t608, t609, \n             t610, t611, t612, t613, t614, t615, t616, t617, \n             t618, t619, t620, t621, t622, t623, t624, t625;\n      int a492, a493, a494, a503;\n      int threadIdx_x = omp_get_thread_num();\n      int blockIdx_x = omp_get_team_num();\n      a492 = (512*(threadIdx_x / 16));  \n\n      a493 = (threadIdx_x % 16); \n\n      a494 = ((2048*blockIdx_x) + a492 + (2*a493));\n      s145 = X[a494];\n      s146 = X[(a494 + 1)];\n      s147 = X[(a494 + 256)];\n      s148 = X[(a494 + 257)];\n      t538 = (s145 + s147);\n      t539 = (s146 + s148);\n      t540 = (s145 - s147);\n      t541 = (s146 - s148);\n      s149 = X[(a494 + 128)];\n      s150 = X[(a494 + 129)];\n      s151 = X[(a494 + 384)];\n      s152 = X[(a494 + 385)];\n      t542 = (s149 + s151);\n      t543 = (s150 + s152);\n      t544 = (s149 - s151);\n      t545 = (s150 - s152);\n      t546 = (t538 + t542);\n      t547 = (t539 + t543);\n      t548 = (t538 - t542);\n      t549 = (t539 - t543);\n      t550 = (t540 + t545);\n      t551 = (t541 - t544);\n      t552 = (t540 - t545);\n      t553 = (t541 + t544);\n      s153 = X[(a494 + 32)];\n      s154 = X[(a494 + 33)];\n      s155 = X[(a494 + 288)];\n      s156 = X[(a494 + 289)];\n      t554 = (s153 + s155);\n      t555 = (s154 + s156);\n      t556 = (s153 - s155);\n      t557 = (s154 - s156);\n      s157 = X[(a494 + 160)];\n      s158 = X[(a494 + 161)];\n      s159 = X[(a494 + 416)];\n      s160 = X[(a494 + 417)];\n      t558 = (s157 + s159);\n      t559 = (s158 + s160);\n      t560 = (s157 - s159);\n      t561 = (s158 - s160);\n      t562 = (t554 + t558);\n      t563 = (t555 + t559);\n      a495 = (0.70710678118654757*(t554 - t558));\n      a496 = (0.70710678118654757*(t555 - t559));\n      s161 = (a495 + a496);\n      s162 = (a496 - a495);\n      t564 = (t556 + t561);\n      t565 = (t557 - t560);\n      t566 = (t556 - t561);\n      t567 = (t557 + t560);\n      s163 = ((0.92387953251128674*t564) + (0.38268343236508978*t565));\n      s164 = ((0.92387953251128674*t565) - (0.38268343236508978*t564));\n      s165 = ((0.38268343236508978*t566) + (0.92387953251128674*t567));\n      s166 = ((0.38268343236508978*t567) - (0.92387953251128674*t566));\n      s167 = X[(a494 + 64)];\n      s168 = X[(a494 + 65)];\n      s169 = X[(a494 + 320)];\n      s170 = X[(a494 + 321)];\n      t568 = (s167 + s169);\n      t569 = (s168 + s170);\n      t570 = (s167 - s169);\n      t571 = (s168 - s170);\n      s171 = X[(a494 + 192)];\n      s172 = X[(a494 + 193)];\n      s173 = X[(a494 + 448)];\n      s174 = X[(a494 + 449)];\n      t572 = (s171 + s173);\n      t573 = (s172 + s174);\n      t574 = (s171 - s173);\n      t575 = (s172 - s174);\n      t576 = (t568 + t572);\n      t577 = (t569 + t573);\n      t578 = (t568 - t572);\n      t579 = (t569 - t573);\n      a497 = (0.70710678118654757*(t570 + t575));\n      a498 = (0.70710678118654757*(t571 - t574));\n      s175 = (a497 + a498);\n      s176 = (a498 - a497);\n      a499 = (0.70710678118654757*(t571 + t574));\n      a500 = (0.70710678118654757*(t570 - t575));\n      s177 = (a499 - a500);\n      s178 = (a500 + a499);\n      s179 = X[(a494 + 96)];\n      s180 = X[(a494 + 97)];\n      s181 = X[(a494 + 352)];\n      s182 = X[(a494 + 353)];\n      t580 = (s179 + s181);\n      t581 = (s180 + s182);\n      t582 = (s179 - s181);\n      t583 = (s180 - s182);\n      s183 = X[(a494 + 224)];\n      s184 = X[(a494 + 225)];\n      s185 = X[(a494 + 480)];\n      s186 = X[(a494 + 481)];\n      t584 = (s183 + s185);\n      t585 = (s184 + s186);\n      t586 = (s183 - s185);\n      t587 = (s184 - s186);\n      t588 = (t580 + t584);\n      t589 = (t581 + t585);\n      a501 = (0.70710678118654757*(t581 - t585));\n      a502 = (0.70710678118654757*(t580 - t584));\n      s187 = (a501 - a502);\n      s188 = (a502 + a501);\n      t590 = (t582 + t587);\n      t591 = (t583 - t586);\n      t592 = (t582 - t587);\n      t593 = (t583 + t586);\n      s189 = ((0.38268343236508978*t590) + (0.92387953251128674*t591));\n      s190 = ((0.38268343236508978*t591) - (0.92387953251128674*t590));\n      s191 = ((0.92387953251128674*t592) + (0.38268343236508978*t593));\n      s192 = ((0.38268343236508978*t592) - (0.92387953251128674*t593));\n      t594 = (t546 + t576);\n      t595 = (t547 + t577);\n      t596 = (t546 - t576);\n      t597 = (t547 - t577);\n      t598 = (t562 + t588);\n      t599 = (t563 + t589);\n      t600 = (t562 - t588);\n      t601 = (t563 - t589);\n      a503 = (a492 + (32*a493));\n      T3[a503] = (t594 + t598);\n      T3[(a503 + 1)] = (t595 + t599);\n      T3[(a503 + 16)] = (t594 - t598);\n      T3[(a503 + 17)] = (t595 - t599);\n      T3[(a503 + 8)] = (t596 + t601);\n      T3[(a503 + 9)] = (t597 - t600);\n      T3[(a503 + 24)] = (t596 - t601);\n      T3[(a503 + 25)] = (t597 + t600);\n      t602 = (t550 + s175);\n      t603 = (t551 + s176);\n      t604 = (t550 - s175);\n      t605 = (t551 - s176);\n      t606 = (s163 + s189);\n      t607 = (s164 + s190);\n      t608 = (s163 - s189);\n      t609 = (s164 - s190);\n      T3[(a503 + 2)] = (t602 + t606);\n      T3[(a503 + 3)] = (t603 + t607);\n      T3[(a503 + 18)] = (t602 - t606);\n      T3[(a503 + 19)] = (t603 - t607);\n      T3[(a503 + 10)] = (t604 + t609);\n      T3[(a503 + 11)] = (t605 - t608);\n      T3[(a503 + 26)] = (t604 - t609);\n      T3[(a503 + 27)] = (t605 + t608);\n      t610 = (t548 + t579);\n      t611 = (t549 - t578);\n      t612 = (t548 - t579);\n      t613 = (t549 + t578);\n      t614 = (s161 + s187);\n      t615 = (s162 - s188);\n      t616 = (s161 - s187);\n      t617 = (s162 + s188);\n      T3[(a503 + 4)] = (t610 + t614);\n      T3[(a503 + 5)] = (t611 + t615);\n      T3[(a503 + 20)] = (t610 - t614);\n      T3[(a503 + 21)] = (t611 - t615);\n      T3[(a503 + 12)] = (t612 + t617);\n      T3[(a503 + 13)] = (t613 - t616);\n      T3[(a503 + 28)] = (t612 - t617);\n      T3[(a503 + 29)] = (t613 + t616);\n      t618 = (t552 + s177);\n      t619 = (t553 - s178);\n      t620 = (t552 - s177);\n      t621 = (t553 + s178);\n      t622 = (s165 - s191);\n      t623 = (s166 + s192);\n      t624 = (s165 + s191);\n      t625 = (s166 - s192);\n      T3[(a503 + 6)] = (t618 + t622);\n      T3[(a503 + 7)] = (t619 + t623);\n      T3[(a503 + 22)] = (t618 - t622);\n      T3[(a503 + 23)] = (t619 - t623);\n      T3[(a503 + 14)] = (t620 + t625);\n      T3[(a503 + 15)] = (t621 - t624);\n      T3[(a503 + 30)] = (t620 - t625);\n      T3[(a503 + 31)] = (t621 + t624);\n      #pragma omp barrier\n      double a1478, a1479, a1480, a1481, a1482, a1483, a1484, a1485, \n             a1486, a1487, a1488, a1489, a1490, a1491, a1492, a1493, \n             a1494, a1495, a1496, a1497, a1498, a1499, a1500, a1501, \n             a1502, a1503, a1504, a1505, a1506, a1507, a1508, a1509, \n             a1510, a1511, a1512, a1513, a1514, a1515, a1516, a1517, \n             s434, s435, s436, s437, s438, s439, s440, s441, \n             s442, s443, s444, s445, s446, s447, s448, s449, \n             s450, s451, s452, s453, s454, s455, s456, s457, \n             s458, s459, s460, s461, s462, s463, s464, s465, \n             s466, s467, s468, s469, s470, s471, s472, s473, \n             s474, s475, s476, s477, s478, s479, s480, s481, \n             s482, s483, s484, s485, s486, s487, s488, s489, \n             s490, s491, s492, s493, s494, s495, s496, s497, \n             s498, s499, s500, s501, s502, s503, s504, s505, \n             s506, s507, s508, s509, s510, s511, s512, s513, \n             t1000, t1001, t1002, t1003, t1004, t1005, t1006, t1007, \n             t1008, t1009, t1010, t1011, t1012, t1013, t1014, t1015, \n             t1016, t1017, t1018, t1019, t1020, t1021, t1022, t1023, \n             t1024, t1025, t1026, t1027, t1028, t1029, t1030, t1031, \n             t1032, t1033, t1034, t1035, t1036, t1037, t1038, t1039, \n             t1040, t1041, t1042, t1043, t1044, t1045, t1046, t1047, \n             t1048, t1049, t1050, t1051, t1052, t1053, t1054, t1055, \n             t1056, t1057, t970, t971, t972, t973, t974, t975, \n             t976, t977, t978, t979, t980, t981, t982, t983, \n             t984, t985, t986, t987, t988, t989, t990, t991, \n             t992, t993, t994, t995, t996, t997, t998, t999;\n      int a1474, a1475, a1476, a1477, a1518;\n      a1474 = (threadIdx_x / 16);\n      a1475 = (threadIdx_x % 16);\n      a1476 = ((512*a1474) + (2*a1475));\n      s434 = T3[a1476];\n      s435 = T3[(a1476 + 1)];\n      s436 = T3[(a1476 + 256)];\n      s437 = T3[(a1476 + 257)];\n      a1477 = (32*a1475);\n      a1478 = D3[a1477];\n      a1479 = D3[(a1477 + 1)];\n      s438 = ((a1478*s434) - (a1479*s435));\n      s439 = ((a1479*s434) + (a1478*s435));\n      a1480 = D3[(a1477 + 2)];\n      a1481 = D3[(a1477 + 3)];\n      s440 = ((a1480*s436) - (a1481*s437));\n      s441 = ((a1481*s436) + (a1480*s437));\n      t970 = (s438 + s440);\n      t971 = (s439 + s441);\n      t972 = (s438 - s440);\n      t973 = (s439 - s441);\n      s442 = T3[(a1476 + 128)];\n      s443 = T3[(a1476 + 129)];\n      s444 = T3[(a1476 + 384)];\n      s445 = T3[(a1476 + 385)];\n      a1482 = D3[(4 + a1477)];\n      a1483 = D3[(5 + a1477)];\n      s446 = ((a1482*s442) - (a1483*s443));\n      s447 = ((a1483*s442) + (a1482*s443));\n      a1484 = D3[(6 + a1477)];\n      a1485 = D3[(7 + a1477)];\n      s448 = ((a1484*s444) - (a1485*s445));\n      s449 = ((a1485*s444) + (a1484*s445));\n      t974 = (s446 + s448);\n      t975 = (s447 + s449);\n      t976 = (s446 - s448);\n      t977 = (s447 - s449);\n      t978 = (t970 + t974);\n      t979 = (t971 + t975);\n      t980 = (t970 - t974);\n      t981 = (t971 - t975);\n      t982 = (t972 + t977);\n      t983 = (t973 - t976);\n      t984 = (t972 - t977);\n      t985 = (t973 + t976);\n      s450 = T3[(a1476 + 32)];\n      s451 = T3[(a1476 + 33)];\n      s452 = T3[(a1476 + 288)];\n      s453 = T3[(a1476 + 289)];\n      a1486 = D3[(a1477 + 8)];\n      a1487 = D3[(9 + a1477)];\n      s454 = ((a1486*s450) - (a1487*s451));\n      s455 = ((a1487*s450) + (a1486*s451));\n      a1488 = D3[(10 + a1477)];\n      a1489 = D3[(11 + a1477)];\n      s456 = ((a1488*s452) - (a1489*s453));\n      s457 = ((a1489*s452) + (a1488*s453));\n      t986 = (s454 + s456);\n      t987 = (s455 + s457);\n      t988 = (s454 - s456);\n      t989 = (s455 - s457);\n      s458 = T3[(a1476 + 160)];\n      s459 = T3[(a1476 + 161)];\n      s460 = T3[(a1476 + 416)];\n      s461 = T3[(a1476 + 417)];\n      a1490 = D3[(12 + a1477)];\n      a1491 = D3[(13 + a1477)];\n      s462 = ((a1490*s458) - (a1491*s459));\n      s463 = ((a1491*s458) + (a1490*s459));\n      a1492 = D3[(14 + a1477)];\n      a1493 = D3[(15 + a1477)];\n      s464 = ((a1492*s460) - (a1493*s461));\n      s465 = ((a1493*s460) + (a1492*s461));\n      t990 = (s462 + s464);\n      t991 = (s463 + s465);\n      t992 = (s462 - s464);\n      t993 = (s463 - s465);\n      t994 = (t986 + t990);\n      t995 = (t987 + t991);\n      a1494 = (0.70710678118654757*(t986 - t990));\n      a1495 = (0.70710678118654757*(t987 - t991));\n      s466 = (a1494 + a1495);\n      s467 = (a1495 - a1494);\n      t996 = (t988 + t993);\n      t997 = (t989 - t992);\n      t998 = (t988 - t993);\n      t999 = (t989 + t992);\n      s468 = ((0.92387953251128674*t996) + (0.38268343236508978*t997));\n      s469 = ((0.92387953251128674*t997) - (0.38268343236508978*t996));\n      s470 = ((0.38268343236508978*t998) + (0.92387953251128674*t999));\n      s471 = ((0.38268343236508978*t999) - (0.92387953251128674*t998));\n      s472 = T3[(a1476 + 64)];\n      s473 = T3[(a1476 + 65)];\n      s474 = T3[(a1476 + 320)];\n      s475 = T3[(a1476 + 321)];\n      a1496 = D3[(a1477 + 16)];\n      a1497 = D3[(17 + a1477)];\n      s476 = ((a1496*s472) - (a1497*s473));\n      s477 = ((a1497*s472) + (a1496*s473));\n      a1498 = D3[(18 + a1477)];\n      a1499 = D3[(19 + a1477)];\n      s478 = ((a1498*s474) - (a1499*s475));\n      s479 = ((a1499*s474) + (a1498*s475));\n      t1000 = (s476 + s478);\n      t1001 = (s477 + s479);\n      t1002 = (s476 - s478);\n      t1003 = (s477 - s479);\n      s480 = T3[(a1476 + 192)];\n      s481 = T3[(a1476 + 193)];\n      s482 = T3[(a1476 + 448)];\n      s483 = T3[(a1476 + 449)];\n      a1500 = D3[(20 + a1477)];\n      a1501 = D3[(21 + a1477)];\n      s484 = ((a1500*s480) - (a1501*s481));\n      s485 = ((a1501*s480) + (a1500*s481));\n      a1502 = D3[(22 + a1477)];\n      a1503 = D3[(23 + a1477)];\n      s486 = ((a1502*s482) - (a1503*s483));\n      s487 = ((a1503*s482) + (a1502*s483));\n      t1004 = (s484 + s486);\n      t1005 = (s485 + s487);\n      t1006 = (s484 - s486);\n      t1007 = (s485 - s487);\n      t1008 = (t1000 + t1004);\n      t1009 = (t1001 + t1005);\n      t1010 = (t1000 - t1004);\n      t1011 = (t1001 - t1005);\n      a1504 = (0.70710678118654757*(t1002 + t1007));\n      a1505 = (0.70710678118654757*(t1003 - t1006));\n      s488 = (a1504 + a1505);\n      s489 = (a1505 - a1504);\n      a1506 = (0.70710678118654757*(t1003 + t1006));\n      a1507 = (0.70710678118654757*(t1002 - t1007));\n      s490 = (a1506 - a1507);\n      s491 = (a1507 + a1506);\n      s492 = T3[(a1476 + 96)];\n      s493 = T3[(a1476 + 97)];\n      s494 = T3[(a1476 + 352)];\n      s495 = T3[(a1476 + 353)];\n      a1508 = D3[(a1477 + 24)];\n      a1509 = D3[(25 + a1477)];\n      s496 = ((a1508*s492) - (a1509*s493));\n      s497 = ((a1509*s492) + (a1508*s493));\n      a1510 = D3[(26 + a1477)];\n      a1511 = D3[(27 + a1477)];\n      s498 = ((a1510*s494) - (a1511*s495));\n      s499 = ((a1511*s494) + (a1510*s495));\n      t1012 = (s496 + s498);\n      t1013 = (s497 + s499);\n      t1014 = (s496 - s498);\n      t1015 = (s497 - s499);\n      s500 = T3[(a1476 + 224)];\n      s501 = T3[(a1476 + 225)];\n      s502 = T3[(a1476 + 480)];\n      s503 = T3[(a1476 + 481)];\n      a1512 = D3[(28 + a1477)];\n      a1513 = D3[(29 + a1477)];\n      s504 = ((a1512*s500) - (a1513*s501));\n      s505 = ((a1513*s500) + (a1512*s501));\n      a1514 = D3[(30 + a1477)];\n      a1515 = D3[(31 + a1477)];\n      s506 = ((a1514*s502) - (a1515*s503));\n      s507 = ((a1515*s502) + (a1514*s503));\n      t1016 = (s504 + s506);\n      t1017 = (s505 + s507);\n      t1018 = (s504 - s506);\n      t1019 = (s505 - s507);\n      t1020 = (t1012 + t1016);\n      t1021 = (t1013 + t1017);\n      a1516 = (0.70710678118654757*(t1013 - t1017));\n      a1517 = (0.70710678118654757*(t1012 - t1016));\n      s508 = (a1516 - a1517);\n      s509 = (a1517 + a1516);\n      t1022 = (t1014 + t1019);\n      t1023 = (t1015 - t1018);\n      t1024 = (t1014 - t1019);\n      t1025 = (t1015 + t1018);\n      s510 = ((0.38268343236508978*t1022) + (0.92387953251128674*t1023));\n      s511 = ((0.38268343236508978*t1023) - (0.92387953251128674*t1022));\n      s512 = ((0.92387953251128674*t1024) + (0.38268343236508978*t1025));\n      s513 = ((0.38268343236508978*t1024) - (0.92387953251128674*t1025));\n      t1026 = (t978 + t1008);\n      t1027 = (t979 + t1009);\n      t1028 = (t978 - t1008);\n      t1029 = (t979 - t1009);\n      t1030 = (t994 + t1020);\n      t1031 = (t995 + t1021);\n      t1032 = (t994 - t1020);\n      t1033 = (t995 - t1021);\n      a1518 = ((8*blockIdx_x) + (131072*a1475) + (2*a1474));\n      P1[a1518] = (t1026 + t1030);\n      P1[(a1518 + 1)] = (t1027 + t1031);\n      P1[(a1518 + 16777216)] = (t1026 - t1030);\n      P1[(a1518 + 16777217)] = (t1027 - t1031);\n      P1[(a1518 + 8388608)] = (t1028 + t1033);\n      P1[(a1518 + 8388609)] = (t1029 - t1032);\n      P1[(a1518 + 25165824)] = (t1028 - t1033);\n      P1[(a1518 + 25165825)] = (t1029 + t1032);\n      t1034 = (t982 + s488);\n      t1035 = (t983 + s489);\n      t1036 = (t982 - s488);\n      t1037 = (t983 - s489);\n      t1038 = (s468 + s510);\n      t1039 = (s469 + s511);\n      t1040 = (s468 - s510);\n      t1041 = (s469 - s511);\n      P1[(a1518 + 2097152)] = (t1034 + t1038);\n      P1[(a1518 + 2097153)] = (t1035 + t1039);\n      P1[(a1518 + 18874368)] = (t1034 - t1038);\n      P1[(a1518 + 18874369)] = (t1035 - t1039);\n      P1[(a1518 + 10485760)] = (t1036 + t1041);\n      P1[(a1518 + 10485761)] = (t1037 - t1040);\n      P1[(a1518 + 27262976)] = (t1036 - t1041);\n      P1[(a1518 + 27262977)] = (t1037 + t1040);\n      t1042 = (t980 + t1011);\n      t1043 = (t981 - t1010);\n      t1044 = (t980 - t1011);\n      t1045 = (t981 + t1010);\n      t1046 = (s466 + s508);\n      t1047 = (s467 - s509);\n      t1048 = (s466 - s508);\n      t1049 = (s467 + s509);\n      P1[(a1518 + 4194304)] = (t1042 + t1046);\n      P1[(a1518 + 4194305)] = (t1043 + t1047);\n      P1[(a1518 + 20971520)] = (t1042 - t1046);\n      P1[(a1518 + 20971521)] = (t1043 - t1047);\n      P1[(a1518 + 12582912)] = (t1044 + t1049);\n      P1[(a1518 + 12582913)] = (t1045 - t1048);\n      P1[(a1518 + 29360128)] = (t1044 - t1049);\n      P1[(a1518 + 29360129)] = (t1045 + t1048);\n      t1050 = (t984 + s490);\n      t1051 = (t985 - s491);\n      t1052 = (t984 - s490);\n      t1053 = (t985 + s491);\n      t1054 = (s470 - s512);\n      t1055 = (s471 + s513);\n      t1056 = (s470 + s512);\n      t1057 = (s471 - s513);\n      P1[(a1518 + 6291456)] = (t1050 + t1054);\n      P1[(a1518 + 6291457)] = (t1051 + t1055);\n      P1[(a1518 + 23068672)] = (t1050 - t1054);\n      P1[(a1518 + 23068673)] = (t1051 - t1055);\n      P1[(a1518 + 14680064)] = (t1052 + t1057);\n      P1[(a1518 + 14680065)] = (t1053 - t1056);\n      P1[(a1518 + 31457280)] = (t1052 - t1057);\n      P1[(a1518 + 31457281)] = (t1053 + t1056);\n      #pragma omp barrier\n    }\n  }\n}\n\nvoid ker_zmddft_fwd_256x256x256_cu1(const double *D3, const double *P1, double *P2)\n{\n  #pragma omp target teams num_teams(16384) thread_limit(64)\n  {\n    double T33[2048];\n    #pragma omp parallel \n    {\n      double a2012, a2013, a2014, a2015, a2016, a2017, a2018, a2019, \n             s658, s659, s660, s661, s662, s663, s664, s665, \n             s666, s667, s668, s669, s670, s671, s672, s673, \n             s674, s675, s676, s677, s678, s679, s680, s681, \n             s682, s683, s684, s685, s686, s687, s688, s689, \n             s690, s691, s692, s693, s694, s695, s696, s697, \n             s698, s699, s700, s701, s702, s703, s704, s705, \n             t1402, t1403, t1404, t1405, t1406, t1407, t1408, t1409, \n             t1410, t1411, t1412, t1413, t1414, t1415, t1416, t1417, \n             t1418, t1419, t1420, t1421, t1422, t1423, t1424, t1425, \n             t1426, t1427, t1428, t1429, t1430, t1431, t1432, t1433, \n             t1434, t1435, t1436, t1437, t1438, t1439, t1440, t1441, \n             t1442, t1443, t1444, t1445, t1446, t1447, t1448, t1449, \n             t1450, t1451, t1452, t1453, t1454, t1455, t1456, t1457, \n             t1458, t1459, t1460, t1461, t1462, t1463, t1464, t1465, \n             t1466, t1467, t1468, t1469, t1470, t1471, t1472, t1473, \n             t1474, t1475, t1476, t1477, t1478, t1479, t1480, t1481, \n             t1482, t1483, t1484, t1485, t1486, t1487, t1488, t1489;\n      int a2009, a2010, a2011, a2020;\n      int threadIdx_x = omp_get_thread_num();\n      int blockIdx_x = omp_get_team_num();\n      a2009 = (512*(threadIdx_x / 16));\n      a2010 = (threadIdx_x % 16);\n      a2011 = ((2048*blockIdx_x) + a2009 + (2*a2010));\n      s658 = P1[a2011];\n      s659 = P1[(a2011 + 1)];\n      s660 = P1[(a2011 + 256)];\n      s661 = P1[(a2011 + 257)];\n      t1402 = (s658 + s660);\n      t1403 = (s659 + s661);\n      t1404 = (s658 - s660);\n      t1405 = (s659 - s661);\n      s662 = P1[(a2011 + 128)];\n      s663 = P1[(a2011 + 129)];\n      s664 = P1[(a2011 + 384)];\n      s665 = P1[(a2011 + 385)];\n      t1406 = (s662 + s664);\n      t1407 = (s663 + s665);\n      t1408 = (s662 - s664);\n      t1409 = (s663 - s665);\n      t1410 = (t1402 + t1406);\n      t1411 = (t1403 + t1407);\n      t1412 = (t1402 - t1406);\n      t1413 = (t1403 - t1407);\n      t1414 = (t1404 + t1409);\n      t1415 = (t1405 - t1408);\n      t1416 = (t1404 - t1409);\n      t1417 = (t1405 + t1408);\n      s666 = P1[(a2011 + 32)];\n      s667 = P1[(a2011 + 33)];\n      s668 = P1[(a2011 + 288)];\n      s669 = P1[(a2011 + 289)];\n      t1418 = (s666 + s668);\n      t1419 = (s667 + s669);\n      t1420 = (s666 - s668);\n      t1421 = (s667 - s669);\n      s670 = P1[(a2011 + 160)];\n      s671 = P1[(a2011 + 161)];\n      s672 = P1[(a2011 + 416)];\n      s673 = P1[(a2011 + 417)];\n      t1422 = (s670 + s672);\n      t1423 = (s671 + s673);\n      t1424 = (s670 - s672);\n      t1425 = (s671 - s673);\n      t1426 = (t1418 + t1422);\n      t1427 = (t1419 + t1423);\n      a2012 = (0.70710678118654757*(t1418 - t1422));\n      a2013 = (0.70710678118654757*(t1419 - t1423));\n      s674 = (a2012 + a2013);\n      s675 = (a2013 - a2012);\n      t1428 = (t1420 + t1425);\n      t1429 = (t1421 - t1424);\n      t1430 = (t1420 - t1425);\n      t1431 = (t1421 + t1424);\n      s676 = ((0.92387953251128674*t1428) + (0.38268343236508978*t1429));\n      s677 = ((0.92387953251128674*t1429) - (0.38268343236508978*t1428));\n      s678 = ((0.38268343236508978*t1430) + (0.92387953251128674*t1431));\n      s679 = ((0.38268343236508978*t1431) - (0.92387953251128674*t1430));\n      s680 = P1[(a2011 + 64)];\n      s681 = P1[(a2011 + 65)];\n      s682 = P1[(a2011 + 320)];\n      s683 = P1[(a2011 + 321)];\n      t1432 = (s680 + s682);\n      t1433 = (s681 + s683);\n      t1434 = (s680 - s682);\n      t1435 = (s681 - s683);\n      s684 = P1[(a2011 + 192)];\n      s685 = P1[(a2011 + 193)];\n      s686 = P1[(a2011 + 448)];\n      s687 = P1[(a2011 + 449)];\n      t1436 = (s684 + s686);\n      t1437 = (s685 + s687);\n      t1438 = (s684 - s686);\n      t1439 = (s685 - s687);\n      t1440 = (t1432 + t1436);\n      t1441 = (t1433 + t1437);\n      t1442 = (t1432 - t1436);\n      t1443 = (t1433 - t1437);\n      a2014 = (0.70710678118654757*(t1434 + t1439));\n      a2015 = (0.70710678118654757*(t1435 - t1438));\n      s688 = (a2014 + a2015);\n      s689 = (a2015 - a2014);\n      a2016 = (0.70710678118654757*(t1435 + t1438));\n      a2017 = (0.70710678118654757*(t1434 - t1439));\n      s690 = (a2016 - a2017);\n      s691 = (a2017 + a2016);\n      s692 = P1[(a2011 + 96)];\n      s693 = P1[(a2011 + 97)];\n      s694 = P1[(a2011 + 352)];\n      s695 = P1[(a2011 + 353)];\n      t1444 = (s692 + s694);\n      t1445 = (s693 + s695);\n      t1446 = (s692 - s694);\n      t1447 = (s693 - s695);\n      s696 = P1[(a2011 + 224)];\n      s697 = P1[(a2011 + 225)];\n      s698 = P1[(a2011 + 480)];\n      s699 = P1[(a2011 + 481)];\n      t1448 = (s696 + s698);\n      t1449 = (s697 + s699);\n      t1450 = (s696 - s698);\n      t1451 = (s697 - s699);\n      t1452 = (t1444 + t1448);\n      t1453 = (t1445 + t1449);\n      a2018 = (0.70710678118654757*(t1445 - t1449));\n      a2019 = (0.70710678118654757*(t1444 - t1448));\n      s700 = (a2018 - a2019);\n      s701 = (a2019 + a2018);\n      t1454 = (t1446 + t1451);\n      t1455 = (t1447 - t1450);\n      t1456 = (t1446 - t1451);\n      t1457 = (t1447 + t1450);\n      s702 = ((0.38268343236508978*t1454) + (0.92387953251128674*t1455));\n      s703 = ((0.38268343236508978*t1455) - (0.92387953251128674*t1454));\n      s704 = ((0.92387953251128674*t1456) + (0.38268343236508978*t1457));\n      s705 = ((0.38268343236508978*t1456) - (0.92387953251128674*t1457));\n      t1458 = (t1410 + t1440);\n      t1459 = (t1411 + t1441);\n      t1460 = (t1410 - t1440);\n      t1461 = (t1411 - t1441);\n      t1462 = (t1426 + t1452);\n      t1463 = (t1427 + t1453);\n      t1464 = (t1426 - t1452);\n      t1465 = (t1427 - t1453);\n      a2020 = (a2009 + (32*a2010));\n      T33[a2020] = (t1458 + t1462);\n      T33[(a2020 + 1)] = (t1459 + t1463);\n      T33[(a2020 + 16)] = (t1458 - t1462);\n      T33[(a2020 + 17)] = (t1459 - t1463);\n      T33[(a2020 + 8)] = (t1460 + t1465);\n      T33[(a2020 + 9)] = (t1461 - t1464);\n      T33[(a2020 + 24)] = (t1460 - t1465);\n      T33[(a2020 + 25)] = (t1461 + t1464);\n      t1466 = (t1414 + s688);\n      t1467 = (t1415 + s689);\n      t1468 = (t1414 - s688);\n      t1469 = (t1415 - s689);\n      t1470 = (s676 + s702);\n      t1471 = (s677 + s703);\n      t1472 = (s676 - s702);\n      t1473 = (s677 - s703);\n      T33[(a2020 + 2)] = (t1466 + t1470);\n      T33[(a2020 + 3)] = (t1467 + t1471);\n      T33[(a2020 + 18)] = (t1466 - t1470);\n      T33[(a2020 + 19)] = (t1467 - t1471);\n      T33[(a2020 + 10)] = (t1468 + t1473);\n      T33[(a2020 + 11)] = (t1469 - t1472);\n      T33[(a2020 + 26)] = (t1468 - t1473);\n      T33[(a2020 + 27)] = (t1469 + t1472);\n      t1474 = (t1412 + t1443);\n      t1475 = (t1413 - t1442);\n      t1476 = (t1412 - t1443);\n      t1477 = (t1413 + t1442);\n      t1478 = (s674 + s700);\n      t1479 = (s675 - s701);\n      t1480 = (s674 - s700);\n      t1481 = (s675 + s701);\n      T33[(a2020 + 4)] = (t1474 + t1478);\n      T33[(a2020 + 5)] = (t1475 + t1479);\n      T33[(a2020 + 20)] = (t1474 - t1478);\n      T33[(a2020 + 21)] = (t1475 - t1479);\n      T33[(a2020 + 12)] = (t1476 + t1481);\n      T33[(a2020 + 13)] = (t1477 - t1480);\n      T33[(a2020 + 28)] = (t1476 - t1481);\n      T33[(a2020 + 29)] = (t1477 + t1480);\n      t1482 = (t1416 + s690);\n      t1483 = (t1417 - s691);\n      t1484 = (t1416 - s690);\n      t1485 = (t1417 + s691);\n      t1486 = (s678 - s704);\n      t1487 = (s679 + s705);\n      t1488 = (s678 + s704);\n      t1489 = (s679 - s705);\n      T33[(a2020 + 6)] = (t1482 + t1486);\n      T33[(a2020 + 7)] = (t1483 + t1487);\n      T33[(a2020 + 22)] = (t1482 - t1486);\n      T33[(a2020 + 23)] = (t1483 - t1487);\n      T33[(a2020 + 14)] = (t1484 + t1489);\n      T33[(a2020 + 15)] = (t1485 - t1488);\n      T33[(a2020 + 30)] = (t1484 - t1489);\n      T33[(a2020 + 31)] = (t1485 + t1488);\n      #pragma omp barrier\n      double a2995, a2996, a2997, a2998, a2999, a3000, a3001, a3002, \n             a3003, a3004, a3005, a3006, a3007, a3008, a3009, a3010, \n             a3011, a3012, a3013, a3014, a3015, a3016, a3017, a3018, \n             a3019, a3020, a3021, a3022, a3023, a3024, a3025, a3026, \n             a3027, a3028, a3029, a3030, a3031, a3032, a3033, a3034, \n             s1000, s1001, s1002, s1003, s1004, s1005, s1006, s1007, \n             s1008, s1009, s1010, s1011, s1012, s1013, s1014, s1015, \n             s1016, s1017, s1018, s1019, s1020, s1021, s1022, s1023, \n             s1024, s1025, s946, s947, s948, s949, s950, s951, \n             s952, s953, s954, s955, s956, s957, s958, s959, \n             s960, s961, s962, s963, s964, s965, s966, s967, \n             s968, s969, s970, s971, s972, s973, s974, s975, \n             s976, s977, s978, s979, s980, s981, s982, s983, \n             s984, s985, s986, s987, s988, s989, s990, s991, \n             s992, s993, s994, s995, s996, s997, s998, s999, \n             t1834, t1835, t1836, t1837, t1838, t1839, t1840, t1841, \n             t1842, t1843, t1844, t1845, t1846, t1847, t1848, t1849, \n             t1850, t1851, t1852, t1853, t1854, t1855, t1856, t1857, \n             t1858, t1859, t1860, t1861, t1862, t1863, t1864, t1865, \n             t1866, t1867, t1868, t1869, t1870, t1871, t1872, t1873, \n             t1874, t1875, t1876, t1877, t1878, t1879, t1880, t1881, \n             t1882, t1883, t1884, t1885, t1886, t1887, t1888, t1889, \n             t1890, t1891, t1892, t1893, t1894, t1895, t1896, t1897, \n             t1898, t1899, t1900, t1901, t1902, t1903, t1904, t1905, \n             t1906, t1907, t1908, t1909, t1910, t1911, t1912, t1913, \n             t1914, t1915, t1916, t1917, t1918, t1919, t1920, t1921;\n      int a2991, a2992, a2993, a2994, a3035;\n      a2991 = (threadIdx_x / 16);\n      a2992 = (threadIdx_x % 16);\n      a2993 = ((512*a2991) + (2*a2992));\n      s946 = T33[a2993];\n      s947 = T33[(a2993 + 1)];\n      s948 = T33[(a2993 + 256)];\n      s949 = T33[(a2993 + 257)];\n      a2994 = (32*a2992);\n      a2995 = D3[a2994];\n      a2996 = D3[(a2994 + 1)];\n      s950 = ((a2995*s946) - (a2996*s947));\n      s951 = ((a2996*s946) + (a2995*s947));\n      a2997 = D3[(a2994 + 2)];\n      a2998 = D3[(a2994 + 3)];\n      s952 = ((a2997*s948) - (a2998*s949));\n      s953 = ((a2998*s948) + (a2997*s949));\n      t1834 = (s950 + s952);\n      t1835 = (s951 + s953);\n      t1836 = (s950 - s952);\n      t1837 = (s951 - s953);\n      s954 = T33[(a2993 + 128)];\n      s955 = T33[(a2993 + 129)];\n      s956 = T33[(a2993 + 384)];\n      s957 = T33[(a2993 + 385)];\n      a2999 = D3[(4 + a2994)];\n      a3000 = D3[(5 + a2994)];\n      s958 = ((a2999*s954) - (a3000*s955));\n      s959 = ((a3000*s954) + (a2999*s955));\n      a3001 = D3[(6 + a2994)];\n      a3002 = D3[(7 + a2994)];\n      s960 = ((a3001*s956) - (a3002*s957));\n      s961 = ((a3002*s956) + (a3001*s957));\n      t1838 = (s958 + s960);\n      t1839 = (s959 + s961);\n      t1840 = (s958 - s960);\n      t1841 = (s959 - s961);\n      t1842 = (t1834 + t1838);\n      t1843 = (t1835 + t1839);\n      t1844 = (t1834 - t1838);\n      t1845 = (t1835 - t1839);\n      t1846 = (t1836 + t1841);\n      t1847 = (t1837 - t1840);\n      t1848 = (t1836 - t1841);\n      t1849 = (t1837 + t1840);\n      s962 = T33[(a2993 + 32)];\n      s963 = T33[(a2993 + 33)];\n      s964 = T33[(a2993 + 288)];\n      s965 = T33[(a2993 + 289)];\n      a3003 = D3[(a2994 + 8)];\n      a3004 = D3[(9 + a2994)];\n      s966 = ((a3003*s962) - (a3004*s963));\n      s967 = ((a3004*s962) + (a3003*s963));\n      a3005 = D3[(10 + a2994)];\n      a3006 = D3[(11 + a2994)];\n      s968 = ((a3005*s964) - (a3006*s965));\n      s969 = ((a3006*s964) + (a3005*s965));\n      t1850 = (s966 + s968);\n      t1851 = (s967 + s969);\n      t1852 = (s966 - s968);\n      t1853 = (s967 - s969);\n      s970 = T33[(a2993 + 160)];\n      s971 = T33[(a2993 + 161)];\n      s972 = T33[(a2993 + 416)];\n      s973 = T33[(a2993 + 417)];\n      a3007 = D3[(12 + a2994)];\n      a3008 = D3[(13 + a2994)];\n      s974 = ((a3007*s970) - (a3008*s971));\n      s975 = ((a3008*s970) + (a3007*s971));\n      a3009 = D3[(14 + a2994)];\n      a3010 = D3[(15 + a2994)];\n      s976 = ((a3009*s972) - (a3010*s973));\n      s977 = ((a3010*s972) + (a3009*s973));\n      t1854 = (s974 + s976);\n      t1855 = (s975 + s977);\n      t1856 = (s974 - s976);\n      t1857 = (s975 - s977);\n      t1858 = (t1850 + t1854);\n      t1859 = (t1851 + t1855);\n      a3011 = (0.70710678118654757*(t1850 - t1854));\n      a3012 = (0.70710678118654757*(t1851 - t1855));\n      s978 = (a3011 + a3012);\n      s979 = (a3012 - a3011);\n      t1860 = (t1852 + t1857);\n      t1861 = (t1853 - t1856);\n      t1862 = (t1852 - t1857);\n      t1863 = (t1853 + t1856);\n      s980 = ((0.92387953251128674*t1860) + (0.38268343236508978*t1861));\n      s981 = ((0.92387953251128674*t1861) - (0.38268343236508978*t1860));\n      s982 = ((0.38268343236508978*t1862) + (0.92387953251128674*t1863));\n      s983 = ((0.38268343236508978*t1863) - (0.92387953251128674*t1862));\n      s984 = T33[(a2993 + 64)];\n      s985 = T33[(a2993 + 65)];\n      s986 = T33[(a2993 + 320)];\n      s987 = T33[(a2993 + 321)];\n      a3013 = D3[(a2994 + 16)];\n      a3014 = D3[(17 + a2994)];\n      s988 = ((a3013*s984) - (a3014*s985));\n      s989 = ((a3014*s984) + (a3013*s985));\n      a3015 = D3[(18 + a2994)];\n      a3016 = D3[(19 + a2994)];\n      s990 = ((a3015*s986) - (a3016*s987));\n      s991 = ((a3016*s986) + (a3015*s987));\n      t1864 = (s988 + s990);\n      t1865 = (s989 + s991);\n      t1866 = (s988 - s990);\n      t1867 = (s989 - s991);\n      s992 = T33[(a2993 + 192)];\n      s993 = T33[(a2993 + 193)];\n      s994 = T33[(a2993 + 448)];\n      s995 = T33[(a2993 + 449)];\n      a3017 = D3[(20 + a2994)];\n      a3018 = D3[(21 + a2994)];\n      s996 = ((a3017*s992) - (a3018*s993));\n      s997 = ((a3018*s992) + (a3017*s993));\n      a3019 = D3[(22 + a2994)];\n      a3020 = D3[(23 + a2994)];\n      s998 = ((a3019*s994) - (a3020*s995));\n      s999 = ((a3020*s994) + (a3019*s995));\n      t1868 = (s996 + s998);\n      t1869 = (s997 + s999);\n      t1870 = (s996 - s998);\n      t1871 = (s997 - s999);\n      t1872 = (t1864 + t1868);\n      t1873 = (t1865 + t1869);\n      t1874 = (t1864 - t1868);\n      t1875 = (t1865 - t1869);\n      a3021 = (0.70710678118654757*(t1866 + t1871));\n      a3022 = (0.70710678118654757*(t1867 - t1870));\n      s1000 = (a3021 + a3022);\n      s1001 = (a3022 - a3021);\n      a3023 = (0.70710678118654757*(t1867 + t1870));\n      a3024 = (0.70710678118654757*(t1866 - t1871));\n      s1002 = (a3023 - a3024);\n      s1003 = (a3024 + a3023);\n      s1004 = T33[(a2993 + 96)];\n      s1005 = T33[(a2993 + 97)];\n      s1006 = T33[(a2993 + 352)];\n      s1007 = T33[(a2993 + 353)];\n      a3025 = D3[(a2994 + 24)];\n      a3026 = D3[(25 + a2994)];\n      s1008 = ((a3025*s1004) - (a3026*s1005));\n      s1009 = ((a3026*s1004) + (a3025*s1005));\n      a3027 = D3[(26 + a2994)];\n      a3028 = D3[(27 + a2994)];\n      s1010 = ((a3027*s1006) - (a3028*s1007));\n      s1011 = ((a3028*s1006) + (a3027*s1007));\n      t1876 = (s1008 + s1010);\n      t1877 = (s1009 + s1011);\n      t1878 = (s1008 - s1010);\n      t1879 = (s1009 - s1011);\n      s1012 = T33[(a2993 + 224)];\n      s1013 = T33[(a2993 + 225)];\n      s1014 = T33[(a2993 + 480)];\n      s1015 = T33[(a2993 + 481)];\n      a3029 = D3[(28 + a2994)];\n      a3030 = D3[(29 + a2994)];\n      s1016 = ((a3029*s1012) - (a3030*s1013));\n      s1017 = ((a3030*s1012) + (a3029*s1013));\n      a3031 = D3[(30 + a2994)];\n      a3032 = D3[(31 + a2994)];\n      s1018 = ((a3031*s1014) - (a3032*s1015));\n      s1019 = ((a3032*s1014) + (a3031*s1015));\n      t1880 = (s1016 + s1018);\n      t1881 = (s1017 + s1019);\n      t1882 = (s1016 - s1018);\n      t1883 = (s1017 - s1019);\n      t1884 = (t1876 + t1880);\n      t1885 = (t1877 + t1881);\n      a3033 = (0.70710678118654757*(t1877 - t1881));\n      a3034 = (0.70710678118654757*(t1876 - t1880));\n      s1020 = (a3033 - a3034);\n      s1021 = (a3034 + a3033);\n      t1886 = (t1878 + t1883);\n      t1887 = (t1879 - t1882);\n      t1888 = (t1878 - t1883);\n      t1889 = (t1879 + t1882);\n      s1022 = ((0.38268343236508978*t1886) + (0.92387953251128674*t1887));\n      s1023 = ((0.38268343236508978*t1887) - (0.92387953251128674*t1886));\n      s1024 = ((0.92387953251128674*t1888) + (0.38268343236508978*t1889));\n      s1025 = ((0.38268343236508978*t1888) - (0.92387953251128674*t1889));\n      t1890 = (t1842 + t1872);\n      t1891 = (t1843 + t1873);\n      t1892 = (t1842 - t1872);\n      t1893 = (t1843 - t1873);\n      t1894 = (t1858 + t1884);\n      t1895 = (t1859 + t1885);\n      t1896 = (t1858 - t1884);\n      t1897 = (t1859 - t1885);\n      a3035 = ((8*blockIdx_x) + (131072*a2992) + (2*a2991));\n      P2[a3035] = (t1890 + t1894);\n      P2[(a3035 + 1)] = (t1891 + t1895);\n      P2[(a3035 + 16777216)] = (t1890 - t1894);\n      P2[(a3035 + 16777217)] = (t1891 - t1895);\n      P2[(a3035 + 8388608)] = (t1892 + t1897);\n      P2[(a3035 + 8388609)] = (t1893 - t1896);\n      P2[(a3035 + 25165824)] = (t1892 - t1897);\n      P2[(a3035 + 25165825)] = (t1893 + t1896);\n      t1898 = (t1846 + s1000);\n      t1899 = (t1847 + s1001);\n      t1900 = (t1846 - s1000);\n      t1901 = (t1847 - s1001);\n      t1902 = (s980 + s1022);\n      t1903 = (s981 + s1023);\n      t1904 = (s980 - s1022);\n      t1905 = (s981 - s1023);\n      P2[(a3035 + 2097152)] = (t1898 + t1902);\n      P2[(a3035 + 2097153)] = (t1899 + t1903);\n      P2[(a3035 + 18874368)] = (t1898 - t1902);\n      P2[(a3035 + 18874369)] = (t1899 - t1903);\n      P2[(a3035 + 10485760)] = (t1900 + t1905);\n      P2[(a3035 + 10485761)] = (t1901 - t1904);\n      P2[(a3035 + 27262976)] = (t1900 - t1905);\n      P2[(a3035 + 27262977)] = (t1901 + t1904);\n      t1906 = (t1844 + t1875);\n      t1907 = (t1845 - t1874);\n      t1908 = (t1844 - t1875);\n      t1909 = (t1845 + t1874);\n      t1910 = (s978 + s1020);\n      t1911 = (s979 - s1021);\n      t1912 = (s978 - s1020);\n      t1913 = (s979 + s1021);\n      P2[(a3035 + 4194304)] = (t1906 + t1910);\n      P2[(a3035 + 4194305)] = (t1907 + t1911);\n      P2[(a3035 + 20971520)] = (t1906 - t1910);\n      P2[(a3035 + 20971521)] = (t1907 - t1911);\n      P2[(a3035 + 12582912)] = (t1908 + t1913);\n      P2[(a3035 + 12582913)] = (t1909 - t1912);\n      P2[(a3035 + 29360128)] = (t1908 - t1913);\n      P2[(a3035 + 29360129)] = (t1909 + t1912);\n      t1914 = (t1848 + s1002);\n      t1915 = (t1849 - s1003);\n      t1916 = (t1848 - s1002);\n      t1917 = (t1849 + s1003);\n      t1918 = (s982 - s1024);\n      t1919 = (s983 + s1025);\n      t1920 = (s982 + s1024);\n      t1921 = (s983 - s1025);\n      P2[(a3035 + 6291456)] = (t1914 + t1918);\n      P2[(a3035 + 6291457)] = (t1915 + t1919);\n      P2[(a3035 + 23068672)] = (t1914 - t1918);\n      P2[(a3035 + 23068673)] = (t1915 - t1919);\n      P2[(a3035 + 14680064)] = (t1916 + t1921);\n      P2[(a3035 + 14680065)] = (t1917 - t1920);\n      P2[(a3035 + 31457280)] = (t1916 - t1921);\n      P2[(a3035 + 31457281)] = (t1917 + t1920);\n      #pragma omp barrier\n    }\n  }\n}\n\nvoid ker_zmddft_fwd_256x256x256_cu2(const double *D3, const double *P2, double *Y) {\n  #pragma omp target teams num_teams(16384) thread_limit(64)\n  {\n    double T63[2048];\n    #pragma omp parallel \n    {\n      double a3529, a3530, a3531, a3532, a3533, a3534, a3535, a3536, \n             s1170, s1171, s1172, s1173, s1174, s1175, s1176, s1177, \n             s1178, s1179, s1180, s1181, s1182, s1183, s1184, s1185, \n             s1186, s1187, s1188, s1189, s1190, s1191, s1192, s1193, \n             s1194, s1195, s1196, s1197, s1198, s1199, s1200, s1201, \n             s1202, s1203, s1204, s1205, s1206, s1207, s1208, s1209, \n             s1210, s1211, s1212, s1213, s1214, s1215, s1216, s1217, \n             t2266, t2267, t2268, t2269, t2270, t2271, t2272, t2273, \n             t2274, t2275, t2276, t2277, t2278, t2279, t2280, t2281, \n             t2282, t2283, t2284, t2285, t2286, t2287, t2288, t2289, \n             t2290, t2291, t2292, t2293, t2294, t2295, t2296, t2297, \n             t2298, t2299, t2300, t2301, t2302, t2303, t2304, t2305, \n             t2306, t2307, t2308, t2309, t2310, t2311, t2312, t2313, \n             t2314, t2315, t2316, t2317, t2318, t2319, t2320, t2321, \n             t2322, t2323, t2324, t2325, t2326, t2327, t2328, t2329, \n             t2330, t2331, t2332, t2333, t2334, t2335, t2336, t2337, \n             t2338, t2339, t2340, t2341, t2342, t2343, t2344, t2345, \n             t2346, t2347, t2348, t2349, t2350, t2351, t2352, t2353;\n      int a3526, a3527, a3528, a3537;\n      int threadIdx_x = omp_get_thread_num();\n      int blockIdx_x = omp_get_team_num();\n      a3526 = (512*(threadIdx_x / 16));\n      a3527 = (threadIdx_x % 16);\n      a3528 = ((2048*blockIdx_x) + a3526 + (2*a3527));\n      s1170 = P2[a3528];\n      s1171 = P2[(a3528 + 1)];\n      s1172 = P2[(a3528 + 256)];\n      s1173 = P2[(a3528 + 257)];\n      t2266 = (s1170 + s1172);\n      t2267 = (s1171 + s1173);\n      t2268 = (s1170 - s1172);\n      t2269 = (s1171 - s1173);\n      s1174 = P2[(a3528 + 128)];\n      s1175 = P2[(a3528 + 129)];\n      s1176 = P2[(a3528 + 384)];\n      s1177 = P2[(a3528 + 385)];\n      t2270 = (s1174 + s1176);\n      t2271 = (s1175 + s1177);\n      t2272 = (s1174 - s1176);\n      t2273 = (s1175 - s1177);\n      t2274 = (t2266 + t2270);\n      t2275 = (t2267 + t2271);\n      t2276 = (t2266 - t2270);\n      t2277 = (t2267 - t2271);\n      t2278 = (t2268 + t2273);\n      t2279 = (t2269 - t2272);\n      t2280 = (t2268 - t2273);\n      t2281 = (t2269 + t2272);\n      s1178 = P2[(a3528 + 32)];\n      s1179 = P2[(a3528 + 33)];\n      s1180 = P2[(a3528 + 288)];\n      s1181 = P2[(a3528 + 289)];\n      t2282 = (s1178 + s1180);\n      t2283 = (s1179 + s1181);\n      t2284 = (s1178 - s1180);\n      t2285 = (s1179 - s1181);\n      s1182 = P2[(a3528 + 160)];\n      s1183 = P2[(a3528 + 161)];\n      s1184 = P2[(a3528 + 416)];\n      s1185 = P2[(a3528 + 417)];\n      t2286 = (s1182 + s1184);\n      t2287 = (s1183 + s1185);\n      t2288 = (s1182 - s1184);\n      t2289 = (s1183 - s1185);\n      t2290 = (t2282 + t2286);\n      t2291 = (t2283 + t2287);\n      a3529 = (0.70710678118654757*(t2282 - t2286));\n      a3530 = (0.70710678118654757*(t2283 - t2287));\n      s1186 = (a3529 + a3530);\n      s1187 = (a3530 - a3529);\n      t2292 = (t2284 + t2289);\n      t2293 = (t2285 - t2288);\n      t2294 = (t2284 - t2289);\n      t2295 = (t2285 + t2288);\n      s1188 = ((0.92387953251128674*t2292) + (0.38268343236508978*t2293));\n      s1189 = ((0.92387953251128674*t2293) - (0.38268343236508978*t2292));\n      s1190 = ((0.38268343236508978*t2294) + (0.92387953251128674*t2295));\n      s1191 = ((0.38268343236508978*t2295) - (0.92387953251128674*t2294));\n      s1192 = P2[(a3528 + 64)];\n      s1193 = P2[(a3528 + 65)];\n      s1194 = P2[(a3528 + 320)];\n      s1195 = P2[(a3528 + 321)];\n      t2296 = (s1192 + s1194);\n      t2297 = (s1193 + s1195);\n      t2298 = (s1192 - s1194);\n      t2299 = (s1193 - s1195);\n      s1196 = P2[(a3528 + 192)];\n      s1197 = P2[(a3528 + 193)];\n      s1198 = P2[(a3528 + 448)];\n      s1199 = P2[(a3528 + 449)];\n      t2300 = (s1196 + s1198);\n      t2301 = (s1197 + s1199);\n      t2302 = (s1196 - s1198);\n      t2303 = (s1197 - s1199);\n      t2304 = (t2296 + t2300);\n      t2305 = (t2297 + t2301);\n      t2306 = (t2296 - t2300);\n      t2307 = (t2297 - t2301);\n      a3531 = (0.70710678118654757*(t2298 + t2303));\n      a3532 = (0.70710678118654757*(t2299 - t2302));\n      s1200 = (a3531 + a3532);\n      s1201 = (a3532 - a3531);\n      a3533 = (0.70710678118654757*(t2299 + t2302));\n      a3534 = (0.70710678118654757*(t2298 - t2303));\n      s1202 = (a3533 - a3534);\n      s1203 = (a3534 + a3533);\n      s1204 = P2[(a3528 + 96)];\n      s1205 = P2[(a3528 + 97)];\n      s1206 = P2[(a3528 + 352)];\n      s1207 = P2[(a3528 + 353)];\n      t2308 = (s1204 + s1206);\n      t2309 = (s1205 + s1207);\n      t2310 = (s1204 - s1206);\n      t2311 = (s1205 - s1207);\n      s1208 = P2[(a3528 + 224)];\n      s1209 = P2[(a3528 + 225)];\n      s1210 = P2[(a3528 + 480)];\n      s1211 = P2[(a3528 + 481)];\n      t2312 = (s1208 + s1210);\n      t2313 = (s1209 + s1211);\n      t2314 = (s1208 - s1210);\n      t2315 = (s1209 - s1211);\n      t2316 = (t2308 + t2312);\n      t2317 = (t2309 + t2313);\n      a3535 = (0.70710678118654757*(t2309 - t2313));\n      a3536 = (0.70710678118654757*(t2308 - t2312));\n      s1212 = (a3535 - a3536);\n      s1213 = (a3536 + a3535);\n      t2318 = (t2310 + t2315);\n      t2319 = (t2311 - t2314);\n      t2320 = (t2310 - t2315);\n      t2321 = (t2311 + t2314);\n      s1214 = ((0.38268343236508978*t2318) + (0.92387953251128674*t2319));\n      s1215 = ((0.38268343236508978*t2319) - (0.92387953251128674*t2318));\n      s1216 = ((0.92387953251128674*t2320) + (0.38268343236508978*t2321));\n      s1217 = ((0.38268343236508978*t2320) - (0.92387953251128674*t2321));\n      t2322 = (t2274 + t2304);\n      t2323 = (t2275 + t2305);\n      t2324 = (t2274 - t2304);\n      t2325 = (t2275 - t2305);\n      t2326 = (t2290 + t2316);\n      t2327 = (t2291 + t2317);\n      t2328 = (t2290 - t2316);\n      t2329 = (t2291 - t2317);\n      a3537 = (a3526 + (32*a3527));\n      T63[a3537] = (t2322 + t2326);\n      T63[(a3537 + 1)] = (t2323 + t2327);\n      T63[(a3537 + 16)] = (t2322 - t2326);\n      T63[(a3537 + 17)] = (t2323 - t2327);\n      T63[(a3537 + 8)] = (t2324 + t2329);\n      T63[(a3537 + 9)] = (t2325 - t2328);\n      T63[(a3537 + 24)] = (t2324 - t2329);\n      T63[(a3537 + 25)] = (t2325 + t2328);\n      t2330 = (t2278 + s1200);\n      t2331 = (t2279 + s1201);\n      t2332 = (t2278 - s1200);\n      t2333 = (t2279 - s1201);\n      t2334 = (s1188 + s1214);\n      t2335 = (s1189 + s1215);\n      t2336 = (s1188 - s1214);\n      t2337 = (s1189 - s1215);\n      T63[(a3537 + 2)] = (t2330 + t2334);\n      T63[(a3537 + 3)] = (t2331 + t2335);\n      T63[(a3537 + 18)] = (t2330 - t2334);\n      T63[(a3537 + 19)] = (t2331 - t2335);\n      T63[(a3537 + 10)] = (t2332 + t2337);\n      T63[(a3537 + 11)] = (t2333 - t2336);\n      T63[(a3537 + 26)] = (t2332 - t2337);\n      T63[(a3537 + 27)] = (t2333 + t2336);\n      t2338 = (t2276 + t2307);\n      t2339 = (t2277 - t2306);\n      t2340 = (t2276 - t2307);\n      t2341 = (t2277 + t2306);\n      t2342 = (s1186 + s1212);\n      t2343 = (s1187 - s1213);\n      t2344 = (s1186 - s1212);\n      t2345 = (s1187 + s1213);\n      T63[(a3537 + 4)] = (t2338 + t2342);\n      T63[(a3537 + 5)] = (t2339 + t2343);\n      T63[(a3537 + 20)] = (t2338 - t2342);\n      T63[(a3537 + 21)] = (t2339 - t2343);\n      T63[(a3537 + 12)] = (t2340 + t2345);\n      T63[(a3537 + 13)] = (t2341 - t2344);\n      T63[(a3537 + 28)] = (t2340 - t2345);\n      T63[(a3537 + 29)] = (t2341 + t2344);\n      t2346 = (t2280 + s1202);\n      t2347 = (t2281 - s1203);\n      t2348 = (t2280 - s1202);\n      t2349 = (t2281 + s1203);\n      t2350 = (s1190 - s1216);\n      t2351 = (s1191 + s1217);\n      t2352 = (s1190 + s1216);\n      t2353 = (s1191 - s1217);\n      T63[(a3537 + 6)] = (t2346 + t2350);\n      T63[(a3537 + 7)] = (t2347 + t2351);\n      T63[(a3537 + 22)] = (t2346 - t2350);\n      T63[(a3537 + 23)] = (t2347 - t2351);\n      T63[(a3537 + 14)] = (t2348 + t2353);\n      T63[(a3537 + 15)] = (t2349 - t2352);\n      T63[(a3537 + 30)] = (t2348 - t2353);\n      T63[(a3537 + 31)] = (t2349 + t2352);\n      #pragma omp barrier\n      double a4512, a4513, a4514, a4515, a4516, a4517, a4518, a4519, \n             a4520, a4521, a4522, a4523, a4524, a4525, a4526, a4527, \n             a4528, a4529, a4530, a4531, a4532, a4533, a4534, a4535, \n             a4536, a4537, a4538, a4539, a4540, a4541, a4542, a4543, \n             a4544, a4545, a4546, a4547, a4548, a4549, a4550, a4551, \n             s1458, s1459, s1460, s1461, s1462, s1463, s1464, s1465, \n             s1466, s1467, s1468, s1469, s1470, s1471, s1472, s1473, \n             s1474, s1475, s1476, s1477, s1478, s1479, s1480, s1481, \n             s1482, s1483, s1484, s1485, s1486, s1487, s1488, s1489, \n             s1490, s1491, s1492, s1493, s1494, s1495, s1496, s1497, \n             s1498, s1499, s1500, s1501, s1502, s1503, s1504, s1505, \n             s1506, s1507, s1508, s1509, s1510, s1511, s1512, s1513, \n             s1514, s1515, s1516, s1517, s1518, s1519, s1520, s1521, \n             s1522, s1523, s1524, s1525, s1526, s1527, s1528, s1529, \n             s1530, s1531, s1532, s1533, s1534, s1535, s1536, s1537, \n             t2698, t2699, t2700, t2701, t2702, t2703, t2704, t2705, \n             t2706, t2707, t2708, t2709, t2710, t2711, t2712, t2713, \n             t2714, t2715, t2716, t2717, t2718, t2719, t2720, t2721, \n             t2722, t2723, t2724, t2725, t2726, t2727, t2728, t2729, \n             t2730, t2731, t2732, t2733, t2734, t2735, t2736, t2737, \n             t2738, t2739, t2740, t2741, t2742, t2743, t2744, t2745, \n             t2746, t2747, t2748, t2749, t2750, t2751, t2752, t2753, \n             t2754, t2755, t2756, t2757, t2758, t2759, t2760, t2761, \n             t2762, t2763, t2764, t2765, t2766, t2767, t2768, t2769, \n             t2770, t2771, t2772, t2773, t2774, t2775, t2776, t2777, \n             t2778, t2779, t2780, t2781, t2782, t2783, t2784, t2785;\n      int a4508, a4509, a4510, a4511, a4552;\n      a4508 = (threadIdx_x / 16);\n      a4509 = (threadIdx_x % 16);\n      a4510 = ((512*a4508) + (2*a4509));\n      s1458 = T63[a4510];\n      s1459 = T63[(a4510 + 1)];\n      s1460 = T63[(a4510 + 256)];\n      s1461 = T63[(a4510 + 257)];\n      a4511 = (32*a4509);\n      a4512 = D3[a4511];\n      a4513 = D3[(a4511 + 1)];\n      s1462 = ((a4512*s1458) - (a4513*s1459));\n      s1463 = ((a4513*s1458) + (a4512*s1459));\n      a4514 = D3[(a4511 + 2)];\n      a4515 = D3[(a4511 + 3)];\n      s1464 = ((a4514*s1460) - (a4515*s1461));\n      s1465 = ((a4515*s1460) + (a4514*s1461));\n      t2698 = (s1462 + s1464);\n      t2699 = (s1463 + s1465);\n      t2700 = (s1462 - s1464);\n      t2701 = (s1463 - s1465);\n      s1466 = T63[(a4510 + 128)];\n      s1467 = T63[(a4510 + 129)];\n      s1468 = T63[(a4510 + 384)];\n      s1469 = T63[(a4510 + 385)];\n      a4516 = D3[(4 + a4511)];\n      a4517 = D3[(5 + a4511)];\n      s1470 = ((a4516*s1466) - (a4517*s1467));\n      s1471 = ((a4517*s1466) + (a4516*s1467));\n      a4518 = D3[(6 + a4511)];\n      a4519 = D3[(7 + a4511)];\n      s1472 = ((a4518*s1468) - (a4519*s1469));\n      s1473 = ((a4519*s1468) + (a4518*s1469));\n      t2702 = (s1470 + s1472);\n      t2703 = (s1471 + s1473);\n      t2704 = (s1470 - s1472);\n      t2705 = (s1471 - s1473);\n      t2706 = (t2698 + t2702);\n      t2707 = (t2699 + t2703);\n      t2708 = (t2698 - t2702);\n      t2709 = (t2699 - t2703);\n      t2710 = (t2700 + t2705);\n      t2711 = (t2701 - t2704);\n      t2712 = (t2700 - t2705);\n      t2713 = (t2701 + t2704);\n      s1474 = T63[(a4510 + 32)];\n      s1475 = T63[(a4510 + 33)];\n      s1476 = T63[(a4510 + 288)];\n      s1477 = T63[(a4510 + 289)];\n      a4520 = D3[(a4511 + 8)];\n      a4521 = D3[(9 + a4511)];\n      s1478 = ((a4520*s1474) - (a4521*s1475));\n      s1479 = ((a4521*s1474) + (a4520*s1475));\n      a4522 = D3[(10 + a4511)];\n      a4523 = D3[(11 + a4511)];\n      s1480 = ((a4522*s1476) - (a4523*s1477));\n      s1481 = ((a4523*s1476) + (a4522*s1477));\n      t2714 = (s1478 + s1480);\n      t2715 = (s1479 + s1481);\n      t2716 = (s1478 - s1480);\n      t2717 = (s1479 - s1481);\n      s1482 = T63[(a4510 + 160)];\n      s1483 = T63[(a4510 + 161)];\n      s1484 = T63[(a4510 + 416)];\n      s1485 = T63[(a4510 + 417)];\n      a4524 = D3[(12 + a4511)];\n      a4525 = D3[(13 + a4511)];\n      s1486 = ((a4524*s1482) - (a4525*s1483));\n      s1487 = ((a4525*s1482) + (a4524*s1483));\n      a4526 = D3[(14 + a4511)];\n      a4527 = D3[(15 + a4511)];\n      s1488 = ((a4526*s1484) - (a4527*s1485));\n      s1489 = ((a4527*s1484) + (a4526*s1485));\n      t2718 = (s1486 + s1488);\n      t2719 = (s1487 + s1489);\n      t2720 = (s1486 - s1488);\n      t2721 = (s1487 - s1489);\n      t2722 = (t2714 + t2718);\n      t2723 = (t2715 + t2719);\n      a4528 = (0.70710678118654757*(t2714 - t2718));\n      a4529 = (0.70710678118654757*(t2715 - t2719));\n      s1490 = (a4528 + a4529);\n      s1491 = (a4529 - a4528);\n      t2724 = (t2716 + t2721);\n      t2725 = (t2717 - t2720);\n      t2726 = (t2716 - t2721);\n      t2727 = (t2717 + t2720);\n      s1492 = ((0.92387953251128674*t2724) + (0.38268343236508978*t2725));\n      s1493 = ((0.92387953251128674*t2725) - (0.38268343236508978*t2724));\n      s1494 = ((0.38268343236508978*t2726) + (0.92387953251128674*t2727));\n      s1495 = ((0.38268343236508978*t2727) - (0.92387953251128674*t2726));\n      s1496 = T63[(a4510 + 64)];\n      s1497 = T63[(a4510 + 65)];\n      s1498 = T63[(a4510 + 320)];\n      s1499 = T63[(a4510 + 321)];\n      a4530 = D3[(a4511 + 16)];\n      a4531 = D3[(17 + a4511)];\n      s1500 = ((a4530*s1496) - (a4531*s1497));\n      s1501 = ((a4531*s1496) + (a4530*s1497));\n      a4532 = D3[(18 + a4511)];\n      a4533 = D3[(19 + a4511)];\n      s1502 = ((a4532*s1498) - (a4533*s1499));\n      s1503 = ((a4533*s1498) + (a4532*s1499));\n      t2728 = (s1500 + s1502);\n      t2729 = (s1501 + s1503);\n      t2730 = (s1500 - s1502);\n      t2731 = (s1501 - s1503);\n      s1504 = T63[(a4510 + 192)];\n      s1505 = T63[(a4510 + 193)];\n      s1506 = T63[(a4510 + 448)];\n      s1507 = T63[(a4510 + 449)];\n      a4534 = D3[(20 + a4511)];\n      a4535 = D3[(21 + a4511)];\n      s1508 = ((a4534*s1504) - (a4535*s1505));\n      s1509 = ((a4535*s1504) + (a4534*s1505));\n      a4536 = D3[(22 + a4511)];\n      a4537 = D3[(23 + a4511)];\n      s1510 = ((a4536*s1506) - (a4537*s1507));\n      s1511 = ((a4537*s1506) + (a4536*s1507));\n      t2732 = (s1508 + s1510);\n      t2733 = (s1509 + s1511);\n      t2734 = (s1508 - s1510);\n      t2735 = (s1509 - s1511);\n      t2736 = (t2728 + t2732);\n      t2737 = (t2729 + t2733);\n      t2738 = (t2728 - t2732);\n      t2739 = (t2729 - t2733);\n      a4538 = (0.70710678118654757*(t2730 + t2735));\n      a4539 = (0.70710678118654757*(t2731 - t2734));\n      s1512 = (a4538 + a4539);\n      s1513 = (a4539 - a4538);\n      a4540 = (0.70710678118654757*(t2731 + t2734));\n      a4541 = (0.70710678118654757*(t2730 - t2735));\n      s1514 = (a4540 - a4541);\n      s1515 = (a4541 + a4540);\n      s1516 = T63[(a4510 + 96)];\n      s1517 = T63[(a4510 + 97)];\n      s1518 = T63[(a4510 + 352)];\n      s1519 = T63[(a4510 + 353)];\n      a4542 = D3[(a4511 + 24)];\n      a4543 = D3[(25 + a4511)];\n      s1520 = ((a4542*s1516) - (a4543*s1517));\n      s1521 = ((a4543*s1516) + (a4542*s1517));\n      a4544 = D3[(26 + a4511)];\n      a4545 = D3[(27 + a4511)];\n      s1522 = ((a4544*s1518) - (a4545*s1519));\n      s1523 = ((a4545*s1518) + (a4544*s1519));\n      t2740 = (s1520 + s1522);\n      t2741 = (s1521 + s1523);\n      t2742 = (s1520 - s1522);\n      t2743 = (s1521 - s1523);\n      s1524 = T63[(a4510 + 224)];\n      s1525 = T63[(a4510 + 225)];\n      s1526 = T63[(a4510 + 480)];\n      s1527 = T63[(a4510 + 481)];\n      a4546 = D3[(28 + a4511)];\n      a4547 = D3[(29 + a4511)];\n      s1528 = ((a4546*s1524) - (a4547*s1525));\n      s1529 = ((a4547*s1524) + (a4546*s1525));\n      a4548 = D3[(30 + a4511)];\n      a4549 = D3[(31 + a4511)];\n      s1530 = ((a4548*s1526) - (a4549*s1527));\n      s1531 = ((a4549*s1526) + (a4548*s1527));\n      t2744 = (s1528 + s1530);\n      t2745 = (s1529 + s1531);\n      t2746 = (s1528 - s1530);\n      t2747 = (s1529 - s1531);\n      t2748 = (t2740 + t2744);\n      t2749 = (t2741 + t2745);\n      a4550 = (0.70710678118654757*(t2741 - t2745));\n      a4551 = (0.70710678118654757*(t2740 - t2744));\n      s1532 = (a4550 - a4551);\n      s1533 = (a4551 + a4550);\n      t2750 = (t2742 + t2747);\n      t2751 = (t2743 - t2746);\n      t2752 = (t2742 - t2747);\n      t2753 = (t2743 + t2746);\n      s1534 = ((0.38268343236508978*t2750) + (0.92387953251128674*t2751));\n      s1535 = ((0.38268343236508978*t2751) - (0.92387953251128674*t2750));\n      s1536 = ((0.92387953251128674*t2752) + (0.38268343236508978*t2753));\n      s1537 = ((0.38268343236508978*t2752) - (0.92387953251128674*t2753));\n      t2754 = (t2706 + t2736);\n      t2755 = (t2707 + t2737);\n      t2756 = (t2706 - t2736);\n      t2757 = (t2707 - t2737);\n      t2758 = (t2722 + t2748);\n      t2759 = (t2723 + t2749);\n      t2760 = (t2722 - t2748);\n      t2761 = (t2723 - t2749);\n      a4552 = ((8*blockIdx_x) + (131072*a4509) + (2*a4508));\n      Y[a4552] = (t2754 + t2758);\n      Y[(a4552 + 1)] = (t2755 + t2759);\n      Y[(a4552 + 16777216)] = (t2754 - t2758);\n      Y[(a4552 + 16777217)] = (t2755 - t2759);\n      Y[(a4552 + 8388608)] = (t2756 + t2761);\n      Y[(a4552 + 8388609)] = (t2757 - t2760);\n      Y[(a4552 + 25165824)] = (t2756 - t2761);\n      Y[(a4552 + 25165825)] = (t2757 + t2760);\n      t2762 = (t2710 + s1512);\n      t2763 = (t2711 + s1513);\n      t2764 = (t2710 - s1512);\n      t2765 = (t2711 - s1513);\n      t2766 = (s1492 + s1534);\n      t2767 = (s1493 + s1535);\n      t2768 = (s1492 - s1534);\n      t2769 = (s1493 - s1535);\n      Y[(a4552 + 2097152)] = (t2762 + t2766);\n      Y[(a4552 + 2097153)] = (t2763 + t2767);\n      Y[(a4552 + 18874368)] = (t2762 - t2766);\n      Y[(a4552 + 18874369)] = (t2763 - t2767);\n      Y[(a4552 + 10485760)] = (t2764 + t2769);\n      Y[(a4552 + 10485761)] = (t2765 - t2768);\n      Y[(a4552 + 27262976)] = (t2764 - t2769);\n      Y[(a4552 + 27262977)] = (t2765 + t2768);\n      t2770 = (t2708 + t2739);\n      t2771 = (t2709 - t2738);\n      t2772 = (t2708 - t2739);\n      t2773 = (t2709 + t2738);\n      t2774 = (s1490 + s1532);\n      t2775 = (s1491 - s1533);\n      t2776 = (s1490 - s1532);\n      t2777 = (s1491 + s1533);\n      Y[(a4552 + 4194304)] = (t2770 + t2774);\n      Y[(a4552 + 4194305)] = (t2771 + t2775);\n      Y[(a4552 + 20971520)] = (t2770 - t2774);\n      Y[(a4552 + 20971521)] = (t2771 - t2775);\n      Y[(a4552 + 12582912)] = (t2772 + t2777);\n      Y[(a4552 + 12582913)] = (t2773 - t2776);\n      Y[(a4552 + 29360128)] = (t2772 - t2777);\n      Y[(a4552 + 29360129)] = (t2773 + t2776);\n      t2778 = (t2712 + s1514);\n      t2779 = (t2713 - s1515);\n      t2780 = (t2712 - s1514);\n      t2781 = (t2713 + s1515);\n      t2782 = (s1494 - s1536);\n      t2783 = (s1495 + s1537);\n      t2784 = (s1494 + s1536);\n      t2785 = (s1495 - s1537);\n      Y[(a4552 + 6291456)] = (t2778 + t2782);\n      Y[(a4552 + 6291457)] = (t2779 + t2783);\n      Y[(a4552 + 23068672)] = (t2778 - t2782);\n      Y[(a4552 + 23068673)] = (t2779 - t2783);\n      Y[(a4552 + 14680064)] = (t2780 + t2785);\n      Y[(a4552 + 14680065)] = (t2781 - t2784);\n      Y[(a4552 + 31457280)] = (t2780 - t2785);\n      Y[(a4552 + 31457281)] = (t2781 + t2784);\n      #pragma omp barrier\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 256*256*256*2;\n  const int t = 33554432;\n  size_t dat_size = n * sizeof(double);\n  size_t tmp_size = t * sizeof(double);\n\n  std::mt19937 engine(n);\n  std::uniform_real_distribution<double> dist(0.0, 1.0);\n  double *x = (double*) malloc (dat_size);\n  for (int i = 0; i < n; i++) x[i] = dist(engine);\n\n  double *y = (double*) malloc (dat_size);\n  double *p1 = (double*) malloc (tmp_size);\n  double *p2 = (double*) malloc (tmp_size);\n\n  #pragma omp target data map (to: x[0:n], d[0:512]) \\\n                          map (from: y[0:n]) \\\n                          map (alloc: p1[0:t], p2[0:t])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      ker_zmddft_fwd_256x256x256_cu0(d, x, p1);\n      ker_zmddft_fwd_256x256x256_cu1(d, p1, p2);\n      ker_zmddft_fwd_256x256x256_cu2(d, p2, y);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %.3f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  double checksum = 0;\n  for (int i = 0; i < n; i++) checksum += y[i];\n  printf(\"checksum = %lf\\n\", checksum);\n\n  free(x);\n  free(y);\n  free(p1);\n  free(p2);\n\n  return 0;\n}\n"}}
{"kernel_name": "zmddft", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n\nconst double d[512] = {\n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 1.0, 0.0, \n  1.0, 0.0, 0.98078528040323043, (-0.19509032201612825), \n  0.99518472667219693, (-0.098017140329560604), 0.95694033573220882, (-0.29028467725446233), \n  0.99969881869620425, (-0.024541228522912288), 0.97570213003852857, (-0.2191012401568698), \n  0.99247953459870997, (-0.1224106751992162), 0.94952818059303667, (-0.31368174039889152), \n  0.99879545620517241, (-0.049067674327418015), 0.97003125319454397, (-0.24298017990326387), \n  0.98917650996478101, (-0.14673047445536175), 0.94154406518302081, (-0.33688985339222005), \n  0.99729045667869021, (-0.073564563599667426), 0.96377606579543984, (-0.26671275747489837), \n  0.98527764238894122, (-0.17096188876030122), 0.93299279883473896, (-0.35989503653498811), \n  1.0, 0.0, 0.92387953251128674, (-0.38268343236508978), \n  0.98078528040323043, (-0.19509032201612825), 0.83146961230254524, (-0.55557023301960218), \n  0.99879545620517241, (-0.049067674327418015), 0.90398929312344334, (-0.42755509343028208), \n  0.97003125319454397, (-0.24298017990326387), 0.80320753148064494, (-0.59569930449243336), \n  0.99518472667219693, (-0.098017140329560604), 0.88192126434835505, (-0.47139673682599764), \n  0.95694033573220882, (-0.29028467725446233), 0.77301045336273699, (-0.63439328416364549), \n  0.98917650996478101, (-0.14673047445536175), 0.85772861000027212, (-0.51410274419322166), \n  0.94154406518302081, (-0.33688985339222005), 0.74095112535495922, (-0.67155895484701833), \n  1.0, 0.0, 0.83146961230254524, (-0.55557023301960218), \n  0.95694033573220882, (-0.29028467725446233), 0.63439328416364549, (-0.77301045336273699), \n  0.99729045667869021, (-0.073564563599667426), 0.78834642762660623, (-0.61523159058062682), \n  0.93299279883473896, (-0.35989503653498811), 0.57580819141784534, (-0.81758481315158371), \n  0.98917650996478101, (-0.14673047445536175), 0.74095112535495922, (-0.67155895484701833), \n  0.90398929312344334, (-0.42755509343028208), 0.51410274419322166, (-0.85772861000027212), \n  0.97570213003852857, (-0.2191012401568698), 0.68954054473706683, (-0.724247082951467), \n  0.87008699110871146, (-0.49289819222978404), 0.44961132965460654, (-0.89322430119551532), \n  1.0, 0.0, 0.70710678118654757, (-0.70710678118654757), \n  0.92387953251128674, (-0.38268343236508978), 0.38268343236508978, (-0.92387953251128674), \n  0.99518472667219693, (-0.098017140329560604), 0.63439328416364549, (-0.77301045336273699), \n  0.88192126434835505, (-0.47139673682599764), 0.29028467725446233, (-0.95694033573220882), \n  0.98078528040323043, (-0.19509032201612825), 0.55557023301960218, (-0.83146961230254524), \n  0.83146961230254524, (-0.55557023301960218), 0.19509032201612825, (-0.98078528040323043), \n  0.95694033573220882, (-0.29028467725446233), 0.47139673682599764, (-0.88192126434835505), \n  0.77301045336273699, (-0.63439328416364549), 0.098017140329560604, (-0.99518472667219693), \n  1.0, 0.0, 0.55557023301960218, (-0.83146961230254524), \n  0.88192126434835505, (-0.47139673682599764), 0.098017140329560604, (-0.99518472667219693), \n  0.99247953459870997, (-0.1224106751992162), 0.44961132965460654, (-0.89322430119551532), \n  0.81758481315158371, (-0.57580819141784534), (-0.024541228522912288), (-0.99969881869620425), \n  0.97003125319454397, (-0.24298017990326387), 0.33688985339222005, (-0.94154406518302081), \n  0.74095112535495922, (-0.67155895484701833), (-0.14673047445536175), (-0.98917650996478101), \n  0.93299279883473896, (-0.35989503653498811), 0.2191012401568698, (-0.97570213003852857), \n  0.65317284295377676, (-0.75720884650648457), (-0.26671275747489837), (-0.96377606579543984), \n  1.0, 0.0, 0.38268343236508978, (-0.92387953251128674), \n  0.83146961230254524, (-0.55557023301960218), (-0.19509032201612825), (-0.98078528040323043), \n  0.98917650996478101, (-0.14673047445536175), 0.24298017990326387, (-0.97003125319454397), \n  0.74095112535495922, (-0.67155895484701833), (-0.33688985339222005), (-0.94154406518302081), \n  0.95694033573220882, (-0.29028467725446233), 0.098017140329560604, (-0.99518472667219693), \n  0.63439328416364549, (-0.77301045336273699), (-0.47139673682599764), (-0.88192126434835505), \n  0.90398929312344334, (-0.42755509343028208), (-0.049067674327418015), (-0.99879545620517241), \n  0.51410274419322166, (-0.85772861000027212), (-0.59569930449243336), (-0.80320753148064494), \n  1.0, 0.0, 0.19509032201612825, (-0.98078528040323043), \n  0.77301045336273699, (-0.63439328416364549), (-0.47139673682599764), (-0.88192126434835505), \n  0.98527764238894122, (-0.17096188876030122), 0.024541228522912288, (-0.99969881869620425), \n  0.65317284295377676, (-0.75720884650648457), (-0.61523159058062682), (-0.78834642762660623), \n  0.94154406518302081, (-0.33688985339222005), (-0.14673047445536175), (-0.98917650996478101), \n  0.51410274419322166, (-0.85772861000027212), (-0.74095112535495922), (-0.67155895484701833), \n  0.87008699110871146, (-0.49289819222978404), (-0.31368174039889152), (-0.94952818059303667), \n  0.35989503653498811, (-0.93299279883473896), (-0.84485356524970712), (-0.53499761988709715), \n  1.0, 0.0, 0.0, (-1.0), \n  0.70710678118654757, (-0.70710678118654757), (-0.70710678118654757), (-0.70710678118654757), \n  0.98078528040323043, (-0.19509032201612825), (-0.19509032201612825), (-0.98078528040323043), \n  0.55557023301960218, (-0.83146961230254524), (-0.83146961230254524), (-0.55557023301960218), \n  0.92387953251128674, (-0.38268343236508978), (-0.38268343236508978), (-0.92387953251128674), \n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), (-0.38268343236508978), \n  0.83146961230254524, (-0.55557023301960218), (-0.55557023301960218), (-0.83146961230254524), \n  0.19509032201612825, (-0.98078528040323043), (-0.98078528040323043), (-0.19509032201612825), \n  1.0, 0.0, (-0.19509032201612825), (-0.98078528040323043), \n  0.63439328416364549, (-0.77301045336273699), (-0.88192126434835505), (-0.47139673682599764), \n  0.97570213003852857, (-0.2191012401568698), (-0.40524131400498986), (-0.91420975570353069), \n  0.44961132965460654, (-0.89322430119551532), (-0.96377606579543984), (-0.26671275747489837), \n  0.90398929312344334, (-0.42755509343028208), (-0.59569930449243336), (-0.80320753148064494), \n  0.24298017990326387, (-0.97003125319454397), (-0.99879545620517241), (-0.049067674327418015), \n  0.78834642762660623, (-0.61523159058062682), (-0.75720884650648457), (-0.65317284295377676), \n  0.024541228522912288, (-0.99969881869620425), (-0.98527764238894122), 0.17096188876030122, \n  1.0, 0.0, (-0.38268343236508978), (-0.92387953251128674), \n  0.55557023301960218, (-0.83146961230254524), (-0.98078528040323043), (-0.19509032201612825), \n  0.97003125319454397, (-0.24298017990326387), (-0.59569930449243336), (-0.80320753148064494), \n  0.33688985339222005, (-0.94154406518302081), (-0.99879545620517241), 0.049067674327418015, \n  0.88192126434835505, (-0.47139673682599764), (-0.77301045336273699), (-0.63439328416364549), \n  0.098017140329560604, (-0.99518472667219693), (-0.95694033573220882), 0.29028467725446233, \n  0.74095112535495922, (-0.67155895484701833), (-0.90398929312344334), (-0.42755509343028208), \n  (-0.14673047445536175), (-0.98917650996478101), (-0.85772861000027212), 0.51410274419322166, \n  1.0, 0.0, (-0.55557023301960218), (-0.83146961230254524), \n  0.47139673682599764, (-0.88192126434835505), (-0.99518472667219693), 0.098017140329560604, \n  0.96377606579543984, (-0.26671275747489837), (-0.75720884650648457), (-0.65317284295377676), \n  0.2191012401568698, (-0.97570213003852857), (-0.93299279883473896), 0.35989503653498811, \n  0.85772861000027212, (-0.51410274419322166), (-0.90398929312344334), (-0.42755509343028208), \n  (-0.049067674327418015), (-0.99879545620517241), (-0.80320753148064494), 0.59569930449243336, \n  0.68954054473706683, (-0.724247082951467), (-0.98527764238894122), (-0.17096188876030122), \n  (-0.31368174039889152), (-0.94952818059303667), (-0.61523159058062682), 0.78834642762660623, \n  1.0, 0.0, (-0.70710678118654757), (-0.70710678118654757), \n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), 0.38268343236508978, \n  0.95694033573220882, (-0.29028467725446233), (-0.88192126434835505), (-0.47139673682599764), \n  0.098017140329560604, (-0.99518472667219693), (-0.77301045336273699), 0.63439328416364549, \n  0.83146961230254524, (-0.55557023301960218), (-0.98078528040323043), (-0.19509032201612825), \n  (-0.19509032201612825), (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524, \n  0.63439328416364549, (-0.77301045336273699), (-0.99518472667219693), 0.098017140329560604, \n  (-0.47139673682599764), (-0.88192126434835505), (-0.29028467725446233), 0.95694033573220882, \n  1.0, 0.0, (-0.83146961230254524), (-0.55557023301960218), \n  0.29028467725446233, (-0.95694033573220882), (-0.77301045336273699), 0.63439328416364549, \n  0.94952818059303667, (-0.31368174039889152), (-0.96377606579543984), (-0.26671275747489837), \n  (-0.024541228522912288), (-0.99969881869620425), (-0.53499761988709715), 0.84485356524970712, \n  0.80320753148064494, (-0.59569930449243336), (-0.99879545620517241), 0.049067674327418015, \n  (-0.33688985339222005), (-0.94154406518302081), (-0.24298017990326387), 0.97003125319454397, \n  0.57580819141784534, (-0.81758481315158371), (-0.93299279883473896), 0.35989503653498811, \n  (-0.61523159058062682), (-0.78834642762660623), 0.073564563599667426, 0.99729045667869021, \n  1.0, 0.0, (-0.92387953251128674), (-0.38268343236508978), \n  0.19509032201612825, (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524, \n  0.94154406518302081, (-0.33688985339222005), (-0.99879545620517241), (-0.049067674327418015), \n  (-0.14673047445536175), (-0.98917650996478101), (-0.24298017990326387), 0.97003125319454397, \n  0.77301045336273699, (-0.63439328416364549), (-0.95694033573220882), 0.29028467725446233, \n  (-0.47139673682599764), (-0.88192126434835505), 0.098017140329560604, 0.99518472667219693, \n  0.51410274419322166, (-0.85772861000027212), (-0.80320753148064494), 0.59569930449243336, \n  (-0.74095112535495922), (-0.67155895484701833), 0.42755509343028208, 0.90398929312344334, \n  1.0, 0.0, (-0.98078528040323043), (-0.19509032201612825), \n  0.098017140329560604, (-0.99518472667219693), (-0.29028467725446233), 0.95694033573220882, \n  0.93299279883473896, (-0.35989503653498811), (-0.98527764238894122), 0.17096188876030122, \n  (-0.26671275747489837), (-0.96377606579543984), 0.073564563599667426, 0.99729045667869021, \n  0.74095112535495922, (-0.67155895484701833), (-0.85772861000027212), 0.51410274419322166, \n  (-0.59569930449243336), (-0.80320753148064494), 0.42755509343028208, 0.90398929312344334, \n  0.44961132965460654, (-0.89322430119551532), (-0.61523159058062682), 0.78834642762660623, \n  (-0.84485356524970712), (-0.53499761988709715), 0.724247082951467, 0.68954054473706683};\n\nvoid ker_zmddft_fwd_256x256x256_cu0(const double *D3, const double *X, double *P1) {\n    {\n    double T3[2048];\n        {\n      double a495, a496, a497, a498, a499, a500, a501, a502, \n             s145, s146, s147, s148, s149, s150, s151, s152, \n             s153, s154, s155, s156, s157, s158, s159, s160, \n             s161, s162, s163, s164, s165, s166, s167, s168, \n             s169, s170, s171, s172, s173, s174, s175, s176, \n             s177, s178, s179, s180, s181, s182, s183, s184, \n             s185, s186, s187, s188, s189, s190, s191, s192, \n             t538, t539, t540, t541, t542, t543, t544, t545, \n             t546, t547, t548, t549, t550, t551, t552, t553, \n             t554, t555, t556, t557, t558, t559, t560, t561, \n             t562, t563, t564, t565, t566, t567, t568, t569, \n             t570, t571, t572, t573, t574, t575, t576, t577, \n             t578, t579, t580, t581, t582, t583, t584, t585, \n             t586, t587, t588, t589, t590, t591, t592, t593, \n             t594, t595, t596, t597, t598, t599, t600, t601, \n             t602, t603, t604, t605, t606, t607, t608, t609, \n             t610, t611, t612, t613, t614, t615, t616, t617, \n             t618, t619, t620, t621, t622, t623, t624, t625;\n      int a492, a493, a494, a503;\n      int threadIdx_x = omp_get_thread_num();\n      int blockIdx_x = omp_get_team_num();\n      a492 = (512*(threadIdx_x / 16));  \n\n      a493 = (threadIdx_x % 16); \n\n      a494 = ((2048*blockIdx_x) + a492 + (2*a493));\n      s145 = X[a494];\n      s146 = X[(a494 + 1)];\n      s147 = X[(a494 + 256)];\n      s148 = X[(a494 + 257)];\n      t538 = (s145 + s147);\n      t539 = (s146 + s148);\n      t540 = (s145 - s147);\n      t541 = (s146 - s148);\n      s149 = X[(a494 + 128)];\n      s150 = X[(a494 + 129)];\n      s151 = X[(a494 + 384)];\n      s152 = X[(a494 + 385)];\n      t542 = (s149 + s151);\n      t543 = (s150 + s152);\n      t544 = (s149 - s151);\n      t545 = (s150 - s152);\n      t546 = (t538 + t542);\n      t547 = (t539 + t543);\n      t548 = (t538 - t542);\n      t549 = (t539 - t543);\n      t550 = (t540 + t545);\n      t551 = (t541 - t544);\n      t552 = (t540 - t545);\n      t553 = (t541 + t544);\n      s153 = X[(a494 + 32)];\n      s154 = X[(a494 + 33)];\n      s155 = X[(a494 + 288)];\n      s156 = X[(a494 + 289)];\n      t554 = (s153 + s155);\n      t555 = (s154 + s156);\n      t556 = (s153 - s155);\n      t557 = (s154 - s156);\n      s157 = X[(a494 + 160)];\n      s158 = X[(a494 + 161)];\n      s159 = X[(a494 + 416)];\n      s160 = X[(a494 + 417)];\n      t558 = (s157 + s159);\n      t559 = (s158 + s160);\n      t560 = (s157 - s159);\n      t561 = (s158 - s160);\n      t562 = (t554 + t558);\n      t563 = (t555 + t559);\n      a495 = (0.70710678118654757*(t554 - t558));\n      a496 = (0.70710678118654757*(t555 - t559));\n      s161 = (a495 + a496);\n      s162 = (a496 - a495);\n      t564 = (t556 + t561);\n      t565 = (t557 - t560);\n      t566 = (t556 - t561);\n      t567 = (t557 + t560);\n      s163 = ((0.92387953251128674*t564) + (0.38268343236508978*t565));\n      s164 = ((0.92387953251128674*t565) - (0.38268343236508978*t564));\n      s165 = ((0.38268343236508978*t566) + (0.92387953251128674*t567));\n      s166 = ((0.38268343236508978*t567) - (0.92387953251128674*t566));\n      s167 = X[(a494 + 64)];\n      s168 = X[(a494 + 65)];\n      s169 = X[(a494 + 320)];\n      s170 = X[(a494 + 321)];\n      t568 = (s167 + s169);\n      t569 = (s168 + s170);\n      t570 = (s167 - s169);\n      t571 = (s168 - s170);\n      s171 = X[(a494 + 192)];\n      s172 = X[(a494 + 193)];\n      s173 = X[(a494 + 448)];\n      s174 = X[(a494 + 449)];\n      t572 = (s171 + s173);\n      t573 = (s172 + s174);\n      t574 = (s171 - s173);\n      t575 = (s172 - s174);\n      t576 = (t568 + t572);\n      t577 = (t569 + t573);\n      t578 = (t568 - t572);\n      t579 = (t569 - t573);\n      a497 = (0.70710678118654757*(t570 + t575));\n      a498 = (0.70710678118654757*(t571 - t574));\n      s175 = (a497 + a498);\n      s176 = (a498 - a497);\n      a499 = (0.70710678118654757*(t571 + t574));\n      a500 = (0.70710678118654757*(t570 - t575));\n      s177 = (a499 - a500);\n      s178 = (a500 + a499);\n      s179 = X[(a494 + 96)];\n      s180 = X[(a494 + 97)];\n      s181 = X[(a494 + 352)];\n      s182 = X[(a494 + 353)];\n      t580 = (s179 + s181);\n      t581 = (s180 + s182);\n      t582 = (s179 - s181);\n      t583 = (s180 - s182);\n      s183 = X[(a494 + 224)];\n      s184 = X[(a494 + 225)];\n      s185 = X[(a494 + 480)];\n      s186 = X[(a494 + 481)];\n      t584 = (s183 + s185);\n      t585 = (s184 + s186);\n      t586 = (s183 - s185);\n      t587 = (s184 - s186);\n      t588 = (t580 + t584);\n      t589 = (t581 + t585);\n      a501 = (0.70710678118654757*(t581 - t585));\n      a502 = (0.70710678118654757*(t580 - t584));\n      s187 = (a501 - a502);\n      s188 = (a502 + a501);\n      t590 = (t582 + t587);\n      t591 = (t583 - t586);\n      t592 = (t582 - t587);\n      t593 = (t583 + t586);\n      s189 = ((0.38268343236508978*t590) + (0.92387953251128674*t591));\n      s190 = ((0.38268343236508978*t591) - (0.92387953251128674*t590));\n      s191 = ((0.92387953251128674*t592) + (0.38268343236508978*t593));\n      s192 = ((0.38268343236508978*t592) - (0.92387953251128674*t593));\n      t594 = (t546 + t576);\n      t595 = (t547 + t577);\n      t596 = (t546 - t576);\n      t597 = (t547 - t577);\n      t598 = (t562 + t588);\n      t599 = (t563 + t589);\n      t600 = (t562 - t588);\n      t601 = (t563 - t589);\n      a503 = (a492 + (32*a493));\n      T3[a503] = (t594 + t598);\n      T3[(a503 + 1)] = (t595 + t599);\n      T3[(a503 + 16)] = (t594 - t598);\n      T3[(a503 + 17)] = (t595 - t599);\n      T3[(a503 + 8)] = (t596 + t601);\n      T3[(a503 + 9)] = (t597 - t600);\n      T3[(a503 + 24)] = (t596 - t601);\n      T3[(a503 + 25)] = (t597 + t600);\n      t602 = (t550 + s175);\n      t603 = (t551 + s176);\n      t604 = (t550 - s175);\n      t605 = (t551 - s176);\n      t606 = (s163 + s189);\n      t607 = (s164 + s190);\n      t608 = (s163 - s189);\n      t609 = (s164 - s190);\n      T3[(a503 + 2)] = (t602 + t606);\n      T3[(a503 + 3)] = (t603 + t607);\n      T3[(a503 + 18)] = (t602 - t606);\n      T3[(a503 + 19)] = (t603 - t607);\n      T3[(a503 + 10)] = (t604 + t609);\n      T3[(a503 + 11)] = (t605 - t608);\n      T3[(a503 + 26)] = (t604 - t609);\n      T3[(a503 + 27)] = (t605 + t608);\n      t610 = (t548 + t579);\n      t611 = (t549 - t578);\n      t612 = (t548 - t579);\n      t613 = (t549 + t578);\n      t614 = (s161 + s187);\n      t615 = (s162 - s188);\n      t616 = (s161 - s187);\n      t617 = (s162 + s188);\n      T3[(a503 + 4)] = (t610 + t614);\n      T3[(a503 + 5)] = (t611 + t615);\n      T3[(a503 + 20)] = (t610 - t614);\n      T3[(a503 + 21)] = (t611 - t615);\n      T3[(a503 + 12)] = (t612 + t617);\n      T3[(a503 + 13)] = (t613 - t616);\n      T3[(a503 + 28)] = (t612 - t617);\n      T3[(a503 + 29)] = (t613 + t616);\n      t618 = (t552 + s177);\n      t619 = (t553 - s178);\n      t620 = (t552 - s177);\n      t621 = (t553 + s178);\n      t622 = (s165 - s191);\n      t623 = (s166 + s192);\n      t624 = (s165 + s191);\n      t625 = (s166 - s192);\n      T3[(a503 + 6)] = (t618 + t622);\n      T3[(a503 + 7)] = (t619 + t623);\n      T3[(a503 + 22)] = (t618 - t622);\n      T3[(a503 + 23)] = (t619 - t623);\n      T3[(a503 + 14)] = (t620 + t625);\n      T3[(a503 + 15)] = (t621 - t624);\n      T3[(a503 + 30)] = (t620 - t625);\n      T3[(a503 + 31)] = (t621 + t624);\n            double a1478, a1479, a1480, a1481, a1482, a1483, a1484, a1485, \n             a1486, a1487, a1488, a1489, a1490, a1491, a1492, a1493, \n             a1494, a1495, a1496, a1497, a1498, a1499, a1500, a1501, \n             a1502, a1503, a1504, a1505, a1506, a1507, a1508, a1509, \n             a1510, a1511, a1512, a1513, a1514, a1515, a1516, a1517, \n             s434, s435, s436, s437, s438, s439, s440, s441, \n             s442, s443, s444, s445, s446, s447, s448, s449, \n             s450, s451, s452, s453, s454, s455, s456, s457, \n             s458, s459, s460, s461, s462, s463, s464, s465, \n             s466, s467, s468, s469, s470, s471, s472, s473, \n             s474, s475, s476, s477, s478, s479, s480, s481, \n             s482, s483, s484, s485, s486, s487, s488, s489, \n             s490, s491, s492, s493, s494, s495, s496, s497, \n             s498, s499, s500, s501, s502, s503, s504, s505, \n             s506, s507, s508, s509, s510, s511, s512, s513, \n             t1000, t1001, t1002, t1003, t1004, t1005, t1006, t1007, \n             t1008, t1009, t1010, t1011, t1012, t1013, t1014, t1015, \n             t1016, t1017, t1018, t1019, t1020, t1021, t1022, t1023, \n             t1024, t1025, t1026, t1027, t1028, t1029, t1030, t1031, \n             t1032, t1033, t1034, t1035, t1036, t1037, t1038, t1039, \n             t1040, t1041, t1042, t1043, t1044, t1045, t1046, t1047, \n             t1048, t1049, t1050, t1051, t1052, t1053, t1054, t1055, \n             t1056, t1057, t970, t971, t972, t973, t974, t975, \n             t976, t977, t978, t979, t980, t981, t982, t983, \n             t984, t985, t986, t987, t988, t989, t990, t991, \n             t992, t993, t994, t995, t996, t997, t998, t999;\n      int a1474, a1475, a1476, a1477, a1518;\n      a1474 = (threadIdx_x / 16);\n      a1475 = (threadIdx_x % 16);\n      a1476 = ((512*a1474) + (2*a1475));\n      s434 = T3[a1476];\n      s435 = T3[(a1476 + 1)];\n      s436 = T3[(a1476 + 256)];\n      s437 = T3[(a1476 + 257)];\n      a1477 = (32*a1475);\n      a1478 = D3[a1477];\n      a1479 = D3[(a1477 + 1)];\n      s438 = ((a1478*s434) - (a1479*s435));\n      s439 = ((a1479*s434) + (a1478*s435));\n      a1480 = D3[(a1477 + 2)];\n      a1481 = D3[(a1477 + 3)];\n      s440 = ((a1480*s436) - (a1481*s437));\n      s441 = ((a1481*s436) + (a1480*s437));\n      t970 = (s438 + s440);\n      t971 = (s439 + s441);\n      t972 = (s438 - s440);\n      t973 = (s439 - s441);\n      s442 = T3[(a1476 + 128)];\n      s443 = T3[(a1476 + 129)];\n      s444 = T3[(a1476 + 384)];\n      s445 = T3[(a1476 + 385)];\n      a1482 = D3[(4 + a1477)];\n      a1483 = D3[(5 + a1477)];\n      s446 = ((a1482*s442) - (a1483*s443));\n      s447 = ((a1483*s442) + (a1482*s443));\n      a1484 = D3[(6 + a1477)];\n      a1485 = D3[(7 + a1477)];\n      s448 = ((a1484*s444) - (a1485*s445));\n      s449 = ((a1485*s444) + (a1484*s445));\n      t974 = (s446 + s448);\n      t975 = (s447 + s449);\n      t976 = (s446 - s448);\n      t977 = (s447 - s449);\n      t978 = (t970 + t974);\n      t979 = (t971 + t975);\n      t980 = (t970 - t974);\n      t981 = (t971 - t975);\n      t982 = (t972 + t977);\n      t983 = (t973 - t976);\n      t984 = (t972 - t977);\n      t985 = (t973 + t976);\n      s450 = T3[(a1476 + 32)];\n      s451 = T3[(a1476 + 33)];\n      s452 = T3[(a1476 + 288)];\n      s453 = T3[(a1476 + 289)];\n      a1486 = D3[(a1477 + 8)];\n      a1487 = D3[(9 + a1477)];\n      s454 = ((a1486*s450) - (a1487*s451));\n      s455 = ((a1487*s450) + (a1486*s451));\n      a1488 = D3[(10 + a1477)];\n      a1489 = D3[(11 + a1477)];\n      s456 = ((a1488*s452) - (a1489*s453));\n      s457 = ((a1489*s452) + (a1488*s453));\n      t986 = (s454 + s456);\n      t987 = (s455 + s457);\n      t988 = (s454 - s456);\n      t989 = (s455 - s457);\n      s458 = T3[(a1476 + 160)];\n      s459 = T3[(a1476 + 161)];\n      s460 = T3[(a1476 + 416)];\n      s461 = T3[(a1476 + 417)];\n      a1490 = D3[(12 + a1477)];\n      a1491 = D3[(13 + a1477)];\n      s462 = ((a1490*s458) - (a1491*s459));\n      s463 = ((a1491*s458) + (a1490*s459));\n      a1492 = D3[(14 + a1477)];\n      a1493 = D3[(15 + a1477)];\n      s464 = ((a1492*s460) - (a1493*s461));\n      s465 = ((a1493*s460) + (a1492*s461));\n      t990 = (s462 + s464);\n      t991 = (s463 + s465);\n      t992 = (s462 - s464);\n      t993 = (s463 - s465);\n      t994 = (t986 + t990);\n      t995 = (t987 + t991);\n      a1494 = (0.70710678118654757*(t986 - t990));\n      a1495 = (0.70710678118654757*(t987 - t991));\n      s466 = (a1494 + a1495);\n      s467 = (a1495 - a1494);\n      t996 = (t988 + t993);\n      t997 = (t989 - t992);\n      t998 = (t988 - t993);\n      t999 = (t989 + t992);\n      s468 = ((0.92387953251128674*t996) + (0.38268343236508978*t997));\n      s469 = ((0.92387953251128674*t997) - (0.38268343236508978*t996));\n      s470 = ((0.38268343236508978*t998) + (0.92387953251128674*t999));\n      s471 = ((0.38268343236508978*t999) - (0.92387953251128674*t998));\n      s472 = T3[(a1476 + 64)];\n      s473 = T3[(a1476 + 65)];\n      s474 = T3[(a1476 + 320)];\n      s475 = T3[(a1476 + 321)];\n      a1496 = D3[(a1477 + 16)];\n      a1497 = D3[(17 + a1477)];\n      s476 = ((a1496*s472) - (a1497*s473));\n      s477 = ((a1497*s472) + (a1496*s473));\n      a1498 = D3[(18 + a1477)];\n      a1499 = D3[(19 + a1477)];\n      s478 = ((a1498*s474) - (a1499*s475));\n      s479 = ((a1499*s474) + (a1498*s475));\n      t1000 = (s476 + s478);\n      t1001 = (s477 + s479);\n      t1002 = (s476 - s478);\n      t1003 = (s477 - s479);\n      s480 = T3[(a1476 + 192)];\n      s481 = T3[(a1476 + 193)];\n      s482 = T3[(a1476 + 448)];\n      s483 = T3[(a1476 + 449)];\n      a1500 = D3[(20 + a1477)];\n      a1501 = D3[(21 + a1477)];\n      s484 = ((a1500*s480) - (a1501*s481));\n      s485 = ((a1501*s480) + (a1500*s481));\n      a1502 = D3[(22 + a1477)];\n      a1503 = D3[(23 + a1477)];\n      s486 = ((a1502*s482) - (a1503*s483));\n      s487 = ((a1503*s482) + (a1502*s483));\n      t1004 = (s484 + s486);\n      t1005 = (s485 + s487);\n      t1006 = (s484 - s486);\n      t1007 = (s485 - s487);\n      t1008 = (t1000 + t1004);\n      t1009 = (t1001 + t1005);\n      t1010 = (t1000 - t1004);\n      t1011 = (t1001 - t1005);\n      a1504 = (0.70710678118654757*(t1002 + t1007));\n      a1505 = (0.70710678118654757*(t1003 - t1006));\n      s488 = (a1504 + a1505);\n      s489 = (a1505 - a1504);\n      a1506 = (0.70710678118654757*(t1003 + t1006));\n      a1507 = (0.70710678118654757*(t1002 - t1007));\n      s490 = (a1506 - a1507);\n      s491 = (a1507 + a1506);\n      s492 = T3[(a1476 + 96)];\n      s493 = T3[(a1476 + 97)];\n      s494 = T3[(a1476 + 352)];\n      s495 = T3[(a1476 + 353)];\n      a1508 = D3[(a1477 + 24)];\n      a1509 = D3[(25 + a1477)];\n      s496 = ((a1508*s492) - (a1509*s493));\n      s497 = ((a1509*s492) + (a1508*s493));\n      a1510 = D3[(26 + a1477)];\n      a1511 = D3[(27 + a1477)];\n      s498 = ((a1510*s494) - (a1511*s495));\n      s499 = ((a1511*s494) + (a1510*s495));\n      t1012 = (s496 + s498);\n      t1013 = (s497 + s499);\n      t1014 = (s496 - s498);\n      t1015 = (s497 - s499);\n      s500 = T3[(a1476 + 224)];\n      s501 = T3[(a1476 + 225)];\n      s502 = T3[(a1476 + 480)];\n      s503 = T3[(a1476 + 481)];\n      a1512 = D3[(28 + a1477)];\n      a1513 = D3[(29 + a1477)];\n      s504 = ((a1512*s500) - (a1513*s501));\n      s505 = ((a1513*s500) + (a1512*s501));\n      a1514 = D3[(30 + a1477)];\n      a1515 = D3[(31 + a1477)];\n      s506 = ((a1514*s502) - (a1515*s503));\n      s507 = ((a1515*s502) + (a1514*s503));\n      t1016 = (s504 + s506);\n      t1017 = (s505 + s507);\n      t1018 = (s504 - s506);\n      t1019 = (s505 - s507);\n      t1020 = (t1012 + t1016);\n      t1021 = (t1013 + t1017);\n      a1516 = (0.70710678118654757*(t1013 - t1017));\n      a1517 = (0.70710678118654757*(t1012 - t1016));\n      s508 = (a1516 - a1517);\n      s509 = (a1517 + a1516);\n      t1022 = (t1014 + t1019);\n      t1023 = (t1015 - t1018);\n      t1024 = (t1014 - t1019);\n      t1025 = (t1015 + t1018);\n      s510 = ((0.38268343236508978*t1022) + (0.92387953251128674*t1023));\n      s511 = ((0.38268343236508978*t1023) - (0.92387953251128674*t1022));\n      s512 = ((0.92387953251128674*t1024) + (0.38268343236508978*t1025));\n      s513 = ((0.38268343236508978*t1024) - (0.92387953251128674*t1025));\n      t1026 = (t978 + t1008);\n      t1027 = (t979 + t1009);\n      t1028 = (t978 - t1008);\n      t1029 = (t979 - t1009);\n      t1030 = (t994 + t1020);\n      t1031 = (t995 + t1021);\n      t1032 = (t994 - t1020);\n      t1033 = (t995 - t1021);\n      a1518 = ((8*blockIdx_x) + (131072*a1475) + (2*a1474));\n      P1[a1518] = (t1026 + t1030);\n      P1[(a1518 + 1)] = (t1027 + t1031);\n      P1[(a1518 + 16777216)] = (t1026 - t1030);\n      P1[(a1518 + 16777217)] = (t1027 - t1031);\n      P1[(a1518 + 8388608)] = (t1028 + t1033);\n      P1[(a1518 + 8388609)] = (t1029 - t1032);\n      P1[(a1518 + 25165824)] = (t1028 - t1033);\n      P1[(a1518 + 25165825)] = (t1029 + t1032);\n      t1034 = (t982 + s488);\n      t1035 = (t983 + s489);\n      t1036 = (t982 - s488);\n      t1037 = (t983 - s489);\n      t1038 = (s468 + s510);\n      t1039 = (s469 + s511);\n      t1040 = (s468 - s510);\n      t1041 = (s469 - s511);\n      P1[(a1518 + 2097152)] = (t1034 + t1038);\n      P1[(a1518 + 2097153)] = (t1035 + t1039);\n      P1[(a1518 + 18874368)] = (t1034 - t1038);\n      P1[(a1518 + 18874369)] = (t1035 - t1039);\n      P1[(a1518 + 10485760)] = (t1036 + t1041);\n      P1[(a1518 + 10485761)] = (t1037 - t1040);\n      P1[(a1518 + 27262976)] = (t1036 - t1041);\n      P1[(a1518 + 27262977)] = (t1037 + t1040);\n      t1042 = (t980 + t1011);\n      t1043 = (t981 - t1010);\n      t1044 = (t980 - t1011);\n      t1045 = (t981 + t1010);\n      t1046 = (s466 + s508);\n      t1047 = (s467 - s509);\n      t1048 = (s466 - s508);\n      t1049 = (s467 + s509);\n      P1[(a1518 + 4194304)] = (t1042 + t1046);\n      P1[(a1518 + 4194305)] = (t1043 + t1047);\n      P1[(a1518 + 20971520)] = (t1042 - t1046);\n      P1[(a1518 + 20971521)] = (t1043 - t1047);\n      P1[(a1518 + 12582912)] = (t1044 + t1049);\n      P1[(a1518 + 12582913)] = (t1045 - t1048);\n      P1[(a1518 + 29360128)] = (t1044 - t1049);\n      P1[(a1518 + 29360129)] = (t1045 + t1048);\n      t1050 = (t984 + s490);\n      t1051 = (t985 - s491);\n      t1052 = (t984 - s490);\n      t1053 = (t985 + s491);\n      t1054 = (s470 - s512);\n      t1055 = (s471 + s513);\n      t1056 = (s470 + s512);\n      t1057 = (s471 - s513);\n      P1[(a1518 + 6291456)] = (t1050 + t1054);\n      P1[(a1518 + 6291457)] = (t1051 + t1055);\n      P1[(a1518 + 23068672)] = (t1050 - t1054);\n      P1[(a1518 + 23068673)] = (t1051 - t1055);\n      P1[(a1518 + 14680064)] = (t1052 + t1057);\n      P1[(a1518 + 14680065)] = (t1053 - t1056);\n      P1[(a1518 + 31457280)] = (t1052 - t1057);\n      P1[(a1518 + 31457281)] = (t1053 + t1056);\n          }\n  }\n}\n\nvoid ker_zmddft_fwd_256x256x256_cu1(const double *D3, const double *P1, double *P2)\n{\n    {\n    double T33[2048];\n        {\n      double a2012, a2013, a2014, a2015, a2016, a2017, a2018, a2019, \n             s658, s659, s660, s661, s662, s663, s664, s665, \n             s666, s667, s668, s669, s670, s671, s672, s673, \n             s674, s675, s676, s677, s678, s679, s680, s681, \n             s682, s683, s684, s685, s686, s687, s688, s689, \n             s690, s691, s692, s693, s694, s695, s696, s697, \n             s698, s699, s700, s701, s702, s703, s704, s705, \n             t1402, t1403, t1404, t1405, t1406, t1407, t1408, t1409, \n             t1410, t1411, t1412, t1413, t1414, t1415, t1416, t1417, \n             t1418, t1419, t1420, t1421, t1422, t1423, t1424, t1425, \n             t1426, t1427, t1428, t1429, t1430, t1431, t1432, t1433, \n             t1434, t1435, t1436, t1437, t1438, t1439, t1440, t1441, \n             t1442, t1443, t1444, t1445, t1446, t1447, t1448, t1449, \n             t1450, t1451, t1452, t1453, t1454, t1455, t1456, t1457, \n             t1458, t1459, t1460, t1461, t1462, t1463, t1464, t1465, \n             t1466, t1467, t1468, t1469, t1470, t1471, t1472, t1473, \n             t1474, t1475, t1476, t1477, t1478, t1479, t1480, t1481, \n             t1482, t1483, t1484, t1485, t1486, t1487, t1488, t1489;\n      int a2009, a2010, a2011, a2020;\n      int threadIdx_x = omp_get_thread_num();\n      int blockIdx_x = omp_get_team_num();\n      a2009 = (512*(threadIdx_x / 16));\n      a2010 = (threadIdx_x % 16);\n      a2011 = ((2048*blockIdx_x) + a2009 + (2*a2010));\n      s658 = P1[a2011];\n      s659 = P1[(a2011 + 1)];\n      s660 = P1[(a2011 + 256)];\n      s661 = P1[(a2011 + 257)];\n      t1402 = (s658 + s660);\n      t1403 = (s659 + s661);\n      t1404 = (s658 - s660);\n      t1405 = (s659 - s661);\n      s662 = P1[(a2011 + 128)];\n      s663 = P1[(a2011 + 129)];\n      s664 = P1[(a2011 + 384)];\n      s665 = P1[(a2011 + 385)];\n      t1406 = (s662 + s664);\n      t1407 = (s663 + s665);\n      t1408 = (s662 - s664);\n      t1409 = (s663 - s665);\n      t1410 = (t1402 + t1406);\n      t1411 = (t1403 + t1407);\n      t1412 = (t1402 - t1406);\n      t1413 = (t1403 - t1407);\n      t1414 = (t1404 + t1409);\n      t1415 = (t1405 - t1408);\n      t1416 = (t1404 - t1409);\n      t1417 = (t1405 + t1408);\n      s666 = P1[(a2011 + 32)];\n      s667 = P1[(a2011 + 33)];\n      s668 = P1[(a2011 + 288)];\n      s669 = P1[(a2011 + 289)];\n      t1418 = (s666 + s668);\n      t1419 = (s667 + s669);\n      t1420 = (s666 - s668);\n      t1421 = (s667 - s669);\n      s670 = P1[(a2011 + 160)];\n      s671 = P1[(a2011 + 161)];\n      s672 = P1[(a2011 + 416)];\n      s673 = P1[(a2011 + 417)];\n      t1422 = (s670 + s672);\n      t1423 = (s671 + s673);\n      t1424 = (s670 - s672);\n      t1425 = (s671 - s673);\n      t1426 = (t1418 + t1422);\n      t1427 = (t1419 + t1423);\n      a2012 = (0.70710678118654757*(t1418 - t1422));\n      a2013 = (0.70710678118654757*(t1419 - t1423));\n      s674 = (a2012 + a2013);\n      s675 = (a2013 - a2012);\n      t1428 = (t1420 + t1425);\n      t1429 = (t1421 - t1424);\n      t1430 = (t1420 - t1425);\n      t1431 = (t1421 + t1424);\n      s676 = ((0.92387953251128674*t1428) + (0.38268343236508978*t1429));\n      s677 = ((0.92387953251128674*t1429) - (0.38268343236508978*t1428));\n      s678 = ((0.38268343236508978*t1430) + (0.92387953251128674*t1431));\n      s679 = ((0.38268343236508978*t1431) - (0.92387953251128674*t1430));\n      s680 = P1[(a2011 + 64)];\n      s681 = P1[(a2011 + 65)];\n      s682 = P1[(a2011 + 320)];\n      s683 = P1[(a2011 + 321)];\n      t1432 = (s680 + s682);\n      t1433 = (s681 + s683);\n      t1434 = (s680 - s682);\n      t1435 = (s681 - s683);\n      s684 = P1[(a2011 + 192)];\n      s685 = P1[(a2011 + 193)];\n      s686 = P1[(a2011 + 448)];\n      s687 = P1[(a2011 + 449)];\n      t1436 = (s684 + s686);\n      t1437 = (s685 + s687);\n      t1438 = (s684 - s686);\n      t1439 = (s685 - s687);\n      t1440 = (t1432 + t1436);\n      t1441 = (t1433 + t1437);\n      t1442 = (t1432 - t1436);\n      t1443 = (t1433 - t1437);\n      a2014 = (0.70710678118654757*(t1434 + t1439));\n      a2015 = (0.70710678118654757*(t1435 - t1438));\n      s688 = (a2014 + a2015);\n      s689 = (a2015 - a2014);\n      a2016 = (0.70710678118654757*(t1435 + t1438));\n      a2017 = (0.70710678118654757*(t1434 - t1439));\n      s690 = (a2016 - a2017);\n      s691 = (a2017 + a2016);\n      s692 = P1[(a2011 + 96)];\n      s693 = P1[(a2011 + 97)];\n      s694 = P1[(a2011 + 352)];\n      s695 = P1[(a2011 + 353)];\n      t1444 = (s692 + s694);\n      t1445 = (s693 + s695);\n      t1446 = (s692 - s694);\n      t1447 = (s693 - s695);\n      s696 = P1[(a2011 + 224)];\n      s697 = P1[(a2011 + 225)];\n      s698 = P1[(a2011 + 480)];\n      s699 = P1[(a2011 + 481)];\n      t1448 = (s696 + s698);\n      t1449 = (s697 + s699);\n      t1450 = (s696 - s698);\n      t1451 = (s697 - s699);\n      t1452 = (t1444 + t1448);\n      t1453 = (t1445 + t1449);\n      a2018 = (0.70710678118654757*(t1445 - t1449));\n      a2019 = (0.70710678118654757*(t1444 - t1448));\n      s700 = (a2018 - a2019);\n      s701 = (a2019 + a2018);\n      t1454 = (t1446 + t1451);\n      t1455 = (t1447 - t1450);\n      t1456 = (t1446 - t1451);\n      t1457 = (t1447 + t1450);\n      s702 = ((0.38268343236508978*t1454) + (0.92387953251128674*t1455));\n      s703 = ((0.38268343236508978*t1455) - (0.92387953251128674*t1454));\n      s704 = ((0.92387953251128674*t1456) + (0.38268343236508978*t1457));\n      s705 = ((0.38268343236508978*t1456) - (0.92387953251128674*t1457));\n      t1458 = (t1410 + t1440);\n      t1459 = (t1411 + t1441);\n      t1460 = (t1410 - t1440);\n      t1461 = (t1411 - t1441);\n      t1462 = (t1426 + t1452);\n      t1463 = (t1427 + t1453);\n      t1464 = (t1426 - t1452);\n      t1465 = (t1427 - t1453);\n      a2020 = (a2009 + (32*a2010));\n      T33[a2020] = (t1458 + t1462);\n      T33[(a2020 + 1)] = (t1459 + t1463);\n      T33[(a2020 + 16)] = (t1458 - t1462);\n      T33[(a2020 + 17)] = (t1459 - t1463);\n      T33[(a2020 + 8)] = (t1460 + t1465);\n      T33[(a2020 + 9)] = (t1461 - t1464);\n      T33[(a2020 + 24)] = (t1460 - t1465);\n      T33[(a2020 + 25)] = (t1461 + t1464);\n      t1466 = (t1414 + s688);\n      t1467 = (t1415 + s689);\n      t1468 = (t1414 - s688);\n      t1469 = (t1415 - s689);\n      t1470 = (s676 + s702);\n      t1471 = (s677 + s703);\n      t1472 = (s676 - s702);\n      t1473 = (s677 - s703);\n      T33[(a2020 + 2)] = (t1466 + t1470);\n      T33[(a2020 + 3)] = (t1467 + t1471);\n      T33[(a2020 + 18)] = (t1466 - t1470);\n      T33[(a2020 + 19)] = (t1467 - t1471);\n      T33[(a2020 + 10)] = (t1468 + t1473);\n      T33[(a2020 + 11)] = (t1469 - t1472);\n      T33[(a2020 + 26)] = (t1468 - t1473);\n      T33[(a2020 + 27)] = (t1469 + t1472);\n      t1474 = (t1412 + t1443);\n      t1475 = (t1413 - t1442);\n      t1476 = (t1412 - t1443);\n      t1477 = (t1413 + t1442);\n      t1478 = (s674 + s700);\n      t1479 = (s675 - s701);\n      t1480 = (s674 - s700);\n      t1481 = (s675 + s701);\n      T33[(a2020 + 4)] = (t1474 + t1478);\n      T33[(a2020 + 5)] = (t1475 + t1479);\n      T33[(a2020 + 20)] = (t1474 - t1478);\n      T33[(a2020 + 21)] = (t1475 - t1479);\n      T33[(a2020 + 12)] = (t1476 + t1481);\n      T33[(a2020 + 13)] = (t1477 - t1480);\n      T33[(a2020 + 28)] = (t1476 - t1481);\n      T33[(a2020 + 29)] = (t1477 + t1480);\n      t1482 = (t1416 + s690);\n      t1483 = (t1417 - s691);\n      t1484 = (t1416 - s690);\n      t1485 = (t1417 + s691);\n      t1486 = (s678 - s704);\n      t1487 = (s679 + s705);\n      t1488 = (s678 + s704);\n      t1489 = (s679 - s705);\n      T33[(a2020 + 6)] = (t1482 + t1486);\n      T33[(a2020 + 7)] = (t1483 + t1487);\n      T33[(a2020 + 22)] = (t1482 - t1486);\n      T33[(a2020 + 23)] = (t1483 - t1487);\n      T33[(a2020 + 14)] = (t1484 + t1489);\n      T33[(a2020 + 15)] = (t1485 - t1488);\n      T33[(a2020 + 30)] = (t1484 - t1489);\n      T33[(a2020 + 31)] = (t1485 + t1488);\n            double a2995, a2996, a2997, a2998, a2999, a3000, a3001, a3002, \n             a3003, a3004, a3005, a3006, a3007, a3008, a3009, a3010, \n             a3011, a3012, a3013, a3014, a3015, a3016, a3017, a3018, \n             a3019, a3020, a3021, a3022, a3023, a3024, a3025, a3026, \n             a3027, a3028, a3029, a3030, a3031, a3032, a3033, a3034, \n             s1000, s1001, s1002, s1003, s1004, s1005, s1006, s1007, \n             s1008, s1009, s1010, s1011, s1012, s1013, s1014, s1015, \n             s1016, s1017, s1018, s1019, s1020, s1021, s1022, s1023, \n             s1024, s1025, s946, s947, s948, s949, s950, s951, \n             s952, s953, s954, s955, s956, s957, s958, s959, \n             s960, s961, s962, s963, s964, s965, s966, s967, \n             s968, s969, s970, s971, s972, s973, s974, s975, \n             s976, s977, s978, s979, s980, s981, s982, s983, \n             s984, s985, s986, s987, s988, s989, s990, s991, \n             s992, s993, s994, s995, s996, s997, s998, s999, \n             t1834, t1835, t1836, t1837, t1838, t1839, t1840, t1841, \n             t1842, t1843, t1844, t1845, t1846, t1847, t1848, t1849, \n             t1850, t1851, t1852, t1853, t1854, t1855, t1856, t1857, \n             t1858, t1859, t1860, t1861, t1862, t1863, t1864, t1865, \n             t1866, t1867, t1868, t1869, t1870, t1871, t1872, t1873, \n             t1874, t1875, t1876, t1877, t1878, t1879, t1880, t1881, \n             t1882, t1883, t1884, t1885, t1886, t1887, t1888, t1889, \n             t1890, t1891, t1892, t1893, t1894, t1895, t1896, t1897, \n             t1898, t1899, t1900, t1901, t1902, t1903, t1904, t1905, \n             t1906, t1907, t1908, t1909, t1910, t1911, t1912, t1913, \n             t1914, t1915, t1916, t1917, t1918, t1919, t1920, t1921;\n      int a2991, a2992, a2993, a2994, a3035;\n      a2991 = (threadIdx_x / 16);\n      a2992 = (threadIdx_x % 16);\n      a2993 = ((512*a2991) + (2*a2992));\n      s946 = T33[a2993];\n      s947 = T33[(a2993 + 1)];\n      s948 = T33[(a2993 + 256)];\n      s949 = T33[(a2993 + 257)];\n      a2994 = (32*a2992);\n      a2995 = D3[a2994];\n      a2996 = D3[(a2994 + 1)];\n      s950 = ((a2995*s946) - (a2996*s947));\n      s951 = ((a2996*s946) + (a2995*s947));\n      a2997 = D3[(a2994 + 2)];\n      a2998 = D3[(a2994 + 3)];\n      s952 = ((a2997*s948) - (a2998*s949));\n      s953 = ((a2998*s948) + (a2997*s949));\n      t1834 = (s950 + s952);\n      t1835 = (s951 + s953);\n      t1836 = (s950 - s952);\n      t1837 = (s951 - s953);\n      s954 = T33[(a2993 + 128)];\n      s955 = T33[(a2993 + 129)];\n      s956 = T33[(a2993 + 384)];\n      s957 = T33[(a2993 + 385)];\n      a2999 = D3[(4 + a2994)];\n      a3000 = D3[(5 + a2994)];\n      s958 = ((a2999*s954) - (a3000*s955));\n      s959 = ((a3000*s954) + (a2999*s955));\n      a3001 = D3[(6 + a2994)];\n      a3002 = D3[(7 + a2994)];\n      s960 = ((a3001*s956) - (a3002*s957));\n      s961 = ((a3002*s956) + (a3001*s957));\n      t1838 = (s958 + s960);\n      t1839 = (s959 + s961);\n      t1840 = (s958 - s960);\n      t1841 = (s959 - s961);\n      t1842 = (t1834 + t1838);\n      t1843 = (t1835 + t1839);\n      t1844 = (t1834 - t1838);\n      t1845 = (t1835 - t1839);\n      t1846 = (t1836 + t1841);\n      t1847 = (t1837 - t1840);\n      t1848 = (t1836 - t1841);\n      t1849 = (t1837 + t1840);\n      s962 = T33[(a2993 + 32)];\n      s963 = T33[(a2993 + 33)];\n      s964 = T33[(a2993 + 288)];\n      s965 = T33[(a2993 + 289)];\n      a3003 = D3[(a2994 + 8)];\n      a3004 = D3[(9 + a2994)];\n      s966 = ((a3003*s962) - (a3004*s963));\n      s967 = ((a3004*s962) + (a3003*s963));\n      a3005 = D3[(10 + a2994)];\n      a3006 = D3[(11 + a2994)];\n      s968 = ((a3005*s964) - (a3006*s965));\n      s969 = ((a3006*s964) + (a3005*s965));\n      t1850 = (s966 + s968);\n      t1851 = (s967 + s969);\n      t1852 = (s966 - s968);\n      t1853 = (s967 - s969);\n      s970 = T33[(a2993 + 160)];\n      s971 = T33[(a2993 + 161)];\n      s972 = T33[(a2993 + 416)];\n      s973 = T33[(a2993 + 417)];\n      a3007 = D3[(12 + a2994)];\n      a3008 = D3[(13 + a2994)];\n      s974 = ((a3007*s970) - (a3008*s971));\n      s975 = ((a3008*s970) + (a3007*s971));\n      a3009 = D3[(14 + a2994)];\n      a3010 = D3[(15 + a2994)];\n      s976 = ((a3009*s972) - (a3010*s973));\n      s977 = ((a3010*s972) + (a3009*s973));\n      t1854 = (s974 + s976);\n      t1855 = (s975 + s977);\n      t1856 = (s974 - s976);\n      t1857 = (s975 - s977);\n      t1858 = (t1850 + t1854);\n      t1859 = (t1851 + t1855);\n      a3011 = (0.70710678118654757*(t1850 - t1854));\n      a3012 = (0.70710678118654757*(t1851 - t1855));\n      s978 = (a3011 + a3012);\n      s979 = (a3012 - a3011);\n      t1860 = (t1852 + t1857);\n      t1861 = (t1853 - t1856);\n      t1862 = (t1852 - t1857);\n      t1863 = (t1853 + t1856);\n      s980 = ((0.92387953251128674*t1860) + (0.38268343236508978*t1861));\n      s981 = ((0.92387953251128674*t1861) - (0.38268343236508978*t1860));\n      s982 = ((0.38268343236508978*t1862) + (0.92387953251128674*t1863));\n      s983 = ((0.38268343236508978*t1863) - (0.92387953251128674*t1862));\n      s984 = T33[(a2993 + 64)];\n      s985 = T33[(a2993 + 65)];\n      s986 = T33[(a2993 + 320)];\n      s987 = T33[(a2993 + 321)];\n      a3013 = D3[(a2994 + 16)];\n      a3014 = D3[(17 + a2994)];\n      s988 = ((a3013*s984) - (a3014*s985));\n      s989 = ((a3014*s984) + (a3013*s985));\n      a3015 = D3[(18 + a2994)];\n      a3016 = D3[(19 + a2994)];\n      s990 = ((a3015*s986) - (a3016*s987));\n      s991 = ((a3016*s986) + (a3015*s987));\n      t1864 = (s988 + s990);\n      t1865 = (s989 + s991);\n      t1866 = (s988 - s990);\n      t1867 = (s989 - s991);\n      s992 = T33[(a2993 + 192)];\n      s993 = T33[(a2993 + 193)];\n      s994 = T33[(a2993 + 448)];\n      s995 = T33[(a2993 + 449)];\n      a3017 = D3[(20 + a2994)];\n      a3018 = D3[(21 + a2994)];\n      s996 = ((a3017*s992) - (a3018*s993));\n      s997 = ((a3018*s992) + (a3017*s993));\n      a3019 = D3[(22 + a2994)];\n      a3020 = D3[(23 + a2994)];\n      s998 = ((a3019*s994) - (a3020*s995));\n      s999 = ((a3020*s994) + (a3019*s995));\n      t1868 = (s996 + s998);\n      t1869 = (s997 + s999);\n      t1870 = (s996 - s998);\n      t1871 = (s997 - s999);\n      t1872 = (t1864 + t1868);\n      t1873 = (t1865 + t1869);\n      t1874 = (t1864 - t1868);\n      t1875 = (t1865 - t1869);\n      a3021 = (0.70710678118654757*(t1866 + t1871));\n      a3022 = (0.70710678118654757*(t1867 - t1870));\n      s1000 = (a3021 + a3022);\n      s1001 = (a3022 - a3021);\n      a3023 = (0.70710678118654757*(t1867 + t1870));\n      a3024 = (0.70710678118654757*(t1866 - t1871));\n      s1002 = (a3023 - a3024);\n      s1003 = (a3024 + a3023);\n      s1004 = T33[(a2993 + 96)];\n      s1005 = T33[(a2993 + 97)];\n      s1006 = T33[(a2993 + 352)];\n      s1007 = T33[(a2993 + 353)];\n      a3025 = D3[(a2994 + 24)];\n      a3026 = D3[(25 + a2994)];\n      s1008 = ((a3025*s1004) - (a3026*s1005));\n      s1009 = ((a3026*s1004) + (a3025*s1005));\n      a3027 = D3[(26 + a2994)];\n      a3028 = D3[(27 + a2994)];\n      s1010 = ((a3027*s1006) - (a3028*s1007));\n      s1011 = ((a3028*s1006) + (a3027*s1007));\n      t1876 = (s1008 + s1010);\n      t1877 = (s1009 + s1011);\n      t1878 = (s1008 - s1010);\n      t1879 = (s1009 - s1011);\n      s1012 = T33[(a2993 + 224)];\n      s1013 = T33[(a2993 + 225)];\n      s1014 = T33[(a2993 + 480)];\n      s1015 = T33[(a2993 + 481)];\n      a3029 = D3[(28 + a2994)];\n      a3030 = D3[(29 + a2994)];\n      s1016 = ((a3029*s1012) - (a3030*s1013));\n      s1017 = ((a3030*s1012) + (a3029*s1013));\n      a3031 = D3[(30 + a2994)];\n      a3032 = D3[(31 + a2994)];\n      s1018 = ((a3031*s1014) - (a3032*s1015));\n      s1019 = ((a3032*s1014) + (a3031*s1015));\n      t1880 = (s1016 + s1018);\n      t1881 = (s1017 + s1019);\n      t1882 = (s1016 - s1018);\n      t1883 = (s1017 - s1019);\n      t1884 = (t1876 + t1880);\n      t1885 = (t1877 + t1881);\n      a3033 = (0.70710678118654757*(t1877 - t1881));\n      a3034 = (0.70710678118654757*(t1876 - t1880));\n      s1020 = (a3033 - a3034);\n      s1021 = (a3034 + a3033);\n      t1886 = (t1878 + t1883);\n      t1887 = (t1879 - t1882);\n      t1888 = (t1878 - t1883);\n      t1889 = (t1879 + t1882);\n      s1022 = ((0.38268343236508978*t1886) + (0.92387953251128674*t1887));\n      s1023 = ((0.38268343236508978*t1887) - (0.92387953251128674*t1886));\n      s1024 = ((0.92387953251128674*t1888) + (0.38268343236508978*t1889));\n      s1025 = ((0.38268343236508978*t1888) - (0.92387953251128674*t1889));\n      t1890 = (t1842 + t1872);\n      t1891 = (t1843 + t1873);\n      t1892 = (t1842 - t1872);\n      t1893 = (t1843 - t1873);\n      t1894 = (t1858 + t1884);\n      t1895 = (t1859 + t1885);\n      t1896 = (t1858 - t1884);\n      t1897 = (t1859 - t1885);\n      a3035 = ((8*blockIdx_x) + (131072*a2992) + (2*a2991));\n      P2[a3035] = (t1890 + t1894);\n      P2[(a3035 + 1)] = (t1891 + t1895);\n      P2[(a3035 + 16777216)] = (t1890 - t1894);\n      P2[(a3035 + 16777217)] = (t1891 - t1895);\n      P2[(a3035 + 8388608)] = (t1892 + t1897);\n      P2[(a3035 + 8388609)] = (t1893 - t1896);\n      P2[(a3035 + 25165824)] = (t1892 - t1897);\n      P2[(a3035 + 25165825)] = (t1893 + t1896);\n      t1898 = (t1846 + s1000);\n      t1899 = (t1847 + s1001);\n      t1900 = (t1846 - s1000);\n      t1901 = (t1847 - s1001);\n      t1902 = (s980 + s1022);\n      t1903 = (s981 + s1023);\n      t1904 = (s980 - s1022);\n      t1905 = (s981 - s1023);\n      P2[(a3035 + 2097152)] = (t1898 + t1902);\n      P2[(a3035 + 2097153)] = (t1899 + t1903);\n      P2[(a3035 + 18874368)] = (t1898 - t1902);\n      P2[(a3035 + 18874369)] = (t1899 - t1903);\n      P2[(a3035 + 10485760)] = (t1900 + t1905);\n      P2[(a3035 + 10485761)] = (t1901 - t1904);\n      P2[(a3035 + 27262976)] = (t1900 - t1905);\n      P2[(a3035 + 27262977)] = (t1901 + t1904);\n      t1906 = (t1844 + t1875);\n      t1907 = (t1845 - t1874);\n      t1908 = (t1844 - t1875);\n      t1909 = (t1845 + t1874);\n      t1910 = (s978 + s1020);\n      t1911 = (s979 - s1021);\n      t1912 = (s978 - s1020);\n      t1913 = (s979 + s1021);\n      P2[(a3035 + 4194304)] = (t1906 + t1910);\n      P2[(a3035 + 4194305)] = (t1907 + t1911);\n      P2[(a3035 + 20971520)] = (t1906 - t1910);\n      P2[(a3035 + 20971521)] = (t1907 - t1911);\n      P2[(a3035 + 12582912)] = (t1908 + t1913);\n      P2[(a3035 + 12582913)] = (t1909 - t1912);\n      P2[(a3035 + 29360128)] = (t1908 - t1913);\n      P2[(a3035 + 29360129)] = (t1909 + t1912);\n      t1914 = (t1848 + s1002);\n      t1915 = (t1849 - s1003);\n      t1916 = (t1848 - s1002);\n      t1917 = (t1849 + s1003);\n      t1918 = (s982 - s1024);\n      t1919 = (s983 + s1025);\n      t1920 = (s982 + s1024);\n      t1921 = (s983 - s1025);\n      P2[(a3035 + 6291456)] = (t1914 + t1918);\n      P2[(a3035 + 6291457)] = (t1915 + t1919);\n      P2[(a3035 + 23068672)] = (t1914 - t1918);\n      P2[(a3035 + 23068673)] = (t1915 - t1919);\n      P2[(a3035 + 14680064)] = (t1916 + t1921);\n      P2[(a3035 + 14680065)] = (t1917 - t1920);\n      P2[(a3035 + 31457280)] = (t1916 - t1921);\n      P2[(a3035 + 31457281)] = (t1917 + t1920);\n          }\n  }\n}\n\nvoid ker_zmddft_fwd_256x256x256_cu2(const double *D3, const double *P2, double *Y) {\n    {\n    double T63[2048];\n        {\n      double a3529, a3530, a3531, a3532, a3533, a3534, a3535, a3536, \n             s1170, s1171, s1172, s1173, s1174, s1175, s1176, s1177, \n             s1178, s1179, s1180, s1181, s1182, s1183, s1184, s1185, \n             s1186, s1187, s1188, s1189, s1190, s1191, s1192, s1193, \n             s1194, s1195, s1196, s1197, s1198, s1199, s1200, s1201, \n             s1202, s1203, s1204, s1205, s1206, s1207, s1208, s1209, \n             s1210, s1211, s1212, s1213, s1214, s1215, s1216, s1217, \n             t2266, t2267, t2268, t2269, t2270, t2271, t2272, t2273, \n             t2274, t2275, t2276, t2277, t2278, t2279, t2280, t2281, \n             t2282, t2283, t2284, t2285, t2286, t2287, t2288, t2289, \n             t2290, t2291, t2292, t2293, t2294, t2295, t2296, t2297, \n             t2298, t2299, t2300, t2301, t2302, t2303, t2304, t2305, \n             t2306, t2307, t2308, t2309, t2310, t2311, t2312, t2313, \n             t2314, t2315, t2316, t2317, t2318, t2319, t2320, t2321, \n             t2322, t2323, t2324, t2325, t2326, t2327, t2328, t2329, \n             t2330, t2331, t2332, t2333, t2334, t2335, t2336, t2337, \n             t2338, t2339, t2340, t2341, t2342, t2343, t2344, t2345, \n             t2346, t2347, t2348, t2349, t2350, t2351, t2352, t2353;\n      int a3526, a3527, a3528, a3537;\n      int threadIdx_x = omp_get_thread_num();\n      int blockIdx_x = omp_get_team_num();\n      a3526 = (512*(threadIdx_x / 16));\n      a3527 = (threadIdx_x % 16);\n      a3528 = ((2048*blockIdx_x) + a3526 + (2*a3527));\n      s1170 = P2[a3528];\n      s1171 = P2[(a3528 + 1)];\n      s1172 = P2[(a3528 + 256)];\n      s1173 = P2[(a3528 + 257)];\n      t2266 = (s1170 + s1172);\n      t2267 = (s1171 + s1173);\n      t2268 = (s1170 - s1172);\n      t2269 = (s1171 - s1173);\n      s1174 = P2[(a3528 + 128)];\n      s1175 = P2[(a3528 + 129)];\n      s1176 = P2[(a3528 + 384)];\n      s1177 = P2[(a3528 + 385)];\n      t2270 = (s1174 + s1176);\n      t2271 = (s1175 + s1177);\n      t2272 = (s1174 - s1176);\n      t2273 = (s1175 - s1177);\n      t2274 = (t2266 + t2270);\n      t2275 = (t2267 + t2271);\n      t2276 = (t2266 - t2270);\n      t2277 = (t2267 - t2271);\n      t2278 = (t2268 + t2273);\n      t2279 = (t2269 - t2272);\n      t2280 = (t2268 - t2273);\n      t2281 = (t2269 + t2272);\n      s1178 = P2[(a3528 + 32)];\n      s1179 = P2[(a3528 + 33)];\n      s1180 = P2[(a3528 + 288)];\n      s1181 = P2[(a3528 + 289)];\n      t2282 = (s1178 + s1180);\n      t2283 = (s1179 + s1181);\n      t2284 = (s1178 - s1180);\n      t2285 = (s1179 - s1181);\n      s1182 = P2[(a3528 + 160)];\n      s1183 = P2[(a3528 + 161)];\n      s1184 = P2[(a3528 + 416)];\n      s1185 = P2[(a3528 + 417)];\n      t2286 = (s1182 + s1184);\n      t2287 = (s1183 + s1185);\n      t2288 = (s1182 - s1184);\n      t2289 = (s1183 - s1185);\n      t2290 = (t2282 + t2286);\n      t2291 = (t2283 + t2287);\n      a3529 = (0.70710678118654757*(t2282 - t2286));\n      a3530 = (0.70710678118654757*(t2283 - t2287));\n      s1186 = (a3529 + a3530);\n      s1187 = (a3530 - a3529);\n      t2292 = (t2284 + t2289);\n      t2293 = (t2285 - t2288);\n      t2294 = (t2284 - t2289);\n      t2295 = (t2285 + t2288);\n      s1188 = ((0.92387953251128674*t2292) + (0.38268343236508978*t2293));\n      s1189 = ((0.92387953251128674*t2293) - (0.38268343236508978*t2292));\n      s1190 = ((0.38268343236508978*t2294) + (0.92387953251128674*t2295));\n      s1191 = ((0.38268343236508978*t2295) - (0.92387953251128674*t2294));\n      s1192 = P2[(a3528 + 64)];\n      s1193 = P2[(a3528 + 65)];\n      s1194 = P2[(a3528 + 320)];\n      s1195 = P2[(a3528 + 321)];\n      t2296 = (s1192 + s1194);\n      t2297 = (s1193 + s1195);\n      t2298 = (s1192 - s1194);\n      t2299 = (s1193 - s1195);\n      s1196 = P2[(a3528 + 192)];\n      s1197 = P2[(a3528 + 193)];\n      s1198 = P2[(a3528 + 448)];\n      s1199 = P2[(a3528 + 449)];\n      t2300 = (s1196 + s1198);\n      t2301 = (s1197 + s1199);\n      t2302 = (s1196 - s1198);\n      t2303 = (s1197 - s1199);\n      t2304 = (t2296 + t2300);\n      t2305 = (t2297 + t2301);\n      t2306 = (t2296 - t2300);\n      t2307 = (t2297 - t2301);\n      a3531 = (0.70710678118654757*(t2298 + t2303));\n      a3532 = (0.70710678118654757*(t2299 - t2302));\n      s1200 = (a3531 + a3532);\n      s1201 = (a3532 - a3531);\n      a3533 = (0.70710678118654757*(t2299 + t2302));\n      a3534 = (0.70710678118654757*(t2298 - t2303));\n      s1202 = (a3533 - a3534);\n      s1203 = (a3534 + a3533);\n      s1204 = P2[(a3528 + 96)];\n      s1205 = P2[(a3528 + 97)];\n      s1206 = P2[(a3528 + 352)];\n      s1207 = P2[(a3528 + 353)];\n      t2308 = (s1204 + s1206);\n      t2309 = (s1205 + s1207);\n      t2310 = (s1204 - s1206);\n      t2311 = (s1205 - s1207);\n      s1208 = P2[(a3528 + 224)];\n      s1209 = P2[(a3528 + 225)];\n      s1210 = P2[(a3528 + 480)];\n      s1211 = P2[(a3528 + 481)];\n      t2312 = (s1208 + s1210);\n      t2313 = (s1209 + s1211);\n      t2314 = (s1208 - s1210);\n      t2315 = (s1209 - s1211);\n      t2316 = (t2308 + t2312);\n      t2317 = (t2309 + t2313);\n      a3535 = (0.70710678118654757*(t2309 - t2313));\n      a3536 = (0.70710678118654757*(t2308 - t2312));\n      s1212 = (a3535 - a3536);\n      s1213 = (a3536 + a3535);\n      t2318 = (t2310 + t2315);\n      t2319 = (t2311 - t2314);\n      t2320 = (t2310 - t2315);\n      t2321 = (t2311 + t2314);\n      s1214 = ((0.38268343236508978*t2318) + (0.92387953251128674*t2319));\n      s1215 = ((0.38268343236508978*t2319) - (0.92387953251128674*t2318));\n      s1216 = ((0.92387953251128674*t2320) + (0.38268343236508978*t2321));\n      s1217 = ((0.38268343236508978*t2320) - (0.92387953251128674*t2321));\n      t2322 = (t2274 + t2304);\n      t2323 = (t2275 + t2305);\n      t2324 = (t2274 - t2304);\n      t2325 = (t2275 - t2305);\n      t2326 = (t2290 + t2316);\n      t2327 = (t2291 + t2317);\n      t2328 = (t2290 - t2316);\n      t2329 = (t2291 - t2317);\n      a3537 = (a3526 + (32*a3527));\n      T63[a3537] = (t2322 + t2326);\n      T63[(a3537 + 1)] = (t2323 + t2327);\n      T63[(a3537 + 16)] = (t2322 - t2326);\n      T63[(a3537 + 17)] = (t2323 - t2327);\n      T63[(a3537 + 8)] = (t2324 + t2329);\n      T63[(a3537 + 9)] = (t2325 - t2328);\n      T63[(a3537 + 24)] = (t2324 - t2329);\n      T63[(a3537 + 25)] = (t2325 + t2328);\n      t2330 = (t2278 + s1200);\n      t2331 = (t2279 + s1201);\n      t2332 = (t2278 - s1200);\n      t2333 = (t2279 - s1201);\n      t2334 = (s1188 + s1214);\n      t2335 = (s1189 + s1215);\n      t2336 = (s1188 - s1214);\n      t2337 = (s1189 - s1215);\n      T63[(a3537 + 2)] = (t2330 + t2334);\n      T63[(a3537 + 3)] = (t2331 + t2335);\n      T63[(a3537 + 18)] = (t2330 - t2334);\n      T63[(a3537 + 19)] = (t2331 - t2335);\n      T63[(a3537 + 10)] = (t2332 + t2337);\n      T63[(a3537 + 11)] = (t2333 - t2336);\n      T63[(a3537 + 26)] = (t2332 - t2337);\n      T63[(a3537 + 27)] = (t2333 + t2336);\n      t2338 = (t2276 + t2307);\n      t2339 = (t2277 - t2306);\n      t2340 = (t2276 - t2307);\n      t2341 = (t2277 + t2306);\n      t2342 = (s1186 + s1212);\n      t2343 = (s1187 - s1213);\n      t2344 = (s1186 - s1212);\n      t2345 = (s1187 + s1213);\n      T63[(a3537 + 4)] = (t2338 + t2342);\n      T63[(a3537 + 5)] = (t2339 + t2343);\n      T63[(a3537 + 20)] = (t2338 - t2342);\n      T63[(a3537 + 21)] = (t2339 - t2343);\n      T63[(a3537 + 12)] = (t2340 + t2345);\n      T63[(a3537 + 13)] = (t2341 - t2344);\n      T63[(a3537 + 28)] = (t2340 - t2345);\n      T63[(a3537 + 29)] = (t2341 + t2344);\n      t2346 = (t2280 + s1202);\n      t2347 = (t2281 - s1203);\n      t2348 = (t2280 - s1202);\n      t2349 = (t2281 + s1203);\n      t2350 = (s1190 - s1216);\n      t2351 = (s1191 + s1217);\n      t2352 = (s1190 + s1216);\n      t2353 = (s1191 - s1217);\n      T63[(a3537 + 6)] = (t2346 + t2350);\n      T63[(a3537 + 7)] = (t2347 + t2351);\n      T63[(a3537 + 22)] = (t2346 - t2350);\n      T63[(a3537 + 23)] = (t2347 - t2351);\n      T63[(a3537 + 14)] = (t2348 + t2353);\n      T63[(a3537 + 15)] = (t2349 - t2352);\n      T63[(a3537 + 30)] = (t2348 - t2353);\n      T63[(a3537 + 31)] = (t2349 + t2352);\n            double a4512, a4513, a4514, a4515, a4516, a4517, a4518, a4519, \n             a4520, a4521, a4522, a4523, a4524, a4525, a4526, a4527, \n             a4528, a4529, a4530, a4531, a4532, a4533, a4534, a4535, \n             a4536, a4537, a4538, a4539, a4540, a4541, a4542, a4543, \n             a4544, a4545, a4546, a4547, a4548, a4549, a4550, a4551, \n             s1458, s1459, s1460, s1461, s1462, s1463, s1464, s1465, \n             s1466, s1467, s1468, s1469, s1470, s1471, s1472, s1473, \n             s1474, s1475, s1476, s1477, s1478, s1479, s1480, s1481, \n             s1482, s1483, s1484, s1485, s1486, s1487, s1488, s1489, \n             s1490, s1491, s1492, s1493, s1494, s1495, s1496, s1497, \n             s1498, s1499, s1500, s1501, s1502, s1503, s1504, s1505, \n             s1506, s1507, s1508, s1509, s1510, s1511, s1512, s1513, \n             s1514, s1515, s1516, s1517, s1518, s1519, s1520, s1521, \n             s1522, s1523, s1524, s1525, s1526, s1527, s1528, s1529, \n             s1530, s1531, s1532, s1533, s1534, s1535, s1536, s1537, \n             t2698, t2699, t2700, t2701, t2702, t2703, t2704, t2705, \n             t2706, t2707, t2708, t2709, t2710, t2711, t2712, t2713, \n             t2714, t2715, t2716, t2717, t2718, t2719, t2720, t2721, \n             t2722, t2723, t2724, t2725, t2726, t2727, t2728, t2729, \n             t2730, t2731, t2732, t2733, t2734, t2735, t2736, t2737, \n             t2738, t2739, t2740, t2741, t2742, t2743, t2744, t2745, \n             t2746, t2747, t2748, t2749, t2750, t2751, t2752, t2753, \n             t2754, t2755, t2756, t2757, t2758, t2759, t2760, t2761, \n             t2762, t2763, t2764, t2765, t2766, t2767, t2768, t2769, \n             t2770, t2771, t2772, t2773, t2774, t2775, t2776, t2777, \n             t2778, t2779, t2780, t2781, t2782, t2783, t2784, t2785;\n      int a4508, a4509, a4510, a4511, a4552;\n      a4508 = (threadIdx_x / 16);\n      a4509 = (threadIdx_x % 16);\n      a4510 = ((512*a4508) + (2*a4509));\n      s1458 = T63[a4510];\n      s1459 = T63[(a4510 + 1)];\n      s1460 = T63[(a4510 + 256)];\n      s1461 = T63[(a4510 + 257)];\n      a4511 = (32*a4509);\n      a4512 = D3[a4511];\n      a4513 = D3[(a4511 + 1)];\n      s1462 = ((a4512*s1458) - (a4513*s1459));\n      s1463 = ((a4513*s1458) + (a4512*s1459));\n      a4514 = D3[(a4511 + 2)];\n      a4515 = D3[(a4511 + 3)];\n      s1464 = ((a4514*s1460) - (a4515*s1461));\n      s1465 = ((a4515*s1460) + (a4514*s1461));\n      t2698 = (s1462 + s1464);\n      t2699 = (s1463 + s1465);\n      t2700 = (s1462 - s1464);\n      t2701 = (s1463 - s1465);\n      s1466 = T63[(a4510 + 128)];\n      s1467 = T63[(a4510 + 129)];\n      s1468 = T63[(a4510 + 384)];\n      s1469 = T63[(a4510 + 385)];\n      a4516 = D3[(4 + a4511)];\n      a4517 = D3[(5 + a4511)];\n      s1470 = ((a4516*s1466) - (a4517*s1467));\n      s1471 = ((a4517*s1466) + (a4516*s1467));\n      a4518 = D3[(6 + a4511)];\n      a4519 = D3[(7 + a4511)];\n      s1472 = ((a4518*s1468) - (a4519*s1469));\n      s1473 = ((a4519*s1468) + (a4518*s1469));\n      t2702 = (s1470 + s1472);\n      t2703 = (s1471 + s1473);\n      t2704 = (s1470 - s1472);\n      t2705 = (s1471 - s1473);\n      t2706 = (t2698 + t2702);\n      t2707 = (t2699 + t2703);\n      t2708 = (t2698 - t2702);\n      t2709 = (t2699 - t2703);\n      t2710 = (t2700 + t2705);\n      t2711 = (t2701 - t2704);\n      t2712 = (t2700 - t2705);\n      t2713 = (t2701 + t2704);\n      s1474 = T63[(a4510 + 32)];\n      s1475 = T63[(a4510 + 33)];\n      s1476 = T63[(a4510 + 288)];\n      s1477 = T63[(a4510 + 289)];\n      a4520 = D3[(a4511 + 8)];\n      a4521 = D3[(9 + a4511)];\n      s1478 = ((a4520*s1474) - (a4521*s1475));\n      s1479 = ((a4521*s1474) + (a4520*s1475));\n      a4522 = D3[(10 + a4511)];\n      a4523 = D3[(11 + a4511)];\n      s1480 = ((a4522*s1476) - (a4523*s1477));\n      s1481 = ((a4523*s1476) + (a4522*s1477));\n      t2714 = (s1478 + s1480);\n      t2715 = (s1479 + s1481);\n      t2716 = (s1478 - s1480);\n      t2717 = (s1479 - s1481);\n      s1482 = T63[(a4510 + 160)];\n      s1483 = T63[(a4510 + 161)];\n      s1484 = T63[(a4510 + 416)];\n      s1485 = T63[(a4510 + 417)];\n      a4524 = D3[(12 + a4511)];\n      a4525 = D3[(13 + a4511)];\n      s1486 = ((a4524*s1482) - (a4525*s1483));\n      s1487 = ((a4525*s1482) + (a4524*s1483));\n      a4526 = D3[(14 + a4511)];\n      a4527 = D3[(15 + a4511)];\n      s1488 = ((a4526*s1484) - (a4527*s1485));\n      s1489 = ((a4527*s1484) + (a4526*s1485));\n      t2718 = (s1486 + s1488);\n      t2719 = (s1487 + s1489);\n      t2720 = (s1486 - s1488);\n      t2721 = (s1487 - s1489);\n      t2722 = (t2714 + t2718);\n      t2723 = (t2715 + t2719);\n      a4528 = (0.70710678118654757*(t2714 - t2718));\n      a4529 = (0.70710678118654757*(t2715 - t2719));\n      s1490 = (a4528 + a4529);\n      s1491 = (a4529 - a4528);\n      t2724 = (t2716 + t2721);\n      t2725 = (t2717 - t2720);\n      t2726 = (t2716 - t2721);\n      t2727 = (t2717 + t2720);\n      s1492 = ((0.92387953251128674*t2724) + (0.38268343236508978*t2725));\n      s1493 = ((0.92387953251128674*t2725) - (0.38268343236508978*t2724));\n      s1494 = ((0.38268343236508978*t2726) + (0.92387953251128674*t2727));\n      s1495 = ((0.38268343236508978*t2727) - (0.92387953251128674*t2726));\n      s1496 = T63[(a4510 + 64)];\n      s1497 = T63[(a4510 + 65)];\n      s1498 = T63[(a4510 + 320)];\n      s1499 = T63[(a4510 + 321)];\n      a4530 = D3[(a4511 + 16)];\n      a4531 = D3[(17 + a4511)];\n      s1500 = ((a4530*s1496) - (a4531*s1497));\n      s1501 = ((a4531*s1496) + (a4530*s1497));\n      a4532 = D3[(18 + a4511)];\n      a4533 = D3[(19 + a4511)];\n      s1502 = ((a4532*s1498) - (a4533*s1499));\n      s1503 = ((a4533*s1498) + (a4532*s1499));\n      t2728 = (s1500 + s1502);\n      t2729 = (s1501 + s1503);\n      t2730 = (s1500 - s1502);\n      t2731 = (s1501 - s1503);\n      s1504 = T63[(a4510 + 192)];\n      s1505 = T63[(a4510 + 193)];\n      s1506 = T63[(a4510 + 448)];\n      s1507 = T63[(a4510 + 449)];\n      a4534 = D3[(20 + a4511)];\n      a4535 = D3[(21 + a4511)];\n      s1508 = ((a4534*s1504) - (a4535*s1505));\n      s1509 = ((a4535*s1504) + (a4534*s1505));\n      a4536 = D3[(22 + a4511)];\n      a4537 = D3[(23 + a4511)];\n      s1510 = ((a4536*s1506) - (a4537*s1507));\n      s1511 = ((a4537*s1506) + (a4536*s1507));\n      t2732 = (s1508 + s1510);\n      t2733 = (s1509 + s1511);\n      t2734 = (s1508 - s1510);\n      t2735 = (s1509 - s1511);\n      t2736 = (t2728 + t2732);\n      t2737 = (t2729 + t2733);\n      t2738 = (t2728 - t2732);\n      t2739 = (t2729 - t2733);\n      a4538 = (0.70710678118654757*(t2730 + t2735));\n      a4539 = (0.70710678118654757*(t2731 - t2734));\n      s1512 = (a4538 + a4539);\n      s1513 = (a4539 - a4538);\n      a4540 = (0.70710678118654757*(t2731 + t2734));\n      a4541 = (0.70710678118654757*(t2730 - t2735));\n      s1514 = (a4540 - a4541);\n      s1515 = (a4541 + a4540);\n      s1516 = T63[(a4510 + 96)];\n      s1517 = T63[(a4510 + 97)];\n      s1518 = T63[(a4510 + 352)];\n      s1519 = T63[(a4510 + 353)];\n      a4542 = D3[(a4511 + 24)];\n      a4543 = D3[(25 + a4511)];\n      s1520 = ((a4542*s1516) - (a4543*s1517));\n      s1521 = ((a4543*s1516) + (a4542*s1517));\n      a4544 = D3[(26 + a4511)];\n      a4545 = D3[(27 + a4511)];\n      s1522 = ((a4544*s1518) - (a4545*s1519));\n      s1523 = ((a4545*s1518) + (a4544*s1519));\n      t2740 = (s1520 + s1522);\n      t2741 = (s1521 + s1523);\n      t2742 = (s1520 - s1522);\n      t2743 = (s1521 - s1523);\n      s1524 = T63[(a4510 + 224)];\n      s1525 = T63[(a4510 + 225)];\n      s1526 = T63[(a4510 + 480)];\n      s1527 = T63[(a4510 + 481)];\n      a4546 = D3[(28 + a4511)];\n      a4547 = D3[(29 + a4511)];\n      s1528 = ((a4546*s1524) - (a4547*s1525));\n      s1529 = ((a4547*s1524) + (a4546*s1525));\n      a4548 = D3[(30 + a4511)];\n      a4549 = D3[(31 + a4511)];\n      s1530 = ((a4548*s1526) - (a4549*s1527));\n      s1531 = ((a4549*s1526) + (a4548*s1527));\n      t2744 = (s1528 + s1530);\n      t2745 = (s1529 + s1531);\n      t2746 = (s1528 - s1530);\n      t2747 = (s1529 - s1531);\n      t2748 = (t2740 + t2744);\n      t2749 = (t2741 + t2745);\n      a4550 = (0.70710678118654757*(t2741 - t2745));\n      a4551 = (0.70710678118654757*(t2740 - t2744));\n      s1532 = (a4550 - a4551);\n      s1533 = (a4551 + a4550);\n      t2750 = (t2742 + t2747);\n      t2751 = (t2743 - t2746);\n      t2752 = (t2742 - t2747);\n      t2753 = (t2743 + t2746);\n      s1534 = ((0.38268343236508978*t2750) + (0.92387953251128674*t2751));\n      s1535 = ((0.38268343236508978*t2751) - (0.92387953251128674*t2750));\n      s1536 = ((0.92387953251128674*t2752) + (0.38268343236508978*t2753));\n      s1537 = ((0.38268343236508978*t2752) - (0.92387953251128674*t2753));\n      t2754 = (t2706 + t2736);\n      t2755 = (t2707 + t2737);\n      t2756 = (t2706 - t2736);\n      t2757 = (t2707 - t2737);\n      t2758 = (t2722 + t2748);\n      t2759 = (t2723 + t2749);\n      t2760 = (t2722 - t2748);\n      t2761 = (t2723 - t2749);\n      a4552 = ((8*blockIdx_x) + (131072*a4509) + (2*a4508));\n      Y[a4552] = (t2754 + t2758);\n      Y[(a4552 + 1)] = (t2755 + t2759);\n      Y[(a4552 + 16777216)] = (t2754 - t2758);\n      Y[(a4552 + 16777217)] = (t2755 - t2759);\n      Y[(a4552 + 8388608)] = (t2756 + t2761);\n      Y[(a4552 + 8388609)] = (t2757 - t2760);\n      Y[(a4552 + 25165824)] = (t2756 - t2761);\n      Y[(a4552 + 25165825)] = (t2757 + t2760);\n      t2762 = (t2710 + s1512);\n      t2763 = (t2711 + s1513);\n      t2764 = (t2710 - s1512);\n      t2765 = (t2711 - s1513);\n      t2766 = (s1492 + s1534);\n      t2767 = (s1493 + s1535);\n      t2768 = (s1492 - s1534);\n      t2769 = (s1493 - s1535);\n      Y[(a4552 + 2097152)] = (t2762 + t2766);\n      Y[(a4552 + 2097153)] = (t2763 + t2767);\n      Y[(a4552 + 18874368)] = (t2762 - t2766);\n      Y[(a4552 + 18874369)] = (t2763 - t2767);\n      Y[(a4552 + 10485760)] = (t2764 + t2769);\n      Y[(a4552 + 10485761)] = (t2765 - t2768);\n      Y[(a4552 + 27262976)] = (t2764 - t2769);\n      Y[(a4552 + 27262977)] = (t2765 + t2768);\n      t2770 = (t2708 + t2739);\n      t2771 = (t2709 - t2738);\n      t2772 = (t2708 - t2739);\n      t2773 = (t2709 + t2738);\n      t2774 = (s1490 + s1532);\n      t2775 = (s1491 - s1533);\n      t2776 = (s1490 - s1532);\n      t2777 = (s1491 + s1533);\n      Y[(a4552 + 4194304)] = (t2770 + t2774);\n      Y[(a4552 + 4194305)] = (t2771 + t2775);\n      Y[(a4552 + 20971520)] = (t2770 - t2774);\n      Y[(a4552 + 20971521)] = (t2771 - t2775);\n      Y[(a4552 + 12582912)] = (t2772 + t2777);\n      Y[(a4552 + 12582913)] = (t2773 - t2776);\n      Y[(a4552 + 29360128)] = (t2772 - t2777);\n      Y[(a4552 + 29360129)] = (t2773 + t2776);\n      t2778 = (t2712 + s1514);\n      t2779 = (t2713 - s1515);\n      t2780 = (t2712 - s1514);\n      t2781 = (t2713 + s1515);\n      t2782 = (s1494 - s1536);\n      t2783 = (s1495 + s1537);\n      t2784 = (s1494 + s1536);\n      t2785 = (s1495 - s1537);\n      Y[(a4552 + 6291456)] = (t2778 + t2782);\n      Y[(a4552 + 6291457)] = (t2779 + t2783);\n      Y[(a4552 + 23068672)] = (t2778 - t2782);\n      Y[(a4552 + 23068673)] = (t2779 - t2783);\n      Y[(a4552 + 14680064)] = (t2780 + t2785);\n      Y[(a4552 + 14680065)] = (t2781 - t2784);\n      Y[(a4552 + 31457280)] = (t2780 - t2785);\n      Y[(a4552 + 31457281)] = (t2781 + t2784);\n          }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 256*256*256*2;\n  const int t = 33554432;\n  size_t dat_size = n * sizeof(double);\n  size_t tmp_size = t * sizeof(double);\n\n  std::mt19937 engine(n);\n  std::uniform_real_distribution<double> dist(0.0, 1.0);\n  double *x = (double*) malloc (dat_size);\n  for (int i = 0; i < n; i++) x[i] = dist(engine);\n\n  double *y = (double*) malloc (dat_size);\n  double *p1 = (double*) malloc (tmp_size);\n  double *p2 = (double*) malloc (tmp_size);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      ker_zmddft_fwd_256x256x256_cu0(d, x, p1);\n      ker_zmddft_fwd_256x256x256_cu1(d, p1, p2);\n      ker_zmddft_fwd_256x256x256_cu2(d, p2, y);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %.3f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  double checksum = 0;\n  for (int i = 0; i < n; i++) checksum += y[i];\n  printf(\"checksum = %lf\\n\", checksum);\n\n  free(x);\n  free(y);\n  free(p1);\n  free(p2);\n\n  return 0;\n}"}}
{"kernel_name": "zmddft", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n\n#define __syncthreads() \\\n  item.barrier(sycl::access::fence_space::local_space)\n\n\n\nsycl::ext::oneapi::experimental::device_global<const double[512]> D3 {\n  1.0, 0.0, 1.0, 0.0,\n  1.0, 0.0, 1.0, 0.0,\n  1.0, 0.0, 1.0, 0.0,\n  1.0, 0.0, 1.0, 0.0,\n  1.0, 0.0, 1.0, 0.0,\n  1.0, 0.0, 1.0, 0.0,\n  1.0, 0.0, 1.0, 0.0,\n  1.0, 0.0, 1.0, 0.0,\n  1.0, 0.0, 0.98078528040323043, (-0.19509032201612825),\n  0.99518472667219693, (-0.098017140329560604), 0.95694033573220882, (-0.29028467725446233),\n  0.99969881869620425, (-0.024541228522912288), 0.97570213003852857, (-0.2191012401568698),\n  0.99247953459870997, (-0.1224106751992162), 0.94952818059303667, (-0.31368174039889152),\n  0.99879545620517241, (-0.049067674327418015), 0.97003125319454397, (-0.24298017990326387),\n  0.98917650996478101, (-0.14673047445536175), 0.94154406518302081, (-0.33688985339222005),\n  0.99729045667869021, (-0.073564563599667426), 0.96377606579543984, (-0.26671275747489837),\n  0.98527764238894122, (-0.17096188876030122), 0.93299279883473896, (-0.35989503653498811),\n  1.0, 0.0, 0.92387953251128674, (-0.38268343236508978),\n  0.98078528040323043, (-0.19509032201612825), 0.83146961230254524, (-0.55557023301960218),\n  0.99879545620517241, (-0.049067674327418015), 0.90398929312344334, (-0.42755509343028208),\n  0.97003125319454397, (-0.24298017990326387), 0.80320753148064494, (-0.59569930449243336),\n  0.99518472667219693, (-0.098017140329560604), 0.88192126434835505, (-0.47139673682599764),\n  0.95694033573220882, (-0.29028467725446233), 0.77301045336273699, (-0.63439328416364549),\n  0.98917650996478101, (-0.14673047445536175), 0.85772861000027212, (-0.51410274419322166),\n  0.94154406518302081, (-0.33688985339222005), 0.74095112535495922, (-0.67155895484701833),\n  1.0, 0.0, 0.83146961230254524, (-0.55557023301960218),\n  0.95694033573220882, (-0.29028467725446233), 0.63439328416364549, (-0.77301045336273699),\n  0.99729045667869021, (-0.073564563599667426), 0.78834642762660623, (-0.61523159058062682),\n  0.93299279883473896, (-0.35989503653498811), 0.57580819141784534, (-0.81758481315158371),\n  0.98917650996478101, (-0.14673047445536175), 0.74095112535495922, (-0.67155895484701833),\n  0.90398929312344334, (-0.42755509343028208), 0.51410274419322166, (-0.85772861000027212),\n  0.97570213003852857, (-0.2191012401568698), 0.68954054473706683, (-0.724247082951467),\n  0.87008699110871146, (-0.49289819222978404), 0.44961132965460654, (-0.89322430119551532),\n  1.0, 0.0, 0.70710678118654757, (-0.70710678118654757),\n  0.92387953251128674, (-0.38268343236508978), 0.38268343236508978, (-0.92387953251128674),\n  0.99518472667219693, (-0.098017140329560604), 0.63439328416364549, (-0.77301045336273699),\n  0.88192126434835505, (-0.47139673682599764), 0.29028467725446233, (-0.95694033573220882),\n  0.98078528040323043, (-0.19509032201612825), 0.55557023301960218, (-0.83146961230254524),\n  0.83146961230254524, (-0.55557023301960218), 0.19509032201612825, (-0.98078528040323043),\n  0.95694033573220882, (-0.29028467725446233), 0.47139673682599764, (-0.88192126434835505),\n  0.77301045336273699, (-0.63439328416364549), 0.098017140329560604, (-0.99518472667219693),\n  1.0, 0.0, 0.55557023301960218, (-0.83146961230254524),\n  0.88192126434835505, (-0.47139673682599764), 0.098017140329560604, (-0.99518472667219693),\n  0.99247953459870997, (-0.1224106751992162), 0.44961132965460654, (-0.89322430119551532),\n  0.81758481315158371, (-0.57580819141784534), (-0.024541228522912288), (-0.99969881869620425),\n  0.97003125319454397, (-0.24298017990326387), 0.33688985339222005, (-0.94154406518302081),\n  0.74095112535495922, (-0.67155895484701833), (-0.14673047445536175), (-0.98917650996478101),\n  0.93299279883473896, (-0.35989503653498811), 0.2191012401568698, (-0.97570213003852857),\n  0.65317284295377676, (-0.75720884650648457), (-0.26671275747489837), (-0.96377606579543984),\n  1.0, 0.0, 0.38268343236508978, (-0.92387953251128674),\n  0.83146961230254524, (-0.55557023301960218), (-0.19509032201612825), (-0.98078528040323043),\n  0.98917650996478101, (-0.14673047445536175), 0.24298017990326387, (-0.97003125319454397),\n  0.74095112535495922, (-0.67155895484701833), (-0.33688985339222005), (-0.94154406518302081),\n  0.95694033573220882, (-0.29028467725446233), 0.098017140329560604, (-0.99518472667219693),\n  0.63439328416364549, (-0.77301045336273699), (-0.47139673682599764), (-0.88192126434835505),\n  0.90398929312344334, (-0.42755509343028208), (-0.049067674327418015), (-0.99879545620517241),\n  0.51410274419322166, (-0.85772861000027212), (-0.59569930449243336), (-0.80320753148064494),\n  1.0, 0.0, 0.19509032201612825, (-0.98078528040323043),\n  0.77301045336273699, (-0.63439328416364549), (-0.47139673682599764), (-0.88192126434835505),\n  0.98527764238894122, (-0.17096188876030122), 0.024541228522912288, (-0.99969881869620425),\n  0.65317284295377676, (-0.75720884650648457), (-0.61523159058062682), (-0.78834642762660623),\n  0.94154406518302081, (-0.33688985339222005), (-0.14673047445536175), (-0.98917650996478101),\n  0.51410274419322166, (-0.85772861000027212), (-0.74095112535495922), (-0.67155895484701833),\n  0.87008699110871146, (-0.49289819222978404), (-0.31368174039889152), (-0.94952818059303667),\n  0.35989503653498811, (-0.93299279883473896), (-0.84485356524970712), (-0.53499761988709715),\n  1.0, 0.0, 0.0, (-1.0),\n  0.70710678118654757, (-0.70710678118654757), (-0.70710678118654757), (-0.70710678118654757),\n  0.98078528040323043, (-0.19509032201612825), (-0.19509032201612825), (-0.98078528040323043),\n  0.55557023301960218, (-0.83146961230254524), (-0.83146961230254524), (-0.55557023301960218),\n  0.92387953251128674, (-0.38268343236508978), (-0.38268343236508978), (-0.92387953251128674),\n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), (-0.38268343236508978),\n  0.83146961230254524, (-0.55557023301960218), (-0.55557023301960218), (-0.83146961230254524),\n  0.19509032201612825, (-0.98078528040323043), (-0.98078528040323043), (-0.19509032201612825),\n  1.0, 0.0, (-0.19509032201612825), (-0.98078528040323043),\n  0.63439328416364549, (-0.77301045336273699), (-0.88192126434835505), (-0.47139673682599764),\n  0.97570213003852857, (-0.2191012401568698), (-0.40524131400498986), (-0.91420975570353069),\n  0.44961132965460654, (-0.89322430119551532), (-0.96377606579543984), (-0.26671275747489837),\n  0.90398929312344334, (-0.42755509343028208), (-0.59569930449243336), (-0.80320753148064494),\n  0.24298017990326387, (-0.97003125319454397), (-0.99879545620517241), (-0.049067674327418015),\n  0.78834642762660623, (-0.61523159058062682), (-0.75720884650648457), (-0.65317284295377676),\n  0.024541228522912288, (-0.99969881869620425), (-0.98527764238894122), 0.17096188876030122,\n  1.0, 0.0, (-0.38268343236508978), (-0.92387953251128674),\n  0.55557023301960218, (-0.83146961230254524), (-0.98078528040323043), (-0.19509032201612825),\n  0.97003125319454397, (-0.24298017990326387), (-0.59569930449243336), (-0.80320753148064494),\n  0.33688985339222005, (-0.94154406518302081), (-0.99879545620517241), 0.049067674327418015,\n  0.88192126434835505, (-0.47139673682599764), (-0.77301045336273699), (-0.63439328416364549),\n  0.098017140329560604, (-0.99518472667219693), (-0.95694033573220882), 0.29028467725446233,\n  0.74095112535495922, (-0.67155895484701833), (-0.90398929312344334), (-0.42755509343028208),\n  (-0.14673047445536175), (-0.98917650996478101), (-0.85772861000027212), 0.51410274419322166,\n  1.0, 0.0, (-0.55557023301960218), (-0.83146961230254524),\n  0.47139673682599764, (-0.88192126434835505), (-0.99518472667219693), 0.098017140329560604,\n  0.96377606579543984, (-0.26671275747489837), (-0.75720884650648457), (-0.65317284295377676),\n  0.2191012401568698, (-0.97570213003852857), (-0.93299279883473896), 0.35989503653498811,\n  0.85772861000027212, (-0.51410274419322166), (-0.90398929312344334), (-0.42755509343028208),\n  (-0.049067674327418015), (-0.99879545620517241), (-0.80320753148064494), 0.59569930449243336,\n  0.68954054473706683, (-0.724247082951467), (-0.98527764238894122), (-0.17096188876030122),\n  (-0.31368174039889152), (-0.94952818059303667), (-0.61523159058062682), 0.78834642762660623,\n  1.0, 0.0, (-0.70710678118654757), (-0.70710678118654757),\n  0.38268343236508978, (-0.92387953251128674), (-0.92387953251128674), 0.38268343236508978,\n  0.95694033573220882, (-0.29028467725446233), (-0.88192126434835505), (-0.47139673682599764),\n  0.098017140329560604, (-0.99518472667219693), (-0.77301045336273699), 0.63439328416364549,\n  0.83146961230254524, (-0.55557023301960218), (-0.98078528040323043), (-0.19509032201612825),\n  (-0.19509032201612825), (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524,\n  0.63439328416364549, (-0.77301045336273699), (-0.99518472667219693), 0.098017140329560604,\n  (-0.47139673682599764), (-0.88192126434835505), (-0.29028467725446233), 0.95694033573220882,\n  1.0, 0.0, (-0.83146961230254524), (-0.55557023301960218),\n  0.29028467725446233, (-0.95694033573220882), (-0.77301045336273699), 0.63439328416364549,\n  0.94952818059303667, (-0.31368174039889152), (-0.96377606579543984), (-0.26671275747489837),\n  (-0.024541228522912288), (-0.99969881869620425), (-0.53499761988709715), 0.84485356524970712,\n  0.80320753148064494, (-0.59569930449243336), (-0.99879545620517241), 0.049067674327418015,\n  (-0.33688985339222005), (-0.94154406518302081), (-0.24298017990326387), 0.97003125319454397,\n  0.57580819141784534, (-0.81758481315158371), (-0.93299279883473896), 0.35989503653498811,\n  (-0.61523159058062682), (-0.78834642762660623), 0.073564563599667426, 0.99729045667869021,\n  1.0, 0.0, (-0.92387953251128674), (-0.38268343236508978),\n  0.19509032201612825, (-0.98078528040323043), (-0.55557023301960218), 0.83146961230254524,\n  0.94154406518302081, (-0.33688985339222005), (-0.99879545620517241), (-0.049067674327418015),\n  (-0.14673047445536175), (-0.98917650996478101), (-0.24298017990326387), 0.97003125319454397,\n  0.77301045336273699, (-0.63439328416364549), (-0.95694033573220882), 0.29028467725446233,\n  (-0.47139673682599764), (-0.88192126434835505), 0.098017140329560604, 0.99518472667219693,\n  0.51410274419322166, (-0.85772861000027212), (-0.80320753148064494), 0.59569930449243336,\n  (-0.74095112535495922), (-0.67155895484701833), 0.42755509343028208, 0.90398929312344334,\n  1.0, 0.0, (-0.98078528040323043), (-0.19509032201612825),\n  0.098017140329560604, (-0.99518472667219693), (-0.29028467725446233), 0.95694033573220882,\n  0.93299279883473896, (-0.35989503653498811), (-0.98527764238894122), 0.17096188876030122,\n  (-0.26671275747489837), (-0.96377606579543984), 0.073564563599667426, 0.99729045667869021,\n  0.74095112535495922, (-0.67155895484701833), (-0.85772861000027212), 0.51410274419322166,\n  (-0.59569930449243336), (-0.80320753148064494), 0.42755509343028208, 0.90398929312344334,\n  0.44961132965460654, (-0.89322430119551532), (-0.61523159058062682), 0.78834642762660623,\n  (-0.84485356524970712), (-0.53499761988709715), 0.724247082951467, 0.68954054473706683};\n\nvoid ker_zmddft_fwd_256x256x256_cu0(sycl::nd_item<1> &item,\n                                    double *__restrict T3,\n                                    const double *__restrict X,\n                                    double *__restrict P1) {\n  double a495, a496, a497, a498, a499, a500, a501, a502,\n         s145, s146, s147, s148, s149, s150, s151, s152,\n         s153, s154, s155, s156, s157, s158, s159, s160,\n         s161, s162, s163, s164, s165, s166, s167, s168,\n         s169, s170, s171, s172, s173, s174, s175, s176,\n         s177, s178, s179, s180, s181, s182, s183, s184,\n         s185, s186, s187, s188, s189, s190, s191, s192,\n         t538, t539, t540, t541, t542, t543, t544, t545,\n         t546, t547, t548, t549, t550, t551, t552, t553,\n         t554, t555, t556, t557, t558, t559, t560, t561,\n         t562, t563, t564, t565, t566, t567, t568, t569,\n         t570, t571, t572, t573, t574, t575, t576, t577,\n         t578, t579, t580, t581, t582, t583, t584, t585,\n         t586, t587, t588, t589, t590, t591, t592, t593,\n         t594, t595, t596, t597, t598, t599, t600, t601,\n         t602, t603, t604, t605, t606, t607, t608, t609,\n         t610, t611, t612, t613, t614, t615, t616, t617,\n         t618, t619, t620, t621, t622, t623, t624, t625;\n  int a492, a493, a494, a503;\n  int threadIdx_x = item.get_local_id(0);\n  int blockIdx_x = item.get_group(0);\n  a492 = (512*(threadIdx_x / 16));\n  a493 = (threadIdx_x % 16);\n  a494 = ((2048*blockIdx_x) + a492 + (2*a493));\n  s145 = X[a494];\n  s146 = X[(a494 + 1)];\n  s147 = X[(a494 + 256)];\n  s148 = X[(a494 + 257)];\n  t538 = (s145 + s147);\n  t539 = (s146 + s148);\n  t540 = (s145 - s147);\n  t541 = (s146 - s148);\n  s149 = X[(a494 + 128)];\n  s150 = X[(a494 + 129)];\n  s151 = X[(a494 + 384)];\n  s152 = X[(a494 + 385)];\n  t542 = (s149 + s151);\n  t543 = (s150 + s152);\n  t544 = (s149 - s151);\n  t545 = (s150 - s152);\n  t546 = (t538 + t542);\n  t547 = (t539 + t543);\n  t548 = (t538 - t542);\n  t549 = (t539 - t543);\n  t550 = (t540 + t545);\n  t551 = (t541 - t544);\n  t552 = (t540 - t545);\n  t553 = (t541 + t544);\n  s153 = X[(a494 + 32)];\n  s154 = X[(a494 + 33)];\n  s155 = X[(a494 + 288)];\n  s156 = X[(a494 + 289)];\n  t554 = (s153 + s155);\n  t555 = (s154 + s156);\n  t556 = (s153 - s155);\n  t557 = (s154 - s156);\n  s157 = X[(a494 + 160)];\n  s158 = X[(a494 + 161)];\n  s159 = X[(a494 + 416)];\n  s160 = X[(a494 + 417)];\n  t558 = (s157 + s159);\n  t559 = (s158 + s160);\n  t560 = (s157 - s159);\n  t561 = (s158 - s160);\n  t562 = (t554 + t558);\n  t563 = (t555 + t559);\n  a495 = (0.70710678118654757*(t554 - t558));\n  a496 = (0.70710678118654757*(t555 - t559));\n  s161 = (a495 + a496);\n  s162 = (a496 - a495);\n  t564 = (t556 + t561);\n  t565 = (t557 - t560);\n  t566 = (t556 - t561);\n  t567 = (t557 + t560);\n  s163 = ((0.92387953251128674*t564) + (0.38268343236508978*t565));\n  s164 = ((0.92387953251128674*t565) - (0.38268343236508978*t564));\n  s165 = ((0.38268343236508978*t566) + (0.92387953251128674*t567));\n  s166 = ((0.38268343236508978*t567) - (0.92387953251128674*t566));\n  s167 = X[(a494 + 64)];\n  s168 = X[(a494 + 65)];\n  s169 = X[(a494 + 320)];\n  s170 = X[(a494 + 321)];\n  t568 = (s167 + s169);\n  t569 = (s168 + s170);\n  t570 = (s167 - s169);\n  t571 = (s168 - s170);\n  s171 = X[(a494 + 192)];\n  s172 = X[(a494 + 193)];\n  s173 = X[(a494 + 448)];\n  s174 = X[(a494 + 449)];\n  t572 = (s171 + s173);\n  t573 = (s172 + s174);\n  t574 = (s171 - s173);\n  t575 = (s172 - s174);\n  t576 = (t568 + t572);\n  t577 = (t569 + t573);\n  t578 = (t568 - t572);\n  t579 = (t569 - t573);\n  a497 = (0.70710678118654757*(t570 + t575));\n  a498 = (0.70710678118654757*(t571 - t574));\n  s175 = (a497 + a498);\n  s176 = (a498 - a497);\n  a499 = (0.70710678118654757*(t571 + t574));\n  a500 = (0.70710678118654757*(t570 - t575));\n  s177 = (a499 - a500);\n  s178 = (a500 + a499);\n  s179 = X[(a494 + 96)];\n  s180 = X[(a494 + 97)];\n  s181 = X[(a494 + 352)];\n  s182 = X[(a494 + 353)];\n  t580 = (s179 + s181);\n  t581 = (s180 + s182);\n  t582 = (s179 - s181);\n  t583 = (s180 - s182);\n  s183 = X[(a494 + 224)];\n  s184 = X[(a494 + 225)];\n  s185 = X[(a494 + 480)];\n  s186 = X[(a494 + 481)];\n  t584 = (s183 + s185);\n  t585 = (s184 + s186);\n  t586 = (s183 - s185);\n  t587 = (s184 - s186);\n  t588 = (t580 + t584);\n  t589 = (t581 + t585);\n  a501 = (0.70710678118654757*(t581 - t585));\n  a502 = (0.70710678118654757*(t580 - t584));\n  s187 = (a501 - a502);\n  s188 = (a502 + a501);\n  t590 = (t582 + t587);\n  t591 = (t583 - t586);\n  t592 = (t582 - t587);\n  t593 = (t583 + t586);\n  s189 = ((0.38268343236508978*t590) + (0.92387953251128674*t591));\n  s190 = ((0.38268343236508978*t591) - (0.92387953251128674*t590));\n  s191 = ((0.92387953251128674*t592) + (0.38268343236508978*t593));\n  s192 = ((0.38268343236508978*t592) - (0.92387953251128674*t593));\n  t594 = (t546 + t576);\n  t595 = (t547 + t577);\n  t596 = (t546 - t576);\n  t597 = (t547 - t577);\n  t598 = (t562 + t588);\n  t599 = (t563 + t589);\n  t600 = (t562 - t588);\n  t601 = (t563 - t589);\n  a503 = (a492 + (32*a493));\n  T3[a503] = (t594 + t598);\n  T3[(a503 + 1)] = (t595 + t599);\n  T3[(a503 + 16)] = (t594 - t598);\n  T3[(a503 + 17)] = (t595 - t599);\n  T3[(a503 + 8)] = (t596 + t601);\n  T3[(a503 + 9)] = (t597 - t600);\n  T3[(a503 + 24)] = (t596 - t601);\n  T3[(a503 + 25)] = (t597 + t600);\n  t602 = (t550 + s175);\n  t603 = (t551 + s176);\n  t604 = (t550 - s175);\n  t605 = (t551 - s176);\n  t606 = (s163 + s189);\n  t607 = (s164 + s190);\n  t608 = (s163 - s189);\n  t609 = (s164 - s190);\n  T3[(a503 + 2)] = (t602 + t606);\n  T3[(a503 + 3)] = (t603 + t607);\n  T3[(a503 + 18)] = (t602 - t606);\n  T3[(a503 + 19)] = (t603 - t607);\n  T3[(a503 + 10)] = (t604 + t609);\n  T3[(a503 + 11)] = (t605 - t608);\n  T3[(a503 + 26)] = (t604 - t609);\n  T3[(a503 + 27)] = (t605 + t608);\n  t610 = (t548 + t579);\n  t611 = (t549 - t578);\n  t612 = (t548 - t579);\n  t613 = (t549 + t578);\n  t614 = (s161 + s187);\n  t615 = (s162 - s188);\n  t616 = (s161 - s187);\n  t617 = (s162 + s188);\n  T3[(a503 + 4)] = (t610 + t614);\n  T3[(a503 + 5)] = (t611 + t615);\n  T3[(a503 + 20)] = (t610 - t614);\n  T3[(a503 + 21)] = (t611 - t615);\n  T3[(a503 + 12)] = (t612 + t617);\n  T3[(a503 + 13)] = (t613 - t616);\n  T3[(a503 + 28)] = (t612 - t617);\n  T3[(a503 + 29)] = (t613 + t616);\n  t618 = (t552 + s177);\n  t619 = (t553 - s178);\n  t620 = (t552 - s177);\n  t621 = (t553 + s178);\n  t622 = (s165 - s191);\n  t623 = (s166 + s192);\n  t624 = (s165 + s191);\n  t625 = (s166 - s192);\n  T3[(a503 + 6)] = (t618 + t622);\n  T3[(a503 + 7)] = (t619 + t623);\n  T3[(a503 + 22)] = (t618 - t622);\n  T3[(a503 + 23)] = (t619 - t623);\n  T3[(a503 + 14)] = (t620 + t625);\n  T3[(a503 + 15)] = (t621 - t624);\n  T3[(a503 + 30)] = (t620 - t625);\n  T3[(a503 + 31)] = (t621 + t624);\n  __syncthreads();\n  double a1478, a1479, a1480, a1481, a1482, a1483, a1484, a1485,\n         a1486, a1487, a1488, a1489, a1490, a1491, a1492, a1493,\n         a1494, a1495, a1496, a1497, a1498, a1499, a1500, a1501,\n         a1502, a1503, a1504, a1505, a1506, a1507, a1508, a1509,\n         a1510, a1511, a1512, a1513, a1514, a1515, a1516, a1517,\n         s434, s435, s436, s437, s438, s439, s440, s441,\n         s442, s443, s444, s445, s446, s447, s448, s449,\n         s450, s451, s452, s453, s454, s455, s456, s457,\n         s458, s459, s460, s461, s462, s463, s464, s465,\n         s466, s467, s468, s469, s470, s471, s472, s473,\n         s474, s475, s476, s477, s478, s479, s480, s481,\n         s482, s483, s484, s485, s486, s487, s488, s489,\n         s490, s491, s492, s493, s494, s495, s496, s497,\n         s498, s499, s500, s501, s502, s503, s504, s505,\n         s506, s507, s508, s509, s510, s511, s512, s513,\n         t1000, t1001, t1002, t1003, t1004, t1005, t1006, t1007,\n         t1008, t1009, t1010, t1011, t1012, t1013, t1014, t1015,\n         t1016, t1017, t1018, t1019, t1020, t1021, t1022, t1023,\n         t1024, t1025, t1026, t1027, t1028, t1029, t1030, t1031,\n         t1032, t1033, t1034, t1035, t1036, t1037, t1038, t1039,\n         t1040, t1041, t1042, t1043, t1044, t1045, t1046, t1047,\n         t1048, t1049, t1050, t1051, t1052, t1053, t1054, t1055,\n         t1056, t1057, t970, t971, t972, t973, t974, t975,\n         t976, t977, t978, t979, t980, t981, t982, t983,\n         t984, t985, t986, t987, t988, t989, t990, t991,\n         t992, t993, t994, t995, t996, t997, t998, t999;\n  int a1474, a1475, a1476, a1477, a1518;\n  a1474 = (threadIdx_x / 16);\n  a1475 = (threadIdx_x % 16);\n  a1476 = ((512*a1474) + (2*a1475));\n  s434 = T3[a1476];\n  s435 = T3[(a1476 + 1)];\n  s436 = T3[(a1476 + 256)];\n  s437 = T3[(a1476 + 257)];\n  a1477 = (32*a1475);\n  a1478 = D3[a1477];\n  a1479 = D3[(a1477 + 1)];\n  s438 = ((a1478*s434) - (a1479*s435));\n  s439 = ((a1479*s434) + (a1478*s435));\n  a1480 = D3[(a1477 + 2)];\n  a1481 = D3[(a1477 + 3)];\n  s440 = ((a1480*s436) - (a1481*s437));\n  s441 = ((a1481*s436) + (a1480*s437));\n  t970 = (s438 + s440);\n  t971 = (s439 + s441);\n  t972 = (s438 - s440);\n  t973 = (s439 - s441);\n  s442 = T3[(a1476 + 128)];\n  s443 = T3[(a1476 + 129)];\n  s444 = T3[(a1476 + 384)];\n  s445 = T3[(a1476 + 385)];\n  a1482 = D3[(4 + a1477)];\n  a1483 = D3[(5 + a1477)];\n  s446 = ((a1482*s442) - (a1483*s443));\n  s447 = ((a1483*s442) + (a1482*s443));\n  a1484 = D3[(6 + a1477)];\n  a1485 = D3[(7 + a1477)];\n  s448 = ((a1484*s444) - (a1485*s445));\n  s449 = ((a1485*s444) + (a1484*s445));\n  t974 = (s446 + s448);\n  t975 = (s447 + s449);\n  t976 = (s446 - s448);\n  t977 = (s447 - s449);\n  t978 = (t970 + t974);\n  t979 = (t971 + t975);\n  t980 = (t970 - t974);\n  t981 = (t971 - t975);\n  t982 = (t972 + t977);\n  t983 = (t973 - t976);\n  t984 = (t972 - t977);\n  t985 = (t973 + t976);\n  s450 = T3[(a1476 + 32)];\n  s451 = T3[(a1476 + 33)];\n  s452 = T3[(a1476 + 288)];\n  s453 = T3[(a1476 + 289)];\n  a1486 = D3[(a1477 + 8)];\n  a1487 = D3[(9 + a1477)];\n  s454 = ((a1486*s450) - (a1487*s451));\n  s455 = ((a1487*s450) + (a1486*s451));\n  a1488 = D3[(10 + a1477)];\n  a1489 = D3[(11 + a1477)];\n  s456 = ((a1488*s452) - (a1489*s453));\n  s457 = ((a1489*s452) + (a1488*s453));\n  t986 = (s454 + s456);\n  t987 = (s455 + s457);\n  t988 = (s454 - s456);\n  t989 = (s455 - s457);\n  s458 = T3[(a1476 + 160)];\n  s459 = T3[(a1476 + 161)];\n  s460 = T3[(a1476 + 416)];\n  s461 = T3[(a1476 + 417)];\n  a1490 = D3[(12 + a1477)];\n  a1491 = D3[(13 + a1477)];\n  s462 = ((a1490*s458) - (a1491*s459));\n  s463 = ((a1491*s458) + (a1490*s459));\n  a1492 = D3[(14 + a1477)];\n  a1493 = D3[(15 + a1477)];\n  s464 = ((a1492*s460) - (a1493*s461));\n  s465 = ((a1493*s460) + (a1492*s461));\n  t990 = (s462 + s464);\n  t991 = (s463 + s465);\n  t992 = (s462 - s464);\n  t993 = (s463 - s465);\n  t994 = (t986 + t990);\n  t995 = (t987 + t991);\n  a1494 = (0.70710678118654757*(t986 - t990));\n  a1495 = (0.70710678118654757*(t987 - t991));\n  s466 = (a1494 + a1495);\n  s467 = (a1495 - a1494);\n  t996 = (t988 + t993);\n  t997 = (t989 - t992);\n  t998 = (t988 - t993);\n  t999 = (t989 + t992);\n  s468 = ((0.92387953251128674*t996) + (0.38268343236508978*t997));\n  s469 = ((0.92387953251128674*t997) - (0.38268343236508978*t996));\n  s470 = ((0.38268343236508978*t998) + (0.92387953251128674*t999));\n  s471 = ((0.38268343236508978*t999) - (0.92387953251128674*t998));\n  s472 = T3[(a1476 + 64)];\n  s473 = T3[(a1476 + 65)];\n  s474 = T3[(a1476 + 320)];\n  s475 = T3[(a1476 + 321)];\n  a1496 = D3[(a1477 + 16)];\n  a1497 = D3[(17 + a1477)];\n  s476 = ((a1496*s472) - (a1497*s473));\n  s477 = ((a1497*s472) + (a1496*s473));\n  a1498 = D3[(18 + a1477)];\n  a1499 = D3[(19 + a1477)];\n  s478 = ((a1498*s474) - (a1499*s475));\n  s479 = ((a1499*s474) + (a1498*s475));\n  t1000 = (s476 + s478);\n  t1001 = (s477 + s479);\n  t1002 = (s476 - s478);\n  t1003 = (s477 - s479);\n  s480 = T3[(a1476 + 192)];\n  s481 = T3[(a1476 + 193)];\n  s482 = T3[(a1476 + 448)];\n  s483 = T3[(a1476 + 449)];\n  a1500 = D3[(20 + a1477)];\n  a1501 = D3[(21 + a1477)];\n  s484 = ((a1500*s480) - (a1501*s481));\n  s485 = ((a1501*s480) + (a1500*s481));\n  a1502 = D3[(22 + a1477)];\n  a1503 = D3[(23 + a1477)];\n  s486 = ((a1502*s482) - (a1503*s483));\n  s487 = ((a1503*s482) + (a1502*s483));\n  t1004 = (s484 + s486);\n  t1005 = (s485 + s487);\n  t1006 = (s484 - s486);\n  t1007 = (s485 - s487);\n  t1008 = (t1000 + t1004);\n  t1009 = (t1001 + t1005);\n  t1010 = (t1000 - t1004);\n  t1011 = (t1001 - t1005);\n  a1504 = (0.70710678118654757*(t1002 + t1007));\n  a1505 = (0.70710678118654757*(t1003 - t1006));\n  s488 = (a1504 + a1505);\n  s489 = (a1505 - a1504);\n  a1506 = (0.70710678118654757*(t1003 + t1006));\n  a1507 = (0.70710678118654757*(t1002 - t1007));\n  s490 = (a1506 - a1507);\n  s491 = (a1507 + a1506);\n  s492 = T3[(a1476 + 96)];\n  s493 = T3[(a1476 + 97)];\n  s494 = T3[(a1476 + 352)];\n  s495 = T3[(a1476 + 353)];\n  a1508 = D3[(a1477 + 24)];\n  a1509 = D3[(25 + a1477)];\n  s496 = ((a1508*s492) - (a1509*s493));\n  s497 = ((a1509*s492) + (a1508*s493));\n  a1510 = D3[(26 + a1477)];\n  a1511 = D3[(27 + a1477)];\n  s498 = ((a1510*s494) - (a1511*s495));\n  s499 = ((a1511*s494) + (a1510*s495));\n  t1012 = (s496 + s498);\n  t1013 = (s497 + s499);\n  t1014 = (s496 - s498);\n  t1015 = (s497 - s499);\n  s500 = T3[(a1476 + 224)];\n  s501 = T3[(a1476 + 225)];\n  s502 = T3[(a1476 + 480)];\n  s503 = T3[(a1476 + 481)];\n  a1512 = D3[(28 + a1477)];\n  a1513 = D3[(29 + a1477)];\n  s504 = ((a1512*s500) - (a1513*s501));\n  s505 = ((a1513*s500) + (a1512*s501));\n  a1514 = D3[(30 + a1477)];\n  a1515 = D3[(31 + a1477)];\n  s506 = ((a1514*s502) - (a1515*s503));\n  s507 = ((a1515*s502) + (a1514*s503));\n  t1016 = (s504 + s506);\n  t1017 = (s505 + s507);\n  t1018 = (s504 - s506);\n  t1019 = (s505 - s507);\n  t1020 = (t1012 + t1016);\n  t1021 = (t1013 + t1017);\n  a1516 = (0.70710678118654757*(t1013 - t1017));\n  a1517 = (0.70710678118654757*(t1012 - t1016));\n  s508 = (a1516 - a1517);\n  s509 = (a1517 + a1516);\n  t1022 = (t1014 + t1019);\n  t1023 = (t1015 - t1018);\n  t1024 = (t1014 - t1019);\n  t1025 = (t1015 + t1018);\n  s510 = ((0.38268343236508978*t1022) + (0.92387953251128674*t1023));\n  s511 = ((0.38268343236508978*t1023) - (0.92387953251128674*t1022));\n  s512 = ((0.92387953251128674*t1024) + (0.38268343236508978*t1025));\n  s513 = ((0.38268343236508978*t1024) - (0.92387953251128674*t1025));\n  t1026 = (t978 + t1008);\n  t1027 = (t979 + t1009);\n  t1028 = (t978 - t1008);\n  t1029 = (t979 - t1009);\n  t1030 = (t994 + t1020);\n  t1031 = (t995 + t1021);\n  t1032 = (t994 - t1020);\n  t1033 = (t995 - t1021);\n  a1518 = ((8*blockIdx_x) + (131072*a1475) + (2*a1474));\n  P1[a1518] = (t1026 + t1030);\n  P1[(a1518 + 1)] = (t1027 + t1031);\n  P1[(a1518 + 16777216)] = (t1026 - t1030);\n  P1[(a1518 + 16777217)] = (t1027 - t1031);\n  P1[(a1518 + 8388608)] = (t1028 + t1033);\n  P1[(a1518 + 8388609)] = (t1029 - t1032);\n  P1[(a1518 + 25165824)] = (t1028 - t1033);\n  P1[(a1518 + 25165825)] = (t1029 + t1032);\n  t1034 = (t982 + s488);\n  t1035 = (t983 + s489);\n  t1036 = (t982 - s488);\n  t1037 = (t983 - s489);\n  t1038 = (s468 + s510);\n  t1039 = (s469 + s511);\n  t1040 = (s468 - s510);\n  t1041 = (s469 - s511);\n  P1[(a1518 + 2097152)] = (t1034 + t1038);\n  P1[(a1518 + 2097153)] = (t1035 + t1039);\n  P1[(a1518 + 18874368)] = (t1034 - t1038);\n  P1[(a1518 + 18874369)] = (t1035 - t1039);\n  P1[(a1518 + 10485760)] = (t1036 + t1041);\n  P1[(a1518 + 10485761)] = (t1037 - t1040);\n  P1[(a1518 + 27262976)] = (t1036 - t1041);\n  P1[(a1518 + 27262977)] = (t1037 + t1040);\n  t1042 = (t980 + t1011);\n  t1043 = (t981 - t1010);\n  t1044 = (t980 - t1011);\n  t1045 = (t981 + t1010);\n  t1046 = (s466 + s508);\n  t1047 = (s467 - s509);\n  t1048 = (s466 - s508);\n  t1049 = (s467 + s509);\n  P1[(a1518 + 4194304)] = (t1042 + t1046);\n  P1[(a1518 + 4194305)] = (t1043 + t1047);\n  P1[(a1518 + 20971520)] = (t1042 - t1046);\n  P1[(a1518 + 20971521)] = (t1043 - t1047);\n  P1[(a1518 + 12582912)] = (t1044 + t1049);\n  P1[(a1518 + 12582913)] = (t1045 - t1048);\n  P1[(a1518 + 29360128)] = (t1044 - t1049);\n  P1[(a1518 + 29360129)] = (t1045 + t1048);\n  t1050 = (t984 + s490);\n  t1051 = (t985 - s491);\n  t1052 = (t984 - s490);\n  t1053 = (t985 + s491);\n  t1054 = (s470 - s512);\n  t1055 = (s471 + s513);\n  t1056 = (s470 + s512);\n  t1057 = (s471 - s513);\n  P1[(a1518 + 6291456)] = (t1050 + t1054);\n  P1[(a1518 + 6291457)] = (t1051 + t1055);\n  P1[(a1518 + 23068672)] = (t1050 - t1054);\n  P1[(a1518 + 23068673)] = (t1051 - t1055);\n  P1[(a1518 + 14680064)] = (t1052 + t1057);\n  P1[(a1518 + 14680065)] = (t1053 - t1056);\n  P1[(a1518 + 31457280)] = (t1052 - t1057);\n  P1[(a1518 + 31457281)] = (t1053 + t1056);\n  __syncthreads();\n}\n\nvoid ker_zmddft_fwd_256x256x256_cu1(sycl::nd_item<1> &item,\n                                    double *__restrict T33,\n                                    const double *__restrict P1,\n                                    double *__restrict P2)\n{\n  double a2012, a2013, a2014, a2015, a2016, a2017, a2018, a2019,\n         s658, s659, s660, s661, s662, s663, s664, s665,\n         s666, s667, s668, s669, s670, s671, s672, s673,\n         s674, s675, s676, s677, s678, s679, s680, s681,\n         s682, s683, s684, s685, s686, s687, s688, s689,\n         s690, s691, s692, s693, s694, s695, s696, s697,\n         s698, s699, s700, s701, s702, s703, s704, s705,\n         t1402, t1403, t1404, t1405, t1406, t1407, t1408, t1409,\n         t1410, t1411, t1412, t1413, t1414, t1415, t1416, t1417,\n         t1418, t1419, t1420, t1421, t1422, t1423, t1424, t1425,\n         t1426, t1427, t1428, t1429, t1430, t1431, t1432, t1433,\n         t1434, t1435, t1436, t1437, t1438, t1439, t1440, t1441,\n         t1442, t1443, t1444, t1445, t1446, t1447, t1448, t1449,\n         t1450, t1451, t1452, t1453, t1454, t1455, t1456, t1457,\n         t1458, t1459, t1460, t1461, t1462, t1463, t1464, t1465,\n         t1466, t1467, t1468, t1469, t1470, t1471, t1472, t1473,\n         t1474, t1475, t1476, t1477, t1478, t1479, t1480, t1481,\n         t1482, t1483, t1484, t1485, t1486, t1487, t1488, t1489;\n  int a2009, a2010, a2011, a2020;\n  int threadIdx_x = item.get_local_id(0);\n  int blockIdx_x = item.get_group(0);\n  a2009 = (512*(threadIdx_x / 16));\n  a2010 = (threadIdx_x % 16);\n  a2011 = ((2048*blockIdx_x) + a2009 + (2*a2010));\n  s658 = P1[a2011];\n  s659 = P1[(a2011 + 1)];\n  s660 = P1[(a2011 + 256)];\n  s661 = P1[(a2011 + 257)];\n  t1402 = (s658 + s660);\n  t1403 = (s659 + s661);\n  t1404 = (s658 - s660);\n  t1405 = (s659 - s661);\n  s662 = P1[(a2011 + 128)];\n  s663 = P1[(a2011 + 129)];\n  s664 = P1[(a2011 + 384)];\n  s665 = P1[(a2011 + 385)];\n  t1406 = (s662 + s664);\n  t1407 = (s663 + s665);\n  t1408 = (s662 - s664);\n  t1409 = (s663 - s665);\n  t1410 = (t1402 + t1406);\n  t1411 = (t1403 + t1407);\n  t1412 = (t1402 - t1406);\n  t1413 = (t1403 - t1407);\n  t1414 = (t1404 + t1409);\n  t1415 = (t1405 - t1408);\n  t1416 = (t1404 - t1409);\n  t1417 = (t1405 + t1408);\n  s666 = P1[(a2011 + 32)];\n  s667 = P1[(a2011 + 33)];\n  s668 = P1[(a2011 + 288)];\n  s669 = P1[(a2011 + 289)];\n  t1418 = (s666 + s668);\n  t1419 = (s667 + s669);\n  t1420 = (s666 - s668);\n  t1421 = (s667 - s669);\n  s670 = P1[(a2011 + 160)];\n  s671 = P1[(a2011 + 161)];\n  s672 = P1[(a2011 + 416)];\n  s673 = P1[(a2011 + 417)];\n  t1422 = (s670 + s672);\n  t1423 = (s671 + s673);\n  t1424 = (s670 - s672);\n  t1425 = (s671 - s673);\n  t1426 = (t1418 + t1422);\n  t1427 = (t1419 + t1423);\n  a2012 = (0.70710678118654757*(t1418 - t1422));\n  a2013 = (0.70710678118654757*(t1419 - t1423));\n  s674 = (a2012 + a2013);\n  s675 = (a2013 - a2012);\n  t1428 = (t1420 + t1425);\n  t1429 = (t1421 - t1424);\n  t1430 = (t1420 - t1425);\n  t1431 = (t1421 + t1424);\n  s676 = ((0.92387953251128674*t1428) + (0.38268343236508978*t1429));\n  s677 = ((0.92387953251128674*t1429) - (0.38268343236508978*t1428));\n  s678 = ((0.38268343236508978*t1430) + (0.92387953251128674*t1431));\n  s679 = ((0.38268343236508978*t1431) - (0.92387953251128674*t1430));\n  s680 = P1[(a2011 + 64)];\n  s681 = P1[(a2011 + 65)];\n  s682 = P1[(a2011 + 320)];\n  s683 = P1[(a2011 + 321)];\n  t1432 = (s680 + s682);\n  t1433 = (s681 + s683);\n  t1434 = (s680 - s682);\n  t1435 = (s681 - s683);\n  s684 = P1[(a2011 + 192)];\n  s685 = P1[(a2011 + 193)];\n  s686 = P1[(a2011 + 448)];\n  s687 = P1[(a2011 + 449)];\n  t1436 = (s684 + s686);\n  t1437 = (s685 + s687);\n  t1438 = (s684 - s686);\n  t1439 = (s685 - s687);\n  t1440 = (t1432 + t1436);\n  t1441 = (t1433 + t1437);\n  t1442 = (t1432 - t1436);\n  t1443 = (t1433 - t1437);\n  a2014 = (0.70710678118654757*(t1434 + t1439));\n  a2015 = (0.70710678118654757*(t1435 - t1438));\n  s688 = (a2014 + a2015);\n  s689 = (a2015 - a2014);\n  a2016 = (0.70710678118654757*(t1435 + t1438));\n  a2017 = (0.70710678118654757*(t1434 - t1439));\n  s690 = (a2016 - a2017);\n  s691 = (a2017 + a2016);\n  s692 = P1[(a2011 + 96)];\n  s693 = P1[(a2011 + 97)];\n  s694 = P1[(a2011 + 352)];\n  s695 = P1[(a2011 + 353)];\n  t1444 = (s692 + s694);\n  t1445 = (s693 + s695);\n  t1446 = (s692 - s694);\n  t1447 = (s693 - s695);\n  s696 = P1[(a2011 + 224)];\n  s697 = P1[(a2011 + 225)];\n  s698 = P1[(a2011 + 480)];\n  s699 = P1[(a2011 + 481)];\n  t1448 = (s696 + s698);\n  t1449 = (s697 + s699);\n  t1450 = (s696 - s698);\n  t1451 = (s697 - s699);\n  t1452 = (t1444 + t1448);\n  t1453 = (t1445 + t1449);\n  a2018 = (0.70710678118654757*(t1445 - t1449));\n  a2019 = (0.70710678118654757*(t1444 - t1448));\n  s700 = (a2018 - a2019);\n  s701 = (a2019 + a2018);\n  t1454 = (t1446 + t1451);\n  t1455 = (t1447 - t1450);\n  t1456 = (t1446 - t1451);\n  t1457 = (t1447 + t1450);\n  s702 = ((0.38268343236508978*t1454) + (0.92387953251128674*t1455));\n  s703 = ((0.38268343236508978*t1455) - (0.92387953251128674*t1454));\n  s704 = ((0.92387953251128674*t1456) + (0.38268343236508978*t1457));\n  s705 = ((0.38268343236508978*t1456) - (0.92387953251128674*t1457));\n  t1458 = (t1410 + t1440);\n  t1459 = (t1411 + t1441);\n  t1460 = (t1410 - t1440);\n  t1461 = (t1411 - t1441);\n  t1462 = (t1426 + t1452);\n  t1463 = (t1427 + t1453);\n  t1464 = (t1426 - t1452);\n  t1465 = (t1427 - t1453);\n  a2020 = (a2009 + (32*a2010));\n  T33[a2020] = (t1458 + t1462);\n  T33[(a2020 + 1)] = (t1459 + t1463);\n  T33[(a2020 + 16)] = (t1458 - t1462);\n  T33[(a2020 + 17)] = (t1459 - t1463);\n  T33[(a2020 + 8)] = (t1460 + t1465);\n  T33[(a2020 + 9)] = (t1461 - t1464);\n  T33[(a2020 + 24)] = (t1460 - t1465);\n  T33[(a2020 + 25)] = (t1461 + t1464);\n  t1466 = (t1414 + s688);\n  t1467 = (t1415 + s689);\n  t1468 = (t1414 - s688);\n  t1469 = (t1415 - s689);\n  t1470 = (s676 + s702);\n  t1471 = (s677 + s703);\n  t1472 = (s676 - s702);\n  t1473 = (s677 - s703);\n  T33[(a2020 + 2)] = (t1466 + t1470);\n  T33[(a2020 + 3)] = (t1467 + t1471);\n  T33[(a2020 + 18)] = (t1466 - t1470);\n  T33[(a2020 + 19)] = (t1467 - t1471);\n  T33[(a2020 + 10)] = (t1468 + t1473);\n  T33[(a2020 + 11)] = (t1469 - t1472);\n  T33[(a2020 + 26)] = (t1468 - t1473);\n  T33[(a2020 + 27)] = (t1469 + t1472);\n  t1474 = (t1412 + t1443);\n  t1475 = (t1413 - t1442);\n  t1476 = (t1412 - t1443);\n  t1477 = (t1413 + t1442);\n  t1478 = (s674 + s700);\n  t1479 = (s675 - s701);\n  t1480 = (s674 - s700);\n  t1481 = (s675 + s701);\n  T33[(a2020 + 4)] = (t1474 + t1478);\n  T33[(a2020 + 5)] = (t1475 + t1479);\n  T33[(a2020 + 20)] = (t1474 - t1478);\n  T33[(a2020 + 21)] = (t1475 - t1479);\n  T33[(a2020 + 12)] = (t1476 + t1481);\n  T33[(a2020 + 13)] = (t1477 - t1480);\n  T33[(a2020 + 28)] = (t1476 - t1481);\n  T33[(a2020 + 29)] = (t1477 + t1480);\n  t1482 = (t1416 + s690);\n  t1483 = (t1417 - s691);\n  t1484 = (t1416 - s690);\n  t1485 = (t1417 + s691);\n  t1486 = (s678 - s704);\n  t1487 = (s679 + s705);\n  t1488 = (s678 + s704);\n  t1489 = (s679 - s705);\n  T33[(a2020 + 6)] = (t1482 + t1486);\n  T33[(a2020 + 7)] = (t1483 + t1487);\n  T33[(a2020 + 22)] = (t1482 - t1486);\n  T33[(a2020 + 23)] = (t1483 - t1487);\n  T33[(a2020 + 14)] = (t1484 + t1489);\n  T33[(a2020 + 15)] = (t1485 - t1488);\n  T33[(a2020 + 30)] = (t1484 - t1489);\n  T33[(a2020 + 31)] = (t1485 + t1488);\n  __syncthreads();\n  double a2995, a2996, a2997, a2998, a2999, a3000, a3001, a3002,\n         a3003, a3004, a3005, a3006, a3007, a3008, a3009, a3010,\n         a3011, a3012, a3013, a3014, a3015, a3016, a3017, a3018,\n         a3019, a3020, a3021, a3022, a3023, a3024, a3025, a3026,\n         a3027, a3028, a3029, a3030, a3031, a3032, a3033, a3034,\n         s1000, s1001, s1002, s1003, s1004, s1005, s1006, s1007,\n         s1008, s1009, s1010, s1011, s1012, s1013, s1014, s1015,\n         s1016, s1017, s1018, s1019, s1020, s1021, s1022, s1023,\n         s1024, s1025, s946, s947, s948, s949, s950, s951,\n         s952, s953, s954, s955, s956, s957, s958, s959,\n         s960, s961, s962, s963, s964, s965, s966, s967,\n         s968, s969, s970, s971, s972, s973, s974, s975,\n         s976, s977, s978, s979, s980, s981, s982, s983,\n         s984, s985, s986, s987, s988, s989, s990, s991,\n         s992, s993, s994, s995, s996, s997, s998, s999,\n         t1834, t1835, t1836, t1837, t1838, t1839, t1840, t1841,\n         t1842, t1843, t1844, t1845, t1846, t1847, t1848, t1849,\n         t1850, t1851, t1852, t1853, t1854, t1855, t1856, t1857,\n         t1858, t1859, t1860, t1861, t1862, t1863, t1864, t1865,\n         t1866, t1867, t1868, t1869, t1870, t1871, t1872, t1873,\n         t1874, t1875, t1876, t1877, t1878, t1879, t1880, t1881,\n         t1882, t1883, t1884, t1885, t1886, t1887, t1888, t1889,\n         t1890, t1891, t1892, t1893, t1894, t1895, t1896, t1897,\n         t1898, t1899, t1900, t1901, t1902, t1903, t1904, t1905,\n         t1906, t1907, t1908, t1909, t1910, t1911, t1912, t1913,\n         t1914, t1915, t1916, t1917, t1918, t1919, t1920, t1921;\n  int a2991, a2992, a2993, a2994, a3035;\n  a2991 = (threadIdx_x / 16);\n  a2992 = (threadIdx_x % 16);\n  a2993 = ((512*a2991) + (2*a2992));\n  s946 = T33[a2993];\n  s947 = T33[(a2993 + 1)];\n  s948 = T33[(a2993 + 256)];\n  s949 = T33[(a2993 + 257)];\n  a2994 = (32*a2992);\n  a2995 = D3[a2994];\n  a2996 = D3[(a2994 + 1)];\n  s950 = ((a2995*s946) - (a2996*s947));\n  s951 = ((a2996*s946) + (a2995*s947));\n  a2997 = D3[(a2994 + 2)];\n  a2998 = D3[(a2994 + 3)];\n  s952 = ((a2997*s948) - (a2998*s949));\n  s953 = ((a2998*s948) + (a2997*s949));\n  t1834 = (s950 + s952);\n  t1835 = (s951 + s953);\n  t1836 = (s950 - s952);\n  t1837 = (s951 - s953);\n  s954 = T33[(a2993 + 128)];\n  s955 = T33[(a2993 + 129)];\n  s956 = T33[(a2993 + 384)];\n  s957 = T33[(a2993 + 385)];\n  a2999 = D3[(4 + a2994)];\n  a3000 = D3[(5 + a2994)];\n  s958 = ((a2999*s954) - (a3000*s955));\n  s959 = ((a3000*s954) + (a2999*s955));\n  a3001 = D3[(6 + a2994)];\n  a3002 = D3[(7 + a2994)];\n  s960 = ((a3001*s956) - (a3002*s957));\n  s961 = ((a3002*s956) + (a3001*s957));\n  t1838 = (s958 + s960);\n  t1839 = (s959 + s961);\n  t1840 = (s958 - s960);\n  t1841 = (s959 - s961);\n  t1842 = (t1834 + t1838);\n  t1843 = (t1835 + t1839);\n  t1844 = (t1834 - t1838);\n  t1845 = (t1835 - t1839);\n  t1846 = (t1836 + t1841);\n  t1847 = (t1837 - t1840);\n  t1848 = (t1836 - t1841);\n  t1849 = (t1837 + t1840);\n  s962 = T33[(a2993 + 32)];\n  s963 = T33[(a2993 + 33)];\n  s964 = T33[(a2993 + 288)];\n  s965 = T33[(a2993 + 289)];\n  a3003 = D3[(a2994 + 8)];\n  a3004 = D3[(9 + a2994)];\n  s966 = ((a3003*s962) - (a3004*s963));\n  s967 = ((a3004*s962) + (a3003*s963));\n  a3005 = D3[(10 + a2994)];\n  a3006 = D3[(11 + a2994)];\n  s968 = ((a3005*s964) - (a3006*s965));\n  s969 = ((a3006*s964) + (a3005*s965));\n  t1850 = (s966 + s968);\n  t1851 = (s967 + s969);\n  t1852 = (s966 - s968);\n  t1853 = (s967 - s969);\n  s970 = T33[(a2993 + 160)];\n  s971 = T33[(a2993 + 161)];\n  s972 = T33[(a2993 + 416)];\n  s973 = T33[(a2993 + 417)];\n  a3007 = D3[(12 + a2994)];\n  a3008 = D3[(13 + a2994)];\n  s974 = ((a3007*s970) - (a3008*s971));\n  s975 = ((a3008*s970) + (a3007*s971));\n  a3009 = D3[(14 + a2994)];\n  a3010 = D3[(15 + a2994)];\n  s976 = ((a3009*s972) - (a3010*s973));\n  s977 = ((a3010*s972) + (a3009*s973));\n  t1854 = (s974 + s976);\n  t1855 = (s975 + s977);\n  t1856 = (s974 - s976);\n  t1857 = (s975 - s977);\n  t1858 = (t1850 + t1854);\n  t1859 = (t1851 + t1855);\n  a3011 = (0.70710678118654757*(t1850 - t1854));\n  a3012 = (0.70710678118654757*(t1851 - t1855));\n  s978 = (a3011 + a3012);\n  s979 = (a3012 - a3011);\n  t1860 = (t1852 + t1857);\n  t1861 = (t1853 - t1856);\n  t1862 = (t1852 - t1857);\n  t1863 = (t1853 + t1856);\n  s980 = ((0.92387953251128674*t1860) + (0.38268343236508978*t1861));\n  s981 = ((0.92387953251128674*t1861) - (0.38268343236508978*t1860));\n  s982 = ((0.38268343236508978*t1862) + (0.92387953251128674*t1863));\n  s983 = ((0.38268343236508978*t1863) - (0.92387953251128674*t1862));\n  s984 = T33[(a2993 + 64)];\n  s985 = T33[(a2993 + 65)];\n  s986 = T33[(a2993 + 320)];\n  s987 = T33[(a2993 + 321)];\n  a3013 = D3[(a2994 + 16)];\n  a3014 = D3[(17 + a2994)];\n  s988 = ((a3013*s984) - (a3014*s985));\n  s989 = ((a3014*s984) + (a3013*s985));\n  a3015 = D3[(18 + a2994)];\n  a3016 = D3[(19 + a2994)];\n  s990 = ((a3015*s986) - (a3016*s987));\n  s991 = ((a3016*s986) + (a3015*s987));\n  t1864 = (s988 + s990);\n  t1865 = (s989 + s991);\n  t1866 = (s988 - s990);\n  t1867 = (s989 - s991);\n  s992 = T33[(a2993 + 192)];\n  s993 = T33[(a2993 + 193)];\n  s994 = T33[(a2993 + 448)];\n  s995 = T33[(a2993 + 449)];\n  a3017 = D3[(20 + a2994)];\n  a3018 = D3[(21 + a2994)];\n  s996 = ((a3017*s992) - (a3018*s993));\n  s997 = ((a3018*s992) + (a3017*s993));\n  a3019 = D3[(22 + a2994)];\n  a3020 = D3[(23 + a2994)];\n  s998 = ((a3019*s994) - (a3020*s995));\n  s999 = ((a3020*s994) + (a3019*s995));\n  t1868 = (s996 + s998);\n  t1869 = (s997 + s999);\n  t1870 = (s996 - s998);\n  t1871 = (s997 - s999);\n  t1872 = (t1864 + t1868);\n  t1873 = (t1865 + t1869);\n  t1874 = (t1864 - t1868);\n  t1875 = (t1865 - t1869);\n  a3021 = (0.70710678118654757*(t1866 + t1871));\n  a3022 = (0.70710678118654757*(t1867 - t1870));\n  s1000 = (a3021 + a3022);\n  s1001 = (a3022 - a3021);\n  a3023 = (0.70710678118654757*(t1867 + t1870));\n  a3024 = (0.70710678118654757*(t1866 - t1871));\n  s1002 = (a3023 - a3024);\n  s1003 = (a3024 + a3023);\n  s1004 = T33[(a2993 + 96)];\n  s1005 = T33[(a2993 + 97)];\n  s1006 = T33[(a2993 + 352)];\n  s1007 = T33[(a2993 + 353)];\n  a3025 = D3[(a2994 + 24)];\n  a3026 = D3[(25 + a2994)];\n  s1008 = ((a3025*s1004) - (a3026*s1005));\n  s1009 = ((a3026*s1004) + (a3025*s1005));\n  a3027 = D3[(26 + a2994)];\n  a3028 = D3[(27 + a2994)];\n  s1010 = ((a3027*s1006) - (a3028*s1007));\n  s1011 = ((a3028*s1006) + (a3027*s1007));\n  t1876 = (s1008 + s1010);\n  t1877 = (s1009 + s1011);\n  t1878 = (s1008 - s1010);\n  t1879 = (s1009 - s1011);\n  s1012 = T33[(a2993 + 224)];\n  s1013 = T33[(a2993 + 225)];\n  s1014 = T33[(a2993 + 480)];\n  s1015 = T33[(a2993 + 481)];\n  a3029 = D3[(28 + a2994)];\n  a3030 = D3[(29 + a2994)];\n  s1016 = ((a3029*s1012) - (a3030*s1013));\n  s1017 = ((a3030*s1012) + (a3029*s1013));\n  a3031 = D3[(30 + a2994)];\n  a3032 = D3[(31 + a2994)];\n  s1018 = ((a3031*s1014) - (a3032*s1015));\n  s1019 = ((a3032*s1014) + (a3031*s1015));\n  t1880 = (s1016 + s1018);\n  t1881 = (s1017 + s1019);\n  t1882 = (s1016 - s1018);\n  t1883 = (s1017 - s1019);\n  t1884 = (t1876 + t1880);\n  t1885 = (t1877 + t1881);\n  a3033 = (0.70710678118654757*(t1877 - t1881));\n  a3034 = (0.70710678118654757*(t1876 - t1880));\n  s1020 = (a3033 - a3034);\n  s1021 = (a3034 + a3033);\n  t1886 = (t1878 + t1883);\n  t1887 = (t1879 - t1882);\n  t1888 = (t1878 - t1883);\n  t1889 = (t1879 + t1882);\n  s1022 = ((0.38268343236508978*t1886) + (0.92387953251128674*t1887));\n  s1023 = ((0.38268343236508978*t1887) - (0.92387953251128674*t1886));\n  s1024 = ((0.92387953251128674*t1888) + (0.38268343236508978*t1889));\n  s1025 = ((0.38268343236508978*t1888) - (0.92387953251128674*t1889));\n  t1890 = (t1842 + t1872);\n  t1891 = (t1843 + t1873);\n  t1892 = (t1842 - t1872);\n  t1893 = (t1843 - t1873);\n  t1894 = (t1858 + t1884);\n  t1895 = (t1859 + t1885);\n  t1896 = (t1858 - t1884);\n  t1897 = (t1859 - t1885);\n  a3035 = ((8*blockIdx_x) + (131072*a2992) + (2*a2991));\n  P2[a3035] = (t1890 + t1894);\n  P2[(a3035 + 1)] = (t1891 + t1895);\n  P2[(a3035 + 16777216)] = (t1890 - t1894);\n  P2[(a3035 + 16777217)] = (t1891 - t1895);\n  P2[(a3035 + 8388608)] = (t1892 + t1897);\n  P2[(a3035 + 8388609)] = (t1893 - t1896);\n  P2[(a3035 + 25165824)] = (t1892 - t1897);\n  P2[(a3035 + 25165825)] = (t1893 + t1896);\n  t1898 = (t1846 + s1000);\n  t1899 = (t1847 + s1001);\n  t1900 = (t1846 - s1000);\n  t1901 = (t1847 - s1001);\n  t1902 = (s980 + s1022);\n  t1903 = (s981 + s1023);\n  t1904 = (s980 - s1022);\n  t1905 = (s981 - s1023);\n  P2[(a3035 + 2097152)] = (t1898 + t1902);\n  P2[(a3035 + 2097153)] = (t1899 + t1903);\n  P2[(a3035 + 18874368)] = (t1898 - t1902);\n  P2[(a3035 + 18874369)] = (t1899 - t1903);\n  P2[(a3035 + 10485760)] = (t1900 + t1905);\n  P2[(a3035 + 10485761)] = (t1901 - t1904);\n  P2[(a3035 + 27262976)] = (t1900 - t1905);\n  P2[(a3035 + 27262977)] = (t1901 + t1904);\n  t1906 = (t1844 + t1875);\n  t1907 = (t1845 - t1874);\n  t1908 = (t1844 - t1875);\n  t1909 = (t1845 + t1874);\n  t1910 = (s978 + s1020);\n  t1911 = (s979 - s1021);\n  t1912 = (s978 - s1020);\n  t1913 = (s979 + s1021);\n  P2[(a3035 + 4194304)] = (t1906 + t1910);\n  P2[(a3035 + 4194305)] = (t1907 + t1911);\n  P2[(a3035 + 20971520)] = (t1906 - t1910);\n  P2[(a3035 + 20971521)] = (t1907 - t1911);\n  P2[(a3035 + 12582912)] = (t1908 + t1913);\n  P2[(a3035 + 12582913)] = (t1909 - t1912);\n  P2[(a3035 + 29360128)] = (t1908 - t1913);\n  P2[(a3035 + 29360129)] = (t1909 + t1912);\n  t1914 = (t1848 + s1002);\n  t1915 = (t1849 - s1003);\n  t1916 = (t1848 - s1002);\n  t1917 = (t1849 + s1003);\n  t1918 = (s982 - s1024);\n  t1919 = (s983 + s1025);\n  t1920 = (s982 + s1024);\n  t1921 = (s983 - s1025);\n  P2[(a3035 + 6291456)] = (t1914 + t1918);\n  P2[(a3035 + 6291457)] = (t1915 + t1919);\n  P2[(a3035 + 23068672)] = (t1914 - t1918);\n  P2[(a3035 + 23068673)] = (t1915 - t1919);\n  P2[(a3035 + 14680064)] = (t1916 + t1921);\n  P2[(a3035 + 14680065)] = (t1917 - t1920);\n  P2[(a3035 + 31457280)] = (t1916 - t1921);\n  P2[(a3035 + 31457281)] = (t1917 + t1920);\n  __syncthreads();\n}\n\nvoid ker_zmddft_fwd_256x256x256_cu2(sycl::nd_item<1> &item,\n                                    double *__restrict T63,\n                                    const double *__restrict P2,\n                                    double *__restrict Y)\n{\n  double a3529, a3530, a3531, a3532, a3533, a3534, a3535, a3536,\n         s1170, s1171, s1172, s1173, s1174, s1175, s1176, s1177,\n         s1178, s1179, s1180, s1181, s1182, s1183, s1184, s1185,\n         s1186, s1187, s1188, s1189, s1190, s1191, s1192, s1193,\n         s1194, s1195, s1196, s1197, s1198, s1199, s1200, s1201,\n         s1202, s1203, s1204, s1205, s1206, s1207, s1208, s1209,\n         s1210, s1211, s1212, s1213, s1214, s1215, s1216, s1217,\n         t2266, t2267, t2268, t2269, t2270, t2271, t2272, t2273,\n         t2274, t2275, t2276, t2277, t2278, t2279, t2280, t2281,\n         t2282, t2283, t2284, t2285, t2286, t2287, t2288, t2289,\n         t2290, t2291, t2292, t2293, t2294, t2295, t2296, t2297,\n         t2298, t2299, t2300, t2301, t2302, t2303, t2304, t2305,\n         t2306, t2307, t2308, t2309, t2310, t2311, t2312, t2313,\n         t2314, t2315, t2316, t2317, t2318, t2319, t2320, t2321,\n         t2322, t2323, t2324, t2325, t2326, t2327, t2328, t2329,\n         t2330, t2331, t2332, t2333, t2334, t2335, t2336, t2337,\n         t2338, t2339, t2340, t2341, t2342, t2343, t2344, t2345,\n         t2346, t2347, t2348, t2349, t2350, t2351, t2352, t2353;\n  int a3526, a3527, a3528, a3537;\n  int threadIdx_x = item.get_local_id(0);\n  int blockIdx_x = item.get_group(0);\n  a3526 = (512*(threadIdx_x / 16));\n  a3527 = (threadIdx_x % 16);\n  a3528 = ((2048*blockIdx_x) + a3526 + (2*a3527));\n  s1170 = P2[a3528];\n  s1171 = P2[(a3528 + 1)];\n  s1172 = P2[(a3528 + 256)];\n  s1173 = P2[(a3528 + 257)];\n  t2266 = (s1170 + s1172);\n  t2267 = (s1171 + s1173);\n  t2268 = (s1170 - s1172);\n  t2269 = (s1171 - s1173);\n  s1174 = P2[(a3528 + 128)];\n  s1175 = P2[(a3528 + 129)];\n  s1176 = P2[(a3528 + 384)];\n  s1177 = P2[(a3528 + 385)];\n  t2270 = (s1174 + s1176);\n  t2271 = (s1175 + s1177);\n  t2272 = (s1174 - s1176);\n  t2273 = (s1175 - s1177);\n  t2274 = (t2266 + t2270);\n  t2275 = (t2267 + t2271);\n  t2276 = (t2266 - t2270);\n  t2277 = (t2267 - t2271);\n  t2278 = (t2268 + t2273);\n  t2279 = (t2269 - t2272);\n  t2280 = (t2268 - t2273);\n  t2281 = (t2269 + t2272);\n  s1178 = P2[(a3528 + 32)];\n  s1179 = P2[(a3528 + 33)];\n  s1180 = P2[(a3528 + 288)];\n  s1181 = P2[(a3528 + 289)];\n  t2282 = (s1178 + s1180);\n  t2283 = (s1179 + s1181);\n  t2284 = (s1178 - s1180);\n  t2285 = (s1179 - s1181);\n  s1182 = P2[(a3528 + 160)];\n  s1183 = P2[(a3528 + 161)];\n  s1184 = P2[(a3528 + 416)];\n  s1185 = P2[(a3528 + 417)];\n  t2286 = (s1182 + s1184);\n  t2287 = (s1183 + s1185);\n  t2288 = (s1182 - s1184);\n  t2289 = (s1183 - s1185);\n  t2290 = (t2282 + t2286);\n  t2291 = (t2283 + t2287);\n  a3529 = (0.70710678118654757*(t2282 - t2286));\n  a3530 = (0.70710678118654757*(t2283 - t2287));\n  s1186 = (a3529 + a3530);\n  s1187 = (a3530 - a3529);\n  t2292 = (t2284 + t2289);\n  t2293 = (t2285 - t2288);\n  t2294 = (t2284 - t2289);\n  t2295 = (t2285 + t2288);\n  s1188 = ((0.92387953251128674*t2292) + (0.38268343236508978*t2293));\n  s1189 = ((0.92387953251128674*t2293) - (0.38268343236508978*t2292));\n  s1190 = ((0.38268343236508978*t2294) + (0.92387953251128674*t2295));\n  s1191 = ((0.38268343236508978*t2295) - (0.92387953251128674*t2294));\n  s1192 = P2[(a3528 + 64)];\n  s1193 = P2[(a3528 + 65)];\n  s1194 = P2[(a3528 + 320)];\n  s1195 = P2[(a3528 + 321)];\n  t2296 = (s1192 + s1194);\n  t2297 = (s1193 + s1195);\n  t2298 = (s1192 - s1194);\n  t2299 = (s1193 - s1195);\n  s1196 = P2[(a3528 + 192)];\n  s1197 = P2[(a3528 + 193)];\n  s1198 = P2[(a3528 + 448)];\n  s1199 = P2[(a3528 + 449)];\n  t2300 = (s1196 + s1198);\n  t2301 = (s1197 + s1199);\n  t2302 = (s1196 - s1198);\n  t2303 = (s1197 - s1199);\n  t2304 = (t2296 + t2300);\n  t2305 = (t2297 + t2301);\n  t2306 = (t2296 - t2300);\n  t2307 = (t2297 - t2301);\n  a3531 = (0.70710678118654757*(t2298 + t2303));\n  a3532 = (0.70710678118654757*(t2299 - t2302));\n  s1200 = (a3531 + a3532);\n  s1201 = (a3532 - a3531);\n  a3533 = (0.70710678118654757*(t2299 + t2302));\n  a3534 = (0.70710678118654757*(t2298 - t2303));\n  s1202 = (a3533 - a3534);\n  s1203 = (a3534 + a3533);\n  s1204 = P2[(a3528 + 96)];\n  s1205 = P2[(a3528 + 97)];\n  s1206 = P2[(a3528 + 352)];\n  s1207 = P2[(a3528 + 353)];\n  t2308 = (s1204 + s1206);\n  t2309 = (s1205 + s1207);\n  t2310 = (s1204 - s1206);\n  t2311 = (s1205 - s1207);\n  s1208 = P2[(a3528 + 224)];\n  s1209 = P2[(a3528 + 225)];\n  s1210 = P2[(a3528 + 480)];\n  s1211 = P2[(a3528 + 481)];\n  t2312 = (s1208 + s1210);\n  t2313 = (s1209 + s1211);\n  t2314 = (s1208 - s1210);\n  t2315 = (s1209 - s1211);\n  t2316 = (t2308 + t2312);\n  t2317 = (t2309 + t2313);\n  a3535 = (0.70710678118654757*(t2309 - t2313));\n  a3536 = (0.70710678118654757*(t2308 - t2312));\n  s1212 = (a3535 - a3536);\n  s1213 = (a3536 + a3535);\n  t2318 = (t2310 + t2315);\n  t2319 = (t2311 - t2314);\n  t2320 = (t2310 - t2315);\n  t2321 = (t2311 + t2314);\n  s1214 = ((0.38268343236508978*t2318) + (0.92387953251128674*t2319));\n  s1215 = ((0.38268343236508978*t2319) - (0.92387953251128674*t2318));\n  s1216 = ((0.92387953251128674*t2320) + (0.38268343236508978*t2321));\n  s1217 = ((0.38268343236508978*t2320) - (0.92387953251128674*t2321));\n  t2322 = (t2274 + t2304);\n  t2323 = (t2275 + t2305);\n  t2324 = (t2274 - t2304);\n  t2325 = (t2275 - t2305);\n  t2326 = (t2290 + t2316);\n  t2327 = (t2291 + t2317);\n  t2328 = (t2290 - t2316);\n  t2329 = (t2291 - t2317);\n  a3537 = (a3526 + (32*a3527));\n  T63[a3537] = (t2322 + t2326);\n  T63[(a3537 + 1)] = (t2323 + t2327);\n  T63[(a3537 + 16)] = (t2322 - t2326);\n  T63[(a3537 + 17)] = (t2323 - t2327);\n  T63[(a3537 + 8)] = (t2324 + t2329);\n  T63[(a3537 + 9)] = (t2325 - t2328);\n  T63[(a3537 + 24)] = (t2324 - t2329);\n  T63[(a3537 + 25)] = (t2325 + t2328);\n  t2330 = (t2278 + s1200);\n  t2331 = (t2279 + s1201);\n  t2332 = (t2278 - s1200);\n  t2333 = (t2279 - s1201);\n  t2334 = (s1188 + s1214);\n  t2335 = (s1189 + s1215);\n  t2336 = (s1188 - s1214);\n  t2337 = (s1189 - s1215);\n  T63[(a3537 + 2)] = (t2330 + t2334);\n  T63[(a3537 + 3)] = (t2331 + t2335);\n  T63[(a3537 + 18)] = (t2330 - t2334);\n  T63[(a3537 + 19)] = (t2331 - t2335);\n  T63[(a3537 + 10)] = (t2332 + t2337);\n  T63[(a3537 + 11)] = (t2333 - t2336);\n  T63[(a3537 + 26)] = (t2332 - t2337);\n  T63[(a3537 + 27)] = (t2333 + t2336);\n  t2338 = (t2276 + t2307);\n  t2339 = (t2277 - t2306);\n  t2340 = (t2276 - t2307);\n  t2341 = (t2277 + t2306);\n  t2342 = (s1186 + s1212);\n  t2343 = (s1187 - s1213);\n  t2344 = (s1186 - s1212);\n  t2345 = (s1187 + s1213);\n  T63[(a3537 + 4)] = (t2338 + t2342);\n  T63[(a3537 + 5)] = (t2339 + t2343);\n  T63[(a3537 + 20)] = (t2338 - t2342);\n  T63[(a3537 + 21)] = (t2339 - t2343);\n  T63[(a3537 + 12)] = (t2340 + t2345);\n  T63[(a3537 + 13)] = (t2341 - t2344);\n  T63[(a3537 + 28)] = (t2340 - t2345);\n  T63[(a3537 + 29)] = (t2341 + t2344);\n  t2346 = (t2280 + s1202);\n  t2347 = (t2281 - s1203);\n  t2348 = (t2280 - s1202);\n  t2349 = (t2281 + s1203);\n  t2350 = (s1190 - s1216);\n  t2351 = (s1191 + s1217);\n  t2352 = (s1190 + s1216);\n  t2353 = (s1191 - s1217);\n  T63[(a3537 + 6)] = (t2346 + t2350);\n  T63[(a3537 + 7)] = (t2347 + t2351);\n  T63[(a3537 + 22)] = (t2346 - t2350);\n  T63[(a3537 + 23)] = (t2347 - t2351);\n  T63[(a3537 + 14)] = (t2348 + t2353);\n  T63[(a3537 + 15)] = (t2349 - t2352);\n  T63[(a3537 + 30)] = (t2348 - t2353);\n  T63[(a3537 + 31)] = (t2349 + t2352);\n  __syncthreads();\n  double a4512, a4513, a4514, a4515, a4516, a4517, a4518, a4519,\n         a4520, a4521, a4522, a4523, a4524, a4525, a4526, a4527,\n         a4528, a4529, a4530, a4531, a4532, a4533, a4534, a4535,\n         a4536, a4537, a4538, a4539, a4540, a4541, a4542, a4543,\n         a4544, a4545, a4546, a4547, a4548, a4549, a4550, a4551,\n         s1458, s1459, s1460, s1461, s1462, s1463, s1464, s1465,\n         s1466, s1467, s1468, s1469, s1470, s1471, s1472, s1473,\n         s1474, s1475, s1476, s1477, s1478, s1479, s1480, s1481,\n         s1482, s1483, s1484, s1485, s1486, s1487, s1488, s1489,\n         s1490, s1491, s1492, s1493, s1494, s1495, s1496, s1497,\n         s1498, s1499, s1500, s1501, s1502, s1503, s1504, s1505,\n         s1506, s1507, s1508, s1509, s1510, s1511, s1512, s1513,\n         s1514, s1515, s1516, s1517, s1518, s1519, s1520, s1521,\n         s1522, s1523, s1524, s1525, s1526, s1527, s1528, s1529,\n         s1530, s1531, s1532, s1533, s1534, s1535, s1536, s1537,\n         t2698, t2699, t2700, t2701, t2702, t2703, t2704, t2705,\n         t2706, t2707, t2708, t2709, t2710, t2711, t2712, t2713,\n         t2714, t2715, t2716, t2717, t2718, t2719, t2720, t2721,\n         t2722, t2723, t2724, t2725, t2726, t2727, t2728, t2729,\n         t2730, t2731, t2732, t2733, t2734, t2735, t2736, t2737,\n         t2738, t2739, t2740, t2741, t2742, t2743, t2744, t2745,\n         t2746, t2747, t2748, t2749, t2750, t2751, t2752, t2753,\n         t2754, t2755, t2756, t2757, t2758, t2759, t2760, t2761,\n         t2762, t2763, t2764, t2765, t2766, t2767, t2768, t2769,\n         t2770, t2771, t2772, t2773, t2774, t2775, t2776, t2777,\n         t2778, t2779, t2780, t2781, t2782, t2783, t2784, t2785;\n  int a4508, a4509, a4510, a4511, a4552;\n  a4508 = (threadIdx_x / 16);\n  a4509 = (threadIdx_x % 16);\n  a4510 = ((512*a4508) + (2*a4509));\n  s1458 = T63[a4510];\n  s1459 = T63[(a4510 + 1)];\n  s1460 = T63[(a4510 + 256)];\n  s1461 = T63[(a4510 + 257)];\n  a4511 = (32*a4509);\n  a4512 = D3[a4511];\n  a4513 = D3[(a4511 + 1)];\n  s1462 = ((a4512*s1458) - (a4513*s1459));\n  s1463 = ((a4513*s1458) + (a4512*s1459));\n  a4514 = D3[(a4511 + 2)];\n  a4515 = D3[(a4511 + 3)];\n  s1464 = ((a4514*s1460) - (a4515*s1461));\n  s1465 = ((a4515*s1460) + (a4514*s1461));\n  t2698 = (s1462 + s1464);\n  t2699 = (s1463 + s1465);\n  t2700 = (s1462 - s1464);\n  t2701 = (s1463 - s1465);\n  s1466 = T63[(a4510 + 128)];\n  s1467 = T63[(a4510 + 129)];\n  s1468 = T63[(a4510 + 384)];\n  s1469 = T63[(a4510 + 385)];\n  a4516 = D3[(4 + a4511)];\n  a4517 = D3[(5 + a4511)];\n  s1470 = ((a4516*s1466) - (a4517*s1467));\n  s1471 = ((a4517*s1466) + (a4516*s1467));\n  a4518 = D3[(6 + a4511)];\n  a4519 = D3[(7 + a4511)];\n  s1472 = ((a4518*s1468) - (a4519*s1469));\n  s1473 = ((a4519*s1468) + (a4518*s1469));\n  t2702 = (s1470 + s1472);\n  t2703 = (s1471 + s1473);\n  t2704 = (s1470 - s1472);\n  t2705 = (s1471 - s1473);\n  t2706 = (t2698 + t2702);\n  t2707 = (t2699 + t2703);\n  t2708 = (t2698 - t2702);\n  t2709 = (t2699 - t2703);\n  t2710 = (t2700 + t2705);\n  t2711 = (t2701 - t2704);\n  t2712 = (t2700 - t2705);\n  t2713 = (t2701 + t2704);\n  s1474 = T63[(a4510 + 32)];\n  s1475 = T63[(a4510 + 33)];\n  s1476 = T63[(a4510 + 288)];\n  s1477 = T63[(a4510 + 289)];\n  a4520 = D3[(a4511 + 8)];\n  a4521 = D3[(9 + a4511)];\n  s1478 = ((a4520*s1474) - (a4521*s1475));\n  s1479 = ((a4521*s1474) + (a4520*s1475));\n  a4522 = D3[(10 + a4511)];\n  a4523 = D3[(11 + a4511)];\n  s1480 = ((a4522*s1476) - (a4523*s1477));\n  s1481 = ((a4523*s1476) + (a4522*s1477));\n  t2714 = (s1478 + s1480);\n  t2715 = (s1479 + s1481);\n  t2716 = (s1478 - s1480);\n  t2717 = (s1479 - s1481);\n  s1482 = T63[(a4510 + 160)];\n  s1483 = T63[(a4510 + 161)];\n  s1484 = T63[(a4510 + 416)];\n  s1485 = T63[(a4510 + 417)];\n  a4524 = D3[(12 + a4511)];\n  a4525 = D3[(13 + a4511)];\n  s1486 = ((a4524*s1482) - (a4525*s1483));\n  s1487 = ((a4525*s1482) + (a4524*s1483));\n  a4526 = D3[(14 + a4511)];\n  a4527 = D3[(15 + a4511)];\n  s1488 = ((a4526*s1484) - (a4527*s1485));\n  s1489 = ((a4527*s1484) + (a4526*s1485));\n  t2718 = (s1486 + s1488);\n  t2719 = (s1487 + s1489);\n  t2720 = (s1486 - s1488);\n  t2721 = (s1487 - s1489);\n  t2722 = (t2714 + t2718);\n  t2723 = (t2715 + t2719);\n  a4528 = (0.70710678118654757*(t2714 - t2718));\n  a4529 = (0.70710678118654757*(t2715 - t2719));\n  s1490 = (a4528 + a4529);\n  s1491 = (a4529 - a4528);\n  t2724 = (t2716 + t2721);\n  t2725 = (t2717 - t2720);\n  t2726 = (t2716 - t2721);\n  t2727 = (t2717 + t2720);\n  s1492 = ((0.92387953251128674*t2724) + (0.38268343236508978*t2725));\n  s1493 = ((0.92387953251128674*t2725) - (0.38268343236508978*t2724));\n  s1494 = ((0.38268343236508978*t2726) + (0.92387953251128674*t2727));\n  s1495 = ((0.38268343236508978*t2727) - (0.92387953251128674*t2726));\n  s1496 = T63[(a4510 + 64)];\n  s1497 = T63[(a4510 + 65)];\n  s1498 = T63[(a4510 + 320)];\n  s1499 = T63[(a4510 + 321)];\n  a4530 = D3[(a4511 + 16)];\n  a4531 = D3[(17 + a4511)];\n  s1500 = ((a4530*s1496) - (a4531*s1497));\n  s1501 = ((a4531*s1496) + (a4530*s1497));\n  a4532 = D3[(18 + a4511)];\n  a4533 = D3[(19 + a4511)];\n  s1502 = ((a4532*s1498) - (a4533*s1499));\n  s1503 = ((a4533*s1498) + (a4532*s1499));\n  t2728 = (s1500 + s1502);\n  t2729 = (s1501 + s1503);\n  t2730 = (s1500 - s1502);\n  t2731 = (s1501 - s1503);\n  s1504 = T63[(a4510 + 192)];\n  s1505 = T63[(a4510 + 193)];\n  s1506 = T63[(a4510 + 448)];\n  s1507 = T63[(a4510 + 449)];\n  a4534 = D3[(20 + a4511)];\n  a4535 = D3[(21 + a4511)];\n  s1508 = ((a4534*s1504) - (a4535*s1505));\n  s1509 = ((a4535*s1504) + (a4534*s1505));\n  a4536 = D3[(22 + a4511)];\n  a4537 = D3[(23 + a4511)];\n  s1510 = ((a4536*s1506) - (a4537*s1507));\n  s1511 = ((a4537*s1506) + (a4536*s1507));\n  t2732 = (s1508 + s1510);\n  t2733 = (s1509 + s1511);\n  t2734 = (s1508 - s1510);\n  t2735 = (s1509 - s1511);\n  t2736 = (t2728 + t2732);\n  t2737 = (t2729 + t2733);\n  t2738 = (t2728 - t2732);\n  t2739 = (t2729 - t2733);\n  a4538 = (0.70710678118654757*(t2730 + t2735));\n  a4539 = (0.70710678118654757*(t2731 - t2734));\n  s1512 = (a4538 + a4539);\n  s1513 = (a4539 - a4538);\n  a4540 = (0.70710678118654757*(t2731 + t2734));\n  a4541 = (0.70710678118654757*(t2730 - t2735));\n  s1514 = (a4540 - a4541);\n  s1515 = (a4541 + a4540);\n  s1516 = T63[(a4510 + 96)];\n  s1517 = T63[(a4510 + 97)];\n  s1518 = T63[(a4510 + 352)];\n  s1519 = T63[(a4510 + 353)];\n  a4542 = D3[(a4511 + 24)];\n  a4543 = D3[(25 + a4511)];\n  s1520 = ((a4542*s1516) - (a4543*s1517));\n  s1521 = ((a4543*s1516) + (a4542*s1517));\n  a4544 = D3[(26 + a4511)];\n  a4545 = D3[(27 + a4511)];\n  s1522 = ((a4544*s1518) - (a4545*s1519));\n  s1523 = ((a4545*s1518) + (a4544*s1519));\n  t2740 = (s1520 + s1522);\n  t2741 = (s1521 + s1523);\n  t2742 = (s1520 - s1522);\n  t2743 = (s1521 - s1523);\n  s1524 = T63[(a4510 + 224)];\n  s1525 = T63[(a4510 + 225)];\n  s1526 = T63[(a4510 + 480)];\n  s1527 = T63[(a4510 + 481)];\n  a4546 = D3[(28 + a4511)];\n  a4547 = D3[(29 + a4511)];\n  s1528 = ((a4546*s1524) - (a4547*s1525));\n  s1529 = ((a4547*s1524) + (a4546*s1525));\n  a4548 = D3[(30 + a4511)];\n  a4549 = D3[(31 + a4511)];\n  s1530 = ((a4548*s1526) - (a4549*s1527));\n  s1531 = ((a4549*s1526) + (a4548*s1527));\n  t2744 = (s1528 + s1530);\n  t2745 = (s1529 + s1531);\n  t2746 = (s1528 - s1530);\n  t2747 = (s1529 - s1531);\n  t2748 = (t2740 + t2744);\n  t2749 = (t2741 + t2745);\n  a4550 = (0.70710678118654757*(t2741 - t2745));\n  a4551 = (0.70710678118654757*(t2740 - t2744));\n  s1532 = (a4550 - a4551);\n  s1533 = (a4551 + a4550);\n  t2750 = (t2742 + t2747);\n  t2751 = (t2743 - t2746);\n  t2752 = (t2742 - t2747);\n  t2753 = (t2743 + t2746);\n  s1534 = ((0.38268343236508978*t2750) + (0.92387953251128674*t2751));\n  s1535 = ((0.38268343236508978*t2751) - (0.92387953251128674*t2750));\n  s1536 = ((0.92387953251128674*t2752) + (0.38268343236508978*t2753));\n  s1537 = ((0.38268343236508978*t2752) - (0.92387953251128674*t2753));\n  t2754 = (t2706 + t2736);\n  t2755 = (t2707 + t2737);\n  t2756 = (t2706 - t2736);\n  t2757 = (t2707 - t2737);\n  t2758 = (t2722 + t2748);\n  t2759 = (t2723 + t2749);\n  t2760 = (t2722 - t2748);\n  t2761 = (t2723 - t2749);\n  a4552 = ((8*blockIdx_x) + (131072*a4509) + (2*a4508));\n  Y[a4552] = (t2754 + t2758);\n  Y[(a4552 + 1)] = (t2755 + t2759);\n  Y[(a4552 + 16777216)] = (t2754 - t2758);\n  Y[(a4552 + 16777217)] = (t2755 - t2759);\n  Y[(a4552 + 8388608)] = (t2756 + t2761);\n  Y[(a4552 + 8388609)] = (t2757 - t2760);\n  Y[(a4552 + 25165824)] = (t2756 - t2761);\n  Y[(a4552 + 25165825)] = (t2757 + t2760);\n  t2762 = (t2710 + s1512);\n  t2763 = (t2711 + s1513);\n  t2764 = (t2710 - s1512);\n  t2765 = (t2711 - s1513);\n  t2766 = (s1492 + s1534);\n  t2767 = (s1493 + s1535);\n  t2768 = (s1492 - s1534);\n  t2769 = (s1493 - s1535);\n  Y[(a4552 + 2097152)] = (t2762 + t2766);\n  Y[(a4552 + 2097153)] = (t2763 + t2767);\n  Y[(a4552 + 18874368)] = (t2762 - t2766);\n  Y[(a4552 + 18874369)] = (t2763 - t2767);\n  Y[(a4552 + 10485760)] = (t2764 + t2769);\n  Y[(a4552 + 10485761)] = (t2765 - t2768);\n  Y[(a4552 + 27262976)] = (t2764 - t2769);\n  Y[(a4552 + 27262977)] = (t2765 + t2768);\n  t2770 = (t2708 + t2739);\n  t2771 = (t2709 - t2738);\n  t2772 = (t2708 - t2739);\n  t2773 = (t2709 + t2738);\n  t2774 = (s1490 + s1532);\n  t2775 = (s1491 - s1533);\n  t2776 = (s1490 - s1532);\n  t2777 = (s1491 + s1533);\n  Y[(a4552 + 4194304)] = (t2770 + t2774);\n  Y[(a4552 + 4194305)] = (t2771 + t2775);\n  Y[(a4552 + 20971520)] = (t2770 - t2774);\n  Y[(a4552 + 20971521)] = (t2771 - t2775);\n  Y[(a4552 + 12582912)] = (t2772 + t2777);\n  Y[(a4552 + 12582913)] = (t2773 - t2776);\n  Y[(a4552 + 29360128)] = (t2772 - t2777);\n  Y[(a4552 + 29360129)] = (t2773 + t2776);\n  t2778 = (t2712 + s1514);\n  t2779 = (t2713 - s1515);\n  t2780 = (t2712 - s1514);\n  t2781 = (t2713 + s1515);\n  t2782 = (s1494 - s1536);\n  t2783 = (s1495 + s1537);\n  t2784 = (s1494 + s1536);\n  t2785 = (s1495 - s1537);\n  Y[(a4552 + 6291456)] = (t2778 + t2782);\n  Y[(a4552 + 6291457)] = (t2779 + t2783);\n  Y[(a4552 + 23068672)] = (t2778 - t2782);\n  Y[(a4552 + 23068673)] = (t2779 - t2783);\n  Y[(a4552 + 14680064)] = (t2780 + t2785);\n  Y[(a4552 + 14680065)] = (t2781 - t2784);\n  Y[(a4552 + 31457280)] = (t2780 - t2785);\n  Y[(a4552 + 31457281)] = (t2781 + t2784);\n  __syncthreads();\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 256*256*256*2;\n  const int t = 33554432;\n  size_t dat_size = n * sizeof(double);\n\n  std::mt19937 engine(n);\n  std::uniform_real_distribution<double> dist(0.0, 1.0);\n  double *x = (double*) malloc (dat_size);\n  for (int i = 0; i < n; i++) x[i] = dist(engine);\n\n  double *y = (double*) malloc (dat_size);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double *Y = sycl::malloc_device<double>(n, q);\n\n  double *X = sycl::malloc_device<double>(n, q);\n  q.memcpy(X, x, dat_size);\n\n  double *P1 = sycl::malloc_device<double>(t, q);\n  double *P2 = sycl::malloc_device<double>(t, q);\n\n  sycl::range<1> b1(64), b2(64), b3(64);\n  sycl::range<1> g1(16384*64), g2(16384*64), g3(16384*64);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<double, 1> temp (sycl::range<1>(2048), cgh);\n      cgh.parallel_for<class cu0>(sycl::nd_range<1>(g1, b1), [=] (sycl::nd_item<1> item) {\n        ker_zmddft_fwd_256x256x256_cu0(item, temp.get_pointer(), X, P1);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<double, 1> temp (sycl::range<1>(2048), cgh);\n      cgh.parallel_for<class cu1>(sycl::nd_range<1>(g2, b2), [=] (sycl::nd_item<1> item) {\n        ker_zmddft_fwd_256x256x256_cu1(item, temp.get_pointer(), P1, P2);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<double, 1> temp (sycl::range<1>(2048), cgh);\n      cgh.parallel_for<class cu2>(sycl::nd_range<1>(g3, b3), [=] (sycl::nd_item<1> item) {\n        ker_zmddft_fwd_256x256x256_cu2(item, temp.get_pointer(), P2, Y);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %.3f (ms)\\n\", time * 1e-6f / repeat);\n\n  q.memcpy(y, Y, dat_size).wait();\n\n  double checksum = 0;\n  for (int i = 0; i < n; i++) checksum += y[i];\n  printf(\"checksum = %lf\\n\", checksum);\n\n  sycl::free(X, q);\n  sycl::free(Y, q);\n  sycl::free(P1, q);\n  sycl::free(P2, q);\n  free(x);\n  free(y);\n\n  return 0;\n}\n"}}
