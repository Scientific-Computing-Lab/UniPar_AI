{"kernel_name": "adam", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <cuda.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\n__global__\nvoid adam (\n        T* __restrict__ p,\n        T* __restrict__ m,\n        T* __restrict__ v,\n  const G* __restrict__ g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n  const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  const size_t totThreads = gridDim.x*blockDim.x;\n\n  for (size_t j = i; j < vector_size; j += totThreads) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-powf(b1, t));\n      float v_corrected = v[j] / (1.f-powf(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sqrtf(v_corrected + eps);\n      else \n\n        denom = sqrtf(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  float *d_m, *d_v, *d_g, *d_p;\n\n  cudaMalloc((void**)&d_m, size_bytes);\n  cudaMemcpy(d_m, m, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_v, size_bytes);\n  cudaMemcpy(d_v, v, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_g, size_bytes);\n  cudaMemcpy(d_g, g, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_p, size_bytes);\n  cudaMemcpy(d_p, p, size_bytes, cudaMemcpyHostToDevice);\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-8f;\n  const float grad_scale = 256.f;\n\n  const int threadsPerBlock = 256;\n  const dim3 grids ((vector_size+threadsPerBlock-1) / threadsPerBlock);\n  const dim3 blocks (threadsPerBlock);\n\n  adamMode_t mode = ADAM_MODE_0;\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    adam<float, float><<<grids, blocks>>> (\n      d_p, d_m, d_v, d_g,\n      beta1, beta2,\n      eps,\n      grad_scale,\n      step_size,\n      time_step,\n      vector_size,\n      mode,\n      decay);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n\n  cudaMemcpy(p, d_p, size_bytes, cudaMemcpyDeviceToHost); \n\n  cudaFree(d_p);\n  cudaFree(d_m);\n  cudaFree(d_v);\n  cudaFree(d_g);\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "adam", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <hip/hip_runtime.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\n__global__\nvoid adam (\n        T* __restrict__ p,\n        T* __restrict__ m,\n        T* __restrict__ v,\n  const G* __restrict__ g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n  const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  const size_t totThreads = gridDim.x*blockDim.x;\n\n  for (size_t j = i; j < vector_size; j += totThreads) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-powf(b1, t));\n      float v_corrected = v[j] / (1.f-powf(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sqrtf(v_corrected + eps);\n      else \n\n        denom = sqrtf(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  float *d_m, *d_v, *d_g, *d_p;\n\n  hipMalloc((void**)&d_m, size_bytes);\n  hipMemcpy(d_m, m, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_v, size_bytes);\n  hipMemcpy(d_v, v, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_g, size_bytes);\n  hipMemcpy(d_g, g, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_p, size_bytes);\n  hipMemcpy(d_p, p, size_bytes, hipMemcpyHostToDevice);\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-8f;\n  const float grad_scale = 256.f;\n\n  const int threadsPerBlock = 256;\n  const dim3 grids ((vector_size+threadsPerBlock-1) / threadsPerBlock);\n  const dim3 blocks (threadsPerBlock);\n\n  adamMode_t mode = ADAM_MODE_0;\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    adam<float, float><<<grids, blocks>>> (\n      d_p, d_m, d_v, d_g,\n      beta1, beta2,\n      eps,\n      grad_scale,\n      step_size,\n      time_step,\n      vector_size,\n      mode,\n      decay);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n\n  hipMemcpy(p, d_p, size_bytes, hipMemcpyDeviceToHost); \n\n  hipFree(d_p);\n  hipFree(d_m);\n  hipFree(d_v);\n  hipFree(d_g);\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "adam", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <omp.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\ninline void adam (\n        T* __restrict p,\n        T* __restrict m,\n        T* __restrict v,\n  const G* __restrict g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (size_t j = 0; j < vector_size; j++) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-powf(b1, t));\n      float v_corrected = v[j] / (1.f-powf(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sqrtf(v_corrected + eps);\n      else \n\n        denom = sqrtf(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-10f;\n  const float grad_scale = 256.f;\n\n  adamMode_t mode = ADAM_MODE_0;\n\n  #pragma omp target data map (to: m[0:vector_size], v[0:vector_size], g[0:vector_size]) \\\n                          map (tofrom: p[0:vector_size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      adam<float, float>(\n        p, m, v, g,\n        beta1, beta2,\n        eps,\n        grad_scale,\n        step_size,\n        time_step,\n        vector_size,\n        mode,\n        decay);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "adam", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\ninline void adam (\n        T* __restrict p,\n        T* __restrict m,\n        T* __restrict v,\n  const G* __restrict g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n    for (size_t j = 0; j < vector_size; j++) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-powf(b1, t));\n      float v_corrected = v[j] / (1.f-powf(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sqrtf(v_corrected + eps);\n      else \n\n        denom = sqrtf(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-10f;\n  const float grad_scale = 256.f;\n\n  adamMode_t mode = ADAM_MODE_0;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      adam<float, float>(\n        p, m, v, g,\n        beta1, beta2,\n        eps,\n        grad_scale,\n        step_size,\n        time_step,\n        vector_size,\n        mode,\n        decay);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}"}}
{"kernel_name": "adam", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <sycl/sycl.hpp>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\nvoid adam (\n  sycl::nd_item<1> &item,\n        T* __restrict p,\n        T* __restrict m,\n        T* __restrict v,\n  const G* __restrict g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n  const int i = item.get_global_id(0);\n  const int totThreads = item.get_group_range(0) * item.get_local_range(0);\n\n  for (size_t j = i; j < vector_size; j += totThreads) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-sycl::pown(b1, t));\n      float v_corrected = v[j] / (1.f-sycl::pown(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sycl::sqrt(v_corrected + eps);\n      else \n\n        denom = sycl::sqrt(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  float *d_m, *d_v, *d_g, *d_p;\n\n  d_m = sycl::malloc_device<float>(vector_size, q);\n  q.memcpy(d_m, m, size_bytes);\n\n  d_v = sycl::malloc_device<float>(vector_size, q);\n  q.memcpy(d_v, v, size_bytes);\n\n  d_g = sycl::malloc_device<float>(vector_size, q);\n  q.memcpy(d_g, g, size_bytes);\n\n  d_p = sycl::malloc_device<float>(vector_size, q);\n  q.memcpy(d_p, p, size_bytes);\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-10f;\n  const float grad_scale = 256.f;\n\n  const int threadsPerBlock = 256;\n  sycl::range<1> gws ((vector_size+threadsPerBlock-1) / threadsPerBlock * threadsPerBlock);\n  sycl::range<1> lws (threadsPerBlock);\n\n  adamMode_t mode = ADAM_MODE_0;\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class kernel>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        adam<float, float>(\n          item,\n          d_p, d_m, d_v, d_g,\n          beta1, beta2,\n          eps,\n          grad_scale,\n          step_size,\n          time_step,\n          vector_size,\n          mode,\n          decay);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n\n  q.memcpy(p, d_p, size_bytes).wait();\n\n  sycl::free(d_p, q);\n  sycl::free(d_m, q);\n  sycl::free(d_v, q);\n  sycl::free(d_g, q);\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "attention", "parallel_api": "cuda", "code": {"main.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"kernels.h\"\n#include \"reference.h\"\n\nfloat* attention_device(const float* key, const float* value, const float* query,\n                        const int n, const int d, const int impl_num, const int repeat)\n{\n  \n\n  float *d_key;\n  cudaMalloc((void**)&d_key, n * d * sizeof(float));\n  cudaMemcpy(d_key, key, n * d * sizeof(float), cudaMemcpyHostToDevice);\n\n  float *d_value;\n  cudaMalloc((void**)&d_value, n * d * sizeof(float));\n  cudaMemcpy(d_value, value, n * d * sizeof(float), cudaMemcpyHostToDevice);\n\n  float *d_query;\n  cudaMalloc((void**)&d_query, d * sizeof(float));\n  cudaMemcpy(d_query, query, d * sizeof(float), cudaMemcpyHostToDevice);\n\n  \n\n  float *d_dot_product;\n  cudaMalloc((void**)&d_dot_product, n * sizeof(float));\n\n  float *d_exp_sum;\n  cudaMalloc((void**)&d_exp_sum, sizeof(float));\n\n  \n\n  float *output = (float*) malloc (d * sizeof(float));\n  float *d_output;\n  cudaMalloc((void**)&d_output, d * sizeof(float));\n\n  cudaDeviceSynchronize();\n\n  if (impl_num == 2) {\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      cudaMemset(d_exp_sum, 0, 4);\n      kernel1_warpReduce<<<(n+7)/8, 256>>>(d_key, d_query, d_dot_product, d_exp_sum, n, d);\n      kernel2_blockReduce<<<d, 256>>>(d_exp_sum, d_dot_product, d_value, d_output, n, d);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  else if (impl_num == 1) {\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      cudaMemset(d_exp_sum, 0, 4);\n      kernel1_blockReduce<<<n, 256>>>(d_key, d_query, d_dot_product, d_exp_sum, n, d);\n      kernel2_blockReduce<<<d, 256>>>(d_exp_sum, d_dot_product, d_value, d_output, n, d);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  else {\n    float *d_score;\n    cudaMalloc((void**)&d_score, n * sizeof(float));\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      cudaMemset(d_exp_sum, 0, 4);\n      kernel1<<<(n+255)/256, 256>>>(d_key, d_query, d_dot_product, d_exp_sum, n, d);\n      kernel2<<<(n+255)/256, 256>>>(d_exp_sum, d_dot_product, d_score, n);\n      kernel3<<<(d+255)/256, 256>>>(d_score, d_value, d_output, n, d);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n    cudaFree(d_score);\n  }\n\n  cudaMemcpy(output, d_output, d * sizeof(float), cudaMemcpyDeviceToHost);\n  cudaFree(d_value);\n  cudaFree(d_output);\n  cudaFree(d_key);\n  cudaFree(d_dot_product);\n  cudaFree(d_exp_sum);\n  return output;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <rows> <columns> <implementation> <repeat>\\n\", argv[0]);\n    printf(\"implementation 0: naive\\n\");\n    printf(\"implementation 1: fused kernels with warp reduce\\n\");\n    printf(\"implementation 2: fused kernels with block reduce\\n\");\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int d = atoi(argv[2]);\n  const int k = atoi(argv[3]);\n  const int r = atoi(argv[4]);\n\n  \n\n  float* key = (float*) malloc (n * d * sizeof(float));\n  float* value = (float*) malloc (n * d * sizeof(float));\n  float* query = (float*) malloc (d * sizeof(float));\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(-0.01f, 0.01f);\n\n  for (int i = 0; i < n * d; i++) {\n    key[i] = dist(gen);\n    value[i] = dist(gen);\n    query[i % d] = dist(gen);\n  }\n\n  float* hout = attention_host(key, value, query, n, d);\n\n  float* dout = attention_device(key, value, query, n, d, k, r);\n\n  float rmse = 0;\n  for (int i = 0; i < d; i++) {\n    rmse += (hout[i] - dout[i]) * (hout[i] - dout[i]);\n  }\n  printf(\"RMSE = %f\\n\", sqrtf(rmse / d));\n\n  free(key);\n  free(value);\n  free(query);\n  free(dout);\n  free(hout);\n  return 0;\n}\n"}}
{"kernel_name": "attention", "parallel_api": "hip", "code": {"main.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"kernels.h\"\n#include \"reference.h\"\n\nfloat* attention_device(const float* key, const float* value, const float* query,\n                        const int n, const int d, const int impl_num, const int repeat)\n{\n  \n\n  float *d_key;\n  hipMalloc((void**)&d_key, n * d * sizeof(float));\n  hipMemcpy(d_key, key, n * d * sizeof(float), hipMemcpyHostToDevice);\n\n  float *d_value;\n  hipMalloc((void**)&d_value, n * d * sizeof(float));\n  hipMemcpy(d_value, value, n * d * sizeof(float), hipMemcpyHostToDevice);\n\n  float *d_query;\n  hipMalloc((void**)&d_query, d * sizeof(float));\n  hipMemcpy(d_query, query, d * sizeof(float), hipMemcpyHostToDevice);\n\n  \n\n  float *d_dot_product;\n  hipMalloc((void**)&d_dot_product, n * sizeof(float));\n\n  float *d_exp_sum;\n  hipMalloc((void**)&d_exp_sum, sizeof(float));\n\n  \n\n  float *output = (float*) malloc (d * sizeof(float));\n  float *d_output;\n  hipMalloc((void**)&d_output, d * sizeof(float));\n\n  hipDeviceSynchronize();\n\n  if (impl_num == 2) {\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      hipMemset(d_exp_sum, 0, 4);\n      kernel1_warpReduce<<<(n+7)/8, 256>>>(d_key, d_query, d_dot_product, d_exp_sum, n, d);\n      kernel2_blockReduce<<<d, 256>>>(d_exp_sum, d_dot_product, d_value, d_output, n, d);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  else if (impl_num == 1) {\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      hipMemset(d_exp_sum, 0, 4);\n      kernel1_blockReduce<<<n, 256>>>(d_key, d_query, d_dot_product, d_exp_sum, n, d);\n      kernel2_blockReduce<<<d, 256>>>(d_exp_sum, d_dot_product, d_value, d_output, n, d);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  else {\n    float *d_score;\n    hipMalloc((void**)&d_score, n * sizeof(float));\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      hipMemset(d_exp_sum, 0, 4);\n      kernel1<<<(n+255)/256, 256>>>(d_key, d_query, d_dot_product, d_exp_sum, n, d);\n      kernel2<<<(n+255)/256, 256>>>(d_exp_sum, d_dot_product, d_score, n);\n      kernel3<<<(d+255)/256, 256>>>(d_score, d_value, d_output, n, d);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n    hipFree(d_score);\n  }\n\n  hipMemcpy(output, d_output, d * sizeof(float), hipMemcpyDeviceToHost);\n  hipFree(d_value);\n  hipFree(d_output);\n  hipFree(d_key);\n  hipFree(d_dot_product);\n  hipFree(d_exp_sum);\n  return output;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <rows> <columns> <implementation> <repeat>\\n\", argv[0]);\n    printf(\"implementation 0: naive\\n\");\n    printf(\"implementation 1: fused kernels with warp reduce\\n\");\n    printf(\"implementation 2: fused kernels with block reduce\\n\");\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int d = atoi(argv[2]);\n  const int k = atoi(argv[3]);\n  const int r = atoi(argv[4]);\n\n  \n\n  float* key = (float*) malloc (n * d * sizeof(float));\n  float* value = (float*) malloc (n * d * sizeof(float));\n  float* query = (float*) malloc (d * sizeof(float));\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(-0.01f, 0.01f);\n\n  for (int i = 0; i < n * d; i++) {\n    key[i] = dist(gen);\n    value[i] = dist(gen);\n    query[i % d] = dist(gen);\n  }\n\n  float* hout = attention_host(key, value, query, n, d);\n\n  float* dout = attention_device(key, value, query, n, d, k, r);\n\n  float rmse = 0;\n  for (int i = 0; i < d; i++) {\n    rmse += (hout[i] - dout[i]) * (hout[i] - dout[i]);\n  }\n  printf(\"RMSE = %f\\n\", sqrtf(rmse / d));\n\n  free(key);\n  free(value);\n  free(query);\n  free(dout);\n  free(hout);\n  return 0;\n}\n"}}
{"kernel_name": "attention", "parallel_api": "omp", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"reference.h\"\n\nfloat* attention_device(const float* key, const float* value, const float* query,\n                        const int n, const int d, const int repeat) \n{\n  \n\n  float* dot_product = (float*) malloc (n * sizeof(float));\n  float* score = (float*) malloc (n * sizeof(float));\n  float* exp_sum = (float*) malloc (sizeof(float));\n\n  \n\n  float* output = (float*) malloc (d * sizeof(float));\n\n  #pragma omp target data map(to: key[0:n*d], value[0:n*d], query[0:d]), \\\n                          map(alloc: dot_product[0:n], score[0:n], exp_sum[0:1]), \\\n                          map(from: output[0:d])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      exp_sum[0] = 0;\n      #pragma omp target update to (exp_sum[0:1])\n\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (int i = 0; i < n; i++) {\n        float sum = 0;\n        for (int j = 0; j < d; j++)\n           sum += key[i * d + j] * query[j];\n        dot_product[i] = sum;\n        #pragma omp atomic update  \n        exp_sum[0] += expf(sum);\n      }\n\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (int i = 0; i < n; i++)\n        score[i] = expf(dot_product[i]) / exp_sum[0];\n      \n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (int j = 0; j < d; j++) {\n        float sum = 0;\n        for (int i = 0; i < n; i++)\n           sum += score[i] * value[i * d + j];\n        output[j] = sum;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  free(dot_product);\n  free(score);\n  free(exp_sum);\n  return output;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <rows> <columns> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int d = atoi(argv[2]);\n  const int r = atoi(argv[3]);\n\n  \n\n  float* key = (float*) malloc (n * d * sizeof(float));\n  float* value = (float*) malloc (n * d * sizeof(float));\n  float* query = (float*) malloc (d * sizeof(float));\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(-0.01f, 0.01f);\n\n  for (int i = 0; i < n * d; i++) {\n    key[i] = dist(gen);\n    value[i] = dist(gen);\n    query[i % d] = dist(gen);\n  }\n\n  float* hout = attention_host(key, value, query, n, d);\n\n  float* dout = attention_device(key, value, query, n, d, r);\n\n  float rmse = 0;\n  for (int i = 0; i < d; i++) \n    rmse += (hout[i] - dout[i]) * (hout[i] - dout[i]);\n  printf(\"RMSE = %f\\n\", sqrtf(rmse / d));\n\n  free(key);\n  free(value);\n  free(query);\n  free(dout);\n  free(hout);\n  return 0;\n}\n"}}
{"kernel_name": "attention", "parallel_api": "serial", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\nfloat* attention_device(const float* key, const float* value, const float* query,\n                        const int n, const int d, const int repeat) \n{\n  \n\n  float* dot_product = (float*) malloc (n * sizeof(float));\n  float* score = (float*) malloc (n * sizeof(float));\n  float* exp_sum = (float*) malloc (sizeof(float));\n\n  \n\n  float* output = (float*) malloc (d * sizeof(float));\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      exp_sum[0] = 0;\n      \n            for (int i = 0; i < n; i++) {\n        float sum = 0;\n        for (int j = 0; j < d; j++)\n           sum += key[i * d + j] * query[j];\n        dot_product[i] = sum;\n                exp_sum[0] += expf(sum);\n      }\n\n            for (int i = 0; i < n; i++)\n        score[i] = expf(dot_product[i]) / exp_sum[0];\n      \n            for (int j = 0; j < d; j++) {\n        float sum = 0;\n        for (int i = 0; i < n; i++)\n           sum += score[i] * value[i * d + j];\n        output[j] = sum;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  free(dot_product);\n  free(score);\n  free(exp_sum);\n  return output;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <rows> <columns> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int d = atoi(argv[2]);\n  const int r = atoi(argv[3]);\n\n  \n\n  float* key = (float*) malloc (n * d * sizeof(float));\n  float* value = (float*) malloc (n * d * sizeof(float));\n  float* query = (float*) malloc (d * sizeof(float));\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(-0.01f, 0.01f);\n\n  for (int i = 0; i < n * d; i++) {\n    key[i] = dist(gen);\n    value[i] = dist(gen);\n    query[i % d] = dist(gen);\n  }\n\n  float* hout = attention_host(key, value, query, n, d);\n\n  float* dout = attention_device(key, value, query, n, d, r);\n\n  float rmse = 0;\n  for (int i = 0; i < d; i++) \n    rmse += (hout[i] - dout[i]) * (hout[i] - dout[i]);\n  printf(\"RMSE = %f\\n\", sqrtf(rmse / d));\n\n  free(key);\n  free(value);\n  free(query);\n  free(dout);\n  free(hout);\n  return 0;\n}"}}
{"kernel_name": "attention", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n#include \"reference.h\"\n\nfloat* attention_device(const float* key, const float* value, const float* query,\n                        const int n, const int d, const int impl_num, const int repeat)\n{\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  float *d_key;\n  d_key = sycl::malloc_device<float>(n * d, q);\n  q.memcpy(d_key, key, n * d * sizeof(float)).wait();\n\n  float *d_value;\n  d_value = sycl::malloc_device<float>(n * d, q);\n  q.memcpy(d_value, value, n * d * sizeof(float)).wait();\n\n  float *d_query;\n  d_query = sycl::malloc_device<float>(d, q);\n  q.memcpy(d_query, query, d * sizeof(float)).wait();\n\n  \n\n  float *d_dot_product;\n  d_dot_product = sycl::malloc_device<float>(n, q);\n\n  float *d_exp_sum;\n  d_exp_sum = sycl::malloc_device<float>(1, q);\n\n  \n\n  float *output = (float*) malloc (d * sizeof(float));\n  float *d_output;\n  d_output = sycl::malloc_device<float>(d, q);\n\n  q.wait();\n\n  if (impl_num == 2) {\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      q.memset(d_exp_sum, 0, 4);\n      q.parallel_for(sycl::nd_range<1>(sycl::range<1>((n+7)/8) *\n                                       sycl::range<1>(256),\n                                       sycl::range<1>(256)),\n                         [=](sycl::nd_item<1> item) [[sycl::reqd_sub_group_size(32)]] {\n                           kernel1_warpReduce(d_key, d_query, d_dot_product,\n                                              d_exp_sum, n, d, item);\n                         });\n      q.submit([&](sycl::handler &cgh) {\n        cgh.parallel_for(sycl::nd_range<1>(sycl::range<1>(d) *\n                                           sycl::range<1>(256),\n                                           sycl::range<1>(256)),\n                         [=](sycl::nd_item<1> item) {\n                           kernel2_blockReduce(d_exp_sum, d_dot_product,\n                                               d_value, d_output, n, d,\n                                               item);\n                         });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  else if (impl_num == 1) {\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      q.memset(d_exp_sum, 0, 4);\n      q.submit([&](sycl::handler &cgh) {\n        cgh.parallel_for(sycl::nd_range<1>(sycl::range<1>(n) *\n                                           sycl::range<1>(256),\n                                           sycl::range<1>(256)),\n                         [=](sycl::nd_item<1> item) {\n                           kernel1_blockReduce(d_key, d_query, d_dot_product,\n                                               d_exp_sum, n, d, item);\n                         });\n      });\n      q.submit([&](sycl::handler &cgh) {\n        cgh.parallel_for(sycl::nd_range<1>(sycl::range<1>(d) *\n                                           sycl::range<1>(256),\n                                           sycl::range<1>(256)),\n                         [=](sycl::nd_item<1> item) {\n                           kernel2_blockReduce(d_exp_sum, d_dot_product,\n                                               d_value, d_output, n, d,\n                                               item);\n                         });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  else {\n    float *d_score;\n    d_score = sycl::malloc_device<float>(n, q);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int k = 0; k < repeat; k++) {\n      q.memset(d_exp_sum, 0, 4);\n      q.parallel_for(\n          sycl::nd_range<1>(sycl::range<1>((n + 255) / 256) *\n                            sycl::range<1>(256),\n                            sycl::range<1>(256)),\n          [=](sycl::nd_item<1> item) {\n            kernel1(d_key, d_query, d_dot_product, d_exp_sum, n, d, item);\n          });\n      q.parallel_for(\n          sycl::nd_range<1>(sycl::range<1>((n + 255) / 256) *\n                            sycl::range<1>(256),\n                            sycl::range<1>(256)),\n          [=](sycl::nd_item<1> item) {\n            kernel2(d_exp_sum, d_dot_product, d_score, n, item);\n          });\n      q.parallel_for(\n          sycl::nd_range<1>(sycl::range<1>((d + 255) / 256) *\n                            sycl::range<1>(256),\n                            sycl::range<1>(256)),\n          [=](sycl::nd_item<1> item) {\n            kernel3(d_score, d_value, d_output, n, d, item);\n          });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of kernels %f (ms)\\n\", time * 1e-6f / repeat);\n    sycl::free(d_score, q);\n  }\n\n  q.memcpy(output, d_output, d * sizeof(float)).wait();\n  sycl::free(d_value, q);\n  sycl::free(d_output, q);\n  sycl::free(d_key, q);\n  sycl::free(d_dot_product, q);\n  sycl::free(d_exp_sum, q);\n  return output;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <rows> <columns> <implementation> <repeat>\\n\", argv[0]);\n    printf(\"implementation 0: naive\\n\");\n    printf(\"implementation 1: fused kernels with warp reduce\\n\");\n    printf(\"implementation 2: fused kernels with block reduce\\n\");\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int d = atoi(argv[2]);\n  const int k = atoi(argv[3]);\n  const int r = atoi(argv[4]);\n\n  \n\n  float* key = (float*) malloc (n * d * sizeof(float));\n  float* value = (float*) malloc (n * d * sizeof(float));\n  float* query = (float*) malloc (d * sizeof(float));\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(-0.01f, 0.01f);\n\n  for (int i = 0; i < n * d; i++) {\n    key[i] = dist(gen);\n    value[i] = dist(gen);\n    query[i % d] = dist(gen);\n  }\n\n  float* hout = attention_host(key, value, query, n, d);\n\n  float* dout = attention_device(key, value, query, n, d, k, r);\n\n  float rmse = 0;\n  for (int i = 0; i < d; i++) {\n    rmse += (hout[i] - dout[i]) * (hout[i] - dout[i]);\n  }\n  printf(\"RMSE = %f\\n\", sqrtf(rmse / d));\n\n  free(key);\n  free(value);\n  free(query);\n  free(dout);\n  free(hout);\n  return 0;\n}\n"}}
{"kernel_name": "channelShuffle", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n#define GridDimMaxY 65536\n\ntemplate <typename T, bool kNFirst>\n__global__ void ChannelShuffleNCHWKernel(\n    const int G,\n    const int K,\n    const int HxW,\n    const T* X,\n          T* Y)\n{\n  const int C = G * K;\n  const int n = kNFirst ? blockIdx.x : blockIdx.y;\n  const int s = kNFirst ? blockIdx.y : blockIdx.x;\n  const int g = blockIdx.z % G;\n  const int k = blockIdx.z / G;\n  const int offset = s * NUM_THREADS + threadIdx.x;\n  if (offset < HxW) {\n    Y[(n * C + blockIdx.z) * HxW + offset] =\n        __ldg(X + (n * C + g * K + k) * HxW + offset);\n  }\n}\n\ntemplate <typename T, int kSharedSize>\n__global__ void\nChannelShuffleNHWCKernel(const int G, const int K, const T* X, T* Y)\n{\n  __shared__ T sdata[kSharedSize];\n  const int C = G * K;\n  const int offset = blockIdx.x * C;\n  for (int i = threadIdx.x; i < C; i += blockDim.x) {\n    sdata[i] = __ldg(X + offset + i);\n  }\n  __syncthreads();\n  for (int i = threadIdx.x; i < C; i += blockDim.x) {\n    const int g = i % G;\n    const int k = i / G;\n    Y[offset + i] = sdata[g * K + k];\n  }\n}\n\ntemplate <typename T>\nbool ChannelShuffleNCHW (T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n  const int S = (HxW + NUM_THREADS - 1) / NUM_THREADS;\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (N <= GridDimMaxY) {\n    const dim3 dim_grid(S, N, C);\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNCHWKernel<float, false>\n        <<<dim_grid, NUM_THREADS>>>(G, K, HxW, X, Y);\n  } else {\n    const dim3 dim_grid(N, S, C);\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNCHWKernel<float, true>\n        <<<dim_grid, NUM_THREADS>>>(G, K, HxW, X, Y);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\ntemplate <typename T>\nbool ChannelShuffleNHWC (T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n  const int outer_size = N * HxW;\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (C <= 32) {\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNHWCKernel<float, 32>\n        <<<outer_size, NUM_THREADS>>>(G, K, X, Y);\n  } else if (C <= 128) {\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNHWCKernel<float, 128>\n        <<<outer_size, NUM_THREADS>>>(G, K, X, Y);\n  } else if (C <= 512) {\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNHWCKernel<float, 512>\n        <<<outer_size, NUM_THREADS>>>(G, K, X, Y);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <group size> <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int G = atoi(argv[1]);\n  const int W = atoi(argv[2]);\n  const int H = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  long time;\n  float *h_X, *h_Y, *h_Y_ref;\n  float *d_X, *d_Y;\n  int error;\n\n  \n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      const int numel = N * C * W * H; \n\n      size_t data_size_bytes = numel * sizeof(float);\n\n      auto errorX = cudaMalloc((void**)&d_X, data_size_bytes);\n      auto errorY = cudaMalloc((void**)&d_Y, data_size_bytes);\n      if (errorX != cudaSuccess || errorY != cudaSuccess) {\n        if (errorX == cudaSuccess) cudaFree(d_X);\n        if (errorY == cudaSuccess) cudaFree(d_Y);\n        printf(\"Device memory allocation failed. Exit\\n\");\n        goto end;\n      }\n\n      h_X = (float*) malloc(data_size_bytes);\n      for (int i = 0; i < numel; i++) h_X[i] = (float) i / numel;\n\n      h_Y = (float*) malloc(data_size_bytes);\n      h_Y_ref = (float*) malloc(data_size_bytes);\n\n      cudaMemcpy(d_X, h_X, data_size_bytes, cudaMemcpyHostToDevice);\n\n      ChannelShuffleNHWC (d_X, N, C, G, numel, d_Y, time, repeat);\n      ChannelShuffleNHWC_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n      cudaMemcpy(h_Y, d_Y, data_size_bytes, cudaMemcpyDeviceToHost);\n      error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n      if (error)\n        printf(\"Failed to pass channel shuffle (NHWC) check\\n\");\n      else\n        printf(\"Average time of channel shuffle (NHWC): %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n      ChannelShuffleNCHW (d_X, N, C, G, numel, d_Y, time, repeat);\n      ChannelShuffleNCHW_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n      cudaMemcpy(h_Y, d_Y, data_size_bytes, cudaMemcpyDeviceToHost);\n      error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n      if (error)\n        printf(\"Failed to pass channel shuffle (NCHW) check\\n\");\n      else\n        printf(\"Average time of channel shuffle (NCHW): %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n      cudaFree(d_X);\n      cudaFree(d_Y);\n      free(h_X);\n      free(h_Y);\n      free(h_Y_ref);\n    }\n  }\n\n  end: return 0;\n}\n"}}
{"kernel_name": "channelShuffle", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n#define GridDimMaxY 65536\n\ntemplate <typename T, bool kNFirst>\n__global__ void ChannelShuffleNCHWKernel(\n    const int G,\n    const int K,\n    const int HxW,\n    const T* X,\n          T* Y)\n{\n  const int C = G * K;\n  const int n = kNFirst ? blockIdx.x : blockIdx.y;\n  const int s = kNFirst ? blockIdx.y : blockIdx.x;\n  const int g = blockIdx.z % G;\n  const int k = blockIdx.z / G;\n  const int offset = s * NUM_THREADS + threadIdx.x;\n  if (offset < HxW) {\n    Y[(n * C + blockIdx.z) * HxW + offset] =\n        __ldg(X + (n * C + g * K + k) * HxW + offset);\n  }\n}\n\ntemplate <typename T, int kSharedSize>\n__global__ void\nChannelShuffleNHWCKernel(const int G, const int K, const T* X, T* Y)\n{\n  __shared__ T sdata[kSharedSize];\n  const int C = G * K;\n  const int offset = blockIdx.x * C;\n  for (int i = threadIdx.x; i < C; i += blockDim.x) {\n    sdata[i] = __ldg(X + offset + i);\n  }\n  __syncthreads();\n  for (int i = threadIdx.x; i < C; i += blockDim.x) {\n    const int g = i % G;\n    const int k = i / G;\n    Y[offset + i] = sdata[g * K + k];\n  }\n}\n\ntemplate <typename T>\nbool ChannelShuffleNCHW (T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n  const int S = (HxW + NUM_THREADS - 1) / NUM_THREADS;\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (N <= GridDimMaxY) {\n    const dim3 dim_grid(S, N, C);\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNCHWKernel<float, false>\n        <<<dim_grid, NUM_THREADS>>>(G, K, HxW, X, Y);\n  } else {\n    const dim3 dim_grid(N, S, C);\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNCHWKernel<float, true>\n        <<<dim_grid, NUM_THREADS>>>(G, K, HxW, X, Y);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\ntemplate <typename T>\nbool ChannelShuffleNHWC (T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n  const int outer_size = N * HxW;\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (C <= 32) {\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNHWCKernel<float, 32>\n        <<<outer_size, NUM_THREADS>>>(G, K, X, Y);\n  } else if (C <= 128) {\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNHWCKernel<float, 128>\n        <<<outer_size, NUM_THREADS>>>(G, K, X, Y);\n  } else if (C <= 512) {\n    for (int i = 0; i < repeat; i++)\n      ChannelShuffleNHWCKernel<float, 512>\n        <<<outer_size, NUM_THREADS>>>(G, K, X, Y);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <group size> <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int G = atoi(argv[1]);\n  const int W = atoi(argv[2]);\n  const int H = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  long time;\n  float *h_X, *h_Y, *h_Y_ref;\n  float *d_X, *d_Y;\n  int error;\n\n  \n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      const int numel = N * C * W * H; \n\n      size_t data_size_bytes = numel * sizeof(float);\n\n      auto errorX = hipMalloc((void**)&d_X, data_size_bytes);\n      auto errorY = hipMalloc((void**)&d_Y, data_size_bytes);\n      if (errorX != hipSuccess || errorY != hipSuccess) {\n        if (errorX == hipSuccess) hipFree(d_X);\n        if (errorY == hipSuccess) hipFree(d_Y);\n        printf(\"Device memory allocation failed. Exit\\n\");\n        goto end;\n      }\n\n      h_X = (float*) malloc(data_size_bytes);\n      for (int i = 0; i < numel; i++) h_X[i] = (float) i / numel;\n\n      h_Y = (float*) malloc(data_size_bytes);\n      h_Y_ref = (float*) malloc(data_size_bytes);\n\n      hipMemcpy(d_X, h_X, data_size_bytes, hipMemcpyHostToDevice);\n\n      ChannelShuffleNHWC (d_X, N, C, G, numel, d_Y, time, repeat);\n      ChannelShuffleNHWC_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n      hipMemcpy(h_Y, d_Y, data_size_bytes, hipMemcpyDeviceToHost);\n      error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n      if (error)\n        printf(\"Failed to pass channel shuffle (NHWC) check\\n\");\n      else\n        printf(\"Average time of channel shuffle (NHWC): %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n      ChannelShuffleNCHW (d_X, N, C, G, numel, d_Y, time, repeat);\n      ChannelShuffleNCHW_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n      hipMemcpy(h_Y, d_Y, data_size_bytes, hipMemcpyDeviceToHost);\n      error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n      if (error)\n        printf(\"Failed to pass channel shuffle (NCHW) check\\n\");\n      else\n        printf(\"Average time of channel shuffle (NCHW): %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n      hipFree(d_X);\n      hipFree(d_Y);\n      free(h_X);\n      free(h_Y);\n      free(h_Y_ref);\n    }\n  }\n\n  end: return 0;\n}\n"}}
{"kernel_name": "channelShuffle", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n\ntemplate <typename T>\nvoid ChannelShuffleNCHWKernel(\n    const int N,\n    const int G,\n    const int K,\n    const int HxW,\n    const T* X,\n          T* Y)\n{\n  const int C = G * K;\n  #pragma omp target teams distribute parallel for collapse(3) num_threads(NUM_THREADS)\n  for (int n = 0; n < N; n++)\n    for (int c = 0; c < C; c++)\n      for (int s = 0; s < HxW; s++)\n        Y[(n * C + c) * HxW + s] = X[(n * C + (c % G) * K + c / G) * HxW + s];\n}\n\ntemplate <typename T>\nvoid\nChannelShuffleNHWCKernel(const int O, const int G, const int K, const T* X, T* Y)\n{\n  const int C = G * K;\n  #pragma omp target teams distribute parallel for collapse(2) num_threads(NUM_THREADS)\n  for (int o = 0; o < O; o++)\n    for (int i = 0; i < C; i++)\n      Y[o*C + i] = X[o*C + (i % G) * K + i / G];\n}\n\ntemplate <typename T>\nbool ChannelShuffleNCHW (T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelShuffleNCHWKernel<float>(N, G, K, HxW, X, Y);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\ntemplate <typename T>\nbool ChannelShuffleNHWC (T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n  const int O = N * HxW;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelShuffleNHWCKernel<float>(O, G, K, X, Y);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <group size> <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int G = atoi(argv[1]);\n  const int W = atoi(argv[2]);\n  const int H = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  long time;\n  float *h_X, *h_Y, *h_Y_ref;\n  int error;\n\n  \n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      const int numel = N * C * W * H; \n\n      size_t data_size_bytes = numel * sizeof(float);\n\n      h_X = (float*) malloc(data_size_bytes);\n      for (int i = 0; i < numel; i++) h_X[i] = (float) i / numel;\n\n      h_Y = (float*) malloc(data_size_bytes);\n      h_Y_ref = (float*) malloc(data_size_bytes);\n\n      #pragma omp target data map(to: h_X[0:numel]) map(alloc: h_Y[0:numel])\n      {\n        ChannelShuffleNHWC (h_X, N, C, G, numel, h_Y, time, repeat);\n        #pragma omp target update from (h_Y[0:numel])\n        ChannelShuffleNHWC_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n        error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n        if (error)\n          printf(\"Failed to pass channel shuffle (NHWC) check\\n\");\n        else\n          printf(\"Average time of channel shuffle (NHWC): %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n        ChannelShuffleNCHW (h_X, N, C, G, numel, h_Y, time, repeat);\n        #pragma omp target update from (h_Y[0:numel])\n        ChannelShuffleNCHW_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n        error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n        if (error)\n          printf(\"Failed to pass channel shuffle (NCHW) check\\n\");\n        else\n          printf(\"Average time of channel shuffle (NCHW): %f (ms)\\n\", (time * 1e-6f) / repeat);\n      }\n\n      free(h_X);\n      free(h_Y);\n      free(h_Y_ref);\n    }\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "channelShuffle", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n\ntemplate <typename T>\nvoid ChannelShuffleNCHWKernel(\n    const int N,\n    const int G,\n    const int K,\n    const int HxW,\n    const T* X,\n          T* Y)\n{\n  const int C = G * K;\n    for (int n = 0; n < N; n++)\n    for (int c = 0; c < C; c++)\n      for (int s = 0; s < HxW; s++)\n        Y[(n * C + c) * HxW + s] = X[(n * C + (c % G) * K + c / G) * HxW + s];\n}\n\ntemplate <typename T>\nvoid\nChannelShuffleNHWCKernel(const int O, const int G, const int K, const T* X, T* Y)\n{\n  const int C = G * K;\n    for (int o = 0; o < O; o++)\n    for (int i = 0; i < C; i++)\n      Y[o*C + i] = X[o*C + (i % G) * K + i / G];\n}\n\ntemplate <typename T>\nbool ChannelShuffleNCHW (T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelShuffleNCHWKernel<float>(N, G, K, HxW, X, Y);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\ntemplate <typename T>\nbool ChannelShuffleNHWC (T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n  const int O = N * HxW;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelShuffleNHWCKernel<float>(O, G, K, X, Y);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <group size> <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int G = atoi(argv[1]);\n  const int W = atoi(argv[2]);\n  const int H = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  long time;\n  float *h_X, *h_Y, *h_Y_ref;\n  int error;\n\n  \n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      const int numel = N * C * W * H; \n\n      size_t data_size_bytes = numel * sizeof(float);\n\n      h_X = (float*) malloc(data_size_bytes);\n      for (int i = 0; i < numel; i++) h_X[i] = (float) i / numel;\n\n      h_Y = (float*) malloc(data_size_bytes);\n      h_Y_ref = (float*) malloc(data_size_bytes);\n\n            {\n        ChannelShuffleNHWC (h_X, N, C, G, numel, h_Y, time, repeat);\n                ChannelShuffleNHWC_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n        error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n        if (error)\n          printf(\"Failed to pass channel shuffle (NHWC) check\\n\");\n        else\n          printf(\"Average time of channel shuffle (NHWC): %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n        ChannelShuffleNCHW (h_X, N, C, G, numel, h_Y, time, repeat);\n                ChannelShuffleNCHW_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n        error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n        if (error)\n          printf(\"Failed to pass channel shuffle (NCHW) check\\n\");\n        else\n          printf(\"Average time of channel shuffle (NCHW): %f (ms)\\n\", (time * 1e-6f) / repeat);\n      }\n\n      free(h_X);\n      free(h_Y);\n      free(h_Y_ref);\n    }\n  }\n\n  return 0;\n}"}}
{"kernel_name": "channelShuffle", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n#define GridDimMaxY 65536\n\ntemplate <typename T, bool kNFirst>\nvoid ChannelShuffleNCHWKernel(\n    sycl::nd_item<3> &item,\n    const int G,\n    const int K,\n    const int HxW,\n    const T* X,\n          T* Y)\n{\n  int blockIdx_x  = item.get_group(2);\n  int threadIdx_x = item.get_local_id(2);\n  int blockIdx_y  = item.get_group(1);\n  int blockIdx_z  = item.get_group(0);\n\n  const int C = G * K;\n  const int n = kNFirst ? blockIdx_x : blockIdx_y;\n  const int s = kNFirst ? blockIdx_y : blockIdx_x;\n  const int g = blockIdx_z % G;\n  const int k = blockIdx_z / G;\n  const int offset = s * NUM_THREADS + threadIdx_x;\n  if (offset < HxW) {\n    Y[(n * C + blockIdx_z) * HxW + offset] =\n        X[(n * C + g * K + k) * HxW + offset];\n  }\n}\n\ntemplate <typename T, int kSharedSize>\nvoid ChannelShuffleNHWCKernel(\n    sycl::nd_item<1> &item,\n    const int G,\n    const int K,\n    const T* X,\n          T* Y)\n{\n  int blockIdx_x  = item.get_group(0);\n  int blockDim_x  = item.get_local_range(0);\n  int threadIdx_x = item.get_local_id(0);\n\n  auto g = item.get_group();\n  sycl::multi_ptr<T[kSharedSize], sycl::access::address_space::local_space> localPtr =\n    sycl::ext::oneapi::group_local_memory_for_overwrite<T[kSharedSize]>(g);\n\n  T* sdata = *localPtr;\n\n  const int C = G * K;\n  const int offset = blockIdx_x * C;\n  for (int i = threadIdx_x; i < C; i += blockDim_x) {\n    sdata[i] = X[offset + i];\n  }\n\n  sycl::group_barrier(g, sycl::memory_scope::work_group);\n\n  for (int i = threadIdx_x; i < C; i += blockDim_x) {\n    const int g = i % G;\n    const int k = i / G;\n    Y[offset + i] = sdata[g * K + k];\n  }\n}\n\ntemplate <typename T>\nbool ChannelShuffleNCHW (sycl::queue &q, T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n  const int S = (HxW + NUM_THREADS - 1) / NUM_THREADS;\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (N <= GridDimMaxY) {\n    sycl::range<3> gws (C, N, S * NUM_THREADS);\n    sycl::range<3> lws (1, 1, NUM_THREADS);\n\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class shuffle_nchw>(\n          sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n          ChannelShuffleNCHWKernel<float, false>(item, G, K, HxW, X, Y);\n        });\n      });\n    }\n  } else {\n    sycl::range<3> gws (C, S, N * NUM_THREADS);\n    sycl::range<3> lws (1, 1, NUM_THREADS);\n\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class shuffle2_nchw>(\n          sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n          ChannelShuffleNCHWKernel<float, true>(item, G, K, HxW, X, Y);\n        });\n      });\n    }\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\ntemplate <typename T>\nbool ChannelShuffleNHWC (sycl::queue &q, T *X, int N, int C, int G, int numel, T *Y,\n                         long &time, int repeat)\n{\n  if (C % G != 0 || numel < N * C) return false;\n\n  const int K = C / G;\n  const int HxW = numel / (N * C);\n  const int outer_size = N * HxW;\n\n  sycl::range<1> gws (outer_size * NUM_THREADS);\n  sycl::range<1> lws (NUM_THREADS);\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (C <= 32) {\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class shuffle_nhwc_sm32>(\n          sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n          ChannelShuffleNHWCKernel<float, 32>(item, G, K, X, Y);\n        });\n      });\n    }\n  } else if (C <= 128) {\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class shuffle_nhwc_sm128>(\n          sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n          ChannelShuffleNHWCKernel<float, 128>(item, G, K, X, Y);\n        });\n      });\n    }\n  } else if (C <= 512) {\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class shuffle_nhwc_sm512>(\n          sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n          ChannelShuffleNHWCKernel<float, 512>(item, G, K, X, Y);\n        });\n      });\n    }\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  return true;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <group size> <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int G = atoi(argv[1]);\n  const int W = atoi(argv[2]);\n  const int H = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  long time;\n  float *h_X, *h_Y, *h_Y_ref;\n  float *d_X, *d_Y;\n  int error;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n      size_t data_size_bytes = sizeof(float) * N * C * W * H;\n\n      const int numel = N * C * W * H; \n\n\n      d_X = sycl::malloc_device<float>(numel, q);\n      d_Y = sycl::malloc_device<float>(numel, q);\n      if (d_X == nullptr || d_Y == nullptr) {\n        if (d_X != nullptr) sycl::free(d_X, q);\n        if (d_Y != nullptr) sycl::free(d_Y, q);\n        printf(\"Device memory allocation failed. Exit\\n\");\n        goto end;\n      }\n\n      h_X = (float*) malloc(data_size_bytes);\n      for (int i = 0; i < numel; i++) h_X[i] = (float) i / numel;\n\n      h_Y = (float*) malloc(data_size_bytes);\n      h_Y_ref = (float*) malloc(data_size_bytes);\n\n      q.memcpy(d_X, h_X, data_size_bytes);\n\n      ChannelShuffleNHWC (q, d_X, N, C, G, numel, d_Y, time, repeat);\n      ChannelShuffleNHWC_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n      q.memcpy(h_Y, d_Y, data_size_bytes).wait();\n      error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n      if (error)\n        printf(\"Failed to pass channel shuffle (NHWC) check\\n\");\n      else\n        printf(\"Average time of channel shuffle (NHWC): %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n      ChannelShuffleNCHW (q, d_X, N, C, G, numel, d_Y, time, repeat);\n      ChannelShuffleNCHW_cpu (h_X, N, C, G, numel, h_Y_ref, time, repeat);\n      q.memcpy(h_Y, d_Y, data_size_bytes).wait();\n      error = memcmp(h_Y, h_Y_ref, data_size_bytes);\n      if (error)\n        printf(\"Failed to pass channel shuffle (NCHW) check\\n\");\n      else\n        printf(\"Average time of channel shuffle (NCHW): %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n      sycl::free(d_X, q);\n      sycl::free(d_Y, q);\n      free(h_X);\n      free(h_Y);\n      free(h_Y_ref);\n    }\n  }\n\n  end: return 0;\n}\n"}}
{"kernel_name": "channelSum", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include <cub/cub.cuh>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n\n\n\ntypedef int scalar_t;\n\ntemplate <typename T>\nusing BlockReduce1D = cub::BlockReduce<T, NUM_THREADS>;\n\ntemplate <typename T, int kBlockDimX, int kBlockDimY>\nusing BlockReduce2D = cub::BlockReduce<T,\n                                       kBlockDimX,\n                                       cub::BLOCK_REDUCE_WARP_REDUCTIONS,\n                                       kBlockDimY>;\n\n#define DISPATCH_REDUCE_KERNEL_BY_2D_BLOCK_WITH_TYPE(                      \\\n    size, Func, T, grid_dim, stream, ...)                                  \\\n  do {                                                                     \\\n    if (size >= 128) {                                                     \\\n      Func<T, 1, 128><<<grid_dim, dim3(1, 128), 0, stream>>>(__VA_ARGS__); \\\n    } else if (size >= 64) {                                               \\\n      Func<T, 2, 64><<<grid_dim, dim3(2, 64), 0, stream>>>(__VA_ARGS__);   \\\n    } else if (size >= 32) {                                               \\\n      Func<T, 4, 32><<<grid_dim, dim3(4, 32), 0, stream>>>(__VA_ARGS__);   \\\n    } else {                                                               \\\n      Func<T, 8, 16><<<grid_dim, dim3(8, 16), 0, stream>>>(__VA_ARGS__);   \\\n    }                                                                      \\\n  } while (false)\n\n\ntemplate <typename T, int kBlockDimX, int kBlockDimY>\n__global__\nvoid ChannelSumNCHW(\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict__ sum,\n    T*__restrict__ sumsq)\n{\n  __shared__\n  typename BlockReduce2D<T, kBlockDimX, kBlockDimY>::TempStorage m_storage;\n\n  __shared__\n  typename BlockReduce2D<T, kBlockDimX, kBlockDimY>::TempStorage v_storage;\n\n  T m_val = 0;\n  T v_val = 0;\n\n  const int c = blockIdx.x;\n\n  \n\n  for (int n = threadIdx.x; n < N; n += blockDim.x) {\n    for (int hw = threadIdx.y; hw < HxW; hw += blockDim.y) {\n      const int index = (n * C + c) * HxW + hw;\n      m_val += __ldg(X + index);\n      v_val += __ldg(X + index) * __ldg(X + index);\n    }\n  }\n  m_val = BlockReduce2D<T, kBlockDimX, kBlockDimY>(m_storage).Sum(m_val);\n  v_val = BlockReduce2D<T, kBlockDimX, kBlockDimY>(v_storage).Sum(v_val);\n\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\ntemplate <typename T>\n__global__\nvoid ChannelSumNHWC(\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict__ sum,\n    T*__restrict__ sumsq)\n{\n  __shared__ typename BlockReduce1D<T>::TempStorage m_storage;\n  __shared__ typename BlockReduce1D<T>::TempStorage v_storage;\n  const int inner_size = N * HxW;\n  const int c = blockIdx.x;\n  T m_val = 0;\n  T v_val = 0;\n  for (int i = threadIdx.x; i < inner_size; i += blockDim.x) {\n    const int index = i * C + c;\n    m_val += __ldg(X + index);\n    v_val += __ldg(X + index) * __ldg(X + index);\n  }\n  m_val = BlockReduce1D<T>(m_storage).Sum(m_val);\n  v_val = BlockReduce1D<T>(v_storage).Sum(v_val);\n  if (threadIdx.x == 0) {\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\nvoid ComputeChannelSumNCHW (\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    DISPATCH_REDUCE_KERNEL_BY_2D_BLOCK_WITH_TYPE(\n      HxW,\n      ChannelSumNCHW,\n      scalar_t,\n      C,\n      0,\n      N,\n      C,\n      HxW,\n      X,\n      sum,\n      sumsq);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nvoid ComputeChannelSumNHWC (\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelSumNHWC<scalar_t> <<<C, NUM_THREADS>>>(N, C, HxW, X, sum, sumsq);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int W = atoi(argv[1]);\n  const int H = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  long time;\n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      int numel = N * C * W * H; \n\n\n      size_t data_size_bytes = numel * sizeof(scalar_t);\n      size_t output_size_bytes = C * sizeof(scalar_t);\n\n      scalar_t *h_X = (scalar_t*) malloc (data_size_bytes);\n      scalar_t *h_sum = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *h_sumsq = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *r_sum = (scalar_t*) malloc (output_size_bytes);\n\n      srand(numel);\n      for (int i = 0; i < numel; i++) h_X[i] = rand() % 256;\n\n      scalar_t *d_X, *d_sum, *d_sumsq;\n      auto errorX = cudaMalloc((void**)&d_X, data_size_bytes);\n      auto errorY = cudaMalloc((void**)&d_sum, output_size_bytes);\n      auto errorZ = cudaMalloc((void**)&d_sumsq, output_size_bytes);\n      if (errorX != cudaSuccess ||\n          errorY != cudaSuccess ||\n          errorZ != cudaSuccess) {\n        if (errorX == cudaSuccess) cudaFree(d_X);\n        if (errorY == cudaSuccess) cudaFree(d_sum);\n        if (errorZ == cudaSuccess) cudaFree(d_sumsq);\n        printf(\"Device memory allocation failed. Exit\\n\");\n        goto end;\n      }\n\n      cudaMemcpy(d_X, h_X, data_size_bytes, cudaMemcpyHostToDevice);\n\n      ComputeChannelSumNHWC (N, C, W*H, d_X, d_sum, d_sumsq, time, repeat);\n\n      cudaMemcpy(h_sum, d_sum, output_size_bytes, cudaMemcpyDeviceToHost);\n      ref_nhwc (N, C, W*H, h_X, r_sum, h_sumsq);\n      bool ok = check(C, h_sum, r_sum);\n\n      printf(\"Average time of channel sum (nhwc): %f (ms)\\n\", (time * 1e-6f) / repeat);\n      printf(\"Verification %s for channel sum (nhwc)\\n\", ok ? \"PASS\" : \"FAIL\");\n\n      ComputeChannelSumNCHW (N, C, W*H, d_X, d_sum, d_sumsq, time, repeat);\n\n      cudaMemcpy(h_sum, d_sum, output_size_bytes, cudaMemcpyDeviceToHost);\n      ref_nchw (N, C, W*H, h_X, r_sum, h_sumsq);\n      ok = check(C, h_sum, r_sum);\n      \n      printf(\"Average time of channel sum (nchw): %f (ms)\\n\", (time * 1e-6f) / repeat);\n      printf(\"Verification %s for channel sum (nchw)\\n\", ok ? \"PASS\" : \"FAIL\");\n\n      cudaFree(d_X);\n      cudaFree(d_sum);\n      cudaFree(d_sumsq);\n\n      free(h_X);\n      free(h_sum);\n      free(r_sum);\n      free(h_sumsq);\n    }\n  }\n  \n  end: return 0;\n}\n"}}
{"kernel_name": "channelSum", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include <hipcub/hipcub.hpp>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n\n\n\ntypedef int scalar_t;\n\ntemplate <typename T>\nusing BlockReduce1D = hipcub::BlockReduce<T, NUM_THREADS>;\n\ntemplate <typename T, int kBlockDimX, int kBlockDimY>\nusing BlockReduce2D = hipcub::BlockReduce<T,\n                                       kBlockDimX,\n                                       hipcub::BLOCK_REDUCE_WARP_REDUCTIONS,\n                                       kBlockDimY>;\n\n#define DISPATCH_REDUCE_KERNEL_BY_2D_BLOCK_WITH_TYPE(                      \\\n    size, Func, T, grid_dim, stream, ...)                                  \\\n  do {                                                                     \\\n    if (size >= 128) {                                                     \\\n      Func<T, 1, 128><<<grid_dim, dim3(1, 128), 0, stream>>>(__VA_ARGS__); \\\n    } else if (size >= 64) {                                               \\\n      Func<T, 2, 64><<<grid_dim, dim3(2, 64), 0, stream>>>(__VA_ARGS__);   \\\n    } else if (size >= 32) {                                               \\\n      Func<T, 4, 32><<<grid_dim, dim3(4, 32), 0, stream>>>(__VA_ARGS__);   \\\n    } else {                                                               \\\n      Func<T, 8, 16><<<grid_dim, dim3(8, 16), 0, stream>>>(__VA_ARGS__);   \\\n    }                                                                      \\\n  } while (false)\n\n\ntemplate <typename T, int kBlockDimX, int kBlockDimY>\n__global__\nvoid ChannelSumNCHW(\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict__ sum,\n    T*__restrict__ sumsq)\n{\n  __shared__\n  typename BlockReduce2D<T, kBlockDimX, kBlockDimY>::TempStorage m_storage;\n\n  __shared__\n  typename BlockReduce2D<T, kBlockDimX, kBlockDimY>::TempStorage v_storage;\n\n  T m_val = 0;\n  T v_val = 0;\n\n  const int c = blockIdx.x;\n\n  \n\n  for (int n = threadIdx.x; n < N; n += blockDim.x) {\n    for (int hw = threadIdx.y; hw < HxW; hw += blockDim.y) {\n      const int index = (n * C + c) * HxW + hw;\n      m_val += __ldg(X + index);\n      v_val += __ldg(X + index) * __ldg(X + index);\n    }\n  }\n  m_val = BlockReduce2D<T, kBlockDimX, kBlockDimY>(m_storage).Sum(m_val);\n  v_val = BlockReduce2D<T, kBlockDimX, kBlockDimY>(v_storage).Sum(v_val);\n\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\ntemplate <typename T>\n__global__\nvoid ChannelSumNHWC(\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict__ sum,\n    T*__restrict__ sumsq)\n{\n  __shared__ typename BlockReduce1D<T>::TempStorage m_storage;\n  __shared__ typename BlockReduce1D<T>::TempStorage v_storage;\n  const int inner_size = N * HxW;\n  const int c = blockIdx.x;\n  T m_val = 0;\n  T v_val = 0;\n  for (int i = threadIdx.x; i < inner_size; i += blockDim.x) {\n    const int index = i * C + c;\n    m_val += __ldg(X + index);\n    v_val += __ldg(X + index) * __ldg(X + index);\n  }\n  m_val = BlockReduce1D<T>(m_storage).Sum(m_val);\n  v_val = BlockReduce1D<T>(v_storage).Sum(v_val);\n  if (threadIdx.x == 0) {\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\nvoid ComputeChannelSumNCHW (\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    DISPATCH_REDUCE_KERNEL_BY_2D_BLOCK_WITH_TYPE(\n      HxW,\n      ChannelSumNCHW,\n      scalar_t,\n      C,\n      0,\n      N,\n      C,\n      HxW,\n      X,\n      sum,\n      sumsq);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nvoid ComputeChannelSumNHWC (\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelSumNHWC<scalar_t> <<<C, NUM_THREADS>>>(N, C, HxW, X, sum, sumsq);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int W = atoi(argv[1]);\n  const int H = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  long time;\n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      int numel = N * C * W * H; \n\n\n      size_t data_size_bytes = numel * sizeof(scalar_t);\n      size_t output_size_bytes = C * sizeof(scalar_t);\n\n      scalar_t *h_X = (scalar_t*) malloc (data_size_bytes);\n      scalar_t *h_sum = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *h_sumsq = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *r_sum = (scalar_t*) malloc (output_size_bytes);\n\n      srand(numel);\n      for (int i = 0; i < numel; i++) h_X[i] = rand() % 256;\n\n      scalar_t *d_X, *d_sum, *d_sumsq;\n      auto errorX = hipMalloc((void**)&d_X, data_size_bytes);\n      auto errorY = hipMalloc((void**)&d_sum, output_size_bytes);\n      auto errorZ = hipMalloc((void**)&d_sumsq, output_size_bytes);\n      if (errorX != hipSuccess ||\n          errorY != hipSuccess ||\n          errorZ != hipSuccess) {\n        if (errorX == hipSuccess) hipFree(d_X);\n        if (errorY == hipSuccess) hipFree(d_sum);\n        if (errorZ == hipSuccess) hipFree(d_sumsq);\n        printf(\"Device memory allocation failed. Exit\\n\");\n        goto end;\n      }\n\n      hipMemcpy(d_X, h_X, data_size_bytes, hipMemcpyHostToDevice);\n\n      ComputeChannelSumNHWC (N, C, W*H, d_X, d_sum, d_sumsq, time, repeat);\n\n      hipMemcpy(h_sum, d_sum, output_size_bytes, hipMemcpyDeviceToHost);\n      ref_nhwc (N, C, W*H, h_X, r_sum, h_sumsq);\n      bool ok = check(C, h_sum, r_sum);\n\n      printf(\"Average time of channel sum (nhwc): %f (ms)\\n\", (time * 1e-6f) / repeat);\n      printf(\"Verification %s for channel sum (nhwc)\\n\", ok ? \"PASS\" : \"FAIL\");\n\n      ComputeChannelSumNCHW (N, C, W*H, d_X, d_sum, d_sumsq, time, repeat);\n\n      hipMemcpy(h_sum, d_sum, output_size_bytes, hipMemcpyDeviceToHost);\n      ref_nchw (N, C, W*H, h_X, r_sum, h_sumsq);\n      ok = check(C, h_sum, r_sum);\n      \n      printf(\"Average time of channel sum (nchw): %f (ms)\\n\", (time * 1e-6f) / repeat);\n      printf(\"Verification %s for channel sum (nchw)\\n\", ok ? \"PASS\" : \"FAIL\");\n\n      hipFree(d_X);\n      hipFree(d_sum);\n      hipFree(d_sumsq);\n\n      free(h_X);\n      free(h_sum);\n      free(r_sum);\n      free(h_sumsq);\n    }\n  }\n  \n  end: return 0;\n}\n"}}
{"kernel_name": "channelSum", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n\n\n\ntypedef int scalar_t;\n\ntemplate <typename T>\nvoid ChannelSumNCHW(\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict sum,\n    T*__restrict sumsq)\n{\n  #pragma omp target teams distribute num_teams(C)\n  for (int c = 0; c < C; c++) {\n    T m_val = 0, v_val = 0;\n    #pragma omp parallel for collapse(2) \\\n    reduction(+:m_val, v_val) num_threads(NUM_THREADS)\n    for (int n = 0; n < N; n++) {\n      for (int hw = 0; hw < HxW; hw++) {\n        const int index = (n * C + c) * HxW + hw;\n        m_val += *(X + index);\n        v_val += *(X + index) * *(X + index);\n      }\n    }\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\ntemplate <typename T>\nvoid ChannelSumNHWC(\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict sum,\n    T*__restrict sumsq)\n{\n  #pragma omp target teams distribute num_teams(C)\n  for (int c = 0; c < C; c++) {\n    T m_val = 0, v_val = 0;\n    #pragma omp parallel for reduction(+:m_val, v_val) num_threads(NUM_THREADS)\n    for (int i = 0; i < N * HxW; i++) {\n      const int index = (i * C + c);\n      m_val += *(X + index);\n      v_val += *(X + index) * *(X + index);\n    }\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\nvoid ComputeChannelSumNCHW (\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelSumNCHW<scalar_t> (N, C, HxW, X, sum, sumsq);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nvoid ComputeChannelSumNHWC (\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelSumNHWC<scalar_t> (N, C, HxW, X, sum, sumsq);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int W = atoi(argv[1]);\n  const int H = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  long time;\n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      int numel = N * C * W * H; \n\n\n      size_t data_size_bytes = numel * sizeof(scalar_t);\n      size_t output_size_bytes = C * sizeof(scalar_t);\n\n      scalar_t *h_X = (scalar_t*) malloc (data_size_bytes);\n      scalar_t *h_sum = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *h_sumsq = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *r_sum = (scalar_t*) malloc (output_size_bytes);\n\n      srand(numel);\n      for (int i = 0; i < numel; i++) h_X[i] = rand() % 256;\n\n      #pragma omp target data map (to: h_X[0:numel]) \\\n                              map (from: h_sum[0:C], h_sumsq[0:C])\n      {\n        ComputeChannelSumNHWC (N, C, W*H, h_X, h_sum, h_sumsq, time, repeat);\n\n        #pragma omp target update from (h_sum[0:C])\n        ref_nhwc (N, C, W*H, h_X, r_sum, h_sumsq);\n        bool ok = check(C, h_sum, r_sum);\n\n        printf(\"Average time of channel sum (nhwc): %f (ms)\\n\", (time * 1e-6f) / repeat);\n        printf(\"Verification %s for channel sum (nhwc)\\n\", ok ? \"PASS\" : \"FAIL\");\n\n        ComputeChannelSumNCHW (N, C, W*H, h_X, h_sum, h_sumsq, time, repeat);\n\n        #pragma omp target update from (h_sum[0:C])\n        ref_nchw (N, C, W*H, h_X, r_sum, h_sumsq);\n        ok = check(C, h_sum, r_sum);\n        \n        printf(\"Average time of channel sum (nchw): %f (ms)\\n\", (time * 1e-6f) / repeat);\n        printf(\"Verification %s for channel sum (nchw)\\n\", ok ? \"PASS\" : \"FAIL\");\n      }\n\n      free(h_X);\n      free(h_sum);\n      free(r_sum);\n      free(h_sumsq);\n    }\n  }\n  \n  end: return 0;\n}\n"}}
{"kernel_name": "channelSum", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n\n\n\ntypedef int scalar_t;\n\ntemplate <typename T>\nvoid ChannelSumNCHW(\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict sum,\n    T*__restrict sumsq)\n{\n    for (int c = 0; c < C; c++) {\n    T m_val = 0, v_val = 0;\n        for (int n = 0; n < N; n++) {\n      for (int hw = 0; hw < HxW; hw++) {\n        const int index = (n * C + c) * HxW + hw;\n        m_val += *(X + index);\n        v_val += *(X + index) * *(X + index);\n      }\n    }\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\ntemplate <typename T>\nvoid ChannelSumNHWC(\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict sum,\n    T*__restrict sumsq)\n{\n    for (int c = 0; c < C; c++) {\n    T m_val = 0, v_val = 0;\n        for (int i = 0; i < N * HxW; i++) {\n      const int index = (i * C + c);\n      m_val += *(X + index);\n      v_val += *(X + index) * *(X + index);\n    }\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\nvoid ComputeChannelSumNCHW (\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelSumNCHW<scalar_t> (N, C, HxW, X, sum, sumsq);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nvoid ComputeChannelSumNHWC (\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    ChannelSumNHWC<scalar_t> (N, C, HxW, X, sum, sumsq);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int W = atoi(argv[1]);\n  const int H = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  long time;\n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      int numel = N * C * W * H; \n\n\n      size_t data_size_bytes = numel * sizeof(scalar_t);\n      size_t output_size_bytes = C * sizeof(scalar_t);\n\n      scalar_t *h_X = (scalar_t*) malloc (data_size_bytes);\n      scalar_t *h_sum = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *h_sumsq = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *r_sum = (scalar_t*) malloc (output_size_bytes);\n\n      srand(numel);\n      for (int i = 0; i < numel; i++) h_X[i] = rand() % 256;\n\n            {\n        ComputeChannelSumNHWC (N, C, W*H, h_X, h_sum, h_sumsq, time, repeat);\n\n                ref_nhwc (N, C, W*H, h_X, r_sum, h_sumsq);\n        bool ok = check(C, h_sum, r_sum);\n\n        printf(\"Average time of channel sum (nhwc): %f (ms)\\n\", (time * 1e-6f) / repeat);\n        printf(\"Verification %s for channel sum (nhwc)\\n\", ok ? \"PASS\" : \"FAIL\");\n\n        ComputeChannelSumNCHW (N, C, W*H, h_X, h_sum, h_sumsq, time, repeat);\n\n                ref_nchw (N, C, W*H, h_X, r_sum, h_sumsq);\n        ok = check(C, h_sum, r_sum);\n        \n        printf(\"Average time of channel sum (nchw): %f (ms)\\n\", (time * 1e-6f) / repeat);\n        printf(\"Verification %s for channel sum (nchw)\\n\", ok ? \"PASS\" : \"FAIL\");\n      }\n\n      free(h_X);\n      free(h_sum);\n      free(r_sum);\n      free(h_sumsq);\n    }\n  }\n  \n  end: return 0;\n}"}}
{"kernel_name": "channelSum", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <functional>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n#define NUM_THREADS 256\n\n\n\ntypedef int scalar_t;\n\n#define DISPATCH_REDUCE_KERNEL_BY_2D_BLOCK_WITH_TYPE(                  \\\n   size, Func, T, grid_dim, ...)                                       \\\n  do {                                                                 \\\n   if (size >= 128) {                                                  \\\n     sycl::range<2> gws (128, grid_dim);                               \\\n     sycl::range<2> lws (128, 1);                                      \\\n     q.submit([&](sycl::handler &cgh) {                                \\\n       cgh.parallel_for(                                               \\\n         sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {    \\\n         Func<T>(item, __VA_ARGS__);                                   \\\n       });                                                             \\\n     });                                                               \\\n   } else if (size >= 64) {                                            \\\n     sycl::range<2> gws (64, 2 * grid_dim);                            \\\n     sycl::range<2> lws (64, 2);                                       \\\n     q.submit([&](sycl::handler &cgh) {                                \\\n       cgh.parallel_for(                                               \\\n         sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {    \\\n         Func<T>(item, __VA_ARGS__);                                   \\\n       });                                                             \\\n     });                                                               \\\n   } else if (size >= 32) {                                            \\\n     sycl::range<2> gws (32, 4 * grid_dim);                            \\\n     sycl::range<2> lws (32, 4);                                       \\\n     q.submit([&](sycl::handler &cgh) {                                \\\n       cgh.parallel_for(                                               \\\n         sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {    \\\n         Func<T>(item, __VA_ARGS__);                                   \\\n       });                                                             \\\n     });                                                               \\\n   } else {                                                            \\\n     sycl::range<2> gws (16, 8 * grid_dim);                            \\\n     sycl::range<2> lws (16, 8);                                       \\\n     q.submit([&](sycl::handler &cgh) {                                \\\n       cgh.parallel_for(                                               \\\n         sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {    \\\n         Func<T>(item, __VA_ARGS__);                                   \\\n       });                                                             \\\n     });                                                               \\\n   }                                                                   \\\n  } while (false)\n\n\ntemplate <typename T>\nvoid ChannelSumNCHW(\n    sycl::nd_item<2> item,\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict__ sum,\n    T*__restrict__ sumsq)\n{\n  T m_val = 0;\n  T v_val = 0;\n\n  const int c = item.get_group(1);\n\n  \n\n  for (int n = item.get_local_id(1); n < N;\n           n += item.get_local_range(1)) {\n    for (int hw = item.get_local_id(0); hw < HxW;\n         hw += item.get_local_range(0)) {\n      const int index = (n * C + c) * HxW + hw;\n      m_val += *(X + index);\n      v_val += *(X + index) * *(X + index);\n    }\n  }\n  auto g = item.get_group();\n  m_val = sycl::reduce_over_group(g, m_val, std::plus<>());\n  v_val = sycl::reduce_over_group(g, v_val, std::plus<>());\n\n  if (item.get_local_id(1) == 0 && item.get_local_id(0) == 0) {\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\ntemplate <typename T>\nvoid ChannelSumNHWC(\n    sycl::nd_item<1> &item,\n    const int N,\n    const int C,\n    const int HxW,\n    const T* X,\n    T*__restrict__ sum,\n    T*__restrict__ sumsq)\n{\n  const int inner_size = N * HxW;\n  const int c = item.get_group(0);\n  T m_val = 0;\n  T v_val = 0;\n  for (int i = item.get_local_id(0); i < inner_size;\n       i += item.get_local_range(0)) {\n    const int index = i * C + c;\n    m_val += *(X + index);\n    v_val += *(X + index) * *(X + index);\n  }\n\n  auto g = item.get_group();\n  m_val = sycl::reduce_over_group(g, m_val, std::plus<>());\n  v_val = sycl::reduce_over_group(g, v_val, std::plus<>());\n  if (item.get_local_id(0) == 0) {\n    sum[c] = m_val;\n    sumsq[c] = v_val;\n  }\n}\n\nvoid ComputeChannelSumNCHW (\n    sycl::queue &q,\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    DISPATCH_REDUCE_KERNEL_BY_2D_BLOCK_WITH_TYPE(\n        HxW, ChannelSumNCHW, scalar_t, C, N, C, HxW, X, sum, sumsq);\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nvoid ComputeChannelSumNHWC (\n    sycl::queue &q,\n    const int N,\n    const int C,\n    const int HxW,\n    const scalar_t* X,\n    scalar_t* sum,\n    scalar_t* sumsq,\n    long &time,\n    int repeat)\n{\n  sycl::range<1> lws (NUM_THREADS);\n  sycl::range<1> gws (C * NUM_THREADS);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        ChannelSumNHWC<scalar_t>(item, N, C, HxW, X, sum, sumsq);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int W = atoi(argv[1]);\n  const int H = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  long time;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  for (int N = 1; N <= 64; N = N * 4) {\n    for (int C = 32; C <= 512; C = C * 4) {\n\n      printf(\"\\n(N=%d C=%d W=%d H=%d)\\n\", N, C, W, H);\n\n      int numel = N * C * W * H; \n\n\n      size_t data_size_bytes = numel * sizeof(scalar_t);\n      size_t output_size_bytes = C * sizeof(scalar_t);\n\n      scalar_t *h_X = (scalar_t*) malloc (data_size_bytes);\n      scalar_t *h_sum = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *h_sumsq = (scalar_t*) malloc (output_size_bytes);\n      scalar_t *r_sum = (scalar_t*) malloc (output_size_bytes);\n\n      srand(numel);\n      for (int i = 0; i < numel; i++) h_X[i] = rand() % 256;\n\n      scalar_t *d_X, *d_sum, *d_sumsq;\n      d_X = sycl::malloc_device<scalar_t>(numel, q);\n      d_sum = sycl::malloc_device<scalar_t>(C, q);\n      d_sumsq = sycl::malloc_device<scalar_t>(C, q);\n      if (d_X == nullptr || d_sum == nullptr || d_sumsq == nullptr) {\n        if (d_X != nullptr) sycl::free(d_X, q);\n        if (d_sum != nullptr) sycl::free(d_sum, q);\n        if (d_sumsq != nullptr) sycl::free(d_sumsq, q);\n        printf(\"Device memory allocation failed. Exit\\n\");\n        goto end;\n      }\n\n      q.memcpy(d_X, h_X, data_size_bytes).wait();\n\n      ComputeChannelSumNHWC (q, N, C, W*H, d_X, d_sum, d_sumsq, time, repeat);\n\n      q.memcpy(h_sum, d_sum, output_size_bytes).wait();\n      ref_nhwc (N, C, W*H, h_X, r_sum, h_sumsq);\n      bool ok = check(C, h_sum, r_sum);\n\n      printf(\"Average time of channel sum (nhwc): %f (ms)\\n\", (time * 1e-6f) / repeat);\n      printf(\"Verification %s for channel sum (nhwc)\\n\", ok ? \"PASS\" : \"FAIL\");\n\n      ComputeChannelSumNCHW (q, N, C, W*H, d_X, d_sum, d_sumsq, time, repeat);\n\n      q.memcpy(h_sum, d_sum, output_size_bytes).wait();\n      ref_nchw (N, C, W*H, h_X, r_sum, h_sumsq);\n      ok = check(C, h_sum, r_sum);\n      \n      printf(\"Average time of channel sum (nchw): %f (ms)\\n\", (time * 1e-6f) / repeat);\n      printf(\"Verification %s for channel sum (nchw)\\n\", ok ? \"PASS\" : \"FAIL\");\n\n      sycl::free(d_X, q);\n      sycl::free(d_sum, q);\n      sycl::free(d_sumsq, q);\n\n      free(h_X);\n      free(h_sum);\n      free(r_sum);\n      free(h_sumsq);\n    }\n  }\n  \n  end: return 0;\n}\n"}}
{"kernel_name": "clink", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <iostream>\n#include <cstring>\n#include <cuda.h>\n#include \"kernel.h\"\n\n#ifdef DEBUG\nvoid dump (const char* work_path, const char* result_filename, const float* result) {\n  char file_name[100];\n  int i;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, result_filename);\n  if (!(fp = fopen(file_name, \"w\"))) {\n    printf(\"File %s cannot be opened for write.\\n\", result_filename);\n    exit(-1);\n  }\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i)\n    fprintf(fp, \"%f\\n\", result[i]);\n  fclose(fp);\n}\n#endif\n\nvoid init(const char* work_path, const char* input_filename, const char* weight_filename,\n    float* sample_input, float* inW, float* intW, float* intB, float* outW, float* outB) {\n\n  char file_name[100];\n\n  float weightVal;\n\n  int i, j, k;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, input_filename);\n  \n\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", input_filename);\n    exit(-1);\n  }\n\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i) {\n    fscanf(fp, \"%f\", &sample_input[i]);\n  }\n  fclose(fp);\n\n  \n\n  for (int i = 1; i < N; i++)\n    memcpy(sample_input+i*SAMPLE_TEST_LEN, sample_input, SAMPLE_TEST_LEN*sizeof(float));\n\n  \n\n  sprintf(file_name, \"%s/%s\", work_path, weight_filename);\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", weight_filename);\n    exit(-1);\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      inW[j*5+i] = weightVal;\n    }\n  }\n  for (k = 0; k < 4; ++k) {\n    for (j = 0; j < 5; ++j) {\n      for (i = 0; i < 5; ++i) {\n        fscanf(fp, \"%f\", &weightVal);\n        intW[k*25+j*5+i] = weightVal;\n      }\n    }\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      intB[j*5+i] = weightVal;\n    }\n  }\n  for (i = 0; i < 5; ++i) {\n    fscanf(fp, \"%f\", &weightVal);\n    outW[i] = weightVal;\n  }\n  fscanf(fp, \"%f\", &weightVal);\n  *outB = weightVal;\n  fclose(fp);\n}\n\nlong lstm_n5(const float* x, \n             const float* inW, \n             const float* intW, \n             const float* intB, \n             const float* outW, \n             const float* outB,\n                   float* y)\n{\n  float *d_x, *d_inW, *d_intW, *d_intB, *d_outW, *d_y, *d_outB;\n  cudaMalloc((void**)&d_x, N * SAMPLE_TEST_LEN * sizeof(float));\n  cudaMalloc((void**)&d_inW, 20 * sizeof(float));\n  cudaMalloc((void**)&d_intW, 100 * sizeof(float));\n  cudaMalloc((void**)&d_intB, 20 * sizeof(float));\n  cudaMalloc((void**)&d_outW, 5 * sizeof(float));\n  cudaMalloc((void**)&d_outB, sizeof(float));\n  cudaMalloc((void**)&d_y, N * SAMPLE_TEST_LEN * sizeof(float));\n\n  cudaMemcpy(d_x, x, N * SAMPLE_TEST_LEN * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_inW, inW, 20 * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_intW, intW, 100 * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_intB, intB, 20 * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_outW, outW, 5 * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_outB, outB, 1 * sizeof(float), cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  lstm_inference<<<dim3(N/WGS), dim3(WGS)>>>(\n      d_x, d_inW, d_intW, d_intB, d_outW, d_outB, d_y);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  cudaMemcpy(y, d_y, N * SAMPLE_TEST_LEN * sizeof(float), cudaMemcpyDeviceToHost);\n  cudaFree(d_x);\n  cudaFree(d_inW);\n  cudaFree(d_intW);\n  cudaFree(d_intB);\n  cudaFree(d_outW);\n  cudaFree(d_outB);\n  cudaFree(d_y);\n  return time;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  float* sample_input = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer1_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer2_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n\n  float inW[20], intW[100], intB[20], outW[5];\n  float outB;\n\n  const char* work_path = \"./\";\n  const char* input_filename = \"input.hpp\";\n  const char* weight1_filename = \"weight_1.hpp\";\n  const char* weight2_filename = \"weight_2.hpp\";\n#ifdef DEBUG\n  const char* result1_filename = \"float_infer_result_1.hpp\";\n  const char* result2_filename = \"float_infer_result_2.hpp\";\n#endif\n\n  long kernel_time = 0;\n  for (int n = 0; n < repeat; n++) {\n    init(work_path, input_filename, weight1_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    auto start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(sample_input, inW, intW, intB, outW, &outB, infer1_out);\n    auto end = std::chrono::steady_clock::now();\n    auto elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result1_filename, infer1_out);\n#endif\n\n    init(work_path, input_filename, weight2_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(sample_input, inW, intW, intB, outW, &outB, infer2_out);\n    end = std::chrono::steady_clock::now();\n    elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result2_filename, infer2_out);\n#endif\n  }\n  std::cout << \"Average kernel time: \" <<  kernel_time * 1e-6 / (2 * repeat) << \" ms\\n\";\n\n  free(sample_input);\n  free(infer1_out);\n  free(infer2_out);\n  printf(\"Processing complete.\\n\");\n  return 0;\n}\n"}}
{"kernel_name": "clink", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <iostream>\n#include <cstring>\n#include <hip/hip_runtime.h>\n#include \"kernel.h\"\n\n#ifdef DEBUG\nvoid dump (const char* work_path, const char* result_filename, const float* result) {\n  char file_name[100];\n  int i;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, result_filename);\n  if (!(fp = fopen(file_name, \"w\"))) {\n    printf(\"File %s cannot be opened for write.\\n\", result_filename);\n    exit(-1);\n  }\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i)\n    fprintf(fp, \"%f\\n\", result[i]);\n  fclose(fp);\n}\n#endif\n\nvoid init(const char* work_path, const char* input_filename, const char* weight_filename,\n    float* sample_input, float* inW, float* intW, float* intB, float* outW, float* outB) {\n\n  char file_name[100];\n\n  float weightVal;\n\n  int i, j, k;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, input_filename);\n  \n\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", input_filename);\n    exit(-1);\n  }\n\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i) {\n    fscanf(fp, \"%f\", &sample_input[i]);\n  }\n  fclose(fp);\n\n  \n\n  for (int i = 1; i < N; i++)\n    memcpy(sample_input+i*SAMPLE_TEST_LEN, sample_input, SAMPLE_TEST_LEN*sizeof(float));\n\n  \n\n  sprintf(file_name, \"%s/%s\", work_path, weight_filename);\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", weight_filename);\n    exit(-1);\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      inW[j*5+i] = weightVal;\n    }\n  }\n  for (k = 0; k < 4; ++k) {\n    for (j = 0; j < 5; ++j) {\n      for (i = 0; i < 5; ++i) {\n        fscanf(fp, \"%f\", &weightVal);\n        intW[k*25+j*5+i] = weightVal;\n      }\n    }\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      intB[j*5+i] = weightVal;\n    }\n  }\n  for (i = 0; i < 5; ++i) {\n    fscanf(fp, \"%f\", &weightVal);\n    outW[i] = weightVal;\n  }\n  fscanf(fp, \"%f\", &weightVal);\n  *outB = weightVal;\n  fclose(fp);\n}\n\nlong lstm_n5(const float* x, \n             const float* inW, \n             const float* intW, \n             const float* intB, \n             const float* outW, \n             const float* outB,\n                   float* y)\n{\n  float *d_x, *d_inW, *d_intW, *d_intB, *d_outW, *d_y, *d_outB;\n  hipMalloc((void**)&d_x, N * SAMPLE_TEST_LEN * sizeof(float));\n  hipMalloc((void**)&d_inW, 20 * sizeof(float));\n  hipMalloc((void**)&d_intW, 100 * sizeof(float));\n  hipMalloc((void**)&d_intB, 20 * sizeof(float));\n  hipMalloc((void**)&d_outW, 5 * sizeof(float));\n  hipMalloc((void**)&d_outB, sizeof(float));\n  hipMalloc((void**)&d_y, N * SAMPLE_TEST_LEN * sizeof(float));\n\n  hipMemcpy(d_x, x, N * SAMPLE_TEST_LEN * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(d_inW, inW, 20 * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(d_intW, intW, 100 * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(d_intB, intB, 20 * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(d_outW, outW, 5 * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(d_outB, outB, 1 * sizeof(float), hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  lstm_inference<<<dim3(N/WGS), dim3(WGS)>>>(\n      d_x, d_inW, d_intW, d_intB, d_outW, d_outB, d_y);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  hipMemcpy(y, d_y, N * SAMPLE_TEST_LEN * sizeof(float), hipMemcpyDeviceToHost);\n  hipFree(d_x);\n  hipFree(d_inW);\n  hipFree(d_intW);\n  hipFree(d_intB);\n  hipFree(d_outW);\n  hipFree(d_outB);\n  hipFree(d_y);\n  return time;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  float* sample_input = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer1_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer2_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n\n  float inW[20], intW[100], intB[20], outW[5];\n  float outB;\n\n  const char* work_path = \"./\";\n  const char* input_filename = \"input.hpp\";\n  const char* weight1_filename = \"weight_1.hpp\";\n  const char* weight2_filename = \"weight_2.hpp\";\n#ifdef DEBUG\n  const char* result1_filename = \"float_infer_result_1.hpp\";\n  const char* result2_filename = \"float_infer_result_2.hpp\";\n#endif\n\n  long kernel_time = 0;\n  for (int n = 0; n < repeat; n++) {\n    init(work_path, input_filename, weight1_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    auto start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(sample_input, inW, intW, intB, outW, &outB, infer1_out);\n    auto end = std::chrono::steady_clock::now();\n    auto elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result1_filename, infer1_out);\n#endif\n\n    init(work_path, input_filename, weight2_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(sample_input, inW, intW, intB, outW, &outB, infer2_out);\n    end = std::chrono::steady_clock::now();\n    elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result2_filename, infer2_out);\n#endif\n  }\n  std::cout << \"Average kernel time: \" <<  kernel_time * 1e-6 / (2 * repeat) << \" ms\\n\";\n\n  free(sample_input);\n  free(infer1_out);\n  free(infer2_out);\n  printf(\"Processing complete.\\n\");\n  return 0;\n}\n"}}
{"kernel_name": "clink", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include <cmath>\n#include <cstring>\n#include <omp.h>\n\n\n\n#define N 8192\n#define WGS 256\n#define SAMPLE_TEST_LEN 20000\n\n#pragma omp declare target\nfloat sigmoid(float x)\n{\n  return 1.f / (1.f + expf(-x));\n}\n#pragma omp end declare target\n\n#ifdef DEBUG\nvoid dump (const char* work_path, const char* result_filename, const float* result) \n{\n  char file_name[100];\n  int i;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, result_filename);\n  \n\n  if (!(fp = fopen(file_name, \"w\"))) {\n    printf(\"File %s cannot be opened for write.\\n\", result_filename);\n    exit(-1);\n  }\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i)\n    fprintf(fp, \"%f\\n\", result[i]);\n  fclose(fp);\n}\n#endif\n\nvoid init(const char* work_path, const char* input_filename, const char* weight_filename,\n\t\tfloat* sample_input, float* inW, float* intW, float* intB, float* outW, float* outB) \n{\n  char file_name[100];\n\n  float weightVal;\n\n  int i, j, k;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, input_filename);\n  \n\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", input_filename);\n    exit(-1);\n  }\n\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i) {\n    fscanf(fp, \"%f\", &sample_input[i]);\n  }\n  fclose(fp);\n\n  \n\n  for (int i = 1; i < N; i++)\n\tmemcpy(sample_input+i*SAMPLE_TEST_LEN, sample_input, SAMPLE_TEST_LEN*sizeof(float));\n\n  \n\n  sprintf(file_name, \"%s/%s\", work_path, weight_filename);\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", weight_filename);\n    exit(-1);\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      inW[j*5+i] = weightVal;\n    }\n  }\n  for (k = 0; k < 4; ++k) {\n    for (j = 0; j < 5; ++j) {\n      for (i = 0; i < 5; ++i) {\n        fscanf(fp, \"%f\", &weightVal);\n        intW[k*25+j*5+i] = weightVal;\n      }\n    }\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      intB[j*5+i] = weightVal;\n    }\n  }\n  for (i = 0; i < 5; ++i) {\n    fscanf(fp, \"%f\", &weightVal);\n    outW[i] = weightVal;\n  }\n  fscanf(fp, \"%f\", &weightVal);\n  *outB = weightVal;\n  fclose(fp);\n}\n\nlong lstm_n5( const float* x, \n    const float* inW, \n    const float* intW, \n    const float* intB, \n    const float* outW, \n    const float* outB,\n    float* y) \n{\n  long time;\n  #pragma omp target data map(to: x[0:N*SAMPLE_TEST_LEN], \\\n                                  inW[0:20], \\\n                                  intW[0:100], \\\n                                  intB[0:20], \\\n                                  outW[0:5], \\\n                                  outB[0:1]) \\\n                     map(from: y[0:N*SAMPLE_TEST_LEN])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    #pragma omp target teams distribute parallel for thread_limit(WGS)\n    for (int gid = 0; gid < N; gid++) {\n\n      int t,i,j;\n\n      float h_state[5] = {0,0,0,0,0};\n      float c_state[5] = {0,0,0,0,0};\n      float i_state[5] = {0,0,0,0,0};\n      float f_state[5] = {0,0,0,0,0};\n      float o_state[5] = {0,0,0,0,0};\n      float g_state[5] = {0,0,0,0,0};\n\n      for (t = 0; t < SAMPLE_TEST_LEN; ++t) {\n        float v = x[gid * SAMPLE_TEST_LEN + t];\n        for (j = 0; j < 5; ++j) {\n          i_state[j] = inW[j] * v;\n          for (i = 0; i < 5; ++i)\n            i_state[j] += h_state[i] * intW[j*5+i];\n          i_state[j] += intB[j];\n          i_state[j] = sigmoid(i_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          f_state[j] = inW[5+j] * v;\n          for (i = 0; i < 5; ++i)\n            f_state[j] += h_state[i] * intW[25+j*5+i];\n          f_state[j] += intB[5+j];\n          f_state[j] = sigmoid(f_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          o_state[j] = inW[10+j] * v;\n          for (i = 0; i < 5; ++i)\n            o_state[j] += h_state[i] * intW[50+j*5+i];\n          o_state[j] += intB[10+j];\n          o_state[j] = sigmoid(o_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          g_state[j] = inW[15+j] * v;\n          for (i = 0; i < 5; ++i)\n            g_state[j] += h_state[i] * intW[75+j*5+i];\n          g_state[j] += intB[15+j];\n          g_state[j] = tanhf(g_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          c_state[j] = c_state[j] * f_state[j] + g_state[j] * i_state[j];\n          h_state[j] = tanhf(c_state[j]) * o_state[j];\n        }\n\n        float b = outB[0];\n        for (j = 0; j < 5; ++j)\n          b += h_state[j] * outW[j];\n        y[gid * SAMPLE_TEST_LEN + t] = b;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n  return time;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  float* sample_input = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer1_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer2_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n\n  float inW[20], intW[100], intB[20], outW[5];\n  float outB;\n\n  const char* work_path = \"./\";\n  const char* input_filename = \"input.hpp\";\n  const char* weight1_filename = \"weight_1.hpp\";\n  const char* weight2_filename = \"weight_2.hpp\";\n#ifdef DEBUG\n  const char* result1_filename = \"float_infer_result_1.hpp\";\n  const char* result2_filename = \"float_infer_result_2.hpp\";\n#endif\n\n  long kernel_time = 0;\n  for (int n = 0; n < repeat; n++) {\n    init(work_path, input_filename, weight1_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    auto start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(sample_input, inW, intW, intB, outW, &outB, infer1_out);\n    auto end = std::chrono::steady_clock::now();\n    auto elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result1_filename, infer1_out);\n#endif\n\n    init(work_path, input_filename, weight2_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(sample_input, inW, intW, intB, outW, &outB, infer2_out);\n    end = std::chrono::steady_clock::now();\n    elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result2_filename, infer2_out);\n#endif\n  }\n  std::cout << \"Average kernel time: \" <<  kernel_time * 1e-6 / (2 * repeat) << \" ms\\n\";\n\n  free(sample_input);\n  free(infer1_out);\n  free(infer2_out);\n  printf(\"Processing complete.\\n\");\n  return 0;\n}\n"}}
{"kernel_name": "clink", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include <cmath>\n#include <cstring>\n\n\n\n#define N 8192\n#define WGS 256\n#define SAMPLE_TEST_LEN 20000\n\nfloat sigmoid(float x)\n{\n  return 1.f / (1.f + expf(-x));\n}\n\n#ifdef DEBUG\nvoid dump (const char* work_path, const char* result_filename, const float* result) \n{\n  char file_name[100];\n  int i;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, result_filename);\n  \n\n  if (!(fp = fopen(file_name, \"w\"))) {\n    printf(\"File %s cannot be opened for write.\\n\", result_filename);\n    exit(-1);\n  }\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i)\n    fprintf(fp, \"%f\\n\", result[i]);\n  fclose(fp);\n}\n#endif\n\nvoid init(const char* work_path, const char* input_filename, const char* weight_filename,\n\t\tfloat* sample_input, float* inW, float* intW, float* intB, float* outW, float* outB) \n{\n  char file_name[100];\n\n  float weightVal;\n\n  int i, j, k;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, input_filename);\n  \n\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", input_filename);\n    exit(-1);\n  }\n\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i) {\n    fscanf(fp, \"%f\", &sample_input[i]);\n  }\n  fclose(fp);\n\n  \n\n  for (int i = 1; i < N; i++)\n\tmemcpy(sample_input+i*SAMPLE_TEST_LEN, sample_input, SAMPLE_TEST_LEN*sizeof(float));\n\n  \n\n  sprintf(file_name, \"%s/%s\", work_path, weight_filename);\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", weight_filename);\n    exit(-1);\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      inW[j*5+i] = weightVal;\n    }\n  }\n  for (k = 0; k < 4; ++k) {\n    for (j = 0; j < 5; ++j) {\n      for (i = 0; i < 5; ++i) {\n        fscanf(fp, \"%f\", &weightVal);\n        intW[k*25+j*5+i] = weightVal;\n      }\n    }\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      intB[j*5+i] = weightVal;\n    }\n  }\n  for (i = 0; i < 5; ++i) {\n    fscanf(fp, \"%f\", &weightVal);\n    outW[i] = weightVal;\n  }\n  fscanf(fp, \"%f\", &weightVal);\n  *outB = weightVal;\n  fclose(fp);\n}\n\nlong lstm_n5( const float* x, \n    const float* inW, \n    const float* intW, \n    const float* intB, \n    const float* outW, \n    const float* outB,\n    float* y) \n{\n  long time;\n    {\n    auto start = std::chrono::steady_clock::now();\n\n        for (int gid = 0; gid < N; gid++) {\n\n      int t,i,j;\n\n      float h_state[5] = {0,0,0,0,0};\n      float c_state[5] = {0,0,0,0,0};\n      float i_state[5] = {0,0,0,0,0};\n      float f_state[5] = {0,0,0,0,0};\n      float o_state[5] = {0,0,0,0,0};\n      float g_state[5] = {0,0,0,0,0};\n\n      for (t = 0; t < SAMPLE_TEST_LEN; ++t) {\n        float v = x[gid * SAMPLE_TEST_LEN + t];\n        for (j = 0; j < 5; ++j) {\n          i_state[j] = inW[j] * v;\n          for (i = 0; i < 5; ++i)\n            i_state[j] += h_state[i] * intW[j*5+i];\n          i_state[j] += intB[j];\n          i_state[j] = sigmoid(i_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          f_state[j] = inW[5+j] * v;\n          for (i = 0; i < 5; ++i)\n            f_state[j] += h_state[i] * intW[25+j*5+i];\n          f_state[j] += intB[5+j];\n          f_state[j] = sigmoid(f_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          o_state[j] = inW[10+j] * v;\n          for (i = 0; i < 5; ++i)\n            o_state[j] += h_state[i] * intW[50+j*5+i];\n          o_state[j] += intB[10+j];\n          o_state[j] = sigmoid(o_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          g_state[j] = inW[15+j] * v;\n          for (i = 0; i < 5; ++i)\n            g_state[j] += h_state[i] * intW[75+j*5+i];\n          g_state[j] += intB[15+j];\n          g_state[j] = tanhf(g_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          c_state[j] = c_state[j] * f_state[j] + g_state[j] * i_state[j];\n          h_state[j] = tanhf(c_state[j]) * o_state[j];\n        }\n\n        float b = outB[0];\n        for (j = 0; j < 5; ++j)\n          b += h_state[j] * outW[j];\n        y[gid * SAMPLE_TEST_LEN + t] = b;\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n  return time;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  float* sample_input = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer1_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer2_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n\n  float inW[20], intW[100], intB[20], outW[5];\n  float outB;\n\n  const char* work_path = \"./\";\n  const char* input_filename = \"input.hpp\";\n  const char* weight1_filename = \"weight_1.hpp\";\n  const char* weight2_filename = \"weight_2.hpp\";\n#ifdef DEBUG\n  const char* result1_filename = \"float_infer_result_1.hpp\";\n  const char* result2_filename = \"float_infer_result_2.hpp\";\n#endif\n\n  long kernel_time = 0;\n  for (int n = 0; n < repeat; n++) {\n    init(work_path, input_filename, weight1_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    auto start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(sample_input, inW, intW, intB, outW, &outB, infer1_out);\n    auto end = std::chrono::steady_clock::now();\n    auto elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result1_filename, infer1_out);\n#endif\n\n    init(work_path, input_filename, weight2_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(sample_input, inW, intW, intB, outW, &outB, infer2_out);\n    end = std::chrono::steady_clock::now();\n    elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result2_filename, infer2_out);\n#endif\n  }\n  std::cout << \"Average kernel time: \" <<  kernel_time * 1e-6 / (2 * repeat) << \" ms\\n\";\n\n  free(sample_input);\n  free(infer1_out);\n  free(infer2_out);\n  printf(\"Processing complete.\\n\");\n  return 0;\n}"}}
{"kernel_name": "clink", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include <cstring>\n#include <sycl/sycl.hpp>\n\n#ifdef __NVPTX__\n  #include <sycl/ext/oneapi/experimental/cuda/builtins.hpp>\n  using namespace sycl::ext::oneapi::experimental::cuda;\n#else\n  #define ldg(a) (*(a))\n#endif\n\n\n\n#define N 8192\n#define WGS 256\n#define SAMPLE_TEST_LEN 20000\n\nfloat sigmoid(float x)\n{\n  return 1.f / (1.f + sycl::exp(-x));\n}\n\n#ifdef DEBUG\nvoid dump (const char* work_path, const char* result_filename, const float* result) \n{\n  char file_name[100];\n  int i;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, result_filename);\n  \n\n  if (!(fp = fopen(file_name, \"w\"))) {\n    printf(\"File %s cannot be opened for write.\\n\", result_filename);\n    exit(-1);\n  }\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i)\n    fprintf(fp, \"%f\\n\", result[i]);\n  fclose(fp);\n}\n#endif\n\nvoid init(const char* work_path, const char* input_filename, const char* weight_filename,\n\t\tfloat* sample_input, float* inW, float* intW, float* intB, float* outW, float* outB) \n{\n  char file_name[100];\n\n  float weightVal;\n\n  int i, j, k;\n\n  FILE *fp;\n\n  sprintf(file_name, \"%s/%s\", work_path, input_filename);\n  \n\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", input_filename);\n    exit(-1);\n  }\n\n  for (i = 0; i < SAMPLE_TEST_LEN; ++i) {\n    fscanf(fp, \"%f\", &sample_input[i]);\n  }\n  fclose(fp);\n\n  \n\n  for (int i = 1; i < N; i++)\n    memcpy(sample_input+i*SAMPLE_TEST_LEN, sample_input, SAMPLE_TEST_LEN*sizeof(float));\n\n  \n\n  sprintf(file_name, \"%s/%s\", work_path, weight_filename);\n  if (!(fp = fopen(file_name, \"r\"))) {\n    printf(\"File %s cannot be opened for read.\\n\", weight_filename);\n    exit(-1);\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      inW[j*5+i] = weightVal;\n    }\n  }\n  for (k = 0; k < 4; ++k) {\n    for (j = 0; j < 5; ++j) {\n      for (i = 0; i < 5; ++i) {\n        fscanf(fp, \"%f\", &weightVal);\n        intW[k*25+j*5+i] = weightVal;\n      }\n    }\n  }\n  for (j = 0; j < 4; ++j) {\n    for (i = 0; i < 5; ++i) {\n      fscanf(fp, \"%f\", &weightVal);\n      intB[j*5+i] = weightVal;\n    }\n  }\n  for (i = 0; i < 5; ++i) {\n    fscanf(fp, \"%f\", &weightVal);\n    outW[i] = weightVal;\n  }\n  fscanf(fp, \"%f\", &weightVal);\n  *outB = weightVal;\n  fclose(fp);\n}\n\nlong lstm_n5( sycl::queue &q,\n              const float* x, \n              const float* inW, \n              const float* intW, \n              const float* intB, \n              const float* outW, \n              const float* outB,\n                    float* y) \n{\n  float *d_x = sycl::malloc_device<float>(N*SAMPLE_TEST_LEN, q);\n  q.memcpy(d_x, x, sizeof(float) * N * SAMPLE_TEST_LEN);\n\n  float *d_inW = sycl::malloc_device<float>(20, q);\n  q.memcpy(d_inW, inW, sizeof(float) * 20);\n\n  float *d_intW = sycl::malloc_device<float>(100, q);\n  q.memcpy(d_intW, intW, sizeof(float) * 100);\n\n  float *d_intB = sycl::malloc_device<float>(20, q);\n  q.memcpy(d_intB, intB, sizeof(float) * 20);\n\n  float *d_outW = sycl::malloc_device<float>(5, q);\n  q.memcpy(d_outW, outW, sizeof(float) * 5);\n\n  float *d_outB = sycl::malloc_device<float>(1, q);\n  q.memcpy(d_outB, outB, sizeof(float));\n\n  float *d_y = sycl::malloc_device<float>(N*SAMPLE_TEST_LEN, q);\n  \n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  q.submit([&](sycl::handler& cgh) {\n    cgh.parallel_for<class lstm>(\n      sycl::nd_range<1>(sycl::range<1>(N), sycl::range<1>(WGS)),\n      [=] (sycl::nd_item<1> item) {\n      int t,i,j;\n      int gid = item.get_global_id(0);\n      \n      float h_state[5] = {0,0,0,0,0};\n      float c_state[5] = {0,0,0,0,0};\n      float i_state[5] = {0,0,0,0,0};\n      float f_state[5] = {0,0,0,0,0};\n      float o_state[5] = {0,0,0,0,0};\n      float g_state[5] = {0,0,0,0,0};\n      \n      for (t = 0; t < SAMPLE_TEST_LEN; ++t) {\n\n        float x = ldg(&d_x[gid * SAMPLE_TEST_LEN + t]);\n\n        for (j = 0; j < 5; ++j) {\n          i_state[j] = ldg(&d_inW[j]) * x;\n          for (i = 0; i < 5; ++i)\n            i_state[j] += h_state[i] * ldg(&d_intW[j*5+i]);\n          i_state[j] += ldg(&d_intB[j]);\n          i_state[j] = sigmoid(i_state[j]);\n        }\n        \n        for (j = 0; j < 5; ++j) {\n          f_state[j] = ldg(&d_inW[5+j]) * x;\n          for (i = 0; i < 5; ++i)\n            f_state[j] += h_state[i] * ldg(&d_intW[25+j*5+i]);\n          f_state[j] += ldg(&d_intB[5+j]);\n          f_state[j] = sigmoid(f_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          o_state[j] = ldg(&d_inW[10+j]) * x;\n          for (i = 0; i < 5; ++i)\n            o_state[j] += h_state[i] * ldg(&d_intW[50+j*5+i]);\n          o_state[j] += ldg(&d_intB[10+j]);\n          o_state[j] = sigmoid(o_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          g_state[j] = ldg(&d_inW[15+j]) * x;\n          for (i = 0; i < 5; ++i)\n            g_state[j] += h_state[i] * ldg(&d_intW[75+j*5+i]);\n          g_state[j] += ldg(&d_intB[15+j]);\n          g_state[j] = sycl::tanh(g_state[j]);\n        }\n\n        for (j = 0; j < 5; ++j) {\n          c_state[j] = c_state[j] * f_state[j] + g_state[j] * i_state[j];\n          h_state[j] = sycl::tanh(c_state[j]) * o_state[j];\n        }\n\n        float y = ldg(&d_outB[0]);\n        for (j = 0; j < 5; ++j)\n          y += h_state[j] * ldg(&d_outW[j]);\n        d_y[gid * SAMPLE_TEST_LEN + t] = y;\n      }\n    });\n  }).wait();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  q.memcpy(y, d_y, sizeof(float) * N * SAMPLE_TEST_LEN).wait();\n  sycl::free(d_x ,q);\n  sycl::free(d_inW ,q);\n  sycl::free(d_intW ,q);\n  sycl::free(d_intB ,q);\n  sycl::free(d_outW ,q);\n  sycl::free(d_outB ,q);\n  sycl::free(d_y ,q);\n  return time;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  float* sample_input = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer1_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n  float* infer2_out = (float*) aligned_alloc(64, sizeof(float)*N*SAMPLE_TEST_LEN);\n\n  float inW[20], intW[100], intB[20], outW[5];\n  float outB;\n\n  const char* work_path = \"./\";\n  const char* input_filename = \"input.hpp\";\n  const char* weight1_filename = \"weight_1.hpp\";\n  const char* weight2_filename = \"weight_2.hpp\";\n#ifdef DEBUG\n  const char* result1_filename = \"float_infer_result_1.hpp\";\n  const char* result2_filename = \"float_infer_result_2.hpp\";\n#endif\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  long kernel_time = 0;\n  for (int n = 0; n < repeat; n++) {\n    init(work_path, input_filename, weight1_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    auto start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(q, sample_input, inW, intW, intB, outW, &outB, infer1_out);\n    auto end = std::chrono::steady_clock::now();\n    auto elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result1_filename, infer1_out);\n#endif\n\n    init(work_path, input_filename, weight2_filename, sample_input, inW, intW, intB, outW, &outB) ;\n    start = std::chrono::steady_clock::now();\n    kernel_time += lstm_n5(q, sample_input, inW, intW, intB, outW, &outB, infer2_out);\n    end = std::chrono::steady_clock::now();\n    elapsedTime =\n      std::chrono::duration_cast<std::chrono::milliseconds>(end-start).count();\n    std::cout << \"Device offload time: \" <<  elapsedTime << \" ms\\n\";\n\n#ifdef DEBUG\n    dump(work_path, result2_filename, infer2_out);\n#endif\n  }\n  std::cout << \"Average kernel time: \" <<  kernel_time * 1e-6 / (2 * repeat) << \" ms\\n\";\n\n  free(sample_input);\n  free(infer1_out);\n  free(infer2_out);\n  printf(\"Processing complete.\\n\");\n  return 0;\n}\n"}}
{"kernel_name": "concat", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\ntemplate <typename T>\n__global__\nvoid concat (const T *__restrict__ inp1,\n             const T *__restrict__ inp2,\n                   T *output,\n             int sz0, int sz2, int sz1_1, int sz1_2)\n{\n  int nele = sz0 * sz2 * (sz1_1 + sz1_2);\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx >= nele) return;\n\n  float *dst_ptr = (float *)output + idx;\n  int idx2 = idx % sz2;\n  idx = idx / sz2;\n  int idx1 = idx % (sz1_1 + sz1_2);\n  int idx0 = idx / (sz1_1 + sz1_2);\n  float *src_ptr;\n  int sz1;\n  if (idx1 < sz1_1) {\n    sz1 = sz1_1;\n    src_ptr = (float *)inp1;\n  } else {\n    idx1 -= sz1_1;\n    sz1 = sz1_2;\n    src_ptr = (float *)inp2;\n  }\n  src_ptr += flat_3dim(idx0, idx1, idx2, sz1, sz2);\n  *dst_ptr = *src_ptr;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  for (int nhead = 6; nhead <= 48; nhead *= 2) {\n    srand(nhead);\n\n    const int seq_len = 1024;\n    const int batch_size = 8;\n    const int hidden_dim = nhead * 128;\n    const int head_dim = hidden_dim / nhead;\n\n    const int sl1 = rand() % (seq_len - 1) + 1;\n    const int sl2 = seq_len - sl1;\n    const int beam_size = 8;\n\n    printf(\"\\n\");\n    printf(\"num_head = %d\\t\", nhead);\n    printf(\"seq_len = %d\\t\", seq_len);\n    printf(\"batch_size = %d\\t\", batch_size);\n    printf(\"hidden_dimension = %d\\t\", hidden_dim);\n    printf(\"beam_size = %d\\n\", beam_size);\n\n    const size_t inp1_size = batch_size * beam_size * hidden_dim * sl1;\n    const size_t inp2_size = batch_size * beam_size * hidden_dim * sl2;\n    const size_t outp_size = batch_size * beam_size * hidden_dim * seq_len;\n\n    const size_t inp1_size_bytes = inp1_size * sizeof(float);\n    const size_t inp2_size_bytes = inp2_size * sizeof(float);\n    const size_t outp_size_bytes = outp_size * sizeof(float);\n\n    float size_bytes = 2 * outp_size_bytes * 1e-9;\n    printf(\"Total device memory usage (GB) = %.2f\\n\", size_bytes);\n\n    float *inp1 = (float*) malloc (inp1_size_bytes);\n    float *inp2 = (float*) malloc (inp2_size_bytes);\n    float *outp = (float*) malloc (outp_size_bytes);\n    float *outp_ref = (float*) malloc (outp_size_bytes);\n\n    for (size_t i = 0; i < inp1_size; i++) {\n      inp1[i] = rand() % inp1_size; \n    }\n\n    for (size_t i = 0; i < inp2_size; i++) {\n      inp2[i] = rand() % inp2_size; \n    }\n\n    float *d_inp1, *d_inp2, *d_outp;\n\n    cudaMalloc ((void**)&d_inp1, inp1_size_bytes);\n    cudaMalloc ((void**)&d_inp2, inp2_size_bytes);\n    cudaMalloc ((void**)&d_outp, outp_size_bytes);\n    cudaMemcpy (d_inp1, inp1, inp1_size_bytes, cudaMemcpyHostToDevice);\n    cudaMemcpy (d_inp2, inp2, inp2_size_bytes, cudaMemcpyHostToDevice);\n\n    const size_t n = batch_size * beam_size * nhead * head_dim * (sl1 + sl2);\n    const size_t nblock = (n + 255) / 256;\n\n    \n\n    concat <<<nblock, 256>>>(\n      d_inp1, d_inp2, d_outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n\n    concat_cpu(\n      inp1, inp2, outp_ref, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n     \n    cudaDeviceSynchronize();\n\n    cudaMemcpy (outp, d_outp, outp_size_bytes, cudaMemcpyDeviceToHost);\n    int error = memcmp(outp_ref, outp, outp_size_bytes);\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      concat <<<nblock, 256>>>(\n          d_inp1, d_inp2, d_outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    float avg_time = (time * 1e-3f) / repeat;\n    printf(\"Average kernel execution time: %f (us)\\n\", avg_time);\n    printf(\"Average kernel throughput : %f (GB/s)\\n\", size_bytes / (avg_time * 1e-6));\n\n    cudaFree(d_inp1);\n    cudaFree(d_inp2);\n    cudaFree(d_outp);\n    free(inp1);\n    free(inp2);\n    free(outp);\n  }\n}\n"}}
{"kernel_name": "concat", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\ntemplate <typename T>\n__global__\nvoid concat (const T *__restrict__ inp1,\n             const T *__restrict__ inp2,\n                   T *output,\n             int sz0, int sz2, int sz1_1, int sz1_2)\n{\n  int nele = sz0 * sz2 * (sz1_1 + sz1_2);\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx >= nele) return;\n\n  float *dst_ptr = (float *)output + idx;\n  int idx2 = idx % sz2;\n  idx = idx / sz2;\n  int idx1 = idx % (sz1_1 + sz1_2);\n  int idx0 = idx / (sz1_1 + sz1_2);\n  float *src_ptr;\n  int sz1;\n  if (idx1 < sz1_1) {\n    sz1 = sz1_1;\n    src_ptr = (float *)inp1;\n  } else {\n    idx1 -= sz1_1;\n    sz1 = sz1_2;\n    src_ptr = (float *)inp2;\n  }\n  src_ptr += flat_3dim(idx0, idx1, idx2, sz1, sz2);\n  *dst_ptr = *src_ptr;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  for (int nhead = 6; nhead <= 48; nhead *= 2) {\n    srand(nhead);\n\n    const int seq_len = 1024;\n    const int batch_size = 8;\n    const int hidden_dim = nhead * 128;\n    const int head_dim = hidden_dim / nhead;\n\n    const int sl1 = rand() % (seq_len - 1) + 1;\n    const int sl2 = seq_len - sl1;\n    const int beam_size = 8;\n\n    printf(\"\\n\");\n    printf(\"num_head = %d\\t\", nhead);\n    printf(\"seq_len = %d\\t\", seq_len);\n    printf(\"batch_size = %d\\t\", batch_size);\n    printf(\"hidden_dimension = %d\\t\", hidden_dim);\n    printf(\"beam_size = %d\\n\", beam_size);\n\n    const size_t inp1_size = batch_size * beam_size * hidden_dim * sl1;\n    const size_t inp2_size = batch_size * beam_size * hidden_dim * sl2;\n    const size_t outp_size = batch_size * beam_size * hidden_dim * seq_len;\n\n    const size_t inp1_size_bytes = inp1_size * sizeof(float);\n    const size_t inp2_size_bytes = inp2_size * sizeof(float);\n    const size_t outp_size_bytes = outp_size * sizeof(float);\n\n    float size_bytes = 2 * outp_size_bytes * 1e-9;\n    printf(\"Total device memory usage (GB) = %.2f\\n\", size_bytes);\n\n    float *inp1 = (float*) malloc (inp1_size_bytes);\n    float *inp2 = (float*) malloc (inp2_size_bytes);\n    float *outp = (float*) malloc (outp_size_bytes);\n    float *outp_ref = (float*) malloc (outp_size_bytes);\n\n    for (size_t i = 0; i < inp1_size; i++) {\n      inp1[i] = rand() % inp1_size; \n    }\n\n    for (size_t i = 0; i < inp2_size; i++) {\n      inp2[i] = rand() % inp2_size; \n    }\n\n    float *d_inp1, *d_inp2, *d_outp;\n\n    hipMalloc ((void**)&d_inp1, inp1_size_bytes);\n    hipMalloc ((void**)&d_inp2, inp2_size_bytes);\n    hipMalloc ((void**)&d_outp, outp_size_bytes);\n    hipMemcpy (d_inp1, inp1, inp1_size_bytes, hipMemcpyHostToDevice);\n    hipMemcpy (d_inp2, inp2, inp2_size_bytes, hipMemcpyHostToDevice);\n\n    const size_t n = batch_size * beam_size * nhead * head_dim * (sl1 + sl2);\n    const size_t nblock = (n + 255) / 256;\n\n    \n\n    concat <<<nblock, 256>>>(\n      d_inp1, d_inp2, d_outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n\n    concat_cpu(\n      inp1, inp2, outp_ref, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n     \n    hipDeviceSynchronize();\n\n    hipMemcpy (outp, d_outp, outp_size_bytes, hipMemcpyDeviceToHost);\n    int error = memcmp(outp_ref, outp, outp_size_bytes);\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      concat <<<nblock, 256>>>(\n          d_inp1, d_inp2, d_outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    float avg_time = (time * 1e-3f) / repeat;\n    printf(\"Average kernel execution time: %f (us)\\n\", avg_time);\n    printf(\"Average kernel throughput : %f (GB/s)\\n\", size_bytes / (avg_time * 1e-6));\n\n    hipFree(d_inp1);\n    hipFree(d_inp2);\n    hipFree(d_outp);\n    free(inp1);\n    free(inp2);\n    free(outp);\n  }\n}\n"}}
{"kernel_name": "concat", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\ntemplate <typename T>\nvoid concat (const T *__restrict inp1,\n             const T *__restrict inp2,\n                   T *output,\n             int sz0, int sz2, int sz1_1, int sz1_2)\n{\n  int nele = sz0 * sz2 * (sz1_1 + sz1_2);\n\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int idx = 0; idx < nele; idx++) {\n    float *dst_ptr = (float *)output + idx;\n    int idx2 = idx % sz2;\n    idx = idx / sz2;\n    int idx1 = idx % (sz1_1 + sz1_2);\n    int idx0 = idx / (sz1_1 + sz1_2);\n    float *src_ptr;\n    int sz1;\n    if (idx1 < sz1_1) {\n      sz1 = sz1_1;\n      src_ptr = (float *)inp1;\n    } else {\n      idx1 -= sz1_1;\n      sz1 = sz1_2;\n      src_ptr = (float *)inp2;\n    }\n    src_ptr += flat_3dim(idx0, idx1, idx2, sz1, sz2);\n    *dst_ptr = *src_ptr;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  for (int nhead = 6; nhead <= 48; nhead *= 2) {\n    srand(nhead);\n\n    const int seq_len = 1024;\n    const int batch_size = 8;\n    const int hidden_dim = nhead * 128;\n    const int head_dim = hidden_dim / nhead;\n\n    const int sl1 = rand() % (seq_len - 1) + 1;\n    const int sl2 = seq_len - sl1;\n    const int beam_size = 8;\n\n    printf(\"\\n\");\n    printf(\"num_head = %d\\t\", nhead);\n    printf(\"seq_len = %d\\t\", seq_len);\n    printf(\"batch_size = %d\\t\", batch_size);\n    printf(\"hidden_dimension = %d\\t\", hidden_dim);\n    printf(\"beam_size = %d\\n\", beam_size);\n\n    const size_t inp1_size = batch_size * beam_size * hidden_dim * sl1;\n    const size_t inp2_size = batch_size * beam_size * hidden_dim * sl2;\n    const size_t outp_size = batch_size * beam_size * hidden_dim * seq_len;\n\n    const size_t inp1_size_bytes = inp1_size * sizeof(float);\n    const size_t inp2_size_bytes = inp2_size * sizeof(float);\n    const size_t outp_size_bytes = outp_size * sizeof(float);\n\n    float size_bytes = 2 * outp_size_bytes * 1e-9;\n    printf(\"Total device memory usage (GB) = %.2f\\n\", size_bytes);\n\n    float *inp1 = (float*) malloc (inp1_size_bytes);\n    float *inp2 = (float*) malloc (inp2_size_bytes);\n    float *outp = (float*) malloc (outp_size_bytes);\n    float *outp_ref = (float*) malloc (outp_size_bytes);\n\n    for (size_t i = 0; i < inp1_size; i++) {\n      inp1[i] = rand() % inp1_size; \n    }\n\n    for (size_t i = 0; i < inp2_size; i++) {\n      inp2[i] = rand() % inp2_size; \n    }\n\n    #pragma omp target data map (to: inp1[0:inp1_size], inp2[0:inp2_size]) \\\n                            map (alloc: outp[0:outp_size])\n    {\n      \n\n      concat(inp1, inp2, outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n      #pragma omp target update from (outp[0:outp_size])\n\n      concat_cpu(\n        inp1, inp2, outp_ref, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n      int error = memcmp(outp_ref, outp, outp_size_bytes);\n      printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        concat(inp1, inp2, outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      float avg_time = (time * 1e-3f) / repeat;\n      printf(\"Average kernel execution time: %f (us)\\n\", avg_time);\n      printf(\"Average kernel throughput : %f (GB/s)\\n\", size_bytes / (avg_time * 1e-6));\n    }\n\n    free(inp1);\n    free(inp2);\n    free(outp);\n  }\n}\n"}}
{"kernel_name": "concat", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include \"reference.h\"\n\ntemplate <typename T>\nvoid concat (const T *__restrict inp1,\n             const T *__restrict inp2,\n                   T *output,\n             int sz0, int sz2, int sz1_1, int sz1_2)\n{\n  int nele = sz0 * sz2 * (sz1_1 + sz1_2);\n\n    for (int idx = 0; idx < nele; idx++) {\n    float *dst_ptr = (float *)output + idx;\n    int idx2 = idx % sz2;\n    idx = idx / sz2;\n    int idx1 = idx % (sz1_1 + sz1_2);\n    int idx0 = idx / (sz1_1 + sz1_2);\n    float *src_ptr;\n    int sz1;\n    if (idx1 < sz1_1) {\n      sz1 = sz1_1;\n      src_ptr = (float *)inp1;\n    } else {\n      idx1 -= sz1_1;\n      sz1 = sz1_2;\n      src_ptr = (float *)inp2;\n    }\n    src_ptr += flat_3dim(idx0, idx1, idx2, sz1, sz2);\n    *dst_ptr = *src_ptr;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  for (int nhead = 6; nhead <= 48; nhead *= 2) {\n    srand(nhead);\n\n    const int seq_len = 1024;\n    const int batch_size = 8;\n    const int hidden_dim = nhead * 128;\n    const int head_dim = hidden_dim / nhead;\n\n    const int sl1 = rand() % (seq_len - 1) + 1;\n    const int sl2 = seq_len - sl1;\n    const int beam_size = 8;\n\n    printf(\"\\n\");\n    printf(\"num_head = %d\\t\", nhead);\n    printf(\"seq_len = %d\\t\", seq_len);\n    printf(\"batch_size = %d\\t\", batch_size);\n    printf(\"hidden_dimension = %d\\t\", hidden_dim);\n    printf(\"beam_size = %d\\n\", beam_size);\n\n    const size_t inp1_size = batch_size * beam_size * hidden_dim * sl1;\n    const size_t inp2_size = batch_size * beam_size * hidden_dim * sl2;\n    const size_t outp_size = batch_size * beam_size * hidden_dim * seq_len;\n\n    const size_t inp1_size_bytes = inp1_size * sizeof(float);\n    const size_t inp2_size_bytes = inp2_size * sizeof(float);\n    const size_t outp_size_bytes = outp_size * sizeof(float);\n\n    float size_bytes = 2 * outp_size_bytes * 1e-9;\n    printf(\"Total device memory usage (GB) = %.2f\\n\", size_bytes);\n\n    float *inp1 = (float*) malloc (inp1_size_bytes);\n    float *inp2 = (float*) malloc (inp2_size_bytes);\n    float *outp = (float*) malloc (outp_size_bytes);\n    float *outp_ref = (float*) malloc (outp_size_bytes);\n\n    for (size_t i = 0; i < inp1_size; i++) {\n      inp1[i] = rand() % inp1_size; \n    }\n\n    for (size_t i = 0; i < inp2_size; i++) {\n      inp2[i] = rand() % inp2_size; \n    }\n\n        {\n      \n\n      concat(inp1, inp2, outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n      \n      concat_cpu(\n        inp1, inp2, outp_ref, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n      int error = memcmp(outp_ref, outp, outp_size_bytes);\n      printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        concat(inp1, inp2, outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      float avg_time = (time * 1e-3f) / repeat;\n      printf(\"Average kernel execution time: %f (us)\\n\", avg_time);\n      printf(\"Average kernel throughput : %f (GB/s)\\n\", size_bytes / (avg_time * 1e-6));\n    }\n\n    free(inp1);\n    free(inp2);\n    free(outp);\n  }\n}"}}
{"kernel_name": "concat", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\ntemplate <typename T>\nvoid concat (sycl::nd_item<1> &item,\n             const T *__restrict inp1,\n             const T *__restrict inp2,\n                   T *output,\n             int sz0, int sz2, int sz1_1, int sz1_2)\n{\n  int nele = sz0 * sz2 * (sz1_1 + sz1_2);\n  int idx = item.get_global_id(0);\n  if (idx >= nele) return;\n\n  float *dst_ptr = (float *)output + idx;\n  int idx2 = idx % sz2;\n  idx = idx / sz2;\n  int idx1 = idx % (sz1_1 + sz1_2);\n  int idx0 = idx / (sz1_1 + sz1_2);\n  float *src_ptr;\n  int sz1;\n  if (idx1 < sz1_1) {\n    sz1 = sz1_1;\n    src_ptr = (float *)inp1;\n  } else {\n    idx1 -= sz1_1;\n    sz1 = sz1_2;\n    src_ptr = (float *)inp2;\n  }\n  src_ptr += flat_3dim(idx0, idx1, idx2, sz1, sz2);\n  *dst_ptr = *src_ptr;\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  for (int nhead = 6; nhead <= 48; nhead *= 2) {\n    srand(nhead);\n\n    const int seq_len = 1024;\n    const int batch_size = 8;\n    const int hidden_dim = nhead * 128;\n    const int head_dim = hidden_dim / nhead;\n\n    const int sl1 = rand() % (seq_len - 1) + 1;\n    const int sl2 = seq_len - sl1;\n    const int beam_size = 8;\n\n    printf(\"\\n\");\n    printf(\"num_head = %d\\t\", nhead);\n    printf(\"seq_len = %d\\t\", seq_len);\n    printf(\"batch_size = %d\\t\", batch_size);\n    printf(\"hidden_dimension = %d\\t\", hidden_dim);\n    printf(\"beam_size = %d\\n\", beam_size);\n\n    const size_t inp1_size = batch_size * beam_size * hidden_dim * sl1;\n    const size_t inp2_size = batch_size * beam_size * hidden_dim * sl2;\n    const size_t outp_size = batch_size * beam_size * hidden_dim * seq_len;\n\n    const size_t inp1_size_bytes = inp1_size * sizeof(float);\n    const size_t inp2_size_bytes = inp2_size * sizeof(float);\n    const size_t outp_size_bytes = outp_size * sizeof(float);\n\n    float size_bytes = 2 * outp_size_bytes * 1e-9;\n    printf(\"Total device memory usage (GB) = %.2f\\n\", size_bytes);\n\n    float *inp1 = (float*) malloc (inp1_size_bytes);\n    float *inp2 = (float*) malloc (inp2_size_bytes);\n    float *outp = (float*) malloc (outp_size_bytes);\n    float *outp_ref = (float*) malloc (outp_size_bytes);\n\n    for (size_t i = 0; i < inp1_size; i++) {\n      inp1[i] = rand() % inp1_size; \n    }\n\n    for (size_t i = 0; i < inp2_size; i++) {\n      inp2[i] = rand() % inp2_size; \n    }\n\n    float *d_inp1, *d_inp2, *d_outp;\n\n    d_inp1 = (float *)sycl::malloc_device(inp1_size_bytes, q);\n    d_inp2 = (float *)sycl::malloc_device(inp2_size_bytes, q);\n    d_outp = (float *)sycl::malloc_device(outp_size_bytes, q);\n    q.memcpy(d_inp1, inp1, inp1_size_bytes);\n    q.memcpy(d_inp2, inp2, inp2_size_bytes);\n\n    const size_t n = batch_size * beam_size * nhead * head_dim * (sl1 + sl2);\n    const size_t nblock = (n + 255) / 256;\n    sycl::range<1> gws (nblock * 256);\n    sycl::range<1> lws (256);\n\n    \n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class warmup>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        concat(item, d_inp1, d_inp2, d_outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n      });\n    });\n\n    concat_cpu(\n      inp1, inp2, outp_ref, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n\n    q.memcpy (outp, d_outp, outp_size_bytes).wait();\n    int error = memcmp(outp_ref, outp, outp_size_bytes);\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class eval>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n          concat(item, d_inp1, d_inp2, d_outp, batch_size * beam_size * nhead, head_dim, sl1, sl2);\n        });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    float avg_time = (time * 1e-3f) / repeat;\n    printf(\"Average kernel execution time: %f (us)\\n\", avg_time);\n    printf(\"Average kernel throughput : %f (GB/s)\\n\", size_bytes / (avg_time * 1e-6));\n\n    sycl::free(d_inp1, q);\n    sycl::free(d_inp2, q);\n    sycl::free(d_outp, q);\n    free(inp1);\n    free(inp2);\n    free(outp);\n  }\n}\n"}}
{"kernel_name": "dense-embedding", "parallel_api": "cuda", "code": {"main.cu": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n\ntemplate <typename T>\nvoid reference(\n    const T* input,\n    const T* dense,\n    T* output,\n    int embedding_dim,\n    int batch_size,\n    const int* offset)\n{\n  for (int batch_idx = 0; batch_idx < batch_size; batch_idx++) {\n    const int range = offset[batch_idx + 1] - offset[batch_idx];\n    for (int idx = 0; idx < embedding_dim; idx++) {\n      const T dense_elem = dense[batch_idx * embedding_dim + idx];\n      for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n        output[offset[batch_idx] + nested_idx] =\n          input[offset[batch_idx] + nested_idx] + dense_elem;\n      }\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void dense_esuhm(\n    const T* input,\n    const T* dense,\n          T* output,\n    int embedding_dim,\n    const int* offset)\n{\n  const int batch_idx  = blockIdx.x; \n\n  const int grain_size = blockDim.x;\n  const int tid = threadIdx.x;\n  const int range = offset[batch_idx + 1] - offset[batch_idx];\n  for (int idx = tid; idx < embedding_dim; idx += grain_size) {\n    const T dense_elem = dense[batch_idx * embedding_dim + idx];\n    for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n      output[offset[batch_idx] + nested_idx] = input[offset[batch_idx] + nested_idx] + dense_elem;\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void dense_esuhm2(\n    const T* input,\n    const T* dense,\n          T* output,\n    int embedding_dim,\n    const int* offset)\n{\n  const int batch_idx  = blockIdx.x;\n  const int start = offset[batch_idx];\n  const int range = offset[batch_idx + 1] - start;\n  for (int idx = threadIdx.x; idx < embedding_dim; idx += blockDim.x) {\n    const T dense_elem = dense[batch_idx * embedding_dim + idx];\n    for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n      output[start + nested_idx] = input[start + nested_idx] + dense_elem;\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int batch_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n  assert(nrows > batch_size * batch_size);\n\n  printf(\"Number of rows in the embedding table: %d\\n\", nrows);\n  printf(\"Batch size: %d\\n\", batch_size);\n\n  const int embed_dims[] = {768, 2048, 12288};\n\n  for (size_t n = 0; n < sizeof(embed_dims)/sizeof(int); n++) {\n    int ncols = embed_dims[n];\n    printf(\"\\nEmbedding dimension: %d\\n\", ncols);\n\n    int input_size = nrows * ncols;  \n\n    size_t input_size_bytes = input_size * sizeof(float);\n\n    int dense_size = batch_size * ncols ;\n    int dense_size_bytes = dense_size * sizeof(float);\n\n    int batch_size_bytes = (batch_size + 1) * sizeof(float);\n\n    float *input, *dense, *output_k1, *output_k2, *output_ref;\n    input = (float*) malloc (input_size_bytes); \n\n    dense = (float*) malloc (dense_size_bytes); \n\n    output_k1 = (float*) malloc (input_size_bytes); \n\n    output_k2 = (float*) malloc (input_size_bytes); \n\n    output_ref = (float*) malloc (input_size_bytes); \n\n    int *input_offset = (int*) malloc (batch_size_bytes);  \n\n\n    \n\n    \n\n    \n\n    \n\n    srand(123);\n    input_offset[0] = 0;\n    for (int i = 1; i <= batch_size; i++)\n      input_offset[i] = input_offset[i-1] + (rand() % batch_size + 1) * ncols;\n\n    std::default_random_engine g (123);\n    std::uniform_real_distribution<float> distr (-1.f, 1.f);\n    for (int i = 0; i < dense_size; i++) {\n      dense[i] = distr(g);\n    }\n\n    for (int i = 0; i < input_size; i++) {\n      input[i] = distr(g);\n      output_ref[i] = 0;\n    }\n\n    reference(input, dense, output_ref, ncols, batch_size, input_offset);\n\n    float *d_input, *d_dense, *d_output;\n    cudaMalloc((void**)&d_input, input_size_bytes);\n    cudaMemcpy(d_input, input, input_size_bytes, cudaMemcpyHostToDevice);\n\n    cudaMalloc((void**)&d_dense, dense_size_bytes);\n    cudaMemcpy(d_dense, dense, dense_size_bytes, cudaMemcpyHostToDevice);\n\n    cudaMalloc((void**)&d_output, input_size_bytes);\n\n    int* d_input_offset;\n    cudaMalloc((void**)&d_input_offset, batch_size_bytes);\n    cudaMemcpy(d_input_offset, input_offset, batch_size_bytes, cudaMemcpyHostToDevice);\n\n    for (int block_size = 128; block_size <= 1024; block_size = block_size * 2) {\n      printf(\"block size: %d\\n\", block_size);\n\n      cudaMemset(d_output, 0, input_size_bytes);\n      cudaDeviceSynchronize();\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++)\n        dense_esuhm<<<batch_size, block_size>>>(d_input, d_dense, d_output, ncols, d_input_offset);\n\n      cudaDeviceSynchronize();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of dense embedding kernel (k1): %f (us)\\n\", (time * 1e-3f) / repeat);\n      cudaMemcpy(output_k1, d_output, input_size_bytes, cudaMemcpyDeviceToHost);\n\n      cudaMemset(d_output, 0, input_size_bytes);\n      cudaDeviceSynchronize();\n      start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++)\n        dense_esuhm2<<<batch_size, block_size>>>(d_input, d_dense, d_output, ncols, d_input_offset);\n\n      cudaDeviceSynchronize();\n      end = std::chrono::steady_clock::now();\n      time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of dense embedding kernel (k2): %f (us)\\n\", (time * 1e-3f) / repeat);\n      cudaMemcpy(output_k2, d_output, input_size_bytes, cudaMemcpyDeviceToHost);\n\n      bool ok = true;\n      for (int i = 0; i < input_size; i++) {\n        if (fabsf(output_k1[i] - output_ref[i]) > 1e-3f ||\n            fabsf(output_k2[i] - output_ref[i]) > 1e-3f) {\n          ok = false;\n          break;\n        }\n      }\n      printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n    }\n\n    cudaFree(d_input);\n    cudaFree(d_dense);\n    cudaFree(d_output);\n    cudaFree(d_input_offset);\n\n    free(input);\n    free(dense);\n    free(output_k1);\n    free(output_k2);\n    free(output_ref);\n    free(input_offset);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "dense-embedding", "parallel_api": "hip", "code": {"main.cu": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n\ntemplate <typename T>\nvoid reference(\n    const T* input,\n    const T* dense,\n    T* output,\n    int embedding_dim,\n    int batch_size,\n    const int* offset)\n{\n  for (int batch_idx = 0; batch_idx < batch_size; batch_idx++) {\n    const int range = offset[batch_idx + 1] - offset[batch_idx];\n    for (int idx = 0; idx < embedding_dim; idx++) {\n      const T dense_elem = dense[batch_idx * embedding_dim + idx];\n      for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n        output[offset[batch_idx] + nested_idx] =\n          input[offset[batch_idx] + nested_idx] + dense_elem;\n      }\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void dense_esuhm(\n    const T* input,\n    const T* dense,\n          T* output,\n    int embedding_dim,\n    const int* offset)\n{\n  const int batch_idx  = blockIdx.x; \n\n  const int grain_size = blockDim.x;\n  const int tid = threadIdx.x;\n  const int range = offset[batch_idx + 1] - offset[batch_idx];\n  for (int idx = tid; idx < embedding_dim; idx += grain_size) {\n    const T dense_elem = dense[batch_idx * embedding_dim + idx];\n    for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n      output[offset[batch_idx] + nested_idx] = input[offset[batch_idx] + nested_idx] + dense_elem;\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void dense_esuhm2(\n    const T* input,\n    const T* dense,\n          T* output,\n    int embedding_dim,\n    const int* offset)\n{\n  const int batch_idx  = blockIdx.x;\n  const int start = offset[batch_idx];\n  const int range = offset[batch_idx + 1] - start;\n  for (int idx = threadIdx.x; idx < embedding_dim; idx += blockDim.x) {\n    const T dense_elem = dense[batch_idx * embedding_dim + idx];\n    for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n      output[start + nested_idx] = input[start + nested_idx] + dense_elem;\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int batch_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n  assert(nrows > batch_size * batch_size);\n\n  printf(\"Number of rows in the embedding table: %d\\n\", nrows);\n  printf(\"Batch size: %d\\n\", batch_size);\n\n  const int embed_dims[] = {768, 2048, 12288};\n\n  for (size_t n = 0; n < sizeof(embed_dims)/sizeof(int); n++) {\n    int ncols = embed_dims[n];\n    printf(\"\\nEmbedding dimension: %d\\n\", ncols);\n\n    int input_size = nrows * ncols;  \n\n    size_t input_size_bytes = input_size * sizeof(float);\n\n    int dense_size = batch_size * ncols ;\n    int dense_size_bytes = dense_size * sizeof(float);\n\n    int batch_size_bytes = (batch_size + 1) * sizeof(float);\n\n    float *input, *dense, *output_k1, *output_k2, *output_ref;\n    input = (float*) malloc (input_size_bytes); \n\n    dense = (float*) malloc (dense_size_bytes); \n\n    output_k1 = (float*) malloc (input_size_bytes); \n\n    output_k2 = (float*) malloc (input_size_bytes); \n\n    output_ref = (float*) malloc (input_size_bytes); \n\n    int *input_offset = (int*) malloc (batch_size_bytes);  \n\n\n    \n\n    \n\n    \n\n    \n\n    srand(123);\n    input_offset[0] = 0;\n    for (int i = 1; i <= batch_size; i++)\n      input_offset[i] = input_offset[i-1] + (rand() % batch_size + 1) * ncols;\n\n    std::default_random_engine g (123);\n    std::uniform_real_distribution<float> distr (-1.f, 1.f);\n    for (int i = 0; i < dense_size; i++) {\n      dense[i] = distr(g);\n    }\n\n    for (int i = 0; i < input_size; i++) {\n      input[i] = distr(g);\n      output_ref[i] = 0;\n    }\n\n    reference(input, dense, output_ref, ncols, batch_size, input_offset);\n\n    float *d_input, *d_dense, *d_output;\n    hipMalloc((void**)&d_input, input_size_bytes);\n    hipMemcpy(d_input, input, input_size_bytes, hipMemcpyHostToDevice);\n\n    hipMalloc((void**)&d_dense, dense_size_bytes);\n    hipMemcpy(d_dense, dense, dense_size_bytes, hipMemcpyHostToDevice);\n\n    hipMalloc((void**)&d_output, input_size_bytes);\n\n    int* d_input_offset;\n    hipMalloc((void**)&d_input_offset, batch_size_bytes);\n    hipMemcpy(d_input_offset, input_offset, batch_size_bytes, hipMemcpyHostToDevice);\n\n    for (int block_size = 128; block_size <= 1024; block_size = block_size * 2) {\n      printf(\"block size: %d\\n\", block_size);\n\n      hipMemset(d_output, 0, input_size_bytes);\n      hipDeviceSynchronize();\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++)\n        dense_esuhm<<<batch_size, block_size>>>(d_input, d_dense, d_output, ncols, d_input_offset);\n\n      hipDeviceSynchronize();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of dense embedding kernel (k1): %f (us)\\n\", (time * 1e-3f) / repeat);\n      hipMemcpy(output_k1, d_output, input_size_bytes, hipMemcpyDeviceToHost);\n\n      hipMemset(d_output, 0, input_size_bytes);\n      hipDeviceSynchronize();\n      start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++)\n        dense_esuhm2<<<batch_size, block_size>>>(d_input, d_dense, d_output, ncols, d_input_offset);\n\n      hipDeviceSynchronize();\n      end = std::chrono::steady_clock::now();\n      time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of dense embedding kernel (k2): %f (us)\\n\", (time * 1e-3f) / repeat);\n      hipMemcpy(output_k2, d_output, input_size_bytes, hipMemcpyDeviceToHost);\n\n      bool ok = true;\n      for (int i = 0; i < input_size; i++) {\n        if (fabsf(output_k1[i] - output_ref[i]) > 1e-3f ||\n            fabsf(output_k2[i] - output_ref[i]) > 1e-3f) {\n          ok = false;\n          break;\n        }\n      }\n      printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n    }\n\n    hipFree(d_input);\n    hipFree(d_dense);\n    hipFree(d_output);\n    hipFree(d_input_offset);\n\n    free(input);\n    free(dense);\n    free(output_k1);\n    free(output_k2);\n    free(output_ref);\n    free(input_offset);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "dense-embedding", "parallel_api": "omp", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n\ntemplate <typename T>\nvoid reference(\n    const T* input,\n    const T* dense,\n    T* output,\n    int embedding_dim,\n    int batch_size,\n    const int* offset)\n{\n  for (int batch_idx = 0; batch_idx < batch_size; batch_idx++) {\n    const int range = offset[batch_idx + 1] - offset[batch_idx];\n    for (int idx = 0; idx < embedding_dim; idx++) {\n      const T dense_elem = dense[batch_idx * embedding_dim + idx];\n      for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n        output[offset[batch_idx] + nested_idx] =\n          input[offset[batch_idx] + nested_idx] + dense_elem;\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int batch_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n  assert(nrows > batch_size * batch_size);\n\n  printf(\"Number of rows in the embedding table: %d\\n\", nrows);\n  printf(\"Batch size: %d\\n\", batch_size);\n\n  const int embed_dims[] = {768, 2048, 12288};\n\n  for (size_t n = 0; n < sizeof(embed_dims)/sizeof(int); n++) {\n    int ncols = embed_dims[n];\n    printf(\"\\nEmbedding dimension: %d\\n\", ncols);\n\n    int input_size = nrows * ncols;  \n\n    size_t input_size_bytes = input_size * sizeof(float);\n\n    int dense_size = batch_size * ncols ;\n    int dense_size_bytes = dense_size * sizeof(float);\n\n    int batch_size_bytes = (batch_size + 1) * sizeof(float);\n\n    float *input, *dense, *output_k1, *output_k2, *output_ref;\n    input = (float*) malloc (input_size_bytes); \n\n    dense = (float*) malloc (dense_size_bytes); \n\n    output_k1 = (float*) malloc (input_size_bytes); \n\n    output_k2 = (float*) malloc (input_size_bytes); \n\n    output_ref = (float*) malloc (input_size_bytes); \n\n    int *offset = (int*) malloc (batch_size_bytes);  \n\n\n    \n\n    \n\n    \n\n    \n\n    srand(123);\n    offset[0] = 0;\n    for (int i = 1; i <= batch_size; i++)\n      offset[i] = offset[i-1] + (rand() % batch_size + 1) * ncols;\n\n    std::default_random_engine g (123);\n    std::uniform_real_distribution<float> distr (-1.f, 1.f);\n    for (int i = 0; i < dense_size; i++) {\n      dense[i] = distr(g);\n    }\n\n    for (int i = 0; i < input_size; i++) {\n      input[i] = distr(g);\n      output_k1[i] = output_k2[i] = output_ref[i] = 0;\n    }\n\n    reference(input, dense, output_ref, ncols, batch_size, offset);\n\n    #pragma omp target data map(to: input[0:input_size], \\\n                                    dense[0:dense_size], \\\n                                    offset[0:batch_size+1], \\\n                                    output_k1[0:input_size], \\\n                                    output_k2[0:input_size])\n    {\n      for (int block_size = 128; block_size <= 1024; block_size = block_size * 2) {\n        printf(\"block size: %d\\n\", block_size);\n\n        auto start = std::chrono::steady_clock::now();\n\n        for (int i = 0; i < repeat; i++) {\n          #pragma omp target teams num_teams(batch_size)\n          {\n            #pragma omp parallel num_threads(block_size)\n            {\n              const int batch_idx  = omp_get_team_num(); \n\n              const int grain_size = omp_get_num_threads();\n              const int tid = omp_get_thread_num();\n              const int range = offset[batch_idx + 1] - offset[batch_idx];\n              for (int idx = tid; idx < ncols; idx += grain_size) {\n                const auto dense_elem = dense[batch_idx * ncols + idx];\n                for (int nested_idx = idx; nested_idx < range; nested_idx += ncols) {\n                  output_k1[offset[batch_idx] + nested_idx] = input[offset[batch_idx] + nested_idx] + dense_elem;\n                }\n              }\n            }\n          }\n        }\n\n        auto end = std::chrono::steady_clock::now();\n        auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        printf(\"Average execution time of dense embedding kernel (k1): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n        #pragma omp target update from (output_k1[0:input_size])\n\n        start = std::chrono::steady_clock::now();\n\n        for (int i = 0; i < repeat; i++) {\n          #pragma omp target teams num_teams(batch_size)\n          {\n            #pragma omp parallel num_threads(block_size)\n            {\n              const int batch_idx  = omp_get_team_num(); \n\n              const int start = offset[batch_idx];\n              const int range = offset[batch_idx + 1] - start;\n              for (int idx = omp_get_thread_num(); idx < ncols; idx += omp_get_num_threads()) {\n                const auto dense_elem = dense[batch_idx * ncols + idx];\n                for (int nested_idx = idx; nested_idx < range; nested_idx += ncols) {\n                  output_k2[start + nested_idx] = input[start + nested_idx] + dense_elem;\n                }\n              }\n            }\n          }\n        }\n\n        end = std::chrono::steady_clock::now();\n        time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        printf(\"Average execution time of dense embedding kernel (k2): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n        #pragma omp target update from (output_k2[0:input_size])\n\n        bool ok = true;\n        for (int i = 0; i < input_size; i++) {\n          if (fabsf(output_k1[i] - output_ref[i]) > 1e-3f ||\n              fabsf(output_k2[i] - output_ref[i]) > 1e-3f) {\n            ok = false;\n            break;\n          }\n        }\n        printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n      }\n    }\n\n    free(input);\n    free(dense);\n    free(output_k1);\n    free(output_k2);\n    free(output_ref);\n    free(offset);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "dense-embedding", "parallel_api": "serial", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n\ntemplate <typename T>\nvoid reference(\n    const T* input,\n    const T* dense,\n    T* output,\n    int embedding_dim,\n    int batch_size,\n    const int* offset)\n{\n  for (int batch_idx = 0; batch_idx < batch_size; batch_idx++) {\n    const int range = offset[batch_idx + 1] - offset[batch_idx];\n    for (int idx = 0; idx < embedding_dim; idx++) {\n      const T dense_elem = dense[batch_idx * embedding_dim + idx];\n      for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n        output[offset[batch_idx] + nested_idx] =\n          input[offset[batch_idx] + nested_idx] + dense_elem;\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int batch_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n  assert(nrows > batch_size * batch_size);\n\n  printf(\"Number of rows in the embedding table: %d\\n\", nrows);\n  printf(\"Batch size: %d\\n\", batch_size);\n\n  const int embed_dims[] = {768, 2048, 12288};\n\n  for (size_t n = 0; n < sizeof(embed_dims)/sizeof(int); n++) {\n    int ncols = embed_dims[n];\n    printf(\"\\nEmbedding dimension: %d\\n\", ncols);\n\n    int input_size = nrows * ncols;  \n\n    size_t input_size_bytes = input_size * sizeof(float);\n\n    int dense_size = batch_size * ncols ;\n    int dense_size_bytes = dense_size * sizeof(float);\n\n    int batch_size_bytes = (batch_size + 1) * sizeof(float);\n\n    float *input, *dense, *output_k1, *output_k2, *output_ref;\n    input = (float*) malloc (input_size_bytes); \n\n    dense = (float*) malloc (dense_size_bytes); \n\n    output_k1 = (float*) malloc (input_size_bytes); \n\n    output_k2 = (float*) malloc (input_size_bytes); \n\n    output_ref = (float*) malloc (input_size_bytes); \n\n    int *offset = (int*) malloc (batch_size_bytes);  \n\n\n    \n\n    \n\n    \n\n    \n\n    srand(123);\n    offset[0] = 0;\n    for (int i = 1; i <= batch_size; i++)\n      offset[i] = offset[i-1] + (rand() % batch_size + 1) * ncols;\n\n    std::default_random_engine g (123);\n    std::uniform_real_distribution<float> distr (-1.f, 1.f);\n    for (int i = 0; i < dense_size; i++) {\n      dense[i] = distr(g);\n    }\n\n    for (int i = 0; i < input_size; i++) {\n      input[i] = distr(g);\n      output_k1[i] = output_k2[i] = output_ref[i] = 0;\n    }\n\n    reference(input, dense, output_ref, ncols, batch_size, offset);\n\n        {\n      for (int block_size = 128; block_size <= 1024; block_size = block_size * 2) {\n        printf(\"block size: %d\\n\", block_size);\n\n        auto start = std::chrono::steady_clock::now();\n\n        for (int i = 0; i < repeat; i++) {\n                    {\n                        {\n              const int batch_idx  = omp_get_team_num(); \n\n              const int grain_size = omp_get_num_threads();\n              const int tid = omp_get_thread_num();\n              const int range = offset[batch_idx + 1] - offset[batch_idx];\n              for (int idx = tid; idx < ncols; idx += grain_size) {\n                const auto dense_elem = dense[batch_idx * ncols + idx];\n                for (int nested_idx = idx; nested_idx < range; nested_idx += ncols) {\n                  output_k1[offset[batch_idx] + nested_idx] = input[offset[batch_idx] + nested_idx] + dense_elem;\n                }\n              }\n            }\n          }\n        }\n\n        auto end = std::chrono::steady_clock::now();\n        auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        printf(\"Average execution time of dense embedding kernel (k1): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n        \n        start = std::chrono::steady_clock::now();\n\n        for (int i = 0; i < repeat; i++) {\n                    {\n                        {\n              const int batch_idx  = omp_get_team_num(); \n\n              const int start = offset[batch_idx];\n              const int range = offset[batch_idx + 1] - start;\n              for (int idx = omp_get_thread_num(); idx < ncols; idx += omp_get_num_threads()) {\n                const auto dense_elem = dense[batch_idx * ncols + idx];\n                for (int nested_idx = idx; nested_idx < range; nested_idx += ncols) {\n                  output_k2[start + nested_idx] = input[start + nested_idx] + dense_elem;\n                }\n              }\n            }\n          }\n        }\n\n        end = std::chrono::steady_clock::now();\n        time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        printf(\"Average execution time of dense embedding kernel (k2): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n        \n        bool ok = true;\n        for (int i = 0; i < input_size; i++) {\n          if (fabsf(output_k1[i] - output_ref[i]) > 1e-3f ||\n              fabsf(output_k2[i] - output_ref[i]) > 1e-3f) {\n            ok = false;\n            break;\n          }\n        }\n        printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n      }\n    }\n\n    free(input);\n    free(dense);\n    free(output_k1);\n    free(output_k2);\n    free(output_ref);\n    free(offset);\n  }\n\n  return 0;\n}"}}
{"kernel_name": "dense-embedding", "parallel_api": "sycl", "code": {"main.cpp": "#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n\ntemplate <typename T>\nvoid reference(\n    const T* input,\n    const T* dense,\n    T* output,\n    int embedding_dim,\n    int batch_size,\n    const int* offset)\n{\n  for (int batch_idx = 0; batch_idx < batch_size; batch_idx++) {\n    const int range = offset[batch_idx + 1] - offset[batch_idx];\n    for (int idx = 0; idx < embedding_dim; idx++) {\n      const T dense_elem = dense[batch_idx * embedding_dim + idx];\n      for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n        output[offset[batch_idx] + nested_idx] =\n          input[offset[batch_idx] + nested_idx] + dense_elem;\n      }\n    }\n  }\n}\n\ntemplate <typename T>\nvoid dense_esuhm(\n    sycl::nd_item<1> &item,\n    const T* input,\n    const T* dense,\n          T* output,\n    int embedding_dim,\n    const int* offset)\n{\n  const int batch_idx  = item.get_group(0); \n\n  const int grain_size = item.get_local_range(0);\n  const int tid = item.get_local_id(0);\n  const int range = offset[batch_idx + 1] - offset[batch_idx];\n  for (int idx = tid; idx < embedding_dim; idx += grain_size) {\n    const T dense_elem = dense[batch_idx * embedding_dim + idx];\n    for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n      output[offset[batch_idx] + nested_idx] =\n        input[offset[batch_idx] + nested_idx] + dense_elem;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid dense_esuhm2(\n    sycl::nd_item<1> &item,\n    const T* input,\n    const T* dense,\n          T* output,\n    int embedding_dim,\n    const int* offset)\n{\n  const int batch_idx = item.get_group(0);\n  const int start = offset[batch_idx];\n  const int range = offset[batch_idx + 1] - start;\n  for (int idx = item.get_local_id(0); idx < embedding_dim;\n           idx += item.get_local_range(0)) {\n    const T dense_elem = dense[batch_idx * embedding_dim + idx];\n    for (int nested_idx = idx; nested_idx < range; nested_idx += embedding_dim) {\n      output[start + nested_idx] = input[start + nested_idx] + dense_elem;\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int batch_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n  assert(nrows > batch_size * batch_size);\n\n  printf(\"Number of rows in the embedding table: %d\\n\", nrows);\n  printf(\"Batch size: %d\\n\", batch_size);\n\n  const int embed_dims[] = {768, 2048, 12288};\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  for (size_t n = 0; n < sizeof(embed_dims)/sizeof(int); n++) {\n    int ncols = embed_dims[n];\n    printf(\"\\nEmbedding dimension: %d\\n\", ncols);\n\n    int input_size = nrows * ncols;  \n\n    size_t input_size_bytes = input_size * sizeof(float);\n\n    int dense_size = batch_size * ncols ;\n    int dense_size_bytes = dense_size * sizeof(float);\n\n    int batch_size_bytes = (batch_size + 1) * sizeof(float);\n\n    float *input, *dense, *output_k1, *output_k2, *output_ref;\n    input = (float*) malloc (input_size_bytes); \n\n    dense = (float*) malloc (dense_size_bytes); \n\n    output_k1 = (float*) malloc (input_size_bytes); \n\n    output_k2 = (float*) malloc (input_size_bytes); \n\n    output_ref = (float*) malloc (input_size_bytes); \n\n    int *input_offset = (int*) malloc (batch_size_bytes);  \n\n\n    \n\n    \n\n    \n\n    \n\n    srand(123);\n    input_offset[0] = 0;\n    for (int i = 1; i <= batch_size; i++)\n      input_offset[i] = input_offset[i-1] + (rand() % batch_size + 1) * ncols;\n\n    std::default_random_engine g (123);\n    std::uniform_real_distribution<float> distr (-1.f, 1.f);\n    for (int i = 0; i < dense_size; i++) {\n      dense[i] = distr(g);\n    }\n\n    for (int i = 0; i < input_size; i++) {\n      input[i] = distr(g);\n      output_ref[i] = 0;\n    }\n\n    reference(input, dense, output_ref, ncols, batch_size, input_offset);\n\n    float *d_input, *d_dense, *d_output;\n    d_input = sycl::malloc_device<float>(input_size, q);\n    q.memcpy(d_input, input, input_size_bytes);\n\n    d_dense = sycl::malloc_device<float>(dense_size, q);\n    q.memcpy(d_dense, dense, dense_size_bytes);\n\n    d_output = sycl::malloc_device<float>(input_size, q);\n    q.memset(d_output, 0, input_size_bytes);\n\n    int* d_input_offset;\n    d_input_offset = sycl::malloc_device<int>(batch_size+1, q);\n    q.memcpy(d_input_offset, input_offset, batch_size_bytes);\n\n    for (int block_size = 128; block_size <= 1024; block_size = block_size * 2) {\n      printf(\"block size: %d\\n\", block_size);\n\n      q.memset(d_output, 0, input_size_bytes);\n      q.wait();\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for<class de1>(\n            sycl::nd_range<1>(sycl::range<1>(batch_size * block_size),\n                              sycl::range<1>(block_size)), [=] (sycl::nd_item<1> item) {\n            dense_esuhm(item, d_input, d_dense, d_output, ncols, d_input_offset);\n          });\n        });\n      }\n\n      q.wait();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of dense embedding kernel (k1): %f (us)\\n\", (time * 1e-3f) / repeat);\n      q.memcpy(output_k1, d_output, input_size_bytes);\n\n      q.memset(d_output, 0, input_size_bytes);\n      q.wait();\n      start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for<class de2>(\n            sycl::nd_range<1>(sycl::range<1>(batch_size * block_size),\n                              sycl::range<1>(block_size)), [=] (sycl::nd_item<1> item) {\n            dense_esuhm2(item, d_input, d_dense, d_output, ncols, d_input_offset);\n          });\n        });\n      }\n\n      q.wait();\n      end = std::chrono::steady_clock::now();\n      time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of dense embedding kernel (k2): %f (us)\\n\", (time * 1e-3f) / repeat);\n      q.memcpy(output_k2, d_output, input_size_bytes).wait();\n\n      bool ok = true;\n      for (int i = 0; i < input_size; i++) {\n        if (fabsf(output_k1[i] - output_ref[i]) > 1e-3f ||\n            fabsf(output_k2[i] - output_ref[i]) > 1e-3f) {\n          ok = false;\n          break;\n        }\n      }\n      printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n    }\n\n    sycl::free(d_input, q);\n    sycl::free(d_dense, q);\n    sycl::free(d_output, q);\n    sycl::free(d_input_offset, q);\n\n    free(input);\n    free(dense);\n    free(output_k1);\n    free(output_k2);\n    free(output_ref);\n    free(input_offset);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "expdist", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"kernel.h\"\n\ntemplate <typename FP, int dim>\nFP cost (FP *A, FP *B, FP *scale_A, FP *scale_B, int m, int n) {\n  double sum = 0;\n  for (int i = 0; i < m; i++) {\n    for (int j = 0; j < n; j++) {\n      FP dist = 0;\n      for (int d = 0; d < dim; d++) {\n        dist += (A[i + d * m] - B[j + d * n]) *\n                (A[i + d * m] - B[j + d * n]);\n      }\n      sum += exp(-dist/(scale_A[i] + scale_B[j]));\n    }\n  }\n  return sum;\n}\n\ntemplate <typename FP>\nvoid test(const int size, const int repeat) {\n\n  const int nblocks = ceilf(size / (block_size_x * tile_size_x)) * \n                      ceilf(size / (block_size_y * tile_size_y));\n\n  size_t point_size_bytes = sizeof(FP) * size * 2;\n  size_t scale_size_bytes = sizeof(FP) * size;\n  size_t cost_size_bytes = sizeof(FP) * nblocks;\n\n  FP *A = (FP*) malloc (point_size_bytes);\n  FP *B = (FP*) malloc (point_size_bytes);\n  for (int i = 0; i < size * 2; i++) {\n    A[i] = 1;\n    B[i] = 0;\n  }\n\n  FP *scaleA = (FP*) malloc (scale_size_bytes);\n  FP *scaleB = (FP*) malloc (scale_size_bytes);\n  for (int i = 0; i < size; i++) {\n    scaleA[i] = 1;\n    scaleB[i] = 1;\n  }\n\n  FP output;\n\n  FP *d_A;\n  FP *d_B;\n  FP *d_scaleA;\n  FP *d_scaleB;\n  FP *d_cost;\n  FP *d_output;\n\n  cudaMalloc((void**)&d_A, point_size_bytes);\n  cudaMalloc((void**)&d_B, point_size_bytes);\n  cudaMalloc((void**)&d_scaleA, scale_size_bytes);\n  cudaMalloc((void**)&d_scaleB, scale_size_bytes);\n  cudaMalloc((void**)&d_cost, cost_size_bytes);\n  cudaMalloc((void**)&d_output, sizeof(FP));\n\n  cudaMemcpy(d_A, A, point_size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_B, B, point_size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_scaleA, scaleA, scale_size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_scaleB, scaleB, scale_size_bytes, cudaMemcpyHostToDevice);\n\n  dim3 grids (size / (block_size_x * tile_size_x), \n              size / (block_size_y * tile_size_y));\n  dim3 blocks (block_size_x, block_size_y);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    distance<FP><<<grids, blocks>>>(d_A, d_B, size, size, d_scaleA, d_scaleB, d_cost);  \n    reduce_cross_term<FP><<<1, reduce_block_size>>>(d_output, d_cost, size, size, nblocks);  \n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(&output, d_output, sizeof(FP), cudaMemcpyDeviceToHost);\n  printf(\"    device result: %lf\\n\", (double)output);\n\n  output = cost<FP, 2>(A, B, scaleA, scaleB, size, size);\n  printf(\"      host result: %lf\\n\", (double)output);\n\n  printf(\"analytical result: %lf\\n\\n\", size * size * exp(-1.0));\n\n  cudaFree(d_A);\n  cudaFree(d_B);\n  cudaFree(d_scaleA);\n  cudaFree(d_scaleB);\n  cudaFree(d_output);\n  cudaFree(d_cost);\n\n  free(A);\n  free(B);\n  free(scaleA);\n  free(scaleB);\n} \n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage ./%s <size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Test single precision\\n\");\n  test<float>(size, repeat);\n\n  printf(\"Test double precision\\n\");\n  test<double>(size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "expdist", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"kernel.h\"\n\ntemplate <typename FP, int dim>\nFP cost (FP *A, FP *B, FP *scale_A, FP *scale_B, int m, int n) {\n  double sum = 0;\n  for (int i = 0; i < m; i++) {\n    for (int j = 0; j < n; j++) {\n      FP dist = 0;\n      for (int d = 0; d < dim; d++) {\n        dist += (A[i + d * m] - B[j + d * n]) *\n                (A[i + d * m] - B[j + d * n]);\n      }\n      sum += exp(-dist/(scale_A[i] + scale_B[j]));\n    }\n  }\n  return sum;\n}\n\ntemplate <typename FP>\nvoid test(const int size, const int repeat) {\n\n  const int nblocks = ceilf(size / (block_size_x * tile_size_x)) * \n                      ceilf(size / (block_size_y * tile_size_y));\n\n  size_t point_size_bytes = sizeof(FP) * size * 2;\n  size_t scale_size_bytes = sizeof(FP) * size;\n  size_t cost_size_bytes = sizeof(FP) * nblocks;\n\n  FP *A = (FP*) malloc (point_size_bytes);\n  FP *B = (FP*) malloc (point_size_bytes);\n  for (int i = 0; i < size * 2; i++) {\n    A[i] = 1;\n    B[i] = 0;\n  }\n\n  FP *scaleA = (FP*) malloc (scale_size_bytes);\n  FP *scaleB = (FP*) malloc (scale_size_bytes);\n  for (int i = 0; i < size; i++) {\n    scaleA[i] = 1;\n    scaleB[i] = 1;\n  }\n\n  FP output;\n\n  FP *d_A;\n  FP *d_B;\n  FP *d_scaleA;\n  FP *d_scaleB;\n  FP *d_cost;\n  FP *d_output;\n\n  hipMalloc((void**)&d_A, point_size_bytes);\n  hipMalloc((void**)&d_B, point_size_bytes);\n  hipMalloc((void**)&d_scaleA, scale_size_bytes);\n  hipMalloc((void**)&d_scaleB, scale_size_bytes);\n  hipMalloc((void**)&d_cost, cost_size_bytes);\n  hipMalloc((void**)&d_output, sizeof(FP));\n\n  hipMemcpy(d_A, A, point_size_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_B, B, point_size_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_scaleA, scaleA, scale_size_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_scaleB, scaleB, scale_size_bytes, hipMemcpyHostToDevice);\n\n  dim3 grids (size / (block_size_x * tile_size_x), \n              size / (block_size_y * tile_size_y));\n  dim3 blocks (block_size_x, block_size_y);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    distance<FP><<<grids, blocks>>>(d_A, d_B, size, size, d_scaleA, d_scaleB, d_cost);  \n    reduce_cross_term<FP><<<1, reduce_block_size>>>(d_output, d_cost, size, size, nblocks);  \n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(&output, d_output, sizeof(FP), hipMemcpyDeviceToHost);\n  printf(\"    device result: %lf\\n\", (double)output);\n\n  output = cost<FP, 2>(A, B, scaleA, scaleB, size, size);\n  printf(\"      host result: %lf\\n\", (double)output);\n\n  printf(\"analytical result: %lf\\n\\n\", size * size * exp(-1.0));\n\n  hipFree(d_A);\n  hipFree(d_B);\n  hipFree(d_scaleA);\n  hipFree(d_scaleB);\n  hipFree(d_output);\n  hipFree(d_cost);\n\n  free(A);\n  free(B);\n  free(scaleA);\n  free(scaleB);\n} \n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage ./%s <size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Test single precision\\n\");\n  test<float>(size, repeat);\n\n  printf(\"Test double precision\\n\");\n  test<double>(size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "expdist", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"kernel.h\"\n\ntemplate <typename FP, int dim>\nFP host_cost (FP *A, FP *B, FP *scale_A, FP *scale_B, int m, int n) {\n  double sum = 0;\n  for (int i = 0; i < m; i++) {\n    for (int j = 0; j < n; j++) {\n      FP dist = 0;\n      for (int d = 0; d < dim; d++) {\n        dist += (A[i + d * m] - B[j + d * n]) *\n                (A[i + d * m] - B[j + d * n]);\n      }\n      sum += exp(-dist/(scale_A[i] + scale_B[j]));\n    }\n  }\n  return sum;\n}\n\ntemplate <typename FP>\nvoid test(const int size, const int repeat) {\n\n  const int nblocks = ceilf(size / (block_size_x * tile_size_x)) * \n                      ceilf(size / (block_size_y * tile_size_y));\n\n  size_t point_size_bytes = sizeof(FP) * size * 2;\n  size_t scale_size_bytes = sizeof(FP) * size * 2;\n  size_t cost_size_bytes = sizeof(FP) * nblocks;\n\n  FP *A = (FP*) malloc (point_size_bytes);\n  FP *B = (FP*) malloc (point_size_bytes);\n  for (int i = 0; i < size * 2; i++) {\n    A[i] = 1;\n    B[i] = 0;\n  }\n\n  FP *scaleA = (FP*) malloc (scale_size_bytes);\n  FP *scaleB = (FP*) malloc (scale_size_bytes);\n  for (int i = 0; i < size; i++) {\n    scaleA[i] = 1;\n    scaleB[i] = 1;\n  }\n\n  FP *cost = (FP*) malloc (cost_size_bytes);\n\n  #pragma omp target data map(to: A[0:size*2], \\\n                                  B[0:size*2], \\\n                                  scaleA[0:size], \\\n                                  scaleB[0:size]) \\\n                          map(alloc: cost[0:nblocks])\n  {\n    const int nblocks = ceilf(size / (block_size_x * tile_size_x)) * \n                        ceilf(size / (block_size_y * tile_size_y));\n\n    FP output;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      distance<FP>(A, B, size, size, scaleA, scaleB, cost);  \n      output = reduce_cross_term<FP>(cost, size, size, nblocks);  \n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    printf(\"    device result: %lf\\n\", (double)output);\n\n    output = host_cost<FP, 2>(A, B, scaleA, scaleB, size, size);\n    printf(\"      host result: %lf\\n\", (double)output);\n\n    printf(\"analytical result: %lf\\n\\n\", size * size * exp(-1.0));\n  }\n\n  free(A);\n  free(B);\n  free(cost);\n  free(scaleA);\n  free(scaleB);\n} \n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage ./%s <size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Test single precision\\n\");\n  test<float>(size, repeat);\n\n  printf(\"Test double precision\\n\");\n  test<double>(size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "expdist", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"kernel.h\"\n\ntemplate <typename FP, int dim>\nFP host_cost (FP *A, FP *B, FP *scale_A, FP *scale_B, int m, int n) {\n  double sum = 0;\n  for (int i = 0; i < m; i++) {\n    for (int j = 0; j < n; j++) {\n      FP dist = 0;\n      for (int d = 0; d < dim; d++) {\n        dist += (A[i + d * m] - B[j + d * n]) *\n                (A[i + d * m] - B[j + d * n]);\n      }\n      sum += exp(-dist/(scale_A[i] + scale_B[j]));\n    }\n  }\n  return sum;\n}\n\ntemplate <typename FP>\nvoid test(const int size, const int repeat) {\n\n  const int nblocks = ceilf(size / (block_size_x * tile_size_x)) * \n                      ceilf(size / (block_size_y * tile_size_y));\n\n  size_t point_size_bytes = sizeof(FP) * size * 2;\n  size_t scale_size_bytes = sizeof(FP) * size * 2;\n  size_t cost_size_bytes = sizeof(FP) * nblocks;\n\n  FP *A = (FP*) malloc (point_size_bytes);\n  FP *B = (FP*) malloc (point_size_bytes);\n  for (int i = 0; i < size * 2; i++) {\n    A[i] = 1;\n    B[i] = 0;\n  }\n\n  FP *scaleA = (FP*) malloc (scale_size_bytes);\n  FP *scaleB = (FP*) malloc (scale_size_bytes);\n  for (int i = 0; i < size; i++) {\n    scaleA[i] = 1;\n    scaleB[i] = 1;\n  }\n\n  FP *cost = (FP*) malloc (cost_size_bytes);\n\n    {\n    const int nblocks = ceilf(size / (block_size_x * tile_size_x)) * \n                        ceilf(size / (block_size_y * tile_size_y));\n\n    FP output;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      distance<FP>(A, B, size, size, scaleA, scaleB, cost);  \n      output = reduce_cross_term<FP>(cost, size, size, nblocks);  \n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    printf(\"    device result: %lf\\n\", (double)output);\n\n    output = host_cost<FP, 2>(A, B, scaleA, scaleB, size, size);\n    printf(\"      host result: %lf\\n\", (double)output);\n\n    printf(\"analytical result: %lf\\n\\n\", size * size * exp(-1.0));\n  }\n\n  free(A);\n  free(B);\n  free(cost);\n  free(scaleA);\n  free(scaleB);\n} \n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage ./%s <size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Test single precision\\n\");\n  test<float>(size, repeat);\n\n  printf(\"Test double precision\\n\");\n  test<double>(size, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "expdist", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp> \n#include \"kernel.h\"\n\ntemplate <typename FP, int dim>\nFP cost (FP *A, FP *B, FP *scale_A, FP *scale_B, int m, int n) {\n  double sum = 0;\n  for (int i = 0; i < m; i++) {\n    for (int j = 0; j < n; j++) {\n      FP dist = 0;\n      for (int d = 0; d < dim; d++) {\n        dist += (A[i + d * m] - B[j + d * n]) *\n                (A[i + d * m] - B[j + d * n]);\n      }\n      sum += exp(-dist/(scale_A[i] + scale_B[j]));\n    }\n  }\n  return sum;\n}\n\ntemplate <typename FP>\nvoid test(const int size, const int repeat) {\n\n  const int nblocks = ceilf(size / (block_size_x * tile_size_x)) * \n                      ceilf(size / (block_size_y * tile_size_y));\n\n  size_t point_size_bytes = sizeof(FP) * size * 2;\n  size_t scale_size_bytes = sizeof(FP) * size;\n\n  FP *A = (FP*) malloc (point_size_bytes);\n  FP *B = (FP*) malloc (point_size_bytes);\n  for (int i = 0; i < size * 2; i++) {\n    A[i] = 1;\n    B[i] = 0;\n  }\n\n  FP *scaleA = (FP*) malloc (scale_size_bytes);\n  FP *scaleB = (FP*) malloc (scale_size_bytes);\n  for (int i = 0; i < size; i++) {\n    scaleA[i] = 1;\n    scaleB[i] = 1;\n  }\n  FP output;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  FP *d_A = sycl::malloc_device<FP>(size*2, q);\n  q.memcpy(d_A, A, point_size_bytes);\n\n  FP *d_B = sycl::malloc_device<FP>(size*2, q);\n  q.memcpy(d_B, B, point_size_bytes);\n\n  FP *d_scaleA = sycl::malloc_device<FP>(size, q);\n  q.memcpy(d_scaleA, scaleA, scale_size_bytes);\n\n  FP *d_scaleB = sycl::malloc_device<FP>(size, q);\n  q.memcpy(d_scaleB, scaleB, scale_size_bytes);\n\n  FP *d_cost = sycl::malloc_device<FP>(nblocks, q);\n  FP *d_output = sycl::malloc_device<FP>(1, q);\n\n  sycl::range<2> gws (size / (block_size_y * tile_size_y) * block_size_y,\n                      size / (block_size_x * tile_size_x) * block_size_x);\n  sycl::range<2> lws (block_size_y, block_size_x);\n\n  sycl::range<1> gws2 (reduce_block_size);\n  sycl::range<1> lws2 (reduce_block_size);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<FP, 1> sh_A (sycl::range<1>(2 * block_size_x * tile_size_x), cgh);\n      sycl::local_accessor<FP, 1> sh_B (sycl::range<1>(2 * block_size_y * tile_size_y), cgh);\n      sycl::local_accessor<FP, 1> sh_scaleA (sycl::range<1>(block_size_x * tile_size_x), cgh);\n      sycl::local_accessor<FP, 1> sh_scaleB (sycl::range<1>(block_size_y * tile_size_y), cgh);\n      sycl::local_accessor<FP, 1> sum (sycl::range<1>(1), cgh);\n      cgh.parallel_for<class computeCost<FP>>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        distance_tiled<FP>(\n          item, d_A, d_B, size, size, d_scaleA, d_scaleB, d_cost,\n          sh_A.get_pointer(), sh_B.get_pointer(), \n          sh_scaleA.get_pointer(), sh_scaleB.get_pointer(), sum.get_pointer());\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<FP, 1> sum (sycl::range<1>(1), cgh);\n      cgh.parallel_for<class reduceBlock<FP>>(\n         sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n         reduce_cross_term<FP>(\n           item, d_output, d_cost, sum.get_pointer(), size, size, nblocks);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(&output, d_output, sizeof(FP)).wait();\n  printf(\"    device result: %lf\\n\", (double)output);\n\n  output = cost<FP, 2>(A, B, scaleA, scaleB, size, size);\n  printf(\"      host result: %lf\\n\", (double)output);\n\n  printf(\"analytical result: %lf\\n\\n\", size * size * exp(-1.0));\n\n  sycl::free(d_A, q);\n  sycl::free(d_B, q);\n  sycl::free(d_scaleA, q);\n  sycl::free(d_scaleB, q);\n  sycl::free(d_output, q);\n  sycl::free(d_cost, q);\n  free(A);\n  free(B);\n  free(scaleA);\n  free(scaleB);\n} \n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage ./%s <size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Test single precision\\n\");\n  test<float>(size, repeat);\n\n  printf(\"Test double precision\\n\");\n  test<double>(size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "flip", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include <cuda.h>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\n__global__ void flip_kernel(\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims)\n{\n  int64_t linear_index = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (linear_index >= n) return;\n\n  int64_t cur_indices = linear_index;\n  int64_t rem = 0;\n  int64_t dst_offset = 0;\n\n  for (int64_t i = 0; i < total_dims; i++) {\n    int64_t temp = cur_indices;\n    cur_indices = cur_indices / strides_contiguous[i];\n    rem = temp - cur_indices * strides_contiguous[i];\n    for (int64_t j = 0; j < flip_dims_size; j++) {\n      \n\n      if (i == flip_dims[j]) {\n        cur_indices = shape[i] - 1 - cur_indices;\n      }\n    }\n    dst_offset += cur_indices * strides[i];\n    cur_indices = rem;\n  }\n  out_tensor[linear_index] = in_tensor[dst_offset];\n}\n\n\n\nvoid property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  property(\"shape\", shape);\n  property(\"flip_dims\", flip);\n  property(\"stride\", stride);\n\n  int64_t dims_bytes = num_dims * sizeof(int64_t);\n  int64_t flip_dims_bytes = num_flip_dims * sizeof(int64_t);\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n  scalar_t *d_input, *d_output;\n  cudaMalloc((void**)&d_input, input_size_bytes);\n  cudaMemcpy(d_input, input, input_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_output, output_size_bytes);\n\n  int64_t *d_flip_dims, *d_shape, *d_strides, *d_strides_contiguous;\n\n  cudaMalloc((void**)&d_flip_dims, flip_dims_bytes);\n  cudaMemcpy(d_flip_dims, flip.data(), flip_dims_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_shape, dims_bytes);\n  cudaMemcpy(d_shape, shape.data(), dims_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_strides, dims_bytes);\n  cudaMemcpy(d_strides, stride.data(), dims_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_strides_contiguous, dims_bytes);\n  cudaMemcpy(d_strides_contiguous, stride.data(), dims_bytes, cudaMemcpyHostToDevice);\n\n  const int threadsPerBlock = 256;\n  dim3 grid ((n + threadsPerBlock - 1) / threadsPerBlock);\n  dim3 block (threadsPerBlock);\n\n  \n\n  flip_kernel<scalar_t><<<grid, block>>> (\n    d_input, d_output, n, d_flip_dims, num_flip_dims,\n    d_strides, d_strides_contiguous, d_shape, num_dims);\n\n  flip_kernel_cpu<scalar_t>(\n    input, output_ref, n, flip.data(), num_flip_dims,\n    stride.data(), stride.data(), shape.data(), num_dims);\n\n  cudaMemcpy(output, d_output, output_size_bytes, cudaMemcpyDeviceToHost);\n  int error = memcmp(output, output_ref, output_size_bytes);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n#ifdef EXAMPLE\n  for (int i = 0; i < n; i++) {\n    printf(\"%f \", output[i]);\n  }\n  printf(\"\\n\");\n#endif\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    flip_kernel<scalar_t><<<grid, block>>> (\n      d_input,\n      d_output,\n      n,\n      d_flip_dims,\n      num_flip_dims,\n      d_strides,\n      d_strides_contiguous,\n      d_shape,\n      num_dims);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(input);\n  free(output);\n  free(output_ref);\n  cudaFree(d_input);\n  cudaFree(d_output);\n  cudaFree(d_flip_dims);\n  cudaFree(d_shape);\n  cudaFree(d_strides);\n  cudaFree(d_strides_contiguous);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "flip", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\n__global__ void flip_kernel(\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims)\n{\n  int64_t linear_index = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (linear_index >= n) return;\n\n  int64_t cur_indices = linear_index;\n  int64_t rem = 0;\n  int64_t dst_offset = 0;\n\n  for (int64_t i = 0; i < total_dims; i++) {\n    int64_t temp = cur_indices;\n    cur_indices = cur_indices / strides_contiguous[i];\n    rem = temp - cur_indices * strides_contiguous[i];\n    for (int64_t j = 0; j < flip_dims_size; j++) {\n      \n\n      if (i == flip_dims[j]) {\n        cur_indices = shape[i] - 1 - cur_indices;\n      }\n    }\n    dst_offset += cur_indices * strides[i];\n    cur_indices = rem;\n  }\n  out_tensor[linear_index] = in_tensor[dst_offset];\n}\n\n\n\nvoid property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  property(\"shape\", shape);\n  property(\"flip_dims\", flip);\n  property(\"stride\", stride);\n\n  int64_t dims_bytes = num_dims * sizeof(int64_t);\n  int64_t flip_dims_bytes = num_flip_dims * sizeof(int64_t);\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n  scalar_t *d_input, *d_output;\n  hipMalloc((void**)&d_input, input_size_bytes);\n  hipMemcpy(d_input, input, input_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_output, output_size_bytes);\n\n  int64_t *d_flip_dims, *d_shape, *d_strides, *d_strides_contiguous;\n\n  hipMalloc((void**)&d_flip_dims, flip_dims_bytes);\n  hipMemcpy(d_flip_dims, flip.data(), flip_dims_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_shape, dims_bytes);\n  hipMemcpy(d_shape, shape.data(), dims_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_strides, dims_bytes);\n  hipMemcpy(d_strides, stride.data(), dims_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_strides_contiguous, dims_bytes);\n  hipMemcpy(d_strides_contiguous, stride.data(), dims_bytes, hipMemcpyHostToDevice);\n\n  const int threadsPerBlock = 256;\n  dim3 grid ((n + threadsPerBlock - 1) / threadsPerBlock);\n  dim3 block (threadsPerBlock);\n\n  \n\n  flip_kernel<scalar_t><<<grid, block>>> (\n    d_input, d_output, n, d_flip_dims, num_flip_dims,\n    d_strides, d_strides_contiguous, d_shape, num_dims);\n\n  flip_kernel_cpu<scalar_t>(\n    input, output_ref, n, flip.data(), num_flip_dims,\n    stride.data(), stride.data(), shape.data(), num_dims);\n\n  hipMemcpy(output, d_output, output_size_bytes, hipMemcpyDeviceToHost);\n  int error = memcmp(output, output_ref, output_size_bytes);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n#ifdef EXAMPLE\n  for (int i = 0; i < n; i++) {\n    printf(\"%f \", output[i]);\n  }\n  printf(\"\\n\");\n#endif\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    flip_kernel<scalar_t><<<grid, block>>> (\n      d_input,\n      d_output,\n      n,\n      d_flip_dims,\n      num_flip_dims,\n      d_strides,\n      d_strides_contiguous,\n      d_shape,\n      num_dims);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(input);\n  free(output);\n  free(output_ref);\n  hipFree(d_input);\n  hipFree(d_output);\n  hipFree(d_flip_dims);\n  hipFree(d_shape);\n  hipFree(d_strides);\n  hipFree(d_strides_contiguous);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "flip", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include <omp.h>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\nvoid flip_kernel(\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims) \n{\n  #pragma omp target teams distribute parallel for num_threads(256)\n  for (int64_t linear_index = 0; linear_index < n; linear_index++) {\n\n    int64_t cur_indices = linear_index;\n    int64_t rem = 0;\n    int64_t dst_offset = 0;\n\n    for (int64_t i = 0; i < total_dims; i++) {\n      int64_t temp = cur_indices;\n      cur_indices = cur_indices / strides_contiguous[i];\n      rem = temp - cur_indices * strides_contiguous[i];\n      for (int64_t j = 0; j < flip_dims_size; j++) {\n        \n\n        if (i == flip_dims[j]) {\n          cur_indices = shape[i] - 1 - cur_indices;\n        }\n      }\n      dst_offset += cur_indices * strides[i];\n      cur_indices = rem;\n    }\n    out_tensor[linear_index] = in_tensor[dst_offset];\n  }\n}\n\n\n\nvoid property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  property(\"shape\", shape);\n  property(\"flip_dims\", flip);\n  property(\"stride\", stride);\n\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n  scalar_t *d_input = input; \n  scalar_t *d_output = output; \n  int64_t *d_shape = shape.data();\n  int64_t *d_flip_dims = flip.data();\n  int64_t *d_strides = stride.data();\n  int64_t *d_strides_contiguous = stride.data();\n\n  #pragma omp target data map(to: d_input[0:n], \\\n                                  d_shape[0:num_dims], \\\n                                  d_flip_dims[0:num_dims], \\\n                                  d_strides[0:num_dims], \\\n                                  d_strides_contiguous[0:num_dims]) \\\n                          map(alloc: d_output[0:n])\n  {\n    \n\n    flip_kernel<scalar_t>(\n      d_input, d_output, n, d_flip_dims, num_flip_dims,\n      d_strides, d_strides_contiguous, d_shape, num_dims);\n\n    flip_kernel_cpu<scalar_t>(\n      input, output_ref, n, flip.data(), num_flip_dims,\n      stride.data(), stride.data(), shape.data(), num_dims);\n\n    #pragma omp target update from (d_output[0:n])\n    int error = memcmp(output, output_ref, output_size_bytes);\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n    #ifdef EXAMPLE\n      for (int i = 0; i < n; i++) {\n        printf(\"%f \", output[i]);\n      }\n      printf(\"\\n\");\n    #endif\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      flip_kernel<scalar_t>(\n        d_input,\n        d_output,\n        n,\n        d_flip_dims,\n        num_flip_dims,\n        d_strides,\n        d_strides_contiguous,\n        d_shape,\n        num_dims);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  free(input);\n  free(output);\n  free(output_ref);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "flip", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\nvoid flip_kernel(\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims) \n{\n    for (int64_t linear_index = 0; linear_index < n; linear_index++) {\n\n    int64_t cur_indices = linear_index;\n    int64_t rem = 0;\n    int64_t dst_offset = 0;\n\n    for (int64_t i = 0; i < total_dims; i++) {\n      int64_t temp = cur_indices;\n      cur_indices = cur_indices / strides_contiguous[i];\n      rem = temp - cur_indices * strides_contiguous[i];\n      for (int64_t j = 0; j < flip_dims_size; j++) {\n        \n\n        if (i == flip_dims[j]) {\n          cur_indices = shape[i] - 1 - cur_indices;\n        }\n      }\n      dst_offset += cur_indices * strides[i];\n      cur_indices = rem;\n    }\n    out_tensor[linear_index] = in_tensor[dst_offset];\n  }\n}\n\n\n\nvoid property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  property(\"shape\", shape);\n  property(\"flip_dims\", flip);\n  property(\"stride\", stride);\n\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n  scalar_t *d_input = input; \n  scalar_t *d_output = output; \n  int64_t *d_shape = shape.data();\n  int64_t *d_flip_dims = flip.data();\n  int64_t *d_strides = stride.data();\n  int64_t *d_strides_contiguous = stride.data();\n\n    {\n    \n\n    flip_kernel<scalar_t>(\n      d_input, d_output, n, d_flip_dims, num_flip_dims,\n      d_strides, d_strides_contiguous, d_shape, num_dims);\n\n    flip_kernel_cpu<scalar_t>(\n      input, output_ref, n, flip.data(), num_flip_dims,\n      stride.data(), stride.data(), shape.data(), num_dims);\n\n        int error = memcmp(output, output_ref, output_size_bytes);\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n    #ifdef EXAMPLE\n      for (int i = 0; i < n; i++) {\n        printf(\"%f \", output[i]);\n      }\n      printf(\"\\n\");\n    #endif\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      flip_kernel<scalar_t>(\n        d_input,\n        d_output,\n        n,\n        d_flip_dims,\n        num_flip_dims,\n        d_strides,\n        d_strides_contiguous,\n        d_shape,\n        num_dims);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  free(input);\n  free(output);\n  free(output_ref);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "flip", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\nvoid flip_kernel(\n    sycl::nd_item<1> &item,\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims)\n{\n  int64_t linear_index = item.get_global_id(0);\n\n  if (linear_index >= n) return;\n\n  int64_t cur_indices = linear_index;\n  int64_t rem = 0;\n  int64_t dst_offset = 0;\n\n  for (int64_t i = 0; i < total_dims; i++) {\n    int64_t temp = cur_indices;\n    cur_indices = cur_indices / strides_contiguous[i];\n    rem = temp - cur_indices * strides_contiguous[i];\n    for (int64_t j = 0; j < flip_dims_size; j++) {\n      \n\n      if (i == flip_dims[j]) {\n        cur_indices = shape[i] - 1 - cur_indices;\n      }\n    }\n    dst_offset += cur_indices * strides[i];\n    cur_indices = rem;\n  }\n  out_tensor[linear_index] = in_tensor[dst_offset];\n}\n\n\n\nvoid print_property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  print_property(\"shape\", shape);\n  print_property(\"flip_dims\", flip);\n  print_property(\"stride\", stride);\n\n  int64_t dims_bytes = num_dims * sizeof(int64_t);\n  int64_t flip_dims_bytes = num_flip_dims * sizeof(int64_t);\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  scalar_t *d_input, *d_output;\n  d_input = sycl::malloc_device<scalar_t>(n, q);\n  q.memcpy(d_input, input, input_size_bytes);\n\n  d_output = sycl::malloc_device<scalar_t>(n, q);\n\n  int64_t *d_flip_dims, *d_shape, *d_strides, *d_strides_contiguous;\n\n  d_flip_dims = sycl::malloc_device<int64_t>(num_flip_dims, q);\n  q.memcpy(d_flip_dims, flip.data(), flip_dims_bytes);\n\n  d_shape = sycl::malloc_device<int64_t>(num_dims, q);\n  q.memcpy(d_shape, shape.data(), dims_bytes);\n\n  d_strides = sycl::malloc_device<int64_t>(num_dims, q);\n  q.memcpy(d_strides, stride.data(), dims_bytes);\n\n  d_strides_contiguous = sycl::malloc_device<int64_t>(num_dims, q);\n  q.memcpy(d_strides_contiguous, stride.data(), dims_bytes);\n\n  const int threadsPerBlock = 256;\n\n  sycl::range<1> gws ((n + threadsPerBlock - 1) / threadsPerBlock * threadsPerBlock);\n  sycl::range<1> lws (threadsPerBlock);\n\n  \n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      flip_kernel<scalar_t>(\n        item,\n        d_input,\n        d_output,\n        n,\n        d_flip_dims,\n        num_flip_dims,\n        d_strides,\n        d_strides_contiguous,\n        d_shape,\n        num_dims);\n    });\n  });\n\n  flip_kernel_cpu<scalar_t>(\n    input, output_ref, n, flip.data(), num_flip_dims,\n    stride.data(), stride.data(), shape.data(), num_dims);\n\n  q.memcpy(output, d_output, output_size_bytes).wait();\n  int error = memcmp(output, output_ref, output_size_bytes);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n#ifdef EXAMPLE\n  for (int i = 0; i < n; i++) {\n    printf(\"%f \", output[i]);\n  }\n  printf(\"\\n\");\n#endif\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        flip_kernel<scalar_t>(\n          item,\n          d_input,\n          d_output,\n          n,\n          d_flip_dims,\n          num_flip_dims,\n          d_strides,\n          d_strides_contiguous,\n          d_shape,\n          num_dims);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(input);\n  free(output);\n  free(output_ref);\n  sycl::free(d_input, q);\n  sycl::free(d_output, q);\n  sycl::free(d_flip_dims, q);\n  sycl::free(d_shape, q);\n  sycl::free(d_strides, q);\n  sycl::free(d_strides_contiguous, q);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "gd", "parallel_api": "cuda", "code": {"main.cu": "#include <cstdio>\n#include <string>\n#include <vector>\n#include <algorithm>\n#include <cuda.h>\n#include \"utils.h\"\n\n__global__ void \nL2_norm(const float *x, float* l2_norm, int n)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) atomicAdd(l2_norm, x[i]*x[i]);\n}\n\n__global__ void\ncompute (\n    const float * __restrict__ x, \n          float * __restrict__ grad, \n    const int   * __restrict__ A_row_ptr,\n    const int   * __restrict__ A_col_index,\n    const float * __restrict__ A_value, \n    const int   * __restrict__ A_y_label,\n    float * __restrict__ total_obj_val,\n    int   * __restrict__ correct,\n    int m ) \n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (i < m) {\n    \n\n    float xp = 0.f;\n    for( int j = A_row_ptr[i]; j < A_row_ptr[i+1]; ++j){\n      xp += A_value[j] * x[A_col_index[j]];\n    }\n\n    \n\n    float v = logf(1.f + expf(-xp * A_y_label[i]));\n    atomicAdd(total_obj_val, v);\n\n    \n\n    float prediction = 1.f / (1.f + expf(-xp));\n    int t = (prediction >= 0.5f) ? 1 : -1;\n    if (A_y_label[i] == t) atomicAdd(correct, 1);\n\n    \n\n    float accum = expf(-A_y_label[i] * xp);\n    accum = accum / (1.f + accum);\n    for(int j = A_row_ptr[i]; j < A_row_ptr[i+1]; ++j){\n      float temp = -accum * A_value[j] * A_y_label[i];\n      atomicAdd(&grad[A_col_index[j]], temp);\n    }\n  }\n}\n\n__global__ void\nupdate(float * __restrict__ x,\n       const float * __restrict__ grad,\n       int m, int n, float lambda, float alpha) \n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) {\n    float g = grad[i] / (float)m + lambda * x[i]; \n    x[i] = x[i] - alpha * g;\n  }\n}\n\nint main(int argc, const char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <path to file> <lambda> <alpha> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const std::string file_path = argv[1]; \n  const float lambda = atof(argv[2]);\n  const float alpha = atof(argv[3]);\n  const int iters = atof(argv[4]);\n\n  \n\n  Classification_Data_CRS A;\n  get_CRSM_from_svm(A, file_path);\n\n  const int m = A.m; \n\n  const int n = A.n; \n\n\n  std::vector<float> x(n, 0.f);\n  std::vector<float> grad (n);\n\n  float *d_x;\n  cudaMalloc((void**)&d_x, n * sizeof(float));\n  cudaMemcpy(d_x, x.data(), n * sizeof(float), cudaMemcpyHostToDevice);\n\n  float *d_grad; \n  cudaMalloc((void**)&d_grad, n * sizeof(float));\n\n  float *d_total_obj_val;\n  cudaMalloc((void**)&d_total_obj_val, sizeof(float));\n\n  float *d_l2_norm;\n  cudaMalloc((void**)&d_l2_norm, sizeof(float));\n\n  int *d_correct;\n  cudaMalloc((void**)&d_correct, sizeof(int));\n\n  int *d_row_ptr;\n  cudaMalloc((void**)&d_row_ptr, A.row_ptr.size() * sizeof(int));\n  cudaMemcpy(d_row_ptr, A.row_ptr.data(), \n             A.row_ptr.size() * sizeof(int), cudaMemcpyHostToDevice);\n\n  int *d_col_index;\n  cudaMalloc((void**)&d_col_index, A.col_index.size() * sizeof(int));\n  cudaMemcpy(d_col_index, A.col_index.data(), \n             A.col_index.size() * sizeof(int), cudaMemcpyHostToDevice);\n\n  float *d_value;\n  cudaMalloc((void**)&d_value, A.values.size() * sizeof(float));\n  cudaMemcpy(d_value, A.values.data(), \n             A.values.size() * sizeof(float), cudaMemcpyHostToDevice);\n\n  int *d_y_label;\n  cudaMalloc((void**)&d_y_label, A.y_label.size() * sizeof(int));\n  cudaMemcpy(d_y_label, A.y_label.data(), \n             A.y_label.size() * sizeof(int), cudaMemcpyHostToDevice);\n\n  dim3 grid ((m+255)/256);\n  dim3 block (256);\n\n  dim3 grid2 ((n+255)/256);\n  dim3 block2 (256);\n\n  float obj_val = 0.f;\n  float train_error = 0.f;\n\n  cudaDeviceSynchronize();\n  long long train_start = get_time();\n\n  for (int k = 0; k < iters; k++) {\n\n    \n\n    float total_obj_val = 0.f;\n    float l2_norm = 0.f;\n    int correct = 0;\n\n    cudaMemcpy(d_total_obj_val, &total_obj_val, sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_l2_norm, &l2_norm, sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_correct, &correct, sizeof(int), cudaMemcpyHostToDevice);\n\n    \n\n    std::fill(grad.begin(), grad.end(), 0.f);\n\n    cudaMemcpy(d_grad, grad.data(), n * sizeof(float), cudaMemcpyHostToDevice);\n\n    \n\n    compute<<<grid, block>>>(\n        d_x, \n        d_grad, \n        d_row_ptr,\n        d_col_index,\n        d_value,\n        d_y_label,\n        d_total_obj_val,\n        d_correct,\n        m\n      ); \n\n    \n\n    L2_norm<<<grid2, block2>>>(d_x, d_l2_norm, n);\n\n    cudaMemcpy(&total_obj_val, d_total_obj_val, sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(&l2_norm, d_l2_norm, sizeof(float), cudaMemcpyDeviceToHost);\n    cudaMemcpy(&correct, d_correct, sizeof(int), cudaMemcpyDeviceToHost);\n\n    obj_val = total_obj_val / (float)m + 0.5f * lambda * l2_norm;\n    train_error = 1.f-(correct/(float)m); \n\n    \n\n    update<<<grid2, block2>>>(d_x, d_grad, m, n, lambda, alpha);\n  }\n\n  cudaDeviceSynchronize();\n  long long train_end = get_time();\n  printf(\"Training time takes %lf (s) for %d iterations\\n\\n\",\n         (train_end - train_start) * 1e-6, iters);\n\n  \n\n  printf(\"object value = %f train_error = %f\\n\", obj_val, train_error);\n\n  cudaFree(d_row_ptr);\n  cudaFree(d_col_index);\n  cudaFree(d_value);\n  cudaFree(d_y_label);\n  cudaFree(d_x);\n  cudaFree(d_grad);\n  cudaFree(d_total_obj_val);\n  cudaFree(d_l2_norm);\n  cudaFree(d_correct);\n\n  return 0; \n}\n"}}
{"kernel_name": "gd", "parallel_api": "hip", "code": {"main.cu": "#include <cstdio>\n#include <string>\n#include <vector>\n#include <algorithm>\n#include <hip/hip_runtime.h>\n#include \"utils.h\"\n\n__global__ void \nL2_norm(const float *x, float* l2_norm, int n)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) atomicAdd(l2_norm, x[i]*x[i]);\n}\n\n__global__ void\ncompute (\n    const float * __restrict__ x, \n          float * __restrict__ grad, \n    const int   * __restrict__ A_row_ptr,\n    const int   * __restrict__ A_col_index,\n    const float * __restrict__ A_value, \n    const int   * __restrict__ A_y_label,\n    float * __restrict__ total_obj_val,\n    int   * __restrict__ correct,\n    int m ) \n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (i < m) {\n    \n\n    float xp = 0.f;\n    for( int j = A_row_ptr[i]; j < A_row_ptr[i+1]; ++j){\n      xp += A_value[j] * x[A_col_index[j]];\n    }\n\n    \n\n    float v = logf(1.f + expf(-xp * A_y_label[i]));\n    atomicAdd(total_obj_val, v);\n\n    \n\n    float prediction = 1.f / (1.f + expf(-xp));\n    int t = (prediction >= 0.5f) ? 1 : -1;\n    if (A_y_label[i] == t) atomicAdd(correct, 1);\n\n    \n\n    float accum = expf(-A_y_label[i] * xp);\n    accum = accum / (1.f + accum);\n    for(int j = A_row_ptr[i]; j < A_row_ptr[i+1]; ++j){\n      float temp = -accum * A_value[j] * A_y_label[i];\n      atomicAdd(&grad[A_col_index[j]], temp);\n    }\n  }\n}\n\n__global__ void\nupdate(float * __restrict__ x,\n       const float * __restrict__ grad,\n       int m, int n, float lambda, float alpha) \n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) {\n    float g = grad[i] / (float)m + lambda * x[i]; \n    x[i] = x[i] - alpha * g;\n  }\n}\n\nint main(int argc, const char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <path to file> <lambda> <alpha> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const std::string file_path = argv[1]; \n  const float lambda = atof(argv[2]);\n  const float alpha = atof(argv[3]);\n  const int iters = atof(argv[4]);\n\n  \n\n  Classification_Data_CRS A;\n  get_CRSM_from_svm(A, file_path);\n\n  const int m = A.m; \n\n  const int n = A.n; \n\n\n  std::vector<float> x(n, 0.f);\n  std::vector<float> grad (n);\n\n  float *d_x;\n  hipMalloc((void**)&d_x, n * sizeof(float));\n  hipMemcpy(d_x, x.data(), n * sizeof(float), hipMemcpyHostToDevice);\n\n  float *d_grad; \n  hipMalloc((void**)&d_grad, n * sizeof(float));\n\n  float *d_total_obj_val;\n  hipMalloc((void**)&d_total_obj_val, sizeof(float));\n\n  float *d_l2_norm;\n  hipMalloc((void**)&d_l2_norm, sizeof(float));\n\n  int *d_correct;\n  hipMalloc((void**)&d_correct, sizeof(int));\n\n  int *d_row_ptr;\n  hipMalloc((void**)&d_row_ptr, A.row_ptr.size() * sizeof(int));\n  hipMemcpy(d_row_ptr, A.row_ptr.data(), \n             A.row_ptr.size() * sizeof(int), hipMemcpyHostToDevice);\n\n  int *d_col_index;\n  hipMalloc((void**)&d_col_index, A.col_index.size() * sizeof(int));\n  hipMemcpy(d_col_index, A.col_index.data(), \n             A.col_index.size() * sizeof(int), hipMemcpyHostToDevice);\n\n  float *d_value;\n  hipMalloc((void**)&d_value, A.values.size() * sizeof(float));\n  hipMemcpy(d_value, A.values.data(), \n             A.values.size() * sizeof(float), hipMemcpyHostToDevice);\n\n  int *d_y_label;\n  hipMalloc((void**)&d_y_label, A.y_label.size() * sizeof(int));\n  hipMemcpy(d_y_label, A.y_label.data(), \n             A.y_label.size() * sizeof(int), hipMemcpyHostToDevice);\n\n  dim3 grid ((m+255)/256);\n  dim3 block (256);\n\n  dim3 grid2 ((n+255)/256);\n  dim3 block2 (256);\n\n  float obj_val = 0.f;\n  float train_error = 0.f;\n\n  hipDeviceSynchronize();\n  long long train_start = get_time();\n\n  for (int k = 0; k < iters; k++) {\n\n    \n\n    float total_obj_val = 0.f;\n    float l2_norm = 0.f;\n    int correct = 0;\n\n    hipMemcpy(d_total_obj_val, &total_obj_val, sizeof(float), hipMemcpyHostToDevice);\n    hipMemcpy(d_l2_norm, &l2_norm, sizeof(float), hipMemcpyHostToDevice);\n    hipMemcpy(d_correct, &correct, sizeof(int), hipMemcpyHostToDevice);\n\n    \n\n    std::fill(grad.begin(), grad.end(), 0.f);\n\n    hipMemcpy(d_grad, grad.data(), n * sizeof(float), hipMemcpyHostToDevice);\n\n    \n\n    compute<<<grid, block>>>(\n        d_x, \n        d_grad, \n        d_row_ptr,\n        d_col_index,\n        d_value,\n        d_y_label,\n        d_total_obj_val,\n        d_correct,\n        m\n      ); \n\n    \n\n    L2_norm<<<grid2, block2>>>(d_x, d_l2_norm, n);\n\n    hipMemcpy(&total_obj_val, d_total_obj_val, sizeof(float), hipMemcpyDeviceToHost);\n    hipMemcpy(&l2_norm, d_l2_norm, sizeof(float), hipMemcpyDeviceToHost);\n    hipMemcpy(&correct, d_correct, sizeof(int), hipMemcpyDeviceToHost);\n\n    obj_val = total_obj_val / (float)m + 0.5f * lambda * l2_norm;\n    train_error = 1.f-(correct/(float)m); \n\n    \n\n    update<<<grid2, block2>>>(d_x, d_grad, m, n, lambda, alpha);\n  }\n\n  hipDeviceSynchronize();\n  long long train_end = get_time();\n  printf(\"Training time takes %lf (s) for %d iterations\\n\\n\",\n         (train_end - train_start) * 1e-6, iters);\n\n  \n\n  printf(\"object value = %f train_error = %f\\n\", obj_val, train_error);\n\n  hipFree(d_row_ptr);\n  hipFree(d_col_index);\n  hipFree(d_value);\n  hipFree(d_y_label);\n  hipFree(d_x);\n  hipFree(d_grad);\n  hipFree(d_total_obj_val);\n  hipFree(d_l2_norm);\n  hipFree(d_correct);\n\n  return 0; \n}\n"}}
{"kernel_name": "gd", "parallel_api": "omp", "code": {"main.cpp": "#include <cstdio>\n#include <string>\n#include <vector>\n#include <algorithm>\n#include <omp.h>\n#include \"utils.h\"\n\nint main(int argc, const char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <path to file> <lambda> <alpha> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const std::string file_path = argv[1]; \n  const float lambda = atof(argv[2]);\n  const float alpha = atof(argv[3]);\n  const int iters = atof(argv[4]);\n\n  \n\n  Classification_Data_CRS A;\n  get_CRSM_from_svm(A, file_path);\n\n  const int m = A.m; \n\n  const int n = A.n; \n\n\n  std::vector<float> x(n, 0.f);\n  std::vector<float> grad (n);\n\n  float *d_grad        = grad.data();\n  float *d_x           = x.data();\n  int   *d_A_row_ptr   = A.row_ptr.data(); \n  int   *d_A_col_index = A.col_index.data();\n  float *d_A_value     = A.values.data();\n  int   *d_A_y_label   = A.y_label.data();\n\n  float total_obj_val[1];\n  float l2_norm[1];\n  int   correct[1];\n\n  #pragma omp target data map (to: d_x[0:n], \\\n                                   d_A_row_ptr[0:A.row_ptr.size()], \\\n                                   d_A_value[0:A.values.size()], \\\n                                   d_A_col_index[0:A.col_index.size()], \\\n                                   d_A_y_label[0:A.y_label.size()]) \\\n                          map (alloc: d_grad[0:n], \\\n                                      total_obj_val[0:1], \\\n                                      l2_norm[0:1], \\\n                                      correct[0:1])\n{\n  long long train_start = get_time();\n\n  float obj_val = 0.f;\n  float train_error = 0.f;\n\n  for (int k = 0; k < iters; k++) {\n\n    \n\n    total_obj_val[0] = 0.f;\n    l2_norm[0] = 0.f;\n    correct[0] = 0;\n    \n    #pragma omp target update to (total_obj_val[0:1])\n    #pragma omp target update to (l2_norm[0:1])\n    #pragma omp target update to (correct[0:1])\n\n    \n\n    std::fill(grad.begin(), grad.end(), 0.f);\n\n    #pragma omp target update to (d_grad[0:n])\n    \n    \n\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < m; ++i) {\n\n      \n\n      float xp = 0.f;\n           \n      for( int j = d_A_row_ptr[i]; j < d_A_row_ptr[i+1]; ++j) {\n        xp += d_A_value[j] * d_x[d_A_col_index[j]];\n      }\n\n      \n\n      float v = logf(1.f + expf(-xp * d_A_y_label[i]));\n      #pragma omp atomic update\n      total_obj_val[0] += v;\n\n      \n\n      float prediction = 1.f / (1.f + expf(-xp));\n      int t = (prediction >= 0.5f) ? 1 : -1;\n      if (d_A_y_label[i] == t) {\n        #pragma omp atomic update\n        correct[0]++;\n      }\n\n      \n\n      float accum = expf(-d_A_y_label[i] * xp);\n      accum = accum / (1.f + accum);\n      for(int j = d_A_row_ptr[i]; j < d_A_row_ptr[i+1]; ++j) {\n        float temp = -accum * d_A_value[j] * d_A_y_label[i];\n        #pragma omp atomic update\n        d_grad[d_A_col_index[j]] += temp;\n      }\n    }\n\n    \n\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < n; ++i) {\n       #pragma omp atomic update\n       l2_norm[0] += d_x[i] * d_x[i];\n    }\n\n    #pragma omp target update from (total_obj_val[0:1])\n    #pragma omp target update from (l2_norm[0:1])\n    #pragma omp target update from (correct[0:1])\n\n    obj_val = total_obj_val[0] / (float)m + 0.5f * lambda * l2_norm[0];\n    train_error = 1.f - (correct[0]/(float)m); \n\n    \n\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < n; ++i) {\n      float g = d_grad[i] / (float)m + lambda * d_x[i]; \n      d_x[i] = d_x[i] - alpha * g;\n    }\n  }\n\n  long long train_end = get_time();\n  printf(\"Training time takes %lld(us) for %d iterations\\n\\n\", \n         train_end - train_start, iters);\n\n  \n\n  printf(\"object value = %f train_error = %f\\n\", obj_val, train_error);\n}\n\n  return 0; \n}\n"}}
{"kernel_name": "gd", "parallel_api": "serial", "code": {"main.cpp": "#include <cstdio>\n#include <string>\n#include <vector>\n#include <algorithm>\n#include \"utils.h\"\n\nint main(int argc, const char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <path to file> <lambda> <alpha> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const std::string file_path = argv[1]; \n  const float lambda = atof(argv[2]);\n  const float alpha = atof(argv[3]);\n  const int iters = atof(argv[4]);\n\n  \n\n  Classification_Data_CRS A;\n  get_CRSM_from_svm(A, file_path);\n\n  const int m = A.m; \n\n  const int n = A.n; \n\n\n  std::vector<float> x(n, 0.f);\n  std::vector<float> grad (n);\n\n  float *d_grad        = grad.data();\n  float *d_x           = x.data();\n  int   *d_A_row_ptr   = A.row_ptr.data(); \n  int   *d_A_col_index = A.col_index.data();\n  float *d_A_value     = A.values.data();\n  int   *d_A_y_label   = A.y_label.data();\n\n  float total_obj_val[1];\n  float l2_norm[1];\n  int   correct[1];\n\n  {\n  long long train_start = get_time();\n\n  float obj_val = 0.f;\n  float train_error = 0.f;\n\n  for (int k = 0; k < iters; k++) {\n\n    \n\n    total_obj_val[0] = 0.f;\n    l2_norm[0] = 0.f;\n    correct[0] = 0;\n    \n            \n    \n\n    std::fill(grad.begin(), grad.end(), 0.f);\n\n        \n    \n\n        for (int i = 0; i < m; ++i) {\n\n      \n\n      float xp = 0.f;\n           \n      for( int j = d_A_row_ptr[i]; j < d_A_row_ptr[i+1]; ++j) {\n        xp += d_A_value[j] * d_x[d_A_col_index[j]];\n      }\n\n      \n\n      float v = logf(1.f + expf(-xp * d_A_y_label[i]));\n            total_obj_val[0] += v;\n\n      \n\n      float prediction = 1.f / (1.f + expf(-xp));\n      int t = (prediction >= 0.5f) ? 1 : -1;\n      if (d_A_y_label[i] == t) {\n                correct[0]++;\n      }\n\n      \n\n      float accum = expf(-d_A_y_label[i] * xp);\n      accum = accum / (1.f + accum);\n      for(int j = d_A_row_ptr[i]; j < d_A_row_ptr[i+1]; ++j) {\n        float temp = -accum * d_A_value[j] * d_A_y_label[i];\n                d_grad[d_A_col_index[j]] += temp;\n      }\n    }\n\n    \n\n        for (int i = 0; i < n; ++i) {\n              l2_norm[0] += d_x[i] * d_x[i];\n    }\n\n            \n    obj_val = total_obj_val[0] / (float)m + 0.5f * lambda * l2_norm[0];\n    train_error = 1.f - (correct[0]/(float)m); \n\n    \n\n        for (int i = 0; i < n; ++i) {\n      float g = d_grad[i] / (float)m + lambda * d_x[i]; \n      d_x[i] = d_x[i] - alpha * g;\n    }\n  }\n\n  long long train_end = get_time();\n  printf(\"Training time takes %lld(us) for %d iterations\\n\\n\", \n         train_end - train_start, iters);\n\n  \n\n  printf(\"object value = %f train_error = %f\\n\", obj_val, train_error);\n}\n\n  return 0; \n}"}}
{"kernel_name": "gd", "parallel_api": "sycl", "code": {"main.cpp": "#include <cstdio>\n#include <string>\n#include <vector>\n#include <algorithm>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n\ntemplate <typename T>\ninline T atomicAdd(T *val, T operand)\n{\n  auto atm = sycl::atomic_ref<T,\n    sycl::memory_order::relaxed,\n    sycl::memory_scope::device,\n    sycl::access::address_space::global_space>(*val);\n  return atm.fetch_add(operand);\n}\n\nint main(int argc, const char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <path to file> <lambda> <alpha> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const std::string file_path = argv[1]; \n  const float lambda = atof(argv[2]);\n  const float alpha = atof(argv[3]);\n  const int iters = atof(argv[4]);\n\n  \n\n  Classification_Data_CRS A;\n  get_CRSM_from_svm(A, file_path);\n\n  const int m = A.m; \n\n  const int n = A.n; \n\n\n  std::vector<float> x(n, 0.f);\n  std::vector<float> grad (n);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_x = sycl::malloc_device<float>(n, q);\n  q.memcpy(d_x, x.data(), n * sizeof(float));\n\n  float *d_grad = sycl::malloc_device<float>(n, q);\n\n  float *d_total_obj_val = sycl::malloc_device<float>(1, q);\n\n  float *d_l2_norm = sycl::malloc_device<float>(1, q);\n\n  int *d_correct = sycl::malloc_device<int>(1, q);\n\n  int *d_row_ptr = sycl::malloc_device<int>(A.row_ptr.size(), q);\n  q.memcpy(d_row_ptr, A.row_ptr.data(), A.row_ptr.size() * sizeof(int));\n\n  int *d_col_index = sycl::malloc_device<int>(A.col_index.size(), q);\n  q.memcpy(d_col_index, A.col_index.data(), A.col_index.size() * sizeof(int));\n\n  float *d_value = sycl::malloc_device<float>(A.values.size(), q);\n  q.memcpy(d_value, A.values.data(), A.values.size() * sizeof(float));\n\n  int *d_y_label = sycl::malloc_device<int>(A.y_label.size(), q);\n  q.memcpy(d_y_label, A.y_label.data(), A.y_label.size() * sizeof(int));\n\n  sycl::range<1> gws((m+255)/256*256);\n  sycl::range<1> lws (256);\n\n  sycl::range<1> gws2((n+255)/256*256);\n  sycl::range<1> lws2 (256);\n\n  float obj_val = 0.f;\n  float train_error = 0.f;\n\n  q.wait();\n  long long train_start = get_time();\n\n  for (int k = 0; k < iters; k++) {\n\n    \n\n    float total_obj_val = 0.f;\n    float l2_norm = 0.f;\n    int correct = 0;\n\n    q.memcpy(d_total_obj_val, &total_obj_val, sizeof(float));\n    q.memcpy(d_l2_norm, &l2_norm, sizeof(float));\n    q.memcpy(d_correct, &correct, sizeof(int));\n\n    \n\n    std::fill(grad.begin(), grad.end(), 0.f);\n\n    q.memcpy(d_grad, grad.data(), n * sizeof(float));\n    \n    \n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class compute>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i < m) {\n          \n\n          float xp = 0.f;\n          for( int j = d_row_ptr[i]; j < d_row_ptr[i+1]; ++j){\n            xp += d_value[j] * d_x[d_col_index[j]];\n          }\n\n          \n\n          float v = sycl::log(1.f + sycl::exp(-xp * d_y_label[i]));\n          atomicAdd(d_total_obj_val, v);\n\n          \n\n          float prediction = 1.f / (1.f + expf(-xp));\n          int t = (prediction >= 0.5f) ? 1 : -1;\n          if (d_y_label[i] == t) {\n            atomicAdd(d_correct, 1);\n\t  }\n\n          \n\n          float accum = sycl::exp(-d_y_label[i] * xp);\n          accum = accum / (1.f + accum);\n          for(int j = d_row_ptr[i]; j < d_row_ptr[i+1]; ++j){\n            float temp = -accum * d_value[j] * d_y_label[i];\n            atomicAdd(d_grad+d_col_index[j], temp);\n          }\n        }\n      }); \n    }); \n\n    \n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class norm>(\n        sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i < n) {\n          atomicAdd(d_l2_norm, d_x[i]*d_x[i]);\n        }\n      });\n    });\n\n    q.memcpy(&total_obj_val, d_total_obj_val, sizeof(float));\n    q.memcpy(&l2_norm, d_l2_norm, sizeof(float));\n    q.memcpy(&correct, d_correct, sizeof(int));\n    \n    q.wait();\n\n    obj_val = total_obj_val / (float)m + 0.5f * lambda * l2_norm;\n    train_error = 1.f-(correct/(float)m); \n\n    \n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class update>(\n        sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i < n) {\n          float g = d_grad[i] / (float)m + lambda * d_x[i];\n          d_x[i] = d_x[i] - alpha * g;\n        }\n      });\n    });\n  }\n\n  q.wait();\n  long long train_end = get_time();\n  printf(\"Training time takes %lf (s) for %d iterations\\n\\n\", \n         (train_end - train_start) * 1e-6, iters);\n\n  \n\n  printf(\"object value = %f train_error = %f\\n\", obj_val, train_error);\n\n  sycl::free(d_row_ptr, q);\n  sycl::free(d_col_index, q);\n  sycl::free(d_value, q);\n  sycl::free(d_y_label, q);\n  sycl::free(d_x, q);\n  sycl::free(d_grad, q);\n  sycl::free(d_total_obj_val, q);\n  sycl::free(d_l2_norm, q);\n  sycl::free(d_correct, q);\n\n  return 0; \n}\n"}}
{"kernel_name": "glu", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <cuda.h>\n#include \"reference.h\"\n\n__global__\nvoid glu_kernel(\n   const int M,\n   const int split_dim_size,\n   const int N,\n   const float* Xdata,\n         float* Ydata)\n{\n  const int xOffset = 2 * split_dim_size * N;\n  const int yOffset = split_dim_size * N;\n  int index = blockIdx.x * blockDim.x + threadIdx.x; \n  if (index >= M * split_dim_size * N) return;\n\n  const int i = index / split_dim_size / N;\n  const int j = index / N % split_dim_size;\n  const int k = index % N;\n  const float x1 = Xdata[i * xOffset + j * N + k];\n  const float x2 = Xdata[i * xOffset + (j + split_dim_size) * N + k];\n  Ydata[i * yOffset + j * N + k] = x1 * (1.f / (1.f + expf(-x2)));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int ndims = atoi(argv[1]);\n  const int dim_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  std::vector<int> Xshape;\n\n  for (int i = 0; i < ndims; i++) {\n    Xshape.push_back(dim_size);\n  }\n\n  std::vector<int> Yshape;\n  Yshape.insert(Yshape.end(), Xshape.begin(), Xshape.end());\n\n  printf(\"Shape of input tensor: ( \");\n  for (int i = 0; i < ndims; i++)\n    printf(\"%d \", Xshape[i]);\n  printf(\")\\n\");\n\n  uint64_t nelems = size_from_dim(0, Xshape);\n  uint64_t nelems_bytes = nelems * sizeof(float);\n\n  float *X = (float*) malloc (nelems_bytes);\n  float *Y = (float*) malloc (nelems_bytes);\n  float *Y_ref = (float*) malloc (nelems_bytes);\n\n  std::default_random_engine generator(123);\n  std::uniform_real_distribution<float> distribution(-6.f,6.f);\n\n  for (uint64_t i = 0; i < nelems; i++) {\n    X[i] = distribution(generator);\n  }\n\n  float *d_X;\n  cudaMalloc((void**)&d_X, nelems_bytes);\n  cudaMemcpy(d_X, X, nelems_bytes, cudaMemcpyHostToDevice); \n\n  float *d_Y;\n  cudaMalloc((void**)&d_Y, nelems_bytes);\n\n  const int block_size = 256;\n\n  for (int input_dim = -1; input_dim < 3 * (ndims-1); input_dim++) {\n\n    const int split_index = (input_dim == -1) ? ndims - 1 : (input_dim % ndims);\n\n    if (Yshape[split_index] % 2 != 0) {\n      printf(\"Split dimension %d should be divided by two. Skip\\n\", Yshape[split_index]);\n      continue;\n    }\n    const int split_dim_size = Yshape[split_index] / 2;\n    const int m = size_to_dim(split_index, Xshape);\n    const int n = size_from_dim(split_index + 1, Xshape);\n\n    ComputeGlu(m, split_dim_size, n, X, Y_ref);\n\n    dim3 grids ((m * split_dim_size * n + block_size - 1) / block_size);\n    dim3 blocks (block_size);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      glu_kernel<<<grids, blocks>>>(m, split_dim_size, n, d_X, d_Y);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of GLU kernel (split dimension = %d): %f (us)\\n\",\n           split_index, (time * 1e-3f) / repeat);\n\n    cudaMemcpy(Y, d_Y, nelems_bytes, cudaMemcpyDeviceToHost);\n\n    bool ok = true;\n    for (uint64_t i = 0; i < nelems/2; i++) {\n      if (fabsf(Y[i] - Y_ref[i]) > 1e-3f) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  free(X);\n  free(Y);\n  free(Y_ref);\n  cudaFree(d_X);\n  cudaFree(d_Y);\n\n  return 0;\n}\n"}}
{"kernel_name": "glu", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n__global__\nvoid glu_kernel(\n   const int M,\n   const int split_dim_size,\n   const int N,\n   const float* Xdata,\n         float* Ydata)\n{\n  const int xOffset = 2 * split_dim_size * N;\n  const int yOffset = split_dim_size * N;\n  int index = blockIdx.x * blockDim.x + threadIdx.x; \n  if (index >= M * split_dim_size * N) return;\n\n  const int i = index / split_dim_size / N;\n  const int j = index / N % split_dim_size;\n  const int k = index % N;\n  const float x1 = Xdata[i * xOffset + j * N + k];\n  const float x2 = Xdata[i * xOffset + (j + split_dim_size) * N + k];\n  Ydata[i * yOffset + j * N + k] = x1 * (1.f / (1.f + expf(-x2)));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int ndims = atoi(argv[1]);\n  const int dim_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  std::vector<int> Xshape;\n\n  for (int i = 0; i < ndims; i++) {\n    Xshape.push_back(dim_size);\n  }\n\n  std::vector<int> Yshape;\n  Yshape.insert(Yshape.end(), Xshape.begin(), Xshape.end());\n\n  printf(\"Shape of input tensor: ( \");\n  for (int i = 0; i < ndims; i++)\n    printf(\"%d \", Xshape[i]);\n  printf(\")\\n\");\n\n  uint64_t nelems = size_from_dim(0, Xshape);\n  uint64_t nelems_bytes = nelems * sizeof(float);\n\n  float *X = (float*) malloc (nelems_bytes);\n  float *Y = (float*) malloc (nelems_bytes);\n  float *Y_ref = (float*) malloc (nelems_bytes);\n\n  std::default_random_engine generator(123);\n  std::uniform_real_distribution<float> distribution(-6.f,6.f);\n\n  for (uint64_t i = 0; i < nelems; i++) {\n    X[i] = i; \n\n  }\n\n  float *d_X;\n  hipMalloc((void**)&d_X, nelems_bytes);\n  hipMemcpy(d_X, X, nelems_bytes, hipMemcpyHostToDevice); \n\n  float *d_Y;\n  hipMalloc((void**)&d_Y, nelems_bytes);\n\n  const int block_size = 256; \n\n  for (int input_dim = -1; input_dim < 3 * (ndims-1); input_dim++) {\n\n    const int split_index = (input_dim == -1) ? ndims - 1 : (input_dim % ndims);\n\n    if (Yshape[split_index] % 2 != 0) {\n      printf(\"Split dimension %d should be divided by two. Skip\\n\", Yshape[split_index]);\n      continue;\n    }\n    const int split_dim_size = Yshape[split_index] / 2;\n    const int m = size_to_dim(split_index, Xshape);\n    const int n = size_from_dim(split_index + 1, Xshape);\n\n    ComputeGlu(m, split_dim_size, n, X, Y_ref);\n\n    dim3 grids ((m * split_dim_size * n + block_size - 1) / block_size);\n    dim3 blocks (block_size);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      glu_kernel<<<grids, blocks>>>(m, split_dim_size, n, d_X, d_Y);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of GLU kernel (split dimension = %d): %f (us)\\n\",\n           split_index, (time * 1e-3f) / repeat);\n\n    hipMemcpy(Y, d_Y, nelems_bytes, hipMemcpyDeviceToHost);\n\n    bool ok = true;\n    for (uint64_t i = 0; i < nelems/2; i++) {\n      if (fabsf(Y[i] - Y_ref[i]) > 1e-3f) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  free(X);\n  free(Y);\n  free(Y_ref);\n  hipFree(d_X);\n  hipFree(d_Y);\n\n  return 0;\n}\n"}}
{"kernel_name": "glu", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <omp.h>\n#include \"reference.h\"\n\n#define block_size 256\n\nvoid glu_kernel(\n   const int M,\n   const int split_dim_size,\n   const int N,\n   const float* Xdata,\n         float* Ydata)\n{\n  #pragma omp target teams distribute parallel for num_threads(block_size)\n  for (int index = 0; index < M * split_dim_size * N; index++) {\n    const int xOffset = 2 * split_dim_size * N;\n    const int yOffset = split_dim_size * N;\n\n    const int i = index / split_dim_size / N;\n    const int j = index / N % split_dim_size;\n    const int k = index % N;\n    const float x1 = Xdata[i * xOffset + j * N + k];\n    const float x2 = Xdata[i * xOffset + (j + split_dim_size) * N + k];\n    Ydata[i * yOffset + j * N + k] = x1 * (1.f / (1.f + expf(-x2)));\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int ndims = atoi(argv[1]);\n  const int dim_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  std::vector<int> Xshape;\n\n  for (int i = 0; i < ndims; i++) {\n    Xshape.push_back(dim_size);\n  }\n\n  std::vector<int> Yshape;\n  Yshape.insert(Yshape.end(), Xshape.begin(), Xshape.end());\n\n  printf(\"Shape of input tensor: ( \");\n  for (int i = 0; i < ndims; i++)\n    printf(\"%d \", Xshape[i]);\n  printf(\")\\n\");\n\n  uint64_t nelems = size_from_dim(0, Xshape);\n  uint64_t nelems_bytes = nelems * sizeof(float);\n\n  float *X = (float*) malloc (nelems_bytes);\n  float *Y = (float*) malloc (nelems_bytes);\n  float *Y_ref = (float*) malloc (nelems_bytes);\n\n  std::default_random_engine generator(123);\n  std::uniform_real_distribution<float> distribution(-6.f,6.f);\n\n  for (uint64_t i = 0; i < nelems; i++) {\n    X[i] = distribution(generator);\n  }\n\n  #pragma omp target data map(to: X[0:nelems]) map(alloc: Y[0:nelems])\n  {\n    for (int input_dim = -1; input_dim < 3 * (ndims-1); input_dim++) {\n\n      const int split_index = (input_dim == -1) ? ndims - 1: (input_dim % ndims);\n\n      if (Yshape[split_index] % 2 != 0) {\n        printf(\"Split dimension %d should be divided by two. Skip\\n\", Yshape[split_index]);\n        continue;\n      }\n      const int split_dim_size = Yshape[split_index] / 2;\n      const int m = size_to_dim(split_index, Xshape);\n      const int n = size_from_dim(split_index + 1, Xshape);\n\n      ComputeGlu(m, split_dim_size, n, X, Y_ref);\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        glu_kernel(m, split_dim_size, n, X, Y);\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of GLU kernel (split dimension = %d): %f (us)\\n\",\n             split_index, (time * 1e-3f) / repeat);\n\n      #pragma omp target update from (Y[0:nelems])\n\n      bool ok = true;\n      for (uint64_t i = 0; i < nelems/2; i++) {\n        if (fabsf(Y[i] - Y_ref[i]) > 1e-3f) {\n          ok = false;\n          break;\n        }\n      }\n      printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n    }\n  }\n\n  free(X);\n  free(Y);\n  free(Y_ref);\n\n  return 0;\n}\n"}}
{"kernel_name": "glu", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <vector>\n#include \"reference.h\"\n\n#define block_size 256\n\nvoid glu_kernel(\n   const int M,\n   const int split_dim_size,\n   const int N,\n   const float* Xdata,\n         float* Ydata)\n{\n    for (int index = 0; index < M * split_dim_size * N; index++) {\n    const int xOffset = 2 * split_dim_size * N;\n    const int yOffset = split_dim_size * N;\n\n    const int i = index / split_dim_size / N;\n    const int j = index / N % split_dim_size;\n    const int k = index % N;\n    const float x1 = Xdata[i * xOffset + j * N + k];\n    const float x2 = Xdata[i * xOffset + (j + split_dim_size) * N + k];\n    Ydata[i * yOffset + j * N + k] = x1 * (1.f / (1.f + expf(-x2)));\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int ndims = atoi(argv[1]);\n  const int dim_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  std::vector<int> Xshape;\n\n  for (int i = 0; i < ndims; i++) {\n    Xshape.push_back(dim_size);\n  }\n\n  std::vector<int> Yshape;\n  Yshape.insert(Yshape.end(), Xshape.begin(), Xshape.end());\n\n  printf(\"Shape of input tensor: ( \");\n  for (int i = 0; i < ndims; i++)\n    printf(\"%d \", Xshape[i]);\n  printf(\")\\n\");\n\n  uint64_t nelems = size_from_dim(0, Xshape);\n  uint64_t nelems_bytes = nelems * sizeof(float);\n\n  float *X = (float*) malloc (nelems_bytes);\n  float *Y = (float*) malloc (nelems_bytes);\n  float *Y_ref = (float*) malloc (nelems_bytes);\n\n  std::default_random_engine generator(123);\n  std::uniform_real_distribution<float> distribution(-6.f,6.f);\n\n  for (uint64_t i = 0; i < nelems; i++) {\n    X[i] = distribution(generator);\n  }\n\n    {\n    for (int input_dim = -1; input_dim < 3 * (ndims-1); input_dim++) {\n\n      const int split_index = (input_dim == -1) ? ndims - 1: (input_dim % ndims);\n\n      if (Yshape[split_index] % 2 != 0) {\n        printf(\"Split dimension %d should be divided by two. Skip\\n\", Yshape[split_index]);\n        continue;\n      }\n      const int split_dim_size = Yshape[split_index] / 2;\n      const int m = size_to_dim(split_index, Xshape);\n      const int n = size_from_dim(split_index + 1, Xshape);\n\n      ComputeGlu(m, split_dim_size, n, X, Y_ref);\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        glu_kernel(m, split_dim_size, n, X, Y);\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of GLU kernel (split dimension = %d): %f (us)\\n\",\n             split_index, (time * 1e-3f) / repeat);\n\n      \n      bool ok = true;\n      for (uint64_t i = 0; i < nelems/2; i++) {\n        if (fabsf(Y[i] - Y_ref[i]) > 1e-3f) {\n          ok = false;\n          break;\n        }\n      }\n      printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n    }\n  }\n\n  free(X);\n  free(Y);\n  free(Y_ref);\n\n  return 0;\n}"}}
{"kernel_name": "glu", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nvoid glu_kernel(\n   sycl::nd_item<1> &item,\n   const int M,\n   const int split_dim_size,\n   const int N,\n   const float* Xdata,\n         float* Ydata)\n{\n  const int xOffset = 2 * split_dim_size * N;\n  const int yOffset = split_dim_size * N;\n  int index = item.get_global_id(0);\n  if (index >= M * split_dim_size * N) return;\n\n  const int i = index / split_dim_size / N;\n  const int j = index / N % split_dim_size;\n  const int k = index % N;\n  const float x1 = Xdata[i * xOffset + j * N + k];\n  const float x2 = Xdata[i * xOffset + (j + split_dim_size) * N + k];\n  Ydata[i * yOffset + j * N + k] = x1 * (1.f / (1.f + sycl::exp(-x2)));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int ndims = atoi(argv[1]);\n  const int dim_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  std::vector<int> Xshape;\n\n  for (int i = 0; i < ndims; i++) {\n    Xshape.push_back(dim_size);\n  }\n\n  std::vector<int> Yshape;\n  Yshape.insert(Yshape.end(), Xshape.begin(), Xshape.end());\n\n  printf(\"Shape of input tensor: ( \");\n  for (int i = 0; i < ndims; i++)\n    printf(\"%d \", Xshape[i]);\n  printf(\")\\n\");\n\n  uint64_t nelems = size_from_dim(0, Xshape);\n  uint64_t nelems_bytes = nelems * sizeof(float);\n\n  float *X = (float*) malloc (nelems_bytes);\n  float *Y = (float*) malloc (nelems_bytes);\n  float *Y_ref = (float*) malloc (nelems_bytes);\n\n  std::default_random_engine generator(123);\n  std::uniform_real_distribution<float> distribution(-6.f,6.f);\n\n  for (uint64_t i = 0; i < nelems; i++) {\n    X[i] = distribution(generator);\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_X = sycl::malloc_device<float>(nelems, q);\n  q.memcpy(d_X, X, nelems_bytes);\n\n  float *d_Y = sycl::malloc_device<float>(nelems, q);\n\n  const int block_size = 256; \n\n  for (int input_dim = -1; input_dim < 3 * (ndims-1); input_dim++) {\n\n    const int split_index = (input_dim == -1) ? (ndims - 1) : (input_dim % ndims);\n\n    if (Yshape[split_index] % 2 != 0) {\n      printf(\"Split dimension %d should be divided by two. Skip\\n\", Yshape[split_index]);\n      continue;\n    }\n    const int split_dim_size = Yshape[split_index] / 2;\n    const int m = size_to_dim(split_index, Xshape);\n    const int n = size_from_dim(split_index + 1, Xshape);\n\n    ComputeGlu(m, split_dim_size, n, X, Y_ref);\n\n    sycl::range<1> gws ((m * split_dim_size * n + block_size - 1) / block_size * block_size);\n    sycl::range<1> lws (block_size);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class glu>(\n          sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n          glu_kernel(item, m, split_dim_size, n, d_X, d_Y);\n        });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of GLU kernel (split dimension = %d): %f (us)\\n\",\n           split_index, (time * 1e-3f) / repeat);\n\n    q.memcpy(Y, d_Y, nelems_bytes).wait();\n\n    bool ok = true;\n    for (uint64_t i = 0; i < nelems/2; i++) {\n      if (fabsf(Y[i] - Y_ref[i]) > 1e-3f) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  free(X);\n  free(Y);\n  free(Y_ref);\n  sycl::free(d_X, q);\n  sycl::free(d_Y, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "kalman", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n#define DI __device__\n\n\n\ntemplate <int n>\nDI void Mv_l(const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = sum;\n  }\n}\n\ntemplate <int n>\nDI void Mv_l(double alpha, const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = alpha * sum;\n  }\n}\n\n\n\ntemplate <int n, bool aT = false, bool bT = false>\nDI void MM_l(const double* A, const double* B, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    for (int j = 0; j < n; j++) {\n      double sum = 0.0;\n      for (int k = 0; k < n; k++) {\n        double Aik = aT ? A[k + i * n] : A[i + k * n];\n        double Bkj = bT ? B[j + k * n] : B[k + j * n];\n        sum += Aik * Bkj;\n      }\n      out[i + j * n] = sum;\n    }\n  }\n}\n\n\n\ntemplate <int rd>\n__global__ void kalman(\n  const double*__restrict__ ys,\n  int nobs,\n  const double*__restrict__ T,\n  const double*__restrict__ Z,\n  const double*__restrict__ RQR,\n  const double*__restrict__ P,\n  const double*__restrict__ alpha,\n  bool intercept,\n  const double*__restrict__ d_mu,\n  int batch_size,\n  double*__restrict__ vs,\n  double*__restrict__ Fs,\n  double*__restrict__ sum_logFs,\n  int n_diff,\n  int fc_steps = 0,\n  double*__restrict__ d_fc = nullptr,\n  bool conf_int = false,\n  double* d_F_fc = nullptr)\n{\n  constexpr int rd2 = rd * rd;\n  double l_RQR[rd2];\n  double l_T[rd2];\n  double l_Z[rd];\n  double l_P[rd2];\n  double l_alpha[rd];\n  double l_K[rd];\n  double l_tmp[rd2];\n  double l_TP[rd2];\n\n  int bid = blockDim.x * blockIdx.x + threadIdx.x;\n  if (bid < batch_size) {\n    \n\n    int b_rd_offset  = bid * rd;\n    int b_rd2_offset = bid * rd2;\n    for (int i = 0; i < rd2; i++) {\n      l_RQR[i] = RQR[b_rd2_offset + i];\n      l_T[i]   = T[b_rd2_offset + i];\n      l_P[i]   = P[b_rd2_offset + i];\n    }\n    for (int i = 0; i < rd; i++) {\n      if (n_diff > 0) l_Z[i] = Z[b_rd_offset + i];\n      l_alpha[i] = alpha[b_rd_offset + i];\n    }\n\n    double b_sum_logFs = 0.0;\n    const double* b_ys = ys + bid * nobs;\n    double* b_vs       = vs + bid * nobs; \n    double* b_Fs       = Fs + bid * nobs;\n\n    double mu = intercept ? d_mu[bid] : 0.0;\n\n    for (int it = 0; it < nobs; it++) {\n      \n\n      double vs_it = b_ys[it];\n      if (n_diff == 0)\n        vs_it -= l_alpha[0];\n      else {\n        for (int i = 0; i < rd; i++) {\n          vs_it -= l_alpha[i] * l_Z[i];\n        }\n      }\n      b_vs[it] = vs_it;\n\n      \n\n      double _Fs;\n      if (n_diff == 0)\n        _Fs = l_P[0];\n      else {\n        _Fs = 0.0;\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n          }\n        }\n      }\n      b_Fs[it] = _Fs;\n      if (it >= n_diff) b_sum_logFs += log(_Fs);\n\n      \n\n      \n\n      MM_l<rd>(l_T, l_P, l_TP);\n      \n\n      double _1_Fs = 1.0 / _Fs;\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_K[i] = _1_Fs * l_TP[i];\n        }\n      } else\n        Mv_l<rd>(_1_Fs, l_TP, l_Z, l_K);\n\n      \n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      \n\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i] + l_K[i] * vs_it;\n      }\n      \n\n      l_alpha[n_diff] += mu;\n\n      \n\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_tmp[i] = l_T[i];\n      }\n      \n\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_tmp[i] -= l_K[i];\n        }\n      } else {\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            l_tmp[j * rd + i] -= l_K[i] * l_Z[j];\n          }\n        }\n      }\n\n      \n\n      \n\n      MM_l<rd, false, true>(l_TP, l_tmp, l_P);\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_P[i] += l_RQR[i];\n      }\n    }\n    sum_logFs[bid] = b_sum_logFs;\n\n    \n\n    double* b_fc   = fc_steps ? d_fc + bid * fc_steps : nullptr;\n    double* b_F_fc = conf_int ? d_F_fc + bid * fc_steps : nullptr;\n    for (int it = 0; it < fc_steps; it++) {\n      if (n_diff == 0)\n        b_fc[it] = l_alpha[0];\n      else {\n        double pred = 0.0;\n        for (int i = 0; i < rd; i++) {\n          pred += l_alpha[i] * l_Z[i];\n        }\n        b_fc[it] = pred;\n      }\n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i];\n      }\n      l_alpha[n_diff] += mu;\n\n      if (conf_int) {\n        if (n_diff == 0)\n          b_F_fc[it] = l_P[0];\n        else {\n          double _Fs = 0.0;\n          for (int i = 0; i < rd; i++) {\n            for (int j = 0; j < rd; j++) {\n              _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n            }\n          }\n          b_F_fc[it] = _Fs;\n        }\n\n        \n\n        \n\n        MM_l<rd>(l_T, l_P, l_TP);\n        \n\n        MM_l<rd, false, true>(l_TP, l_T, l_P);\n        \n\n        for (int i = 0; i < rd2; i++) {\n          l_P[i] += l_RQR[i];\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <#series> <#observations> <forcast steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int nseries = atoi(argv[1]); \n  const int nobs = atoi(argv[2]);\n  const int fc_steps = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int rd = 8;\n  const int rd2 = rd * rd;\n  const int batch_size = nseries;\n  const int rd2_size = nseries * rd2 * sizeof(double);\n  const int rd_size = nseries * rd * sizeof(double);\n  const int nobs_size = nseries * nobs * sizeof(double);\n  const int ns_size = nseries * sizeof(double);\n  const int fc_size = fc_steps * nseries * sizeof(double);\n\n  int i;\n  srand(123);\n  double *RQR = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    RQR[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_RQR;\n  cudaMalloc((void**)&d_RQR, rd2_size);\n  cudaMemcpy(d_RQR, RQR, rd2_size, cudaMemcpyHostToDevice);\n\n  double *T = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    T[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_T;\n  cudaMalloc((void**)&d_T, rd2_size);\n  cudaMemcpy(d_T, T, rd2_size, cudaMemcpyHostToDevice);\n\n  double *P = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    P[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_P;\n  cudaMalloc((void**)&d_P, rd2_size);\n  cudaMemcpy(d_P, P, rd2_size, cudaMemcpyHostToDevice);\n\n  double *Z = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    Z[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_Z;\n  cudaMalloc((void**)&d_Z, rd_size);\n  cudaMemcpy(d_Z, Z, rd_size, cudaMemcpyHostToDevice);\n\n  double *alpha = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    alpha[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_alpha;\n  cudaMalloc((void**)&d_alpha, rd_size);\n  cudaMemcpy(d_alpha, alpha, rd_size, cudaMemcpyHostToDevice);\n\n  double *ys = (double*) malloc (nobs_size);\n  for (i = 0; i < nobs * nseries; i++)\n    ys[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_ys;\n  cudaMalloc((void**)&d_ys, nobs_size);\n  cudaMemcpy(d_ys, ys, nobs_size, cudaMemcpyHostToDevice);\n\n  double *mu = (double*) malloc (ns_size);\n  for (i = 0; i < nseries; i++)\n    mu[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_mu;\n  cudaMalloc((void**)&d_mu, ns_size);\n  cudaMemcpy(d_mu, mu, ns_size, cudaMemcpyHostToDevice);\n\n  double *vs = (double*) malloc (nobs_size);\n  double *d_vs;\n  cudaMalloc((void**)&d_vs, nobs_size);\n\n  double *Fs = (double*) malloc (nobs_size);\n  double *d_Fs;\n  cudaMalloc((void**)&d_Fs, nobs_size);\n\n  double *sum_logFs = (double*) malloc (ns_size);\n  double *d_sum_logFs;\n  cudaMalloc((void**)&d_sum_logFs, ns_size);\n\n  double *fc = (double*) malloc (fc_size);\n  double *d_fc;\n  cudaMalloc((void**)&d_fc, fc_size);\n\n  double *F_fc = (double*) malloc (fc_size);\n  double *d_F_fc;\n  cudaMalloc((void**)&d_F_fc, fc_size);\n\n  dim3 grids ((nseries + 255)/256);\n  dim3 blocks (256);\n\n  for (int n_diff = 0; n_diff < rd; n_diff++) {\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n  \n    for (i = 0; i < repeat; i++)\n      kalman<rd> <<< grids, blocks >>> (\n        d_ys,\n        nobs,\n        d_T,\n        d_Z,\n        d_RQR,\n        d_P,\n        d_alpha,\n        true, \n\n        d_mu,\n        batch_size,\n        d_vs,\n        d_Fs,\n        d_sum_logFs,\n        n_diff,\n        fc_steps,\n        d_fc,\n        true, \n\n        d_F_fc );\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (n_diff = %d): %f (s)\\n\", n_diff, (time * 1e-9f) / repeat);\n  }\n\n  cudaMemcpy(F_fc, d_F_fc, fc_size, cudaMemcpyDeviceToHost);\n\n  double sum = 0.0;\n  for (i = 0; i < fc_steps * nseries - 1; i++)\n    sum += (fabs(F_fc[i+1]) - fabs(F_fc[i])) / (fabs(F_fc[i+1]) + fabs(F_fc[i]));\n  printf(\"Checksum: %lf\\n\", sum);\n\n  free(fc);\n  free(F_fc);\n  free(sum_logFs);\n  free(mu);\n  free(Fs);\n  free(vs);\n  free(ys);\n  free(alpha);\n  free(Z);\n  free(P);\n  free(T);\n  free(RQR);\n  cudaFree(d_RQR);\n  cudaFree(d_T);\n  cudaFree(d_P);\n  cudaFree(d_Z);\n  cudaFree(d_alpha);\n  cudaFree(d_ys);\n  cudaFree(d_vs);\n  cudaFree(d_Fs);\n  cudaFree(d_mu);\n  cudaFree(d_sum_logFs);\n  cudaFree(d_F_fc);\n  cudaFree(d_fc);\n  return 0;\n}\n"}}
{"kernel_name": "kalman", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define DI __device__\n\n\n\ntemplate <int n>\nDI void Mv_l(const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = sum;\n  }\n}\n\ntemplate <int n>\nDI void Mv_l(double alpha, const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = alpha * sum;\n  }\n}\n\n\n\ntemplate <int n, bool aT = false, bool bT = false>\nDI void MM_l(const double* A, const double* B, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    for (int j = 0; j < n; j++) {\n      double sum = 0.0;\n      for (int k = 0; k < n; k++) {\n        double Aik = aT ? A[k + i * n] : A[i + k * n];\n        double Bkj = bT ? B[j + k * n] : B[k + j * n];\n        sum += Aik * Bkj;\n      }\n      out[i + j * n] = sum;\n    }\n  }\n}\n\n\n\ntemplate <int rd>\n__global__ void kalman(\n  const double*__restrict__ ys,\n  int nobs,\n  const double*__restrict__ T,\n  const double*__restrict__ Z,\n  const double*__restrict__ RQR,\n  const double*__restrict__ P,\n  const double*__restrict__ alpha,\n  bool intercept,\n  const double*__restrict__ d_mu,\n  int batch_size,\n  double*__restrict__ vs,\n  double*__restrict__ Fs,\n  double*__restrict__ sum_logFs,\n  int n_diff,\n  int fc_steps = 0,\n  double*__restrict__ d_fc = nullptr,\n  bool conf_int = false,\n  double* d_F_fc = nullptr)\n{\n  constexpr int rd2 = rd * rd;\n  double l_RQR[rd2];\n  double l_T[rd2];\n  double l_Z[rd];\n  double l_P[rd2];\n  double l_alpha[rd];\n  double l_K[rd];\n  double l_tmp[rd2];\n  double l_TP[rd2];\n\n  int bid = blockDim.x * blockIdx.x + threadIdx.x;\n  if (bid < batch_size) {\n    \n\n    int b_rd_offset  = bid * rd;\n    int b_rd2_offset = bid * rd2;\n    for (int i = 0; i < rd2; i++) {\n      l_RQR[i] = RQR[b_rd2_offset + i];\n      l_T[i]   = T[b_rd2_offset + i];\n      l_P[i]   = P[b_rd2_offset + i];\n    }\n    for (int i = 0; i < rd; i++) {\n      if (n_diff > 0) l_Z[i] = Z[b_rd_offset + i];\n      l_alpha[i] = alpha[b_rd_offset + i];\n    }\n\n    double b_sum_logFs = 0.0;\n    const double* b_ys = ys + bid * nobs;\n    double* b_vs       = vs + bid * nobs; \n    double* b_Fs       = Fs + bid * nobs;\n\n    double mu = intercept ? d_mu[bid] : 0.0;\n\n    for (int it = 0; it < nobs; it++) {\n      \n\n      double vs_it = b_ys[it];\n      if (n_diff == 0)\n        vs_it -= l_alpha[0];\n      else {\n        for (int i = 0; i < rd; i++) {\n          vs_it -= l_alpha[i] * l_Z[i];\n        }\n      }\n      b_vs[it] = vs_it;\n\n      \n\n      double _Fs;\n      if (n_diff == 0)\n        _Fs = l_P[0];\n      else {\n        _Fs = 0.0;\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n          }\n        }\n      }\n      b_Fs[it] = _Fs;\n      if (it >= n_diff) b_sum_logFs += log(_Fs);\n\n      \n\n      \n\n      MM_l<rd>(l_T, l_P, l_TP);\n      \n\n      double _1_Fs = 1.0 / _Fs;\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_K[i] = _1_Fs * l_TP[i];\n        }\n      } else\n        Mv_l<rd>(_1_Fs, l_TP, l_Z, l_K);\n\n      \n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      \n\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i] + l_K[i] * vs_it;\n      }\n      \n\n      l_alpha[n_diff] += mu;\n\n      \n\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_tmp[i] = l_T[i];\n      }\n      \n\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_tmp[i] -= l_K[i];\n        }\n      } else {\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            l_tmp[j * rd + i] -= l_K[i] * l_Z[j];\n          }\n        }\n      }\n\n      \n\n      \n\n      MM_l<rd, false, true>(l_TP, l_tmp, l_P);\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_P[i] += l_RQR[i];\n      }\n    }\n    sum_logFs[bid] = b_sum_logFs;\n\n    \n\n    double* b_fc   = fc_steps ? d_fc + bid * fc_steps : nullptr;\n    double* b_F_fc = conf_int ? d_F_fc + bid * fc_steps : nullptr;\n    for (int it = 0; it < fc_steps; it++) {\n      if (n_diff == 0)\n        b_fc[it] = l_alpha[0];\n      else {\n        double pred = 0.0;\n        for (int i = 0; i < rd; i++) {\n          pred += l_alpha[i] * l_Z[i];\n        }\n        b_fc[it] = pred;\n      }\n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i];\n      }\n      l_alpha[n_diff] += mu;\n\n      if (conf_int) {\n        if (n_diff == 0)\n          b_F_fc[it] = l_P[0];\n        else {\n          double _Fs = 0.0;\n          for (int i = 0; i < rd; i++) {\n            for (int j = 0; j < rd; j++) {\n              _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n            }\n          }\n          b_F_fc[it] = _Fs;\n        }\n\n        \n\n        \n\n        MM_l<rd>(l_T, l_P, l_TP);\n        \n\n        MM_l<rd, false, true>(l_TP, l_T, l_P);\n        \n\n        for (int i = 0; i < rd2; i++) {\n          l_P[i] += l_RQR[i];\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <#series> <#observations> <forcast steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int nseries = atoi(argv[1]); \n  const int nobs = atoi(argv[2]);\n  const int fc_steps = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int rd = 8;\n  const int rd2 = rd * rd;\n  const int batch_size = nseries;\n  const int rd2_size = nseries * rd2 * sizeof(double);\n  const int rd_size = nseries * rd * sizeof(double);\n  const int nobs_size = nseries * nobs * sizeof(double);\n  const int ns_size = nseries * sizeof(double);\n  const int fc_size = fc_steps * nseries * sizeof(double);\n\n  int i;\n  srand(123);\n  double *RQR = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    RQR[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_RQR;\n  hipMalloc((void**)&d_RQR, rd2_size);\n  hipMemcpy(d_RQR, RQR, rd2_size, hipMemcpyHostToDevice);\n\n  double *T = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    T[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_T;\n  hipMalloc((void**)&d_T, rd2_size);\n  hipMemcpy(d_T, T, rd2_size, hipMemcpyHostToDevice);\n\n  double *P = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    P[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_P;\n  hipMalloc((void**)&d_P, rd2_size);\n  hipMemcpy(d_P, P, rd2_size, hipMemcpyHostToDevice);\n\n  double *Z = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    Z[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_Z;\n  hipMalloc((void**)&d_Z, rd_size);\n  hipMemcpy(d_Z, Z, rd_size, hipMemcpyHostToDevice);\n\n  double *alpha = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    alpha[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_alpha;\n  hipMalloc((void**)&d_alpha, rd_size);\n  hipMemcpy(d_alpha, alpha, rd_size, hipMemcpyHostToDevice);\n\n  double *ys = (double*) malloc (nobs_size);\n  for (i = 0; i < nobs * nseries; i++)\n    ys[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_ys;\n  hipMalloc((void**)&d_ys, nobs_size);\n  hipMemcpy(d_ys, ys, nobs_size, hipMemcpyHostToDevice);\n\n  double *mu = (double*) malloc (ns_size);\n  for (i = 0; i < nseries; i++)\n    mu[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_mu;\n  hipMalloc((void**)&d_mu, ns_size);\n  hipMemcpy(d_mu, mu, ns_size, hipMemcpyHostToDevice);\n\n  double *vs = (double*) malloc (nobs_size);\n  double *d_vs;\n  hipMalloc((void**)&d_vs, nobs_size);\n\n  double *Fs = (double*) malloc (nobs_size);\n  double *d_Fs;\n  hipMalloc((void**)&d_Fs, nobs_size);\n\n  double *sum_logFs = (double*) malloc (ns_size);\n  double *d_sum_logFs;\n  hipMalloc((void**)&d_sum_logFs, ns_size);\n\n  double *fc = (double*) malloc (fc_size);\n  double *d_fc;\n  hipMalloc((void**)&d_fc, fc_size);\n\n  double *F_fc = (double*) malloc (fc_size);\n  double *d_F_fc;\n  hipMalloc((void**)&d_F_fc, fc_size);\n\n  dim3 grids ((nseries + 255)/256);\n  dim3 blocks (256);\n\n  for (int n_diff = 0; n_diff < rd; n_diff++) {\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n  \n    for (i = 0; i < repeat; i++)\n      hipLaunchKernelGGL(HIP_KERNEL_NAME(kalman<rd>), grids, blocks , 0, 0, \n        d_ys,\n        nobs,\n        d_T,\n        d_Z,\n        d_RQR,\n        d_P,\n        d_alpha,\n        true, \n\n        d_mu,\n        batch_size,\n        d_vs,\n        d_Fs,\n        d_sum_logFs,\n        n_diff,\n        fc_steps,\n        d_fc,\n        true, \n\n        d_F_fc );\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (n_diff = %d): %f (s)\\n\", n_diff, (time * 1e-9f) / repeat);\n  }\n\n  hipMemcpy(F_fc, d_F_fc, fc_size, hipMemcpyDeviceToHost);\n\n  double sum = 0.0;\n  for (i = 0; i < fc_steps * nseries - 1; i++)\n    sum += (fabs(F_fc[i+1]) - fabs(F_fc[i])) / (fabs(F_fc[i+1]) + fabs(F_fc[i]));\n  printf(\"Checksum: %lf\\n\", sum);\n\n  free(fc);\n  free(F_fc);\n  free(sum_logFs);\n  free(mu);\n  free(Fs);\n  free(vs);\n  free(ys);\n  free(alpha);\n  free(Z);\n  free(P);\n  free(T);\n  free(RQR);\n  hipFree(d_RQR);\n  hipFree(d_T);\n  hipFree(d_P);\n  hipFree(d_Z);\n  hipFree(d_alpha);\n  hipFree(d_ys);\n  hipFree(d_vs);\n  hipFree(d_Fs);\n  hipFree(d_mu);\n  hipFree(d_sum_logFs);\n  hipFree(d_F_fc);\n  hipFree(d_fc);\n  return 0;\n}\n"}}
{"kernel_name": "kalman", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#pragma omp declare target\n\n\n\ntemplate <int n>\nvoid Mv_l(const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = sum;\n  }\n}\n\ntemplate <int n>\nvoid Mv_l(double alpha, const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = alpha * sum;\n  }\n}\n\n\n\ntemplate <int n, bool aT = false, bool bT = false>\nvoid MM_l(const double* A, const double* B, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    for (int j = 0; j < n; j++) {\n      double sum = 0.0;\n      for (int k = 0; k < n; k++) {\n        double Aik = aT ? A[k + i * n] : A[i + k * n];\n        double Bkj = bT ? B[j + k * n] : B[k + j * n];\n        sum += Aik * Bkj;\n      }\n      out[i + j * n] = sum;\n    }\n  }\n}\n#pragma omp end declare target\n\n\n\ntemplate <int rd>\nvoid kalman(\n  const double*__restrict ys,\n  int nobs,\n  const double*__restrict T,\n  const double*__restrict Z,\n  const double*__restrict RQR,\n  const double*__restrict P,\n  const double*__restrict alpha,\n  bool intercept,\n  const double*__restrict d_mu,\n  int batch_size,\n  double*__restrict vs,\n  double*__restrict Fs,\n  double*__restrict sum_logFs,\n  int n_diff,\n  int fc_steps = 0,\n  double*__restrict d_fc = nullptr,\n  bool conf_int = false,\n  double* d_F_fc = nullptr)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int bid = 0; bid < batch_size; bid++) {\n    constexpr int rd2 = rd * rd;\n    double l_RQR[rd2];\n    double l_T[rd2];\n    double l_Z[rd];\n    double l_P[rd2];\n    double l_alpha[rd];\n    double l_K[rd];\n    double l_tmp[rd2];\n    double l_TP[rd2];\n\n    \n\n    int b_rd_offset  = bid * rd;\n    int b_rd2_offset = bid * rd2;\n    for (int i = 0; i < rd2; i++) {\n      l_RQR[i] = RQR[b_rd2_offset + i];\n      l_T[i]   = T[b_rd2_offset + i];\n      l_P[i]   = P[b_rd2_offset + i];\n    }\n    for (int i = 0; i < rd; i++) {\n      if (n_diff > 0) l_Z[i] = Z[b_rd_offset + i];\n      l_alpha[i] = alpha[b_rd_offset + i];\n    }\n\n    double b_sum_logFs = 0.0;\n    const double* b_ys = ys + bid * nobs;\n    double* b_vs       = vs + bid * nobs; \n    double* b_Fs       = Fs + bid * nobs;\n\n    double mu = intercept ? d_mu[bid] : 0.0;\n\n    for (int it = 0; it < nobs; it++) {\n      \n\n      double vs_it = b_ys[it];\n      if (n_diff == 0)\n        vs_it -= l_alpha[0];\n      else {\n        for (int i = 0; i < rd; i++) {\n          vs_it -= l_alpha[i] * l_Z[i];\n        }\n      }\n      b_vs[it] = vs_it;\n\n      \n\n      double _Fs;\n      if (n_diff == 0)\n        _Fs = l_P[0];\n      else {\n        _Fs = 0.0;\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n          }\n        }\n      }\n      b_Fs[it] = _Fs;\n      if (it >= n_diff) b_sum_logFs += log(_Fs);\n\n      \n\n      \n\n      MM_l<rd>(l_T, l_P, l_TP);\n      \n\n      double _1_Fs = 1.0 / _Fs;\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_K[i] = _1_Fs * l_TP[i];\n        }\n      } else\n        Mv_l<rd>(_1_Fs, l_TP, l_Z, l_K);\n\n      \n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      \n\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i] + l_K[i] * vs_it;\n      }\n      \n\n      l_alpha[n_diff] += mu;\n\n      \n\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_tmp[i] = l_T[i];\n      }\n      \n\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_tmp[i] -= l_K[i];\n        }\n      } else {\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            l_tmp[j * rd + i] -= l_K[i] * l_Z[j];\n          }\n        }\n      }\n\n      \n\n      \n\n      MM_l<rd, false, true>(l_TP, l_tmp, l_P);\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_P[i] += l_RQR[i];\n      }\n    }\n    sum_logFs[bid] = b_sum_logFs;\n\n    \n\n    double* b_fc   = fc_steps ? d_fc + bid * fc_steps : nullptr;\n    double* b_F_fc = conf_int ? d_F_fc + bid * fc_steps : nullptr;\n    for (int it = 0; it < fc_steps; it++) {\n      if (n_diff == 0)\n        b_fc[it] = l_alpha[0];\n      else {\n        double pred = 0.0;\n        for (int i = 0; i < rd; i++) {\n          pred += l_alpha[i] * l_Z[i];\n        }\n        b_fc[it] = pred;\n      }\n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i];\n      }\n      l_alpha[n_diff] += mu;\n\n      if (conf_int) {\n        if (n_diff == 0)\n          b_F_fc[it] = l_P[0];\n        else {\n          double _Fs = 0.0;\n          for (int i = 0; i < rd; i++) {\n            for (int j = 0; j < rd; j++) {\n              _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n            }\n          }\n          b_F_fc[it] = _Fs;\n        }\n\n        \n\n        \n\n        MM_l<rd>(l_T, l_P, l_TP);\n        \n\n        MM_l<rd, false, true>(l_TP, l_T, l_P);\n        \n\n        for (int i = 0; i < rd2; i++) {\n          l_P[i] += l_RQR[i];\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <#series> <#observations> <forcast steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int nseries = atoi(argv[1]); \n  const int nobs = atoi(argv[2]);\n  const int fc_steps = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int rd = 8;\n  const int rd2 = rd * rd;\n  const int batch_size = nseries;\n\n  const int rd2_word = nseries * rd2;\n  const int rd_word = nseries * rd;\n  const int nobs_word = nseries * nobs;\n  const int ns_word = nseries;\n  const int fc_word = fc_steps * nseries;\n\n  const int rd2_size = rd2_word * sizeof(double);\n  const int rd_size = rd_word * sizeof(double);\n  const int nobs_size = nobs_word * sizeof(double);\n  const int ns_size = ns_word * sizeof(double);\n  const int fc_size = fc_word * sizeof(double);\n\n  int i;\n  srand(123);\n  double *RQR = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    RQR[i] = (double)rand() / (double)RAND_MAX;\n\n  double *T = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    T[i] = (double)rand() / (double)RAND_MAX;\n\n  double *P = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    P[i] = (double)rand() / (double)RAND_MAX;\n\n  double *Z = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    Z[i] = (double)rand() / (double)RAND_MAX;\n\n  double *alpha = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    alpha[i] = (double)rand() / (double)RAND_MAX;\n\n  double *ys = (double*) malloc (nobs_size);\n  for (i = 0; i < nobs * nseries; i++)\n    ys[i] = (double)rand() / (double)RAND_MAX;\n\n  double *mu = (double*) malloc (ns_size);\n  for (i = 0; i < nseries; i++)\n    mu[i] = (double)rand() / (double)RAND_MAX;\n\n  double *vs = (double*) malloc (nobs_size);\n\n  double *Fs = (double*) malloc (nobs_size);\n\n  double *sum_logFs = (double*) malloc (ns_size);\n\n  double *fc = (double*) malloc (fc_size);\n\n  double *F_fc = (double*) malloc (fc_size);\n\n  #pragma omp target data map(to: RQR[0:rd2_word],\\\n                                    T[0:rd2_word],\\\n                                    P[0:rd2_word],\\\n                                    Z[0:rd_word],\\\n                                    alpha[0:rd_word],\\\n                                    ys[0:nobs_word],\\\n                                    mu[0:ns_word]) \\\n                          map (alloc: vs[0:nobs_word],\\\n                                    Fs[0:nobs_word],\\\n                                    sum_logFs[0:ns_word], \\\n                                    fc[0:fc_word]) \\\n                          map(from: F_fc[0:fc_word])\n  {\n    for (int n_diff = 0; n_diff < rd; n_diff++) {\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (i = 0; i < repeat; i++)\n        kalman<rd> (\n          ys,\n          nobs,\n          T,\n          Z,\n          RQR,\n          P,\n          alpha,\n          true, \n\n          mu,\n          batch_size,\n          vs,\n          Fs,\n          sum_logFs,\n          n_diff,\n          fc_steps,\n          fc,\n          true, \n\n          F_fc );\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average kernel execution time (n_diff = %d): %f (s)\\n\", n_diff, (time * 1e-9f) / repeat);\n    }\n  }\n\n  double sum = 0.0;\n  for (i = 0; i < fc_steps * nseries - 1; i++)\n    sum += (fabs(F_fc[i+1]) - fabs(F_fc[i])) / (fabs(F_fc[i+1]) + fabs(F_fc[i]));\n  printf(\"Checksum: %lf\\n\", sum);\n\n  free(fc);\n  free(F_fc);\n  free(sum_logFs);\n  free(mu);\n  free(Fs);\n  free(vs);\n  free(ys);\n  free(alpha);\n  free(Z);\n  free(P);\n  free(T);\n  free(RQR);\n  return 0;\n}\n"}}
{"kernel_name": "kalman", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n\n\n\n\ntemplate <int n>\nvoid Mv_l(const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = sum;\n  }\n}\n\ntemplate <int n>\nvoid Mv_l(double alpha, const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = alpha * sum;\n  }\n}\n\n\n\ntemplate <int n, bool aT = false, bool bT = false>\nvoid MM_l(const double* A, const double* B, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    for (int j = 0; j < n; j++) {\n      double sum = 0.0;\n      for (int k = 0; k < n; k++) {\n        double Aik = aT ? A[k + i * n] : A[i + k * n];\n        double Bkj = bT ? B[j + k * n] : B[k + j * n];\n        sum += Aik * Bkj;\n      }\n      out[i + j * n] = sum;\n    }\n  }\n}\n\n\n\ntemplate <int rd>\nvoid kalman(\n  const double*__restrict ys,\n  int nobs,\n  const double*__restrict T,\n  const double*__restrict Z,\n  const double*__restrict RQR,\n  const double*__restrict P,\n  const double*__restrict alpha,\n  bool intercept,\n  const double*__restrict d_mu,\n  int batch_size,\n  double*__restrict vs,\n  double*__restrict Fs,\n  double*__restrict sum_logFs,\n  int n_diff,\n  int fc_steps = 0,\n  double*__restrict d_fc = nullptr,\n  bool conf_int = false,\n  double* d_F_fc = nullptr)\n{\n    for (int bid = 0; bid < batch_size; bid++) {\n    constexpr int rd2 = rd * rd;\n    double l_RQR[rd2];\n    double l_T[rd2];\n    double l_Z[rd];\n    double l_P[rd2];\n    double l_alpha[rd];\n    double l_K[rd];\n    double l_tmp[rd2];\n    double l_TP[rd2];\n\n    \n\n    int b_rd_offset  = bid * rd;\n    int b_rd2_offset = bid * rd2;\n    for (int i = 0; i < rd2; i++) {\n      l_RQR[i] = RQR[b_rd2_offset + i];\n      l_T[i]   = T[b_rd2_offset + i];\n      l_P[i]   = P[b_rd2_offset + i];\n    }\n    for (int i = 0; i < rd; i++) {\n      if (n_diff > 0) l_Z[i] = Z[b_rd_offset + i];\n      l_alpha[i] = alpha[b_rd_offset + i];\n    }\n\n    double b_sum_logFs = 0.0;\n    const double* b_ys = ys + bid * nobs;\n    double* b_vs       = vs + bid * nobs; \n    double* b_Fs       = Fs + bid * nobs;\n\n    double mu = intercept ? d_mu[bid] : 0.0;\n\n    for (int it = 0; it < nobs; it++) {\n      \n\n      double vs_it = b_ys[it];\n      if (n_diff == 0)\n        vs_it -= l_alpha[0];\n      else {\n        for (int i = 0; i < rd; i++) {\n          vs_it -= l_alpha[i] * l_Z[i];\n        }\n      }\n      b_vs[it] = vs_it;\n\n      \n\n      double _Fs;\n      if (n_diff == 0)\n        _Fs = l_P[0];\n      else {\n        _Fs = 0.0;\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n          }\n        }\n      }\n      b_Fs[it] = _Fs;\n      if (it >= n_diff) b_sum_logFs += log(_Fs);\n\n      \n\n      \n\n      MM_l<rd>(l_T, l_P, l_TP);\n      \n\n      double _1_Fs = 1.0 / _Fs;\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_K[i] = _1_Fs * l_TP[i];\n        }\n      } else\n        Mv_l<rd>(_1_Fs, l_TP, l_Z, l_K);\n\n      \n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      \n\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i] + l_K[i] * vs_it;\n      }\n      \n\n      l_alpha[n_diff] += mu;\n\n      \n\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_tmp[i] = l_T[i];\n      }\n      \n\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_tmp[i] -= l_K[i];\n        }\n      } else {\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            l_tmp[j * rd + i] -= l_K[i] * l_Z[j];\n          }\n        }\n      }\n\n      \n\n      \n\n      MM_l<rd, false, true>(l_TP, l_tmp, l_P);\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_P[i] += l_RQR[i];\n      }\n    }\n    sum_logFs[bid] = b_sum_logFs;\n\n    \n\n    double* b_fc   = fc_steps ? d_fc + bid * fc_steps : nullptr;\n    double* b_F_fc = conf_int ? d_F_fc + bid * fc_steps : nullptr;\n    for (int it = 0; it < fc_steps; it++) {\n      if (n_diff == 0)\n        b_fc[it] = l_alpha[0];\n      else {\n        double pred = 0.0;\n        for (int i = 0; i < rd; i++) {\n          pred += l_alpha[i] * l_Z[i];\n        }\n        b_fc[it] = pred;\n      }\n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i];\n      }\n      l_alpha[n_diff] += mu;\n\n      if (conf_int) {\n        if (n_diff == 0)\n          b_F_fc[it] = l_P[0];\n        else {\n          double _Fs = 0.0;\n          for (int i = 0; i < rd; i++) {\n            for (int j = 0; j < rd; j++) {\n              _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n            }\n          }\n          b_F_fc[it] = _Fs;\n        }\n\n        \n\n        \n\n        MM_l<rd>(l_T, l_P, l_TP);\n        \n\n        MM_l<rd, false, true>(l_TP, l_T, l_P);\n        \n\n        for (int i = 0; i < rd2; i++) {\n          l_P[i] += l_RQR[i];\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <#series> <#observations> <forcast steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int nseries = atoi(argv[1]); \n  const int nobs = atoi(argv[2]);\n  const int fc_steps = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int rd = 8;\n  const int rd2 = rd * rd;\n  const int batch_size = nseries;\n\n  const int rd2_word = nseries * rd2;\n  const int rd_word = nseries * rd;\n  const int nobs_word = nseries * nobs;\n  const int ns_word = nseries;\n  const int fc_word = fc_steps * nseries;\n\n  const int rd2_size = rd2_word * sizeof(double);\n  const int rd_size = rd_word * sizeof(double);\n  const int nobs_size = nobs_word * sizeof(double);\n  const int ns_size = ns_word * sizeof(double);\n  const int fc_size = fc_word * sizeof(double);\n\n  int i;\n  srand(123);\n  double *RQR = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    RQR[i] = (double)rand() / (double)RAND_MAX;\n\n  double *T = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    T[i] = (double)rand() / (double)RAND_MAX;\n\n  double *P = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    P[i] = (double)rand() / (double)RAND_MAX;\n\n  double *Z = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    Z[i] = (double)rand() / (double)RAND_MAX;\n\n  double *alpha = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    alpha[i] = (double)rand() / (double)RAND_MAX;\n\n  double *ys = (double*) malloc (nobs_size);\n  for (i = 0; i < nobs * nseries; i++)\n    ys[i] = (double)rand() / (double)RAND_MAX;\n\n  double *mu = (double*) malloc (ns_size);\n  for (i = 0; i < nseries; i++)\n    mu[i] = (double)rand() / (double)RAND_MAX;\n\n  double *vs = (double*) malloc (nobs_size);\n\n  double *Fs = (double*) malloc (nobs_size);\n\n  double *sum_logFs = (double*) malloc (ns_size);\n\n  double *fc = (double*) malloc (fc_size);\n\n  double *F_fc = (double*) malloc (fc_size);\n\n    {\n    for (int n_diff = 0; n_diff < rd; n_diff++) {\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (i = 0; i < repeat; i++)\n        kalman<rd> (\n          ys,\n          nobs,\n          T,\n          Z,\n          RQR,\n          P,\n          alpha,\n          true, \n\n          mu,\n          batch_size,\n          vs,\n          Fs,\n          sum_logFs,\n          n_diff,\n          fc_steps,\n          fc,\n          true, \n\n          F_fc );\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average kernel execution time (n_diff = %d): %f (s)\\n\", n_diff, (time * 1e-9f) / repeat);\n    }\n  }\n\n  double sum = 0.0;\n  for (i = 0; i < fc_steps * nseries - 1; i++)\n    sum += (fabs(F_fc[i+1]) - fabs(F_fc[i])) / (fabs(F_fc[i+1]) + fabs(F_fc[i]));\n  printf(\"Checksum: %lf\\n\", sum);\n\n  free(fc);\n  free(F_fc);\n  free(sum_logFs);\n  free(mu);\n  free(Fs);\n  free(vs);\n  free(ys);\n  free(alpha);\n  free(Z);\n  free(P);\n  free(T);\n  free(RQR);\n  return 0;\n}"}}
{"kernel_name": "kalman", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n\n\ntemplate <int n>\nvoid Mv_l(const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = sum;\n  }\n}\n\ntemplate <int n>\nvoid Mv_l(double alpha, const double* A, const double* v, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    double sum = 0.0;\n    for (int j = 0; j < n; j++) {\n      sum += A[i + j * n] * v[j];\n    }\n    out[i] = alpha * sum;\n  }\n}\n\n\n\ntemplate <int n, bool aT = false, bool bT = false>\nvoid MM_l(const double* A, const double* B, double* out)\n{\n  for (int i = 0; i < n; i++) {\n    for (int j = 0; j < n; j++) {\n      double sum = 0.0;\n      for (int k = 0; k < n; k++) {\n        double Aik = aT ? A[k + i * n] : A[i + k * n];\n        double Bkj = bT ? B[j + k * n] : B[k + j * n];\n        sum += Aik * Bkj;\n      }\n      out[i + j * n] = sum;\n    }\n  }\n}\n\n\n\ntemplate <int rd>\nvoid kalman(\n  sycl::nd_item<1> &item,\n  const double*__restrict ys,\n  int nobs,\n  const double*__restrict T,\n  const double*__restrict Z,\n  const double*__restrict RQR,\n  const double*__restrict P,\n  const double*__restrict alpha,\n  bool intercept,\n  const double*__restrict d_mu,\n  int batch_size,\n  double*__restrict vs,\n  double*__restrict Fs,\n  double*__restrict sum_logFs,\n  int n_diff,\n  int fc_steps = 0,\n  double*__restrict d_fc = nullptr,\n  bool conf_int = false,\n  double* d_F_fc = nullptr)\n{\n  constexpr int rd2 = rd * rd;\n  double l_RQR[rd2];\n  double l_T[rd2];\n  double l_Z[rd];\n  double l_P[rd2];\n  double l_alpha[rd];\n  double l_K[rd];\n  double l_tmp[rd2];\n  double l_TP[rd2];\n\n  int bid = item.get_global_id(0);\n  if (bid < batch_size) {\n    \n\n    int b_rd_offset  = bid * rd;\n    int b_rd2_offset = bid * rd2;\n    for (int i = 0; i < rd2; i++) {\n      l_RQR[i] = RQR[b_rd2_offset + i];\n      l_T[i]   = T[b_rd2_offset + i];\n      l_P[i]   = P[b_rd2_offset + i];\n    }\n    for (int i = 0; i < rd; i++) {\n      if (n_diff > 0) l_Z[i] = Z[b_rd_offset + i];\n      l_alpha[i] = alpha[b_rd_offset + i];\n    }\n\n    double b_sum_logFs = 0.0;\n    const double* b_ys = ys + bid * nobs;\n    double* b_vs       = vs + bid * nobs;\n    double* b_Fs       = Fs + bid * nobs;\n\n    double mu = intercept ? d_mu[bid] : 0.0;\n\n    for (int it = 0; it < nobs; it++) {\n      \n\n      double vs_it = b_ys[it];\n      if (n_diff == 0)\n        vs_it -= l_alpha[0];\n      else {\n        for (int i = 0; i < rd; i++) {\n          vs_it -= l_alpha[i] * l_Z[i];\n        }\n      }\n      b_vs[it] = vs_it;\n\n      \n\n      double _Fs;\n      if (n_diff == 0)\n        _Fs = l_P[0];\n      else {\n        _Fs = 0.0;\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n          }\n        }\n      }\n      b_Fs[it] = _Fs;\n      if (it >= n_diff) b_sum_logFs += sycl::log(_Fs);\n\n      \n\n      \n\n      MM_l<rd>(l_T, l_P, l_TP);\n      \n\n      double _1_Fs = 1.0 / _Fs;\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_K[i] = _1_Fs * l_TP[i];\n        }\n      } else\n        Mv_l<rd>(_1_Fs, l_TP, l_Z, l_K);\n\n      \n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      \n\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i] + l_K[i] * vs_it;\n      }\n      \n\n      l_alpha[n_diff] += mu;\n\n      \n\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_tmp[i] = l_T[i];\n      }\n      \n\n      if (n_diff == 0) {\n        for (int i = 0; i < rd; i++) {\n          l_tmp[i] -= l_K[i];\n        }\n      } else {\n        for (int i = 0; i < rd; i++) {\n          for (int j = 0; j < rd; j++) {\n            l_tmp[j * rd + i] -= l_K[i] * l_Z[j];\n          }\n        }\n      }\n\n      \n\n      \n\n      MM_l<rd, false, true>(l_TP, l_tmp, l_P);\n      \n\n      for (int i = 0; i < rd2; i++) {\n        l_P[i] += l_RQR[i];\n      }\n    }\n    sum_logFs[bid] = b_sum_logFs;\n\n    \n\n    double* b_fc   = fc_steps ? d_fc + bid * fc_steps : nullptr;\n    double* b_F_fc = conf_int ? d_F_fc + bid * fc_steps : nullptr;\n    for (int it = 0; it < fc_steps; it++) {\n      if (n_diff == 0)\n        b_fc[it] = l_alpha[0];\n      else {\n        double pred = 0.0;\n        for (int i = 0; i < rd; i++) {\n          pred += l_alpha[i] * l_Z[i];\n        }\n        b_fc[it] = pred;\n      }\n\n      \n\n      Mv_l<rd>(l_T, l_alpha, l_tmp);\n      for (int i = 0; i < rd; i++) {\n        l_alpha[i] = l_tmp[i];\n      }\n      l_alpha[n_diff] += mu;\n\n      if (conf_int) {\n        if (n_diff == 0)\n          b_F_fc[it] = l_P[0];\n        else {\n          double _Fs = 0.0;\n          for (int i = 0; i < rd; i++) {\n            for (int j = 0; j < rd; j++) {\n              _Fs += l_P[j * rd + i] * l_Z[i] * l_Z[j];\n            }\n          }\n          b_F_fc[it] = _Fs;\n        }\n\n        \n\n        \n\n        MM_l<rd>(l_T, l_P, l_TP);\n        \n\n        MM_l<rd, false, true>(l_TP, l_T, l_P);\n        \n\n        for (int i = 0; i < rd2; i++) {\n          l_P[i] += l_RQR[i];\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <#series> <#observations> <forcast steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int nseries = atoi(argv[1]);\n  const int nobs = atoi(argv[2]);\n  const int fc_steps = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int rd = 8;\n  const int rd2 = rd * rd;\n  const int batch_size = nseries;\n\n  const int rd2_word = nseries * rd2;\n  const int rd_word = nseries * rd;\n  const int nobs_word = nseries * nobs;\n  const int ns_word = nseries;\n  const int fc_word = fc_steps * nseries;\n\n  const int rd2_size = rd2_word * sizeof(double);\n  const int rd_size = rd_word * sizeof(double);\n  const int nobs_size = nobs_word * sizeof(double);\n  const int ns_size = ns_word * sizeof(double);\n  const int fc_size = fc_word * sizeof(double);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int i;\n  srand(123);\n  double *RQR = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    RQR[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_RQR = sycl::malloc_device<double>(rd2_word, q);\n  q.memcpy(d_RQR, RQR, rd2_size);\n\n  double *T = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    T[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_T = sycl::malloc_device<double>(rd2_word, q);\n  q.memcpy(d_T, T, rd2_size);\n\n  double *P = (double*) malloc (rd2_size);\n  for (i = 0; i < rd2 * nseries; i++)\n    P[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_P = sycl::malloc_device<double>(rd2_word, q);\n  q.memcpy(d_P, P, rd2_size);\n\n  double *Z = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    Z[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_Z = sycl::malloc_device<double>(rd_word, q);\n  q.memcpy(d_Z, Z, rd_size);\n\n  double *alpha = (double*) malloc (rd_size);\n  for (i = 0; i < rd * nseries; i++)\n    alpha[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_alpha = sycl::malloc_device<double>(rd_word, q);\n  q.memcpy(d_alpha, alpha, rd_size);\n\n  double *ys = (double*) malloc (nobs_size);\n  for (i = 0; i < nobs * nseries; i++)\n    ys[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_ys = sycl::malloc_device<double>(nobs_word, q);\n  q.memcpy(d_ys, ys, nobs_size);\n\n  double *mu = (double*) malloc (ns_size);\n  for (i = 0; i < nseries; i++)\n    mu[i] = (double)rand() / (double)RAND_MAX;\n\n  double *d_mu = sycl::malloc_device<double>(ns_word, q);\n  q.memcpy(d_mu, mu, ns_size);\n\n  double *d_vs = sycl::malloc_device<double>(nobs_word, q);\n\n  double *d_Fs = sycl::malloc_device<double>(nobs_word, q);\n\n  double *d_sum_logFs = sycl::malloc_device<double>(ns_word, q);\n\n  double *d_fc = sycl::malloc_device<double>(fc_word, q);\n\n  double *F_fc = (double*) malloc (fc_size);\n  double *d_F_fc = sycl::malloc_device<double>(fc_word, q);\n\n  sycl::range<1> gws ((nseries + 255)/256*256);\n  sycl::range<1> lws  (256);\n\n  for (int n_diff = 0; n_diff < rd; n_diff++) {\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (i = 0; i < repeat; i++)\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class filter>(\n          sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n          kalman<rd> (\n            item,\n            d_ys,\n            nobs,\n            d_T,\n            d_Z,\n            d_RQR,\n            d_P,\n            d_alpha,\n            true, \n\n            d_mu,\n            batch_size,\n            d_vs,\n            d_Fs,\n            d_sum_logFs,\n            n_diff,\n            fc_steps,\n            d_fc,\n            true, \n\n            d_F_fc );\n        });\n     });\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (n_diff = %d): %f (s)\\n\", n_diff, (time * 1e-9f) / repeat);\n  }\n\n  q.memcpy(F_fc, d_F_fc, fc_size).wait();\n\n  double sum = 0.0;\n  for (i = 0; i < fc_steps * nseries - 1; i++)\n    sum += (fabs(F_fc[i+1]) - fabs(F_fc[i])) / (fabs(F_fc[i+1]) + fabs(F_fc[i]));\n  printf(\"Checksum: %lf\\n\", sum);\n\n  free(F_fc);\n  free(mu);\n  free(ys);\n  free(alpha);\n  free(Z);\n  free(P);\n  free(T);\n  free(RQR);\n  sycl::free(d_RQR, q);\n  sycl::free(d_T, q);\n  sycl::free(d_P, q);\n  sycl::free(d_Z, q);\n  sycl::free(d_alpha, q);\n  sycl::free(d_ys, q);\n  sycl::free(d_vs, q);\n  sycl::free(d_Fs, q);\n  sycl::free(d_mu, q);\n  sycl::free(d_sum_logFs, q);\n  sycl::free(d_F_fc, q);\n  sycl::free(d_fc, q);\n  return 0;\n}\n"}}
{"kernel_name": "knn", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n\n#include <cstdio>\n#include <algorithm>\n#include <sys/time.h>\n#include <time.h>\n#include <cuda.h>\n\n\n\n#define BLOCK_DIM 16\n\n\n\n__global__\nvoid cuComputeDistanceGlobal(const float *__restrict__ A,\n                             int wA,\n                             const float *__restrict__ B,\n                             int wB,\n                             int dim,\n                             float *__restrict__ AB)\n{\n  \n\n  \n\n  __shared__ float shared_A[BLOCK_DIM][BLOCK_DIM];\n  __shared__ float shared_B[BLOCK_DIM][BLOCK_DIM];\n\n  \n\n  __shared__ int begin_A;\n  __shared__ int begin_B;\n  __shared__ int step_A;\n  __shared__ int step_B;\n  __shared__ int end_A;\n\n  \n\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n\n  \n\n  float tmp;\n  float ssd = 0;\n\n  \n\n  begin_A = BLOCK_DIM * blockIdx.y;\n  begin_B = BLOCK_DIM * blockIdx.x;\n  step_A = BLOCK_DIM * wA;\n  step_B = BLOCK_DIM * wB;\n  end_A = begin_A + (dim - 1) * wA;\n\n  \n\n  int cond0 = (begin_A + tx < wA); \n\n  int cond1 = (begin_B + tx < wB); \n\n                                   \n\n  int cond2 =\n      (begin_A + ty < wA); \n\n\n  \n\n  \n\n  for (int a = begin_A, b = begin_B; a <= end_A; a += step_A, b += step_B) {\n    \n\n    \n\n    if (a / wA + ty < dim) {\n      shared_A[ty][tx] = (cond0) ? A[a + wA * ty + tx] : 0;\n      shared_B[ty][tx] = (cond1) ? B[b + wB * ty + tx] : 0;\n    } else {\n      shared_A[ty][tx] = 0;\n      shared_B[ty][tx] = 0;\n    }\n\n    \n\n    __syncthreads();\n\n    \n\n    \n\n    if (cond2 && cond1) {\n      for (int k = 0; k < BLOCK_DIM; ++k) {\n        tmp = shared_A[k][ty] - shared_B[k][tx];\n        ssd += tmp * tmp;\n      }\n    }\n\n    \n\n    \n\n    __syncthreads();\n  }\n\n  \n\n  if (cond2 && cond1)\n    AB[(begin_A + ty) * wB + begin_B + tx] = ssd;\n}\n\n\n\n__global__\nvoid cuInsertionSort(float *__restrict__ dist,\n                       int *__restrict__ ind,\n                       int width, int height, int k)\n{\n  \n\n  int l, i, j;\n  float *p_dist;\n  int *p_ind;\n  float curr_dist, max_dist;\n  int curr_row, max_row;\n  unsigned int xIndex = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (xIndex < width) {\n    \n\n    p_dist = dist + xIndex;\n    p_ind = ind + xIndex;\n    max_dist = p_dist[0];\n    p_ind[0] = 0;\n\n    \n\n    for (l = 1; l < k; l++) {\n      curr_row = l * width;\n      curr_dist = p_dist[curr_row];\n      if (curr_dist < max_dist) {\n        i = l - 1;\n        for (int a = 0; a < l - 1; a++) {\n          if (p_dist[a * width] > curr_dist) {\n            i = a;\n            break;\n          }\n        }\n        for (j = l; j > i; j--) {\n          p_dist[j * width] = p_dist[(j - 1) * width];\n          p_ind[j * width] = p_ind[(j - 1) * width];\n        }\n        p_dist[i * width] = curr_dist;\n        p_ind[i * width] = l;\n      } else {\n        p_ind[l * width] = l;\n      }\n      max_dist = p_dist[curr_row];\n    }\n\n    \n\n    max_row = (k - 1) * width;\n    for (l = k; l < height; l++) {\n      curr_dist = p_dist[l * width];\n      if (curr_dist < max_dist) {\n        i = k - 1;\n        for (int a = 0; a < k - 1; a++) {\n          if (p_dist[a * width] > curr_dist) {\n            i = a;\n            break;\n          }\n        }\n        for (j = k - 1; j > i; j--) {\n          p_dist[j * width] = p_dist[(j - 1) * width];\n          p_ind[j * width] = p_ind[(j - 1) * width];\n        }\n        p_dist[i * width] = curr_dist;\n        p_ind[i * width] = l;\n        max_dist = p_dist[max_row];\n      }\n    }\n  }\n}\n\n\n\n__global__ void cuParallelSqrt(float *dist, int width, int k) {\n  unsigned int xIndex = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int yIndex = blockIdx.y * blockDim.y + threadIdx.y;\n  if (xIndex < width && yIndex < k)\n    dist[yIndex * width + xIndex] = sqrt(dist[yIndex * width + xIndex]);\n}\n\n\n\n\n\n\n\n\n\nvoid knn_parallel(float *ref_host, int ref_width, float *query_host,\n              int query_width, int height, int k, float *dist_host,\n              int *ind_host) {\n\n  unsigned int size_of_float = sizeof(float);\n  unsigned int size_of_int = sizeof(int);\n\n  \n\n  float *query_dev;\n  float *ref_dev;\n  float *dist_dev;\n  int *ind_dev;\n\n  \n\n  cudaMalloc((void **)&query_dev, query_width * height * size_of_float);\n  cudaMalloc((void **)&dist_dev, query_width * ref_width * size_of_float);\n\n  \n\n  cudaMalloc((void **)&ind_dev, query_width * k * size_of_int);\n\n  \n\n  cudaMalloc((void **)&ref_dev, ref_width * height * size_of_float);\n\n  cudaMemcpy(ref_dev, ref_host, ref_width * height * size_of_float,\n             cudaMemcpyHostToDevice);\n\n  \n\n  cudaMemcpy(query_dev, query_host, query_width * height * size_of_float,\n             cudaMemcpyHostToDevice);\n\n  \n\n  dim3 g_16x16((query_width + 15) / 16, (ref_width + 15) / 16, 1);\n  dim3 t_16x16(16, 16, 1);\n  \n\n  dim3 g_256x1((query_width + 255) / 256, 1, 1);\n  dim3 t_256x1(256, 1, 1);\n\n  dim3 g_k_16x16((query_width + 15) / 16, (k + 15) / 16, 1);\n  dim3 t_k_16x16(16, 16, 1);\n\n  \n\n  cuComputeDistanceGlobal<<<g_16x16, t_16x16>>>(ref_dev, ref_width, query_dev,\n                                                query_width, height, dist_dev);\n\n#ifdef DEBUG\n  cudaMemcpy(dist_host, dist_dev, query_width * ref_width * size_of_float,\n             cudaMemcpyDeviceToHost);\n\n  for (int i = 0; i < query_width * ref_width; i++)\n    printf(\"k1 dist: %d %f\\n\", i, dist_host[i]);\n#endif\n\n  \n\n  cuInsertionSort<<<g_256x1, t_256x1>>>(dist_dev, ind_dev, query_width,\n                                        ref_width, k);\n\n#ifdef DEBUG\n  cudaMemcpy(dist_host, dist_dev, query_width * ref_width * size_of_float,\n             cudaMemcpyDeviceToHost);\n\n  for (int i = 0; i < query_width * ref_width; i++)\n    printf(\"k2 dist: %d %f\\n\", i, dist_host[i]);\n\n  cudaMemcpy(ind_host, ind_dev, query_width * k * size_of_int,\n             cudaMemcpyDeviceToHost);\n  for (int i = 0; i < query_width * k; i++)\n    printf(\"k2 index: %d %d\\n\", i, ind_host[i]);\n#endif\n\n  \n\n  cuParallelSqrt<<<g_k_16x16, t_k_16x16>>>(dist_dev, query_width, k);\n  cudaDeviceSynchronize();\n  \n\n  cudaMemcpy(dist_host, dist_dev, query_width * k * size_of_float,\n             cudaMemcpyDeviceToHost);\n\n  cudaMemcpy(ind_host, ind_dev, query_width * k * size_of_int,\n             cudaMemcpyDeviceToHost);\n\n  \n\n  cudaFree(ref_dev);\n  cudaFree(ind_dev);\n  cudaFree(query_dev);\n  cudaFree(dist_dev);\n}\n\nfloat compute_distance(const float *ref, int ref_nb, const float *query,\n                       int query_nb, int dim, int ref_index, int query_index) {\n  float sum = 0.f;\n  for (int d = 0; d < dim; ++d) {\n    const float diff =\n        ref[d * ref_nb + ref_index] - query[d * query_nb + query_index];\n    sum += diff * diff;\n  }\n  return sqrtf(sum);\n}\n\nvoid modified_insertion_sort(float *dist, int *index, int length, int k) {\n\n  \n\n  index[0] = 0;\n\n  \n\n  for (int i = 1; i < length; ++i) {\n\n    \n\n    float curr_dist = dist[i];\n    int curr_index = i;\n\n    \n\n    \n\n    if (i >= k && curr_dist >= dist[k - 1]) {\n      continue;\n    }\n\n    \n\n    int j = std::min(i, k - 1);\n    while (j > 0 && dist[j - 1] > curr_dist) {\n      dist[j] = dist[j - 1];\n      index[j] = index[j - 1];\n      --j;\n    }\n\n    \n\n    dist[j] = curr_dist;\n    index[j] = curr_index;\n  }\n}\n\nbool knn_c(const float *ref, int ref_nb, const float *query, int query_nb,\n           int dim, int k, float *knn_dist, int *knn_index) {\n  \n\n  \n\n  float *dist = (float *)malloc(ref_nb * sizeof(float));\n  int *index = (int *)malloc(ref_nb * sizeof(int));\n\n  \n\n  if (!dist || !index) {\n    printf(\"Memory allocation error\\n\");\n    free(dist);\n    free(index);\n    return false;\n  }\n\n  \n\n  for (int i = 0; i < query_nb; ++i) {\n\n    \n\n    for (int j = 0; j < ref_nb; ++j) {\n      dist[j] = compute_distance(ref, ref_nb, query, query_nb, dim, j, i);\n      index[j] = j;\n    }\n\n    \n\n    modified_insertion_sort(dist, index, ref_nb, k);\n\n    \n\n    for (int j = 0; j < k; ++j) {\n      knn_dist[j * query_nb + i] = dist[j];\n      knn_index[j * query_nb + i] = index[j];\n    }\n  }\n\n  \n\n  free(dist);\n  free(index);\n  return true;\n}\n\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int iterations = atoi(argv[1]);\n  \n  \n\n  float *ref;          \n\n  float *query;        \n\n  float *dist;         \n\n  int *ind;            \n\n  int ref_nb = 4096;   \n\n  int query_nb = 4096; \n\n  int dim = 68;        \n\n  int k = 20;          \n\n  int c_iterations = 1;\n  int i;\n  const float precision = 0.001f; \n\n  int nb_correct_precisions = 0;\n  int nb_correct_indexes = 0;\n  \n\n  ref = (float *)malloc(ref_nb * dim * sizeof(float));\n  query = (float *)malloc(query_nb * dim * sizeof(float));\n  dist = (float *)malloc(query_nb * k * sizeof(float));\n  ind = (int *)malloc(query_nb * k * sizeof(float));\n\n  \n\n  srand(2);\n  for (i = 0; i < ref_nb * dim; i++)\n    ref[i] = (float)rand() / (float)RAND_MAX;\n  for (i = 0; i < query_nb * dim; i++)\n    query[i] = (float)rand() / (float)RAND_MAX;\n\n  \n\n  printf(\"Number of reference points      : %6d\\n\", ref_nb);\n  printf(\"Number of query points          : %6d\\n\", query_nb);\n  printf(\"Dimension of points             : %4d\\n\", dim);\n  printf(\"Number of neighbors to consider : %4d\\n\", k);\n  printf(\"Processing kNN search           :\\n\");\n\n  float *knn_dist = (float *)malloc(query_nb * k * sizeof(float));\n  int *knn_index = (int *)malloc(query_nb * k * sizeof(int));\n  printf(\"Ground truth computation in progress...\\n\\n\");\n  if (!knn_c(ref, ref_nb, query, query_nb, dim, k, knn_dist, knn_index)) {\n    free(ref);\n    free(query);\n    free(knn_dist);\n    free(knn_index);\n    return EXIT_FAILURE;\n  }\n\n  struct timeval tic;\n  struct timeval toc;\n  float elapsed_time;\n\n  printf(\"On CPU: \\n\");\n  gettimeofday(&tic, NULL);\n  for (i = 0; i < c_iterations; i++) {\n    knn_c(ref, ref_nb, query, query_nb, dim, k, dist, ind);\n  }\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         c_iterations, elapsed_time / (c_iterations));\n\n  printf(\"on GPU: \\n\");\n  gettimeofday(&tic, NULL);\n  for (i = 0; i < iterations; i++) {\n    knn_parallel(ref, ref_nb, query, query_nb, dim, k, dist, ind);\n  }\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         iterations, elapsed_time / (iterations));\n\n  for (int i = 0; i < query_nb * k; ++i) {\n    if (fabs(dist[i] - knn_dist[i]) <= precision) {\n      nb_correct_precisions++;\n    }\n    if (ind[i] == knn_index[i]) {\n      nb_correct_indexes++;\n    } else {\n      printf(\"Mismatch @%d: %d %d\\n\", i, ind[i], knn_index[i]);\n    }\n  }\n\n  float precision_accuracy = nb_correct_precisions / ((float)query_nb * k);\n  float index_accuracy = nb_correct_indexes / ((float)query_nb * k);\n  printf(\"Precision accuracy %f\\nIndex accuracy %f\\n\", precision_accuracy, index_accuracy);\n\n  free(ind);\n  free(dist);\n  free(query);\n  free(ref);\n}\n"}}
{"kernel_name": "knn", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n\n#include <cstdio>\n#include <algorithm>\n#include <sys/time.h>\n#include <time.h>\n#include <hip/hip_runtime.h>\n\n\n\n#define BLOCK_DIM 16\n\n\n\n__global__\nvoid cuComputeDistanceGlobal(const float *__restrict__ A,\n                             int wA,\n                             const float *__restrict__ B,\n                             int wB,\n                             int dim,\n                             float *__restrict__ AB)\n{\n  \n\n  \n\n  __shared__ float shared_A[BLOCK_DIM][BLOCK_DIM];\n  __shared__ float shared_B[BLOCK_DIM][BLOCK_DIM];\n\n  \n\n  __shared__ int begin_A;\n  __shared__ int begin_B;\n  __shared__ int step_A;\n  __shared__ int step_B;\n  __shared__ int end_A;\n\n  \n\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n\n  \n\n  float tmp;\n  float ssd = 0;\n\n  \n\n  begin_A = BLOCK_DIM * blockIdx.y;\n  begin_B = BLOCK_DIM * blockIdx.x;\n  step_A = BLOCK_DIM * wA;\n  step_B = BLOCK_DIM * wB;\n  end_A = begin_A + (dim - 1) * wA;\n\n  \n\n  int cond0 = (begin_A + tx < wA); \n\n  int cond1 = (begin_B + tx < wB); \n\n                                   \n\n  int cond2 =\n      (begin_A + ty < wA); \n\n\n  \n\n  \n\n  for (int a = begin_A, b = begin_B; a <= end_A; a += step_A, b += step_B) {\n    \n\n    \n\n    if (a / wA + ty < dim) {\n      shared_A[ty][tx] = (cond0) ? A[a + wA * ty + tx] : 0;\n      shared_B[ty][tx] = (cond1) ? B[b + wB * ty + tx] : 0;\n    } else {\n      shared_A[ty][tx] = 0;\n      shared_B[ty][tx] = 0;\n    }\n\n    \n\n    __syncthreads();\n\n    \n\n    \n\n    if (cond2 && cond1) {\n      for (int k = 0; k < BLOCK_DIM; ++k) {\n        tmp = shared_A[k][ty] - shared_B[k][tx];\n        ssd += tmp * tmp;\n      }\n    }\n\n    \n\n    \n\n    __syncthreads();\n  }\n\n  \n\n  if (cond2 && cond1)\n    AB[(begin_A + ty) * wB + begin_B + tx] = ssd;\n}\n\n\n\n__global__\nvoid cuInsertionSort(float *__restrict__ dist,\n                       int *__restrict__ ind,\n                       int width, int height, int k)\n{\n  \n\n  int l, i, j;\n  float *p_dist;\n  int *p_ind;\n  float curr_dist, max_dist;\n  int curr_row, max_row;\n  unsigned int xIndex = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (xIndex < width) {\n    \n\n    p_dist = dist + xIndex;\n    p_ind = ind + xIndex;\n    max_dist = p_dist[0];\n    p_ind[0] = 0;\n\n    \n\n    for (l = 1; l < k; l++) {\n      curr_row = l * width;\n      curr_dist = p_dist[curr_row];\n      if (curr_dist < max_dist) {\n        i = l - 1;\n        for (int a = 0; a < l - 1; a++) {\n          if (p_dist[a * width] > curr_dist) {\n            i = a;\n            break;\n          }\n        }\n        for (j = l; j > i; j--) {\n          p_dist[j * width] = p_dist[(j - 1) * width];\n          p_ind[j * width] = p_ind[(j - 1) * width];\n        }\n        p_dist[i * width] = curr_dist;\n        p_ind[i * width] = l;\n      } else {\n        p_ind[l * width] = l;\n      }\n      max_dist = p_dist[curr_row];\n    }\n\n    \n\n    max_row = (k - 1) * width;\n    for (l = k; l < height; l++) {\n      curr_dist = p_dist[l * width];\n      if (curr_dist < max_dist) {\n        i = k - 1;\n        for (int a = 0; a < k - 1; a++) {\n          if (p_dist[a * width] > curr_dist) {\n            i = a;\n            break;\n          }\n        }\n        for (j = k - 1; j > i; j--) {\n          p_dist[j * width] = p_dist[(j - 1) * width];\n          p_ind[j * width] = p_ind[(j - 1) * width];\n        }\n        p_dist[i * width] = curr_dist;\n        p_ind[i * width] = l;\n        max_dist = p_dist[max_row];\n      }\n    }\n  }\n}\n\n\n\n__global__ void cuParallelSqrt(float *dist, int width, int k) {\n  unsigned int xIndex = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int yIndex = blockIdx.y * blockDim.y + threadIdx.y;\n  if (xIndex < width && yIndex < k)\n    dist[yIndex * width + xIndex] = sqrt(dist[yIndex * width + xIndex]);\n}\n\n\n\n\n\n\n\n\n\nvoid knn_parallel(float *ref_host, int ref_width, float *query_host,\n              int query_width, int height, int k, float *dist_host,\n              int *ind_host) {\n\n  unsigned int size_of_float = sizeof(float);\n  unsigned int size_of_int = sizeof(int);\n\n  \n\n  float *query_dev;\n  float *ref_dev;\n  float *dist_dev;\n  int *ind_dev;\n\n  \n\n  hipMalloc((void **)&query_dev, query_width * height * size_of_float);\n  hipMalloc((void **)&dist_dev, query_width * ref_width * size_of_float);\n\n  \n\n  hipMalloc((void **)&ind_dev, query_width * k * size_of_int);\n\n  \n\n  hipMalloc((void **)&ref_dev, ref_width * height * size_of_float);\n\n  hipMemcpy(ref_dev, ref_host, ref_width * height * size_of_float,\n             hipMemcpyHostToDevice);\n\n  \n\n  hipMemcpy(query_dev, query_host, query_width * height * size_of_float,\n             hipMemcpyHostToDevice);\n\n  \n\n  dim3 g_16x16((query_width + 15) / 16, (ref_width + 15) / 16, 1);\n  dim3 t_16x16(16, 16, 1);\n  \n\n  dim3 g_256x1((query_width + 255) / 256, 1, 1);\n  dim3 t_256x1(256, 1, 1);\n\n  dim3 g_k_16x16((query_width + 15) / 16, (k + 15) / 16, 1);\n  dim3 t_k_16x16(16, 16, 1);\n\n  \n\n  hipLaunchKernelGGL(cuComputeDistanceGlobal, g_16x16, t_16x16, 0, 0, ref_dev, ref_width, query_dev,\n                                                query_width, height, dist_dev);\n\n#ifdef DEBUG\n  hipMemcpy(dist_host, dist_dev, query_width * ref_width * size_of_float,\n             hipMemcpyDeviceToHost);\n\n  for (int i = 0; i < query_width * ref_width; i++)\n    printf(\"k1 dist: %d %f\\n\", i, dist_host[i]);\n#endif\n\n  \n\n  hipLaunchKernelGGL(cuInsertionSort, g_256x1, t_256x1, 0, 0, dist_dev, ind_dev, query_width,\n                                        ref_width, k);\n\n#ifdef DEBUG\n  hipMemcpy(dist_host, dist_dev, query_width * ref_width * size_of_float,\n             hipMemcpyDeviceToHost);\n\n  for (int i = 0; i < query_width * ref_width; i++)\n    printf(\"k2 dist: %d %f\\n\", i, dist_host[i]);\n\n  hipMemcpy(ind_host, ind_dev, query_width * k * size_of_int,\n             hipMemcpyDeviceToHost);\n  for (int i = 0; i < query_width * k; i++)\n    printf(\"k2 index: %d %d\\n\", i, ind_host[i]);\n#endif\n\n  \n\n  hipLaunchKernelGGL(cuParallelSqrt, g_k_16x16, t_k_16x16, 0, 0, dist_dev, query_width, k);\n  hipDeviceSynchronize();\n  \n\n  hipMemcpy(dist_host, dist_dev, query_width * k * size_of_float,\n             hipMemcpyDeviceToHost);\n\n  hipMemcpy(ind_host, ind_dev, query_width * k * size_of_int,\n             hipMemcpyDeviceToHost);\n\n  \n\n  hipFree(ref_dev);\n  hipFree(ind_dev);\n  hipFree(query_dev);\n  hipFree(dist_dev);\n}\n\nfloat compute_distance(const float *ref, int ref_nb, const float *query,\n                       int query_nb, int dim, int ref_index, int query_index) {\n  float sum = 0.f;\n  for (int d = 0; d < dim; ++d) {\n    const float diff =\n        ref[d * ref_nb + ref_index] - query[d * query_nb + query_index];\n    sum += diff * diff;\n  }\n  return sqrtf(sum);\n}\n\nvoid modified_insertion_sort(float *dist, int *index, int length, int k) {\n\n  \n\n  index[0] = 0;\n\n  \n\n  for (int i = 1; i < length; ++i) {\n\n    \n\n    float curr_dist = dist[i];\n    int curr_index = i;\n\n    \n\n    \n\n    if (i >= k && curr_dist >= dist[k - 1]) {\n      continue;\n    }\n\n    \n\n    int j = std::min(i, k - 1);\n    while (j > 0 && dist[j - 1] > curr_dist) {\n      dist[j] = dist[j - 1];\n      index[j] = index[j - 1];\n      --j;\n    }\n\n    \n\n    dist[j] = curr_dist;\n    index[j] = curr_index;\n  }\n}\n\nbool knn_c(const float *ref, int ref_nb, const float *query, int query_nb,\n           int dim, int k, float *knn_dist, int *knn_index) {\n  \n\n  \n\n  float *dist = (float *)malloc(ref_nb * sizeof(float));\n  int *index = (int *)malloc(ref_nb * sizeof(int));\n\n  \n\n  if (!dist || !index) {\n    printf(\"Memory allocation error\\n\");\n    free(dist);\n    free(index);\n    return false;\n  }\n\n  \n\n  for (int i = 0; i < query_nb; ++i) {\n\n    \n\n    for (int j = 0; j < ref_nb; ++j) {\n      dist[j] = compute_distance(ref, ref_nb, query, query_nb, dim, j, i);\n      index[j] = j;\n    }\n\n    \n\n    modified_insertion_sort(dist, index, ref_nb, k);\n\n    \n\n    for (int j = 0; j < k; ++j) {\n      knn_dist[j * query_nb + i] = dist[j];\n      knn_index[j * query_nb + i] = index[j];\n    }\n  }\n\n  \n\n  free(dist);\n  free(index);\n  return true;\n}\n\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int iterations = atoi(argv[1]);\n  \n  \n\n  float *ref;          \n\n  float *query;        \n\n  float *dist;         \n\n  int *ind;            \n\n  int ref_nb = 4096;   \n\n  int query_nb = 4096; \n\n  int dim = 68;        \n\n  int k = 20;          \n\n  int c_iterations = 1;\n  int i;\n  const float precision = 0.001f; \n\n  int nb_correct_precisions = 0;\n  int nb_correct_indexes = 0;\n  \n\n  ref = (float *)malloc(ref_nb * dim * sizeof(float));\n  query = (float *)malloc(query_nb * dim * sizeof(float));\n  dist = (float *)malloc(query_nb * k * sizeof(float));\n  ind = (int *)malloc(query_nb * k * sizeof(float));\n\n  \n\n  srand(2);\n  for (i = 0; i < ref_nb * dim; i++)\n    ref[i] = (float)rand() / (float)RAND_MAX;\n  for (i = 0; i < query_nb * dim; i++)\n    query[i] = (float)rand() / (float)RAND_MAX;\n\n\n  \n\n  printf(\"Number of reference points      : %6d\\n\", ref_nb);\n  printf(\"Number of query points          : %6d\\n\", query_nb);\n  printf(\"Dimension of points             : %4d\\n\", dim);\n  printf(\"Number of neighbors to consider : %4d\\n\", k);\n  printf(\"Processing kNN search           :\\n\");\n\n  float *knn_dist = (float *)malloc(query_nb * k * sizeof(float));\n  int *knn_index = (int *)malloc(query_nb * k * sizeof(int));\n  printf(\"Ground truth computation in progress...\\n\\n\");\n  if (!knn_c(ref, ref_nb, query, query_nb, dim, k, knn_dist, knn_index)) {\n    free(ref);\n    free(query);\n    free(knn_dist);\n    free(knn_index);\n    return EXIT_FAILURE;\n  }\n\n  struct timeval tic;\n  struct timeval toc;\n  float elapsed_time;\n\n  printf(\"On CPU: \\n\");\n  gettimeofday(&tic, NULL);\n  for (i = 0; i < c_iterations; i++) {\n    knn_c(ref, ref_nb, query, query_nb, dim, k, dist, ind);\n  }\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         c_iterations, elapsed_time / (c_iterations));\n\n  printf(\"on GPU: \\n\");\n  gettimeofday(&tic, NULL);\n  for (i = 0; i < iterations; i++) {\n    knn_parallel(ref, ref_nb, query, query_nb, dim, k, dist, ind);\n  }\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         iterations, elapsed_time / (iterations));\n\n  for (int i = 0; i < query_nb * k; ++i) {\n    if (fabs(dist[i] - knn_dist[i]) <= precision) {\n      nb_correct_precisions++;\n    }\n    if (ind[i] == knn_index[i]) {\n      nb_correct_indexes++;\n    } else {\n      printf(\"Mismatch @%d: %d %d\\n\", i, ind[i], knn_index[i]);\n    }\n  }\n\n  float precision_accuracy = nb_correct_precisions / ((float)query_nb * k);\n  float index_accuracy = nb_correct_indexes / ((float)query_nb * k);\n  printf(\"Precision accuracy %f\\nIndex accuracy %f\\n\", precision_accuracy, index_accuracy);\n\n  free(ind);\n  free(dist);\n  free(query);\n  free(ref);\n}\n"}}
{"kernel_name": "knn", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n\n\n#include <algorithm>\n#include <cstdio>\n#include <sys/time.h>\n#include <time.h>\n#include <omp.h>\n#include <math.h>\n\n\n\n#define BLOCK_DIM 16\n\n\n\n\n\n\n\n\nfloat compute_distance(const float *ref, int ref_nb, const float *query,\n                       int query_nb, int dim, int ref_index, int query_index) {\n  float sum = 0.f;\n  for (int d = 0; d < dim; ++d) {\n    const float diff =\n        ref[d * ref_nb + ref_index] - query[d * query_nb + query_index];\n    sum += diff * diff;\n  }\n  return sqrtf(sum);\n}\n\nvoid modified_insertion_sort(float *dist, int *index, int length, int k) {\n\n  \n\n  index[0] = 0;\n\n  \n\n  for (int i = 1; i < length; ++i) {\n\n    \n\n    float curr_dist = dist[i];\n    int curr_index = i;\n\n    \n\n    \n\n    if (i >= k && curr_dist >= dist[k - 1]) {\n      continue;\n    }\n\n    \n\n    int j = std::min(i, k - 1);\n    while (j > 0 && dist[j - 1] > curr_dist) {\n      dist[j] = dist[j - 1];\n      index[j] = index[j - 1];\n      --j;\n    }\n\n    \n\n    dist[j] = curr_dist;\n    index[j] = curr_index;\n  }\n}\n\nbool knn_serial(const float *ref, int ref_nb, const float *query, int query_nb,\n           int dim, int k, float *knn_dist, int *knn_index) {\n  \n\n  \n\n  float *dist = (float *)malloc(ref_nb * sizeof(float));\n  int *index = (int *)malloc(ref_nb * sizeof(int));\n\n  \n\n  if (!dist || !index) {\n    printf(\"Memory allocation error\\n\");\n    free(dist);\n    free(index);\n    return false;\n  }\n\n  \n\n  for (int i = 0; i < query_nb; ++i) {\n\n    \n\n    for (int j = 0; j < ref_nb; ++j) {\n      dist[j] = compute_distance(ref, ref_nb, query, query_nb, dim, j, i);\n      index[j] = j;\n    }\n\n    \n\n    modified_insertion_sort(dist, index, ref_nb, k);\n\n    \n\n    for (int j = 0; j < k; ++j) {\n      knn_dist[j * query_nb + i] = dist[j];\n      knn_index[j * query_nb + i] = index[j];\n    }\n  }\n\n  \n\n  free(dist);\n  free(index);\n  return true;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int iterations = atoi(argv[1]);\n\n  float *ref;          \n\n  float *query;        \n\n  float *dist;         \n\n  int *ind;            \n\n  int ref_nb = 4096;   \n\n  int query_nb = 4096; \n\n  int dim = 68;        \n\n  int k = 20;          \n\n  int c_iterations = 1;\n  int i;\n  const float precision = 0.001f; \n\n  int nb_correct_precisions = 0;\n  int nb_correct_indexes = 0;\n  \n\n  ref = (float *)malloc(ref_nb * dim * sizeof(float));\n  query = (float *)malloc(query_nb * dim * sizeof(float));\n  \n\n  dist = (float *)malloc(query_nb * ref_nb * sizeof(float));\n  ind = (int *)malloc(query_nb * k * sizeof(float));\n\n  \n\n  srand(2);\n  for (i = 0; i < ref_nb * dim; i++)\n    ref[i] = (float)rand() / (float)RAND_MAX;\n  for (i = 0; i < query_nb * dim; i++)\n    query[i] = (float)rand() / (float)RAND_MAX;\n\n  \n\n  printf(\"Number of reference points      : %6d\\n\", ref_nb);\n  printf(\"Number of query points          : %6d\\n\", query_nb);\n  printf(\"Dimension of points             : %4d\\n\", dim);\n  printf(\"Number of neighbors to consider : %4d\\n\", k);\n  printf(\"Processing kNN search           :\\n\");\n\n  float *knn_dist = (float *)malloc(query_nb * k * sizeof(float));\n  int *knn_index = (int *)malloc(query_nb * k * sizeof(int));\n  printf(\"Ground truth computation in progress...\\n\\n\");\n  if (!knn_serial(ref, ref_nb, query, query_nb, dim, k, knn_dist, knn_index)) {\n    free(ref);\n    free(query);\n    free(knn_dist);\n    free(knn_index);\n    return EXIT_FAILURE;\n  }\n\n  struct timeval tic;\n  struct timeval toc;\n  float elapsed_time;\n\n  printf(\"On CPU: \\n\");\n  gettimeofday(&tic, NULL);\n  for (i = 0; i < c_iterations; i++) {\n    knn_serial(ref, ref_nb, query, query_nb, dim, k, dist, ind);\n  }\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         c_iterations, elapsed_time / (c_iterations));\n\n  printf(\"on GPU: \\n\");\n  gettimeofday(&tic, NULL);\n\n  for (i = 0; i < iterations; i++) {\n    #pragma omp target data map(to: ref[0:ref_nb * dim], query[0:query_nb * dim]) \\\n                          map(alloc: dist[0:query_nb * ref_nb], ind[0:query_nb * k])\n    {\n      \n\n      #pragma omp target teams num_teams((ref_nb + 15)*(query_nb + 15)/256) thread_limit(256) \n      {\n        float shared_A[BLOCK_DIM*BLOCK_DIM];\n        float shared_B[BLOCK_DIM*BLOCK_DIM];\n        int begin_A;\n        int begin_B;\n        int step_A;\n        int step_B;\n        int end_A;\n        \n        #pragma omp parallel \n        {\n          \n\n          int tx = omp_get_thread_num() % 16;\n          int ty = omp_get_thread_num() / 16;\n      \n          \n\n          float tmp;\n          float ssd = 0;\n      \n          \n\n          begin_A = BLOCK_DIM * (omp_get_team_num() / ((query_nb+15)/16));\n          begin_B = BLOCK_DIM * (omp_get_team_num() % ((query_nb+15)/16));\n          step_A  = BLOCK_DIM * ref_nb;\n          step_B  = BLOCK_DIM * query_nb;\n          end_A   = begin_A + (dim - 1) * ref_nb;\n      \n          \n\n          int cond0 = (begin_A + tx < ref_nb); \n\n          int cond1 = (begin_B + tx < query_nb); \n\n                                           \n\n          int cond2 =\n              (begin_A + ty < ref_nb); \n\n      \n          \n\n          \n\n          for (int a = begin_A, b = begin_B; \n                   a <= end_A; a += step_A, b += step_B) {\n            \n\n            \n\n            if (a / ref_nb + ty < dim) {\n              shared_A[ty*BLOCK_DIM+tx] = (cond0) ? ref[a + ref_nb * ty + tx] : 0;\n              shared_B[ty*BLOCK_DIM+tx] = (cond1) ? query[b + query_nb * ty + tx] : 0;\n            } else {\n              shared_A[ty*BLOCK_DIM+tx] = 0;\n              shared_B[ty*BLOCK_DIM+tx] = 0;\n            }\n      \n            \n\n            #pragma omp barrier\n      \n            \n\n            \n\n            if (cond2 && cond1) {\n              for (int k = 0; k < BLOCK_DIM; ++k) {\n                tmp = shared_A[k*BLOCK_DIM+ty] - shared_B[k*BLOCK_DIM+tx];\n                ssd += tmp * tmp;\n              }\n            }\n      \n            \n\n            \n\n            #pragma omp barrier\n          }\n      \n          \n\n          if (cond2 && cond1) dist[(begin_A + ty) * query_nb + begin_B + tx] = ssd;\n        }\n      }\n      \n      \n\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (unsigned int xIndex = 0; xIndex < query_nb; xIndex++) {\n        \n\n        float* p_dist = &dist[xIndex];\n        int* p_ind = &ind[xIndex];\n        float max_dist = p_dist[0];\n        p_ind[0] = 0;\n      \n        \n\n        for (int l = 1; l < k; l++) {\n          int curr_row = l * query_nb;\n          float curr_dist = p_dist[curr_row];\n          if (curr_dist < max_dist) {\n            int i = l - 1;\n            for (int a = 0; a < l - 1; a++) {\n              if (p_dist[a * query_nb] > curr_dist) {\n                i = a;\n                break;\n              }\n            }\n            for (int j = l; j > i; j--) {\n              p_dist[j * query_nb] = p_dist[(j - 1) * query_nb];\n              p_ind[j * query_nb] = p_ind[(j - 1) * query_nb];\n            }\n            p_dist[i * query_nb] = curr_dist;\n            p_ind[i * query_nb] = l;\n          } else {\n            p_ind[l * query_nb] = l;\n          }\n          max_dist = p_dist[curr_row];\n        }\n      \n        \n\n        int max_row = (k - 1) * query_nb;\n        for (int l = k; l < ref_nb; l++) {\n          float curr_dist = p_dist[l * query_nb];\n          if (curr_dist < max_dist) {\n            int i = k - 1;\n            for (int a = 0; a < k - 1; a++) {\n              if (p_dist[a * query_nb] > curr_dist) {\n                i = a;\n                break;\n              }\n            }\n            for (int j = k - 1; j > i; j--) {\n              p_dist[j * query_nb] = p_dist[(j - 1) * query_nb];\n              p_ind[j * query_nb] = p_ind[(j - 1) * query_nb];\n            }\n            p_dist[i * query_nb] = curr_dist;\n            p_ind[i * query_nb] = l;\n            max_dist = p_dist[max_row];\n          }\n        }\n      }\n      \n      \n\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (unsigned int i = 0; i < query_nb * k; i++)\n        dist[i] = sqrtf(dist[i]);\n\n      #pragma omp target update from (dist[0:query_nb * k]) \n      #pragma omp target update from (ind[0:query_nb * k])\n    }\n  }\n\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         iterations, elapsed_time / (iterations));\n\n  for (int i = 0; i < query_nb * k; ++i) {\n    if (fabs(dist[i] - knn_dist[i]) <= precision) {\n      nb_correct_precisions++;\n    }\n    if (ind[i] == knn_index[i]) {\n      nb_correct_indexes++;\n    } else {\n      printf(\"Mismatch @index %d: %d %d\\n\", i, ind[i], knn_index[i]);\n    }\n  }\n\n  float precision_accuracy = nb_correct_precisions / ((float)query_nb * k);\n  float index_accuracy = nb_correct_indexes / ((float)query_nb * k);\n  printf(\"Precision accuracy %f\\nIndex accuracy %f\\n\", precision_accuracy, index_accuracy);\n\n  free(ind);\n  free(dist);\n  free(query);\n  free(ref);\n}\n"}}
{"kernel_name": "knn", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n\n\n#include <algorithm>\n#include <cstdio>\n#include <sys/time.h>\n#include <time.h>\n#include <math.h>\n\n\n\n#define BLOCK_DIM 16\n\n\n\n\n\n\n\n\nfloat compute_distance(const float *ref, int ref_nb, const float *query,\n                       int query_nb, int dim, int ref_index, int query_index) {\n  float sum = 0.f;\n  for (int d = 0; d < dim; ++d) {\n    const float diff =\n        ref[d * ref_nb + ref_index] - query[d * query_nb + query_index];\n    sum += diff * diff;\n  }\n  return sqrtf(sum);\n}\n\nvoid modified_insertion_sort(float *dist, int *index, int length, int k) {\n\n  \n\n  index[0] = 0;\n\n  \n\n  for (int i = 1; i < length; ++i) {\n\n    \n\n    float curr_dist = dist[i];\n    int curr_index = i;\n\n    \n\n    \n\n    if (i >= k && curr_dist >= dist[k - 1]) {\n      continue;\n    }\n\n    \n\n    int j = std::min(i, k - 1);\n    while (j > 0 && dist[j - 1] > curr_dist) {\n      dist[j] = dist[j - 1];\n      index[j] = index[j - 1];\n      --j;\n    }\n\n    \n\n    dist[j] = curr_dist;\n    index[j] = curr_index;\n  }\n}\n\nbool knn_serial(const float *ref, int ref_nb, const float *query, int query_nb,\n           int dim, int k, float *knn_dist, int *knn_index) {\n  \n\n  \n\n  float *dist = (float *)malloc(ref_nb * sizeof(float));\n  int *index = (int *)malloc(ref_nb * sizeof(int));\n\n  \n\n  if (!dist || !index) {\n    printf(\"Memory allocation error\\n\");\n    free(dist);\n    free(index);\n    return false;\n  }\n\n  \n\n  for (int i = 0; i < query_nb; ++i) {\n\n    \n\n    for (int j = 0; j < ref_nb; ++j) {\n      dist[j] = compute_distance(ref, ref_nb, query, query_nb, dim, j, i);\n      index[j] = j;\n    }\n\n    \n\n    modified_insertion_sort(dist, index, ref_nb, k);\n\n    \n\n    for (int j = 0; j < k; ++j) {\n      knn_dist[j * query_nb + i] = dist[j];\n      knn_index[j * query_nb + i] = index[j];\n    }\n  }\n\n  \n\n  free(dist);\n  free(index);\n  return true;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int iterations = atoi(argv[1]);\n\n  float *ref;          \n\n  float *query;        \n\n  float *dist;         \n\n  int *ind;            \n\n  int ref_nb = 4096;   \n\n  int query_nb = 4096; \n\n  int dim = 68;        \n\n  int k = 20;          \n\n  int c_iterations = 1;\n  int i;\n  const float precision = 0.001f; \n\n  int nb_correct_precisions = 0;\n  int nb_correct_indexes = 0;\n  \n\n  ref = (float *)malloc(ref_nb * dim * sizeof(float));\n  query = (float *)malloc(query_nb * dim * sizeof(float));\n  \n\n  dist = (float *)malloc(query_nb * ref_nb * sizeof(float));\n  ind = (int *)malloc(query_nb * k * sizeof(float));\n\n  \n\n  srand(2);\n  for (i = 0; i < ref_nb * dim; i++)\n    ref[i] = (float)rand() / (float)RAND_MAX;\n  for (i = 0; i < query_nb * dim; i++)\n    query[i] = (float)rand() / (float)RAND_MAX;\n\n  \n\n  printf(\"Number of reference points      : %6d\\n\", ref_nb);\n  printf(\"Number of query points          : %6d\\n\", query_nb);\n  printf(\"Dimension of points             : %4d\\n\", dim);\n  printf(\"Number of neighbors to consider : %4d\\n\", k);\n  printf(\"Processing kNN search           :\\n\");\n\n  float *knn_dist = (float *)malloc(query_nb * k * sizeof(float));\n  int *knn_index = (int *)malloc(query_nb * k * sizeof(int));\n  printf(\"Ground truth computation in progress...\\n\\n\");\n  if (!knn_serial(ref, ref_nb, query, query_nb, dim, k, knn_dist, knn_index)) {\n    free(ref);\n    free(query);\n    free(knn_dist);\n    free(knn_index);\n    return EXIT_FAILURE;\n  }\n\n  struct timeval tic;\n  struct timeval toc;\n  float elapsed_time;\n\n  printf(\"On CPU: \\n\");\n  gettimeofday(&tic, NULL);\n  for (i = 0; i < c_iterations; i++) {\n    knn_serial(ref, ref_nb, query, query_nb, dim, k, dist, ind);\n  }\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         c_iterations, elapsed_time / (c_iterations));\n\n  printf(\"on GPU: \\n\");\n  gettimeofday(&tic, NULL);\n\n  for (i = 0; i < iterations; i++) {\n        {\n      \n\n            {\n        float shared_A[BLOCK_DIM*BLOCK_DIM];\n        float shared_B[BLOCK_DIM*BLOCK_DIM];\n        int begin_A;\n        int begin_B;\n        int step_A;\n        int step_B;\n        int end_A;\n        \n                {\n          \n\n          int tx = omp_get_thread_num() % 16;\n          int ty = omp_get_thread_num() / 16;\n      \n          \n\n          float tmp;\n          float ssd = 0;\n      \n          \n\n          begin_A = BLOCK_DIM * (omp_get_team_num() / ((query_nb+15)/16));\n          begin_B = BLOCK_DIM * (omp_get_team_num() % ((query_nb+15)/16));\n          step_A  = BLOCK_DIM * ref_nb;\n          step_B  = BLOCK_DIM * query_nb;\n          end_A   = begin_A + (dim - 1) * ref_nb;\n      \n          \n\n          int cond0 = (begin_A + tx < ref_nb); \n\n          int cond1 = (begin_B + tx < query_nb); \n\n                                           \n\n          int cond2 =\n              (begin_A + ty < ref_nb); \n\n      \n          \n\n          \n\n          for (int a = begin_A, b = begin_B; \n                   a <= end_A; a += step_A, b += step_B) {\n            \n\n            \n\n            if (a / ref_nb + ty < dim) {\n              shared_A[ty*BLOCK_DIM+tx] = (cond0) ? ref[a + ref_nb * ty + tx] : 0;\n              shared_B[ty*BLOCK_DIM+tx] = (cond1) ? query[b + query_nb * ty + tx] : 0;\n            } else {\n              shared_A[ty*BLOCK_DIM+tx] = 0;\n              shared_B[ty*BLOCK_DIM+tx] = 0;\n            }\n      \n            \n\n                  \n            \n\n            \n\n            if (cond2 && cond1) {\n              for (int k = 0; k < BLOCK_DIM; ++k) {\n                tmp = shared_A[k*BLOCK_DIM+ty] - shared_B[k*BLOCK_DIM+tx];\n                ssd += tmp * tmp;\n              }\n            }\n      \n            \n\n            \n\n                      }\n      \n          \n\n          if (cond2 && cond1) dist[(begin_A + ty) * query_nb + begin_B + tx] = ssd;\n        }\n      }\n      \n      \n\n            for (unsigned int xIndex = 0; xIndex < query_nb; xIndex++) {\n        \n\n        float* p_dist = &dist[xIndex];\n        int* p_ind = &ind[xIndex];\n        float max_dist = p_dist[0];\n        p_ind[0] = 0;\n      \n        \n\n        for (int l = 1; l < k; l++) {\n          int curr_row = l * query_nb;\n          float curr_dist = p_dist[curr_row];\n          if (curr_dist < max_dist) {\n            int i = l - 1;\n            for (int a = 0; a < l - 1; a++) {\n              if (p_dist[a * query_nb] > curr_dist) {\n                i = a;\n                break;\n              }\n            }\n            for (int j = l; j > i; j--) {\n              p_dist[j * query_nb] = p_dist[(j - 1) * query_nb];\n              p_ind[j * query_nb] = p_ind[(j - 1) * query_nb];\n            }\n            p_dist[i * query_nb] = curr_dist;\n            p_ind[i * query_nb] = l;\n          } else {\n            p_ind[l * query_nb] = l;\n          }\n          max_dist = p_dist[curr_row];\n        }\n      \n        \n\n        int max_row = (k - 1) * query_nb;\n        for (int l = k; l < ref_nb; l++) {\n          float curr_dist = p_dist[l * query_nb];\n          if (curr_dist < max_dist) {\n            int i = k - 1;\n            for (int a = 0; a < k - 1; a++) {\n              if (p_dist[a * query_nb] > curr_dist) {\n                i = a;\n                break;\n              }\n            }\n            for (int j = k - 1; j > i; j--) {\n              p_dist[j * query_nb] = p_dist[(j - 1) * query_nb];\n              p_ind[j * query_nb] = p_ind[(j - 1) * query_nb];\n            }\n            p_dist[i * query_nb] = curr_dist;\n            p_ind[i * query_nb] = l;\n            max_dist = p_dist[max_row];\n          }\n        }\n      }\n      \n      \n\n            for (unsigned int i = 0; i < query_nb * k; i++)\n        dist[i] = sqrtf(dist[i]);\n\n                }\n  }\n\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         iterations, elapsed_time / (iterations));\n\n  for (int i = 0; i < query_nb * k; ++i) {\n    if (fabs(dist[i] - knn_dist[i]) <= precision) {\n      nb_correct_precisions++;\n    }\n    if (ind[i] == knn_index[i]) {\n      nb_correct_indexes++;\n    } else {\n      printf(\"Mismatch @index %d: %d %d\\n\", i, ind[i], knn_index[i]);\n    }\n  }\n\n  float precision_accuracy = nb_correct_precisions / ((float)query_nb * k);\n  float index_accuracy = nb_correct_indexes / ((float)query_nb * k);\n  printf(\"Precision accuracy %f\\nIndex accuracy %f\\n\", precision_accuracy, index_accuracy);\n\n  free(ind);\n  free(dist);\n  free(query);\n  free(ref);\n}"}}
{"kernel_name": "knn", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n\n#include <sys/time.h>\n#include <algorithm>\n#include <cstdio>\n#include <sycl/sycl.hpp>\n\n\n\n#define BLOCK_DIM 16\n\n\n\n\n\n\n\n\n\n\nvoid knn_parallel(sycl::queue &q, float *ref_host, int ref_width, float *query_host,\n              int query_width, int height, int k, float *dist_host, int *ind_host) {\n\n  unsigned int size_of_float = sizeof(float);\n  unsigned int size_of_int = sizeof(int);\n\n  \n\n  float *query_dev = sycl::malloc_device<float>(query_width * height, q);\n  q.memcpy(query_dev, query_host, query_width * height * sizeof(float));\n\n  float *dist_dev  = sycl::malloc_device<float>(query_width * ref_width, q);\n\n    int *ind_dev   = sycl::malloc_device<int>(query_width * k, q);\n\n  float *ref_dev   = sycl::malloc_device<float>(ref_width * height, q);\n  q.memcpy(ref_dev, ref_host, ref_width * height * sizeof(float));\n\n  \n\n  sycl::range<2> g_16x16((ref_width + 15) / 16 * 16, (query_width + 15) / 16 * 16);\n  sycl::range<2> t_16x16(16, 16);\n\n  sycl::range<1> g_256x1((query_width + 255) / 256 * 256);\n  sycl::range<1> t_256x1(256);\n\n  sycl::range<2> g_k_16x16((k + 15) / 16 * 16, (query_width + 15) / 16 * 16);\n  sycl::range<2> t_k_16x16(16, 16);\n\n\n  \n\n  \n\n  q.submit([&] (sycl::handler &h) {\n    auto A = ref_dev;\n    auto B = query_dev;\n    auto AB = dist_dev;\n    sycl::local_accessor<float, 2> shared_A (sycl::range<2>{BLOCK_DIM, BLOCK_DIM}, h);\n    sycl::local_accessor<float, 2> shared_B (sycl::range<2>{BLOCK_DIM, BLOCK_DIM}, h);\n    sycl::local_accessor<int, 0> begin_A (h);\n    sycl::local_accessor<int, 0> begin_B (h);\n    sycl::local_accessor<int, 0> step_A (h);\n    sycl::local_accessor<int, 0> step_B (h);\n    sycl::local_accessor<int, 0> end_A (h);\n    h.parallel_for<class ComputeDistanceGlobal>(\n      sycl::nd_range<2>(g_16x16, t_16x16), [=] (sycl::nd_item<2> item) {\n      \n\n      int tx = item.get_local_id(1);\n      int ty = item.get_local_id(0);\n\n      \n\n      float tmp;\n      float ssd = 0;\n\n      \n\n      begin_A = BLOCK_DIM * item.get_group(0);\n      begin_B = BLOCK_DIM * item.get_group(1);\n      step_A  = BLOCK_DIM * ref_width;\n      step_B  = BLOCK_DIM * query_width;\n      end_A   = begin_A + (height - 1) * ref_width;\n\n      \n\n      int cond0 = (begin_A + tx < ref_width); \n\n      int cond1 = (begin_B + tx < query_width); \n\n                                       \n\n      int cond2 = (begin_A + ty < ref_width); \n\n\n      \n\n      \n\n      for (int a = begin_A, b = begin_B;\n               a <= end_A; a += step_A, b += step_B) {\n        \n\n        \n\n        if (a / ref_width + ty < height) {\n          shared_A[ty][tx] = (cond0) ? A[a + ref_width * ty + tx] : 0;\n          shared_B[ty][tx] = (cond1) ? B[b + query_width * ty + tx] : 0;\n        } else {\n          shared_A[ty][tx] = 0;\n          shared_B[ty][tx] = 0;\n        }\n\n        \n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        \n\n        \n\n        if (cond2 && cond1) {\n          for (int k = 0; k < BLOCK_DIM; ++k) {\n            tmp = shared_A[k][ty] - shared_B[k][tx];\n            ssd += tmp * tmp;\n          }\n        }\n\n        \n\n        \n\n        item.barrier(sycl::access::fence_space::local_space);\n      }\n\n      \n\n      if (cond2 && cond1)\n        AB[(begin_A + ty) * query_width + begin_B + tx] = ssd;\n    });\n  });\n\n#ifdef DEBUG\n  q.memcpy(dist_host, dist_dev, query_width * ref_width * size_of_float).wait();\n  for (int i = 0; i < query_width * ref_width; i++)\n    printf(\"k1 dist: %d %f\\n\", i, dist_host[i]);\n#endif\n\n  \n\n  \n\n  q.submit([&] (sycl::handler &h) {\n    h.parallel_for<class insertionSort>(\n      sycl::nd_range<1>(g_256x1, t_256x1), [=] (sycl::nd_item<1> item) {\n      int l, i, j;\n      float *p_dist;\n      int *p_ind;\n      float curr_dist, max_dist;\n      int curr_row, max_row;\n      unsigned int xIndex = item.get_global_id(0);\n\n      if (xIndex < query_width) {\n        \n\n        p_dist = &dist_dev[xIndex];\n        p_ind = &ind_dev[xIndex];\n        max_dist = p_dist[0];\n        p_ind[0] = 0;\n\n        \n\n        for (l = 1; l < k; l++) {\n          curr_row = l * query_width;\n          curr_dist = p_dist[curr_row];\n          if (curr_dist < max_dist) {\n            i = l - 1;\n            for (int a = 0; a < l - 1; a++) {\n              if (p_dist[a * query_width] > curr_dist) {\n                i = a;\n                break;\n              }\n            }\n            for (j = l; j > i; j--) {\n              p_dist[j * query_width] = p_dist[(j - 1) * query_width];\n              p_ind[j * query_width] = p_ind[(j - 1) * query_width];\n            }\n            p_dist[i * query_width] = curr_dist;\n            p_ind[i * query_width] = l;\n          } else {\n            p_ind[l * query_width] = l;\n          }\n          max_dist = p_dist[curr_row];\n        }\n\n        \n\n        max_row = (k - 1) * query_width;\n        for (l = k; l < ref_width; l++) {\n          curr_dist = p_dist[l * query_width];\n          if (curr_dist < max_dist) {\n            i = k - 1;\n            for (int a = 0; a < k - 1; a++) {\n              if (p_dist[a * query_width] > curr_dist) {\n                i = a;\n                break;\n              }\n            }\n            for (j = k - 1; j > i; j--) {\n              p_dist[j * query_width] = p_dist[(j - 1) * query_width];\n              p_ind[j * query_width] = p_ind[(j - 1) * query_width];\n            }\n            p_dist[i * query_width] = curr_dist;\n            p_ind[i * query_width] = l;\n            max_dist = p_dist[max_row];\n          }\n        }\n      }\n    });\n  });\n\n#ifdef DEBUG\n  q.memcpy(dist_host, dist_dev, query_width * ref_width * size_of_float);\n  q.memcpy(ind_host, ind_dev, query_width * k * size_of_int);\n  q.wait();\n\n  for (int i = 0; i < query_width * ref_width; i++)\n    printf(\"k2 dist: %d %f\\n\", i, dist_host[i]);\n\n  for (int i = 0; i < query_width * k; i++)\n    printf(\"k2 index: %d %d\\n\", i, ind_host[i]);\n#endif\n\n  \n\n  \n\n  q.submit([&] (sycl::handler &h) {\n    h.parallel_for<class parallelSqrt>(\n      sycl::nd_range<2>(g_k_16x16, t_k_16x16), [=] (sycl::nd_item<2> item) {\n      unsigned int xIndex = item.get_global_id(1);\n      unsigned int yIndex = item.get_global_id(0);\n      if (xIndex < query_width && yIndex < k)\n        dist_dev[yIndex * query_width + xIndex] = sycl::sqrt(dist_dev[yIndex * query_width + xIndex]);\n    });\n  });\n\n  q.memcpy(dist_host, dist_dev, query_width * k * size_of_float);\n  q.memcpy(ind_host, ind_dev, query_width * k * size_of_int);\n  q.wait();\n\n  sycl::free(ref_dev, q);\n  sycl::free(ind_dev, q);\n  sycl::free(query_dev, q);\n  sycl::free(dist_dev, q);\n}\n\nfloat compute_distance(const float *ref, int ref_nb, const float *query,\n                       int query_nb, int dim, int ref_index, int query_index) {\n  float sum = 0.f;\n  for (int d = 0; d < dim; ++d) {\n    const float diff =\n        ref[d * ref_nb + ref_index] - query[d * query_nb + query_index];\n    sum += diff * diff;\n  }\n  return sqrtf(sum);\n}\n\nvoid modified_insertion_sort(float *dist, int *index, int length, int k) {\n\n  \n\n  index[0] = 0;\n\n  \n\n  for (int i = 1; i < length; ++i) {\n\n    \n\n    float curr_dist = dist[i];\n    int curr_index = i;\n\n    \n\n    \n\n    if (i >= k && curr_dist >= dist[k - 1]) {\n      continue;\n    }\n\n    \n\n    int j = std::min(i, k - 1);\n    while (j > 0 && dist[j - 1] > curr_dist) {\n      dist[j] = dist[j - 1];\n      index[j] = index[j - 1];\n      --j;\n    }\n\n    \n\n    dist[j] = curr_dist;\n    index[j] = curr_index;\n  }\n}\n\nbool knn_serial(const float *ref, int ref_nb, const float *query, int query_nb,\n           int dim, int k, float *knn_dist, int *knn_index) {\n  \n\n  \n\n  float *dist = (float *)malloc(ref_nb * sizeof(float));\n  int *index = (int *)malloc(ref_nb * sizeof(int));\n\n  \n\n  if (!dist || !index) {\n    printf(\"Memory allocation error\\n\");\n    free(dist);\n    free(index);\n    return false;\n  }\n\n  \n\n  for (int i = 0; i < query_nb; ++i) {\n\n    \n\n    for (int j = 0; j < ref_nb; ++j) {\n      dist[j] = compute_distance(ref, ref_nb, query, query_nb, dim, j, i);\n      index[j] = j;\n    }\n\n    \n\n    modified_insertion_sort(dist, index, ref_nb, k);\n\n    \n\n    for (int j = 0; j < k; ++j) {\n      knn_dist[j * query_nb + i] = dist[j];\n      knn_index[j * query_nb + i] = index[j];\n    }\n  }\n\n  \n\n  free(dist);\n  free(index);\n  return true;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int iterations = atoi(argv[1]);\n\n  float *ref;          \n\n  float *query;        \n\n  float *dist;         \n\n  int *ind;            \n\n  int ref_nb = 4096;   \n\n  int query_nb = 4096; \n\n  int dim = 68;        \n\n  int k = 20;          \n\n  int c_iterations = 1;\n  int i;\n  const float precision = 0.001f; \n\n  int nb_correct_precisions = 0;\n  int nb_correct_indexes = 0;\n  \n\n  ref = (float *)malloc(ref_nb * dim * sizeof(float));\n  query = (float *)malloc(query_nb * dim * sizeof(float));\n  dist = (float *)malloc(query_nb * k * sizeof(float));\n  ind = (int *)malloc(query_nb * k * sizeof(float));\n\n  \n\n  srand(2);\n  for (i = 0; i < ref_nb * dim; i++)\n    ref[i] = (float)rand() / (float)RAND_MAX;\n  for (i = 0; i < query_nb * dim; i++)\n    query[i] = (float)rand() / (float)RAND_MAX;\n\n  \n\n  printf(\"Number of reference points      : %6d\\n\", ref_nb);\n  printf(\"Number of query points          : %6d\\n\", query_nb);\n  printf(\"Dimension of points             : %4d\\n\", dim);\n  printf(\"Number of neighbors to consider : %4d\\n\", k);\n  printf(\"Processing kNN search           :\\n\");\n\n  float *knn_dist = (float *)malloc(query_nb * k * sizeof(float));\n  int *knn_index = (int *)malloc(query_nb * k * sizeof(int));\n  printf(\"Ground truth computation in progress...\\n\\n\");\n  if (!knn_serial(ref, ref_nb, query, query_nb, dim, k, knn_dist, knn_index)) {\n    free(ref);\n    free(query);\n    free(knn_dist);\n    free(knn_index);\n    return EXIT_FAILURE;\n  }\n\n  struct timeval tic;\n  struct timeval toc;\n  float elapsed_time;\n\n  printf(\"On CPU: \\n\");\n  gettimeofday(&tic, NULL);\n  for (i = 0; i < c_iterations; i++) {\n    knn_serial(ref, ref_nb, query, query_nb, dim, k, dist, ind);\n  }\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         c_iterations, elapsed_time / (c_iterations));\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  printf(\"on GPU: \\n\");\n  gettimeofday(&tic, NULL);\n  for (i = 0; i < iterations; i++) {\n    knn_parallel(q, ref, ref_nb, query, query_nb, dim, k, dist, ind);\n  }\n  gettimeofday(&toc, NULL);\n  elapsed_time = toc.tv_sec - tic.tv_sec;\n  elapsed_time += (toc.tv_usec - tic.tv_usec) / 1000000.;\n  printf(\" done in %f s for %d iterations (%f s by iteration)\\n\", elapsed_time,\n         iterations, elapsed_time / (iterations));\n\n  for (int i = 0; i < query_nb * k; ++i) {\n    if (fabs(dist[i] - knn_dist[i]) <= precision) {\n      nb_correct_precisions++;\n    }\n    if (ind[i] == knn_index[i]) {\n      nb_correct_indexes++;\n    } else {\n      printf(\"Mismatch @index %d: %d %d\\n\", i, ind[i], knn_index[i]);\n    }\n  }\n\n  float precision_accuracy = nb_correct_precisions / ((float)query_nb * k);\n  float index_accuracy = nb_correct_indexes / ((float)query_nb * k);\n  printf(\"Precision accuracy %f\\nIndex accuracy %f\\n\", precision_accuracy, index_accuracy);\n\n  free(ind);\n  free(dist);\n  free(query);\n  free(ref);\n}\n"}}
{"kernel_name": "lda", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <vector>\n#include <numeric>\n#include <cuda.h>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int repeat = atoi(argv[1]);\n\n  int i;\n  srand(123);\n\n  const int num_topics = 1000;\n  const int num_words  = 10266;\n  const int block_cnt  = 500;\n  const int num_indptr = block_cnt; \n\n  const int block_dim  = 256;\n  const int num_iters  = 64;\n \n  std::vector<float> alpha(num_topics);\n  for (i = 0; i < num_topics; i++)  alpha[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> beta(num_topics * num_words);\n  for (i = 0; i < num_topics * num_words; i++)  beta[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> grad_alpha(num_topics * block_cnt, 0.0f);\n  std::vector<float> new_beta(num_topics * num_words, 0.0f);\n  std::vector<int> h_locks(num_words, 0);\n  std::vector<float> gamma (num_indptr * num_topics);\n\n  std::vector<int> indptr (num_indptr+1, 0);\n  indptr[num_indptr] = num_words-1;\n  for (i = num_indptr; i >= 1; i--) {\n    int t = indptr[i] - 1 - (rand() % (num_words/num_indptr));\n    if (t < 0) break;\n    indptr[i-1] = t;\n  }\n  const int num_cols = num_words;\n\n  std::vector<int> cols (num_cols);\n  std::vector<float> counts (num_cols);\n\n  for (i = 0; i < num_cols; i++) {\n    cols[i] = i;\n    counts[i] = 0.5f; \n\n  }\n\n  float *d_alpha, *d_beta, *d_grad_alpha, *d_new_beta;\n  float *d_counts, *d_gamma, *d_vali_losses, *d_train_losses;\n  int *d_locks, *d_cols, *d_indptr;\n  bool *d_vali;\n\n  cudaMalloc((void**)&d_alpha, sizeof(float) * num_topics);\n  cudaMemcpy(d_alpha, alpha.data(), sizeof(float) * num_topics, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_beta, sizeof(float) * num_topics * num_words);\n  cudaMemcpy(d_beta, beta.data(), sizeof(float) * num_topics * num_words, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_grad_alpha, sizeof(float) * num_topics * block_cnt);\n  cudaMemcpy(d_grad_alpha, grad_alpha.data(), sizeof(float) * block_cnt * num_topics, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_new_beta, sizeof(float) * num_topics * num_words);\n  cudaMemcpy(d_new_beta, new_beta.data(), sizeof(float) * num_topics * num_words, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_locks, sizeof(int) * num_words);\n  cudaMemcpy(d_locks, h_locks.data(), sizeof(int) * num_words, cudaMemcpyHostToDevice);\n  \n  cudaMalloc((void**)&d_cols, sizeof(int) * num_cols);\n  cudaMemcpy(d_cols, cols.data(), sizeof(int) * num_cols, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_indptr, sizeof(int) * (num_indptr + 1));\n  cudaMemcpy(d_indptr, indptr.data(), sizeof(int) * (num_indptr + 1), cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_vali, sizeof(bool) * num_cols);\n\n  cudaMalloc((void**)&d_counts, sizeof(float) * num_cols);\n  cudaMemcpy(d_counts, counts.data(), sizeof(float) * num_cols, cudaMemcpyHostToDevice);\n\n  \n\n  cudaMalloc((void**)&d_gamma, sizeof(float) * num_indptr * num_topics);\n\n  \n\n  cudaMalloc((void**)&d_train_losses, sizeof(float) * block_cnt);\n  cudaMemset(d_train_losses, 0, sizeof(float) * block_cnt);\n\n  cudaMalloc((void**)&d_vali_losses, sizeof(float) * block_cnt);\n  cudaMemset(d_vali_losses, 0, sizeof(float) * block_cnt);\n\n  \n\n  std::vector<float> train_losses(block_cnt), vali_losses(block_cnt);\n\n  \n\n  cudaMemset(d_vali, 0, sizeof(bool) * num_cols); \n  bool init_gamma = false;\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (i = 0; i < repeat; i++) {\n    init_gamma = (i == 0) ? true : false;\n    EstepKernel<<<block_cnt, block_dim, 4 * num_topics * sizeof(float)>>>(\n      d_cols,\n      d_indptr,\n      d_vali,\n      d_counts,\n      init_gamma, num_cols, num_indptr, num_topics, num_iters,\n      d_alpha,\n      d_beta,\n      d_gamma,\n      d_grad_alpha,\n      d_new_beta,\n      d_train_losses,\n      d_vali_losses,\n      d_locks);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (training): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  cudaMemset(d_vali, 0xFFFFFFFF, sizeof(bool) * num_cols); \n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (i = 0; i < repeat; i++) {\n    EstepKernel<<<block_cnt, block_dim, 4 * num_topics * sizeof(float)>>>(\n      d_cols,\n      d_indptr,\n      d_vali,\n      d_counts,\n      init_gamma, num_cols, num_indptr, num_topics, num_iters,\n      d_alpha,\n      d_beta,\n      d_gamma,\n      d_grad_alpha,\n      d_new_beta,\n      d_train_losses,\n      d_vali_losses,\n      d_locks);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (validation): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(vali_losses.data(), d_vali_losses, sizeof(float) * block_cnt, cudaMemcpyDeviceToHost);\n  cudaMemcpy(train_losses.data(), d_train_losses, sizeof(float) * block_cnt, cudaMemcpyDeviceToHost);\n\n  float total_train_loss = std::accumulate(train_losses.begin(), train_losses.end(), 0.0f);\n  float total_vali_loss = std::accumulate(vali_losses.begin(), vali_losses.end(), 0.0f);\n  printf(\"Total train and validate loss: %f %f\\n\", total_train_loss, total_vali_loss);\n\n  cudaFree(d_cols);\n  cudaFree(d_indptr);\n  cudaFree(d_vali);\n  cudaFree(d_counts);\n  cudaFree(d_alpha);\n  cudaFree(d_beta);\n  cudaFree(d_gamma);\n  cudaFree(d_grad_alpha);\n  cudaFree(d_new_beta);\n  cudaFree(d_train_losses);\n  cudaFree(d_vali_losses);\n  cudaFree(d_locks);\n\n  return 0;\n}\n"}}
{"kernel_name": "lda", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <vector>\n#include <numeric>\n#include <hip/hip_runtime.h>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int repeat = atoi(argv[1]);\n\n  int i;\n  srand(123);\n\n  const int num_topics = 1000;\n  const int num_words  = 10266;\n  const int block_cnt  = 500;\n  const int num_indptr = block_cnt; \n\n  const int block_dim  = 256;\n  const int num_iters  = 64;\n \n  std::vector<float> alpha(num_topics);\n  for (i = 0; i < num_topics; i++)  alpha[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> beta(num_topics * num_words);\n  for (i = 0; i < num_topics * num_words; i++)  beta[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> grad_alpha(num_topics * block_cnt, 0.0f);\n  std::vector<float> new_beta(num_topics * num_words, 0.0f);\n  std::vector<int> h_locks(num_words, 0);\n  std::vector<float> gamma (num_indptr * num_topics);\n\n  std::vector<int> indptr (num_indptr+1, 0);\n  indptr[num_indptr] = num_words-1;\n  for (i = num_indptr; i >= 1; i--) {\n    int t = indptr[i] - 1 - (rand() % (num_words/num_indptr));\n    if (t < 0) break;\n    indptr[i-1] = t;\n  }\n  const int num_cols = num_words;\n\n  std::vector<int> cols (num_cols);\n  std::vector<float> counts (num_cols);\n\n  for (i = 0; i < num_cols; i++) {\n    cols[i] = i;\n    counts[i] = 0.5f; \n\n  }\n\n  float *d_alpha, *d_beta, *d_grad_alpha, *d_new_beta;\n  float *d_counts, *d_gamma, *d_vali_losses, *d_train_losses;\n  int *d_locks, *d_cols, *d_indptr;\n  bool *d_vali;\n\n  hipMalloc((void**)&d_alpha, sizeof(float) * num_topics);\n  hipMemcpy(d_alpha, alpha.data(), sizeof(float) * num_topics, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_beta, sizeof(float) * num_topics * num_words);\n  hipMemcpy(d_beta, beta.data(), sizeof(float) * num_topics * num_words, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_grad_alpha, sizeof(float) * num_topics * block_cnt);\n  hipMemcpy(d_grad_alpha, grad_alpha.data(), sizeof(float) * block_cnt * num_topics, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_new_beta, sizeof(float) * num_topics * num_words);\n  hipMemcpy(d_new_beta, new_beta.data(), sizeof(float) * num_topics * num_words, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_locks, sizeof(int) * num_words);\n  hipMemcpy(d_locks, h_locks.data(), sizeof(int) * num_words, hipMemcpyHostToDevice);\n  \n  hipMalloc((void**)&d_cols, sizeof(int) * num_cols);\n  hipMemcpy(d_cols, cols.data(), sizeof(int) * num_cols, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_indptr, sizeof(int) * (num_indptr + 1));\n  hipMemcpy(d_indptr, indptr.data(), sizeof(int) * (num_indptr + 1), hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_vali, sizeof(bool) * num_cols);\n\n  hipMalloc((void**)&d_counts, sizeof(float) * num_cols);\n  hipMemcpy(d_counts, counts.data(), sizeof(float) * num_cols, hipMemcpyHostToDevice);\n\n  \n\n  hipMalloc((void**)&d_gamma, sizeof(float) * num_indptr * num_topics);\n\n  \n\n  hipMalloc((void**)&d_train_losses, sizeof(float) * block_cnt);\n  hipMemset(d_train_losses, 0, sizeof(float) * block_cnt);\n\n  hipMalloc((void**)&d_vali_losses, sizeof(float) * block_cnt);\n  hipMemset(d_vali_losses, 0, sizeof(float) * block_cnt);\n\n  \n\n  std::vector<float> train_losses(block_cnt), vali_losses(block_cnt);\n\n  \n\n  hipMemset(d_vali, 0, sizeof(bool) * num_cols); \n  bool init_gamma = false;\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (i = 0; i < repeat; i++) {\n    init_gamma = (i == 0) ? true : false;\n    EstepKernel<<<block_cnt, block_dim, 4 * num_topics * sizeof(float)>>>(\n      d_cols,\n      d_indptr,\n      d_vali,\n      d_counts,\n      init_gamma, num_cols, num_indptr, num_topics, num_iters,\n      d_alpha,\n      d_beta,\n      d_gamma,\n      d_grad_alpha,\n      d_new_beta,\n      d_train_losses,\n      d_vali_losses,\n      d_locks);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (training): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  hipMemset(d_vali, 0xFFFFFFFF, sizeof(bool) * num_cols); \n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (i = 0; i < repeat; i++) {\n    EstepKernel<<<block_cnt, block_dim, 4 * num_topics * sizeof(float)>>>(\n      d_cols,\n      d_indptr,\n      d_vali,\n      d_counts,\n      init_gamma, num_cols, num_indptr, num_topics, num_iters,\n      d_alpha,\n      d_beta,\n      d_gamma,\n      d_grad_alpha,\n      d_new_beta,\n      d_train_losses,\n      d_vali_losses,\n      d_locks);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (validation): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(vali_losses.data(), d_vali_losses, sizeof(float) * block_cnt, hipMemcpyDeviceToHost);\n  hipMemcpy(train_losses.data(), d_train_losses, sizeof(float) * block_cnt, hipMemcpyDeviceToHost);\n\n  float total_train_loss = std::accumulate(train_losses.begin(), train_losses.end(), 0.0f);\n  float total_vali_loss = std::accumulate(vali_losses.begin(), vali_losses.end(), 0.0f);\n  printf(\"Total train and validate loss: %f %f\\n\", total_train_loss, total_vali_loss);\n\n  hipFree(d_cols);\n  hipFree(d_indptr);\n  hipFree(d_vali);\n  hipFree(d_counts);\n  hipFree(d_alpha);\n  hipFree(d_beta);\n  hipFree(d_gamma);\n  hipFree(d_grad_alpha);\n  hipFree(d_new_beta);\n  hipFree(d_train_losses);\n  hipFree(d_vali_losses);\n  hipFree(d_locks);\n\n  return 0;\n}\n"}}
{"kernel_name": "lda", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <cstdio>\n#include <cstring>\n#include <cstdlib>\n#include <vector>\n#include <numeric>\n#include <math.h>\n#include <omp.h>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int repeat = atoi(argv[1]);\n\n  int i;\n  srand(123);\n\n  const int num_topics = 1000;\n  const int num_words  = 10266;\n  const int block_cnt  = 500;\n  const int num_indptr = block_cnt; \n\n  const int block_dim  = 256;\n  const int num_iters  = 64;\n \n  std::vector<float> alpha(num_topics);\n  for (i = 0; i < num_topics; i++)  alpha[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> beta(num_topics * num_words);\n  for (i = 0; i < num_topics * num_words; i++)  beta[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> grad_alpha(num_topics * block_cnt, 0.0f);\n  std::vector<float> new_beta(num_topics * num_words, 0.0f);\n  std::vector<int> h_locks(num_words, 0);\n  std::vector<float> gamma (num_indptr * num_topics);\n\n  std::vector<int> indptr (num_indptr+1, 0);\n  indptr[num_indptr] = num_words-1;\n  for (i = num_indptr; i >= 1; i--) {\n    int t = indptr[i] - 1 - (rand() % (num_words/num_indptr));\n    if (t < 0) break;\n    indptr[i-1] = t;\n  }\n  const int num_cols = num_words;\n\n  std::vector<int> cols (num_cols);\n  std::vector<float> counts (num_cols);\n\n  for (i = 0; i < num_cols; i++) {\n    cols[i] = i;\n    counts[i] = 0.5f; \n\n  }\n\n  float *d_alpha = alpha.data(); \n  float *d_beta = beta.data(); \n  float *d_grad_alpha = grad_alpha.data();\n  float *d_new_beta = new_beta.data();\n  float *d_counts = counts.data();\n  int *d_locks = h_locks.data();\n  int *d_cols = cols.data();\n  int *d_indptr = indptr.data();\n\n  \n\n  bool *d_vali = (bool*) calloc (num_cols, sizeof(bool));\n\n  \n\n  float *d_gamma = (float*) malloc (sizeof(float) * num_indptr * num_topics);\n\n  \n\n  std::vector<float> train_losses(block_cnt, 0.f), vali_losses(block_cnt, 0.f);\n\n  float *d_train_losses = train_losses.data();\n  float *d_vali_losses = vali_losses.data();\n\n  #pragma omp target data map (to: d_alpha[0:num_topics], \\\n                                   d_beta[0:num_topics * num_words],\\\n                                   d_grad_alpha[0:num_topics * block_cnt],\\\n                                   d_new_beta[0:num_topics * num_words],\\\n                                   d_locks[0:num_words],\\\n                                   d_cols[0:num_cols],\\\n                                   d_indptr[0:num_indptr+1],\\\n                                   d_counts[0:num_cols],\\\n                                   d_vali[0:num_cols]) \\\n                          map (tofrom: d_train_losses[0:block_cnt], \\\n                                       d_vali_losses[0:block_cnt]) \\\n                          map (alloc: d_gamma[0:num_indptr * num_topics])\n  {\n    \n\n    bool init_gamma = false;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (i = 0; i < repeat; i++) {\n      init_gamma = (i == 0) ? true : false;\n      EstepKernel<block_cnt, block_dim, 4 * num_topics>(\n        d_cols,\n        d_indptr,\n        d_vali,\n        d_counts,\n        init_gamma, num_cols, num_indptr, num_topics, num_iters,\n        d_alpha,\n        d_beta,\n        d_gamma,\n        d_grad_alpha,\n        d_new_beta,\n        d_train_losses,\n        d_vali_losses,\n        d_locks);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (training): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    \n\n    memset(d_vali, 0xFFFFFFFF, sizeof(bool) * num_cols); \n    #pragma omp target update to (d_vali[0:num_cols])\n\n    start = std::chrono::steady_clock::now();\n\n    for (i = 0; i < repeat; i++) {\n      EstepKernel<block_cnt, block_dim, 4 * num_topics>(\n        d_cols,\n        d_indptr,\n        d_vali,\n        d_counts,\n        init_gamma, num_cols, num_indptr, num_topics, num_iters,\n        d_alpha,\n        d_beta,\n        d_gamma,\n        d_grad_alpha,\n        d_new_beta,\n        d_train_losses,\n        d_vali_losses,\n        d_locks);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (validation): %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  float total_train_loss = std::accumulate(train_losses.begin(), train_losses.end(), 0.0f);\n  float total_vali_loss = std::accumulate(vali_losses.begin(), vali_losses.end(), 0.0f);\n  printf(\"Total train and validate loss: %f %f\\n\", total_train_loss, total_vali_loss);\n\n  free(d_vali);\n  free(d_gamma);\n\n  return 0;\n}\n"}}
{"kernel_name": "lda", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <cstdio>\n#include <cstring>\n#include <cstdlib>\n#include <vector>\n#include <numeric>\n#include <math.h>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int repeat = atoi(argv[1]);\n\n  int i;\n  srand(123);\n\n  const int num_topics = 1000;\n  const int num_words  = 10266;\n  const int block_cnt  = 500;\n  const int num_indptr = block_cnt; \n\n  const int block_dim  = 256;\n  const int num_iters  = 64;\n \n  std::vector<float> alpha(num_topics);\n  for (i = 0; i < num_topics; i++)  alpha[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> beta(num_topics * num_words);\n  for (i = 0; i < num_topics * num_words; i++)  beta[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> grad_alpha(num_topics * block_cnt, 0.0f);\n  std::vector<float> new_beta(num_topics * num_words, 0.0f);\n  std::vector<int> h_locks(num_words, 0);\n  std::vector<float> gamma (num_indptr * num_topics);\n\n  std::vector<int> indptr (num_indptr+1, 0);\n  indptr[num_indptr] = num_words-1;\n  for (i = num_indptr; i >= 1; i--) {\n    int t = indptr[i] - 1 - (rand() % (num_words/num_indptr));\n    if (t < 0) break;\n    indptr[i-1] = t;\n  }\n  const int num_cols = num_words;\n\n  std::vector<int> cols (num_cols);\n  std::vector<float> counts (num_cols);\n\n  for (i = 0; i < num_cols; i++) {\n    cols[i] = i;\n    counts[i] = 0.5f; \n\n  }\n\n  float *d_alpha = alpha.data(); \n  float *d_beta = beta.data(); \n  float *d_grad_alpha = grad_alpha.data();\n  float *d_new_beta = new_beta.data();\n  float *d_counts = counts.data();\n  int *d_locks = h_locks.data();\n  int *d_cols = cols.data();\n  int *d_indptr = indptr.data();\n\n  \n\n  bool *d_vali = (bool*) calloc (num_cols, sizeof(bool));\n\n  \n\n  float *d_gamma = (float*) malloc (sizeof(float) * num_indptr * num_topics);\n\n  \n\n  std::vector<float> train_losses(block_cnt, 0.f), vali_losses(block_cnt, 0.f);\n\n  float *d_train_losses = train_losses.data();\n  float *d_vali_losses = vali_losses.data();\n\n    {\n    \n\n    bool init_gamma = false;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (i = 0; i < repeat; i++) {\n      init_gamma = (i == 0) ? true : false;\n      EstepKernel<block_cnt, block_dim, 4 * num_topics>(\n        d_cols,\n        d_indptr,\n        d_vali,\n        d_counts,\n        init_gamma, num_cols, num_indptr, num_topics, num_iters,\n        d_alpha,\n        d_beta,\n        d_gamma,\n        d_grad_alpha,\n        d_new_beta,\n        d_train_losses,\n        d_vali_losses,\n        d_locks);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (training): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    \n\n    memset(d_vali, 0xFFFFFFFF, sizeof(bool) * num_cols); \n    \n    start = std::chrono::steady_clock::now();\n\n    for (i = 0; i < repeat; i++) {\n      EstepKernel<block_cnt, block_dim, 4 * num_topics>(\n        d_cols,\n        d_indptr,\n        d_vali,\n        d_counts,\n        init_gamma, num_cols, num_indptr, num_topics, num_iters,\n        d_alpha,\n        d_beta,\n        d_gamma,\n        d_grad_alpha,\n        d_new_beta,\n        d_train_losses,\n        d_vali_losses,\n        d_locks);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (validation): %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  float total_train_loss = std::accumulate(train_losses.begin(), train_losses.end(), 0.0f);\n  float total_vali_loss = std::accumulate(vali_losses.begin(), vali_losses.end(), 0.0f);\n  printf(\"Total train and validate loss: %f %f\\n\", total_train_loss, total_vali_loss);\n\n  free(d_vali);\n  free(d_gamma);\n\n  return 0;\n}"}}
{"kernel_name": "lda", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <vector>\n#include <numeric>\n#include <sycl/sycl.hpp>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int repeat = atoi(argv[1]);\n\n  int i;\n  srand(123);\n\n  const int num_topics = 1000;\n  const int num_words  = 10266;\n  const int block_cnt  = 500;\n  const int num_indptr = block_cnt; \n\n  const int block_dim  = 256;\n  const int num_iters  = 64;\n\n  std::vector<float> alpha(num_topics);\n  for (i = 0; i < num_topics; i++)  alpha[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> beta(num_topics * num_words);\n  for (i = 0; i < num_topics * num_words; i++)  beta[i] = (float) rand() / (float) RAND_MAX;\n\n  std::vector<float> grad_alpha(num_topics * block_cnt, 0.0f);\n  std::vector<float> new_beta(num_topics * num_words, 0.0f);\n  std::vector<int> h_locks(num_words, 0);\n  std::vector<float> gamma (num_indptr * num_topics);\n\n  std::vector<int> indptr (num_indptr+1, 0);\n  indptr[num_indptr] = num_words-1;\n  for (i = num_indptr; i >= 1; i--) {\n    int t = indptr[i] - 1 - (rand() % (num_words/num_indptr));\n    if (t < 0) break;\n    indptr[i-1] = t;\n  }\n  const int num_cols = num_words;\n\n  std::vector<int> cols (num_cols);\n  std::vector<float> counts (num_cols);\n\n  for (i = 0; i < num_cols; i++) {\n    cols[i] = i;\n    counts[i] = 0.5f; \n\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_alpha = sycl::malloc_device<float>(num_topics, q);\n  q.memcpy(d_alpha, alpha.data(), sizeof(float) * num_topics);\n\n  float *d_beta = sycl::malloc_device<float>(num_topics * num_words, q);\n  q.memcpy(d_beta, beta.data(), sizeof(float) * num_topics * num_words);\n\n  float *d_grad_alpha = sycl::malloc_device<float>(block_cnt * num_topics, q);\n  q.memcpy(d_grad_alpha, grad_alpha.data(), sizeof(float) * block_cnt * num_topics);\n\n  float *d_new_beta = sycl::malloc_device<float>(num_topics * num_words, q);\n  q.memcpy(d_new_beta, new_beta.data(), sizeof(float) * num_topics * num_words);\n\n  int *d_locks = sycl::malloc_device<int>(num_words, q);\n  q.memcpy(d_locks, h_locks.data(), sizeof(int) * num_words);\n\n  int *d_cols = sycl::malloc_device<int>(num_cols, q);\n  q.memcpy(d_cols, cols.data(), sizeof(int) * num_cols);\n\n  int *d_indptr = sycl::malloc_device<int>(num_indptr + 1, q);\n  q.memcpy(d_indptr, indptr.data(), sizeof(int) * (num_indptr + 1));\n\n  bool *d_vali = sycl::malloc_device<bool>(num_cols, q);\n\n  float *d_counts = sycl::malloc_device<float>(num_cols, q);\n  q.memcpy(d_counts, counts.data(), sizeof(float) * num_cols);\n\n  \n\n  float *d_gamma = sycl::malloc_device<float>(num_indptr * num_topics, q);\n\n  \n\n  float *d_train_losses = sycl::malloc_device<float>(block_cnt, q);\n  q.memset(d_train_losses, 0, sizeof(float) * block_cnt);\n\n  float *d_vali_losses = sycl::malloc_device<float>(block_cnt, q);\n  q.memset(d_vali_losses, 0, sizeof(float) * block_cnt);\n\n  \n\n  std::vector<float> train_losses(block_cnt), vali_losses(block_cnt);\n\n  \n\n  q.memset(d_vali, 0, sizeof(bool) * num_cols);\n\n  sycl::range<1> gws (block_cnt * block_dim);\n  sycl::range<1> lws (block_dim);\n\n  bool init_gamma = false;\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (i = 0; i < repeat; i++) {\n    init_gamma = (i == 0) ? true : false;\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> shared (sycl::range<1>(4 * num_topics), cgh);\n      sycl::local_accessor<float, 1> reduce (sycl::range<1>(32), cgh);\n      cgh.parallel_for<class train_step>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        EstepKernel(\n          item,\n          shared.get_pointer(),\n          reduce.get_pointer(),\n          d_cols,\n          d_indptr,\n          d_vali,\n          d_counts,\n          init_gamma, num_cols, num_indptr, num_topics, num_iters,\n          d_alpha,\n          d_beta,\n          d_gamma,\n          d_grad_alpha,\n          d_new_beta,\n          d_train_losses,\n          d_vali_losses,\n          d_locks);\n       });\n     });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (training): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  q.memset(d_vali, true, sizeof(bool) * num_cols);\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> shared (sycl::range<1>(4 * num_topics), cgh);\n      sycl::local_accessor<float, 1> reduce (sycl::range<1>(32), cgh);\n      cgh.parallel_for<class vali_step>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        EstepKernel(\n          item,\n          shared.get_pointer(),\n          reduce.get_pointer(),\n          d_cols,\n          d_indptr,\n          d_vali,\n          d_counts,\n          init_gamma, num_cols, num_indptr, num_topics, num_iters,\n          d_alpha,\n          d_beta,\n          d_gamma,\n          d_grad_alpha,\n          d_new_beta,\n          d_train_losses,\n          d_vali_losses,\n          d_locks);\n       });\n     });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (validation): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(vali_losses.data(), d_vali_losses, sizeof(float) * block_cnt);\n  q.memcpy(train_losses.data(), d_train_losses, sizeof(float) * block_cnt);\n  q.wait();\n\n  float total_train_loss = std::accumulate(train_losses.begin(), train_losses.end(), 0.0f);\n  float total_vali_loss = std::accumulate(vali_losses.begin(), vali_losses.end(), 0.0f);\n  printf(\"Total train and validate loss: %f %f\\n\", total_train_loss, total_vali_loss);\n\n  sycl::free(d_cols, q);\n  sycl::free(d_indptr, q);\n  sycl::free(d_vali, q);\n  sycl::free(d_counts, q);\n  sycl::free(d_alpha, q);\n  sycl::free(d_beta, q);\n  sycl::free(d_gamma, q);\n  sycl::free(d_grad_alpha, q);\n  sycl::free(d_new_beta, q);\n  sycl::free(d_train_losses, q);\n  sycl::free(d_vali_losses, q);\n  sycl::free(d_locks, q);\n  return 0;\n}\n"}}
{"kernel_name": "lif", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\nvoid reference (\n    int numNeurons, int neurons_per_item, float dt, \n    float*__restrict__ encode_result,\n    float*__restrict__ voltage_array,\n    float*__restrict__ reftime_array,\n    float tau_rc, float tau_ref,\n    float*__restrict__ bias,\n    float*__restrict__ gain,\n    float*__restrict__ spikes)\n{\n  for (int i = 0; i < numNeurons; i++)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n\n    voltage *= mult;\n\n    \n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\n__global__ void lif (\n    int numNeurons, int neurons_per_item, float dt, \n    const float*__restrict__ encode_result,\n          float*__restrict__ voltage_array,\n          float*__restrict__ reftime_array,\n    float tau_rc, float tau_ref,\n    const float*__restrict__ bias,\n    const float*__restrict__ gain,\n          float*__restrict__ spikes)\n{\n  int i = threadIdx.x + blockDim.x * blockIdx.x;\n  if (i < numNeurons)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n    \n    voltage *= mult;\n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <neurons per item> <num_items> <num_steps>\\n\", argv[0]);\n    return 1;\n  }\n  const int neurons_per_item = atoi(argv[1]);\n  const int num_items = atoi(argv[2]);\n  const int num_steps = atoi(argv[3]);\n\n  const int num_neurons = neurons_per_item * num_items;\n  const size_t neurons_size = num_neurons * sizeof(float);\n  const size_t items_size = num_items * sizeof(float);\n  const size_t neurons_per_item_size = neurons_per_item * sizeof(float);\n\n  float dt = 0.1;    \n\n  float tau_rc = 10; \n\n  float tau_ref = 2; \n\n\n  float* encode_result = (float*) malloc (items_size);\n  float* bias = (float*) malloc (neurons_per_item_size);\n  float* gain = (float*) malloc (neurons_per_item_size);\n\n  \n\n  float* voltage = (float*) malloc (neurons_size);\n  float* reftime = (float*) malloc (neurons_size);\n  float* spikes = (float*) malloc (neurons_size);;\n\n  \n\n  float* voltage_gold = (float*) malloc (neurons_size);\n  float* reftime_gold = (float*) malloc (neurons_size);\n  float* spikes_gold = (float*) malloc (neurons_size);;\n\n  srand(123);\n  for (int i = 0; i < num_items; i++) {\n    encode_result[i] = rand() / (float)RAND_MAX;\n  }\n  for (int i = 0; i < num_neurons; i++) {\n    voltage_gold[i] = voltage[i] = 1.f + rand() / (float)RAND_MAX;\n    reftime_gold[i] = reftime[i] = rand() % 5 / 10.f;\n  }\n  for (int i = 0; i < neurons_per_item; i++) {\n    bias[i] = rand() / (float)RAND_MAX;\n    gain[i] = rand() / (float)RAND_MAX + 0.5f;\n  }\n\n  float* d_encode_result;\n  float* d_bias;\n  float* d_gain;\n  cudaMalloc((void**)&d_encode_result, items_size);\n  cudaMalloc((void**)&d_bias, neurons_per_item_size);\n  cudaMalloc((void**)&d_gain, neurons_per_item_size);\n\n  \n\n  float* d_voltage;\n  float* d_reftime;\n  float* d_spikes;\n  cudaMalloc((void**)&d_voltage, neurons_size);\n  cudaMalloc((void**)&d_reftime, neurons_size);\n  cudaMalloc((void**)&d_spikes, neurons_size);\n\n  cudaMemcpy(d_encode_result, encode_result, items_size, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_bias, bias, neurons_per_item_size, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_gain, gain, neurons_per_item_size, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_voltage, voltage, neurons_size, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_reftime, reftime, neurons_size, cudaMemcpyHostToDevice);\n\n  dim3 blocks (256);\n  dim3 grids ((num_neurons + 255) / 256);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for(int step = 0; step < num_steps; step++) {\n    lif<<<grids, blocks>>>(\n        num_neurons, \n        neurons_per_item,\n        dt,\n        d_encode_result,\n        d_voltage,\n        d_reftime, \n        tau_rc,\n        tau_ref, \n        d_bias,\n        d_gain, \n        d_spikes);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto elapsed_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (elapsed_time * 1e-3) / num_steps);\n\n  cudaMemcpy(spikes, d_spikes, neurons_size, cudaMemcpyDeviceToHost); \n  cudaMemcpy(voltage, d_voltage, neurons_size, cudaMemcpyDeviceToHost); \n  cudaMemcpy(reftime, d_reftime, neurons_size, cudaMemcpyDeviceToHost); \n\n  for(int step = 0; step < num_steps; step++) {\n    reference(num_neurons, \n        neurons_per_item,\n        dt,\n        encode_result,\n        voltage_gold,\n        reftime_gold, \n        tau_rc,\n        tau_ref, \n        bias,\n        gain, \n        spikes_gold);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < num_neurons; i++) {\n    if (fabsf(spikes[i] - spikes_gold[i]) > 1e-3) {\n      printf(\"@%d: %f %f\\n\", i, spikes[i], spikes_gold[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  free(encode_result);\n  free(voltage);\n  free(voltage_gold);\n  free(reftime);\n  free(reftime_gold);\n  free(bias);\n  free(gain);\n  free(spikes);\n  free(spikes_gold);\n\n  cudaFree(d_encode_result);\n  cudaFree(d_voltage);\n  cudaFree(d_reftime);\n  cudaFree(d_bias);\n  cudaFree(d_gain);\n  cudaFree(d_spikes);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n"}}
{"kernel_name": "lif", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\nvoid reference (\n    int numNeurons, int neurons_per_item, float dt, \n    float*__restrict__ encode_result,\n    float*__restrict__ voltage_array,\n    float*__restrict__ reftime_array,\n    float tau_rc, float tau_ref,\n    float*__restrict__ bias,\n    float*__restrict__ gain,\n    float*__restrict__ spikes)\n{\n  for (int i = 0; i < numNeurons; i++)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n\n    voltage *= mult;\n\n    \n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\n__global__ void lif (\n    int numNeurons, int neurons_per_item, float dt, \n    const float*__restrict__ encode_result,\n          float*__restrict__ voltage_array,\n          float*__restrict__ reftime_array,\n    float tau_rc, float tau_ref,\n    const float*__restrict__ bias,\n    const float*__restrict__ gain,\n          float*__restrict__ spikes)\n{\n  int i = threadIdx.x + blockDim.x * blockIdx.x;\n  if (i < numNeurons)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n    \n    voltage *= mult;\n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <neurons per item> <num_items> <num_steps>\\n\", argv[0]);\n    return 1;\n  }\n  const int neurons_per_item = atoi(argv[1]);\n  const int num_items = atoi(argv[2]);\n  const int num_steps = atoi(argv[3]);\n\n  const int num_neurons = neurons_per_item * num_items;\n  const size_t neurons_size = num_neurons * sizeof(float);\n  const size_t items_size = num_items * sizeof(float);\n  const size_t neurons_per_item_size = neurons_per_item * sizeof(float);\n\n  float dt = 0.1;    \n\n  float tau_rc = 10; \n\n  float tau_ref = 2; \n\n\n  float* encode_result = (float*) malloc (items_size);\n  float* bias = (float*) malloc (neurons_per_item_size);\n  float* gain = (float*) malloc (neurons_per_item_size);\n\n  \n\n  float* voltage = (float*) malloc (neurons_size);\n  float* reftime = (float*) malloc (neurons_size);\n  float* spikes = (float*) malloc (neurons_size);;\n\n  \n\n  float* voltage_gold = (float*) malloc (neurons_size);\n  float* reftime_gold = (float*) malloc (neurons_size);\n  float* spikes_gold = (float*) malloc (neurons_size);;\n\n  srand(123);\n  for (int i = 0; i < num_items; i++) {\n    encode_result[i] = rand() / (float)RAND_MAX;\n  }\n  for (int i = 0; i < num_neurons; i++) {\n    voltage_gold[i] = voltage[i] = 1.f + rand() / (float)RAND_MAX;\n    reftime_gold[i] = reftime[i] = rand() % 5 / 10.f;\n  }\n  for (int i = 0; i < neurons_per_item; i++) {\n    bias[i] = rand() / (float)RAND_MAX;\n    gain[i] = rand() / (float)RAND_MAX + 0.5f;\n  }\n\n  float* d_encode_result;\n  float* d_bias;\n  float* d_gain;\n  hipMalloc((void**)&d_encode_result, items_size);\n  hipMalloc((void**)&d_bias, neurons_per_item_size);\n  hipMalloc((void**)&d_gain, neurons_per_item_size);\n\n  \n\n  float* d_voltage;\n  float* d_reftime;\n  float* d_spikes;\n  hipMalloc((void**)&d_voltage, neurons_size);\n  hipMalloc((void**)&d_reftime, neurons_size);\n  hipMalloc((void**)&d_spikes, neurons_size);\n\n  hipMemcpy(d_encode_result, encode_result, items_size, hipMemcpyHostToDevice);\n  hipMemcpy(d_bias, bias, neurons_per_item_size, hipMemcpyHostToDevice);\n  hipMemcpy(d_gain, gain, neurons_per_item_size, hipMemcpyHostToDevice);\n  hipMemcpy(d_voltage, voltage, neurons_size, hipMemcpyHostToDevice);\n  hipMemcpy(d_reftime, reftime, neurons_size, hipMemcpyHostToDevice);\n\n  dim3 blocks (256);\n  dim3 grids ((num_neurons + 255) / 256);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for(int step = 0; step < num_steps; step++) {\n    hipLaunchKernelGGL(lif, grids, blocks, 0, 0, \n        num_neurons, \n        neurons_per_item,\n        dt,\n        d_encode_result,\n        d_voltage,\n        d_reftime, \n        tau_rc,\n        tau_ref, \n        d_bias,\n        d_gain, \n        d_spikes);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto elapsed_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (elapsed_time * 1e-3) / num_steps);\n\n  hipMemcpy(spikes, d_spikes, neurons_size, hipMemcpyDeviceToHost); \n  hipMemcpy(voltage, d_voltage, neurons_size, hipMemcpyDeviceToHost); \n  hipMemcpy(reftime, d_reftime, neurons_size, hipMemcpyDeviceToHost); \n\n  for(int step = 0; step < num_steps; step++) {\n    reference(num_neurons, \n        neurons_per_item,\n        dt,\n        encode_result,\n        voltage_gold,\n        reftime_gold, \n        tau_rc,\n        tau_ref, \n        bias,\n        gain, \n        spikes_gold);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < num_neurons; i++) {\n    if (fabsf(spikes[i] - spikes_gold[i]) > 1e-3) {\n      printf(\"@%d: %f %f\\n\", i, spikes[i], spikes_gold[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  free(encode_result);\n  free(voltage);\n  free(voltage_gold);\n  free(reftime);\n  free(reftime_gold);\n  free(bias);\n  free(gain);\n  free(spikes);\n  free(spikes_gold);\n\n  hipFree(d_encode_result);\n  hipFree(d_voltage);\n  hipFree(d_reftime);\n  hipFree(d_bias);\n  hipFree(d_gain);\n  hipFree(d_spikes);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n"}}
{"kernel_name": "lif", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\nvoid reference (\n    int numNeurons, int neurons_per_item, float dt, \n    float*__restrict encode_result,\n    float*__restrict voltage_array,\n    float*__restrict reftime_array,\n    float tau_rc, float tau_ref,\n    float*__restrict bias,\n    float*__restrict gain,\n    float*__restrict spikes)\n{\n  for (int i = 0; i < numNeurons; i++)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n\n    voltage *= mult;\n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\nvoid test (\n    int numNeurons, int neurons_per_item, float dt, \n    float*__restrict encode_result,\n    float*__restrict voltage_array,\n    float*__restrict reftime_array,\n    float tau_rc, float tau_ref,\n    float*__restrict bias,\n    float*__restrict gain,\n    float*__restrict spikes)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < numNeurons; i++)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n\n    voltage *= mult;\n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <neurons per item> <num_items> <num_steps>\\n\", argv[0]);\n    return 1;\n  }\n  const int neurons_per_item = atoi(argv[1]);\n  const int num_items = atoi(argv[2]);\n  const int num_steps = atoi(argv[3]);\n\n  const int num_neurons = neurons_per_item * num_items;\n  const size_t neurons_size = num_neurons * sizeof(float);\n  const size_t items_size = num_items * sizeof(float);\n  const size_t neurons_per_item_size = neurons_per_item * sizeof(float);\n\n  float dt = 0.1;    \n\n  float tau_rc = 10; \n\n  float tau_ref = 2; \n\n\n  float* encode_result = (float*) malloc (items_size);\n  float* bias = (float*) malloc (neurons_per_item_size);\n  float* gain = (float*) malloc (neurons_per_item_size);\n\n  \n\n  float* voltage = (float*) malloc (neurons_size);\n  float* reftime = (float*) malloc (neurons_size);\n  float* spikes = (float*) malloc (neurons_size);;\n\n  \n\n  float* voltage_gold = (float*) malloc (neurons_size);\n  float* reftime_gold = (float*) malloc (neurons_size);\n  float* spikes_gold = (float*) malloc (neurons_size);;\n\n  srand(123);\n  for (int i = 0; i < num_items; i++) {\n    encode_result[i] = rand() / (float)RAND_MAX;\n  }\n  for (int i = 0; i < num_neurons; i++) {\n    voltage_gold[i] = voltage[i] = 1.f + rand() / (float)RAND_MAX;\n    reftime_gold[i] = reftime[i] = rand() % 5 / 10.f;\n  }\n  for (int i = 0; i < neurons_per_item; i++) {\n    bias[i] = rand() / (float)RAND_MAX;\n    gain[i] = rand() / (float)RAND_MAX + 0.5f;\n  }\n\n#pragma omp target data map(to: encode_result[0:num_items],\\\n                                bias[0:neurons_per_item],\\\n                                gain[0:neurons_per_item])\\\n                        map(from: spikes[0:num_neurons]) \\\n                        map(tofrom: voltage[0:num_neurons],\\\n                                    reftime[0:num_neurons])\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for(int step = 0; step < num_steps; step++) {\n    test(\n        num_neurons, \n        neurons_per_item,\n        dt,\n        encode_result,\n        voltage,\n        reftime, \n        tau_rc,\n        tau_ref, \n        bias,\n        gain, \n        spikes);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto elapsed_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (elapsed_time * 1e-3) / num_steps);\n}\n\n  for(int step = 0; step < num_steps; step++) {\n    reference(num_neurons, \n        neurons_per_item,\n        dt,\n        encode_result,\n        voltage_gold,\n        reftime_gold, \n        tau_rc,\n        tau_ref, \n        bias,\n        gain, \n        spikes_gold);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < num_neurons; i++) {\n    if (fabsf(spikes[i] - spikes_gold[i]) > 1e-3) {\n      printf(\"@%d: %f %f\\n\", i, spikes[i], spikes_gold[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  free(encode_result);\n  free(voltage);\n  free(voltage_gold);\n  free(reftime);\n  free(reftime_gold);\n  free(bias);\n  free(gain);\n  free(spikes);\n  free(spikes_gold);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n\n"}}
{"kernel_name": "lif", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n\nvoid reference (\n    int numNeurons, int neurons_per_item, float dt, \n    float*__restrict encode_result,\n    float*__restrict voltage_array,\n    float*__restrict reftime_array,\n    float tau_rc, float tau_ref,\n    float*__restrict bias,\n    float*__restrict gain,\n    float*__restrict spikes)\n{\n  for (int i = 0; i < numNeurons; i++)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n\n    voltage *= mult;\n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\nvoid test (\n    int numNeurons, int neurons_per_item, float dt, \n    float*__restrict encode_result,\n    float*__restrict voltage_array,\n    float*__restrict reftime_array,\n    float tau_rc, float tau_ref,\n    float*__restrict bias,\n    float*__restrict gain,\n    float*__restrict spikes)\n{\n    for (int i = 0; i < numNeurons; i++)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n\n    voltage *= mult;\n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <neurons per item> <num_items> <num_steps>\\n\", argv[0]);\n    return 1;\n  }\n  const int neurons_per_item = atoi(argv[1]);\n  const int num_items = atoi(argv[2]);\n  const int num_steps = atoi(argv[3]);\n\n  const int num_neurons = neurons_per_item * num_items;\n  const size_t neurons_size = num_neurons * sizeof(float);\n  const size_t items_size = num_items * sizeof(float);\n  const size_t neurons_per_item_size = neurons_per_item * sizeof(float);\n\n  float dt = 0.1;    \n\n  float tau_rc = 10; \n\n  float tau_ref = 2; \n\n\n  float* encode_result = (float*) malloc (items_size);\n  float* bias = (float*) malloc (neurons_per_item_size);\n  float* gain = (float*) malloc (neurons_per_item_size);\n\n  \n\n  float* voltage = (float*) malloc (neurons_size);\n  float* reftime = (float*) malloc (neurons_size);\n  float* spikes = (float*) malloc (neurons_size);;\n\n  \n\n  float* voltage_gold = (float*) malloc (neurons_size);\n  float* reftime_gold = (float*) malloc (neurons_size);\n  float* spikes_gold = (float*) malloc (neurons_size);;\n\n  srand(123);\n  for (int i = 0; i < num_items; i++) {\n    encode_result[i] = rand() / (float)RAND_MAX;\n  }\n  for (int i = 0; i < num_neurons; i++) {\n    voltage_gold[i] = voltage[i] = 1.f + rand() / (float)RAND_MAX;\n    reftime_gold[i] = reftime[i] = rand() % 5 / 10.f;\n  }\n  for (int i = 0; i < neurons_per_item; i++) {\n    bias[i] = rand() / (float)RAND_MAX;\n    gain[i] = rand() / (float)RAND_MAX + 0.5f;\n  }\n\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for(int step = 0; step < num_steps; step++) {\n    test(\n        num_neurons, \n        neurons_per_item,\n        dt,\n        encode_result,\n        voltage,\n        reftime, \n        tau_rc,\n        tau_ref, \n        bias,\n        gain, \n        spikes);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto elapsed_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (elapsed_time * 1e-3) / num_steps);\n}\n\n  for(int step = 0; step < num_steps; step++) {\n    reference(num_neurons, \n        neurons_per_item,\n        dt,\n        encode_result,\n        voltage_gold,\n        reftime_gold, \n        tau_rc,\n        tau_ref, \n        bias,\n        gain, \n        spikes_gold);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < num_neurons; i++) {\n    if (fabsf(spikes[i] - spikes_gold[i]) > 1e-3) {\n      printf(\"@%d: %f %f\\n\", i, spikes[i], spikes_gold[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  free(encode_result);\n  free(voltage);\n  free(voltage_gold);\n  free(reftime);\n  free(reftime_gold);\n  free(bias);\n  free(gain);\n  free(spikes);\n  free(spikes_gold);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n"}}
{"kernel_name": "lif", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nvoid reference (\n    int numNeurons, int neurons_per_item, float dt,\n    float*__restrict encode_result,\n    float*__restrict voltage_array,\n    float*__restrict reftime_array,\n    float tau_rc, float tau_ref,\n    float*__restrict bias,\n    float*__restrict gain,\n    float*__restrict spikes)\n{\n  for (int i = 0; i < numNeurons; i++)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -expm1f(-dt / tau_rc) * (current - voltage);\n    voltage = fmaxf(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n\n    voltage *= mult;\n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\nvoid lif (\n    sycl::nd_item<1> &item,\n    int numNeurons, int neurons_per_item, float dt,\n    const float*__restrict encode_result,\n          float*__restrict voltage_array,\n          float*__restrict reftime_array,\n    float tau_rc, float tau_ref,\n    const float*__restrict bias,\n    const float*__restrict gain,\n          float*__restrict spikes)\n{\n  int i = item.get_global_id(0);\n  if( i < numNeurons)\n  {\n    int neuron_index = i % neurons_per_item;\n    int item_index = (int)(i / neurons_per_item);\n\n    float voltage = voltage_array[i];\n    float ref_time = reftime_array[i];\n    float current = bias[neuron_index] + gain[neuron_index] * encode_result[item_index];\n    float dV, spike, mult;\n\n    dV = -sycl::expm1(-dt / tau_rc) * (current - voltage);\n    voltage = sycl::fmax(voltage + dV, 0.f);\n\n    ref_time -= dt;\n\n    mult = ref_time;\n    mult *= -1.f / dt;\n    mult += 1.f;\n\n    mult = mult > 1.f ? 1.f : mult;\n    mult = mult < 0.f ? 0.f : mult;\n\n    voltage *= mult;\n\n    if(voltage > 1.f){\n      spike = 1.f / dt;\n      ref_time = tau_ref + dt * (1.f - (voltage - 1.f) / dV);\n      voltage = 0.f;\n    }else{\n      spike = 0.f;\n    }\n\n    reftime_array[i] = ref_time;\n    voltage_array[i] = voltage;\n    spikes[i] = spike;\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <neurons per item> <num_items> <num_steps>\\n\", argv[0]);\n    return 1;\n  }\n  const int neurons_per_item = atoi(argv[1]);\n  const int num_items = atoi(argv[2]);\n  const int num_steps = atoi(argv[3]);\n\n  const int num_neurons = neurons_per_item * num_items;\n  const size_t neurons_size = num_neurons * sizeof(float);\n  const size_t items_size = num_items * sizeof(float);\n  const size_t neurons_per_item_size = neurons_per_item * sizeof(float);\n\n  float dt = 0.1;    \n\n  float tau_rc = 10; \n\n  float tau_ref = 2; \n\n\n  float* encode_result = (float*) malloc (items_size);\n  float* bias = (float*) malloc (neurons_per_item_size);\n  float* gain = (float*) malloc (neurons_per_item_size);\n\n  \n\n  float* voltage = (float*) malloc (neurons_size);\n  float* reftime = (float*) malloc (neurons_size);\n  float* spikes = (float*) malloc (neurons_size);;\n\n  \n\n  float* voltage_gold = (float*) malloc (neurons_size);\n  float* reftime_gold = (float*) malloc (neurons_size);\n  float* spikes_gold = (float*) malloc (neurons_size);;\n\n  srand(123);\n  for (int i = 0; i < num_items; i++) {\n    encode_result[i] = rand() / (float)RAND_MAX;\n  }\n  for (int i = 0; i < num_neurons; i++) {\n    voltage_gold[i] = voltage[i] = 1.f + rand() / (float)RAND_MAX;\n    reftime_gold[i] = reftime[i] = rand() % 5 / 10.f;\n  }\n  for (int i = 0; i < neurons_per_item; i++) {\n    bias[i] = rand() / (float)RAND_MAX;\n    gain[i] = rand() / (float)RAND_MAX + 0.5f;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_encode_result = sycl::malloc_device<float>(num_items, q);\n  float *d_bias = sycl::malloc_device<float>(neurons_per_item, q);\n  float *d_gain = sycl::malloc_device<float>(neurons_per_item, q);\n  float *d_voltage = sycl::malloc_device<float>(num_neurons, q);\n  float *d_reftime = sycl::malloc_device<float>(num_neurons, q);\n  float *d_spikes = sycl::malloc_device<float>(num_neurons, q);\n\n  q.memcpy(d_encode_result, encode_result, items_size);\n  q.memcpy(d_bias, bias, neurons_per_item_size);\n  q.memcpy(d_gain, gain, neurons_per_item_size);\n  q.memcpy(d_voltage, voltage, neurons_size);\n  q.memcpy(d_reftime, reftime, neurons_size);\n\n  sycl::range<1> lws (256);\n  sycl::range<1> gws ((num_neurons + 255) / 256 * 256);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for(int step = 0; step < num_steps; step++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        lif(item,\n            num_neurons,\n            neurons_per_item,\n            dt,\n            d_encode_result,\n            d_voltage,\n            d_reftime,\n            tau_rc,\n            tau_ref,\n            d_bias,\n            d_gain,\n            d_spikes);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto elapsed_time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (elapsed_time * 1e-3) / num_steps);\n\n  q.memcpy(spikes, d_spikes, neurons_size);\n  q.memcpy(voltage, d_voltage, neurons_size);\n  q.memcpy(reftime, d_reftime, neurons_size);\n  q.wait();\n\n  for(int step = 0; step < num_steps; step++) {\n    reference(num_neurons,\n              neurons_per_item,\n              dt,\n              encode_result,\n              voltage_gold,\n              reftime_gold,\n              tau_rc,\n              tau_ref,\n              bias,\n              gain,\n              spikes_gold);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < num_neurons; i++) {\n    if (fabsf(spikes[i] - spikes_gold[i]) > 1e-3) {\n      printf(\"@%d: %f %f\\n\", i, spikes[i], spikes_gold[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  sycl::free(d_encode_result, q);\n  sycl::free(d_voltage, q);\n  sycl::free(d_reftime, q);\n  sycl::free(d_bias, q);\n  sycl::free(d_gain, q);\n  sycl::free(d_spikes, q);\n\n  free(encode_result);\n  free(voltage);\n  free(voltage_gold);\n  free(reftime);\n  free(reftime_gold);\n  free(bias);\n  free(gain);\n  free(spikes);\n  free(spikes_gold);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n"}}
{"kernel_name": "lrn", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cstdio>\n#include <iostream>\n#include <vector>\n#include <cuda.h>\n#include \"kernels.h\"\n\nusing namespace std::chrono;\n\nvoid Forward(int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 6;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) { \n    src[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *src_mem;\n  size_t bytes_to_copy_s = wk_size * sizeof(float);\n  cudaMalloc((void**)&src_mem, bytes_to_copy_s);\n  cudaMemcpy(src_mem, src.data(), bytes_to_copy_s, cudaMemcpyHostToDevice);\n\n  size_t bytes_to_copy_d = wk_size * sizeof(float);\n  float *dst_mem;\n  cudaMalloc((void**)&dst_mem, bytes_to_copy_d);\n  cudaMemcpy(dst_mem, dst.data(), bytes_to_copy_d, cudaMemcpyHostToDevice);\n\n  printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n  for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n    int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n    cudaDeviceSynchronize();\n    auto start = high_resolution_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      lrn_fwd_kernel<<<wg_cnt, wg_size>>>(\n        src_mem, dst_mem, N, C, D, H, W, stride_mb, ndims, wk_size, size, alpha, beta, k);\n    }\n\n    cudaDeviceSynchronize();\n    auto stop = high_resolution_clock::now();\n\n    auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n    printf(\"Average execution time of lrn_fwd_kernel: %.6f sec \\n\", time / repeat);\n\n    auto data_inGB = (2 * wk_size * sizeof(float)) / 1e9f;\n    auto bandwidth = data_inGB * repeat / time;\n\n    printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n  }\n\n  cudaMemcpy(dst.data(), dst_mem, bytes_to_copy_d, cudaMemcpyDeviceToHost);\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) { \n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n\n  cudaFree(src_mem);\n  cudaFree(dst_mem);\n}\n\n\nvoid Backward(int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 5;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n  std::vector<float> diff_src(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) { \n    diff_src[i] = src[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *src_mem;\n  size_t bytes_to_copy_s = wk_size * sizeof(float);\n  cudaMalloc((void**)&src_mem, bytes_to_copy_s);\n  cudaMemcpy(src_mem, src.data(), bytes_to_copy_s, cudaMemcpyHostToDevice);\n\n  float *diff_src_mem;\n  size_t bytes_to_copy_diff = wk_size * sizeof(float);\n  cudaMalloc((void**)&diff_src_mem, bytes_to_copy_diff);\n  cudaMemcpy(diff_src_mem, diff_src.data(), bytes_to_copy_diff, cudaMemcpyHostToDevice);\n\n  float *dst_mem;\n  size_t bytes_to_copy_d = wk_size * sizeof(float);\n  cudaMalloc((void**)&dst_mem, bytes_to_copy_d);\n  cudaMemcpy(dst_mem, src.data(), bytes_to_copy_d, cudaMemcpyHostToDevice);\n\n  printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n  for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n    int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n    cudaDeviceSynchronize();\n    auto start = high_resolution_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      lrn_bwd_kernel<<<wg_cnt, wg_size>>>(\n        src_mem, dst_mem, diff_src_mem, N, C, D, H, W, stride_mb, ndims, wk_size, size, alpha, beta, k);\n    }\n\n    cudaDeviceSynchronize();\n    auto stop = high_resolution_clock::now();\n\n    auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n    printf(\"Average execution time of lrn_bwd_kernel: %.6f sec \\n\", time / repeat);\n\n    auto data_inGB = (3 * wk_size * sizeof(float)) / 1e9f;\n    auto bandwidth = data_inGB * repeat / time;\n\n    printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n  }\n\n\n  cudaMemcpy(dst.data(), dst_mem, bytes_to_copy_d, cudaMemcpyDeviceToHost);\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) { \n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n  cudaFree(src_mem);\n  cudaFree(diff_src_mem);\n  cudaFree(dst_mem);\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Forward(repeat);\n  Backward(repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "lrn", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cstdio>\n#include <iostream>\n#include <vector>\n#include <hip/hip_runtime.h>\n#include \"kernels.h\"\n\nusing namespace std::chrono;\n\nvoid Forward(int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 6;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) { \n    src[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *src_mem;\n  size_t bytes_to_copy_s = wk_size * sizeof(float);\n  hipMalloc((void**)&src_mem, bytes_to_copy_s);\n  hipMemcpy(src_mem, src.data(), bytes_to_copy_s, hipMemcpyHostToDevice);\n\n  size_t bytes_to_copy_d = wk_size * sizeof(float);\n  float *dst_mem;\n  hipMalloc((void**)&dst_mem, bytes_to_copy_d);\n  hipMemcpy(dst_mem, dst.data(), bytes_to_copy_d, hipMemcpyHostToDevice);\n\n  printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n  for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n    int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n    hipDeviceSynchronize();\n    auto start = high_resolution_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      lrn_fwd_kernel<<<wg_cnt, wg_size>>>(\n        src_mem, dst_mem, N, C, D, H, W, stride_mb, ndims, wk_size, size, alpha, beta, k);\n    }\n\n    hipDeviceSynchronize();\n    auto stop = high_resolution_clock::now();\n\n    auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n    printf(\"Average execution time of lrn_fwd_kernel: %.6f sec \\n\", time / repeat);\n\n    auto data_inGB = (2 * wk_size * sizeof(float)) / 1e9f;\n    auto bandwidth = data_inGB * repeat / time;\n\n    printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n  }\n\n  hipMemcpy(dst.data(), dst_mem, bytes_to_copy_d, hipMemcpyDeviceToHost);\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) { \n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n\n  hipFree(src_mem);\n  hipFree(dst_mem);\n}\n\n\nvoid Backward(int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 5;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n  std::vector<float> diff_src(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) { \n    diff_src[i] = src[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *src_mem;\n  size_t bytes_to_copy_s = wk_size * sizeof(float);\n  hipMalloc((void**)&src_mem, bytes_to_copy_s);\n  hipMemcpy(src_mem, src.data(), bytes_to_copy_s, hipMemcpyHostToDevice);\n\n  float *diff_src_mem;\n  size_t bytes_to_copy_diff = wk_size * sizeof(float);\n  hipMalloc((void**)&diff_src_mem, bytes_to_copy_diff);\n  hipMemcpy(diff_src_mem, diff_src.data(), bytes_to_copy_diff, hipMemcpyHostToDevice);\n\n  float *dst_mem;\n  size_t bytes_to_copy_d = wk_size * sizeof(float);\n  hipMalloc((void**)&dst_mem, bytes_to_copy_d);\n  hipMemcpy(dst_mem, src.data(), bytes_to_copy_d, hipMemcpyHostToDevice);\n\n  printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n  for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n    int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n    hipDeviceSynchronize();\n    auto start = high_resolution_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      lrn_bwd_kernel<<<wg_cnt, wg_size>>>(\n        src_mem, dst_mem, diff_src_mem, N, C, D, H, W, stride_mb, ndims, wk_size, size, alpha, beta, k);\n    }\n\n    hipDeviceSynchronize();\n    auto stop = high_resolution_clock::now();\n\n    auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n    printf(\"Average execution time of lrn_bwd_kernel: %.6f sec \\n\", time / repeat);\n\n    auto data_inGB = (3 * wk_size * sizeof(float)) / 1e9f;\n    auto bandwidth = data_inGB * repeat / time;\n\n    printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n  }\n\n\n  hipMemcpy(dst.data(), dst_mem, bytes_to_copy_d, hipMemcpyDeviceToHost);\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) { \n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n  hipFree(src_mem);\n  hipFree(diff_src_mem);\n  hipFree(dst_mem);\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Forward(repeat);\n  Backward(repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "lrn", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <cstdio>\n#include <iostream>\n#include <vector>\n#include <math.h>\n#include <omp.h>\n#include \"kernels.h\"\n\nusing namespace std::chrono;\n\nvoid Forward(int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 6;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) { \n    src[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *src_mem = src.data();\n  float *dst_mem = dst.data();\n\n  #pragma omp target data map(to: src_mem[0:wk_size]) \\\n                          map(from: dst_mem[0:wk_size])\n  {\n    printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n    for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n      int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n      auto start = high_resolution_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        lrn_fwd_kernel(\n          src_mem, dst_mem, N, C, D, H, W, stride_mb, ndims,\n          wg_cnt, wg_size, wk_size, size, alpha, beta, k);\n      }\n\n      auto stop = high_resolution_clock::now();\n\n      auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n      printf(\"Average execution time of lrn_fwd_kernel: %.6f sec \\n\", time / repeat);\n\n      auto data_inGB = (2 * wk_size * sizeof(float)) / 1e9f;\n      auto bandwidth = data_inGB * repeat / time;\n\n      printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n    }\n  }\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) { \n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n}\n\n\nvoid Backward(int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 5;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n  std::vector<float> diff_src(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) { \n    dst[i] = diff_src[i] = src[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *src_mem = src.data();\n  float *diff_src_mem = diff_src.data();\n  float *dst_mem = dst.data();\n\n  #pragma omp target data map(to: src_mem[0:wk_size], diff_src_mem[0:wk_size]) \\\n                          map(tofrom: dst_mem[0:wk_size])\n  {\n    printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n    for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n      int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n      auto start = high_resolution_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        lrn_bwd_kernel(\n          src_mem, dst_mem, diff_src_mem, N, C, D, H, W, stride_mb, ndims,\n          wg_cnt, wg_size, wk_size, size, alpha, beta, k);\n      }\n\n      auto stop = high_resolution_clock::now();\n\n      auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n      printf(\"Average execution time of lrn_bwd_kernel: %.6f sec \\n\", time / repeat);\n\n      auto data_inGB = (3 * wk_size * sizeof(float)) / 1e9f;\n      auto bandwidth = data_inGB * repeat / time;\n\n      printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n    }\n  }\n\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) { \n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Forward(repeat);\n  Backward(repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "lrn", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <cstdio>\n#include <iostream>\n#include <vector>\n#include <math.h>\n#include \"kernels.h\"\n\nusing namespace std::chrono;\n\nvoid Forward(int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 6;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) { \n    src[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *src_mem = src.data();\n  float *dst_mem = dst.data();\n\n    {\n    printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n    for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n      int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n      auto start = high_resolution_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        lrn_fwd_kernel(\n          src_mem, dst_mem, N, C, D, H, W, stride_mb, ndims,\n          wg_cnt, wg_size, wk_size, size, alpha, beta, k);\n      }\n\n      auto stop = high_resolution_clock::now();\n\n      auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n      printf(\"Average execution time of lrn_fwd_kernel: %.6f sec \\n\", time / repeat);\n\n      auto data_inGB = (2 * wk_size * sizeof(float)) / 1e9f;\n      auto bandwidth = data_inGB * repeat / time;\n\n      printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n    }\n  }\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) { \n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n}\n\n\nvoid Backward(int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 5;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n  std::vector<float> diff_src(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) { \n    dst[i] = diff_src[i] = src[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *src_mem = src.data();\n  float *diff_src_mem = diff_src.data();\n  float *dst_mem = dst.data();\n\n    {\n    printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n    for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n      int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n      auto start = high_resolution_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        lrn_bwd_kernel(\n          src_mem, dst_mem, diff_src_mem, N, C, D, H, W, stride_mb, ndims,\n          wg_cnt, wg_size, wk_size, size, alpha, beta, k);\n      }\n\n      auto stop = high_resolution_clock::now();\n\n      auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n      printf(\"Average execution time of lrn_bwd_kernel: %.6f sec \\n\", time / repeat);\n\n      auto data_inGB = (3 * wk_size * sizeof(float)) / 1e9f;\n      auto bandwidth = data_inGB * repeat / time;\n\n      printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n    }\n  }\n\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) { \n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Forward(repeat);\n  Backward(repeat);\n\n  return 0;\n}"}}
{"kernel_name": "lrn", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cstdio>\n#include <iostream>\n#include <vector>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n\nusing namespace std::chrono;\n\nvoid Forward(sycl::queue &q, int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 6;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) {\n    src[i] = rand() / (float)RAND_MAX;\n  }\n\n  size_t bytes_to_copy_s = wk_size * sizeof(float);\n  float *src_mem = sycl::malloc_device<float>(wk_size, q);\n  q.memcpy(src_mem, src.data(), bytes_to_copy_s);\n\n  size_t bytes_to_copy_d = wk_size * sizeof(float);\n  float *dst_mem = sycl::malloc_device<float>(wk_size, q);\n  q.memcpy(dst_mem, dst.data(), bytes_to_copy_d);\n\n  printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n  for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n    int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n    sycl::range<1> gws (wg_size * wg_cnt);\n    sycl::range<1> lws (wg_size);\n\n    q.wait();\n    auto start = high_resolution_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class fwd>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n          lrn_fwd_kernel(item, src_mem, dst_mem, N, C, D, H, W,\n                         stride_mb, ndims, wk_size, size, alpha, beta, k);\n        });\n      });\n    }\n\n    q.wait();\n    auto stop = high_resolution_clock::now();\n\n    auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n    printf(\"Average execution time of lrn_fwd_kernel: %.6f sec \\n\", time / repeat);\n\n    auto data_inGB = (2 * wk_size * sizeof(float)) / 1e9f;\n    auto bandwidth = data_inGB * repeat / time;\n\n    printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n  }\n\n  q.memcpy(dst.data(), dst_mem, bytes_to_copy_d).wait();\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) {\n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n\n  free(src_mem, q);\n  free(dst_mem, q);\n}\n\nvoid Backward(sycl::queue &q, int repeat)\n{\n  int64_t ndims = 5;\n  int64_t size = 5;\n  float alpha = 0.000122;\n  float beta = 0.750000;\n  float k = 1.000000;\n  int64_t N = 5;\n  int64_t C = 150;\n  int64_t D = 100;\n  int64_t H = 160;\n  int64_t W = 160;\n  int64_t stride_mb = C*D*H*W;\n  int64_t wk_size = N*C*D*H*W;\n\n  std::vector<float> src(wk_size, 0);\n  std::vector<float> dst(wk_size, 0);\n  std::vector<float> diff_src(wk_size, 0);\n\n  srand(123);\n  for (int64_t i = 0; i < wk_size; i++) {\n    diff_src[i] = src[i] = rand() / (float)RAND_MAX;\n  }\n\n  size_t bytes_to_copy_s = wk_size * sizeof(float);\n  float *src_mem = sycl::malloc_device<float>(wk_size, q);\n  q.memcpy(src_mem, src.data(), bytes_to_copy_s);\n\n  size_t bytes_to_copy_diff = wk_size * sizeof(float);\n  float *diff_src_mem = sycl::malloc_device<float>(wk_size, q);\n  q.memcpy(diff_src_mem, diff_src.data(), bytes_to_copy_diff);\n\n  size_t bytes_to_copy_d = wk_size * sizeof(float);\n  float *dst_mem = sycl::malloc_device<float>(wk_size, q);\n  q.memcpy(dst_mem, src.data(), bytes_to_copy_d);\n\n  printf(\"Sweep the work-group sizes from 64 to 512\\n\");\n  for (int wg_size = 64; wg_size <= 512; wg_size = wg_size * 2) {\n\n    int64_t wg_cnt = (wk_size + wg_size - 1) / wg_size;\n\n    sycl::range<1> gws (wg_size * wg_cnt);\n    sycl::range<1> lws (wg_size);\n\n    q.wait();\n    auto start = high_resolution_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class bwd>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n           lrn_bwd_kernel(item, src_mem, dst_mem, diff_src_mem, N, C,\n                          D, H, W, stride_mb, ndims, wk_size,\n                          size, alpha, beta, k);\n         });\n      });\n    }\n\n    q.wait();\n    auto stop = high_resolution_clock::now();\n\n    auto time = (duration_cast<microseconds>(stop - start)).count()/1e6f;\n    printf(\"Average execution time of lrn_bwd_kernel: %.6f sec \\n\", time / repeat);\n\n    auto data_inGB = (3 * wk_size * sizeof(float)) / 1e9f;\n    auto bandwidth = data_inGB * repeat / time;\n\n    printf(\"Kernel bandwidth: %.6f GB/s \\n\", bandwidth);\n  }\n\n  q.memcpy(dst.data(), dst_mem, bytes_to_copy_d).wait();\n  double checksum = 0;\n  for (int64_t i = 0; i < wk_size; i++) {\n    checksum += dst[i];\n  }\n  printf(\"Checksum: %lf\\n\", checksum / wk_size);\n  free(src_mem, q);\n  free(diff_src_mem, q);\n  free(dst_mem, q);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  Forward(q, repeat);\n  Backward(q, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mask", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n#define GPU_THREADS 256\n\n#define KERNEL_LOOP(index, range) \\\n   for (int index = blockIdx.x * blockDim.x + threadIdx.x;  \\\n            index < (range); index += blockDim.x * gridDim.x) \n\ntemplate <typename T>\n__global__ void sequenceMaskKernel(\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* seq_lengths,\n    T fill_val,\n    T* out)\n{\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= seq_lengths[j] ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n      out[index] = (j >= seq_lengths[i] ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void windowMaskKernel(\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* window_centers,\n    const int radius,\n    T fill_val,\n    T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] =\n          (k < window_centers[j] - radius || k > window_centers[j] + radius\n               ? fill_val\n               : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] =\n          (j < window_centers[i] - radius || j > window_centers[i] + radius\n               ? fill_val\n               : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void\nupperMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k > j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j > i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void\nlowerMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k < j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j < i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void\nupperDiagMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j >= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void\nlowerDiagMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k <= j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j <= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate<typename T>\nvoid print_mask_ratio (T *h_out, T *d_out, T fill_val, int data_size) {\n  T* out = (T*) malloc (data_size * sizeof(T));\n  cudaMemcpy(out, d_out, data_size * sizeof(T), cudaMemcpyDeviceToHost);\n  int error = memcmp(h_out, out, data_size * sizeof(T));\n  int cnt_fill = 0;\n  for (int i = 0; i < data_size; i++) {\n    if (h_out[i] == fill_val) cnt_fill++;\n  }\n  printf(\"%s, Mask ratio: %f\\n\", (error ? \"FAIL\" : \"PASS\"),\n                                 (float) cnt_fill / data_size);\n  free(out);\n}\n\ntemplate<typename T>\nvoid eval_mask (const int M, const int N, const int B, const int repeat) {\n\n  const T fill_val = -1;\n  const int radius = M / 4;  \n\n\n  int batch_dim = (B <= 0) ? 1 : B;\n\n  printf(\"\\nM = %d, N = %d, B = %d\\n\", M, N, batch_dim);\n\n  int data_size = N * M * batch_dim;\n  size_t data_size_in_bytes = data_size * sizeof(T); \n\n  int window_size = N;\n  size_t window_size_in_bytes = N * sizeof(int);\n\n  int seq_len = N;\n  size_t seq_len_in_bytes = seq_len * sizeof(int); \n\n  T *h_in = (T*) malloc (data_size_in_bytes);\n  T *h_out = (T*) malloc (data_size_in_bytes);\n  int *h_seq_len = (int*) malloc (seq_len_in_bytes);\n  int *h_window = (int*) malloc (window_size_in_bytes);\n\n  srand(123);\n  for (int i = 0; i < seq_len; i++) {\n    h_seq_len[i] = rand() % (M / 2); \n\n  }\n  for (int i = 0; i < window_size; i++) {\n    h_window[i] = rand() % M;\n  }\n  for (int i = 0; i < data_size; i++) {\n    h_in[i] = rand() % (M * N);\n  }\n  \n  T *d_in, *d_out;\n  int *d_seq_len, *d_window;\n  cudaMalloc((void**)&d_in, data_size_in_bytes);\n  cudaMalloc((void**)&d_out, data_size_in_bytes);\n  cudaMalloc((void**)&d_window, window_size_in_bytes);\n  cudaMalloc((void**)&d_seq_len, seq_len_in_bytes);\n\n  cudaMemcpy(d_in, h_in, data_size_in_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_seq_len, h_seq_len, seq_len_in_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_window, h_window, window_size_in_bytes, cudaMemcpyHostToDevice);\n\n  int nblocks = (B <= 0) ? (N * M / GPU_THREADS) : (N * M);\n  dim3 grid (nblocks);\n  dim3 block (GPU_THREADS);\n\n  sequenceMaskKernel_cpu(N, M, batch_dim, h_in, h_seq_len, fill_val, h_out);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    sequenceMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, d_seq_len, fill_val, d_out);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of sequenceMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n \n  windowMaskKernel_cpu(N, M, batch_dim, h_in, h_window, radius, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    windowMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, d_window, radius, fill_val, d_out);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of windowMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  upperMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    upperMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, fill_val, d_out);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of upperMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  lowerMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    lowerMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, fill_val, d_out);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of lowerMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  upperDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    upperDiagMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, fill_val, d_out);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of upperDiagMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  lowerDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    lowerDiagMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, fill_val, d_out);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of lowerDiagMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  cudaFree(d_in);\n  cudaFree(d_out);\n  cudaFree(d_window);\n  cudaFree(d_seq_len);\n\n  free(h_in);\n  free(h_out);\n  free(h_window);\n  free(h_seq_len);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <sequence length> <sequence length> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int B = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  eval_mask<int>(M, N, B, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mask", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n#define GPU_THREADS 256\n\n#define KERNEL_LOOP(index, range) \\\n   for (int index = blockIdx.x * blockDim.x + threadIdx.x;  \\\n            index < (range); index += blockDim.x * gridDim.x) \n\ntemplate <typename T>\n__global__ void sequenceMaskKernel(\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* seq_lengths,\n    T fill_val,\n    T* out)\n{\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= seq_lengths[j] ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n      out[index] = (j >= seq_lengths[i] ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void windowMaskKernel(\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* window_centers,\n    const int radius,\n    T fill_val,\n    T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] =\n          (k < window_centers[j] - radius || k > window_centers[j] + radius\n               ? fill_val\n               : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] =\n          (j < window_centers[i] - radius || j > window_centers[i] + radius\n               ? fill_val\n               : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void\nupperMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k > j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j > i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void\nlowerMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k < j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j < i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void\nupperDiagMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j >= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\n__global__ void\nlowerDiagMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k <= j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j <= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate<typename T>\nvoid print_mask_ratio (T *h_out, T *d_out, T fill_val, int data_size) {\n  T* out = (T*) malloc (data_size * sizeof(T));\n  hipMemcpy(out, d_out, data_size * sizeof(T), hipMemcpyDeviceToHost);\n  int error = memcmp(h_out, out, data_size * sizeof(T));\n  int cnt_fill = 0;\n  for (int i = 0; i < data_size; i++) {\n    if (h_out[i] == fill_val) cnt_fill++;\n  }\n  printf(\"%s, Mask ratio: %f\\n\", (error ? \"FAIL\" : \"PASS\"),\n                                 (float) cnt_fill / data_size);\n  free(out);\n}\n\ntemplate<typename T>\nvoid eval_mask (const int M, const int N, const int B, const int repeat) {\n\n  const T fill_val = -1;\n  const int radius = M / 4;  \n\n\n  int batch_dim = (B <= 0) ? 1 : B;\n\n  printf(\"\\nM = %d, N = %d, B = %d\\n\", M, N, batch_dim);\n\n  int data_size = N * M * batch_dim;\n  size_t data_size_in_bytes = data_size * sizeof(T); \n\n  int window_size = N;\n  size_t window_size_in_bytes = N * sizeof(int);\n\n  int seq_len = N;\n  size_t seq_len_in_bytes = seq_len * sizeof(int); \n\n  T *h_in = (T*) malloc (data_size_in_bytes);\n  T *h_out = (T*) malloc (data_size_in_bytes);\n  int *h_seq_len = (int*) malloc (seq_len_in_bytes);\n  int *h_window = (int*) malloc (window_size_in_bytes);\n\n  srand(123);\n  for (int i = 0; i < seq_len; i++) {\n    h_seq_len[i] = rand() % (M / 2); \n\n  }\n  for (int i = 0; i < window_size; i++) {\n    h_window[i] = rand() % M;\n  }\n  for (int i = 0; i < data_size; i++) {\n    h_in[i] = rand() % (M * N);\n  }\n  \n  T *d_in, *d_out;\n  int *d_seq_len, *d_window;\n  hipMalloc((void**)&d_in, data_size_in_bytes);\n  hipMalloc((void**)&d_out, data_size_in_bytes);\n  hipMalloc((void**)&d_window, window_size_in_bytes);\n  hipMalloc((void**)&d_seq_len, seq_len_in_bytes);\n\n  hipMemcpy(d_in, h_in, data_size_in_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_seq_len, h_seq_len, seq_len_in_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_window, h_window, window_size_in_bytes, hipMemcpyHostToDevice);\n\n  int nblocks = (B <= 0) ? (N * M / GPU_THREADS) : (N * M);\n  dim3 grid (nblocks);\n  dim3 block (GPU_THREADS);\n\n  sequenceMaskKernel_cpu(N, M, batch_dim, h_in, h_seq_len, fill_val, h_out);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    sequenceMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, d_seq_len, fill_val, d_out);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of sequenceMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n \n  windowMaskKernel_cpu(N, M, batch_dim, h_in, h_window, radius, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    windowMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, d_window, radius, fill_val, d_out);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of windowMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  upperMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    upperMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, fill_val, d_out);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of upperMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  lowerMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    lowerMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, fill_val, d_out);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of lowerMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  upperDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    upperDiagMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, fill_val, d_out);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of upperDiagMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  lowerDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    lowerDiagMaskKernel<<<grid, block>>>(\n      N, M, batch_dim, d_in, fill_val, d_out);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of lowerDiagMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(h_out, d_out, fill_val, data_size);\n\n  hipFree(d_in);\n  hipFree(d_out);\n  hipFree(d_window);\n  hipFree(d_seq_len);\n\n  free(h_in);\n  free(h_out);\n  free(h_window);\n  free(h_seq_len);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <sequence length> <sequence length> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int B = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  eval_mask<int>(M, N, B, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mask", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\n#define GPU_THREADS 256\n\n#define KERNEL_LOOP(index, range) \\\n   for (int index = 0; index < (range); index++)\n\ntemplate <typename T>\nvoid sequenceMaskKernel(\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* seq_lengths,\n    T fill_val,\n    T* out)\n{\n  if (B >= 0) {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= seq_lengths[j] ? fill_val : in[ind]);\n    }\n  } else {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N/GPU_THREADS) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n      out[index] = (j >= seq_lengths[i] ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid windowMaskKernel(\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* window_centers,\n    const int radius,\n    T fill_val,\n    T* out) {\n  if (B >= 0) {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] =\n          (k < window_centers[j] - radius || k > window_centers[j] + radius\n               ? fill_val\n               : in[ind]);\n    }\n  } else {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N/GPU_THREADS) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] =\n          (j < window_centers[i] - radius || j > window_centers[i] + radius\n               ? fill_val\n               : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid\nupperMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k > j ? fill_val : in[ind]);\n    }\n  } else {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N/GPU_THREADS) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j > i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid\nlowerMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k < j ? fill_val : in[ind]);\n    }\n  } else {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N/GPU_THREADS) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j < i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid\nupperDiagMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= j ? fill_val : in[ind]);\n    }\n  } else {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N/GPU_THREADS) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j >= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid\nlowerDiagMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k <= j ? fill_val : in[ind]);\n    }\n  } else {\n    #pragma omp target teams distribute parallel for \\\n    num_teams(M*N/GPU_THREADS) num_threads(GPU_THREADS)\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j <= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate<typename T>\nvoid print_mask_ratio (T *h_out, T *out_ref, T fill_val, int data_size) {\n  #pragma omp target update from (h_out[0:data_size])\n  int error = memcmp(h_out, out_ref, data_size * sizeof(T));\n  int cnt_fill = 0;\n  for (int i = 0; i < data_size; i++) {\n    if (h_out[i] == fill_val) cnt_fill++;\n  }\n  printf(\"%s, Mask ratio: %f\\n\", (error ? \"FAIL\" : \"PASS\"),\n                                 (float) cnt_fill / data_size);\n}\n\ntemplate<typename T>\nvoid eval_mask (const int M, const int N, const int B, const int repeat) {\n\n  const T fill_val = -1;\n  const int radius = M / 4;  \n\n\n  int batch_dim = (B <= 0) ? 1 : B;\n\n  printf(\"\\nM = %d, N = %d, B = %d\\n\", M, N, batch_dim);\n\n  int data_size = N * M * batch_dim;\n  size_t data_size_in_bytes = data_size * sizeof(T); \n\n  int window_size = N;\n  size_t window_size_in_bytes = N * sizeof(int);\n\n  int seq_len = N;\n  size_t seq_len_in_bytes = seq_len * sizeof(int); \n\n  T *h_in = (T*) malloc (data_size_in_bytes);\n  T *h_out = (T*) malloc (data_size_in_bytes);\n  T *out_ref = (T*) malloc (data_size_in_bytes);\n  int *h_seq_len = (int*) malloc (seq_len_in_bytes);\n  int *h_window = (int*) malloc (window_size_in_bytes);\n\n  srand(123);\n  for (int i = 0; i < seq_len; i++) {\n    h_seq_len[i] = rand() % (M / 2); \n\n  }\n  for (int i = 0; i < window_size; i++) {\n    h_window[i] = rand() % M;\n  }\n  for (int i = 0; i < data_size; i++) {\n    h_in[i] = rand() % (M * N);\n  }\n  \n  #pragma omp target data map (to: h_in[0:data_size], \\\n                                   h_seq_len[0:seq_len], \\\n                                   h_window[0:window_size]) \\\n                          map (alloc: h_out[0:data_size])\n  {\n    sequenceMaskKernel_cpu(N, M, batch_dim, h_in, h_seq_len, fill_val, out_ref);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      sequenceMaskKernel(\n        N, M, batch_dim, h_in, h_seq_len, fill_val, h_out);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of sequenceMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    windowMaskKernel_cpu(N, M, batch_dim, h_in, h_window, radius, fill_val, out_ref);\n \n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      windowMaskKernel(\n        N, M, batch_dim, h_in, h_window, radius, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of windowMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    upperMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, out_ref);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      upperMaskKernel(\n        N, M, batch_dim, h_in, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of upperMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    lowerMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, out_ref);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      lowerMaskKernel(\n        N, M, batch_dim, h_in, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of lowerMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    upperDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, out_ref);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      upperDiagMaskKernel(\n        N, M, batch_dim, h_in, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of upperDiagMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    lowerDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, out_ref);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      lowerDiagMaskKernel(N, M, batch_dim, h_in, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of lowerDiagMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n  }\n\n  free(h_in);\n  free(h_out);\n  free(out_ref);\n  free(h_window);\n  free(h_seq_len);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <sequence length> <sequence length> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int B = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  eval_mask<int>(M, N, B, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mask", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include \"reference.h\"\n\n#define GPU_THREADS 256\n\n#define KERNEL_LOOP(index, range) \\\n   for (int index = 0; index < (range); index++)\n\ntemplate <typename T>\nvoid sequenceMaskKernel(\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* seq_lengths,\n    T fill_val,\n    T* out)\n{\n  if (B >= 0) {\n        KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= seq_lengths[j] ? fill_val : in[ind]);\n    }\n  } else {\n        KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n      out[index] = (j >= seq_lengths[i] ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid windowMaskKernel(\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* window_centers,\n    const int radius,\n    T fill_val,\n    T* out) {\n  if (B >= 0) {\n        KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] =\n          (k < window_centers[j] - radius || k > window_centers[j] + radius\n               ? fill_val\n               : in[ind]);\n    }\n  } else {\n        KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] =\n          (j < window_centers[i] - radius || j > window_centers[i] + radius\n               ? fill_val\n               : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid\nupperMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n        KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k > j ? fill_val : in[ind]);\n    }\n  } else {\n        KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j > i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid\nlowerMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n        KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k < j ? fill_val : in[ind]);\n    }\n  } else {\n        KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j < i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid\nupperDiagMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n        KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= j ? fill_val : in[ind]);\n    }\n  } else {\n        KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j >= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid\nlowerDiagMaskKernel(int N, int M, int B, const T* in, T fill_val, T* out) {\n  if (B >= 0) {\n        KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k <= j ? fill_val : in[ind]);\n    }\n  } else {\n        KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j <= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate<typename T>\nvoid print_mask_ratio (T *h_out, T *out_ref, T fill_val, int data_size) {\n    int error = memcmp(h_out, out_ref, data_size * sizeof(T));\n  int cnt_fill = 0;\n  for (int i = 0; i < data_size; i++) {\n    if (h_out[i] == fill_val) cnt_fill++;\n  }\n  printf(\"%s, Mask ratio: %f\\n\", (error ? \"FAIL\" : \"PASS\"),\n                                 (float) cnt_fill / data_size);\n}\n\ntemplate<typename T>\nvoid eval_mask (const int M, const int N, const int B, const int repeat) {\n\n  const T fill_val = -1;\n  const int radius = M / 4;  \n\n\n  int batch_dim = (B <= 0) ? 1 : B;\n\n  printf(\"\\nM = %d, N = %d, B = %d\\n\", M, N, batch_dim);\n\n  int data_size = N * M * batch_dim;\n  size_t data_size_in_bytes = data_size * sizeof(T); \n\n  int window_size = N;\n  size_t window_size_in_bytes = N * sizeof(int);\n\n  int seq_len = N;\n  size_t seq_len_in_bytes = seq_len * sizeof(int); \n\n  T *h_in = (T*) malloc (data_size_in_bytes);\n  T *h_out = (T*) malloc (data_size_in_bytes);\n  T *out_ref = (T*) malloc (data_size_in_bytes);\n  int *h_seq_len = (int*) malloc (seq_len_in_bytes);\n  int *h_window = (int*) malloc (window_size_in_bytes);\n\n  srand(123);\n  for (int i = 0; i < seq_len; i++) {\n    h_seq_len[i] = rand() % (M / 2); \n\n  }\n  for (int i = 0; i < window_size; i++) {\n    h_window[i] = rand() % M;\n  }\n  for (int i = 0; i < data_size; i++) {\n    h_in[i] = rand() % (M * N);\n  }\n  \n    {\n    sequenceMaskKernel_cpu(N, M, batch_dim, h_in, h_seq_len, fill_val, out_ref);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      sequenceMaskKernel(\n        N, M, batch_dim, h_in, h_seq_len, fill_val, h_out);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of sequenceMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    windowMaskKernel_cpu(N, M, batch_dim, h_in, h_window, radius, fill_val, out_ref);\n \n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      windowMaskKernel(\n        N, M, batch_dim, h_in, h_window, radius, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of windowMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    upperMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, out_ref);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      upperMaskKernel(\n        N, M, batch_dim, h_in, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of upperMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    lowerMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, out_ref);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      lowerMaskKernel(\n        N, M, batch_dim, h_in, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of lowerMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    upperDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, out_ref);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      upperDiagMaskKernel(\n        N, M, batch_dim, h_in, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of upperDiagMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n\n    lowerDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, out_ref);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      lowerDiagMaskKernel(N, M, batch_dim, h_in, fill_val, h_out);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of lowerDiagMask kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    print_mask_ratio(h_out, out_ref, fill_val, data_size);\n  }\n\n  free(h_in);\n  free(h_out);\n  free(out_ref);\n  free(h_window);\n  free(h_seq_len);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <sequence length> <sequence length> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int B = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  eval_mask<int>(M, N, B, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "mask", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n#define GPU_THREADS 256\n\n#define KERNEL_LOOP(index, range) \\\n  for (int index = item.get_global_id(0);  \\\n           index < (range); \\\n           index += item.get_local_range(0) * item.get_group_range(0))\n\ntemplate <typename T>\nvoid sequenceMaskKernel(\n    sycl::nd_item<1> &item,\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* seq_lengths,\n    T fill_val,\n    T* out)\n{\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= seq_lengths[j] ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n      out[index] = (j >= seq_lengths[i] ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid windowMaskKernel(\n    sycl::nd_item<1> &item,\n    int N,\n    int M,\n    int B,\n    const T* in,\n    const int* window_centers,\n    const int radius,\n    T fill_val,\n    T* out) {\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] =\n          (k < window_centers[j] - radius || k > window_centers[j] + radius\n               ? fill_val\n               : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] =\n          (j < window_centers[i] - radius || j > window_centers[i] + radius\n               ? fill_val\n               : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid upperMaskKernel(sycl::nd_item<1> &item, int N, int M, int B,\n                     const T* in, T fill_val, T* out)\n{\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k > j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j > i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid lowerMaskKernel(sycl::nd_item<1> &item, int N, int M, int B,\n                     const T* in, T fill_val, T* out)\n{\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k < j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j < i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid upperDiagMaskKernel(sycl::nd_item<1> &item, int N, int M, int B,\n                         const T* in, T fill_val, T* out)\n{\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k >= j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j >= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid lowerDiagMaskKernel(sycl::nd_item<1> &item, int N, int M, int B,\n                         const T* in, T fill_val, T* out)\n{\n  if (B >= 0) {\n    KERNEL_LOOP(index, B * N * M) {\n      int k = index % M;\n      int j = (index - k) / M % N;\n      int i = (index - M * j - k) / (N * M);\n\n      int ind = N * M * i + M * j + k;\n      out[ind] = (k <= j ? fill_val : in[ind]);\n    }\n  } else {\n    KERNEL_LOOP(index, N * M) {\n      int i = index / M;\n      int j = index % M;\n\n      out[index] = (j <= i ? fill_val : in[index]);\n    }\n  }\n}\n\ntemplate<typename T>\nvoid print_mask_ratio (sycl::queue &q, T *h_out, T *d_out, T fill_val, int data_size) {\n  T* out = (T*) malloc (data_size * sizeof(T));\n  q.memcpy(out, d_out, data_size * sizeof(T));\n  int error = memcmp(h_out, out, data_size * sizeof(T));\n  int cnt_fill = 0;\n  for (int i = 0; i < data_size; i++) {\n    if (h_out[i] == fill_val) cnt_fill++;\n  }\n  printf(\"%s, Mask ratio: %f\\n\", (error ? \"FAIL\" : \"PASS\"),\n                                 (float) cnt_fill / data_size);\n}\n\ntemplate<typename T>\nvoid eval_mask (const int M, const int N, const int B, const int repeat) {\n\n  const T fill_val = -1;\n  const int radius = M / 4;  \n\n\n  int batch_dim = (B <= 0) ? 1 : B;\n\n  printf(\"\\nM = %d, N = %d, B = %d\\n\", M, N, batch_dim);\n\n  int data_size = N * M * batch_dim;\n  size_t data_size_in_bytes = data_size * sizeof(T);\n\n  int window_size = N;\n  size_t window_size_in_bytes = N * sizeof(int);\n\n  int seq_len = N;\n  size_t seq_len_in_bytes = seq_len * sizeof(int);\n\n  T *h_in = (T*) malloc (data_size_in_bytes);\n  T *h_out = (T*) malloc (data_size_in_bytes);\n  int *h_seq_len = (int*) malloc (seq_len_in_bytes);\n  int *h_window = (int*) malloc (window_size_in_bytes);\n\n  srand(123);\n  for (int i = 0; i < seq_len; i++) {\n    h_seq_len[i] = rand() % (M / 2); \n\n  }\n  for (int i = 0; i < window_size; i++) {\n    h_window[i] = rand() % M;\n  }\n  for (int i = 0; i < data_size; i++) {\n    h_in[i] = rand() % (M * N);\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  T *d_in, *d_out;\n  int *d_seq_len, *d_window;\n  d_in = sycl::malloc_device<T>(data_size, q);\n  d_out = sycl::malloc_device<T>(data_size, q);\n  d_window = sycl::malloc_device<int>(window_size, q);\n  d_seq_len = sycl::malloc_device<int>(seq_len, q);\n\n  q.memcpy(d_in, h_in, data_size_in_bytes);\n  q.memcpy(d_seq_len, h_seq_len, seq_len_in_bytes);\n  q.memcpy(d_window, h_window, window_size_in_bytes);\n\n  int nblocks = (B <= 0) ? (N * M / GPU_THREADS) : (N * M);\n  sycl::range<1> gws (nblocks * GPU_THREADS);\n  sycl::range<1> lws (GPU_THREADS);\n\n  sequenceMaskKernel_cpu(N, M, batch_dim, h_in, h_seq_len, fill_val, h_out);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class sequence>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        sequenceMaskKernel(item, N, M, batch_dim, d_in, d_seq_len, fill_val, d_out);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of sequenceMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(q, h_out, d_out, fill_val, data_size);\n\n  windowMaskKernel_cpu(N, M, batch_dim, h_in, h_window, radius, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class window>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        windowMaskKernel(item, N, M, batch_dim, d_in, d_window,\n                         radius, fill_val, d_out);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of windowMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(q, h_out, d_out, fill_val, data_size);\n\n  upperMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class upper>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        upperMaskKernel(item, N, M, batch_dim, d_in, fill_val, d_out);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of upperMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(q, h_out, d_out, fill_val, data_size);\n\n  lowerMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class lower>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        lowerMaskKernel(item, N, M, batch_dim, d_in, fill_val, d_out);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of lowerMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(q, h_out, d_out, fill_val, data_size);\n\n  upperDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class upperDiag>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        upperDiagMaskKernel(item, N, M, batch_dim, d_in, fill_val, d_out);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of upperDiagMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(q, h_out, d_out, fill_val, data_size);\n\n  lowerDiagMaskKernel_cpu(N, M, batch_dim, h_in, fill_val, h_out);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class lowerDiag>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        lowerDiagMaskKernel(item, N, M, batch_dim, d_in, fill_val, d_out);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of lowerDiagMask kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  print_mask_ratio(q, h_out, d_out, fill_val, data_size);\n\n  sycl::free(d_in, q);\n  sycl::free(d_out, q);\n  sycl::free(d_window, q);\n  sycl::free(d_seq_len, q);\n\n  free(h_in);\n  free(h_out);\n  free(h_window);\n  free(h_seq_len);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <sequence length> <sequence length> <batch size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int M = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n  const int B = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  eval_mask<int>(M, N, B, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "matern", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n\n\n\n\n\n\n\n\n\n\n__global__ void matern_kernel (\n  const int num_targets,\n  const float l,\n  const float *__restrict__ sources,\n  const float *__restrict__ targets,\n  const float *__restrict__ weights,\n        float *__restrict__ result)\n{\n  int tx = threadIdx.x;\n  int px = blockIdx.x * blockDim.x + tx; \n\n  if (px >= num_targets) return;\n\n  int ty = threadIdx.y;\n  int py = ty; \n\n  if (py >= SY) return;\n\n  __shared__ float local_result[SX * SY];\n  __shared__ float local_targets[SX * 3];\n  __shared__ float local_sources[SY * 3];\n  __shared__ float local_weights[SY];\n\n  if (ty == 0) {\n    for (int i = 0; i < 3; i++)\n      local_targets[tx * 3 + i] = targets[px * 3 + i];\n  }\n\n  if (tx == 0) {\n    for (int i = 0; i < 3; i++)\n      local_sources[ty * 3 + i] = sources[py * 3 + i];\n    local_weights[ty] = weights[ty];\n  }\n\n  __syncthreads();\n\n  float squared_diff = 0.f;\n  \n  for (int i = 0; i < 3; i++) {\n    squared_diff += (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]) *\n                    (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]);\n  } \n  float diff = sqrtf(squared_diff);\n\n  local_result[tx * SY + ty] = \n    (1.f + sqrtf(5.f) * diff / l + 5.f * squared_diff / (3.f * l * l)) *  \n    expf(-sqrtf(5.f) * diff  / l) * local_weights[ty];\n   \n  __syncthreads();\n\n  if (ty == 0) {\n    float res = 0.f;\n    for (int i = 0; i < SY; i++)\n      res += local_result[tx * SY + i];\n    result[px] = res;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int npoints = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int source_size = nsources * 3;  \n\n  const int source_size_byte = source_size * sizeof(float);\n\n  const int weight_size = nsources;\n  const int weight_size_byte = weight_size * sizeof(float);\n\n  const int ntargets = npoints * npoints * npoints;\n  const int target_size = ntargets * 3;\n  const int target_size_byte = target_size * sizeof(float);\n\n  const int result_size_byte = ntargets * sizeof(float);\n\n  float *sources = (float*) malloc (source_size_byte);\n  float *targets = (float*) malloc (target_size_byte);\n  float *weights = (float*) malloc (weight_size_byte);\n  float *result = (float*) malloc (result_size_byte);\n  float *result_ref = (float*) malloc (result_size_byte);\n\n  srand(123);\n  for (int i = 0; i < source_size; i++)\n    sources[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < weight_size; i++)\n    weights[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < target_size; i++) \n    targets[i] = rand() / (float)RAND_MAX;\n\n  const int nblocks = (ntargets + SX - 1) / SX;\n  dim3 grids (nblocks, 1);\n  dim3 blocks (SX, 64);\n\n  float *d_sources;\n  cudaMalloc((void**)&d_sources, source_size_byte); \n\n  float *d_weights;\n  cudaMalloc((void**)&d_weights, weight_size_byte); \n\n  float *d_targets;\n  cudaMalloc((void**)&d_targets, target_size_byte);\n\n  float *d_result;\n  cudaMalloc((void**)&d_result, result_size_byte);\n\n  cudaMemcpy(d_sources, sources, source_size_byte, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_weights, weights, weight_size_byte, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_targets, targets, target_size_byte, cudaMemcpyHostToDevice);\n\n  float l = 0.1f; \n\n\n  \n\n  const int ntargets_small = 16*16*16;\n  printf(\"------------------------------------------------------------\\n\");\n  printf(\"Verifying the kernel results with the problem size (16 cube)\\n\");\n  printf(\"------------------------------------------------------------\\n\");\n\n  while (l <= 1e5f) {\n    matern_kernel<<<grids, blocks>>>(ntargets_small, l, d_sources, d_targets, d_weights, d_result);\n    matern_kernel_reference(nsources, ntargets_small, l, sources, targets, weights, result_ref);\n    cudaMemcpy(result, d_result, ntargets_small * sizeof(float), cudaMemcpyDeviceToHost);\n    bool ok = true;\n    for (int i = 0; i < ntargets_small; i++) {\n      if (fabsf(result[i] - result_ref[i]) > 1e-3f) {\n        printf(\"@%d actual=%f expected=%f\\n\", i, result[i] , result_ref[i]);\n        ok = false;\n        break;\n      }\n    }\n    printf(\"Length scale = %.1e check = %s\\n\", l, ok ? \"PASS\" : \"FAIL\");\n    l = l * 10.f;\n  }\n\n  printf(\"--------------------------------------------------------------------\\n\");\n  printf(\"Timing the kernel execution with the problem size (%d cube)\\n\", npoints);\n  printf(\"--------------------------------------------------------------------\\n\");\n\n  l = 0.1f;\n  while (l <= 1e5f) {\n    printf(\"Warmup..\\n\");\n    for (int i = 0; i < repeat; i++) {\n      matern_kernel<<<grids, blocks>>>(ntargets, l, d_sources, d_targets, d_weights, d_result);\n    }\n    cudaDeviceSynchronize();\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      matern_kernel<<<grids, blocks>>>(ntargets, l, d_sources, d_targets, d_weights, d_result);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Length scale = %.1e \", l);\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    l = l * 10.f;\n  }\n\n  cudaFree(d_sources);\n  cudaFree(d_weights);\n  cudaFree(d_targets);\n  cudaFree(d_result);\n\n  free(sources);\n  free(weights);\n  free(targets);\n  free(result);\n  free(result_ref);\n  return 0;\n}\n"}}
{"kernel_name": "matern", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n\n\n\n\n\n\n\n\n\n\n__global__ void matern_kernel (\n  const int num_targets,\n  const float l,\n  const float *__restrict__ sources,\n  const float *__restrict__ targets,\n  const float *__restrict__ weights,\n        float *__restrict__ result)\n{\n  int tx = threadIdx.x;\n  int px = blockIdx.x * blockDim.x + tx; \n\n  if (px >= num_targets) return;\n\n  int ty = threadIdx.y;  \n\n  int py = ty; \n\n  if (py >= SY) return;\n\n  __shared__ float local_result[SX * SY];\n  __shared__ float local_targets[SX * 3];\n  __shared__ float local_sources[SY * 3];\n  __shared__ float local_weights[SY];\n\n  if (ty == 0) {\n    for (int i = 0; i < 3; i++)\n      local_targets[tx * 3 + i] = targets[px * 3 + i];\n  }\n\n  if (tx == 0) {\n    for (int i = 0; i < 3; i++)\n      local_sources[ty * 3 + i] = sources[py * 3 + i];\n    local_weights[ty] = weights[ty];\n  }\n\n  __syncthreads();\n\n  float squared_diff = 0.f;\n  \n  for (int i = 0; i < 3; i++) {\n    squared_diff += (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]) *\n                    (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]);\n  } \n  float diff = sqrtf(squared_diff);\n\n  local_result[tx * SY + ty] = \n    (1.f + sqrtf(5.f) * diff / l + 5.f * squared_diff / (3.f * l * l)) *  \n    expf(-sqrtf(5.f) * diff / l) * local_weights[ty];\n   \n  __syncthreads();\n\n  if (ty == 0) {\n    float res = 0.f;\n    for (int i = 0; i < SY; i++)\n      res += local_result[tx * SY + i];\n    result[px] = res;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int npoints = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int source_size = nsources * 3;  \n\n  const int source_size_byte = source_size * sizeof(float);\n\n  const int weight_size = nsources;\n  const int weight_size_byte = weight_size * sizeof(float);\n\n  const int ntargets = npoints * npoints * npoints;\n  const int target_size = ntargets * 3;\n  const int target_size_byte = target_size * sizeof(float);\n\n  const int result_size_byte = ntargets * sizeof(float);\n\n  float *sources = (float*) malloc (source_size_byte);\n  float *targets = (float*) malloc (target_size_byte);\n  float *weights = (float*) malloc (weight_size_byte);\n  float *result = (float*) malloc (result_size_byte);\n  float *result_ref = (float*) malloc (result_size_byte);\n\n  srand(123);\n\n  for (int i = 0; i < source_size; i++)\n    sources[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < weight_size; i++)\n    weights[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < target_size; i++)\n    targets[i] = rand() / (float)RAND_MAX;\n\n  const int nblocks = (ntargets + SX - 1) / SX;\n  dim3 grids (nblocks, 1);\n  dim3 blocks (SX, 64);\n\n  float *d_sources;\n  hipMalloc((void**)&d_sources, source_size_byte); \n\n  float *d_weights;\n  hipMalloc((void**)&d_weights, weight_size_byte); \n\n  float *d_targets;\n  hipMalloc((void**)&d_targets, target_size_byte);\n\n  float *d_result;\n  hipMalloc((void**)&d_result, result_size_byte);\n\n  hipMemcpy(d_sources, sources, source_size_byte, hipMemcpyHostToDevice);\n  hipMemcpy(d_weights, weights, weight_size_byte, hipMemcpyHostToDevice);\n  hipMemcpy(d_targets, targets, target_size_byte, hipMemcpyHostToDevice);\n\n  float l = 0.1f; \n\n\n  \n\n  const int ntargets_small = 16*16*16;\n  printf(\"------------------------------------------------------------\\n\");\n  printf(\"Verifying the kernel results with the problem size (16 cube)\\n\");\n  printf(\"------------------------------------------------------------\\n\");\n\n  while (l <= 1e5f) {\n    hipLaunchKernelGGL(matern_kernel, grids, blocks, 0, 0, ntargets_small, l, d_sources, d_targets, d_weights, d_result);\n    matern_kernel_reference(nsources, ntargets_small, l, sources, targets, weights, result_ref);\n    hipMemcpy(result, d_result, ntargets_small * sizeof(float), hipMemcpyDeviceToHost);\n    bool ok = true;\n    for (int i = 0; i < ntargets_small; i++) {\n      if (fabsf(result[i] - result_ref[i]) > 1e-3f) {\n        printf(\"@%d actual=%f expected=%f\\n\", i, result[i] , result_ref[i]);\n        ok = false;\n        break;\n      }\n    }\n    printf(\"Length scale = %.1e check = %s\\n\", l, ok ? \"PASS\" : \"FAIL\");\n    l = l * 10.f;\n  }\n\n  printf(\"--------------------------------------------------------------------\\n\");\n  printf(\"Timing the kernel execution with the problem size (%d cube)\\n\", npoints);\n  printf(\"--------------------------------------------------------------------\\n\");\n\n  l = 0.1f;\n  while (l <= 1e5f) {\n    printf(\"Warmup..\\n\");\n    for (int i = 0; i < repeat; i++) {\n      hipLaunchKernelGGL(matern_kernel, grids, blocks, 0, 0, ntargets, l, d_sources, d_targets, d_weights, d_result);\n    }\n    hipDeviceSynchronize();\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      hipLaunchKernelGGL(matern_kernel, grids, blocks, 0, 0, ntargets, l, d_sources, d_targets, d_weights, d_result);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Length scale = %.1e \", l);\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    l = l * 10.f;\n  }\n\n  hipFree(d_sources);\n  hipFree(d_weights);\n  hipFree(d_targets);\n  hipFree(d_result);\n\n  free(sources);\n  free(weights);\n  free(targets);\n  free(result);\n  free(result_ref);\n  return 0;\n}\n"}}
{"kernel_name": "matern", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\n\n\n\n\n\n\n\n\n\n\nvoid matern_kernel (\n  const int ntargets,\n  const float l,\n  const float *__restrict sources,\n  const float *__restrict targets,\n  const float *__restrict weights,\n        float *__restrict result)\n\n{\n  #pragma omp target teams distribute thread_limit(SX*64)\n  for (int t = 0; t < ntargets; t++) {\n    float sum = 0.f;\n    #pragma omp parallel for reduction(+:sum)\n    for (int s = 0; s < nsources; s++) {\n      float squared_diff = 0.f;\n      for (int i = 0; i < 3; i++) {\n        squared_diff += (sources[s*3+i] - targets[t*3+i]) *\n                        (sources[s*3+i] - targets[t*3+i]);\n      }\n      float diff = sqrtf(squared_diff);\n      sum += (1.f + sqrtf(5.f) * diff / l + 5.f * squared_diff / (3.f * l * l)) *  \n             expf(-sqrtf(5.f) * diff  / l) * weights[s];\n    }\n    result[t] = sum;\n  }\n  #pragma omp target update from(result[0:ntargets])\n}\n\nvoid matern_kernel2 (\n  const int ntargets,\n  const float l,\n  const float *__restrict sources,\n  const float *__restrict targets,\n  const float *__restrict weights,\n        float *__restrict result)\n\n{\n  const int teams = (ntargets + SX - 1) / SX;\n\n  \n\n  #pragma omp target teams num_teams(teams) thread_limit(SX*64)\n  {\n    float local_result[SX * SY];\n    float local_targets[SX * 3];\n    float local_sources[SY * 3];\n    float local_weights[SY];\n\n    #pragma omp parallel\n    {\n      int tx = omp_get_thread_num() % SX;\n      int ty = omp_get_thread_num() / SX;\n      int px = omp_get_team_num() * SX + tx; \n\n      int py = ty; \n\n\n      if (px < ntargets && py < SY) {\n        if (ty == 0) {\n          for (int i = 0; i < 3; i++)\n            local_targets[tx * 3 + i] = targets[px * 3 + i];\n        }\n\n        if (tx == 0) {\n          for (int i = 0; i < 3; i++)\n            local_sources[ty * 3 + i] = sources[py * 3 + i];\n          local_weights[ty] = weights[ty];\n        }\n      }\n      #pragma omp barrier\n\n      if (px < ntargets && py < SY) {\n        float squared_diff = 0.f;\n        \n        for (int i = 0; i < 3; i++) {\n          squared_diff += (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]) *\n                          (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]);\n        }\n        float diff = sqrtf(squared_diff);\n\n        local_result[tx * SY + ty] = \n          (1.f + sqrtf(5.f) * diff / l + 5.f * squared_diff / (3.f * l * l)) *  \n          expf(-sqrtf(5.f) * diff / l) * local_weights[ty];\n\n      }\n      #pragma omp barrier\n\n      if (px < ntargets && py < SY) {\n        if (ty == 0) {\n          float res = 0.f;\n          for (int i = 0; i < SY; i++)\n            res += local_result[tx * SY + i];\n          result[px] = res;\n        }\n      }\n    }\n  }\n  #pragma omp target update from(result[0:ntargets])\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int npoints = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int source_size = nsources * 3;  \n\n  const int source_size_byte = source_size * sizeof(float);\n\n  const int weight_size = nsources;\n  const int weight_size_byte = weight_size * sizeof(float);\n\n  const int ntargets = npoints * npoints * npoints;\n  const int target_size = ntargets * 3;\n  const int target_size_byte = target_size * sizeof(float);\n\n  const int result_size = ntargets;\n  const int result_size_byte = ntargets * sizeof(float);\n\n  float *sources = (float*) malloc (source_size_byte);\n  float *targets = (float*) malloc (target_size_byte);\n  float *weights = (float*) malloc (weight_size_byte);\n  float *result = (float*) malloc (result_size_byte);\n  float *result_ref = (float*) malloc (result_size_byte);\n\n  srand(123);\n  for (int i = 0; i < source_size; i++)\n    sources[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < weight_size; i++)\n    weights[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < target_size; i++) \n    targets[i] = rand() / (float)RAND_MAX;\n\n  #pragma omp target data map(to: sources[0:source_size],\\\n                                  weights[0:weight_size],\\\n                                  targets[0:target_size]) \\\n                          map(alloc: result[0:result_size])\n  {\n    float l = 0.1f; \n\n\n    \n\n    const int ntargets_small = 16*16*16;\n    printf(\"------------------------------------------------------------\\n\");\n    printf(\"Verifying the kernel results with the problem size (16 cube)\\n\");\n    printf(\"------------------------------------------------------------\\n\");\n\n    while (l <= 1e5f) {\n      matern_kernel_reference(nsources, ntargets_small, l, sources, targets, weights, result_ref);\n\n      matern_kernel2(ntargets_small, l, sources, targets, weights, result);\n\n      bool ok = true;\n      for (int i = 0; i < ntargets_small; i++) {\n        if (fabsf(result[i] - result_ref[i]) > 1e-3f) {\n          printf(\"@%d actual=%f expected=%f\\n\", i, result[i] , result_ref[i]);\n          ok = false;\n          break;\n        }\n      }\n      printf(\"Length scale = %.1e check = %s\\n\", l, ok ? \"PASS\" : \"FAIL\");\n      l = l * 10.f;\n    }\n\n    printf(\"--------------------------------------------------------------------\\n\");\n    printf(\"Timing the kernel execution with the problem size (%d cube)\\n\", npoints);\n    printf(\"--------------------------------------------------------------------\\n\");\n\n    l = 0.1f;\n    while (l <= 1e5f) {\n      printf(\"Warmup..\\n\");\n      for (int i = 0; i < repeat; i++) {\n        matern_kernel2(ntargets, l, sources, targets, weights, result);\n      }\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        matern_kernel2(ntargets, l, sources, targets, weights, result);\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Length scale = %.1e \", l);\n      printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n      l = l * 10.f;\n    }\n  }\n\n  free(sources);\n  free(weights);\n  free(targets);\n  free(result);\n  free(result_ref);\n  return 0;\n}\n"}}
{"kernel_name": "matern", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\n\n\n\n\n\n\n\n\n\n\nvoid matern_kernel (\n  const int ntargets,\n  const float l,\n  const float *__restrict sources,\n  const float *__restrict targets,\n  const float *__restrict weights,\n        float *__restrict result)\n\n{\n    for (int t = 0; t < ntargets; t++) {\n    float sum = 0.f;\n        for (int s = 0; s < nsources; s++) {\n      float squared_diff = 0.f;\n      for (int i = 0; i < 3; i++) {\n        squared_diff += (sources[s*3+i] - targets[t*3+i]) *\n                        (sources[s*3+i] - targets[t*3+i]);\n      }\n      float diff = sqrtf(squared_diff);\n      sum += (1.f + sqrtf(5.f) * diff / l + 5.f * squared_diff / (3.f * l * l)) *  \n             expf(-sqrtf(5.f) * diff  / l) * weights[s];\n    }\n    result[t] = sum;\n  }\n  }\n\nvoid matern_kernel2 (\n  const int ntargets,\n  const float l,\n  const float *__restrict sources,\n  const float *__restrict targets,\n  const float *__restrict weights,\n        float *__restrict result)\n\n{\n  const int teams = (ntargets + SX - 1) / SX;\n\n  \n\n    {\n    float local_result[SX * SY];\n    float local_targets[SX * 3];\n    float local_sources[SY * 3];\n    float local_weights[SY];\n\n        {\n      int tx = omp_get_thread_num() % SX;\n      int ty = omp_get_thread_num() / SX;\n      int px = omp_get_team_num() * SX + tx; \n\n      int py = ty; \n\n\n      if (px < ntargets && py < SY) {\n        if (ty == 0) {\n          for (int i = 0; i < 3; i++)\n            local_targets[tx * 3 + i] = targets[px * 3 + i];\n        }\n\n        if (tx == 0) {\n          for (int i = 0; i < 3; i++)\n            local_sources[ty * 3 + i] = sources[py * 3 + i];\n          local_weights[ty] = weights[ty];\n        }\n      }\n      \n      if (px < ntargets && py < SY) {\n        float squared_diff = 0.f;\n        \n        for (int i = 0; i < 3; i++) {\n          squared_diff += (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]) *\n                          (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]);\n        }\n        float diff = sqrtf(squared_diff);\n\n        local_result[tx * SY + ty] = \n          (1.f + sqrtf(5.f) * diff / l + 5.f * squared_diff / (3.f * l * l)) *  \n          expf(-sqrtf(5.f) * diff / l) * local_weights[ty];\n\n      }\n      \n      if (px < ntargets && py < SY) {\n        if (ty == 0) {\n          float res = 0.f;\n          for (int i = 0; i < SY; i++)\n            res += local_result[tx * SY + i];\n          result[px] = res;\n        }\n      }\n    }\n  }\n  }\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int npoints = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int source_size = nsources * 3;  \n\n  const int source_size_byte = source_size * sizeof(float);\n\n  const int weight_size = nsources;\n  const int weight_size_byte = weight_size * sizeof(float);\n\n  const int ntargets = npoints * npoints * npoints;\n  const int target_size = ntargets * 3;\n  const int target_size_byte = target_size * sizeof(float);\n\n  const int result_size = ntargets;\n  const int result_size_byte = ntargets * sizeof(float);\n\n  float *sources = (float*) malloc (source_size_byte);\n  float *targets = (float*) malloc (target_size_byte);\n  float *weights = (float*) malloc (weight_size_byte);\n  float *result = (float*) malloc (result_size_byte);\n  float *result_ref = (float*) malloc (result_size_byte);\n\n  srand(123);\n  for (int i = 0; i < source_size; i++)\n    sources[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < weight_size; i++)\n    weights[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < target_size; i++) \n    targets[i] = rand() / (float)RAND_MAX;\n\n    {\n    float l = 0.1f; \n\n\n    \n\n    const int ntargets_small = 16*16*16;\n    printf(\"------------------------------------------------------------\\n\");\n    printf(\"Verifying the kernel results with the problem size (16 cube)\\n\");\n    printf(\"------------------------------------------------------------\\n\");\n\n    while (l <= 1e5f) {\n      matern_kernel_reference(nsources, ntargets_small, l, sources, targets, weights, result_ref);\n\n      matern_kernel2(ntargets_small, l, sources, targets, weights, result);\n\n      bool ok = true;\n      for (int i = 0; i < ntargets_small; i++) {\n        if (fabsf(result[i] - result_ref[i]) > 1e-3f) {\n          printf(\"@%d actual=%f expected=%f\\n\", i, result[i] , result_ref[i]);\n          ok = false;\n          break;\n        }\n      }\n      printf(\"Length scale = %.1e check = %s\\n\", l, ok ? \"PASS\" : \"FAIL\");\n      l = l * 10.f;\n    }\n\n    printf(\"--------------------------------------------------------------------\\n\");\n    printf(\"Timing the kernel execution with the problem size (%d cube)\\n\", npoints);\n    printf(\"--------------------------------------------------------------------\\n\");\n\n    l = 0.1f;\n    while (l <= 1e5f) {\n      printf(\"Warmup..\\n\");\n      for (int i = 0; i < repeat; i++) {\n        matern_kernel2(ntargets, l, sources, targets, weights, result);\n      }\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        matern_kernel2(ntargets, l, sources, targets, weights, result);\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Length scale = %.1e \", l);\n      printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n      l = l * 10.f;\n    }\n  }\n\n  free(sources);\n  free(weights);\n  free(targets);\n  free(result);\n  free(result_ref);\n  return 0;\n}"}}
{"kernel_name": "matern", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n\n\n\n\n\n\n\n\n\n\nvoid matern_kernel (\n  sycl::nd_item<2> &item,\n  const int num_targets,\n  const float l,\n  const float *__restrict sources,\n  const float *__restrict targets,\n  const float *__restrict weights,\n        float *__restrict result,\n        float *__restrict local_result,\n        float *__restrict local_targets,\n        float *__restrict local_sources,\n        float *__restrict local_weights)\n\n{\n  int tx = item.get_local_id(1);\n  int px = item.get_global_id(1); \n\n  if (px >= num_targets) return;\n\n  int ty = item.get_local_id(0);\n  int py = ty; \n\n  if (py >= SY) return;\n\n  if (ty == 0) {\n    for (int i = 0; i < 3; i++)\n      local_targets[tx * 3 + i] = targets[px * 3 + i];\n  }\n\n  if (tx == 0) {\n    for (int i = 0; i < 3; i++)\n      local_sources[ty * 3 + i] = sources[py * 3 + i];\n    local_weights[ty] = weights[ty];\n  }\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  float squared_diff = 0.f;\n\n  for (int i = 0; i < 3; i++) {\n    squared_diff += (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]) *\n                    (local_targets[tx * 3 + i] - local_sources[ty * 3 + i]);\n  }\n  float diff = sycl::sqrt(squared_diff);\n\n  local_result[tx * SY + ty] =\n    (1.f + sycl::sqrt(5.f) * diff / l + 5.f * squared_diff / (3.f * l * l)) *\n    sycl::exp(-sycl::sqrt(5.f) * diff / l) * local_weights[ty];\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (ty == 0) {\n    float res = 0.f;\n    for (int i = 0; i < SY; i++)\n      res += local_result[tx * SY + i];\n    result[px] = res;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int npoints = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int source_size = nsources * 3;  \n\n  const int source_size_byte = source_size * sizeof(float);\n\n  const int weight_size = nsources;\n  const int weight_size_byte = weight_size * sizeof(float);\n\n  const int ntargets = npoints * npoints * npoints;\n  const int target_size = ntargets * 3;\n  const int target_size_byte = target_size * sizeof(float);\n\n  const int result_size = ntargets;\n  const int result_size_byte = ntargets * sizeof(float);\n\n  float *sources = (float*) malloc (source_size_byte);\n  float *targets = (float*) malloc (target_size_byte);\n  float *weights = (float*) malloc (weight_size_byte);\n  float *result = (float*) malloc (result_size_byte);\n  float *result_ref = (float*) malloc (result_size_byte);\n\n  srand(123);\n  for (int i = 0; i < source_size; i++)\n    sources[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < weight_size; i++)\n    weights[i] = rand() / (float)RAND_MAX;\n\n  for (int i = 0; i < target_size; i++)\n    targets[i] = rand() / (float)RAND_MAX;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_sources = sycl::malloc_device<float>(source_size, q);\n  float *d_weights = sycl::malloc_device<float>(weight_size, q);\n  float *d_targets = sycl::malloc_device<float>(target_size, q);\n  float *d_result = sycl::malloc_device<float>(result_size, q);\n\n  q.memcpy(d_sources, sources, source_size_byte);\n  q.memcpy(d_weights, weights, weight_size_byte);\n  q.memcpy(d_targets, targets, target_size_byte);\n  q.wait();\n\n  float l = 0.1f; \n\n\n  const int nblocks = (ntargets + SX - 1) / SX;\n  sycl::range<2> gws (64, SX * nblocks);\n  sycl::range<2> lws (64, SX);\n\n  \n\n  const int ntargets_small = 16*16*16;\n  printf(\"------------------------------------------------------------\\n\");\n  printf(\"Verifying the kernel results with the problem size (16 cube)\\n\");\n  printf(\"------------------------------------------------------------\\n\");\n\n  while (l <= 1e5f) {\n    auto e = q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> l_result (sycl::range<1>(SX*SY), cgh);\n      sycl::local_accessor<float, 1> l_targets (sycl::range<1>(SX*3), cgh);\n      sycl::local_accessor<float, 1> l_sources (sycl::range<1>(SY*3), cgh);\n      sycl::local_accessor<float, 1> l_weights (sycl::range<1>(SY), cgh);\n      cgh.parallel_for<class test>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        matern_kernel(item, ntargets_small, l, d_sources, d_targets, d_weights, d_result,\n                      l_result.get_pointer(), l_targets.get_pointer(),\n                      l_sources.get_pointer(), l_weights.get_pointer());\n      });\n    });\n\n    matern_kernel_reference(nsources, ntargets_small, l, sources, targets, weights, result_ref);\n\n    q.memcpy(result, d_result, ntargets_small * sizeof(float), e).wait();\n\n    bool ok = true;\n    for (int i = 0; i < ntargets_small; i++) {\n      if (fabsf(result[i] - result_ref[i]) > 1e-3f) {\n        printf(\"@%d actual=%f expected=%f\\n\", i, result[i] , result_ref[i]);\n        ok = false;\n        break;\n      }\n    }\n    printf(\"Length scale = %.1e check = %s\\n\", l, ok ? \"PASS\" : \"FAIL\");\n    l = l * 10.f;\n  }\n\n  printf(\"--------------------------------------------------------------------\\n\");\n  printf(\"Timing the kernel execution with the problem size (%d cube)\\n\", npoints);\n  printf(\"--------------------------------------------------------------------\\n\");\n\n  l = 0.1f;\n  while (l <= 1e5f) {\n    printf(\"Warmup..\\n\");\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        sycl::local_accessor<float, 1> l_result (sycl::range<1>(SX*SY), cgh);\n        sycl::local_accessor<float, 1> l_targets (sycl::range<1>(SX*3), cgh);\n        sycl::local_accessor<float, 1> l_sources (sycl::range<1>(SY*3), cgh);\n        sycl::local_accessor<float, 1> l_weights (sycl::range<1>(SY), cgh);\n        cgh.parallel_for<class warmup>(\n          sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n          matern_kernel(item, ntargets, l, d_sources, d_targets, d_weights, d_result,\n                        l_result.get_pointer(), l_targets.get_pointer(),\n                        l_sources.get_pointer(), l_weights.get_pointer());\n        });\n      });\n    }\n    q.wait();\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        sycl::local_accessor<float, 1> l_result (sycl::range<1>(SX*SY), cgh);\n        sycl::local_accessor<float, 1> l_targets (sycl::range<1>(SX*3), cgh);\n        sycl::local_accessor<float, 1> l_sources (sycl::range<1>(SY*3), cgh);\n        sycl::local_accessor<float, 1> l_weights (sycl::range<1>(SY), cgh);\n        cgh.parallel_for<class measure>(\n          sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n          matern_kernel(item, ntargets, l, d_sources, d_targets, d_weights, d_result,\n                        l_result.get_pointer(), l_targets.get_pointer(),\n                        l_sources.get_pointer(), l_weights.get_pointer());\n        });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Length scale = %.1e \", l);\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    l = l * 10.f;\n  }\n\n  sycl::free(d_sources, q);\n  sycl::free(d_weights, q);\n  sycl::free(d_targets, q);\n  sycl::free(d_result, q);\n\n  free(sources);\n  free(weights);\n  free(targets);\n  free(result);\n  free(result_ref);\n  return 0;\n}\n"}}
{"kernel_name": "maxpool3d", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\ntypedef float DTYPE;\n\n__global__ void\nmaxpool3d(\n  const DTYPE* i_img,\n        DTYPE* o_img,\n  const int Hstride,\n  const int Vstride,\n  const int pool_width,\n  const int pool_height,\n  const int i_img_width,\n  const int i_img_height,\n  const int o_img_width,\n  const int o_img_height )\n{\n  const int x = blockDim.x * blockIdx.x + threadIdx.x;\n  const int y = blockDim.y * blockIdx.y + threadIdx.y;\n  const int z = blockDim.z * blockIdx.z + threadIdx.z;\n  const int xidx = Hstride * x;\n  const int yidx = Vstride * y;\n  DTYPE maxval = (DTYPE)0;\n\n  for (int r = 0; r < pool_height; r++) \n  { \n    const int idxIntmp = ((z * i_img_height + yidx + r) * i_img_width) + xidx;\n    for(int c = 0; c < pool_width; c++)\n    {\n      const int idxIn = idxIntmp + c;\n      maxval = fmaxf(maxval, i_img[idxIn]);\n    }\n  }\n  o_img[(((z * o_img_height) + y) * o_img_width) + x] = maxval;\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <image count> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int i_img_width  = atoi(argv[1]);  \n  int i_img_height = atoi(argv[2]);\n\n  if (i_img_width % 16 != 0 || i_img_height % 16 != 0) {\n    printf(\"image dimension is a multiple of 16\\n\");\n    return 1;\n  }\n\n  int i_img_count = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  int Hstride=2, Vstride=2;\n  int o_img_width  = i_img_width/Hstride;\n  int o_img_height = i_img_height/Vstride;\n\n  printf(\"input image width %d Hstride %d\\n\", i_img_width, Hstride);\n  printf(\"input image height %d Vstride %d\\n\", i_img_height, Vstride);\n  printf(\"output image width %d\\n\", o_img_width);\n  printf(\"output image height %d\\n\", o_img_height);\n\n  \n\n  int size_image = i_img_width*i_img_height;\n  size_t mem_size_image = sizeof(DTYPE) * size_image;\n  DTYPE *h_image  = (DTYPE*)malloc(mem_size_image * i_img_count);\n\n  srand(2);\n\n  for(int j=0;j<i_img_count;j++) {\n    for(int i=0;i<size_image;i++) {\n      h_image[(j*size_image)+i] = rand()%256 / (DTYPE)255;\n    }\n  }\n\n  \n\n  int size_output = o_img_width * o_img_height;\n  size_t mem_size_output = sizeof(DTYPE) * size_output;\n  DTYPE* h_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n  DTYPE* d_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n\n  \n\n  DTYPE* d_image;\n  cudaMalloc((void**)&d_image, mem_size_image*i_img_count);\n  cudaMemcpy(d_image, h_image, mem_size_image*i_img_count, cudaMemcpyHostToDevice);\n\n  DTYPE* d_result;\n  cudaMalloc((void**)&d_result, mem_size_output*i_img_count);\n\n  \n\n  dim3 block_dim (16, 16, 1);\n  dim3 grid_dim(o_img_width/16, o_img_height/16, i_img_count);\n\n  \n\n  const int pool_width  = Hstride;\n  const int pool_height = Vstride;\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++) {\n    maxpool3d<<<grid_dim, block_dim>>>(d_image, d_result, Hstride, Vstride, \n      pool_width, pool_height, i_img_width, i_img_height, o_img_width, o_img_height);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  cudaMemcpy(d_output, d_result, mem_size_output*i_img_count, cudaMemcpyDeviceToHost);\n\n  for (int z = 0; z < i_img_count; z++) {\n    for (int y = 0; y < o_img_height; y++) {\n      for (int x = 0; x < o_img_width; x++) {\n        const int xidx = Hstride*x;\n        const int yidx = Vstride*y;\n        DTYPE maxval = (DTYPE)0;\n        for (int r = 0; r < pool_height; r++) \n        { \n          const int idxIntmp = ((z*i_img_height + yidx + r) * i_img_width) + xidx;\n          for(int c = 0; c < pool_width; c++)\n          {\n            const int idxIn = idxIntmp + c;\n            maxval = fmaxf(maxval,h_image[idxIn]);\n          }\n        }\n        h_output[(((z*o_img_height)+y)*o_img_width)+x] = maxval;\n      }\n    }\n  }\n\n  int status = memcmp(h_output, d_output, sizeof(DTYPE)*i_img_count*o_img_width*o_img_height);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(h_image);\n  free(h_output);\n  free(d_output);\n  cudaFree(d_image);\n  cudaFree(d_result);\n  return status;\n}\n"}}
{"kernel_name": "maxpool3d", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\ntypedef float DTYPE;\n\n__global__ void\nmaxpool3d(\n  const DTYPE* i_img,\n        DTYPE* o_img,\n  const int Hstride,\n  const int Vstride,\n  const int pool_width,\n  const int pool_height,\n  const int i_img_width,\n  const int i_img_height,\n  const int o_img_width,\n  const int o_img_height )\n{\n  const int x = blockDim.x * blockIdx.x + threadIdx.x;\n  const int y = blockDim.y * blockIdx.y + threadIdx.y;\n  const int z = blockDim.z * blockIdx.z + threadIdx.z;\n  const int xidx = Hstride * x;\n  const int yidx = Vstride * y;\n  DTYPE maxval = (DTYPE)0;\n\n  for (int r = 0; r < pool_height; r++) \n  { \n    const int idxIntmp = ((z * i_img_height + yidx + r) * i_img_width) + xidx;\n    for(int c = 0; c < pool_width; c++)\n    {\n      const int idxIn = idxIntmp + c;\n      maxval = fmaxf(maxval, i_img[idxIn]);\n    }\n  }\n  o_img[(((z * o_img_height) + y) * o_img_width) + x] = maxval;\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <image count> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int i_img_width  = atoi(argv[1]);  \n  int i_img_height = atoi(argv[2]);\n  int i_img_count = atoi(argv[3]);\n\n  if (i_img_width % 16 != 0 || i_img_height % 16 != 0) {\n    printf(\"image dimension is a multiple of 16\\n\");\n    return 1;\n  }\n\n  int repeat = atoi(argv[4]);\n\n  int Hstride=2, Vstride=2;\n  int o_img_width  = i_img_width/Hstride;\n  int o_img_height = i_img_height/Vstride;\n\n  printf(\"input image width %d Hstride %d\\n\", i_img_width, Hstride);\n  printf(\"input image height %d Vstride %d\\n\", i_img_height, Vstride);\n  printf(\"output image width %d\\n\", o_img_width);\n  printf(\"output image height %d\\n\", o_img_height);\n\n  \n\n  int size_image = i_img_width*i_img_height;\n  size_t mem_size_image = sizeof(DTYPE) * size_image;\n  DTYPE *h_image  = (DTYPE*)malloc(mem_size_image * i_img_count);\n\n  srand(2);\n\n  for(int j=0;j<i_img_count;j++) {\n    for(int i=0;i<size_image;i++) {\n      h_image[(j*size_image)+i] = rand()%256 / (DTYPE)255;\n    }\n  }\n\n  \n\n  int size_output = o_img_width * o_img_height;\n  size_t mem_size_output = sizeof(DTYPE) * size_output;\n  DTYPE* h_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n  DTYPE* d_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n\n  \n\n  DTYPE* d_image;\n  hipMalloc((void**)&d_image, mem_size_image*i_img_count);\n  hipMemcpy(d_image, h_image, mem_size_image*i_img_count, hipMemcpyHostToDevice);\n\n  DTYPE* d_result;\n  hipMalloc((void**)&d_result, mem_size_output*i_img_count);\n\n  \n\n  dim3 block_dim (16, 16, 1);\n  dim3 grid_dim(o_img_width/16, o_img_height/16, i_img_count);\n\n  \n\n  const int pool_width  = Hstride;\n  const int pool_height = Vstride;\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++) {\n    maxpool3d<<<grid_dim, block_dim>>>(d_image, d_result, Hstride, Vstride, \n      pool_width, pool_height, i_img_width, i_img_height, o_img_width, o_img_height);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  hipMemcpy(d_output, d_result, mem_size_output*i_img_count, hipMemcpyDeviceToHost);\n\n  for (int z = 0; z < i_img_count; z++) {\n    for (int y = 0; y < o_img_height; y++) {\n      for (int x = 0; x < o_img_width; x++) {\n        const int xidx = Hstride*x;\n        const int yidx = Vstride*y;\n        DTYPE maxval = (DTYPE)0;\n        for (int r = 0; r < pool_height; r++) \n        { \n          const int idxIntmp = ((z*i_img_height + yidx + r) * i_img_width) + xidx;\n          for(int c = 0; c < pool_width; c++)\n          {\n            const int idxIn = idxIntmp + c;\n            maxval = fmaxf(maxval,h_image[idxIn]);\n          }\n        }\n        h_output[(((z*o_img_height)+y)*o_img_width)+x] = maxval;\n      }\n    }\n  }\n\n  int status = memcmp(h_output, d_output, sizeof(DTYPE)*i_img_count*o_img_width*o_img_height);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(h_image);\n  free(h_output);\n  free(d_output);\n  hipFree(d_image);\n  hipFree(d_result);\n  return status;\n}\n"}}
{"kernel_name": "maxpool3d", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\ntypedef float DTYPE;\n\nint main(int argc, char** argv)\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <image count> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int i_img_width  = atoi(argv[1]);  \n  int i_img_height = atoi(argv[2]);\n\n  \n\n  if (i_img_width % 16 != 0 || i_img_height % 16 != 0) {\n    printf(\"image dimension is a multiple of 16\\n\");\n    return 1;\n  }\n\n  int i_img_count = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  int Hstride=2, Vstride=2;\n  int o_img_width  = i_img_width/Hstride;\n  int o_img_height = i_img_height/Vstride;\n\n  printf(\"input image width %d Hstride %d\\n\", i_img_width,Hstride);\n  printf(\"input image height %d Vstride %d\\n\", i_img_height,Vstride);\n  printf(\"output image width %d\\n\", o_img_width);\n  printf(\"output image height %d\\n\", o_img_height);\n\n  \n\n  int size_image = i_img_width*i_img_height;\n  size_t mem_size_image = sizeof(DTYPE) * size_image;\n  DTYPE *h_image  = (DTYPE*)malloc(mem_size_image * i_img_count);\n\n  srand(2);\n\n  for(int j=0;j<i_img_count;j++) {\n    for(int i=0;i<size_image;i++) {\n      h_image[(j*size_image)+i] = rand()%256 / (DTYPE)255;\n    }\n  }\n\n  \n\n  int size_output = o_img_width * o_img_height;\n  size_t mem_size_output = sizeof(DTYPE) * size_output;\n  DTYPE* h_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n  DTYPE* d_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n\n  \n\n  const int pool_width  = Hstride;\n  const int pool_height = Vstride;\n\n  #pragma omp target data map(to: h_image[0:size_image*i_img_count]) \\\n                          map(from: d_output[0:size_output*i_img_count])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      #pragma omp target teams distribute parallel for collapse(3) thread_limit(256) \n      for (int z = 0; z < i_img_count; z++) {\n        for (int y = 0; y < o_img_height; y++) {\n          for (int x = 0; x < o_img_width; x++) {\n            const int xidx = Hstride*x;\n            const int yidx = Vstride*y;\n            DTYPE maxval = (DTYPE)0;\n            for (int r = 0; r < pool_height; r++) \n            { \n              const int idxIntmp = ((z*i_img_height + yidx + r) * i_img_width) + xidx;\n              for(int c = 0; c < pool_width; c++)\n              {\n                const int idxIn = idxIntmp + c;\n                maxval = fmaxf(maxval,h_image[idxIn]);\n              }\n            }\n            d_output[(((z*o_img_height)+y)*o_img_width)+x] = maxval;\n          }\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  } \n\n  \n\n  for (int z = 0; z < i_img_count; z++) {\n    for (int y = 0; y < o_img_height; y++) {\n      for (int x = 0; x < o_img_width; x++) {\n        const int xidx = Hstride*x;\n        const int yidx = Vstride*y;\n        DTYPE maxval = (DTYPE)0;\n        for (int r = 0; r < pool_height; r++) \n        { \n          const int idxIntmp = ((z*i_img_height + yidx + r) * i_img_width) + xidx;\n          for(int c = 0; c < pool_width; c++)\n          {\n            const int idxIn = idxIntmp + c;\n            maxval = fmaxf(maxval, h_image[idxIn]);\n          }\n        }\n        h_output[(((z * o_img_height) + y) * o_img_width) + x] = maxval;\n      }\n    }\n  }\n\n  int status = memcmp(h_output, d_output, sizeof(DTYPE)*i_img_count*o_img_height*o_img_width);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(h_image);\n  free(h_output);\n  free(d_output);\n  return status;\n}\n"}}
{"kernel_name": "maxpool3d", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n\ntypedef float DTYPE;\n\nint main(int argc, char** argv)\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <image count> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int i_img_width  = atoi(argv[1]);  \n  int i_img_height = atoi(argv[2]);\n\n  \n\n  if (i_img_width % 16 != 0 || i_img_height % 16 != 0) {\n    printf(\"image dimension is a multiple of 16\\n\");\n    return 1;\n  }\n\n  int i_img_count = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  int Hstride=2, Vstride=2;\n  int o_img_width  = i_img_width/Hstride;\n  int o_img_height = i_img_height/Vstride;\n\n  printf(\"input image width %d Hstride %d\\n\", i_img_width,Hstride);\n  printf(\"input image height %d Vstride %d\\n\", i_img_height,Vstride);\n  printf(\"output image width %d\\n\", o_img_width);\n  printf(\"output image height %d\\n\", o_img_height);\n\n  \n\n  int size_image = i_img_width*i_img_height;\n  size_t mem_size_image = sizeof(DTYPE) * size_image;\n  DTYPE *h_image  = (DTYPE*)malloc(mem_size_image * i_img_count);\n\n  srand(2);\n\n  for(int j=0;j<i_img_count;j++) {\n    for(int i=0;i<size_image;i++) {\n      h_image[(j*size_image)+i] = rand()%256 / (DTYPE)255;\n    }\n  }\n\n  \n\n  int size_output = o_img_width * o_img_height;\n  size_t mem_size_output = sizeof(DTYPE) * size_output;\n  DTYPE* h_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n  DTYPE* d_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n\n  \n\n  const int pool_width  = Hstride;\n  const int pool_height = Vstride;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n            for (int z = 0; z < i_img_count; z++) {\n        for (int y = 0; y < o_img_height; y++) {\n          for (int x = 0; x < o_img_width; x++) {\n            const int xidx = Hstride*x;\n            const int yidx = Vstride*y;\n            DTYPE maxval = (DTYPE)0;\n            for (int r = 0; r < pool_height; r++) \n            { \n              const int idxIntmp = ((z*i_img_height + yidx + r) * i_img_width) + xidx;\n              for(int c = 0; c < pool_width; c++)\n              {\n                const int idxIn = idxIntmp + c;\n                maxval = fmaxf(maxval,h_image[idxIn]);\n              }\n            }\n            d_output[(((z*o_img_height)+y)*o_img_width)+x] = maxval;\n          }\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  } \n\n  \n\n  for (int z = 0; z < i_img_count; z++) {\n    for (int y = 0; y < o_img_height; y++) {\n      for (int x = 0; x < o_img_width; x++) {\n        const int xidx = Hstride*x;\n        const int yidx = Vstride*y;\n        DTYPE maxval = (DTYPE)0;\n        for (int r = 0; r < pool_height; r++) \n        { \n          const int idxIntmp = ((z*i_img_height + yidx + r) * i_img_width) + xidx;\n          for(int c = 0; c < pool_width; c++)\n          {\n            const int idxIn = idxIntmp + c;\n            maxval = fmaxf(maxval, h_image[idxIn]);\n          }\n        }\n        h_output[(((z * o_img_height) + y) * o_img_width) + x] = maxval;\n      }\n    }\n  }\n\n  int status = memcmp(h_output, d_output, sizeof(DTYPE)*i_img_count*o_img_height*o_img_width);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(h_image);\n  free(h_output);\n  free(d_output);\n  return status;\n}"}}
{"kernel_name": "maxpool3d", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\ntypedef float DTYPE;\n\nint main(int argc, char** argv)\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <image count> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int i_img_width  = atoi(argv[1]);\n  int i_img_height = atoi(argv[2]);\n\n  if (i_img_width % 16 != 0 || i_img_height % 16 != 0) {\n    printf(\"image dimension is a multiple of 16\\n\");\n    return 1;\n  }\n\n  int i_img_count = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  int Hstride=2, Vstride=2;\n  int o_img_width  = i_img_width/Hstride;\n  int o_img_height = i_img_height/Vstride;\n\n  printf(\"input image width %d Hstride %d\\n\", i_img_width,Hstride);\n  printf(\"input image height %d Vstride %d\\n\", i_img_height,Vstride);\n  printf(\"output image width %d\\n\", o_img_width);\n  printf(\"output image height %d\\n\", o_img_height);\n\n  \n\n  int size_image = i_img_width * i_img_height;\n  size_t mem_size_image = sizeof(DTYPE) * size_image;\n  DTYPE *h_image  = (DTYPE*)malloc(mem_size_image * i_img_count);\n\n  srand(2);\n\n  for(int j=0;j<i_img_count;j++) {\n    for(int i=0;i<size_image;i++) {\n      h_image[(j*size_image)+i] = rand()%256 / (DTYPE)255;\n    }\n  }\n\n  \n\n  int size_output = o_img_width * o_img_height;\n  size_t mem_size_output = sizeof(DTYPE) * size_output;\n  DTYPE* h_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n  DTYPE* d_output = (DTYPE*) malloc(mem_size_output*i_img_count);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  DTYPE *d_image = sycl::malloc_device<DTYPE>(size_image*i_img_count, q);\n  q.memcpy(d_image, h_image, mem_size_image*i_img_count);\n\n  DTYPE *d_result = sycl::malloc_device<DTYPE>(size_output*i_img_count, q);\n\n  \n\n  sycl::range<3> lws (1, 16, 16);\n  sycl::range<3> gws (i_img_count, o_img_height, o_img_width);\n\n  \n\n  const int pool_width  = Hstride;\n  const int pool_height = Vstride;\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&] (sycl::handler &h) {\n      h.parallel_for<class maxpool3>(\n      sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        const int x = item.get_global_id(2);\n        const int y = item.get_global_id(1);\n        const int z = item.get_global_id(0);\n        const int xidx = Hstride*x;\n        const int yidx = Vstride*y;\n        DTYPE maxval = (DTYPE)0;\n\n        for (int r = 0; r < pool_height; r++)\n        {\n          const int idxIntmp = ((z*i_img_height + yidx + r) * i_img_width) + xidx;\n          for(int c = 0; c < pool_width; c++)\n          {\n            const int idxIn = idxIntmp + c;\n            maxval = sycl::fmax(maxval, d_image[idxIn]);\n          }\n        }\n        d_result[(((z * o_img_height) + y) * o_img_width) + x] = maxval;\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(d_output, d_result, mem_size_output*i_img_count).wait();\n\n  \n\n  for (int z = 0; z < i_img_count; z++) {\n    for (int y = 0; y < o_img_height; y++) {\n      for (int x = 0; x < o_img_width; x++) {\n        const int xidx = Hstride*x;\n        const int yidx = Vstride*y;\n        DTYPE maxval = (DTYPE)0;\n        for (int r = 0; r < pool_height; r++)\n        {\n          const int idxIntmp = ((z*i_img_height + yidx + r) * i_img_width) + xidx;\n          for(int c = 0; c < pool_width; c++)\n          {\n            const int idxIn = idxIntmp + c;\n            maxval = fmaxf(maxval, h_image[idxIn]);\n          }\n        }\n        h_output[(((z*o_img_height)+y)*o_img_width)+x] = maxval;\n      }\n    }\n  }\n\n  int status = memcmp(h_output, d_output, sizeof(DTYPE)*i_img_count*o_img_width*o_img_height);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(h_image);\n  free(h_output);\n  free(d_output);\n  sycl::free(d_image, q);\n  sycl::free(d_result, q);\n  return status;\n}\n"}}
{"kernel_name": "mcpr", "parallel_api": "cuda", "code": {"main.cu": "#include <cstdio>\n#include <cstdlib>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <cuda.h>\n#include \"kernels.h\"\n\n\n\ndouble* t(const double *idata, const int width, const int height)\n{\n  double *odata = (double*) malloc (sizeof(double) * width * height); \n  for (int yIndex = 0; yIndex < height; yIndex++) {\n    for (int xIndex = 0; xIndex < width; xIndex++) {\n      int index_in  = xIndex + width * yIndex;\n      int index_out = yIndex + height * xIndex;\n      odata[index_out] = idata[index_in];\n    }\n  }\n  return odata;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <path to filename> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  char *filename = argv[1];\n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int n = 26280, K = 21, M = 10000;\n\n  FILE *fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    printf(\"Error: failed to open file alphas.csv. Exit\\n\");\n    return 1;\n  }\n\n  int alphas_size = n * K; \n\n  int alphas_size_byte = n * K * sizeof(double);\n\n  int rands_size = M * K;  \n\n  int rands_size_byte = M * K * sizeof(double);\n\n  double *alphas, *rands, *probs;\n  alphas = (double*) malloc (alphas_size_byte);\n  rands = (double*) malloc (rands_size_byte);\n  probs = (double*) malloc (alphas_size_byte);\n\n  \n\n  for (int i = 0; i < alphas_size; i++)\n    fscanf(fp, \"%lf\", &alphas[i]);\n  fclose(fp);\n\n  \n\n  std::mt19937 gen(19937);\n  std::normal_distribution<double> norm_dist(0.0,1.0);\n  for (int i = 0; i < rands_size; i++) rands[i] = norm_dist(gen); \n\n  double *d_alphas, *d_rands, *d_probs;\n  cudaMalloc((void**)&d_rands, rands_size_byte);\n  cudaMalloc((void**)&d_alphas, alphas_size_byte);\n  cudaMalloc((void**)&d_probs, alphas_size_byte);\n\n  cudaMemcpy(d_rands, rands, rands_size_byte, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_alphas, alphas, alphas_size_byte, cudaMemcpyHostToDevice);\n\n  \n\n  int threads_per_block = 192;\n  dim3 threads (threads_per_block);\n  dim3 blocks(ceil(1.0 * n / threads_per_block));\n\n  cudaMemset(d_probs, 0.0, alphas_size_byte);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    compute_probs<<<blocks, threads>>>(d_alphas, d_rands, d_probs, n, K, M);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(probs, d_probs, alphas_size_byte, cudaMemcpyDeviceToHost);\n  double s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs: checksum = %lf\\n\", s);\n\n  \n\n  double *t_rands = t(rands, K, M);\n  double *t_alphas = t(alphas, K, n);\n  cudaMemcpy(d_rands, t_rands, rands_size_byte, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_alphas, t_alphas, alphas_size_byte, cudaMemcpyHostToDevice);\n\n  cudaMemset(d_probs, 0.0, alphas_size_byte);\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    compute_probs_unitStrides<<<blocks, threads>>>(\n      d_alphas, d_rands, d_probs, n, K, M);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(probs, d_probs, alphas_size_byte, cudaMemcpyDeviceToHost);\n  s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs_unitStrides: checksum = %lf\\n\", s);\n\n  \n\n  threads_per_block = 96;\n  dim3 threads2 (threads_per_block);\n  dim3 blocks2 (ceil(1.0 * n / threads_per_block));\n\n  const int sm_size = sizeof(double) * K * threads_per_block * 2;\n  cudaMemset(d_probs, 0.0, alphas_size_byte);\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    compute_probs_unitStrides_sharedMem<<<blocks2, threads2, sm_size, 0>>>(\n      d_alphas, d_rands, d_probs, n, K, M);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(probs, d_probs, alphas_size_byte, cudaMemcpyDeviceToHost);\n  s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs_unitStrides_sharedMem: checksum = %lf\\n\", s);\n\n  \n\n  cudaFree(d_alphas);\n  cudaFree(d_rands);\n  cudaFree(d_probs);\n  free(alphas);\n  free(rands);\n  free(t_alphas);\n  free(t_rands);\n  free(probs);\n  return 0;\n}\n"}}
{"kernel_name": "mcpr", "parallel_api": "hip", "code": {"main.cu": "#include <cstdio>\n#include <cstdlib>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"kernels.h\"\n\n\n\ndouble* t(const double *idata, const int width, const int height)\n{\n  double *odata = (double*) malloc (sizeof(double) * width * height); \n  for (int yIndex = 0; yIndex < height; yIndex++) {\n    for (int xIndex = 0; xIndex < width; xIndex++) {\n      int index_in  = xIndex + width * yIndex;\n      int index_out = yIndex + height * xIndex;\n      odata[index_out] = idata[index_in];\n    }\n  }\n  return odata;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <path to filename> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  char *filename = argv[1];\n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int n = 26280, K = 21, M = 10000;\n\n  FILE *fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    printf(\"Error: failed to open file alphas.csv. Exit\\n\");\n    return 1;\n  }\n\n  int alphas_size = n * K; \n\n  int alphas_size_byte = n * K * sizeof(double);\n\n  int rands_size = M * K;  \n\n  int rands_size_byte = M * K * sizeof(double);\n\n  double *alphas, *rands, *probs;\n  alphas = (double*) malloc (alphas_size_byte);\n  rands = (double*) malloc (rands_size_byte);\n  probs = (double*) malloc (alphas_size_byte);\n\n  \n\n  for (int i = 0; i < alphas_size; i++)\n    fscanf(fp, \"%lf\", &alphas[i]);\n  fclose(fp);\n\n  \n\n  std::mt19937 gen(19937);\n  std::normal_distribution<double> norm_dist(0.0,1.0);\n  for (int i = 0; i < rands_size; i++) rands[i] = norm_dist(gen); \n\n  double *d_alphas, *d_rands, *d_probs;\n  hipMalloc((void**)&d_rands, rands_size_byte);\n  hipMalloc((void**)&d_alphas, alphas_size_byte);\n  hipMalloc((void**)&d_probs, alphas_size_byte);\n\n  hipMemcpy(d_rands, rands, rands_size_byte, hipMemcpyHostToDevice);\n  hipMemcpy(d_alphas, alphas, alphas_size_byte, hipMemcpyHostToDevice);\n\n  \n\n  int threads_per_block = 192;\n  dim3 threads (threads_per_block);\n  dim3 blocks(ceil(1.0 * n / threads_per_block));\n\n  hipMemset(d_probs, 0.0, alphas_size_byte);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(compute_probs, blocks, threads, 0, 0, d_alphas, d_rands, d_probs, n, K, M);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(probs, d_probs, alphas_size_byte, hipMemcpyDeviceToHost);\n  double s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs: checksum = %lf\\n\", s);\n\n  \n\n  double *t_rands = t(rands, K, M);\n  double *t_alphas = t(alphas, K, n);\n  hipMemcpy(d_rands, t_rands, rands_size_byte, hipMemcpyHostToDevice);\n  hipMemcpy(d_alphas, t_alphas, alphas_size_byte, hipMemcpyHostToDevice);\n\n  hipMemset(d_probs, 0.0, alphas_size_byte);\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(compute_probs_unitStrides, blocks, threads, 0, 0, \n      d_alphas, d_rands, d_probs, n, K, M);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(probs, d_probs, alphas_size_byte, hipMemcpyDeviceToHost);\n  s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs_unitStrides: checksum = %lf\\n\", s);\n\n  \n\n  threads_per_block = 96;\n  dim3 threads2 (threads_per_block);\n  dim3 blocks2(ceil(1.0 * n / threads_per_block));\n\n  const int sm_size = sizeof(double) * K * threads_per_block * 2;\n  hipMemset(d_probs, 0.0, alphas_size_byte);\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(compute_probs_unitStrides_sharedMem, blocks2, threads2, sm_size, 0, \n      d_alphas, d_rands, d_probs, n, K, M);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(probs, d_probs, alphas_size_byte, hipMemcpyDeviceToHost);\n  s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs_unitStrides_sharedMem: checksum = %lf\\n\", s);\n\n  \n\n  hipFree(d_alphas);\n  hipFree(d_rands);\n  hipFree(d_probs);\n  free(alphas);\n  free(rands);\n  free(t_alphas);\n  free(t_rands);\n  free(probs);\n  return 0;\n}\n"}}
{"kernel_name": "mcpr", "parallel_api": "omp", "code": {"main.cpp": "#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <omp.h>\n#include \"kernels.h\"\n\n\n\ndouble* t(const double *idata, const int width, const int height)\n{\n  double *odata = (double*) malloc (sizeof(double) * width * height); \n  for (int yIndex = 0; yIndex < height; yIndex++) {\n    for (int xIndex = 0; xIndex < width; xIndex++) {\n      int index_in  = xIndex + width * yIndex;\n      int index_out = yIndex + height * xIndex;\n      odata[index_out] = idata[index_in];\n    }\n  }\n  return odata;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <path to filename> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  char *filename = argv[1];\n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int n = 26280, K = 21, M = 10000;\n\n  FILE *fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    printf(\"Error: failed to open file alphas.csv. Exit\\n\");\n    return 1;\n  }\n\n  int alphas_size = n * K; \n\n  int alphas_size_byte = n * K * sizeof(double);\n\n  int rands_size = M * K;  \n\n  int rands_size_byte = M * K * sizeof(double);\n\n  double *alphas, *rands, *probs;\n  alphas = (double*) malloc (alphas_size_byte);\n  rands = (double*) malloc (rands_size_byte);\n  probs = (double*) malloc (alphas_size_byte);\n\n  \n\n  for (int i = 0; i < alphas_size; i++)\n    fscanf(fp, \"%lf\", &alphas[i]);\n  fclose(fp);\n\n  \n\n  std::mt19937 gen(19937);\n  std::normal_distribution<double> norm_dist(0.0,1.0);\n  for (int i = 0; i < rands_size; i++) rands[i] = norm_dist(gen); \n\n  #pragma omp target data map (to: rands[0:rands_size], alphas[0:alphas_size]) \\\n                          map (alloc: probs[0:alphas_size])\n  {\n    \n\n    int threads_per_block = 192;\n    int num_blocks = ceil(1.0 * n / threads_per_block);\n\n    memset(probs, 0, alphas_size_byte);\n    #pragma omp target update to (probs[0:alphas_size])\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      compute_probs(alphas, rands, probs, n, K, M, threads_per_block, num_blocks);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    #pragma omp target update from (probs[0:alphas_size])\n\n    double s = 0.0;\n    for (int i = 0; i < alphas_size; i++) s += probs[i];\n    printf(\"compute_probs: checksum = %lf\\n\", s);\n\n    \n\n    double *t_rands = t(rands, K, M);\n    double *t_alphas = t(alphas, K, n);\n\n    memcpy(rands, t_rands, rands_size_byte);\n    memcpy(alphas, t_alphas, alphas_size_byte);\n\n    #pragma omp target update to (rands[0:rands_size])\n    #pragma omp target update to (alphas[0:alphas_size])\n\n    memset(probs, 0, alphas_size_byte);\n    #pragma omp target update to (probs[0:alphas_size])\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      compute_probs_unitStrides(alphas, rands, probs, n, K, M,\n                                threads_per_block, num_blocks);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    #pragma omp target update from (probs[0:alphas_size])\n\n    s = 0.0;\n    for (int i = 0; i < alphas_size; i++) s += probs[i];\n    printf(\"compute_probs_unitStrides: checksum = %lf\\n\", s);\n\n    \n\n    threads_per_block = 96;\n    num_blocks = ceil(1.0 * n / threads_per_block);\n\n    memset(probs, 0, alphas_size_byte);\n    #pragma omp target update to (probs[0:alphas_size])\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      compute_probs_unitStrides_sharedMem(alphas, rands, probs, n, K, M,\n                                          threads_per_block, num_blocks);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    #pragma omp target update from (probs[0:alphas_size])\n\n    s = 0.0;\n    for (int i = 0; i < alphas_size; i++) s += probs[i];\n    printf(\"compute_probs_unitStrides_sharedMem: checksum = %lf\\n\", s);\n \n    free(t_alphas);\n    free(t_rands);\n  }\n\n  \n\n  free(alphas);\n  free(rands);\n  free(probs);\n  return 0;\n}\n"}}
{"kernel_name": "mcpr", "parallel_api": "serial", "code": {"main.cpp": "#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include \"kernels.h\"\n\n\n\ndouble* t(const double *idata, const int width, const int height)\n{\n  double *odata = (double*) malloc (sizeof(double) * width * height); \n  for (int yIndex = 0; yIndex < height; yIndex++) {\n    for (int xIndex = 0; xIndex < width; xIndex++) {\n      int index_in  = xIndex + width * yIndex;\n      int index_out = yIndex + height * xIndex;\n      odata[index_out] = idata[index_in];\n    }\n  }\n  return odata;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <path to filename> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  char *filename = argv[1];\n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int n = 26280, K = 21, M = 10000;\n\n  FILE *fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    printf(\"Error: failed to open file alphas.csv. Exit\\n\");\n    return 1;\n  }\n\n  int alphas_size = n * K; \n\n  int alphas_size_byte = n * K * sizeof(double);\n\n  int rands_size = M * K;  \n\n  int rands_size_byte = M * K * sizeof(double);\n\n  double *alphas, *rands, *probs;\n  alphas = (double*) malloc (alphas_size_byte);\n  rands = (double*) malloc (rands_size_byte);\n  probs = (double*) malloc (alphas_size_byte);\n\n  \n\n  for (int i = 0; i < alphas_size; i++)\n    fscanf(fp, \"%lf\", &alphas[i]);\n  fclose(fp);\n\n  \n\n  std::mt19937 gen(19937);\n  std::normal_distribution<double> norm_dist(0.0,1.0);\n  for (int i = 0; i < rands_size; i++) rands[i] = norm_dist(gen); \n\n    {\n    \n\n    int threads_per_block = 192;\n    int num_blocks = ceil(1.0 * n / threads_per_block);\n\n    memset(probs, 0, alphas_size_byte);\n    \n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      compute_probs(alphas, rands, probs, n, K, M, threads_per_block, num_blocks);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    \n    double s = 0.0;\n    for (int i = 0; i < alphas_size; i++) s += probs[i];\n    printf(\"compute_probs: checksum = %lf\\n\", s);\n\n    \n\n    double *t_rands = t(rands, K, M);\n    double *t_alphas = t(alphas, K, n);\n\n    memcpy(rands, t_rands, rands_size_byte);\n    memcpy(alphas, t_alphas, alphas_size_byte);\n\n        \n    memset(probs, 0, alphas_size_byte);\n    \n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      compute_probs_unitStrides(alphas, rands, probs, n, K, M,\n                                threads_per_block, num_blocks);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    \n    s = 0.0;\n    for (int i = 0; i < alphas_size; i++) s += probs[i];\n    printf(\"compute_probs_unitStrides: checksum = %lf\\n\", s);\n\n    \n\n    threads_per_block = 96;\n    num_blocks = ceil(1.0 * n / threads_per_block);\n\n    memset(probs, 0, alphas_size_byte);\n    \n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      compute_probs_unitStrides_sharedMem(alphas, rands, probs, n, K, M,\n                                          threads_per_block, num_blocks);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n    \n    s = 0.0;\n    for (int i = 0; i < alphas_size; i++) s += probs[i];\n    printf(\"compute_probs_unitStrides_sharedMem: checksum = %lf\\n\", s);\n \n    free(t_alphas);\n    free(t_rands);\n  }\n\n  \n\n  free(alphas);\n  free(rands);\n  free(probs);\n  return 0;\n}"}}
{"kernel_name": "mcpr", "parallel_api": "sycl", "code": {"main.cpp": "#include <cstdio>\n#include <cstdlib>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n\n\n\ndouble* t(const double *idata, const int width, const int height)\n{\n  double *odata = (double*) malloc (sizeof(double) * width * height); \n  for (int yIndex = 0; yIndex < height; yIndex++) {\n    for (int xIndex = 0; xIndex < width; xIndex++) {\n      int index_in  = xIndex + width * yIndex;\n      int index_out = yIndex + height * xIndex;\n      odata[index_out] = idata[index_in];\n    }\n  }\n  return odata;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <path to filename> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  char *filename = argv[1];\n  const int repeat = atoi(argv[2]);\n\n  \n\n  const int n = 26280, K = 21, M = 10000;\n\n  FILE *fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    printf(\"Error: failed to open file alphas.csv. Exit\\n\");\n    return 1;\n  }\n\n  int alphas_size = n * K; \n\n  int alphas_size_byte = n * K * sizeof(double);\n\n  int rands_size = M * K;  \n\n  int rands_size_byte = M * K * sizeof(double);\n\n  double *alphas, *rands, *probs;\n  alphas = (double*) malloc (alphas_size_byte);\n  rands = (double*) malloc (rands_size_byte);\n  probs = (double*) malloc (alphas_size_byte);\n\n  \n\n  for (int i = 0; i < alphas_size; i++)\n    fscanf(fp, \"%lf\", &alphas[i]);\n  fclose(fp);\n\n  \n\n  std::mt19937 gen(19937);\n  std::normal_distribution<double> norm_dist(0.0,1.0);\n  for (int i = 0; i < rands_size; i++) rands[i] = norm_dist(gen); \n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double *d_alphas, *d_rands, *d_probs;\n  d_rands = (double*) sycl::malloc_device(rands_size_byte, q);\n  d_alphas = (double*) sycl::malloc_device(alphas_size_byte, q);\n  d_probs = (double*) sycl::malloc_device(alphas_size_byte, q);\n  q.memcpy(d_rands, rands, rands_size_byte);\n  q.memcpy(d_alphas, alphas, alphas_size_byte);\n\n  \n\n  int threads_per_block = 192;\n  sycl::range<1> lws (threads_per_block);\n  sycl::range<1> gws (ceil(1.0 * n / threads_per_block) * threads_per_block);\n\n  q.memset(d_probs, 0.0, alphas_size_byte);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k1>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        compute_probs(d_alphas, d_rands, d_probs, n, K, M, item);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(probs, d_probs, alphas_size_byte).wait();\n\n  double s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs: checksum = %lf\\n\", s);\n\n  \n\n  double *t_rands = t(rands, K, M);\n  double *t_alphas = t(alphas, K, n);\n  q.memcpy(d_rands, t_rands, rands_size_byte);\n  q.memcpy(d_alphas, t_alphas, alphas_size_byte);\n\n  q.memset(d_probs, 0.0, alphas_size_byte);\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k2>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        compute_probs_unitStrides(d_alphas, d_rands, d_probs, n, K, M, item);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(probs, d_probs, alphas_size_byte).wait();\n\n  s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs_unitStrides: checksum = %lf\\n\", s);\n\n  \n\n  threads_per_block = 96;\n  sycl::range<1> lws2 (threads_per_block);\n  sycl::range<1> gws2 (ceil(1.0 * n / threads_per_block) * threads_per_block);\n\n  q.memset(d_probs, 0.0, alphas_size_byte);\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<double, 1> sm (sycl::range<1>(K * threads_per_block * 2), cgh);\n      cgh.parallel_for<class k3>(\n        sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n        compute_probs_unitStrides_sharedMem(d_alphas, d_rands, d_probs, n, K, M,\n                                            sm.get_pointer(), item);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(probs, d_probs, alphas_size_byte).wait();\n\n  s = 0.0;\n  for (int i = 0; i < alphas_size; i++) s += probs[i];\n  printf(\"compute_probs_unitStrides_sharedMem: checksum = %lf\\n\", s);\n\n  \n\n  sycl::free(d_alphas, q);\n  sycl::free(d_rands, q);\n  sycl::free(d_probs, q);\n  free(alphas);\n  free(rands);\n  free(t_alphas);\n  free(t_rands);\n  free(probs);\n  return 0;\n}\n"}}
{"kernel_name": "meanshift", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include <cuda.h>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  __global__ void mean_shift(const float *data, float *data_next) {\n    size_t tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    if (tid < N) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  __global__ void mean_shift_tiling(const float* data, float* data_next) {\n\n    \n\n    __shared__ float local_data[TILE_WIDTH * D];\n    __shared__ float valid_data[TILE_WIDTH];\n    \n\n    int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    int row = tid * D;\n    int local_row = threadIdx.x * D;\n    float new_position[D] = {0.f};\n    float tot_weight = 0.f;\n    \n\n    for (int t = 0; t < BLOCKS; ++t) {\n      int tid_in_tile = t * TILE_WIDTH + threadIdx.x;\n      if (tid_in_tile < N) {\n        int row_in_tile = tid_in_tile * D;\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = data[row_in_tile + j];\n        }\n        valid_data[threadIdx.x] = 1;\n      }\n      else {\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = 0;\n        }\n        valid_data[threadIdx.x] = 0;\n      }\n      __syncthreads();\n      for (int i = 0; i < TILE_WIDTH; ++i) {\n        int local_row_tile = i * D;\n        float valid_radius = RADIUS * valid_data[i];\n        float sq_dist = 0.;\n        for (int j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                     (data[row + j] - local_data[local_row_tile + j]);\n        }\n        if (sq_dist <= valid_radius) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (int j = 0; j < D; ++j) {\n            new_position[j] += (weight * local_data[local_row_tile + j]);\n          }\n          tot_weight += (weight * valid_data[i]);\n        }\n      }\n      __syncthreads();\n    }\n    if (tid < N) {\n      for (int j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result;\n\n  \n\n  float *d_data;\n  float *d_data_next;\n  size_t data_bytes = N * D * sizeof(float);\n  cudaMalloc((void**)&d_data, data_bytes);\n  cudaMalloc((void**)&d_data_next, data_bytes);\n\n  \n\n  cudaMemcpy(d_data, data.data(), data_bytes, cudaMemcpyHostToDevice);\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    mean_shift::gpu::mean_shift<<<BLOCKS, THREADS>>>(d_data, d_data_next);\n    cudaDeviceSynchronize();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (base) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  cudaMemcpy(result.data(), d_data, data_bytes, cudaMemcpyDeviceToHost);\n  auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  \n\n  cudaMemcpy(d_data, data.data(), data_bytes, cudaMemcpyHostToDevice);\n\n  start = std::chrono::steady_clock::now();\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    mean_shift::gpu::mean_shift_tiling<<<BLOCKS, THREADS>>>(d_data, d_data_next);\n    cudaDeviceSynchronize();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  cudaMemcpy(result.data(), d_data, data_bytes, cudaMemcpyDeviceToHost);\n\n  centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  cudaFree(d_data);\n  cudaFree(d_data_next);\n  return 0;\n}\n"}}
{"kernel_name": "meanshift", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include <hip/hip_runtime.h>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  __global__ void mean_shift(const float *data, float *data_next) {\n    size_t tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    if (tid < N) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  __global__ void mean_shift_tiling(const float* data, float* data_next) {\n\n    \n\n    __shared__ float local_data[TILE_WIDTH * D];\n    __shared__ float valid_data[TILE_WIDTH];\n    \n\n    int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n    int row = tid * D;\n    int local_row = threadIdx.x * D;\n    float new_position[D] = {0.f};\n    float tot_weight = 0.f;\n    \n\n    for (int t = 0; t < BLOCKS; ++t) {\n      int tid_in_tile = t * TILE_WIDTH + threadIdx.x;\n      if (tid_in_tile < N) {\n        int row_in_tile = tid_in_tile * D;\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = data[row_in_tile + j];\n        }\n        valid_data[threadIdx.x] = 1;\n      }\n      else {\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = 0;\n        }\n        valid_data[threadIdx.x] = 0;\n      }\n      __syncthreads();\n      for (int i = 0; i < TILE_WIDTH; ++i) {\n        int local_row_tile = i * D;\n        float valid_radius = RADIUS * valid_data[i];\n        float sq_dist = 0.;\n        for (int j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                     (data[row + j] - local_data[local_row_tile + j]);\n        }\n        if (sq_dist <= valid_radius) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (int j = 0; j < D; ++j) {\n            new_position[j] += (weight * local_data[local_row_tile + j]);\n          }\n          tot_weight += (weight * valid_data[i]);\n        }\n      }\n      __syncthreads();\n    }\n    if (tid < N) {\n      for (int j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result;\n\n  \n\n  float *d_data;\n  float *d_data_next;\n  size_t data_bytes = N * D * sizeof(float);\n  hipMalloc((void**)&d_data, data_bytes);\n  hipMalloc((void**)&d_data_next, data_bytes);\n\n  \n\n  hipMemcpy(d_data, data.data(), data_bytes, hipMemcpyHostToDevice);\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    hipLaunchKernelGGL(mean_shift::gpu::mean_shift, BLOCKS, THREADS, 0, 0, d_data, d_data_next);\n    hipDeviceSynchronize();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (base) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  hipMemcpy(result.data(), d_data, data_bytes, hipMemcpyDeviceToHost);\n  auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  \n\n  hipMemcpy(d_data, data.data(), data_bytes, hipMemcpyHostToDevice);\n\n  start = std::chrono::steady_clock::now();\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    hipLaunchKernelGGL(mean_shift::gpu::mean_shift_tiling, BLOCKS, THREADS, 0, 0, d_data, d_data_next);\n    hipDeviceSynchronize();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  hipMemcpy(result.data(), d_data, data_bytes, hipMemcpyDeviceToHost);\n  centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n\n  hipFree(d_data);\n  hipFree(d_data_next);\n  return 0;\n}\n"}}
{"kernel_name": "meanshift", "parallel_api": "omp", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include <omp.h>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  void mean_shift(const float *data, float *data_next,\n                  const int teams, const int threads) {\n    #pragma omp target teams distribute parallel for num_teams(teams) thread_limit(64)\n    for (size_t tid = 0; tid < N; tid++) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  void mean_shift_tiling(const float* data, float* data_next,\n                         const int teams, const int threads) {\n    #pragma omp target teams num_teams(teams) thread_limit(threads)\n    {\n      float local_data[TILE_WIDTH * D];\n      float valid_data[TILE_WIDTH];\n      #pragma omp parallel \n      {\n        int lid = omp_get_thread_num();\n        int bid = omp_get_team_num();\n        int tid = bid * omp_get_num_threads() + lid;\n        int row = tid * D;\n        int local_row = lid * D;\n        float new_position[D] = {0.f};\n        float tot_weight = 0.f;\n        \n\n        for (int t = 0; t < BLOCKS; ++t) {\n          int tid_in_tile = t * TILE_WIDTH + lid;\n          if (tid_in_tile < N) {\n            int row_in_tile = tid_in_tile * D;\n            for (int j = 0; j < D; ++j) {\n              local_data[local_row + j] = data[row_in_tile + j];\n            }\n            valid_data[lid] = 1;\n          }\n          else {\n            for (int j = 0; j < D; ++j) {\n              local_data[local_row + j] = 0;\n            }\n            valid_data[lid] = 0;\n          }\n          #pragma omp barrier\n          for (int i = 0; i < TILE_WIDTH; ++i) {\n            int local_row_tile = i * D;\n            float valid_radius = RADIUS * valid_data[i];\n            float sq_dist = 0.;\n            for (int j = 0; j < D; ++j) {\n              sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                         (data[row + j] - local_data[local_row_tile + j]);\n            }\n            if (sq_dist <= valid_radius) {\n              float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n              for (int j = 0; j < D; ++j) {\n                new_position[j] += (weight * local_data[local_row_tile + j]);\n              }\n              tot_weight += (weight * valid_data[i]);\n            }\n          }\n          #pragma omp barrier\n        }\n        if (tid < N) {\n          for (int j = 0; j < D; ++j) {\n            data_next[row + j] = new_position[j] / tot_weight;\n          }\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result = data;\n\n  \n\n  size_t data_bytes = N * D * sizeof(float);\n  float *d_data = result.data();\n  float *d_data_next = (float*) malloc (data_bytes);\n\n  \n\n  #pragma omp target data map(to: d_data[0:N*D]) map(alloc: d_data_next[0:N*D])\n  {\n    \n\n    auto start = std::chrono::steady_clock::now();\n\n    for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n      mean_shift::gpu::mean_shift(d_data, d_data_next, BLOCKS, THREADS);\n      mean_shift::gpu::utils::swap(d_data, d_data_next);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"\\nAverage execution time of mean-shift (base) \"\n              << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n    \n\n    #pragma omp target update from (d_data[0:N*D])\n    auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n    bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n    if (centroids.size() == M && are_close)\n       std::cout << \"PASS\\n\";\n    else\n       std::cout << \"FAIL\\n\";\n\n    \n\n    result = data;\n    #pragma omp target update to (d_data[0:N*D])\n\n    start = std::chrono::steady_clock::now();\n    for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n      mean_shift::gpu::mean_shift_tiling(d_data, d_data_next, BLOCKS, THREADS);\n      mean_shift::gpu::utils::swap(d_data, d_data_next);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n              << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n    \n\n    #pragma omp target update from (d_data[0:N*D])\n    centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n    are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n    if (centroids.size() == M && are_close)\n       std::cout << \"PASS\\n\";\n    else\n       std::cout << \"FAIL\\n\";\n  }\n\n  free(d_data_next);\n  return 0;\n}\n"}}
{"kernel_name": "meanshift", "parallel_api": "serial", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  void mean_shift(const float *data, float *data_next,\n                  const int teams, const int threads) {\n        for (size_t tid = 0; tid < N; tid++) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  void mean_shift_tiling(const float* data, float* data_next,\n                         const int teams, const int threads) {\n        {\n      float local_data[TILE_WIDTH * D];\n      float valid_data[TILE_WIDTH];\n            {\n        int lid = omp_get_thread_num();\n        int bid = omp_get_team_num();\n        int tid = bid * omp_get_num_threads() + lid;\n        int row = tid * D;\n        int local_row = lid * D;\n        float new_position[D] = {0.f};\n        float tot_weight = 0.f;\n        \n\n        for (int t = 0; t < BLOCKS; ++t) {\n          int tid_in_tile = t * TILE_WIDTH + lid;\n          if (tid_in_tile < N) {\n            int row_in_tile = tid_in_tile * D;\n            for (int j = 0; j < D; ++j) {\n              local_data[local_row + j] = data[row_in_tile + j];\n            }\n            valid_data[lid] = 1;\n          }\n          else {\n            for (int j = 0; j < D; ++j) {\n              local_data[local_row + j] = 0;\n            }\n            valid_data[lid] = 0;\n          }\n                    for (int i = 0; i < TILE_WIDTH; ++i) {\n            int local_row_tile = i * D;\n            float valid_radius = RADIUS * valid_data[i];\n            float sq_dist = 0.;\n            for (int j = 0; j < D; ++j) {\n              sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                         (data[row + j] - local_data[local_row_tile + j]);\n            }\n            if (sq_dist <= valid_radius) {\n              float weight = expf(-sq_dist / DBL_SIGMA_SQ);\n              for (int j = 0; j < D; ++j) {\n                new_position[j] += (weight * local_data[local_row_tile + j]);\n              }\n              tot_weight += (weight * valid_data[i]);\n            }\n          }\n                  }\n        if (tid < N) {\n          for (int j = 0; j < D; ++j) {\n            data_next[row + j] = new_position[j] / tot_weight;\n          }\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result = data;\n\n  \n\n  size_t data_bytes = N * D * sizeof(float);\n  float *d_data = result.data();\n  float *d_data_next = (float*) malloc (data_bytes);\n\n  \n\n    {\n    \n\n    auto start = std::chrono::steady_clock::now();\n\n    for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n      mean_shift::gpu::mean_shift(d_data, d_data_next, BLOCKS, THREADS);\n      mean_shift::gpu::utils::swap(d_data, d_data_next);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"\\nAverage execution time of mean-shift (base) \"\n              << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n    \n\n        auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n    bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n    if (centroids.size() == M && are_close)\n       std::cout << \"PASS\\n\";\n    else\n       std::cout << \"FAIL\\n\";\n\n    \n\n    result = data;\n    \n    start = std::chrono::steady_clock::now();\n    for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n      mean_shift::gpu::mean_shift_tiling(d_data, d_data_next, BLOCKS, THREADS);\n      mean_shift::gpu::utils::swap(d_data, d_data_next);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n              << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n    \n\n        centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n    are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n    if (centroids.size() == M && are_close)\n       std::cout << \"PASS\\n\";\n    else\n       std::cout << \"FAIL\\n\";\n  }\n\n  free(d_data_next);\n  return 0;\n}"}}
{"kernel_name": "meanshift", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <chrono>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n#include \"constants.h\"\n\nnamespace mean_shift::gpu {\n  void mean_shift(sycl::nd_item<1> &item, const float *data, float *data_next) {\n    size_t tid = item.get_global_id(0);\n    if (tid < N) {\n      size_t row = tid * D;\n      float new_position[D] = {0.f};\n      float tot_weight = 0.f;\n      for (size_t i = 0; i < N; ++i) {\n        size_t row_n = i * D;\n        float sq_dist = 0.f;\n        for (size_t j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - data[row_n + j]) * (data[row + j] - data[row_n + j]);\n        }\n        if (sq_dist <= RADIUS) {\n          float weight = sycl::exp(-sq_dist / DBL_SIGMA_SQ);\n          for (size_t j = 0; j < D; ++j) {\n            new_position[j] += weight * data[row_n + j];\n          }\n          tot_weight += weight;\n        }\n      }\n      for (size_t j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n\n  void mean_shift_tiling(sycl::nd_item<1> &item,\n                         float *__restrict local_data,\n                         float *__restrict valid_data,\n                         const float* data,\n                               float*__restrict data_next) {\n\n    \n\n    \n\n    int tid = item.get_global_id(0);\n    int lid = item.get_local_id(0);\n    int row = tid * D;\n    int local_row = lid * D;\n    float new_position[D] = {0.f};\n    float tot_weight = 0.f;\n    \n\n    for (int t = 0; t < BLOCKS; ++t) {\n      int tid_in_tile = t * TILE_WIDTH + lid;\n      if (tid_in_tile < N) {\n        int row_in_tile = tid_in_tile * D;\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = data[row_in_tile + j];\n        }\n        valid_data[lid] = 1;\n      }\n      else {\n        for (int j = 0; j < D; ++j) {\n          local_data[local_row + j] = 0;\n        }\n        valid_data[lid] = 0;\n      }\n      item.barrier(sycl::access::fence_space::local_space);\n      for (int i = 0; i < TILE_WIDTH; ++i) {\n        int local_row_tile = i * D;\n        float valid_radius = RADIUS * valid_data[i];\n        float sq_dist = 0.;\n        for (int j = 0; j < D; ++j) {\n          sq_dist += (data[row + j] - local_data[local_row_tile + j]) *\n                     (data[row + j] - local_data[local_row_tile + j]);\n        }\n        if (sq_dist <= valid_radius) {\n          float weight = sycl::exp(-sq_dist / DBL_SIGMA_SQ);\n          for (int j = 0; j < D; ++j) {\n            new_position[j] += (weight * local_data[local_row_tile + j]);\n          }\n          tot_weight += (weight * valid_data[i]);\n        }\n      }\n      item.barrier(sycl::access::fence_space::local_space);\n    }\n    if (tid < N) {\n      for (int j = 0; j < D; ++j) {\n        data_next[row + j] = new_position[j] / tot_weight;\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    std::cout << \"Usage: \" << argv[0] << \" <path to data> <path to centroids>\" << std::endl;\n    return 1;\n  }\n  const auto path_to_data = argv[1];\n  const auto path_to_centroids = argv[2];\n\n  constexpr auto N = mean_shift::gpu::N;\n  constexpr auto D = mean_shift::gpu::D;\n  constexpr auto M = mean_shift::gpu::M;\n  constexpr auto THREADS = mean_shift::gpu::THREADS;\n  constexpr auto BLOCKS = mean_shift::gpu::BLOCKS;\n  constexpr auto TILE_WIDTH = mean_shift::gpu::TILE_WIDTH;\n  constexpr auto DIST_TO_REAL = mean_shift::gpu::DIST_TO_REAL;\n\n  mean_shift::gpu::utils::print_info(path_to_data, N, D, BLOCKS, THREADS, TILE_WIDTH);\n\n  \n\n  const std::array<float, M * D> real = mean_shift::gpu::utils::load_csv<M, D>(path_to_centroids, ',');\n  std::array<float, N * D> data = mean_shift::gpu::utils::load_csv<N, D>(path_to_data, ',');\n  std::array<float, N * D> result {};\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  size_t data_bytes = N * D * sizeof(float);\n  float *d_data = (float*) sycl::malloc_device (data_bytes, q);\n  float *d_data_next = (float*) sycl::malloc_device (data_bytes, q);;\n\n  \n\n  q.memcpy(d_data, data.data(), data_bytes).wait();\n\n  sycl::range<1> gws (BLOCKS * THREADS);\n  sycl::range<1> lws (THREADS);\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class base>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        mean_shift::gpu::mean_shift(item, d_data, d_data_next);\n      });\n    }).wait();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (base) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  q.memcpy(result.data(), d_data, data_bytes).wait();\n  auto centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  bool are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  \n\n  q.memcpy(d_data, data.data(), data_bytes).wait();\n\n  start = std::chrono::steady_clock::now();\n  for (size_t i = 0; i < mean_shift::gpu::NUM_ITER; ++i) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> local_data (sycl::range<1>(TILE_WIDTH * D), cgh);\n      sycl::local_accessor<float, 1> valid_data (sycl::range<1>(TILE_WIDTH), cgh);\n      cgh.parallel_for<class opt>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        mean_shift::gpu::mean_shift_tiling(item, local_data.get_pointer(),\n                                           valid_data.get_pointer(),\n                                           d_data, d_data_next);\n      });\n    }).wait();\n    mean_shift::gpu::utils::swap(d_data, d_data_next);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"\\nAverage execution time of mean-shift (opt) \"\n            << (time * 1e-6f) / mean_shift::gpu::NUM_ITER << \" ms\\n\" << std::endl;\n\n  \n\n  q.memcpy(result.data(), d_data, data_bytes).wait();\n  centroids = mean_shift::gpu::utils::reduce_to_centroids<N, D>(result, mean_shift::gpu::MIN_DISTANCE);\n  are_close = mean_shift::gpu::utils::are_close_to_real<M, D>(centroids, real, DIST_TO_REAL);\n  if (centroids.size() == M && are_close)\n     std::cout << \"PASS\\n\";\n  else\n     std::cout << \"FAIL\\n\";\n\n  sycl::free(d_data, q);\n  sycl::free(d_data_next, q);\n  return 0;\n}\n"}}
{"kernel_name": "mrc", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"reference.h\"\n\n__global__\nvoid MRCGradient (\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\n__global__\nvoid MRCGradient2(\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n  float *d_X1, *d_X2, *d_O, *d_dX1, *d_dX2;\n  int *d_Y;\n  cudaMalloc((void**)&d_X1, size_bytes);\n  cudaMemcpy(d_X1, h_X1, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_X2, size_bytes);\n  cudaMemcpy(d_X2, h_X2, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_O, size_bytes);\n  cudaMemcpy(d_O, h_O, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_Y, size_bytes);\n  cudaMemcpy(d_Y, h_Y, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_dX1, size_bytes);\n  cudaMalloc((void**)&d_dX2, size_bytes);\n\n  dim3 grid ((length + 255) / 256);\n  dim3 block (256);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    MRCGradient <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n    MRCGradient2 <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n  }\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) \n    MRCGradient <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) \n    MRCGradient2 <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  cudaMemcpy(h_dX1, d_dX1, size_bytes, cudaMemcpyDeviceToHost); \n  cudaMemcpy(h_dX2, d_dX2, size_bytes, cudaMemcpyDeviceToHost); \n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_X1);\n  cudaFree(d_X2);\n  cudaFree(d_O);\n  cudaFree(d_Y);\n  cudaFree(d_dX1);\n  cudaFree(d_dX2);\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}\n"}}
{"kernel_name": "mrc", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n__global__\nvoid MRCGradient (\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\n__global__\nvoid MRCGradient2(\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n  float *d_X1, *d_X2, *d_O, *d_dX1, *d_dX2;\n  int *d_Y;\n  hipMalloc((void**)&d_X1, size_bytes);\n  hipMemcpy(d_X1, h_X1, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_X2, size_bytes);\n  hipMemcpy(d_X2, h_X2, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_O, size_bytes);\n  hipMemcpy(d_O, h_O, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_Y, size_bytes);\n  hipMemcpy(d_Y, h_Y, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_dX1, size_bytes);\n  hipMalloc((void**)&d_dX2, size_bytes);\n\n  dim3 grid ((length + 255) / 256);\n  dim3 block (256);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    MRCGradient <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n    MRCGradient2 <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n  }\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) \n    MRCGradient <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) \n    MRCGradient2 <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  hipMemcpy(h_dX1, d_dX1, size_bytes, hipMemcpyDeviceToHost); \n  hipMemcpy(h_dX2, d_dX2, size_bytes, hipMemcpyDeviceToHost); \n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_X1);\n  hipFree(d_X2);\n  hipFree(d_O);\n  hipFree(d_Y);\n  hipFree(d_dX1);\n  hipFree(d_dX2);\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}\n"}}
{"kernel_name": "mrc", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"reference.h\"\n\nvoid MRCGradient (\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict dX1, float*__restrict dX2) {\n  #pragma omp target teams distribute parallel for num_threads(256)\n  for (int i = 0; i < N; i++) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\nvoid MRCGradient2(\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict dX1, float*__restrict dX2) {\n  #pragma omp target teams distribute parallel for num_threads(256)\n  for (int i = 0; i < N; i++) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n  #pragma omp target data map(to: h_X1[0:length], \\\n                                  h_X2[0:length], \\\n                                  h_O[0:length], \\\n                                  h_Y[0:length]) \\\n                          map(from: h_dX1[0:length],\\\n                                    h_dX2[0:length])\n  {\n    \n\n    for (int i = 0; i < repeat; i++) {\n      MRCGradient(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n      MRCGradient2(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n    }\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) \n      MRCGradient(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) \n      MRCGradient2(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}\n"}}
{"kernel_name": "mrc", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\nvoid MRCGradient (\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict dX1, float*__restrict dX2) {\n    for (int i = 0; i < N; i++) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\nvoid MRCGradient2(\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict dX1, float*__restrict dX2) {\n    for (int i = 0; i < N; i++) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n    {\n    \n\n    for (int i = 0; i < repeat; i++) {\n      MRCGradient(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n      MRCGradient2(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n    }\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) \n      MRCGradient(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) \n      MRCGradient2(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}"}}
{"kernel_name": "mrc", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nvoid MRCGradient (\n    sycl::nd_item<1> &item,\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2) {\n  int i = item.get_global_id(0);\n  if (i < N) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\nvoid MRCGradient2(\n    sycl::nd_item<1> &item,\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2) {\n  int i = item.get_global_id(0);\n  if (i < N) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_X1, *d_X2, *d_O, *d_dX1, *d_dX2;\n  int *d_Y;\n  d_X1 = sycl::malloc_device<float>(length, q);\n  q.memcpy(d_X1, h_X1, size_bytes);\n\n  d_X2 = sycl::malloc_device<float>(length, q);\n  q.memcpy(d_X2, h_X2, size_bytes);\n\n  d_O = sycl::malloc_device<float>(length, q);\n  q.memcpy(d_O, h_O, size_bytes);\n\n  d_Y = sycl::malloc_device<int>(length, q);\n  q.memcpy(d_Y, h_Y, size_bytes);\n\n  d_dX1 = sycl::malloc_device<float>(length, q);\n  d_dX2 = sycl::malloc_device<float>(length, q);\n\n  sycl::range<1> gws ((length + 255) / 256 * 256);\n  sycl::range<1> lws (256);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        MRCGradient(item, length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n      });\n    });\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        MRCGradient2(item, length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n      });\n    });\n  }\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        MRCGradient(item, length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        MRCGradient2(item, length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  q.memcpy(h_dX1, d_dX1, size_bytes).wait();\n  q.memcpy(h_dX2, d_dX2, size_bytes).wait();\n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_X1, q);\n  sycl::free(d_X2, q);\n  sycl::free(d_O, q);\n  sycl::free(d_Y, q);\n  sycl::free(d_dX1, q);\n  sycl::free(d_dX2, q);\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}\n"}}
{"kernel_name": "nlll", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t, \n          typename index_t, int NLL_LOSS_THREADS>\n__global__\nvoid nll_loss_forward_reduce2d_kernel(\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n  __shared__ accscalar_t sm_inputs[NLL_LOSS_THREADS],\n                         acc_weight[NLL_LOSS_THREADS];\n\n  int tid = threadIdx.x;\n  sm_inputs[tid] = static_cast<accscalar_t>(0);\n  acc_weight[tid] = static_cast<accscalar_t>(0);\n\n  for (int i = tid; i < nframe; i += NLL_LOSS_THREADS) {\n    index_t t = target[i];\n    if (t != ignore_index) {\n      scalar_t cur_weight =\n          weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n      sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n      acc_weight[tid] += cur_weight;\n    }\n  }\n\n  __syncthreads();\n\n  if (tid == 0) {\n    accscalar_t output_acc = 0;\n    accscalar_t total_weight_acc = 0;\n    for (int i = 0; i < NLL_LOSS_THREADS; ++i) {\n      output_acc += sm_inputs[i];\n      total_weight_acc += acc_weight[i];\n    }\n    *total_weight = static_cast<scalar_t>(total_weight_acc);\n    if (size_average) {\n      *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n    } else {\n      *output = static_cast<scalar_t>(output_acc);\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  int64_t weights_size = nframe;\n  int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  int64_t target_size = nframe;\n  int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  int output_size_bytes = sizeof(scalar_t);\n\n  scalar_t h_output;\n  scalar_t h_total_weight;\n\n  scalar_t *d_output;\n  scalar_t *d_total_weight;\n  scalar_t *d_input;\n   index_t *d_target;\n  scalar_t *d_weights;\n\n  cudaMalloc((void**)&d_input, input_size_bytes); \n  cudaMemcpy(d_input, h_input, input_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_weights, weights_size_bytes); \n  cudaMemcpy(d_weights, h_weights, weights_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_target, target_size_bytes); \n  cudaMemcpy(d_target, h_target, target_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_total_weight, output_size_bytes); \n  cudaMalloc((void**)&d_output, output_size_bytes); \n\n  dim3 grid (1);\n  dim3 block (GPU_THREADS);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    nll_loss_forward_reduce2d_kernel\n      <scalar_t, scalar_t, index_t, GPU_THREADS>\n      <<<grid, block>>>(d_output,\n                        d_total_weight,\n                        d_input,\n                        d_target,\n                        d_weights,\n                        size_average,\n                        nframe,\n                        kdim,\n                        ignore_index);\n  }\n  cudaDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n  printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  cudaMemcpy(&h_output, d_output, output_size_bytes, cudaMemcpyDeviceToHost);\n  cudaMemcpy(&h_total_weight, d_total_weight, output_size_bytes, cudaMemcpyDeviceToHost);\n\n  bool ok = true;\n  if (fabs(h_output - r_output) > 1e-1 ||\n      fabs(h_total_weight - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output, (float)r_output, \n                            (float)h_total_weight, (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_output);\n  cudaFree(d_total_weight);\n  cudaFree(d_input);\n  cudaFree(d_target);\n  cudaFree(d_weights);\n}\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n  \n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}\n"}}
{"kernel_name": "nlll", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t, \n          typename index_t, int NLL_LOSS_THREADS>\n__global__\nvoid nll_loss_forward_reduce2d_kernel(\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n  __shared__ accscalar_t sm_inputs[NLL_LOSS_THREADS],\n                         acc_weight[NLL_LOSS_THREADS];\n\n  int tid = threadIdx.x;\n  sm_inputs[tid] = static_cast<accscalar_t>(0);\n  acc_weight[tid] = static_cast<accscalar_t>(0);\n\n  for (int i = tid; i < nframe; i += NLL_LOSS_THREADS) {\n    index_t t = target[i];\n    if (t != ignore_index) {\n      scalar_t cur_weight =\n          weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n      sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n      acc_weight[tid] += cur_weight;\n    }\n  }\n\n  __syncthreads();\n\n  if (tid == 0) {\n    accscalar_t output_acc = 0;\n    accscalar_t total_weight_acc = 0;\n    for (int i = 0; i < NLL_LOSS_THREADS; ++i) {\n      output_acc += sm_inputs[i];\n      total_weight_acc += acc_weight[i];\n    }\n    *total_weight = static_cast<scalar_t>(total_weight_acc);\n    if (size_average) {\n      *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n    } else {\n      *output = static_cast<scalar_t>(output_acc);\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  int64_t weights_size = nframe;\n  int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  int64_t target_size = nframe;\n  int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  int output_size_bytes = sizeof(scalar_t);\n\n  scalar_t h_output;\n  scalar_t h_total_weight;\n\n  scalar_t *d_output;\n  scalar_t *d_total_weight;\n  scalar_t *d_input;\n   index_t *d_target;\n  scalar_t *d_weights;\n\n  hipMalloc((void**)&d_input, input_size_bytes); \n  hipMemcpy(d_input, h_input, input_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_weights, weights_size_bytes); \n  hipMemcpy(d_weights, h_weights, weights_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_target, target_size_bytes); \n  hipMemcpy(d_target, h_target, target_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_total_weight, output_size_bytes); \n  hipMalloc((void**)&d_output, output_size_bytes); \n\n  dim3 grid (1);\n  dim3 block (GPU_THREADS);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    nll_loss_forward_reduce2d_kernel\n      <scalar_t, scalar_t, index_t, GPU_THREADS>\n      <<<grid, block>>>(d_output,\n                        d_total_weight,\n                        d_input,\n                        d_target,\n                        d_weights,\n                        size_average,\n                        nframe,\n                        kdim,\n                        ignore_index);\n  }\n  hipDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n  printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  hipMemcpy(&h_output, d_output, output_size_bytes, hipMemcpyDeviceToHost);\n  hipMemcpy(&h_total_weight, d_total_weight, output_size_bytes, hipMemcpyDeviceToHost);\n\n  bool ok = true;\n  if (fabs(h_output - r_output) > 1e-1 ||\n      fabs(h_total_weight - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output, (float)r_output, \n                            (float)h_total_weight, (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_output);\n  hipFree(d_total_weight);\n  hipFree(d_input);\n  hipFree(d_target);\n  hipFree(d_weights);\n}\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n  \n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}\n"}}
{"kernel_name": "nlll", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t, \n          typename index_t, int NLL_LOSS_THREADS>\nvoid nll_loss_forward_reduce2d_kernel(\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n  #pragma omp target teams num_teams(1) thread_limit(NLL_LOSS_THREADS)\n  {\n    accscalar_t sm_inputs[NLL_LOSS_THREADS],\n                acc_weight[NLL_LOSS_THREADS];\n    #pragma omp parallel\n    {\n      int tid = omp_get_thread_num();\n      int nthreads = omp_get_num_threads();\n\n      sm_inputs[tid] = static_cast<accscalar_t>(0);\n      acc_weight[tid] = static_cast<accscalar_t>(0);\n\n      \n\n      for (int i = tid; i < nframe; i += nthreads) {\n        index_t t = target[i];\n        if (t != ignore_index) {\n          scalar_t cur_weight =\n              weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n          sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n          acc_weight[tid] += cur_weight;\n        }\n      }\n\n      #pragma omp barrier\n\n      if (tid == 0) {\n        accscalar_t output_acc = 0;\n        accscalar_t total_weight_acc = 0;\n        \n\n        for (int i = 0; i < nthreads; ++i) {\n          output_acc += sm_inputs[i];\n          total_weight_acc += acc_weight[i];\n        }\n        *total_weight = static_cast<scalar_t>(total_weight_acc);\n        if (size_average) {\n          *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n        } else {\n          *output = static_cast<scalar_t>(output_acc);\n        }\n      }\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t weights_size = nframe;\n  int64_t target_size = nframe;\n\n  scalar_t h_output[1];\n  scalar_t h_total_weight[1];\n\n  #pragma omp target data map(to: h_input[0:input_size], \\\n                                  h_weights[0:weights_size], \\\n                                  h_target[0:target_size]) \\\n                          map(from: h_output[0:1], h_total_weight[0:1])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      nll_loss_forward_reduce2d_kernel\n        <scalar_t, scalar_t, index_t, GPU_THREADS>(\n        h_output,\n        h_total_weight,\n        h_input,\n        h_target,\n        h_weights,\n        size_average,\n        nframe,\n        kdim,\n        ignore_index);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n    printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n\n  }\n\n  bool ok = true;\n  if (fabs(h_output[0] - r_output) > 1e-1 ||\n      fabs(h_total_weight[0] - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output[0], (float)r_output, \n                            (float)h_total_weight[0], (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n  \n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}\n"}}
{"kernel_name": "nlll", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t, \n          typename index_t, int NLL_LOSS_THREADS>\nvoid nll_loss_forward_reduce2d_kernel(\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n    {\n    accscalar_t sm_inputs[NLL_LOSS_THREADS],\n                acc_weight[NLL_LOSS_THREADS];\n        {\n      int tid = omp_get_thread_num();\n      int nthreads = omp_get_num_threads();\n\n      sm_inputs[tid] = static_cast<accscalar_t>(0);\n      acc_weight[tid] = static_cast<accscalar_t>(0);\n\n      \n\n      for (int i = tid; i < nframe; i += nthreads) {\n        index_t t = target[i];\n        if (t != ignore_index) {\n          scalar_t cur_weight =\n              weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n          sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n          acc_weight[tid] += cur_weight;\n        }\n      }\n\n      \n      if (tid == 0) {\n        accscalar_t output_acc = 0;\n        accscalar_t total_weight_acc = 0;\n        \n\n        for (int i = 0; i < nthreads; ++i) {\n          output_acc += sm_inputs[i];\n          total_weight_acc += acc_weight[i];\n        }\n        *total_weight = static_cast<scalar_t>(total_weight_acc);\n        if (size_average) {\n          *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n        } else {\n          *output = static_cast<scalar_t>(output_acc);\n        }\n      }\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t weights_size = nframe;\n  int64_t target_size = nframe;\n\n  scalar_t h_output[1];\n  scalar_t h_total_weight[1];\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      nll_loss_forward_reduce2d_kernel\n        <scalar_t, scalar_t, index_t, GPU_THREADS>(\n        h_output,\n        h_total_weight,\n        h_input,\n        h_target,\n        h_weights,\n        size_average,\n        nframe,\n        kdim,\n        ignore_index);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n    printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n\n  }\n\n  bool ok = true;\n  if (fabs(h_output[0] - r_output) > 1e-1 ||\n      fabs(h_total_weight[0] - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output[0], (float)r_output, \n                            (float)h_total_weight[0], (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n  \n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}"}}
{"kernel_name": "nlll", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t,\n          typename index_t, int NLL_LOSS_THREADS>\nvoid nll_loss_forward_reduce2d_kernel(\n    sycl::nd_item<1> &item,\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n   auto g = item.get_group();\n\n   sycl::multi_ptr<accscalar_t[NLL_LOSS_THREADS], sycl::access::address_space::local_space>\n     ip = sycl::ext::oneapi::group_local_memory_for_overwrite<accscalar_t[NLL_LOSS_THREADS]>(g);\n   accscalar_t* sm_inputs = *ip;\n\n   sycl::multi_ptr<accscalar_t[NLL_LOSS_THREADS], sycl::access::address_space::local_space>\n     wp = sycl::ext::oneapi::group_local_memory_for_overwrite<accscalar_t[NLL_LOSS_THREADS]>(g);\n   accscalar_t* acc_weight = *wp;\n\n  int tid = item.get_local_id(0);\n  sm_inputs[tid] = static_cast<accscalar_t>(0);\n  acc_weight[tid] = static_cast<accscalar_t>(0);\n\n  for (int i = tid; i < nframe; i += NLL_LOSS_THREADS) {\n    index_t t = target[i];\n    if (t != ignore_index) {\n      scalar_t cur_weight =\n          weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n      sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n      acc_weight[tid] += cur_weight;\n    }\n  }\n\n  group_barrier(g, sycl::memory_scope::work_group);\n\n  if (tid == 0) {\n    accscalar_t output_acc = 0;\n    accscalar_t total_weight_acc = 0;\n    for (int i = 0; i < NLL_LOSS_THREADS; ++i) {\n      output_acc += sm_inputs[i];\n      total_weight_acc += acc_weight[i];\n    }\n    *total_weight = static_cast<scalar_t>(total_weight_acc);\n    if (size_average) {\n      *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n    } else {\n      *output = static_cast<scalar_t>(output_acc);\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  int64_t weights_size = nframe;\n  int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  int64_t target_size = nframe;\n  int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  int output_size_bytes = sizeof(scalar_t);\n\n  scalar_t h_output;\n  scalar_t h_total_weight;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  scalar_t *d_output = sycl::malloc_device<scalar_t>(1, q);\n  scalar_t *d_total_weight = sycl::malloc_device<scalar_t>(1, q);\n  scalar_t *d_input = sycl::malloc_device<scalar_t>(input_size, q);\n   index_t *d_target = sycl::malloc_device<index_t>(target_size, q);\n  scalar_t *d_weights = sycl::malloc_device<scalar_t>(weights_size, q);\n\n  q.memcpy(d_input, h_input, input_size_bytes);\n\n  q.memcpy(d_weights, h_weights, weights_size_bytes);\n\n  q.memcpy(d_target, h_target, target_size_bytes);\n\n  sycl::range<1> gws (GPU_THREADS);\n  sycl::range<1> lws (GPU_THREADS);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        nll_loss_forward_reduce2d_kernel\n          <scalar_t, scalar_t, index_t, GPU_THREADS>(\n                        item,\n                        d_output,\n                        d_total_weight,\n                        d_input,\n                        d_target,\n                        d_weights,\n                        size_average,\n                        nframe,\n                        kdim,\n                        ignore_index);\n      });\n    });\n  }\n  q.wait();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n  printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  q.memcpy(&h_output, d_output, output_size_bytes);\n  q.memcpy(&h_total_weight, d_total_weight, output_size_bytes);\n  q.wait();\n\n  bool ok = true;\n  if (fabs(h_output - r_output) > 1e-1 || fabs(h_total_weight - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output, (float)r_output,\n                            (float)h_total_weight, (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_output, q);\n  sycl::free(d_total_weight, q);\n  sycl::free(d_input, q);\n  sycl::free(d_target, q);\n  sycl::free(d_weights, q);\n}\n\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n\n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}\n"}}
{"kernel_name": "overlay", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\ntemplate<typename T>\n__global__ void DetectionOverlayBox(\n  const T*__restrict__ input,\n        T*__restrict__  output,\n  int imgWidth, int imgHeight,\n  int x0, int y0, int boxWidth, int boxHeight,\n  const float4 color) \n{\n  const int box_x = blockIdx.x * blockDim.x + threadIdx.x;\n  const int box_y = blockIdx.y * blockDim.y + threadIdx.y;\n  \n  if( box_x >= boxWidth || box_y >= boxHeight ) return;\n  \n  const int x = box_x + x0;\n  const int y = box_y + y0;\n  \n  if( x >= imgWidth || y >= imgHeight ) return;\n  \n  T px = input[ y * imgWidth + x ];\n  \n  const float alpha = color.w / 255.0f;\n  const float ialph = 1.0f - alpha;\n  \n  px.x = alpha * color.x + ialph * px.x;\n  px.y = alpha * color.y + ialph * px.y;\n  px.z = alpha * color.z + ialph * px.z;\n  \n  output[y * imgWidth + x] = px;\n}\n\ntemplate<typename T>\nint DetectionOverlay(\n  T* input, T* output, uint32_t width, uint32_t height, \n  Box *detections, int numDetections, float4 colors )\n{\n  if( !input || !output || width == 0 || height == 0 || !detections || numDetections == 0)\n    return 1;\n  \t\t\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  \n  for( int n=0; n < numDetections; n++ )\n  {\n    const int boxWidth = detections[n].width;\n    const int boxHeight = detections[n].height;\n    const int boxLeft = detections[n].left;\n    const int boxTop = detections[n].top;\n    \n    \n\n    const dim3 blockDim(8, 8);\n    const dim3 gridDim((boxWidth+7)/8, (boxHeight+7)/8);\n    DetectionOverlayBox<T><<<gridDim, blockDim>>>(\n      input, output, width, height, boxLeft, boxTop, boxWidth, boxHeight, colors);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  return 0;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <width> <height>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int img_size = width * height;\n  const int img_size_byte = sizeof(float3) * width * height;\n\n  srand(123);\n  float3 *input = (float3*) malloc (img_size_byte);\n  float3 *output = (float3*) malloc (img_size_byte);\n  float3 *ref_output = (float3*) malloc (img_size_byte);\n\n  for (int i = 0; i < img_size; i++) {\n    ref_output[i].x = input[i].x = rand() % 256; \n    ref_output[i].y = input[i].y = rand() % 256; \n    ref_output[i].z = input[i].z = rand() % 256; \n  }\n   \n  float3 *d_input, *d_output;\n  cudaMalloc((void**)&d_input, img_size_byte);\n  cudaMalloc((void**)&d_output, img_size_byte);\n  cudaMemcpy(d_input, input, img_size_byte, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_output, d_input, img_size_byte, cudaMemcpyDeviceToDevice);\n\n  const int numDetections = img_size * 0.8f;\n  Box* detections = (Box*) malloc (numDetections * sizeof(Box));\n  for (int i = 0; i < numDetections; i++) {\n    detections[i].width = 64 + rand() % 128;\n    detections[i].height = 64 + rand() % 128;\n    detections[i].left = rand() % (width - 64);\n    detections[i].top = rand() % (height - 64);\n  }\n   \n  float4 colors = make_float4(255, 204, 203, 1); \n\n  DetectionOverlay<float3>(d_input, d_output, width, height, detections, numDetections, colors);  \n\n  reference<float3>(input, ref_output, width, height, detections, numDetections, colors);  \n\n  cudaMemcpy(output, d_output, img_size_byte, cudaMemcpyDeviceToHost);\n\n  bool ok = true;\n  for (int i = 0; i < img_size; i++) \n    if ((fabsf(ref_output[i].x - output[i].x) > 1e-3f) ||\n        (fabsf(ref_output[i].y - output[i].y) > 1e-3f) ||\n        (fabsf(ref_output[i].z - output[i].z) > 1e-3f)) {\n      printf(\"Error at index %d\\n\", i);\n      ok = false;\n      break;\n    }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_input);\n  cudaFree(d_output);\n  free(input);\n  free(output);\n  free(ref_output);\n  free(detections);\n  return 0;\n}\n"}}
{"kernel_name": "overlay", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\ntemplate<typename T>\n__global__ void DetectionOverlayBox(\n  const T*__restrict__ input,\n        T*__restrict__  output,\n  int imgWidth, int imgHeight,\n  int x0, int y0, int boxWidth, int boxHeight,\n  const float4 color) \n{\n  const int box_x = blockIdx.x * blockDim.x + threadIdx.x;\n  const int box_y = blockIdx.y * blockDim.y + threadIdx.y;\n  \n  if( box_x >= boxWidth || box_y >= boxHeight ) return;\n  \n  const int x = box_x + x0;\n  const int y = box_y + y0;\n  \n  if( x >= imgWidth || y >= imgHeight ) return;\n  \n  T px = input[ y * imgWidth + x ];\n  \n  const float alpha = color.w / 255.0f;\n  const float ialph = 1.0f - alpha;\n  \n  px.x = alpha * color.x + ialph * px.x;\n  px.y = alpha * color.y + ialph * px.y;\n  px.z = alpha * color.z + ialph * px.z;\n  \n  output[y * imgWidth + x] = px;\n}\n\ntemplate<typename T>\nint DetectionOverlay(\n  T* input, T* output, uint32_t width, uint32_t height, \n  Box *detections, int numDetections, float4 colors )\n{\n  if( !input || !output || width == 0 || height == 0 || !detections || numDetections == 0)\n    return 1;\n  \t\t\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  \n  for( int n=0; n < numDetections; n++ )\n  {\n    const int boxWidth = detections[n].width;\n    const int boxHeight = detections[n].height;\n    const int boxLeft = detections[n].left;\n    const int boxTop = detections[n].top;\n    \n    \n\n    const dim3 blockDim(8, 8);\n    const dim3 gridDim((boxWidth+7)/8, (boxHeight+7)/8);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(DetectionOverlayBox<T>), gridDim, blockDim, 0, 0, \n      input, output, width, height, boxLeft, boxTop, boxWidth, boxHeight, colors);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  return 0;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <width> <height>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int img_size = width * height;\n  const int img_size_byte = sizeof(float3) * width * height;\n\n  srand(123);\n  float3 *input = (float3*) malloc (img_size_byte);\n  float3 *output = (float3*) malloc (img_size_byte);\n  float3 *ref_output = (float3*) malloc (img_size_byte);\n\n  for (int i = 0; i < img_size; i++) {\n    ref_output[i].x = input[i].x = rand() % 256; \n    ref_output[i].y = input[i].y = rand() % 256; \n    ref_output[i].z = input[i].z = rand() % 256; \n  }\n   \n  float3 *d_input, *d_output;\n  hipMalloc((void**)&d_input, img_size_byte);\n  hipMalloc((void**)&d_output, img_size_byte);\n  hipMemcpy(d_input, input, img_size_byte, hipMemcpyHostToDevice);\n  hipMemcpy(d_output, d_input, img_size_byte, hipMemcpyDeviceToDevice);\n\n  const int numDetections = img_size * 0.8f;\n  Box* detections = (Box*) malloc (numDetections * sizeof(Box));\n  for (int i = 0; i < numDetections; i++) {\n    detections[i].width = 64 + rand() % 128;\n    detections[i].height = 64 + rand() % 128;\n    detections[i].left = rand() % (width - 64);\n    detections[i].top = rand() % (height - 64);\n  }\n   \n  float4 colors = make_float4(255, 204, 203, 1); \n\n  DetectionOverlay<float3>(d_input, d_output, width, height, detections, numDetections, colors);  \n\n  reference<float3>(input, ref_output, width, height, detections, numDetections, colors);  \n\n  hipMemcpy(output, d_output, img_size_byte, hipMemcpyDeviceToHost);\n\n  bool ok = true;\n  for (int i = 0; i < img_size; i++) \n    if ((fabsf(ref_output[i].x - output[i].x) > 1e-3f) ||\n        (fabsf(ref_output[i].y - output[i].y) > 1e-3f) ||\n        (fabsf(ref_output[i].z - output[i].z) > 1e-3f)) {\n      printf(\"Error at index %d\\n\", i);\n      ok = false;\n      break;\n    }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_input);\n  hipFree(d_output);\n  free(input);\n  free(output);\n  free(ref_output);\n  free(detections);\n  return 0;\n}\n"}}
{"kernel_name": "overlay", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\ntemplate<typename T>\nvoid DetectionOverlayBox(\n  const T*__restrict input,\n        T*__restrict output,\n  int imgWidth, int imgHeight,\n  int x0, int y0, int boxWidth, int boxHeight,\n  const float4 color) \n{\n  #pragma omp target teams distribute parallel for collapse(2) thread_limit(64)\n  for(int box_y = 0; box_y < boxHeight; box_y++)\n    for(int box_x = 0; box_x < boxWidth; box_x++) {\n  \n      const int x = box_x + x0;\n      const int y = box_y + y0;\n      \n      if( x < imgWidth && y < imgHeight ) {\n      \n        T px = input[ y * imgWidth + x ];\n        \n        const float alpha = color.w / 255.0f;\n        const float ialph = 1.0f - alpha;\n        \n        px.x = alpha * color.x + ialph * px.x;\n        px.y = alpha * color.y + ialph * px.y;\n        px.z = alpha * color.z + ialph * px.z;\n        \n        output[y * imgWidth + x] = px;\n      }\n    }\n}\n\ntemplate<typename T>\nint DetectionOverlay(\n  T* input, T* output, uint32_t width, uint32_t height, \n  Box *detections, int numDetections, float4 colors )\n{\n  if( !input || !output || width == 0 || height == 0 || !detections || numDetections == 0)\n    return 1;\n  \t\t\n  auto start = std::chrono::steady_clock::now();\n\n  for( int n=0; n < numDetections; n++ )\n  {\n    const int boxWidth = detections[n].width;\n    const int boxHeight = detections[n].height;\n    const int boxLeft = detections[n].left;\n    const int boxTop = detections[n].top;\n    \n    \n\n    DetectionOverlayBox<T>(\n      input, output, width, height, boxLeft, boxTop, boxWidth, boxHeight, colors);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  return 0;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <width> <height>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int img_size = width * height;\n  const int img_size_byte = sizeof(float3) * width * height;\n\n  srand(123);\n  float3 *input = (float3*) malloc (img_size_byte);\n  float3 *output = (float3*) malloc (img_size_byte);\n  float3 *ref_output = (float3*) malloc (img_size_byte);\n\n  for (int i = 0; i < img_size; i++) {\n    output[i].x = ref_output[i].x = input[i].x = rand() % 256; \n    output[i].y = ref_output[i].y = input[i].y = rand() % 256; \n    output[i].z = ref_output[i].z = input[i].z = rand() % 256; \n  }\n   \n  float4 colors = {255, 204, 203, 1};\n\n  const int numDetections = img_size * 0.8f;\n  Box* detections = (Box*) malloc (numDetections * sizeof(Box));\n  for (int i = 0; i < numDetections; i++) {\n    detections[i].width = 64 + rand() % 128;\n    detections[i].height = 64 + rand() % 128;\n    detections[i].left = rand() % (width - 64);\n    detections[i].top = rand() % (height - 64);\n  }\n\n  \n\n  #pragma omp target data map (to: input[0:img_size]) \\\n                          map (tofrom: output[0:img_size])\n  {\n    DetectionOverlay<float3>(input, output, width, height, detections, numDetections, colors);  \n  }\n\n  reference<float3>(input, ref_output, width, height, detections, numDetections, colors);  \n\n  bool ok = true;\n  for (int i = 0; i < img_size; i++) \n    if ((fabsf(ref_output[i].x - output[i].x) > 1e-3f) ||\n        (fabsf(ref_output[i].y - output[i].y) > 1e-3f) ||\n        (fabsf(ref_output[i].z - output[i].z) > 1e-3f)) {\n      printf(\"Error at index %d\\n\", i);\n      ok = false;\n      break;\n    }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(input);\n  free(output);\n  free(ref_output);\n  free(detections);\n  return 0;\n}\n"}}
{"kernel_name": "overlay", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\ntemplate<typename T>\nvoid DetectionOverlayBox(\n  const T*__restrict input,\n        T*__restrict output,\n  int imgWidth, int imgHeight,\n  int x0, int y0, int boxWidth, int boxHeight,\n  const float4 color) \n{\n    for(int box_y = 0; box_y < boxHeight; box_y++)\n    for(int box_x = 0; box_x < boxWidth; box_x++) {\n  \n      const int x = box_x + x0;\n      const int y = box_y + y0;\n      \n      if( x < imgWidth && y < imgHeight ) {\n      \n        T px = input[ y * imgWidth + x ];\n        \n        const float alpha = color.w / 255.0f;\n        const float ialph = 1.0f - alpha;\n        \n        px.x = alpha * color.x + ialph * px.x;\n        px.y = alpha * color.y + ialph * px.y;\n        px.z = alpha * color.z + ialph * px.z;\n        \n        output[y * imgWidth + x] = px;\n      }\n    }\n}\n\ntemplate<typename T>\nint DetectionOverlay(\n  T* input, T* output, uint32_t width, uint32_t height, \n  Box *detections, int numDetections, float4 colors )\n{\n  if( !input || !output || width == 0 || height == 0 || !detections || numDetections == 0)\n    return 1;\n  \t\t\n  auto start = std::chrono::steady_clock::now();\n\n  for( int n=0; n < numDetections; n++ )\n  {\n    const int boxWidth = detections[n].width;\n    const int boxHeight = detections[n].height;\n    const int boxLeft = detections[n].left;\n    const int boxTop = detections[n].top;\n    \n    \n\n    DetectionOverlayBox<T>(\n      input, output, width, height, boxLeft, boxTop, boxWidth, boxHeight, colors);\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  return 0;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <width> <height>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int img_size = width * height;\n  const int img_size_byte = sizeof(float3) * width * height;\n\n  srand(123);\n  float3 *input = (float3*) malloc (img_size_byte);\n  float3 *output = (float3*) malloc (img_size_byte);\n  float3 *ref_output = (float3*) malloc (img_size_byte);\n\n  for (int i = 0; i < img_size; i++) {\n    output[i].x = ref_output[i].x = input[i].x = rand() % 256; \n    output[i].y = ref_output[i].y = input[i].y = rand() % 256; \n    output[i].z = ref_output[i].z = input[i].z = rand() % 256; \n  }\n   \n  float4 colors = {255, 204, 203, 1};\n\n  const int numDetections = img_size * 0.8f;\n  Box* detections = (Box*) malloc (numDetections * sizeof(Box));\n  for (int i = 0; i < numDetections; i++) {\n    detections[i].width = 64 + rand() % 128;\n    detections[i].height = 64 + rand() % 128;\n    detections[i].left = rand() % (width - 64);\n    detections[i].top = rand() % (height - 64);\n  }\n\n  \n\n    {\n    DetectionOverlay<float3>(input, output, width, height, detections, numDetections, colors);  \n  }\n\n  reference<float3>(input, ref_output, width, height, detections, numDetections, colors);  \n\n  bool ok = true;\n  for (int i = 0; i < img_size; i++) \n    if ((fabsf(ref_output[i].x - output[i].x) > 1e-3f) ||\n        (fabsf(ref_output[i].y - output[i].y) > 1e-3f) ||\n        (fabsf(ref_output[i].z - output[i].z) > 1e-3f)) {\n      printf(\"Error at index %d\\n\", i);\n      ok = false;\n      break;\n    }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(input);\n  free(output);\n  free(ref_output);\n  free(detections);\n  return 0;\n}"}}
{"kernel_name": "overlay", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\ntemplate <typename T>\nclass overlay;\n\ntemplate<typename T>\nvoid DetectionOverlayBox(\n  sycl::nd_item<2> &item,\n  const T*__restrict input,\n        T*__restrict output,\n  int imgWidth, int imgHeight,\n  int x0, int y0, int boxWidth, int boxHeight,\n  const float4 color)\n{\n  const int box_x = item.get_global_id(1);\n  const int box_y = item.get_global_id(0);\n\n  if( box_x >= boxWidth || box_y >= boxHeight ) return;\n\n  const int x = box_x + x0;\n  const int y = box_y + y0;\n\n  if( x >= imgWidth || y >= imgHeight ) return;\n\n  T px = input[ y * imgWidth + x ];\n\n  const float alpha = color.w() / 255.0f;\n  const float ialph = 1.0f - alpha;\n\n  px.x() = alpha * color.x() + ialph * px.x();\n  px.y() = alpha * color.y() + ialph * px.y();\n  px.z() = alpha * color.z() + ialph * px.z();\n\n  output[y * imgWidth + x] = px;\n}\n\ntemplate<typename T>\nint DetectionOverlay(\n  sycl::queue &q,\n  T *input, T *output, uint32_t width, uint32_t height,\n  Box *detections, int numDetections, float4 colors)\n{\n  if( width == 0 || height == 0 || !detections || numDetections == 0)\n    return 1;\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for( int n=0; n < numDetections; n++ )\n  {\n    const int boxWidth = detections[n].width;\n    const int boxHeight = detections[n].height;\n    const int boxLeft = detections[n].left;\n    const int boxTop = detections[n].top;\n\n    \n\n    const sycl::range<2> lws (8, 8);\n    const sycl::range<2> gws ((boxHeight+7)/8*8, (boxWidth+7)/8*8);\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class overlay<T>>(sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        DetectionOverlayBox<T>(item, input, output,\n          width, height, boxLeft, boxTop, boxWidth, boxHeight, colors);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  return 0;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <width> <height>\\n\", argv[0]);\n    return 1;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int img_size = width * height;\n  const int img_size_byte = sizeof(float3) * width * height;\n\n  srand(123);\n  float3 *input = (float3*) malloc (img_size_byte);\n  float3 *output = (float3*) malloc (img_size_byte);\n  float3 *ref_output = (float3*) malloc (img_size_byte);\n\n  for (int i = 0; i < img_size; i++) {\n    ref_output[i].x() = input[i].x() = rand() % 256;\n    ref_output[i].y() = input[i].y() = rand() % 256;\n    ref_output[i].z() = input[i].z() = rand() % 256;\n  }\n\n  float3 *d_input = sycl::malloc_device<float3>(img_size, q);\n  q.memcpy(d_input, input, img_size_byte);\n\n  float3 *d_output = sycl::malloc_device<float3>(img_size, q);\n  q.memcpy(d_output, d_input, img_size_byte);\n\n  const int numDetections = img_size * 0.8f;\n  Box* detections = (Box*) malloc (numDetections * sizeof(Box));\n  for (int i = 0; i < numDetections; i++) {\n    detections[i].width = 64 + rand() % 128;\n    detections[i].height = 64 + rand() % 128;\n    detections[i].left = rand() % (width - 64);\n    detections[i].top = rand() % (height - 64);\n  }\n\n  float4 colors = {255, 204, 203, 1};\n\n  DetectionOverlay<float3>(q, d_input, d_output, width, height, detections, numDetections, colors);\n\n  reference<float3>(input, ref_output, width, height, detections, numDetections, colors);\n\n  q.memcpy(output, d_output, img_size_byte).wait();\n\n  bool ok = true;\n  for (int i = 0; i < img_size; i++)\n    if ((fabsf(ref_output[i].x() - output[i].x()) > 1e-3f) ||\n        (fabsf(ref_output[i].y() - output[i].y()) > 1e-3f) ||\n        (fabsf(ref_output[i].z() - output[i].z()) > 1e-3f)) {\n      printf(\"Error at index %d\\n\", i);\n      ok = false;\n      break;\n    }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_input, q);\n  sycl::free(d_output, q);\n  free(input);\n  free(output);\n  free(ref_output);\n  free(detections);\n  return 0;\n}\n"}}
{"kernel_name": "p4", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <cuda.h>\n#include \"params.h\"\n\n__device__\nfloat sigmoid(const float x) { return 1.0f / (1.0f + expf(-x)); }\n\n__global__\nvoid postprocess (\n  const float *__restrict__ cls_input,\n        float *__restrict__ box_input,\n  const float *__restrict__ dir_cls_input,\n  const float *__restrict__ anchors,\n  const float *__restrict__ anchor_bottom_heights,\n        float *__restrict__ bndbox_output,\n        int *__restrict__ object_counter,\n  const float min_x_range,\n  const float max_x_range,\n  const float min_y_range,\n  const float max_y_range,\n  const int feature_x_size,\n  const int feature_y_size,\n  const int num_anchors,\n  const int num_classes,\n  const int num_box_values,\n  const float score_thresh,\n  const float dir_offset)\n{\n  int loc_index = blockIdx.x;\n  int ith_anchor = threadIdx.x;\n  if (ith_anchor >= num_anchors) return;\n\n  int col = loc_index % feature_x_size;\n  int row = loc_index / feature_x_size;\n  float x_offset = min_x_range + col * (max_x_range - min_x_range) / (feature_x_size - 1);\n  float y_offset = min_y_range + row * (max_y_range - min_y_range) / (feature_y_size - 1);\n  int cls_offset = loc_index * num_anchors * num_classes + ith_anchor * num_classes;\n  float dev_cls[2] = {-1.f, 0.f};\n\n  const float *scores = cls_input + cls_offset;\n  float max_score = sigmoid(scores[0]);\n  int cls_id = 0;\n  for (int i = 1; i < num_classes; i++) {\n    float cls_score = sigmoid(scores[i]);\n    if (cls_score > max_score) {\n      max_score = cls_score;\n      cls_id = i;\n    }\n  }\n  dev_cls[0] = static_cast<float>(cls_id);\n  dev_cls[1] = max_score;\n\n  if (dev_cls[1] >= score_thresh)\n  {\n    const int box_offset = loc_index * num_anchors * num_box_values + ith_anchor * num_box_values;\n    const int dir_cls_offset = loc_index * num_anchors * 2 + ith_anchor * 2;\n    const float *anchor_ptr = anchors + ith_anchor * 4;\n    const float z_offset = anchor_ptr[2] / 2 + anchor_bottom_heights[ith_anchor / 2];\n    const float anchor[7] = {x_offset, y_offset, z_offset, anchor_ptr[0], anchor_ptr[1], anchor_ptr[2], anchor_ptr[3]};\n    float *box_encodings = box_input + box_offset;\n\n    const float xa = anchor[0];\n    const float ya = anchor[1];\n    const float za = anchor[2];\n    const float dxa = anchor[3];\n    const float dya = anchor[4];\n    const float dza = anchor[5];\n    const float ra = anchor[6];\n    const float diagonal = sqrtf(dxa * dxa + dya * dya);\n    box_encodings[0] = box_encodings[0] * diagonal + xa;\n    box_encodings[1] = box_encodings[1] * diagonal + ya;\n    box_encodings[2] = box_encodings[2] * dza + za;\n    box_encodings[3] = expf(box_encodings[3]) * dxa;\n    box_encodings[4] = expf(box_encodings[4]) * dya;\n    box_encodings[5] = expf(box_encodings[5]) * dza;\n    box_encodings[6] = box_encodings[6] + ra;\n\n    const int dir_label = dir_cls_input[dir_cls_offset] > dir_cls_input[dir_cls_offset + 1] ? 0 : 1;\n    const float period = (float)M_PI;\n    const float val = box_input[box_offset + 6] - dir_offset;\n    const float dir_rot = val - floorf(val / (period + 1e-8f)) * period;\n    const float yaw = dir_rot + dir_offset + period * dir_label;\n\n    int resCount = (int)atomicAdd(object_counter, 1);\n    bndbox_output[0] = resCount+1;\n    float *data = bndbox_output + 1 + resCount * 9;\n    data[0] = box_input[box_offset];\n    data[1] = box_input[box_offset + 1];\n    data[2] = box_input[box_offset + 2];\n    data[3] = box_input[box_offset + 3];\n    data[4] = box_input[box_offset + 4];\n    data[5] = box_input[box_offset + 5];\n    data[6] = yaw;\n    data[7] = dev_cls[0];\n    data[8] = dev_cls[1];\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Params p;  \n\n  const float min_x_range = p.min_x_range;\n  const float max_x_range = p.max_x_range;\n  const float min_y_range = p.min_y_range;\n  const float max_y_range = p.max_y_range;\n  const int feature_x_size = p.feature_x_size;\n  const int feature_y_size = p.feature_y_size;\n  const int num_anchors = p.num_anchors;\n  const int num_classes = p.num_classes;\n  const int num_box_values = p.num_box_values;\n  const float score_thresh = p.score_thresh;\n  const float dir_offset = p.dir_offset;\n  const int len_per_anchor = p.len_per_anchor;\n  const int num_dir_bins = p.num_dir_bins;\n  \n  const int feature_size = feature_x_size * feature_y_size;\n  const int feature_anchor_size = feature_size * num_anchors;\n  const int cls_size = feature_anchor_size * num_classes;\n  const int box_size = feature_anchor_size * num_box_values;\n  const int dir_cls_size = feature_anchor_size * num_dir_bins;\n  const int bndbox_size = feature_anchor_size * 9 + 1;\n\n  const int cls_size_byte = cls_size * sizeof(float);\n  const int box_size_byte = box_size * sizeof(float);\n  const int dir_cls_size_byte = dir_cls_size * sizeof(float);\n  const int bndbox_size_byte = bndbox_size * sizeof(float);\n\n  \n\n  float *h_cls_input = (float*) malloc (cls_size_byte);\n  float *h_box_input = (float*) malloc (box_size_byte);\n  float *h_dir_cls_input = (float*) malloc (dir_cls_size_byte);\n\n  \n\n  float *h_bndbox_output = (float*) malloc (bndbox_size_byte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < cls_size; i++)  h_cls_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < box_size; i++)  h_box_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < dir_cls_size; i++)  h_dir_cls_input[i] = rand() / (float)RAND_MAX;\n  \n  float *d_cls_input, *d_box_input, *d_dir_cls_input, *d_bndbox_output;\n  float *d_anchors, *d_anchor_bottom_heights;\n  int *d_object_counter;\n\n  cudaMalloc((void **)&d_cls_input, cls_size_byte);\n  cudaMalloc((void **)&d_box_input, box_size_byte);\n  cudaMalloc((void **)&d_dir_cls_input, dir_cls_size_byte);\n  cudaMalloc((void **)&d_bndbox_output, bndbox_size_byte);\n\n  cudaMemcpy(d_cls_input, h_cls_input, cls_size_byte, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_dir_cls_input, h_dir_cls_input, dir_cls_size_byte, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void **)&d_anchors, num_anchors * len_per_anchor * sizeof(float));\n  cudaMalloc((void **)&d_anchor_bottom_heights, num_classes * sizeof(float));\n  cudaMalloc((void **)&d_object_counter, sizeof(int));\n\n  cudaMemcpy(d_anchors, p.anchors,\n             num_anchors * len_per_anchor * sizeof(float), cudaMemcpyHostToDevice);\n\n  cudaMemcpy(d_anchor_bottom_heights, p.anchor_bottom_heights,\n             num_classes * sizeof(float), cudaMemcpyHostToDevice);\n\n  double time = 0.0;\n\n  dim3 threads (num_anchors);\n  dim3 blocks (feature_size);\n\n  for (int i = 0; i < repeat; i++) {\n    cudaMemcpy(d_box_input, h_box_input, box_size_byte, cudaMemcpyHostToDevice);\n    cudaMemset(d_object_counter, 0, sizeof(int));\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    postprocess<<<blocks, threads>>> (\n      d_cls_input,\n      d_box_input,\n      d_dir_cls_input,\n      d_anchors,\n      d_anchor_bottom_heights,\n      d_bndbox_output,\n      d_object_counter,\n      min_x_range,\n      max_x_range,\n      min_y_range,\n      max_y_range,\n      feature_x_size,\n      feature_y_size,\n      num_anchors,\n      num_classes,\n      num_box_values,\n      score_thresh,\n      dir_offset);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  printf(\"Average execution time of postprocess kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_bndbox_output, d_bndbox_output, bndbox_size_byte, cudaMemcpyDeviceToHost);\n  \n  double checksum = 0.0;\n  for (int i = 0; i < bndbox_size; i++) checksum += h_bndbox_output[i];\n  printf(\"checksum = %lf\\n\", checksum / bndbox_size);\n\n  cudaFree(d_anchors);\n  cudaFree(d_anchor_bottom_heights);\n  cudaFree(d_object_counter);\n  cudaFree(d_cls_input);\n  cudaFree(d_box_input);\n  cudaFree(d_dir_cls_input);\n  cudaFree(d_bndbox_output);\n\n  free(h_cls_input);\n  free(h_box_input);\n  free(h_dir_cls_input);\n  free(h_bndbox_output);\n\n  return 0;\n}\n"}}
{"kernel_name": "p4", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <hip/hip_runtime.h>\n#include \"params.h\"\n\n__device__\nfloat sigmoid(const float x) { return 1.0f / (1.0f + expf(-x)); }\n\n__global__\nvoid postprocess (\n  const float *__restrict__ cls_input,\n        float *__restrict__ box_input,\n  const float *__restrict__ dir_cls_input,\n  const float *__restrict__ anchors,\n  const float *__restrict__ anchor_bottom_heights,\n        float *__restrict__ bndbox_output,\n        int *__restrict__ object_counter,\n  const float min_x_range,\n  const float max_x_range,\n  const float min_y_range,\n  const float max_y_range,\n  const int feature_x_size,\n  const int feature_y_size,\n  const int num_anchors,\n  const int num_classes,\n  const int num_box_values,\n  const float score_thresh,\n  const float dir_offset)\n{\n  int loc_index = blockIdx.x;\n  int ith_anchor = threadIdx.x;\n  if (ith_anchor >= num_anchors) return;\n\n  int col = loc_index % feature_x_size;\n  int row = loc_index / feature_x_size;\n  float x_offset = min_x_range + col * (max_x_range - min_x_range) / (feature_x_size - 1);\n  float y_offset = min_y_range + row * (max_y_range - min_y_range) / (feature_y_size - 1);\n  int cls_offset = loc_index * num_anchors * num_classes + ith_anchor * num_classes;\n  float dev_cls[2] = {-1.f, 0.f};\n\n  const float *scores = cls_input + cls_offset;\n  float max_score = sigmoid(scores[0]);\n  int cls_id = 0;\n  for (int i = 1; i < num_classes; i++) {\n    float cls_score = sigmoid(scores[i]);\n    if (cls_score > max_score) {\n      max_score = cls_score;\n      cls_id = i;\n    }\n  }\n  dev_cls[0] = static_cast<float>(cls_id);\n  dev_cls[1] = max_score;\n\n  if (dev_cls[1] >= score_thresh)\n  {\n    const int box_offset = loc_index * num_anchors * num_box_values + ith_anchor * num_box_values;\n    const int dir_cls_offset = loc_index * num_anchors * 2 + ith_anchor * 2;\n    const float *anchor_ptr = anchors + ith_anchor * 4;\n    const float z_offset = anchor_ptr[2] / 2 + anchor_bottom_heights[ith_anchor / 2];\n    const float anchor[7] = {x_offset, y_offset, z_offset, anchor_ptr[0], anchor_ptr[1], anchor_ptr[2], anchor_ptr[3]};\n    float *box_encodings = box_input + box_offset;\n\n    const float xa = anchor[0];\n    const float ya = anchor[1];\n    const float za = anchor[2];\n    const float dxa = anchor[3];\n    const float dya = anchor[4];\n    const float dza = anchor[5];\n    const float ra = anchor[6];\n    const float diagonal = sqrtf(dxa * dxa + dya * dya);\n    box_encodings[0] = box_encodings[0] * diagonal + xa;\n    box_encodings[1] = box_encodings[1] * diagonal + ya;\n    box_encodings[2] = box_encodings[2] * dza + za;\n    box_encodings[3] = expf(box_encodings[3]) * dxa;\n    box_encodings[4] = expf(box_encodings[4]) * dya;\n    box_encodings[5] = expf(box_encodings[5]) * dza;\n    box_encodings[6] = box_encodings[6] + ra;\n\n    const int dir_label = dir_cls_input[dir_cls_offset] > dir_cls_input[dir_cls_offset + 1] ? 0 : 1;\n    const float period = (float)M_PI;\n    const float val = box_input[box_offset + 6] - dir_offset;\n    const float dir_rot = val - floorf(val / (period + 1e-8f)) * period;\n    const float yaw = dir_rot + dir_offset + period * dir_label;\n\n    int resCount = (int)atomicAdd(object_counter, 1);\n    bndbox_output[0] = resCount+1;\n    float *data = bndbox_output + 1 + resCount * 9;\n    data[0] = box_input[box_offset];\n    data[1] = box_input[box_offset + 1];\n    data[2] = box_input[box_offset + 2];\n    data[3] = box_input[box_offset + 3];\n    data[4] = box_input[box_offset + 4];\n    data[5] = box_input[box_offset + 5];\n    data[6] = yaw;\n    data[7] = dev_cls[0];\n    data[8] = dev_cls[1];\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Params p;  \n\n  const float min_x_range = p.min_x_range;\n  const float max_x_range = p.max_x_range;\n  const float min_y_range = p.min_y_range;\n  const float max_y_range = p.max_y_range;\n  const int feature_x_size = p.feature_x_size;\n  const int feature_y_size = p.feature_y_size;\n  const int num_anchors = p.num_anchors;\n  const int num_classes = p.num_classes;\n  const int num_box_values = p.num_box_values;\n  const float score_thresh = p.score_thresh;\n  const float dir_offset = p.dir_offset;\n  const int len_per_anchor = p.len_per_anchor;\n  const int num_dir_bins = p.num_dir_bins;\n  \n  const int feature_size = feature_x_size * feature_y_size;\n  const int feature_anchor_size = feature_size * num_anchors;\n  const int cls_size = feature_anchor_size * num_classes;\n  const int box_size = feature_anchor_size * num_box_values;\n  const int dir_cls_size = feature_anchor_size * num_dir_bins;\n  const int bndbox_size = feature_anchor_size * 9 + 1;\n\n  const int cls_size_byte = cls_size * sizeof(float);\n  const int box_size_byte = box_size * sizeof(float);\n  const int dir_cls_size_byte = dir_cls_size * sizeof(float);\n  const int bndbox_size_byte = bndbox_size * sizeof(float);\n\n  \n\n  float *h_cls_input = (float*) malloc (cls_size_byte);\n  float *h_box_input = (float*) malloc (box_size_byte);\n  float *h_dir_cls_input = (float*) malloc (dir_cls_size_byte);\n\n  \n\n  float *h_bndbox_output = (float*) malloc (bndbox_size_byte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < cls_size; i++)  h_cls_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < box_size; i++)  h_box_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < dir_cls_size; i++)  h_dir_cls_input[i] = rand() / (float)RAND_MAX;\n  \n  float *d_cls_input, *d_box_input, *d_dir_cls_input, *d_bndbox_output;\n  float *d_anchors, *d_anchor_bottom_heights;\n  int *d_object_counter;\n\n  hipMalloc((void **)&d_cls_input, cls_size_byte);\n  hipMalloc((void **)&d_box_input, box_size_byte);\n  hipMalloc((void **)&d_dir_cls_input, dir_cls_size_byte);\n  hipMalloc((void **)&d_bndbox_output, bndbox_size_byte);\n\n  hipMemcpy(d_cls_input, h_cls_input, cls_size_byte, hipMemcpyHostToDevice);\n  hipMemcpy(d_dir_cls_input, h_dir_cls_input, dir_cls_size_byte, hipMemcpyHostToDevice);\n\n  hipMalloc((void **)&d_anchors, num_anchors * len_per_anchor * sizeof(float));\n  hipMalloc((void **)&d_anchor_bottom_heights, num_classes * sizeof(float));\n  hipMalloc((void **)&d_object_counter, sizeof(int));\n\n  hipMemcpy(d_anchors, p.anchors,\n             num_anchors * len_per_anchor * sizeof(float), hipMemcpyHostToDevice);\n\n  hipMemcpy(d_anchor_bottom_heights, p.anchor_bottom_heights,\n             num_classes * sizeof(float), hipMemcpyHostToDevice);\n\n  double time = 0.0;\n\n  dim3 threads (num_anchors);\n  dim3 blocks (feature_size);\n\n  for (int i = 0; i < repeat; i++) {\n    hipMemcpy(d_box_input, h_box_input, box_size_byte, hipMemcpyHostToDevice);\n    hipMemset(d_object_counter, 0, sizeof(int));\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    hipLaunchKernelGGL(postprocess, blocks, threads, 0, 0, \n      d_cls_input,\n      d_box_input,\n      d_dir_cls_input,\n      d_anchors,\n      d_anchor_bottom_heights,\n      d_bndbox_output,\n      d_object_counter,\n      min_x_range,\n      max_x_range,\n      min_y_range,\n      max_y_range,\n      feature_x_size,\n      feature_y_size,\n      num_anchors,\n      num_classes,\n      num_box_values,\n      score_thresh,\n      dir_offset);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  printf(\"Average execution time of postprocess kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_bndbox_output, d_bndbox_output, bndbox_size_byte, hipMemcpyDeviceToHost);\n  \n  double checksum = 0.0;\n  for (int i = 0; i < bndbox_size; i++) checksum += h_bndbox_output[i];\n  printf(\"checksum = %lf\\n\", checksum / bndbox_size);\n\n  hipFree(d_anchors);\n  hipFree(d_anchor_bottom_heights);\n  hipFree(d_object_counter);\n  hipFree(d_cls_input);\n  hipFree(d_box_input);\n  hipFree(d_dir_cls_input);\n  hipFree(d_bndbox_output);\n\n  free(h_cls_input);\n  free(h_box_input);\n  free(h_dir_cls_input);\n  free(h_bndbox_output);\n\n  return 0;\n}\n"}}
{"kernel_name": "p4", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <math.h>\n#include <omp.h>\n#include \"params.h\"\n\n#pragma omp declare target\nfloat sigmoid(const float x) { return 1.0f / (1.0f + expf(-x)); }\n\nvoid postprocess (\n  const float *__restrict cls_input,\n        float *__restrict box_input,\n  const float *__restrict dir_cls_input,\n  const float *__restrict anchors,\n  const float *__restrict anchor_bottom_heights,\n        float *__restrict bndbox_output,\n        int *__restrict object_counter,\n  const float min_x_range,\n  const float max_x_range,\n  const float min_y_range,\n  const float max_y_range,\n  const int feature_x_size,\n  const int feature_y_size,\n  const int num_anchors,\n  const int num_classes,\n  const int num_box_values,\n  const float score_thresh,\n  const float dir_offset)\n{\n  int loc_index = omp_get_team_num();\n  int itanchor = omp_get_thread_num();\n  if (itanchor >= num_anchors) return;\n\n  int col = loc_index % feature_x_size;\n  int row = loc_index / feature_x_size;\n  float x_offset = min_x_range + col * (max_x_range - min_x_range) / (feature_x_size - 1);\n  float y_offset = min_y_range + row * (max_y_range - min_y_range) / (feature_y_size - 1);\n  int cls_offset = loc_index * num_anchors * num_classes + itanchor * num_classes;\n  float dev_cls[2] = {-1.f, 0.f};\n\n  const float *scores = cls_input + cls_offset;\n  float max_score = sigmoid(scores[0]);\n  int cls_id = 0;\n  for (int i = 1; i < num_classes; i++) {\n    float cls_score = sigmoid(scores[i]);\n    if (cls_score > max_score) {\n      max_score = cls_score;\n      cls_id = i;\n    }\n  }\n  dev_cls[0] = static_cast<float>(cls_id);\n  dev_cls[1] = max_score;\n\n  if (dev_cls[1] >= score_thresh)\n  {\n    int box_offset = loc_index * num_anchors * num_box_values + itanchor * num_box_values;\n    int dir_cls_offset = loc_index * num_anchors * 2 + itanchor * 2;\n    const float *anchor_ptr = anchors + itanchor * 4;\n    float z_offset = anchor_ptr[2] / 2 + anchor_bottom_heights[itanchor / 2];\n    float anchor[7] = {x_offset, y_offset, z_offset, anchor_ptr[0], anchor_ptr[1], anchor_ptr[2], anchor_ptr[3]};\n    float *box_encodings = box_input + box_offset;\n\n    float xa = anchor[0];\n    float ya = anchor[1];\n    float za = anchor[2];\n    float dxa = anchor[3];\n    float dya = anchor[4];\n    float dza = anchor[5];\n    float ra = anchor[6];\n    float diagonal = sqrtf(dxa * dxa + dya * dya);\n    box_encodings[0] = box_encodings[0] * diagonal + xa;\n    box_encodings[1] = box_encodings[1] * diagonal + ya;\n    box_encodings[2] = box_encodings[2] * dza + za;\n    box_encodings[3] = expf(box_encodings[3]) * dxa;\n    box_encodings[4] = expf(box_encodings[4]) * dya;\n    box_encodings[5] = expf(box_encodings[5]) * dza;\n    box_encodings[6] = box_encodings[6] + ra;\n\n    float yaw;\n    int dir_label = dir_cls_input[dir_cls_offset] > dir_cls_input[dir_cls_offset + 1] ? 0 : 1;\n    const float period = (float)M_PI;\n    float val = box_input[box_offset + 6] - dir_offset;\n    float dir_rot = val - floorf(val / (period + 1e-8f)) * period;\n    yaw = dir_rot + dir_offset + period * dir_label;\n\n    int resCount;\n\n    #pragma omp atomic capture\n    {\n      resCount = object_counter[0]; object_counter[0]++;\n    }\n\n    bndbox_output[0] = resCount+1;\n    float *data = bndbox_output + 1 + resCount * 9;\n    data[0] = box_input[box_offset];\n    data[1] = box_input[box_offset + 1];\n    data[2] = box_input[box_offset + 2];\n    data[3] = box_input[box_offset + 3];\n    data[4] = box_input[box_offset + 4];\n    data[5] = box_input[box_offset + 5];\n    data[6] = yaw;\n    data[7] = dev_cls[0];\n    data[8] = dev_cls[1];\n  }\n}\n\n#pragma omp end declare target\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Params p;  \n\n  const float min_x_range = p.min_x_range;\n  const float max_x_range = p.max_x_range;\n  const float min_y_range = p.min_y_range;\n  const float max_y_range = p.max_y_range;\n  const int feature_x_size = p.feature_x_size;\n  const int feature_y_size = p.feature_y_size;\n  const int num_anchors = p.num_anchors;\n  const int num_classes = p.num_classes;\n  const int num_box_values = p.num_box_values;\n  const float score_thresh = p.score_thresh;\n  const float dir_offset = p.dir_offset;\n  const int len_per_anchor = p.len_per_anchor;\n  const int num_dir_bins = p.num_dir_bins;\n  \n  const int feature_size = feature_x_size * feature_y_size;\n  const int feature_anchor_size = feature_size * num_anchors;\n  const int cls_size = feature_anchor_size * num_classes;\n  const int box_size = feature_anchor_size * num_box_values;\n  const int dir_cls_size = feature_anchor_size * num_dir_bins;\n  const int bndbox_size = feature_anchor_size * 9 + 1;\n\n  const int cls_size_byte = cls_size * sizeof(float);\n  const int box_size_byte = box_size * sizeof(float);\n  const int dir_cls_size_byte = dir_cls_size * sizeof(float);\n  const int bndbox_size_byte = bndbox_size * sizeof(float);\n\n  \n\n  float *cls_input = (float*) malloc (cls_size_byte);\n  float *box_input = (float*) malloc (box_size_byte);\n  float *dir_cls_input = (float*) malloc (dir_cls_size_byte);\n\n  \n\n  float *bndbox_output = (float*) malloc (bndbox_size_byte);\n\n  const float *anchors = p.anchors;\n  const float *anchor_bottom_heights = p.anchor_bottom_heights;\n  int object_counter[1];\n\n  \n\n  srand(123);\n  for (int i = 0; i < cls_size; i++)  cls_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < box_size; i++)  box_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < dir_cls_size; i++)  dir_cls_input[i] = rand() / (float)RAND_MAX;\n  \n  #pragma omp target data map(to: cls_input[0:cls_size], \\\n                                  dir_cls_input[0:dir_cls_size], \\\n                                  anchors[0:num_anchors * len_per_anchor], \\\n                                  anchor_bottom_heights[0:num_classes]) \\\n                          map(alloc: box_input[0:box_size], object_counter[1]) \\\n                          map(from: bndbox_output[0:bndbox_size])\n  {\n     \n  double time = 0.0;\n\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target update to (box_input[0:box_size])\n\n    object_counter[0] = 0;\n    #pragma omp target update to (object_counter[0:1])\n\n    auto start = std::chrono::steady_clock::now();\n\n    #pragma omp target teams num_teams(feature_size) thread_limit(num_anchors)\n    {\n      #pragma omp parallel \n      {\n        postprocess(cls_input,\n                    box_input,\n                    dir_cls_input,\n                    anchors,\n                    anchor_bottom_heights,\n                    bndbox_output,\n                    object_counter,\n                    min_x_range,\n                    max_x_range,\n                    min_y_range,\n                    max_y_range,\n                    feature_x_size,\n                    feature_y_size,\n                    num_anchors,\n                    num_classes,\n                    num_box_values,\n                    score_thresh,\n                    dir_offset);\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  printf(\"Average execution time of postprocess kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  }\n\n  double checksum = 0.0;\n  for (int i = 0; i < bndbox_size; i++) checksum += bndbox_output[i];\n  printf(\"checksum = %lf\\n\", checksum / bndbox_size);\n\n  free(cls_input);\n  free(box_input);\n  free(dir_cls_input);\n  free(bndbox_output);\n\n  return 0;\n}\n"}}
{"kernel_name": "p4", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <math.h>\n#include \"params.h\"\n\nfloat sigmoid(const float x) { return 1.0f / (1.0f + expf(-x)); }\n\nvoid postprocess (\n  const float *__restrict cls_input,\n        float *__restrict box_input,\n  const float *__restrict dir_cls_input,\n  const float *__restrict anchors,\n  const float *__restrict anchor_bottom_heights,\n        float *__restrict bndbox_output,\n        int *__restrict object_counter,\n  const float min_x_range,\n  const float max_x_range,\n  const float min_y_range,\n  const float max_y_range,\n  const int feature_x_size,\n  const int feature_y_size,\n  const int num_anchors,\n  const int num_classes,\n  const int num_box_values,\n  const float score_thresh,\n  const float dir_offset)\n{\n  int loc_index = omp_get_team_num();\n  int itanchor = omp_get_thread_num();\n  if (itanchor >= num_anchors) return;\n\n  int col = loc_index % feature_x_size;\n  int row = loc_index / feature_x_size;\n  float x_offset = min_x_range + col * (max_x_range - min_x_range) / (feature_x_size - 1);\n  float y_offset = min_y_range + row * (max_y_range - min_y_range) / (feature_y_size - 1);\n  int cls_offset = loc_index * num_anchors * num_classes + itanchor * num_classes;\n  float dev_cls[2] = {-1.f, 0.f};\n\n  const float *scores = cls_input + cls_offset;\n  float max_score = sigmoid(scores[0]);\n  int cls_id = 0;\n  for (int i = 1; i < num_classes; i++) {\n    float cls_score = sigmoid(scores[i]);\n    if (cls_score > max_score) {\n      max_score = cls_score;\n      cls_id = i;\n    }\n  }\n  dev_cls[0] = static_cast<float>(cls_id);\n  dev_cls[1] = max_score;\n\n  if (dev_cls[1] >= score_thresh)\n  {\n    int box_offset = loc_index * num_anchors * num_box_values + itanchor * num_box_values;\n    int dir_cls_offset = loc_index * num_anchors * 2 + itanchor * 2;\n    const float *anchor_ptr = anchors + itanchor * 4;\n    float z_offset = anchor_ptr[2] / 2 + anchor_bottom_heights[itanchor / 2];\n    float anchor[7] = {x_offset, y_offset, z_offset, anchor_ptr[0], anchor_ptr[1], anchor_ptr[2], anchor_ptr[3]};\n    float *box_encodings = box_input + box_offset;\n\n    float xa = anchor[0];\n    float ya = anchor[1];\n    float za = anchor[2];\n    float dxa = anchor[3];\n    float dya = anchor[4];\n    float dza = anchor[5];\n    float ra = anchor[6];\n    float diagonal = sqrtf(dxa * dxa + dya * dya);\n    box_encodings[0] = box_encodings[0] * diagonal + xa;\n    box_encodings[1] = box_encodings[1] * diagonal + ya;\n    box_encodings[2] = box_encodings[2] * dza + za;\n    box_encodings[3] = expf(box_encodings[3]) * dxa;\n    box_encodings[4] = expf(box_encodings[4]) * dya;\n    box_encodings[5] = expf(box_encodings[5]) * dza;\n    box_encodings[6] = box_encodings[6] + ra;\n\n    float yaw;\n    int dir_label = dir_cls_input[dir_cls_offset] > dir_cls_input[dir_cls_offset + 1] ? 0 : 1;\n    const float period = (float)M_PI;\n    float val = box_input[box_offset + 6] - dir_offset;\n    float dir_rot = val - floorf(val / (period + 1e-8f)) * period;\n    yaw = dir_rot + dir_offset + period * dir_label;\n\n    int resCount;\n\n        {\n      resCount = object_counter[0]; object_counter[0]++;\n    }\n\n    bndbox_output[0] = resCount+1;\n    float *data = bndbox_output + 1 + resCount * 9;\n    data[0] = box_input[box_offset];\n    data[1] = box_input[box_offset + 1];\n    data[2] = box_input[box_offset + 2];\n    data[3] = box_input[box_offset + 3];\n    data[4] = box_input[box_offset + 4];\n    data[5] = box_input[box_offset + 5];\n    data[6] = yaw;\n    data[7] = dev_cls[0];\n    data[8] = dev_cls[1];\n  }\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Params p;  \n\n  const float min_x_range = p.min_x_range;\n  const float max_x_range = p.max_x_range;\n  const float min_y_range = p.min_y_range;\n  const float max_y_range = p.max_y_range;\n  const int feature_x_size = p.feature_x_size;\n  const int feature_y_size = p.feature_y_size;\n  const int num_anchors = p.num_anchors;\n  const int num_classes = p.num_classes;\n  const int num_box_values = p.num_box_values;\n  const float score_thresh = p.score_thresh;\n  const float dir_offset = p.dir_offset;\n  const int len_per_anchor = p.len_per_anchor;\n  const int num_dir_bins = p.num_dir_bins;\n  \n  const int feature_size = feature_x_size * feature_y_size;\n  const int feature_anchor_size = feature_size * num_anchors;\n  const int cls_size = feature_anchor_size * num_classes;\n  const int box_size = feature_anchor_size * num_box_values;\n  const int dir_cls_size = feature_anchor_size * num_dir_bins;\n  const int bndbox_size = feature_anchor_size * 9 + 1;\n\n  const int cls_size_byte = cls_size * sizeof(float);\n  const int box_size_byte = box_size * sizeof(float);\n  const int dir_cls_size_byte = dir_cls_size * sizeof(float);\n  const int bndbox_size_byte = bndbox_size * sizeof(float);\n\n  \n\n  float *cls_input = (float*) malloc (cls_size_byte);\n  float *box_input = (float*) malloc (box_size_byte);\n  float *dir_cls_input = (float*) malloc (dir_cls_size_byte);\n\n  \n\n  float *bndbox_output = (float*) malloc (bndbox_size_byte);\n\n  const float *anchors = p.anchors;\n  const float *anchor_bottom_heights = p.anchor_bottom_heights;\n  int object_counter[1];\n\n  \n\n  srand(123);\n  for (int i = 0; i < cls_size; i++)  cls_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < box_size; i++)  box_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < dir_cls_size; i++)  dir_cls_input[i] = rand() / (float)RAND_MAX;\n  \n    {\n     \n  double time = 0.0;\n\n  for (int i = 0; i < repeat; i++) {\n    \n    object_counter[0] = 0;\n    \n    auto start = std::chrono::steady_clock::now();\n\n        {\n            {\n        postprocess(cls_input,\n                    box_input,\n                    dir_cls_input,\n                    anchors,\n                    anchor_bottom_heights,\n                    bndbox_output,\n                    object_counter,\n                    min_x_range,\n                    max_x_range,\n                    min_y_range,\n                    max_y_range,\n                    feature_x_size,\n                    feature_y_size,\n                    num_anchors,\n                    num_classes,\n                    num_box_values,\n                    score_thresh,\n                    dir_offset);\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  printf(\"Average execution time of postprocess kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  }\n\n  double checksum = 0.0;\n  for (int i = 0; i < bndbox_size; i++) checksum += bndbox_output[i];\n  printf(\"checksum = %lf\\n\", checksum / bndbox_size);\n\n  free(cls_input);\n  free(box_input);\n  free(dir_cls_input);\n  free(bndbox_output);\n\n  return 0;\n}"}}
{"kernel_name": "p4", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <sycl/sycl.hpp>\n#include \"params.h\"\n\nfloat sigmoid(const float x) { return 1.0f / (1.0f + sycl::exp(-x)); }\n\nvoid postprocess (\n  sycl::nd_item<1> &item,\n  const float *__restrict cls_input,\n        float *__restrict box_input,\n  const float *__restrict dir_cls_input,\n  const float *__restrict anchors,\n  const float *__restrict anchor_bottom_heights,\n        float *__restrict bndbox_output,\n        int *__restrict object_counter,\n  const float min_x_range,\n  const float max_x_range,\n  const float min_y_range,\n  const float max_y_range,\n  const int feature_x_size,\n  const int feature_y_size,\n  const int num_anchors,\n  const int num_classes,\n  const int num_box_values,\n  const float score_thresh,\n  const float dir_offset)\n{\n  int loc_index = item.get_group(0);\n  int ith_anchor = item.get_local_id(0);\n  if (ith_anchor >= num_anchors) return;\n\n  int col = loc_index % feature_x_size;\n  int row = loc_index / feature_x_size;\n  float x_offset = min_x_range + col * (max_x_range - min_x_range) / (feature_x_size - 1);\n  float y_offset = min_y_range + row * (max_y_range - min_y_range) / (feature_y_size - 1);\n  int cls_offset = loc_index * num_anchors * num_classes + ith_anchor * num_classes;\n  float dev_cls[2] = {-1.f, 0.f};\n\n  const float *scores = cls_input + cls_offset;\n  float max_score = sigmoid(scores[0]);\n  int cls_id = 0;\n  for (int i = 1; i < num_classes; i++) {\n    float cls_score = sigmoid(scores[i]);\n    if (cls_score > max_score) {\n      max_score = cls_score;\n      cls_id = i;\n    }\n  }\n  dev_cls[0] = static_cast<float>(cls_id);\n  dev_cls[1] = max_score;\n\n  if (dev_cls[1] >= score_thresh)\n  {\n    const int box_offset = loc_index * num_anchors * num_box_values + ith_anchor * num_box_values;\n    const int dir_cls_offset = loc_index * num_anchors * 2 + ith_anchor * 2;\n    const float *anchor_ptr = anchors + ith_anchor * 4;\n    const float z_offset = anchor_ptr[2] / 2 + anchor_bottom_heights[ith_anchor / 2];\n    const float anchor[7] = {x_offset, y_offset, z_offset, anchor_ptr[0], anchor_ptr[1], anchor_ptr[2], anchor_ptr[3]};\n    float *box_encodings = box_input + box_offset;\n\n    const float xa = anchor[0];\n    const float ya = anchor[1];\n    const float za = anchor[2];\n    const float dxa = anchor[3];\n    const float dya = anchor[4];\n    const float dza = anchor[5];\n    const float ra = anchor[6];\n    const float diagonal = sycl::sqrt(dxa * dxa + dya * dya);\n    box_encodings[0] = box_encodings[0] * diagonal + xa;\n    box_encodings[1] = box_encodings[1] * diagonal + ya;\n    box_encodings[2] = box_encodings[2] * dza + za;\n    box_encodings[3] = sycl::exp(box_encodings[3]) * dxa;\n    box_encodings[4] = sycl::exp(box_encodings[4]) * dya;\n    box_encodings[5] = sycl::exp(box_encodings[5]) * dza;\n    box_encodings[6] = box_encodings[6] + ra;\n\n    const int dir_label = dir_cls_input[dir_cls_offset] > dir_cls_input[dir_cls_offset + 1] ? 0 : 1;\n    const float period = (float)M_PI;\n    const float val = box_input[box_offset + 6] - dir_offset;\n    const float dir_rot = val - sycl::floor(val / (period + 1e-8f)) * period;\n    const float yaw = dir_rot + dir_offset + period * dir_label;\n\n    auto ao_ref = sycl::atomic_ref<int,\n                  sycl::memory_order::relaxed,\n                  sycl::memory_scope::device,\n                  sycl::access::address_space::global_space> (object_counter[0]);\n    int resCount = ao_ref.fetch_add(1);\n\n    bndbox_output[0] = resCount+1;\n    float *data = bndbox_output + 1 + resCount * 9;\n    data[0] = box_input[box_offset];\n    data[1] = box_input[box_offset + 1];\n    data[2] = box_input[box_offset + 2];\n    data[3] = box_input[box_offset + 3];\n    data[4] = box_input[box_offset + 4];\n    data[5] = box_input[box_offset + 5];\n    data[6] = yaw;\n    data[7] = dev_cls[0];\n    data[8] = dev_cls[1];\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  Params p;  \n\n  const float min_x_range = p.min_x_range;\n  const float max_x_range = p.max_x_range;\n  const float min_y_range = p.min_y_range;\n  const float max_y_range = p.max_y_range;\n  const int feature_x_size = p.feature_x_size;\n  const int feature_y_size = p.feature_y_size;\n  const int num_anchors = p.num_anchors;\n  const int num_classes = p.num_classes;\n  const int num_box_values = p.num_box_values;\n  const float score_thresh = p.score_thresh;\n  const float dir_offset = p.dir_offset;\n  const int len_per_anchor = p.len_per_anchor;\n  const int num_dir_bins = p.num_dir_bins;\n\n  const int feature_size = feature_x_size * feature_y_size;\n  const int feature_anchor_size = feature_size * num_anchors;\n  const int cls_size = feature_anchor_size * num_classes;\n  const int box_size = feature_anchor_size * num_box_values;\n  const int dir_cls_size = feature_anchor_size * num_dir_bins;\n  const int bndbox_size = feature_anchor_size * 9 + 1;\n\n  const int cls_size_byte = cls_size * sizeof(float);\n  const int box_size_byte = box_size * sizeof(float);\n  const int dir_cls_size_byte = dir_cls_size * sizeof(float);\n  const int bndbox_size_byte = bndbox_size * sizeof(float);\n\n  \n\n  float *h_cls_input = (float*) malloc (cls_size_byte);\n  float *h_box_input = (float*) malloc (box_size_byte);\n  float *h_dir_cls_input = (float*) malloc (dir_cls_size_byte);\n\n  \n\n  float *h_bndbox_output = (float*) malloc (bndbox_size_byte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < cls_size; i++)  h_cls_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < box_size; i++)  h_box_input[i] = rand() / (float)RAND_MAX;\n  for (int i = 0; i < dir_cls_size; i++)  h_dir_cls_input[i] = rand() / (float)RAND_MAX;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_cls_input = sycl::malloc_device<float>(cls_size, q);\n  float *d_box_input = sycl::malloc_device<float>(box_size, q);\n  float *d_dir_cls_input = sycl::malloc_device<float>(dir_cls_size, q);\n  float *d_bndbox_output = sycl::malloc_device<float>(bndbox_size, q);\n  float *d_anchors = sycl::malloc_device<float>(num_anchors * len_per_anchor, q);\n  float *d_anchor_bottom_heights = sycl::malloc_device<float>(num_classes, q);\n    int *d_object_counter = sycl::malloc_device<int>(1, q);\n\n  q.memcpy(d_cls_input, h_cls_input, cls_size_byte);\n  q.memcpy(d_dir_cls_input, h_dir_cls_input, dir_cls_size_byte);\n  q.memcpy(d_anchors, p.anchors, num_anchors * len_per_anchor * sizeof(float));\n  q.memcpy(d_anchor_bottom_heights, p.anchor_bottom_heights, num_classes * sizeof(float));\n\n  double time = 0.0;\n\n  sycl::range<1> lws (num_anchors);\n  sycl::range<1> gws (feature_size * num_anchors);\n\n  for (int i = 0; i < repeat; i++) {\n    q.memcpy(d_box_input, h_box_input, box_size_byte);\n    q.memset(d_object_counter, 0, sizeof(int));\n\n    q.wait();\n\n    auto start = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class p4>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        postprocess(item,\n                    d_cls_input,\n                    d_box_input,\n                    d_dir_cls_input,\n                    d_anchors,\n                    d_anchor_bottom_heights,\n                    d_bndbox_output,\n                    d_object_counter,\n                    min_x_range,\n                    max_x_range,\n                    min_y_range,\n                    max_y_range,\n                    feature_x_size,\n                    feature_y_size,\n                    num_anchors,\n                    num_classes,\n                    num_box_values,\n                    score_thresh,\n                    dir_offset);\n      });\n    }).wait();\n\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  printf(\"Average execution time of postprocess kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(h_bndbox_output, d_bndbox_output, bndbox_size_byte).wait();\n\n  double checksum = 0.0;\n  for (int i = 0; i < bndbox_size; i++) checksum += h_bndbox_output[i];\n  printf(\"checksum = %lf\\n\", checksum / bndbox_size);\n\n  sycl::free(d_anchors, q);\n  sycl::free(d_anchor_bottom_heights, q);\n  sycl::free(d_object_counter, q);\n  sycl::free(d_cls_input, q);\n  sycl::free(d_box_input, q);\n  sycl::free(d_dir_cls_input, q);\n  sycl::free(d_bndbox_output, q);\n\n  free(h_cls_input);\n  free(h_box_input);\n  free(h_dir_cls_input);\n  free(h_bndbox_output);\n\n  return 0;\n}\n"}}
{"kernel_name": "page-rank", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <time.h>\n#include <math.h>\n#include <getopt.h>\n#include <chrono>\n#include <cuda.h>\n\n#define D_FACTOR (0.85f)\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 256\n#endif\n\n\n\nconst int max_iter = 1000;\nconst float threshold= 1e-16f;\n\n__global__\nvoid map(const int *__restrict__ pages,\n         const float *__restrict__ page_ranks,\n               float *__restrict__ maps,\n         const unsigned int *__restrict__ noutlinks,\n         const int n)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  int j;\n  if(i < n){\n    float outbound_rank = page_ranks[i]/(float)noutlinks[i];\n    for(j=0; j<n; ++j){\n      maps[i*n+j] = pages[i*n+j]*outbound_rank;\n    }\n  }\n}\n\n__global__\nvoid reduce(      float *__restrict__ page_ranks,\n            const float *__restrict__ maps,\n            const int n,\n                  float *__restrict__ dif)\n{\n\n  int j = threadIdx.x + blockIdx.x * blockDim.x;\n  int i;\n  float new_rank;\n  float old_rank;\n\n  if(j<n){\n    old_rank = page_ranks[j];\n    new_rank = 0.0f;\n    for(i=0; i< n; ++i){\n      new_rank += maps[i*n + j];\n    }\n\n    new_rank = ((1.f-D_FACTOR)/n)+(D_FACTOR*new_rank);\n    dif[j] = fmaxf(fabsf(new_rank - old_rank), dif[j]);\n    page_ranks[j] = new_rank;\n  }\n}\n\n\n\nint *random_pages(int n, unsigned int *noutlinks, int divisor){\n  int i, j, k;\n  int *pages = (int*) malloc(sizeof(int)*n*n); \n\n\n  if (divisor <= 0) {\n    fprintf(stderr, \"ERROR: Invalid divisor '%d' for random initialization, divisor should be greater or equal to 1\\n\", divisor);\n    exit(1);\n  }\n\n  for(i=0; i<n; ++i){\n    noutlinks[i] = 0;\n    for(j=0; j<n; ++j){\n      if(i!=j && (abs(rand())%divisor == 0)){\n        pages[i*n+j] = 1;\n        noutlinks[i] += 1;\n      }\n    }\n\n    \n\n    if(noutlinks[i] == 0){\n      do { k = abs(rand()) % n; } while ( k == i);\n      pages[i*n + k] = 1;\n      noutlinks[i] = 1;\n    }\n  }\n  return pages;\n}\n\nvoid init_array(float *a, int n, float val){\n  int i;\n  for(i=0; i<n; ++i){\n    a[i] = val;\n  }\n}\n\nvoid usage(char *argv[]){\n  fprintf(stderr, \"Usage: %s [-n number of pages] [-i max iterations]\"\n                  \" [-t threshold] [-q divisor for zero density]\\n\", argv[0]);\n}\n\nstatic struct option size_opts[] =\n{\n  \n\n  {\"number of pages\", 1, NULL, 'n'},\n  {\"max number of iterations\", 1, NULL, 'i'},\n  {\"minimum threshold\", 1, NULL, 't'},\n  {\"divisor for zero density\", 1, NULL, 'q'},\n  { 0, 0, 0}\n};\n\nfloat maximum_dif(float *difs, int n){\n  int i;\n  float max = 0.0f;\n  for(i=0; i<n; ++i){\n    max = difs[i] > max ? difs[i] : max;\n  }\n  return max;\n}\n\nint main(int argc, char *argv[]) {\n  int *pages;\n  float *maps;\n  float *page_ranks;\n  unsigned int *noutlinks;\n  int t;\n  float max_diff;\n\n  int i = 0;\n  int j;\n  int n = 1000;\n  int iter = max_iter;\n  float thresh = threshold;\n  int divisor = 2;\n  int nb_links = 0;\n\n  int opt, opt_index = 0;\n  while((opt = getopt_long(argc, argv, \"::n:i:t:q:\", size_opts, &opt_index)) != -1){\n    switch(opt){\n      case 'n':\n        n = atoi(optarg);\n        break;\n      case 'i':\n        iter = atoi(optarg);\n        break;\n      case 't':\n        thresh = atof(optarg);\n        break;\n      case 'q':\n        divisor = atoi(optarg);\n        break;\n      default:\n        usage(argv);\n        exit(EXIT_FAILURE);\n    }\n  }\n  page_ranks = (float*)malloc(sizeof(float)*n);\n  maps = (float*)malloc(sizeof(float)*n*n);\n  noutlinks = (unsigned int*)malloc(sizeof(unsigned int)*n);\n\n  max_diff=99.0f;\n\n  for (i=0; i<n; ++i) {\n    noutlinks[i] = 0;\n  }\n  pages = random_pages(n,noutlinks,divisor);\n  init_array(page_ranks, n, 1.0f / (float) n);\n\n  nb_links = 0;\n  for (i=0; i<n; ++i) {\n    for (j=0; j<n; ++j) {\n      nb_links += pages[i*n+j];\n    }\n  }\n\n  float *diffs;\n  diffs  = (float*) malloc(sizeof(float)*n);\n  for(i = 0; i < n; ++i){\n    diffs[i] = 0.0f;\n  }\n\n  int *d_pages;\n  float *d_maps;\n  float *d_page_ranks;\n  float *d_diffs;\n  unsigned int *d_noutlinks;\n\n  cudaMalloc((void**)&d_pages, sizeof(int)*n*n);\n  cudaMalloc((void**)&d_page_ranks, sizeof(float)*n);\n  cudaMalloc((void**)&d_maps, sizeof(float)*n*n);\n  cudaMalloc((void**)&d_noutlinks, sizeof(unsigned int)*n);\n  cudaMalloc((void**)&d_diffs, sizeof(float)*n);\n\n  cudaMemcpy(d_pages, pages, sizeof(int)*n*n, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_page_ranks, page_ranks, sizeof(float)*n, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_noutlinks, noutlinks, sizeof(unsigned int)*n, cudaMemcpyHostToDevice);\n\n  size_t block_size  = n < BLOCK_SIZE ? n : BLOCK_SIZE;\n  size_t num_blocks = (n+block_size-1) / block_size;\n\n  double ktime = 0.0;\n \n  for (t=1; t<=iter && max_diff>=thresh; ++t) {\n    auto start = std::chrono::high_resolution_clock::now();\n\n    map <<< dim3(num_blocks), dim3(block_size) >>> (\n      d_pages, d_page_ranks, d_maps, d_noutlinks, n);\n\n    reduce <<< dim3(num_blocks), dim3(block_size) >>> (\n      d_page_ranks, d_maps, n, d_diffs);\n    \n    cudaDeviceSynchronize();\n    auto end = std::chrono::high_resolution_clock::now();\n    ktime += std::chrono::duration_cast<std::chrono::duration<double>>(end - start).count();\n\n    cudaMemcpy(diffs, d_diffs, sizeof(float)*n, cudaMemcpyDeviceToHost);\n    cudaMemset(d_diffs, 0, sizeof(float)*n);\n    max_diff = maximum_dif(diffs, n);\n  }\n  \n\n  \n\n\n  cudaFree(d_pages);\n  cudaFree(d_maps);\n  cudaFree(d_page_ranks);\n  cudaFree(d_noutlinks);\n  cudaFree(d_diffs);\n\n  fprintf(stderr, \"Max difference %f is reached at iteration %d\\n\", max_diff, t);\n  printf(\"\\\"Options\\\": \\\"-n %d -i %d -t %f\\\". Total kernel execution time: %lf (s)\\n\",\n         n, iter, thresh, ktime);\n\n  free(pages);\n  free(maps);\n  free(page_ranks);\n  free(noutlinks);\n  free(diffs);\n\n  return 0;\n}\n"}}
{"kernel_name": "page-rank", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <time.h>\n#include <math.h>\n#include <getopt.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define D_FACTOR (0.85f)\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 256\n#endif\n\n\n\nconst int max_iter = 1000;\nconst float threshold= 1e-16f;\n\n__global__\nvoid map(const int *__restrict__ pages,\n         const float *__restrict__ page_ranks,\n               float *__restrict__ maps,\n         const unsigned int *__restrict__ noutlinks,\n         const int n)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  int j;\n  if(i < n){\n    float outbound_rank = page_ranks[i]/(float)noutlinks[i];\n    for(j=0; j<n; ++j){\n      maps[i*n+j] = pages[i*n+j]*outbound_rank;\n    }\n  }\n}\n\n__global__\nvoid reduce(      float *__restrict__ page_ranks,\n            const float *__restrict__ maps,\n            const int n,\n                  float *__restrict__ dif)\n{\n\n  int j = threadIdx.x + blockIdx.x * blockDim.x;\n  int i;\n  float new_rank;\n  float old_rank;\n\n  if(j<n){\n    old_rank = page_ranks[j];\n    new_rank = 0.0f;\n    for(i=0; i< n; ++i){\n      new_rank += maps[i*n + j];\n    }\n\n    new_rank = ((1.f-D_FACTOR)/n)+(D_FACTOR*new_rank);\n    dif[j] = fmaxf(fabsf(new_rank - old_rank), dif[j]);\n    page_ranks[j] = new_rank;\n  }\n}\n\n\n\nint *random_pages(int n, unsigned int *noutlinks, int divisor){\n  int i, j, k;\n  int *pages = (int*) malloc(sizeof(int)*n*n); \n\n\n  if (divisor <= 0) {\n    fprintf(stderr, \"ERROR: Invalid divisor '%d' for random initialization, divisor should be greater or equal to 1\\n\", divisor);\n    exit(1);\n  }\n\n  for(i=0; i<n; ++i){\n    noutlinks[i] = 0;\n    for(j=0; j<n; ++j){\n      if(i!=j && (abs(rand())%divisor == 0)){\n        pages[i*n+j] = 1;\n        noutlinks[i] += 1;\n      }\n    }\n\n    \n\n    if(noutlinks[i] == 0){\n      do { k = abs(rand()) % n; } while ( k == i);\n      pages[i*n + k] = 1;\n      noutlinks[i] = 1;\n    }\n  }\n  return pages;\n}\n\nvoid init_array(float *a, int n, float val){\n  int i;\n  for(i=0; i<n; ++i){\n    a[i] = val;\n  }\n}\n\nvoid usage(char *argv[]){\n  fprintf(stderr, \"Usage: %s [-n number of pages] [-i max iterations]\"\n                  \" [-t threshold] [-q divisor for zero density]\\n\", argv[0]);\n}\n\nstatic struct option size_opts[] =\n{\n  \n\n  {\"number of pages\", 1, NULL, 'n'},\n  {\"max number of iterations\", 1, NULL, 'i'},\n  {\"minimum threshold\", 1, NULL, 't'},\n  {\"divisor for zero density\", 1, NULL, 'q'},\n  { 0, 0, 0}\n};\n\nfloat maximum_dif(float *difs, int n){\n  int i;\n  float max = 0.0f;\n  for(i=0; i<n; ++i){\n    max = difs[i] > max ? difs[i] : max;\n  }\n  return max;\n}\n\nint main(int argc, char *argv[]) {\n  int *pages;\n  float *maps;\n  float *page_ranks;\n  unsigned int *noutlinks;\n  int t;\n  float max_diff;\n\n  int i = 0;\n  int j;\n  int n = 1000;\n  int iter = max_iter;\n  float thresh = threshold;\n  int divisor = 2;\n  int nb_links = 0;\n\n  int opt, opt_index = 0;\n  while((opt = getopt_long(argc, argv, \"::n:i:t:q:\", size_opts, &opt_index)) != -1){\n    switch(opt){\n      case 'n':\n        n = atoi(optarg);\n        break;\n      case 'i':\n        iter = atoi(optarg);\n        break;\n      case 't':\n        thresh = atof(optarg);\n        break;\n      case 'q':\n        divisor = atoi(optarg);\n        break;\n      default:\n        usage(argv);\n        exit(EXIT_FAILURE);\n    }\n  }\n  page_ranks = (float*)malloc(sizeof(float)*n);\n  maps = (float*)malloc(sizeof(float)*n*n);\n  noutlinks = (unsigned int*)malloc(sizeof(unsigned int)*n);\n\n  max_diff=99.0f;\n\n  for (i=0; i<n; ++i) {\n    noutlinks[i] = 0;\n  }\n  pages = random_pages(n,noutlinks,divisor);\n  init_array(page_ranks, n, 1.0f / (float) n);\n\n  nb_links = 0;\n  for (i=0; i<n; ++i) {\n    for (j=0; j<n; ++j) {\n      nb_links += pages[i*n+j];\n    }\n  }\n\n  float *diffs;\n  diffs  = (float*) malloc(sizeof(float)*n);\n  for(i = 0; i < n; ++i){\n    diffs[i] = 0.0f;\n  }\n\n  int *d_pages;\n  float *d_maps;\n  float *d_page_ranks;\n  float *d_diffs;\n  unsigned int *d_noutlinks;\n\n  hipMalloc((void**)&d_pages, sizeof(int)*n*n);\n  hipMalloc((void**)&d_page_ranks, sizeof(float)*n);\n  hipMalloc((void**)&d_maps, sizeof(float)*n*n);\n  hipMalloc((void**)&d_noutlinks, sizeof(unsigned int)*n);\n  hipMalloc((void**)&d_diffs, sizeof(float)*n);\n\n  hipMemcpy(d_pages, pages, sizeof(int)*n*n, hipMemcpyHostToDevice);\n  hipMemcpy(d_page_ranks, page_ranks, sizeof(float)*n, hipMemcpyHostToDevice);\n  hipMemcpy(d_noutlinks, noutlinks, sizeof(unsigned int)*n, hipMemcpyHostToDevice);\n\n  size_t block_size  = n < BLOCK_SIZE ? n : BLOCK_SIZE;\n  size_t num_blocks = (n+block_size-1) / block_size;\n\n  double ktime = 0.0;\n \n  for (t=1; t<=iter && max_diff>=thresh; ++t) {\n    auto start = std::chrono::high_resolution_clock::now();\n\n    hipLaunchKernelGGL(map, dim3(num_blocks), dim3(block_size), 0, 0, \n      d_pages, d_page_ranks, d_maps, d_noutlinks, n);\n\n    hipLaunchKernelGGL(reduce, dim3(num_blocks), dim3(block_size), 0, 0,\n      d_page_ranks, d_maps, n, d_diffs);\n    \n    hipDeviceSynchronize();\n    auto end = std::chrono::high_resolution_clock::now();\n    ktime += std::chrono::duration_cast<std::chrono::duration<double> >(end - start).count();\n\n    hipMemcpy(diffs, d_diffs, sizeof(float)*n, hipMemcpyDeviceToHost);\n    hipMemset(d_diffs, 0, sizeof(float)*n);\n    max_diff = maximum_dif(diffs, n);\n  }\n  \n\n  \n\n\n  hipFree(d_pages);\n  hipFree(d_maps);\n  hipFree(d_page_ranks);\n  hipFree(d_noutlinks);\n  hipFree(d_diffs);\n\n  fprintf(stderr, \"Max difference %f is reached at iteration %d\\n\", max_diff, t);\n  printf(\"\\\"Options\\\": \\\"-n %d -i %d -t %f\\\". Total kernel execution time: %lf (s)\\n\",\n         n, iter, thresh, ktime);\n\n  free(pages);\n  free(maps);\n  free(page_ranks);\n  free(noutlinks);\n  free(diffs);\n\n  return 0;\n}\n"}}
{"kernel_name": "page-rank", "parallel_api": "omp", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <math.h>\n#include <getopt.h>\n#include <chrono>\n\n#define D_FACTOR (0.85f)\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 256\n#endif\n\n\n\nconst int max_iter = 1000;\nconst float threshold= 1e-16f;\n\n\n\nint *random_pages(int n, unsigned int *noutlinks, int divisor){\n  int i, j, k;\n  int *pages = (int*) malloc(sizeof(int)*n*n); \n\n\n  if (divisor <= 0) {\n    fprintf(stderr, \"ERROR: Invalid divisor '%d' for random initialization, divisor should be greater or equal to 1\\n\", divisor);\n    exit(1);\n  }\n\n  for(i=0; i<n; ++i){\n    noutlinks[i] = 0;\n    for(j=0; j<n; ++j){\n      if(i!=j && (abs(rand())%divisor == 0)){\n        pages[i*n+j] = 1;\n        noutlinks[i] += 1;\n      }\n    }\n\n    \n\n    if(noutlinks[i] == 0){\n      do { k = abs(rand()) % n; } while ( k == i);\n      pages[i*n + k] = 1;\n      noutlinks[i] = 1;\n    }\n  }\n  return pages;\n}\n\nvoid init_array(float *a, int n, float val){\n  int i;\n  for(i=0; i<n; ++i){\n    a[i] = val;\n  }\n}\n\nvoid usage(char *argv[]){\n  fprintf(stderr, \"Usage: %s [-n number of pages] [-i max iterations]\"\n      \" [-t threshold] [-q divsor for zero density]\\n\", argv[0]);\n}\n\nstatic struct option size_opts[] =\n{\n  \n\n  {\"number of pages\", 1, NULL, 'n'},\n  {\"max number of iterations\", 1, NULL, 'i'},\n  {\"minimum threshold\", 1, NULL, 't'},\n  {\"divisor for zero density\", 1, NULL, 'q'},\n  { 0, 0, 0}\n};\n\nfloat maximum_dif(float *difs, int n){\n  int i;\n  float max = 0.0f;\n  for(i=0; i<n; ++i){\n    max = difs[i] > max ? difs[i] : max;\n  }\n  return max;\n}\nint main(int argc, char *argv[]) {\n  int *pages;\n  float *maps;\n  float *page_ranks;\n  unsigned int *noutlinks;\n  int t;\n  float max_diff;\n\n  int i = 0;\n  int j;\n  int n = 1000;\n  int iter = max_iter;\n  float thresh = threshold;\n  int divisor = 2;\n  int nb_links = 0;\n\n  int opt, opt_index = 0;\n  while((opt = getopt_long(argc, argv, \"::n:i:t:q:\", size_opts, &opt_index)) != -1){\n    switch(opt){\n      case 'n':\n        n = atoi(optarg);\n        break;\n      case 'i':\n        iter = atoi(optarg);\n        break;\n      case 't':\n        thresh = atof(optarg);\n        break;\n      case 'q':\n        divisor = atoi(optarg);\n        break;\n      default:\n        usage(argv);\n        exit(EXIT_FAILURE);\n    }\n  }\n  page_ranks = (float*)malloc(sizeof(float)*n);\n  maps = (float*)malloc(sizeof(float)*n*n);\n  noutlinks = (unsigned int*)malloc(sizeof(unsigned int)*n);\n\n  max_diff=99.0f;\n\n  for (i=0; i<n; ++i) {\n    noutlinks[i] = 0;\n  }\n  pages = random_pages(n,noutlinks,divisor);\n  init_array(page_ranks, n, 1.0f / (float) n);\n\n  nb_links = 0;\n  for (i=0; i<n; ++i) {\n    for (j=0; j<n; ++j) {\n      nb_links += pages[i*n+j];\n    }\n  }\n\n  float *diffs;\n  diffs  = (float*) malloc(sizeof(float)*n);\n  for(i = 0; i < n; ++i){\n    diffs[i] = 0.0f;\n  }\n\n  size_t block_size  = n < BLOCK_SIZE ? n : BLOCK_SIZE;\n\n  double ktime = 0.0;\n\n   #pragma omp target data map(to: pages[0:n*n], \\\n                                   page_ranks[0:n], \\\n                                   noutlinks[0:n]) \\\n                           map(alloc: diffs[0:n]) \\\n                           map(alloc: maps[0:n*n]) \n   {\n     for (t=1; t<=iter && max_diff>=thresh; ++t) {\n       auto start = std::chrono::high_resolution_clock::now();\n   \n       #pragma omp target teams distribute parallel for thread_limit(block_size) \n       for (int i = 0; i < n; i++) {\n         float outbound_rank = page_ranks[i]/(float)noutlinks[i];\n         for(int j=0; j<n; ++j) maps[i*n+j] = pages[i*n+j]*outbound_rank;\n       }\n   \n       #pragma omp target teams distribute parallel for thread_limit(block_size) \n       for (int j = 0; j < n; j++) {\n         float new_rank;\n         float old_rank;\n         old_rank = page_ranks[j];\n         new_rank = 0.0f;\n         for(int i=0; i< n; ++i) new_rank += maps[i*n + j];\n         new_rank = ((1.f-D_FACTOR)/n)+(D_FACTOR*new_rank);\n         diffs[j] = fmaxf(fabsf(new_rank - old_rank), diffs[j]);\n         page_ranks[j] = new_rank;\n       }\n   \n       auto end = std::chrono::high_resolution_clock::now();\n       ktime += std::chrono::duration_cast<std::chrono::duration<double> >(end - start).count();\n   \n       #pragma omp target update from(diffs[0:n])\n       max_diff = maximum_dif(diffs, n);\n   \n       #pragma omp target teams distribute parallel for thread_limit(block_size) \n       for (int i = 0; i < n; i++)\n         diffs[i] = 0.f;\n     }\n   \n     fprintf(stderr, \"Max difference %f is reached at iteration %d\\n\", max_diff, t);\n     printf(\"\\\"Options\\\": \\\"-n %d -i %d -t %f\\\". Total kernel execution time: %lf (s)\\n\",\n            n, iter, thresh, ktime);\n  }\n\n  free(pages);\n  free(maps);\n  free(page_ranks);\n  free(noutlinks);\n  free(diffs);\n  return 0;\n}\n"}}
{"kernel_name": "page-rank", "parallel_api": "serial", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <math.h>\n#include <getopt.h>\n#include <chrono>\n\n#define D_FACTOR (0.85f)\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 256\n#endif\n\n\n\nconst int max_iter = 1000;\nconst float threshold= 1e-16f;\n\n\n\nint *random_pages(int n, unsigned int *noutlinks, int divisor){\n  int i, j, k;\n  int *pages = (int*) malloc(sizeof(int)*n*n); \n\n\n  if (divisor <= 0) {\n    fprintf(stderr, \"ERROR: Invalid divisor '%d' for random initialization, divisor should be greater or equal to 1\\n\", divisor);\n    exit(1);\n  }\n\n  for(i=0; i<n; ++i){\n    noutlinks[i] = 0;\n    for(j=0; j<n; ++j){\n      if(i!=j && (abs(rand())%divisor == 0)){\n        pages[i*n+j] = 1;\n        noutlinks[i] += 1;\n      }\n    }\n\n    \n\n    if(noutlinks[i] == 0){\n      do { k = abs(rand()) % n; } while ( k == i);\n      pages[i*n + k] = 1;\n      noutlinks[i] = 1;\n    }\n  }\n  return pages;\n}\n\nvoid init_array(float *a, int n, float val){\n  int i;\n  for(i=0; i<n; ++i){\n    a[i] = val;\n  }\n}\n\nvoid usage(char *argv[]){\n  fprintf(stderr, \"Usage: %s [-n number of pages] [-i max iterations]\"\n      \" [-t threshold] [-q divsor for zero density]\\n\", argv[0]);\n}\n\nstatic struct option size_opts[] =\n{\n  \n\n  {\"number of pages\", 1, NULL, 'n'},\n  {\"max number of iterations\", 1, NULL, 'i'},\n  {\"minimum threshold\", 1, NULL, 't'},\n  {\"divisor for zero density\", 1, NULL, 'q'},\n  { 0, 0, 0}\n};\n\nfloat maximum_dif(float *difs, int n){\n  int i;\n  float max = 0.0f;\n  for(i=0; i<n; ++i){\n    max = difs[i] > max ? difs[i] : max;\n  }\n  return max;\n}\nint main(int argc, char *argv[]) {\n  int *pages;\n  float *maps;\n  float *page_ranks;\n  unsigned int *noutlinks;\n  int t;\n  float max_diff;\n\n  int i = 0;\n  int j;\n  int n = 1000;\n  int iter = max_iter;\n  float thresh = threshold;\n  int divisor = 2;\n  int nb_links = 0;\n\n  int opt, opt_index = 0;\n  while((opt = getopt_long(argc, argv, \"::n:i:t:q:\", size_opts, &opt_index)) != -1){\n    switch(opt){\n      case 'n':\n        n = atoi(optarg);\n        break;\n      case 'i':\n        iter = atoi(optarg);\n        break;\n      case 't':\n        thresh = atof(optarg);\n        break;\n      case 'q':\n        divisor = atoi(optarg);\n        break;\n      default:\n        usage(argv);\n        exit(EXIT_FAILURE);\n    }\n  }\n  page_ranks = (float*)malloc(sizeof(float)*n);\n  maps = (float*)malloc(sizeof(float)*n*n);\n  noutlinks = (unsigned int*)malloc(sizeof(unsigned int)*n);\n\n  max_diff=99.0f;\n\n  for (i=0; i<n; ++i) {\n    noutlinks[i] = 0;\n  }\n  pages = random_pages(n,noutlinks,divisor);\n  init_array(page_ranks, n, 1.0f / (float) n);\n\n  nb_links = 0;\n  for (i=0; i<n; ++i) {\n    for (j=0; j<n; ++j) {\n      nb_links += pages[i*n+j];\n    }\n  }\n\n  float *diffs;\n  diffs  = (float*) malloc(sizeof(float)*n);\n  for(i = 0; i < n; ++i){\n    diffs[i] = 0.0f;\n  }\n\n  size_t block_size  = n < BLOCK_SIZE ? n : BLOCK_SIZE;\n\n  double ktime = 0.0;\n\n      {\n     for (t=1; t<=iter && max_diff>=thresh; ++t) {\n       auto start = std::chrono::high_resolution_clock::now();\n   \n              for (int i = 0; i < n; i++) {\n         float outbound_rank = page_ranks[i]/(float)noutlinks[i];\n         for(int j=0; j<n; ++j) maps[i*n+j] = pages[i*n+j]*outbound_rank;\n       }\n   \n              for (int j = 0; j < n; j++) {\n         float new_rank;\n         float old_rank;\n         old_rank = page_ranks[j];\n         new_rank = 0.0f;\n         for(int i=0; i< n; ++i) new_rank += maps[i*n + j];\n         new_rank = ((1.f-D_FACTOR)/n)+(D_FACTOR*new_rank);\n         diffs[j] = fmaxf(fabsf(new_rank - old_rank), diffs[j]);\n         page_ranks[j] = new_rank;\n       }\n   \n       auto end = std::chrono::high_resolution_clock::now();\n       ktime += std::chrono::duration_cast<std::chrono::duration<double> >(end - start).count();\n   \n              max_diff = maximum_dif(diffs, n);\n   \n              for (int i = 0; i < n; i++)\n         diffs[i] = 0.f;\n     }\n   \n     fprintf(stderr, \"Max difference %f is reached at iteration %d\\n\", max_diff, t);\n     printf(\"\\\"Options\\\": \\\"-n %d -i %d -t %f\\\". Total kernel execution time: %lf (s)\\n\",\n            n, iter, thresh, ktime);\n  }\n\n  free(pages);\n  free(maps);\n  free(page_ranks);\n  free(noutlinks);\n  free(diffs);\n  return 0;\n}"}}
{"kernel_name": "page-rank", "parallel_api": "sycl", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <time.h>\n#include <math.h>\n#include <getopt.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#ifdef __NVPTX__\n  #include <sycl/ext/oneapi/experimental/cuda/builtins.hpp>\n  using namespace sycl::ext::oneapi::experimental::cuda;\n#else\n  #define ldg(a) (*(a))\n#endif\n\n#define D_FACTOR (0.85f)\n#ifndef BLOCK_SIZE\n#define BLOCK_SIZE 256\n#endif\n\n\n\nconst int max_iter = 1000;\nconst float threshold= 1e-16f;\n\n\n\nint *random_pages(int n, unsigned int *noutlinks, int divisor){\n  int i, j, k;\n  int *pages = (int*) malloc(sizeof(int)*n*n); \n\n\n  if (divisor <= 0) {\n    fprintf(stderr, \"ERROR: Invalid divisor '%d' for random initialization, divisor should be greater or equal to 1\\n\", divisor);\n    exit(1);\n  }\n\n  for(i=0; i<n; ++i){\n    noutlinks[i] = 0;\n    for(j=0; j<n; ++j){\n      if(i!=j && (abs(rand())%divisor == 0)){\n        pages[i*n+j] = 1;\n        noutlinks[i] += 1;\n      }\n    }\n\n    \n\n    if(noutlinks[i] == 0){\n      do { k = abs(rand()) % n; } while ( k == i);\n      pages[i*n + k] = 1;\n      noutlinks[i] = 1;\n    }\n  }\n  return pages;\n}\n\nvoid init_array(float *a, int n, float val){\n  int i;\n  for(i=0; i<n; ++i){\n    a[i] = val;\n  }\n}\n\nvoid usage(char *argv[]){\n  fprintf(stderr, \"Usage: %s [-n number of pages] [-i max iterations]\"\n                  \" [-t threshold] [-q divsor for zero density]\\n\", argv[0]);\n}\n\nstatic struct option size_opts[] =\n{\n  \n\n  {\"number of pages\", 1, NULL, 'n'},\n  {\"max number of iterations\", 1, NULL, 'i'},\n  {\"minimum threshold\", 1, NULL, 't'},\n  {\"divisor for zero density\", 1, NULL, 'q'},\n  { 0, 0, 0}\n};\n\nfloat maximum_dif(float *difs, int n){\n  int i;\n  float max = 0.0f;\n  for(i=0; i<n; ++i){\n    max = difs[i] > max ? difs[i] : max;\n  }\n  return max;\n}\n\nint main(int argc, char *argv[]) {\n  int *pages;\n  float *maps;\n  float *page_ranks;\n  unsigned int *noutlinks;\n  int t;\n  float max_diff;\n\n  int i = 0;\n  int j;\n  int n = 1000;\n  int iter = max_iter;\n  float thresh = threshold;\n  int divisor = 2;\n  int nb_links = 0;\n\n  int opt, opt_index = 0;\n  while((opt = getopt_long(argc, argv, \"::n:i:t:q:\", size_opts, &opt_index)) != -1){\n    switch(opt){\n      case 'n':\n        n = atoi(optarg);\n        break;\n      case 'i':\n        iter = atoi(optarg);\n        break;\n      case 't':\n        thresh = atof(optarg);\n        break;\n      case 'q':\n        divisor = atoi(optarg);\n        break;\n      default:\n        usage(argv);\n        exit(EXIT_FAILURE);\n    }\n  }\n  page_ranks = (float*)malloc(sizeof(float)*n);\n  maps = (float*)malloc(sizeof(float)*n*n);\n  noutlinks = (unsigned int*)malloc(sizeof(unsigned int)*n);\n\n  max_diff=99.0f;\n\n  for (i=0; i<n; ++i) {\n    noutlinks[i] = 0;\n  }\n  pages = random_pages(n,noutlinks,divisor);\n  init_array(page_ranks, n, 1.0f / (float) n);\n\n  nb_links = 0;\n  for (i=0; i<n; ++i) {\n    for (j=0; j<n; ++j) {\n      nb_links += pages[i*n+j];\n    }\n  }\n\n  float *diffs;\n  diffs  = (float*) malloc(sizeof(float)*n);\n  for(i = 0; i < n; ++i){\n    diffs[i] = 0.0f;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_pages = sycl::malloc_device<int>(n*n, q);\n  q.memcpy(d_pages, pages, sizeof(int) * n * n);\n\n  float *d_page_ranks = sycl::malloc_device<float>(n, q);\n  q.memcpy(d_page_ranks, page_ranks, sizeof(float) * n);\n\n  float *d_maps = sycl::malloc_device<float>(n*n, q);\n\n  unsigned int *d_noutlinks = sycl::malloc_device<unsigned int>(n, q);\n  q.memcpy(d_noutlinks, noutlinks, sizeof(unsigned int) * n);\n\n  float *d_diffs = sycl::malloc_device<float>(n, q);\n\n  size_t block_size  = n < BLOCK_SIZE ? n : BLOCK_SIZE;\n  size_t global_work_size = (n+block_size-1) / block_size * block_size;\n\n  sycl::range<1> gws (global_work_size);\n  sycl::range<1> lws (block_size);\n\n  q.wait();\n  double ktime = 0.0;\n\n  for (t=1; t<=iter && max_diff>=thresh; ++t) {\n    auto start = std::chrono::high_resolution_clock::now();\n\n    \n\n    q.submit([&](sycl::handler& cgh) {\n      cgh.parallel_for<class map>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i < n) {\n          float outbound_rank = ldg(&d_page_ranks[i])/(float)ldg(&d_noutlinks[i]);\n          for(int j=0; j<n; ++j)\n            d_maps[i*n+j] = ldg(&d_pages[i*n+j])*outbound_rank;\n        }\n      });\n    });\n\n    \n\n    q.submit([&](sycl::handler& cgh) {\n      cgh.parallel_for<class reduce>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int j = item.get_global_id(0);\n        float new_rank;\n        float old_rank;\n        if (j < n) {\n          old_rank = d_page_ranks[j];\n          new_rank = 0.0f;\n          for(int i=0; i< n; ++i) new_rank += d_maps[i*n + j];\n          new_rank = ((1.f-D_FACTOR)/n)+(D_FACTOR*new_rank);\n          d_diffs[j] = sycl::max(sycl::fabs(new_rank - old_rank), d_diffs[j]);\n          d_page_ranks[j] = new_rank;\n        }\n      });\n    });\n\n    q.wait();\n    auto end = std::chrono::high_resolution_clock::now();\n    ktime += std::chrono::duration_cast<std::chrono::duration<double>>(end - start).count();\n\n    q.memcpy(diffs, d_diffs, sizeof(float)*n).wait();\n    q.memset(d_diffs, 0, sizeof(float)*n);\n\n    max_diff = maximum_dif(diffs, n);\n  }\n\n  sycl::free(d_pages, q);\n  sycl::free(d_maps, q);\n  sycl::free(d_page_ranks, q);\n  sycl::free(d_noutlinks, q);\n  sycl::free(d_diffs, q);\n\n  fprintf(stderr, \"Max difference %f is reached at iteration %d\\n\", max_diff, t);\n  printf(\"\\\"Options\\\": \\\"-n %d -i %d -t %f\\\". Total kernel execution time: %lf (s)\\n\",\n         n, iter, thresh, ktime);\n\n  free(pages);\n  free(maps);\n  free(page_ranks);\n  free(noutlinks);\n  free(diffs);\n  return 0;\n}\n"}}
{"kernel_name": "perplexity", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <float.h>\n#include <chrono>\n#include <vector>\n#include <cuda.h>\n\n#include \"reference.cpp\"\n\n\n\ntemplate <typename value_idx, typename value_t>\n__global__\nvoid sigmas_kernel(const value_t* __restrict__ distances,\n                         value_t* __restrict__ P,\n                   const float perplexity,\n                   const float desired_entropy,\n                   const int epochs,\n                   const float tol,\n                   const value_idx n,\n                   const int k)\n{\n  \n\n  const int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= n) return;\n\n  value_t beta_min = -INFINITY, beta_max = INFINITY;\n  value_t beta = 1;\n  const int ik = i * k;\n  int step;\n\n  for (step = 0; step < epochs; step++) {\n    value_t sum_Pi = FLT_EPSILON;\n\n    \n\n    for (int j = 0; j < k; j++) {\n      P[ik + j] = __expf(-distances[ik + j] * beta);\n      sum_Pi += P[ik + j];\n    }\n\n    \n\n    value_t sum_disti_Pi = 0;\n    const value_t div    = __fdividef(1.0f, sum_Pi);\n    for (int j = 0; j < k; j++) {\n      P[ik + j] *= div;\n      sum_disti_Pi += distances[ik + j] * P[ik + j];\n    }\n\n    const value_t entropy      = __logf(sum_Pi) + beta * sum_disti_Pi;\n    const value_t entropy_diff = entropy - desired_entropy;\n    if (fabsf(entropy_diff) <= tol) {\n      break;\n    }\n\n    \n\n    if (entropy_diff > 0) {\n      beta_min = beta;\n      if (isinf(beta_max))\n        beta *= 2.0f;\n      else\n        beta = (beta + beta_max) * 0.5f;\n    } else {\n      beta_max = beta;\n      if (isinf(beta_min))\n        beta *= 0.5f;\n      else\n        beta = (beta + beta_min) * 0.5f;\n    }\n  }\n}\n\n\n\ntemplate <typename value_idx, typename value_t>\nvoid perplexity_search(const value_t* __restrict__ distances,\n                       value_t* __restrict__ P,\n                       const float perplexity,\n                       const int epochs,\n                       const float tol,\n                       const value_idx n,\n                       const int dim,\n                       double &time)\n{\n  const float desired_entropy = logf(perplexity);\n  dim3 grid ((n+255)/256);\n  dim3 block (256);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  sigmas_kernel<<<grid, block>>>(distances, P, perplexity, desired_entropy, epochs, tol, n, dim);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of points> <perplexity> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]); \n\n  const int p = atoi(argv[2]); \n\n  const int repeat = atoi(argv[3]);\n\n  const int n_nbrs = 4 * p;    \n\n  const int max_iter = 100;    \n\n  const float tol = 1e-8f;     \n\n\n  srand(123); \n  std::vector<float> data(n * n_nbrs);\n  std::vector<float> h_data(n * n_nbrs);\n  std::vector<float> distance(n * n_nbrs);\n  for (int i = 0; i < n * n_nbrs; i++) {\n    distance[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *d_data;\n  cudaMalloc((void**)&d_data, sizeof(float)*n*n_nbrs);\n\n  float *d_distance;\n  cudaMalloc((void**)&d_distance, sizeof(float)*n*n_nbrs);\n\n  cudaMemcpy(d_distance, distance.data(), sizeof(float)*n*n_nbrs, cudaMemcpyHostToDevice); \n\n  double time = 0.0;\n\n  for (int i = 0; i < repeat; i++)\n    perplexity_search(d_distance, d_data, p, max_iter, tol, n, n_nbrs, time);\n\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(data.data(), d_data, sizeof(float)*n*n_nbrs, cudaMemcpyDeviceToHost); \n\n  \n\n  reference(distance.data(), h_data.data(), p, max_iter, tol, n, n_nbrs);\n\n  bool ok = true;\n  for (int i = 0; i < n*n_nbrs; i++) {\n    if (fabsf(data[i] - h_data[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, data[i], h_data[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n  cudaFree(d_distance);\n  cudaFree(d_data);\n  return 0;\n}\n"}}
{"kernel_name": "perplexity", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <float.h>\n#include <chrono>\n#include <vector>\n#include <hip/hip_runtime.h>\n\n#include \"reference.cpp\"\n\n\n\ntemplate <typename value_idx, typename value_t>\n__global__\nvoid sigmas_kernel(const value_t* __restrict__ distances,\n                         value_t* __restrict__ P,\n                   const float perplexity,\n                   const float desired_entropy,\n                   const int epochs,\n                   const float tol,\n                   const value_idx n,\n                   const int k)\n{\n  \n\n  const int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= n) return;\n\n  value_t beta_min = -INFINITY, beta_max = INFINITY;\n  value_t beta = 1;\n  const int ik = i * k;\n  int step;\n\n  for (step = 0; step < epochs; step++) {\n    value_t sum_Pi = FLT_EPSILON;\n\n    \n\n    for (int j = 0; j < k; j++) {\n      P[ik + j] = __expf(-distances[ik + j] * beta);\n      sum_Pi += P[ik + j];\n    }\n\n    \n\n    value_t sum_disti_Pi = 0;\n    const value_t div    = __fdividef(1.0f, sum_Pi);\n    for (int j = 0; j < k; j++) {\n      P[ik + j] *= div;\n      sum_disti_Pi += distances[ik + j] * P[ik + j];\n    }\n\n    const value_t entropy      = __logf(sum_Pi) + beta * sum_disti_Pi;\n    const value_t entropy_diff = entropy - desired_entropy;\n    if (fabsf(entropy_diff) <= tol) {\n      break;\n    }\n\n    \n\n    if (entropy_diff > 0) {\n      beta_min = beta;\n      if (isinf(beta_max))\n        beta *= 2.0f;\n      else\n        beta = (beta + beta_max) * 0.5f;\n    } else {\n      beta_max = beta;\n      if (isinf(beta_min))\n        beta *= 0.5f;\n      else\n        beta = (beta + beta_min) * 0.5f;\n    }\n  }\n}\n\n\n\ntemplate <typename value_idx, typename value_t>\nvoid perplexity_search(const value_t* __restrict__ distances,\n                       value_t* __restrict__ P,\n                       const float perplexity,\n                       const int epochs,\n                       const float tol,\n                       const value_idx n,\n                       const int dim,\n                       double &time)\n{\n  const float desired_entropy = logf(perplexity);\n  dim3 grid ((n+255)/256);\n  dim3 block (256);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  hipLaunchKernelGGL(sigmas_kernel, grid, block, 0, 0, distances, P, perplexity, desired_entropy, epochs, tol, n, dim);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of points> <perplexity> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]); \n\n  const int p = atoi(argv[2]); \n\n  const int repeat = atoi(argv[3]);\n\n  const int n_nbrs = 4 * p;    \n\n  const int max_iter = 100;    \n\n  const float tol = 1e-8f;     \n\n\n  srand(123); \n  std::vector<float> data(n * n_nbrs);\n  std::vector<float> h_data(n * n_nbrs);\n  std::vector<float> distance(n * n_nbrs);\n  for (int i = 0; i < n * n_nbrs; i++) {\n    distance[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *d_data;\n  hipMalloc((void**)&d_data, sizeof(float)*n*n_nbrs);\n\n  float *d_distance;\n  hipMalloc((void**)&d_distance, sizeof(float)*n*n_nbrs);\n\n  hipMemcpy(d_distance, distance.data(), sizeof(float)*n*n_nbrs, hipMemcpyHostToDevice); \n\n  double time = 0.0;\n\n  for (int i = 0; i < repeat; i++)\n    perplexity_search(d_distance, d_data, p, max_iter, tol, n, n_nbrs, time);\n\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(data.data(), d_data, sizeof(float)*n*n_nbrs, hipMemcpyDeviceToHost); \n\n  \n\n  reference(distance.data(), h_data.data(), p, max_iter, tol, n, n_nbrs);\n\n  bool ok = true;\n  for (int i = 0; i < n*n_nbrs; i++) {\n    if (fabsf(data[i] - h_data[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, data[i], h_data[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n  hipFree(d_distance);\n  hipFree(d_data);\n  return 0;\n}\n"}}
{"kernel_name": "perplexity", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <float.h>\n#include <chrono>\n#include <vector>\n#include <omp.h>\n\n#include \"reference.cpp\"\n\ntemplate <typename value_idx, typename value_t>\nvoid perplexity_search(const value_t* __restrict distances,\n                       value_t* __restrict P,\n                       const float perplexity,\n                       const int epochs,\n                       const float tol,\n                       const value_idx n,\n                       const int k,\n                       double &time)\n{\n  const float desired_entropy = logf(perplexity);\n\n  auto start = std::chrono::steady_clock::now();\n\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < n; i++) {\n    value_t beta_min = -INFINITY, beta_max = INFINITY;\n    value_t beta = 1;\n    const int ik = i * k;\n    int step;\n\n    for (step = 0; step < epochs; step++) {\n      value_t sum_Pi = FLT_EPSILON;\n\n      \n\n      for (int j = 0; j < k; j++) {\n        P[ik + j] = expf(-distances[ik + j] * beta);\n        sum_Pi += P[ik + j];\n      }\n\n      \n\n      value_t sum_disti_Pi = 0;\n      const value_t div    = 1.0f / sum_Pi;\n      for (int j = 0; j < k; j++) {\n        P[ik + j] *= div;\n        sum_disti_Pi += distances[ik + j] * P[ik + j];\n      }\n\n      const value_t entropy      = logf(sum_Pi) + beta * sum_disti_Pi;\n      const value_t entropy_diff = entropy - desired_entropy;\n      if (fabsf(entropy_diff) <= tol) {\n        break;\n      }\n\n      \n\n      if (entropy_diff > 0) {\n        beta_min = beta;\n        if (isinf(beta_max))\n          beta *= 2.0f;\n        else\n          beta = (beta + beta_max) * 0.5f;\n      } else {\n        beta_max = beta;\n        if (isinf(beta_min))\n          beta *= 0.5f;\n        else\n          beta = (beta + beta_min) * 0.5f;\n      }\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of points> <perplexity> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]); \n\n  const int p = atoi(argv[2]); \n\n  const int repeat = atoi(argv[3]);\n\n  const int n_nbrs = 4 * p;    \n\n  const int max_iter = 100;    \n\n  const float tol = 1e-8f;     \n\n\n  srand(123); \n  std::vector<float> data(n * n_nbrs);\n  std::vector<float> h_data(n * n_nbrs);\n  std::vector<float> distance(n * n_nbrs);\n  for (int i = 0; i < n * n_nbrs; i++) {\n    distance[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *d_data = data.data();\n  const float *d_distance = distance.data();\n\n  #pragma omp target data map (from: d_data[0:n*n_nbrs]) map(to: d_distance[0:n*n_nbrs])\n  {\n    double time = 0.0;\n  \n    for (int i = 0; i < repeat; i++)\n      perplexity_search(d_distance, d_data, p, max_iter, tol, n, n_nbrs, time);\n  \n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference(distance.data(), h_data.data(), p, max_iter, tol, n, n_nbrs);\n\n  bool ok = true;\n  for (int i = 0; i < n*n_nbrs; i++) {\n    if (fabsf(data[i] - h_data[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, data[i], h_data[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n  return 0;\n}\n"}}
{"kernel_name": "perplexity", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <float.h>\n#include <chrono>\n#include <vector>\n\n#include \"reference.cpp\"\n\ntemplate <typename value_idx, typename value_t>\nvoid perplexity_search(const value_t* __restrict distances,\n                       value_t* __restrict P,\n                       const float perplexity,\n                       const int epochs,\n                       const float tol,\n                       const value_idx n,\n                       const int k,\n                       double &time)\n{\n  const float desired_entropy = logf(perplexity);\n\n  auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < n; i++) {\n    value_t beta_min = -INFINITY, beta_max = INFINITY;\n    value_t beta = 1;\n    const int ik = i * k;\n    int step;\n\n    for (step = 0; step < epochs; step++) {\n      value_t sum_Pi = FLT_EPSILON;\n\n      \n\n      for (int j = 0; j < k; j++) {\n        P[ik + j] = expf(-distances[ik + j] * beta);\n        sum_Pi += P[ik + j];\n      }\n\n      \n\n      value_t sum_disti_Pi = 0;\n      const value_t div    = 1.0f / sum_Pi;\n      for (int j = 0; j < k; j++) {\n        P[ik + j] *= div;\n        sum_disti_Pi += distances[ik + j] * P[ik + j];\n      }\n\n      const value_t entropy      = logf(sum_Pi) + beta * sum_disti_Pi;\n      const value_t entropy_diff = entropy - desired_entropy;\n      if (fabsf(entropy_diff) <= tol) {\n        break;\n      }\n\n      \n\n      if (entropy_diff > 0) {\n        beta_min = beta;\n        if (isinf(beta_max))\n          beta *= 2.0f;\n        else\n          beta = (beta + beta_max) * 0.5f;\n      } else {\n        beta_max = beta;\n        if (isinf(beta_min))\n          beta *= 0.5f;\n        else\n          beta = (beta + beta_min) * 0.5f;\n      }\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of points> <perplexity> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]); \n\n  const int p = atoi(argv[2]); \n\n  const int repeat = atoi(argv[3]);\n\n  const int n_nbrs = 4 * p;    \n\n  const int max_iter = 100;    \n\n  const float tol = 1e-8f;     \n\n\n  srand(123); \n  std::vector<float> data(n * n_nbrs);\n  std::vector<float> h_data(n * n_nbrs);\n  std::vector<float> distance(n * n_nbrs);\n  for (int i = 0; i < n * n_nbrs; i++) {\n    distance[i] = rand() / (float)RAND_MAX;\n  }\n\n  float *d_data = data.data();\n  const float *d_distance = distance.data();\n\n    {\n    double time = 0.0;\n  \n    for (int i = 0; i < repeat; i++)\n      perplexity_search(d_distance, d_data, p, max_iter, tol, n, n_nbrs, time);\n  \n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference(distance.data(), h_data.data(), p, max_iter, tol, n, n_nbrs);\n\n  bool ok = true;\n  for (int i = 0; i < n*n_nbrs; i++) {\n    if (fabsf(data[i] - h_data[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, data[i], h_data[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n  return 0;\n}"}}
{"kernel_name": "perplexity", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <float.h>\n#include <chrono>\n#include <vector>\n#include <sycl/sycl.hpp>\n\n#include \"reference.cpp\"\n\n\n\ntemplate <typename value_idx, typename value_t>\nclass search;\n\n\n\ntemplate <typename value_idx, typename value_t>\nvoid perplexity_search(sycl::queue &q,\n                       const value_t *d_distances,\n                       value_t *d_data,\n                       const float perplexity,\n                       const int epochs,\n                       const float tol,\n                       const value_idx n,\n                       const int k,\n                       double &time)\n{\n  const float desired_entropy = logf(perplexity);\n  sycl::range<1> gws ((n+255)/256*256);\n  sycl::range<1> lws  (256);\n\n  auto start = std::chrono::steady_clock::now();\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class search<value_idx, value_t>>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      \n\n      const int i = item.get_global_id(0);\n      if (i >= n) return;\n\n      value_t beta_min = -INFINITY, beta_max = INFINITY;\n      value_t beta = 1;\n      const int ik = i * k;\n      int step;\n\n      for (step = 0; step < epochs; step++) {\n        value_t sum = FLT_EPSILON;\n\n        \n\n        for (int j = 0; j < k; j++) {\n          d_data[ik + j] = sycl::native::exp(-d_distances[ik + j] * beta);\n          sum += d_data[ik + j];\n        }\n\n        \n\n        value_t sum_dist = 0;\n        const value_t div    = sycl::native::divide(1.0f, sum);\n        for (int j = 0; j < k; j++) {\n          d_data[ik + j] *= div;\n          sum_dist += d_distances[ik + j] * d_data[ik + j];\n        }\n\n        const value_t entropy      = sycl::native::log(sum) + beta * sum_dist;\n        const value_t entropy_diff = entropy - desired_entropy;\n        if (sycl::fabs(entropy_diff) <= tol) {\n          break;\n        }\n\n        \n\n        if (entropy_diff > 0) {\n          beta_min = beta;\n          if (sycl::isinf(beta_max))\n            beta *= 2.0f;\n          else\n            beta = (beta + beta_max) * 0.5f;\n        } else {\n          beta_max = beta;\n          if (sycl::isinf(beta_min))\n            beta *= 0.5f;\n          else\n            beta = (beta + beta_min) * 0.5f;\n        }\n      }\n    });\n  });\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of points> <perplexity> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]); \n\n  const int p = atoi(argv[2]); \n\n  const int repeat = atoi(argv[3]);\n\n  const int n_nbrs = 4 * p;    \n\n  const int max_iter = 100;    \n\n  const float tol = 1e-8f;     \n\n\n  srand(123);\n  std::vector<float> data(n * n_nbrs);\n  std::vector<float> h_data(n * n_nbrs);\n  std::vector<float> distance(n * n_nbrs);\n  for (int i = 0; i < n * n_nbrs; i++) {\n    distance[i] = rand() / (float)RAND_MAX;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_data = sycl::malloc_device<float>(n*n_nbrs, q);\n\n  float *d_distance = sycl::malloc_device<float>(n*n_nbrs, q);\n  q.memcpy(d_distance, distance.data(), sizeof(float)*n*n_nbrs).wait();\n\n  double time = 0.0;\n\n  for (int i = 0; i < repeat; i++)\n    perplexity_search(q, d_distance, d_data, p, max_iter, tol, n, n_nbrs, time);\n\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(data.data(), d_data, sizeof(float)*n*n_nbrs).wait();\n\n  \n\n  reference(distance.data(), h_data.data(), p, max_iter, tol, n, n_nbrs);\n\n  bool ok = true;\n  for (int i = 0; i < n*n_nbrs; i++) {\n    if (fabsf(data[i] - h_data[i]) > 1e-3f) {\n      printf(\"%d %f %f\\n\", i, data[i], h_data[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_distance, q);\n  sycl::free(d_data, q);\n  return 0;\n}\n\n"}}
{"kernel_name": "pointwise", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n\n\n#define cudaErrCheck(stat) { cudaErrCheck_((stat), __FILE__, __LINE__); }\nvoid cudaErrCheck_(cudaError_t stat, const char *file, int line) {\n  if (stat != cudaSuccess) {\n    fprintf(stderr, \"CUDA Error: %s %s %d\\n\", cudaGetErrorString(stat), file, line);\n  }\n}\n\ntypedef struct {\n  double i, c, h;\n} checksum;\n\n\n\n__forceinline__ __device__ float sigmoidf(float in) {\n  return 1.f / (1.f + expf(-in));  \n}\n\n\n\n__global__ \nvoid elementWise_fp(int hiddenSize, int miniBatch,\n    const float *__restrict__ tmp_h, \n    const float *__restrict__ tmp_i, \n    const float *__restrict__ bias,\n    float *__restrict__ linearGates,\n    float *__restrict__ h_out,\n    float *__restrict__ i_out,\n    const float *__restrict__ c_in,\n    float *__restrict__ c_out)\n{\n  int index = blockIdx.x * blockDim.x + threadIdx.x;\n  int numElements = miniBatch * hiddenSize;\n\n  if (index >= numElements) return;\n\n  int batch = index / hiddenSize;\n  int gateIndex = (index % hiddenSize) + 4 * batch * hiddenSize;   \n\n  float g[4];\n\n  for (int i = 0; i < 4; i++) {\n    g[i] = tmp_i[i * hiddenSize + gateIndex] + tmp_h[i * hiddenSize + gateIndex];\n    g[i] += bias[i * hiddenSize + index % hiddenSize] + bias[(i + 4) * hiddenSize + index % hiddenSize];\n    linearGates[gateIndex + i * hiddenSize] = g[i];\n  }   \n\n  float in_gate     = sigmoidf(g[0]);\n  float forget_gate = sigmoidf(g[1]);\n  float in_gate2    = tanhf(g[2]);\n  float out_gate    = sigmoidf(g[3]);\n\n  float val = (forget_gate * c_in[index]) + (in_gate * in_gate2);\n\n  c_out[index] = val;\n\n  val = out_gate * tanhf(val);                                   \n\n  h_out[index] = val;\n  i_out[index] = val;\n}\n\n__device__\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n__global__\nvoid init (float* data, int size) {\n  int index = blockIdx.x * blockDim.x + threadIdx.x;\n  if (index >= size) return;\n  unsigned int seed = index ^ size;\n  data[index] = LCG_random(&seed);\n}\n\nvoid test(int hiddenSize, int miniBatch, int seqLength, int numLayers,\n          checksum &cs, double &time) {\n  float *h_data;\n  float *i_data;\n  float *c_data;\n  float *bias;\n  float *tmp_h;\n  float *tmp_i;\n  float *linearGates;\n\n  \n\n  int numElements = hiddenSize * miniBatch;\n\n  int hc_size = (seqLength + 1) * (numLayers) * numElements;\n  int i_size = (seqLength) * (numLayers + 1) * numElements;\n  int bias_size = numLayers * hiddenSize * 8;\n  int tmp_h_size = 4 * numLayers * numElements;\n  int tmp_i_size = 4 * seqLength * numElements;\n\n  cudaErrCheck(cudaMalloc((void**)&h_data, hc_size * sizeof(float)));\n  cudaErrCheck(cudaMalloc((void**)&i_data, i_size * sizeof(float)));\n  cudaErrCheck(cudaMalloc((void**)&c_data, hc_size * sizeof(float)));\n  cudaErrCheck(cudaMalloc((void**)&bias, bias_size * sizeof(float)));\n\n  \n\n  cudaErrCheck(cudaMalloc((void**)&tmp_h, tmp_h_size * sizeof(float)));\n  cudaErrCheck(cudaMalloc((void**)&tmp_i, tmp_i_size * sizeof(float)));\n\n  \n\n  cudaErrCheck(cudaMalloc((void**)&linearGates, 4 * seqLength * numLayers * numElements * sizeof(float)));  \n\n  \n\n  dim3 blocks (256);\n  dim3 grids_hc ((hc_size + 255)/256);\n  dim3 grids_b ((bias_size + 255)/256);\n  dim3 grids_tmp_h ((tmp_h_size + 255)/256);\n  dim3 grids_tmp_i ((tmp_i_size + 255)/256);\n          \n  init <<< grids_tmp_h, blocks >>> (tmp_h, tmp_h_size);\n  init <<< grids_tmp_i, blocks >>> (tmp_i, tmp_i_size);\n  init <<< grids_hc, blocks >>> (c_data, hc_size);\n  init <<< grids_b, blocks >>> (bias, bias_size);\n\n  cudaDeviceSynchronize();\n\n  int lStart = 0;\n  int lEnd = 0;\n  int rStart = 0;\n  int rEnd = 0;\n  int recurBatchSize = 2;\n\n  dim3 grids_p ((numElements + 255)/256);\n  \n  double ktime = 0.0;\n\n  while (true) {\n    \n\n    if (lEnd == 0) {\n      lStart = 0;\n      lEnd = 1;\n      rStart = 0;\n    }\n    else {\n      \n\n      lStart++;\n      lEnd++;\n\n      rStart -= recurBatchSize;\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        rStart += (lStart + 1) * recurBatchSize;\n\n        lStart = 0;\n        lEnd = 1;\n      }\n\n      \n\n      while (rStart >= seqLength && lEnd <= numLayers) {\n        lStart++;\n        lEnd++;\n        rStart -= recurBatchSize;\n      }\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        break;\n      }\n    }\n\n    rEnd = rStart + recurBatchSize;\n    if (rEnd > seqLength) rEnd = seqLength;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int layer = lStart; layer < lEnd; layer++) {\n      for (int i = rStart; i < rEnd; i++)\n        elementWise_fp <<< grids_p, blocks >>> \n        (hiddenSize, miniBatch,\n         tmp_h + 4 * layer * numElements, \n         tmp_i + 4 * i * numElements, \n         bias + 8 * layer * hiddenSize,\n         linearGates + 4 * (i * numElements + layer * seqLength * numElements),\n         h_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements,\n         i_data + i * numElements + (layer + 1) * seqLength * numElements,\n         c_data + i * numElements + layer * (seqLength + 1) * numElements,\n         c_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements);\n      cudaErrCheck(cudaGetLastError());\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  time += ktime;\n  \n\n\n  float *testOutputi = (float*)malloc(numElements * seqLength * sizeof(float));\n  float *testOutputh = (float*)malloc(numElements * numLayers * sizeof(float));\n  float *testOutputc = (float*)malloc(numElements * numLayers * sizeof(float));\n\n  cudaDeviceSynchronize();\n  \n  cudaErrCheck(cudaMemcpy(testOutputi, i_data + numLayers * seqLength * numElements, \n    seqLength * numElements * sizeof(float), cudaMemcpyDeviceToHost));\n  for (int layer = 0; layer < numLayers; layer++) {\n    cudaErrCheck(cudaMemcpy(testOutputh + layer * numElements, \n      h_data + seqLength * numElements + layer * (seqLength + 1) * numElements, \n      numElements * sizeof(float), cudaMemcpyDeviceToHost));\n    cudaErrCheck(cudaMemcpy(testOutputc + layer * numElements, \n      c_data + seqLength * numElements + layer * (seqLength + 1) * numElements, \n      numElements * sizeof(float), cudaMemcpyDeviceToHost));\n  }\n\n  double checksumi = 0.0;\n  double checksumh = 0.0;\n  double checksumc = 0.0;\n\n  for (int m = 0; m < miniBatch; m++) {\n    for (int j = 0; j < seqLength; j++) {\n      for (int i = 0; i < hiddenSize; i++) {\n        checksumi += testOutputi[j * numElements + m * hiddenSize + i];\n        \n\n      }\n    }\n    for (int j = 0; j < numLayers; j++) {\n      for (int i = 0; i < hiddenSize; i++) {         \n        checksumh += testOutputh[j * numElements + m * hiddenSize + i];\n        checksumc += testOutputc[j * numElements + m * hiddenSize + i];\n      }\n    }\n  }\n\n  free(testOutputi);\n  free(testOutputc);\n  free(testOutputh);\n\n  cudaErrCheck(cudaFree(h_data));\n  cudaErrCheck(cudaFree(i_data));  \n  cudaErrCheck(cudaFree(c_data));  \n\n  cudaErrCheck(cudaFree(bias));\n  cudaErrCheck(cudaFree(tmp_h));\n  cudaErrCheck(cudaFree(tmp_i));\n  cudaErrCheck(cudaFree(linearGates));\n\n  cs.i = checksumi;\n  cs.c = checksumc;\n  cs.h = checksumh;\n}\n\nint main(int argc, char* argv[]) {\n  int seqLength;\n  int numLayers;\n  int hiddenSize;\n  int miniBatch; \n  int numRuns; \n\n  if (argc == 6) {\n    seqLength = atoi(argv[1]);\n    numLayers = atoi(argv[2]);\n    hiddenSize = atoi(argv[3]);\n    miniBatch = atoi(argv[4]);   \n    numRuns = atoi(argv[5]);   \n  }\n  else if (argc == 1) {\n    printf(\"Running with default settings\\n\");\n    seqLength = 100;\n    numLayers = 4;\n    hiddenSize = 512;\n    miniBatch = 64;\n    numRuns = 1;\n  }\n  else {\n    printf(\"Usage: %s <seqLength> <numLayers> <hiddenSize> <miniBatch> <repeat>\\n\", argv[0]);\n    return 1;      \n  }\n\n  printf(\"seqLength %d, numLayers %d, hiddenSize %d, miniBatch %d\\n\",\n         seqLength, numLayers, hiddenSize, miniBatch);  \n\n  checksum cs;\n  \n  double time = 0.0;\n\n  for (int run = 0; run < numRuns; run++) {\n    test(hiddenSize, miniBatch, seqLength, numLayers, cs, time);\n  }\n\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / numRuns);\n  printf(\"i checksum %E     \", cs.i);\n  printf(\"c checksum %E     \", cs.c);\n  printf(\"h checksum %E\\n\", cs.h);\n  return 0;\n}\n"}}
{"kernel_name": "pointwise", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n\n\n#define hipErrCheck(stat) { hipErrCheck_((stat), __FILE__, __LINE__); }\nvoid hipErrCheck_(hipError_t stat, const char *file, int line) {\n  if (stat != hipSuccess) {\n    fprintf(stderr, \"HIP Error: %s %s %d\\n\", hipGetErrorString(stat), file, line);\n  }\n}\n\ntypedef struct {\n  double i, c, h;\n} checksum;\n\n\n\n__forceinline__ __device__ float sigmoidf(float in) {\n  return 1.f / (1.f + expf(-in));  \n}\n\n\n\n__global__ \nvoid elementWise_fp(int hiddenSize, int miniBatch,\n    const float *__restrict__ tmp_h, \n    const float *__restrict__ tmp_i, \n    const float *__restrict__ bias,\n    float *__restrict__ linearGates,\n    float *__restrict__ h_out,\n    float *__restrict__ i_out,\n    const float *__restrict__ c_in,\n    float *__restrict__ c_out)\n{\n  int index = blockIdx.x * blockDim.x + threadIdx.x;\n  int numElements = miniBatch * hiddenSize;\n\n  if (index >= numElements) return;\n\n  int batch = index / hiddenSize;\n  int gateIndex = (index % hiddenSize) + 4 * batch * hiddenSize;   \n\n  float g[4];\n\n  for (int i = 0; i < 4; i++) {\n    g[i] = tmp_i[i * hiddenSize + gateIndex] + tmp_h[i * hiddenSize + gateIndex];\n    g[i] += bias[i * hiddenSize + index % hiddenSize] + bias[(i + 4) * hiddenSize + index % hiddenSize];\n    linearGates[gateIndex + i * hiddenSize] = g[i];\n  }   \n\n  float in_gate     = sigmoidf(g[0]);\n  float forget_gate = sigmoidf(g[1]);\n  float in_gate2    = tanhf(g[2]);\n  float out_gate    = sigmoidf(g[3]);\n\n  float val = (forget_gate * c_in[index]) + (in_gate * in_gate2);\n\n  c_out[index] = val;\n\n  val = out_gate * tanhf(val);                                   \n\n  h_out[index] = val;\n  i_out[index] = val;\n}\n\n__device__\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n__global__\nvoid init (float* data, int size) {\n  int index = blockIdx.x * blockDim.x + threadIdx.x;\n  if (index >= size) return;\n  unsigned int seed = index ^ size;\n  data[index] = LCG_random(&seed);\n}\n\nvoid test(int hiddenSize, int miniBatch, int seqLength, int numLayers,\n          checksum &cs, double &time) {\n  float *h_data;\n  float *i_data;\n  float *c_data;\n  float *bias;\n  float *tmp_h;\n  float *tmp_i;\n  float *linearGates;\n\n  \n\n  int numElements = hiddenSize * miniBatch;\n\n  int hc_size = (seqLength + 1) * (numLayers) * numElements;\n  int i_size = (seqLength) * (numLayers + 1) * numElements;\n  int bias_size = numLayers * hiddenSize * 8;\n  int tmp_h_size = 4 * numLayers * numElements;\n  int tmp_i_size = 4 * seqLength * numElements;\n\n  hipErrCheck(hipMalloc((void**)&h_data, hc_size * sizeof(float)));\n  hipErrCheck(hipMalloc((void**)&i_data, i_size * sizeof(float)));\n  hipErrCheck(hipMalloc((void**)&c_data, hc_size * sizeof(float)));\n  hipErrCheck(hipMalloc((void**)&bias, bias_size * sizeof(float)));\n\n  \n\n  hipErrCheck(hipMalloc((void**)&tmp_h, tmp_h_size * sizeof(float)));\n  hipErrCheck(hipMalloc((void**)&tmp_i, tmp_i_size * sizeof(float)));\n\n  \n\n  hipErrCheck(hipMalloc((void**)&linearGates, 4 * seqLength * numLayers * numElements * sizeof(float)));  \n\n  \n\n  dim3 blocks (256);\n  dim3 grids_hc ((hc_size + 255)/256);\n  dim3 grids_b ((bias_size + 255)/256);\n  dim3 grids_tmp_h ((tmp_h_size + 255)/256);\n  dim3 grids_tmp_i ((tmp_i_size + 255)/256);\n          \n  hipLaunchKernelGGL(init, grids_tmp_h, blocks , 0, 0, tmp_h, tmp_h_size);\n  hipLaunchKernelGGL(init, grids_tmp_i, blocks , 0, 0, tmp_i, tmp_i_size);\n  hipLaunchKernelGGL(init, grids_hc, blocks , 0, 0, c_data, hc_size);\n  hipLaunchKernelGGL(init, grids_b, blocks , 0, 0, bias, bias_size);\n\n  hipDeviceSynchronize();\n\n  int lStart = 0;\n  int lEnd = 0;\n  int rStart = 0;\n  int rEnd = 0;\n  int recurBatchSize = 2;\n\n  dim3 grids_p ((numElements + 255)/256);\n  \n  double ktime = 0.0;\n\n  while (true) {\n    \n\n    if (lEnd == 0) {\n      lStart = 0;\n      lEnd = 1;\n      rStart = 0;\n    }\n    else {\n      \n\n      lStart++;\n      lEnd++;\n\n      rStart -= recurBatchSize;\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        rStart += (lStart + 1) * recurBatchSize;\n\n        lStart = 0;\n        lEnd = 1;\n      }\n\n      \n\n      while (rStart >= seqLength && lEnd <= numLayers) {\n        lStart++;\n        lEnd++;\n        rStart -= recurBatchSize;\n      }\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        break;\n      }\n    }\n\n    rEnd = rStart + recurBatchSize;\n    if (rEnd > seqLength) rEnd = seqLength;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int layer = lStart; layer < lEnd; layer++) {\n      for (int i = rStart; i < rEnd; i++)\n        hipLaunchKernelGGL(elementWise_fp, grids_p, blocks , 0, 0, hiddenSize, miniBatch,\n         tmp_h + 4 * layer * numElements, \n         tmp_i + 4 * i * numElements, \n         bias + 8 * layer * hiddenSize,\n         linearGates + 4 * (i * numElements + layer * seqLength * numElements),\n         h_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements,\n         i_data + i * numElements + (layer + 1) * seqLength * numElements,\n         c_data + i * numElements + layer * (seqLength + 1) * numElements,\n         c_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements);\n      hipErrCheck(hipGetLastError());\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  time += ktime;\n  \n\n\n  float *testOutputi = (float*)malloc(numElements * seqLength * sizeof(float));\n  float *testOutputh = (float*)malloc(numElements * numLayers * sizeof(float));\n  float *testOutputc = (float*)malloc(numElements * numLayers * sizeof(float));\n\n  hipDeviceSynchronize();\n  \n  hipErrCheck(hipMemcpy(testOutputi, i_data + numLayers * seqLength * numElements, \n    seqLength * numElements * sizeof(float), hipMemcpyDeviceToHost));\n  for (int layer = 0; layer < numLayers; layer++) {\n    hipErrCheck(hipMemcpy(testOutputh + layer * numElements, \n      h_data + seqLength * numElements + layer * (seqLength + 1) * numElements, \n      numElements * sizeof(float), hipMemcpyDeviceToHost));\n    hipErrCheck(hipMemcpy(testOutputc + layer * numElements, \n      c_data + seqLength * numElements + layer * (seqLength + 1) * numElements, \n      numElements * sizeof(float), hipMemcpyDeviceToHost));\n  }\n\n  double checksumi = 0.0;\n  double checksumh = 0.0;\n  double checksumc = 0.0;\n\n  for (int m = 0; m < miniBatch; m++) {\n    for (int j = 0; j < seqLength; j++) {\n      for (int i = 0; i < hiddenSize; i++) {\n        checksumi += testOutputi[j * numElements + m * hiddenSize + i];\n        \n\n      }\n    }\n    for (int j = 0; j < numLayers; j++) {\n      for (int i = 0; i < hiddenSize; i++) {         \n        checksumh += testOutputh[j * numElements + m * hiddenSize + i];\n        checksumc += testOutputc[j * numElements + m * hiddenSize + i];\n      }\n    }\n  }\n\n  free(testOutputi);\n  free(testOutputc);\n  free(testOutputh);\n\n  hipErrCheck(hipFree(h_data));\n  hipErrCheck(hipFree(i_data));  \n  hipErrCheck(hipFree(c_data));  \n\n  hipErrCheck(hipFree(bias));\n  hipErrCheck(hipFree(tmp_h));\n  hipErrCheck(hipFree(tmp_i));\n  hipErrCheck(hipFree(linearGates));\n\n  cs.i = checksumi;\n  cs.c = checksumc;\n  cs.h = checksumh;\n}\n\nint main(int argc, char* argv[]) {\n  int seqLength;\n  int numLayers;\n  int hiddenSize;\n  int miniBatch; \n  int numRuns; \n\n  if (argc == 6) {\n    seqLength = atoi(argv[1]);\n    numLayers = atoi(argv[2]);\n    hiddenSize = atoi(argv[3]);\n    miniBatch = atoi(argv[4]);   \n    numRuns = atoi(argv[5]);   \n  }\n  else if (argc == 1) {\n    printf(\"Running with default settings\\n\");\n    seqLength = 100;\n    numLayers = 4;\n    hiddenSize = 512;\n    miniBatch = 64;\n    numRuns = 1;\n  }\n  else {\n    printf(\"Usage: %s <seqLength> <numLayers> <hiddenSize> <miniBatch> <repeat>\\n\", argv[0]);\n    return 1;      \n  }\n\n  printf(\"seqLength %d, numLayers %d, hiddenSize %d, miniBatch %d\\n\",\n         seqLength, numLayers, hiddenSize, miniBatch);  \n\n  checksum cs;\n  \n  double time = 0.0;\n\n  for (int run = 0; run < numRuns; run++) {\n    test(hiddenSize, miniBatch, seqLength, numLayers, cs, time);\n  }\n\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / numRuns);\n  printf(\"i checksum %E     \", cs.i);\n  printf(\"c checksum %E     \", cs.c);\n  printf(\"h checksum %E\\n\", cs.h);\n  return 0;\n}\n"}}
{"kernel_name": "pointwise", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n\ntypedef struct {\n  double i, c, h;\n} checksum;\n\n\n\ninline float sigmoidf(float in) {\n  return 1.f / (1.f + expf(-in));  \n}\n\n\n\nvoid elementWise_fp(int hiddenSize, int miniBatch,\n    const float *__restrict tmp_h, \n    const float *__restrict tmp_i, \n    const float *__restrict bias,\n    float *__restrict linearGates,\n    float *__restrict h_out,\n    float *__restrict i_out,\n    const float *__restrict c_in,\n    float *__restrict c_out)\n{\n  int numElements = miniBatch * hiddenSize;\n\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int index = 0; index < numElements; index++) {\n\n    int batch = index / hiddenSize;\n    int gateIndex = (index % hiddenSize) + 4 * batch * hiddenSize;   \n\n    float g[4];\n\n    for (int i = 0; i < 4; i++) {\n      g[i] = tmp_i[i * hiddenSize + gateIndex] + tmp_h[i * hiddenSize + gateIndex];\n      g[i] += bias[i * hiddenSize + index % hiddenSize] + bias[(i + 4) * hiddenSize + index % hiddenSize];\n      linearGates[gateIndex + i * hiddenSize] = g[i];\n    }   \n\n    float in_gate     = sigmoidf(g[0]);\n    float forget_gate = sigmoidf(g[1]);\n    float in_gate2    = tanhf(g[2]);\n    float out_gate    = sigmoidf(g[3]);\n\n    float val = (forget_gate * c_in[index]) + (in_gate * in_gate2);\n\n    c_out[index] = val;\n\n    val = out_gate * tanhf(val);                                   \n\n    h_out[index] = val;\n    i_out[index] = val;\n  }\n}\n\n#pragma omp declare target\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n#pragma omp end declare target\n\nvoid init (float* data, int size) {\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int index = 0; index < size; index++) {\n    unsigned int seed = index ^ size;\n    data[index] = LCG_random(&seed);\n  }\n}\n\nvoid test(int hiddenSize, int miniBatch, int seqLength, int numLayers,\n          checksum &cs, double &time) {\n  float *h_data;\n  float *i_data;\n  float *c_data;\n  float *bias;\n  float *tmp_h;\n  float *tmp_i;\n  float *linearGates;\n\n  \n\n  int numElements = hiddenSize * miniBatch;\n\n  int hc_size = (seqLength + 1) * (numLayers) * numElements;\n  int i_size = (seqLength) * (numLayers + 1) * numElements;\n  int bias_size = numLayers * hiddenSize * 8;\n  int tmp_h_size = 4 * numLayers * numElements;\n  int tmp_i_size = 4 * seqLength * numElements;\n\n  h_data = (float*) malloc (hc_size * sizeof(float));\n  i_data = (float*) malloc (i_size * sizeof(float));\n  c_data = (float*) malloc (hc_size * sizeof(float));\n  bias = (float*) malloc (bias_size * sizeof(float));\n\n  \n\n  tmp_h = (float*) malloc (tmp_h_size * sizeof(float));\n  tmp_i = (float*) malloc (tmp_i_size * sizeof(float));\n\n  \n\n  linearGates = (float*) malloc (4 * seqLength * numLayers * numElements * sizeof(float));  \n\n#pragma omp target data map (alloc: h_data[0:hc_size], \\\n                                    i_data[0:i_size],\\\n                                    c_data[0:hc_size],\\\n                                    bias[0:bias_size],\\\n                                    tmp_h[0:tmp_h_size],\\\n                                    tmp_i[0:tmp_i_size])\n  {\n  \n\n  init(tmp_h, tmp_h_size);\n  init(tmp_i, tmp_i_size);\n  init(c_data, hc_size);\n  init(bias, bias_size);\n\n  int lStart = 0;\n  int lEnd = 0;\n  int rStart = 0;\n  int rEnd = 0;\n  int recurBatchSize = 2;\n\n  double ktime = 0.0;\n\n  while (true) {\n    \n\n    if (lEnd == 0) {\n      lStart = 0;\n      lEnd = 1;\n      rStart = 0;\n    }\n    else {\n      \n\n      lStart++;\n      lEnd++;\n\n      rStart -= recurBatchSize;\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        rStart += (lStart + 1) * recurBatchSize;\n\n        lStart = 0;\n        lEnd = 1;\n      }\n\n      \n\n      while (rStart >= seqLength && lEnd <= numLayers) {\n        lStart++;\n        lEnd++;\n        rStart -= recurBatchSize;\n      }\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        break;\n      }\n    }\n\n    rEnd = rStart + recurBatchSize;\n    if (rEnd > seqLength) rEnd = seqLength;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int layer = lStart; layer < lEnd; layer++) {\n      for (int i = rStart; i < rEnd; i++)\n        elementWise_fp\n        (hiddenSize, miniBatch,\n         tmp_h + 4 * layer * numElements, \n         tmp_i + 4 * i * numElements, \n         bias + 8 * layer * hiddenSize,\n         linearGates + 4 * (i * numElements + layer * seqLength * numElements),\n         h_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements,\n         i_data + i * numElements + (layer + 1) * seqLength * numElements,\n         c_data + i * numElements + layer * (seqLength + 1) * numElements,\n         c_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  time += ktime;\n  \n\n\n  #pragma omp target update from (i_data[0:i_size])\n  #pragma omp target update from (h_data[0:hc_size])\n  #pragma omp target update from (c_data[0:hc_size])\n  }\n\n  float *testOutputi = (float*)malloc(numElements * seqLength * sizeof(float));\n  float *testOutputh = (float*)malloc(numElements * numLayers * sizeof(float));\n  float *testOutputc = (float*)malloc(numElements * numLayers * sizeof(float));\n\n  memcpy(testOutputi, i_data + numLayers * seqLength * numElements, \n    seqLength * numElements * sizeof(float));\n\n  for (int layer = 0; layer < numLayers; layer++) {\n    memcpy(testOutputh + layer * numElements, \n      h_data + seqLength * numElements + layer * (seqLength + 1) * numElements, \n      numElements * sizeof(float));\n    memcpy(testOutputc + layer * numElements, \n      c_data + seqLength * numElements + layer * (seqLength + 1) * numElements, \n      numElements * sizeof(float));\n  }\n  \n  double checksumi = 0.;\n  double checksumh = 0.;\n  double checksumc = 0.;\n\n  for (int m = 0; m < miniBatch; m++) {\n    for (int j = 0; j < seqLength; j++) {\n      for (int i = 0; i < hiddenSize; i++) {\n        checksumi += testOutputi[j * numElements + m * hiddenSize + i];\n        \n\n      }\n    }\n    for (int j = 0; j < numLayers; j++) {\n      for (int i = 0; i < hiddenSize; i++) {         \n        checksumh += testOutputh[j * numElements + m * hiddenSize + i];\n        checksumc += testOutputc[j * numElements + m * hiddenSize + i];\n      }\n    }\n  }\n\n  free(testOutputi);\n  free(testOutputc);\n  free(testOutputh);\n\n  cs.i = checksumi;\n  cs.c = checksumc;\n  cs.h = checksumh;\n\n  free(h_data);\n  free(i_data);\n  free(c_data);\n  free(bias);\n  free(tmp_h);\n  free(tmp_i);\n  free(linearGates);\n}\n\nint main(int argc, char* argv[]) {\n  int seqLength;\n  int numLayers;\n  int hiddenSize;\n  int miniBatch; \n  int numRuns;\n\n  if (argc == 6) {\n    seqLength = atoi(argv[1]);\n    numLayers = atoi(argv[2]);\n    hiddenSize = atoi(argv[3]);\n    miniBatch = atoi(argv[4]);   \n    numRuns = atoi(argv[5]);   \n  }\n  else if (argc == 1) {\n    printf(\"Running with default settings\\n\");\n    seqLength = 100;\n    numLayers = 4;\n    hiddenSize = 512;\n    miniBatch = 64;\n    numRuns = 1;\n  }\n  else {\n    printf(\"Usage: %s <seqLength> <numLayers> <hiddenSize> <miniBatch> <repeat>\\n\", argv[0]);\n    return 1;      \n  }\n\n  printf(\"seqLength %d, numLayers %d, hiddenSize %d, miniBatch %d\\n\",\n         seqLength, numLayers, hiddenSize, miniBatch);  \n\n  checksum cs;\n  \n  double time = 0.0;\n\n  for (int run = 0; run < numRuns; run++) {\n    test(hiddenSize, miniBatch, seqLength, numLayers, cs, time);\n  }\n\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / numRuns);\n  printf(\"i checksum %E     \", cs.i);\n  printf(\"c checksum %E     \", cs.c);\n  printf(\"h checksum %E\\n\", cs.h);\n  return 0;\n}\n"}}
{"kernel_name": "pointwise", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <string.h>\n#include <chrono>\n\ntypedef struct {\n  double i, c, h;\n} checksum;\n\n\n\ninline float sigmoidf(float in) {\n  return 1.f / (1.f + expf(-in));  \n}\n\n\n\nvoid elementWise_fp(int hiddenSize, int miniBatch,\n    const float *__restrict tmp_h, \n    const float *__restrict tmp_i, \n    const float *__restrict bias,\n    float *__restrict linearGates,\n    float *__restrict h_out,\n    float *__restrict i_out,\n    const float *__restrict c_in,\n    float *__restrict c_out)\n{\n  int numElements = miniBatch * hiddenSize;\n\n    for (int index = 0; index < numElements; index++) {\n\n    int batch = index / hiddenSize;\n    int gateIndex = (index % hiddenSize) + 4 * batch * hiddenSize;   \n\n    float g[4];\n\n    for (int i = 0; i < 4; i++) {\n      g[i] = tmp_i[i * hiddenSize + gateIndex] + tmp_h[i * hiddenSize + gateIndex];\n      g[i] += bias[i * hiddenSize + index % hiddenSize] + bias[(i + 4) * hiddenSize + index % hiddenSize];\n      linearGates[gateIndex + i * hiddenSize] = g[i];\n    }   \n\n    float in_gate     = sigmoidf(g[0]);\n    float forget_gate = sigmoidf(g[1]);\n    float in_gate2    = tanhf(g[2]);\n    float out_gate    = sigmoidf(g[3]);\n\n    float val = (forget_gate * c_in[index]) + (in_gate * in_gate2);\n\n    c_out[index] = val;\n\n    val = out_gate * tanhf(val);                                   \n\n    h_out[index] = val;\n    i_out[index] = val;\n  }\n}\n\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\nvoid init (float* data, int size) {\n    for (int index = 0; index < size; index++) {\n    unsigned int seed = index ^ size;\n    data[index] = LCG_random(&seed);\n  }\n}\n\nvoid test(int hiddenSize, int miniBatch, int seqLength, int numLayers,\n          checksum &cs, double &time) {\n  float *h_data;\n  float *i_data;\n  float *c_data;\n  float *bias;\n  float *tmp_h;\n  float *tmp_i;\n  float *linearGates;\n\n  \n\n  int numElements = hiddenSize * miniBatch;\n\n  int hc_size = (seqLength + 1) * (numLayers) * numElements;\n  int i_size = (seqLength) * (numLayers + 1) * numElements;\n  int bias_size = numLayers * hiddenSize * 8;\n  int tmp_h_size = 4 * numLayers * numElements;\n  int tmp_i_size = 4 * seqLength * numElements;\n\n  h_data = (float*) malloc (hc_size * sizeof(float));\n  i_data = (float*) malloc (i_size * sizeof(float));\n  c_data = (float*) malloc (hc_size * sizeof(float));\n  bias = (float*) malloc (bias_size * sizeof(float));\n\n  \n\n  tmp_h = (float*) malloc (tmp_h_size * sizeof(float));\n  tmp_i = (float*) malloc (tmp_i_size * sizeof(float));\n\n  \n\n  linearGates = (float*) malloc (4 * seqLength * numLayers * numElements * sizeof(float));  \n\n  {\n  \n\n  init(tmp_h, tmp_h_size);\n  init(tmp_i, tmp_i_size);\n  init(c_data, hc_size);\n  init(bias, bias_size);\n\n  int lStart = 0;\n  int lEnd = 0;\n  int rStart = 0;\n  int rEnd = 0;\n  int recurBatchSize = 2;\n\n  double ktime = 0.0;\n\n  while (true) {\n    \n\n    if (lEnd == 0) {\n      lStart = 0;\n      lEnd = 1;\n      rStart = 0;\n    }\n    else {\n      \n\n      lStart++;\n      lEnd++;\n\n      rStart -= recurBatchSize;\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        rStart += (lStart + 1) * recurBatchSize;\n\n        lStart = 0;\n        lEnd = 1;\n      }\n\n      \n\n      while (rStart >= seqLength && lEnd <= numLayers) {\n        lStart++;\n        lEnd++;\n        rStart -= recurBatchSize;\n      }\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        break;\n      }\n    }\n\n    rEnd = rStart + recurBatchSize;\n    if (rEnd > seqLength) rEnd = seqLength;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int layer = lStart; layer < lEnd; layer++) {\n      for (int i = rStart; i < rEnd; i++)\n        elementWise_fp\n        (hiddenSize, miniBatch,\n         tmp_h + 4 * layer * numElements, \n         tmp_i + 4 * i * numElements, \n         bias + 8 * layer * hiddenSize,\n         linearGates + 4 * (i * numElements + layer * seqLength * numElements),\n         h_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements,\n         i_data + i * numElements + (layer + 1) * seqLength * numElements,\n         c_data + i * numElements + layer * (seqLength + 1) * numElements,\n         c_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  time += ktime;\n  \n\n\n        }\n\n  float *testOutputi = (float*)malloc(numElements * seqLength * sizeof(float));\n  float *testOutputh = (float*)malloc(numElements * numLayers * sizeof(float));\n  float *testOutputc = (float*)malloc(numElements * numLayers * sizeof(float));\n\n  memcpy(testOutputi, i_data + numLayers * seqLength * numElements, \n    seqLength * numElements * sizeof(float));\n\n  for (int layer = 0; layer < numLayers; layer++) {\n    memcpy(testOutputh + layer * numElements, \n      h_data + seqLength * numElements + layer * (seqLength + 1) * numElements, \n      numElements * sizeof(float));\n    memcpy(testOutputc + layer * numElements, \n      c_data + seqLength * numElements + layer * (seqLength + 1) * numElements, \n      numElements * sizeof(float));\n  }\n  \n  double checksumi = 0.;\n  double checksumh = 0.;\n  double checksumc = 0.;\n\n  for (int m = 0; m < miniBatch; m++) {\n    for (int j = 0; j < seqLength; j++) {\n      for (int i = 0; i < hiddenSize; i++) {\n        checksumi += testOutputi[j * numElements + m * hiddenSize + i];\n        \n\n      }\n    }\n    for (int j = 0; j < numLayers; j++) {\n      for (int i = 0; i < hiddenSize; i++) {         \n        checksumh += testOutputh[j * numElements + m * hiddenSize + i];\n        checksumc += testOutputc[j * numElements + m * hiddenSize + i];\n      }\n    }\n  }\n\n  free(testOutputi);\n  free(testOutputc);\n  free(testOutputh);\n\n  cs.i = checksumi;\n  cs.c = checksumc;\n  cs.h = checksumh;\n\n  free(h_data);\n  free(i_data);\n  free(c_data);\n  free(bias);\n  free(tmp_h);\n  free(tmp_i);\n  free(linearGates);\n}\n\nint main(int argc, char* argv[]) {\n  int seqLength;\n  int numLayers;\n  int hiddenSize;\n  int miniBatch; \n  int numRuns;\n\n  if (argc == 6) {\n    seqLength = atoi(argv[1]);\n    numLayers = atoi(argv[2]);\n    hiddenSize = atoi(argv[3]);\n    miniBatch = atoi(argv[4]);   \n    numRuns = atoi(argv[5]);   \n  }\n  else if (argc == 1) {\n    printf(\"Running with default settings\\n\");\n    seqLength = 100;\n    numLayers = 4;\n    hiddenSize = 512;\n    miniBatch = 64;\n    numRuns = 1;\n  }\n  else {\n    printf(\"Usage: %s <seqLength> <numLayers> <hiddenSize> <miniBatch> <repeat>\\n\", argv[0]);\n    return 1;      \n  }\n\n  printf(\"seqLength %d, numLayers %d, hiddenSize %d, miniBatch %d\\n\",\n         seqLength, numLayers, hiddenSize, miniBatch);  \n\n  checksum cs;\n  \n  double time = 0.0;\n\n  for (int run = 0; run < numRuns; run++) {\n    test(hiddenSize, miniBatch, seqLength, numLayers, cs, time);\n  }\n\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / numRuns);\n  printf(\"i checksum %E     \", cs.i);\n  printf(\"c checksum %E     \", cs.c);\n  printf(\"h checksum %E\\n\", cs.h);\n  return 0;\n}"}}
{"kernel_name": "pointwise", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <math.h>\n#include <sycl/sycl.hpp>\n\ntypedef struct {\n  double i, c, h;\n} checksum;\n\n\n\ninline float sigmoidf(float in) {\n  return 1.f / (1.f + sycl::exp(-in));\n}\n\n\n\nvoid elementWise_fp(\n    sycl::nd_item<1> &item,\n    int hiddenSize, int miniBatch,\n    const float *__restrict tmp_h,\n    const float *__restrict tmp_i,\n    const float *__restrict bias,\n    float *__restrict linearGates,\n    float *__restrict h_out,\n    float *__restrict i_out,\n    const float *__restrict c_in,\n    float *__restrict c_out)\n{\n  int index = item.get_global_id(0);\n  int numElements = miniBatch * hiddenSize;\n\n  if (index >= numElements) return;\n\n  int batch = index / hiddenSize;\n  int gateIndex = (index % hiddenSize) + 4 * batch * hiddenSize;\n\n  float g[4];\n\n  for (int i = 0; i < 4; i++) {\n    g[i] = tmp_i[i * hiddenSize + gateIndex] + tmp_h[i * hiddenSize + gateIndex];\n    g[i] += bias[i * hiddenSize + index % hiddenSize] + bias[(i + 4) * hiddenSize + index % hiddenSize];\n    linearGates[gateIndex + i * hiddenSize] = g[i];\n  }\n\n  float in_gate     = sigmoidf(g[0]);\n  float forget_gate = sigmoidf(g[1]);\n  float in_gate2    = sycl::tanh(g[2]);\n  float out_gate    = sigmoidf(g[3]);\n\n  float val = (forget_gate * c_in[index]) + (in_gate * in_gate2);\n\n  c_out[index] = val;\n\n  val = out_gate * sycl::tanh(val);\n\n  h_out[index] = val;\n  i_out[index] = val;\n}\n\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\nvoid init (sycl::nd_item<1> &item, float* data, int size) {\n  int index = item.get_global_id(0);\n  if (index >= size) return;\n  unsigned int seed = index ^ size;\n  data[index] = LCG_random(&seed);\n}\n\nvoid test(sycl::queue &q, int hiddenSize, int miniBatch, int seqLength, int numLayers,\n          checksum &cs, double &time) {\n\n  \n\n  int numElements = hiddenSize * miniBatch;\n\n  int hc_size = (seqLength + 1) * (numLayers) * numElements;\n  int i_size = (seqLength) * (numLayers + 1) * numElements;\n  int bias_size = numLayers * hiddenSize * 8;\n  int tmp_h_size = 4 * numLayers * numElements;\n  int tmp_i_size = 4 * seqLength * numElements;\n\n  float *h_data = sycl::malloc_device<float>(hc_size, q);\n  float *i_data = sycl::malloc_device<float>(i_size, q);\n  float *c_data = sycl::malloc_device<float>(hc_size, q);\n  float *bias = sycl::malloc_device<float>(bias_size, q);\n\n  \n\n  float *tmp_h = sycl::malloc_device<float>(tmp_h_size, q);\n  float *tmp_i = sycl::malloc_device<float>(tmp_i_size, q);\n\n  \n\n  float *linearGates = sycl::malloc_device<float>(4 * seqLength * numLayers * numElements, q);\n\n  \n\n  sycl::range<1> lws (256);\n  sycl::range<1> gws_hc ((hc_size + 255)/256*256);\n  sycl::range<1> gws_b ((bias_size + 255)/256*256);\n  sycl::range<1> gws_tmp_h ((tmp_h_size + 255)/256*256);\n  sycl::range<1> gws_tmp_i ((tmp_i_size + 255)/256*256);\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class init_h_data>(\n      sycl::nd_range<1>(gws_tmp_h, lws), [=] (sycl::nd_item<1> item) {\n      init(item, tmp_h, tmp_h_size);\n    });\n  });\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class init_c_data>(\n      sycl::nd_range<1>(gws_hc, lws), [=] (sycl::nd_item<1> item) {\n      init(item, c_data, hc_size);\n    });\n  });\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class init_i_data>(\n      sycl::nd_range<1>(gws_tmp_i, lws), [=] (sycl::nd_item<1> item) {\n      init(item, tmp_i, tmp_i_size);\n    });\n  });\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class init_bias_data>(\n      sycl::nd_range<1>(gws_b, lws), [=] (sycl::nd_item<1> item) {\n      init(item, bias, bias_size);\n    });\n  });\n\n  q.wait();\n\n  int lStart = 0;\n  int lEnd = 0;\n  int rStart = 0;\n  int rEnd = 0;\n  int recurBatchSize = 2;\n\n  sycl::range<1> gws_p ((numElements + 255)/256*256);\n\n  double ktime = 0.0;\n\n  while (true) {\n    \n\n    if (lEnd == 0) {\n      lStart = 0;\n      lEnd = 1;\n      rStart = 0;\n    }\n    else {\n      \n\n      lStart++;\n      lEnd++;\n\n      rStart -= recurBatchSize;\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        rStart += (lStart + 1) * recurBatchSize;\n\n        lStart = 0;\n        lEnd = 1;\n      }\n\n      \n\n      while (rStart >= seqLength && lEnd <= numLayers) {\n        lStart++;\n        lEnd++;\n        rStart -= recurBatchSize;\n      }\n\n      \n\n      if (lEnd > numLayers || rStart < 0) {\n        break;\n      }\n    }\n\n    rEnd = rStart + recurBatchSize;\n    if (rEnd > seqLength) rEnd = seqLength;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int layer = lStart; layer < lEnd; layer++) {\n      for (int i = rStart; i < rEnd; i++)\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for<class pw>(sycl::nd_range<1>(gws_p, lws), [=] (sycl::nd_item<1> item) {\n            elementWise_fp\n            (item,\n\t     hiddenSize, miniBatch,\n             tmp_h + 4 * layer * numElements,\n             tmp_i + 4 * i * numElements,\n             bias + 8 * layer * hiddenSize,\n             linearGates + 4 * (i * numElements + layer * seqLength * numElements),\n             h_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements,\n             i_data + i * numElements + (layer + 1) * seqLength * numElements,\n             c_data + i * numElements + layer * (seqLength + 1) * numElements,\n             c_data + (i + 1) * numElements + layer * (seqLength + 1) * numElements);\n\t  });\n        });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    ktime += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  time += ktime;\n  \n\n\n  float *testOutputi = (float*)malloc(numElements * seqLength * sizeof(float));\n  float *testOutputh = (float*)malloc(numElements * numLayers * sizeof(float));\n  float *testOutputc = (float*)malloc(numElements * numLayers * sizeof(float));\n\n  q.wait();\n\n  q.memcpy(testOutputi, i_data + numLayers * seqLength * numElements,\n    seqLength * numElements * sizeof(float));\n  for (int layer = 0; layer < numLayers; layer++) {\n    q.memcpy(testOutputh + layer * numElements,\n      h_data + seqLength * numElements + layer * (seqLength + 1) * numElements,\n      numElements * sizeof(float));\n    q.memcpy(testOutputc + layer * numElements,\n      c_data + seqLength * numElements + layer * (seqLength + 1) * numElements,\n      numElements * sizeof(float));\n  }\n  q.wait();\n\n  double checksumi = 0.;\n  double checksumh = 0.;\n  double checksumc = 0.;\n\n  for (int m = 0; m < miniBatch; m++) {\n    for (int j = 0; j < seqLength; j++) {\n      for (int i = 0; i < hiddenSize; i++) {\n        checksumi += testOutputi[j * numElements + m * hiddenSize + i];\n        \n\n      }\n    }\n    for (int j = 0; j < numLayers; j++) {\n      for (int i = 0; i < hiddenSize; i++) {\n        checksumh += testOutputh[j * numElements + m * hiddenSize + i];\n        checksumc += testOutputc[j * numElements + m * hiddenSize + i];\n      }\n    }\n  }\n\n  free(testOutputi);\n  free(testOutputc);\n  free(testOutputh);\n\n  sycl::free(h_data, q);\n  sycl::free(i_data, q);\n  sycl::free(c_data, q);\n\n  sycl::free(bias, q);\n  sycl::free(tmp_h, q);\n  sycl::free(tmp_i, q);\n  sycl::free(linearGates, q);\n\n  cs.i = checksumi;\n  cs.c = checksumc;\n  cs.h = checksumh;\n}\n\nint main(int argc, char* argv[]) {\n  int seqLength;\n  int numLayers;\n  int hiddenSize;\n  int miniBatch;\n  int numRuns;\n\n  if (argc == 6) {\n    seqLength = atoi(argv[1]);\n    numLayers = atoi(argv[2]);\n    hiddenSize = atoi(argv[3]);\n    miniBatch = atoi(argv[4]);\n    numRuns = atoi(argv[5]);\n  }\n  else if (argc == 1) {\n    printf(\"Running with default settings\\n\");\n    seqLength = 100;\n    numLayers = 4;\n    hiddenSize = 512;\n    miniBatch = 64;\n    numRuns = 1;\n  }\n  else {\n    printf(\"Usage: %s <seqLength> <numLayers> <hiddenSize> <miniBatch> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"seqLength %d, numLayers %d, hiddenSize %d, miniBatch %d\\n\",\n         seqLength, numLayers, hiddenSize, miniBatch);\n\n  checksum cs;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double time = 0.0;\n\n  for (int run = 0; run < numRuns; run++) {\n    test(q, hiddenSize, miniBatch, seqLength, numLayers, cs, time);\n  }\n\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / numRuns);\n  printf(\"i checksum %E     \", cs.i);\n  printf(\"c checksum %E     \", cs.c);\n  printf(\"h checksum %E\\n\", cs.h);\n  return 0;\n}\n\n"}}
{"kernel_name": "pool", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n#include <cuda.h>\n\n#define HOSTDEVICE __host__ __device__\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    HOSTDEVICE inline void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    HOSTDEVICE inline void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\ntemplate <typename PoolProcess, typename T,\n          int ksize_height,\n          int ksize_width,\n          int stride_height,\n          int stride_width,\n          int padding_height,\n          int padding_width,\n          bool exclusive>\n__global__ void KernelPool2DGrad(\n    const int nthreads,\n    const T*__restrict__ input_data,\n    const T*__restrict__ output_data,\n    const T*__restrict__ output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    PoolProcess pool_process,\n    T*__restrict__ input_grad,\n    bool channel_last = false)\n{\n  for (int index = blockIdx.x * blockDim.x + threadIdx.x; index < nthreads;\n           index += blockDim.x * gridDim.x) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = min(h_offset / stride_height + 1, output_height);\n    pwend = min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict__ output_data_t = output_data + output_stride;\n    const T *__restrict__ output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = min(hstart + ksize_height, input_height);\n        int wend = min(wstart + ksize_width, input_width);\n        hstart = max(hstart, 0);\n        wstart = max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 1;\n  const int padding_width = 1;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n  float *input_data, *output_data, *output_grad_data, *input_grad_data;\n  cudaMalloc((void **)&input_data, input_numel * sizeof(float));\n  cudaMalloc((void **)&input_grad_data, input_numel * sizeof(float));\n  cudaMalloc((void **)&output_data, output_numel * sizeof(float));\n  cudaMalloc((void **)&output_grad_data, output_numel * sizeof(float));\n  cudaMemcpy(input_data, input, input_numel * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(output_data, output, output_numel * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(output_grad_data, output_grad, output_numel * sizeof(float), cudaMemcpyHostToDevice);\n\n  int blocks = (nthreads + BSIZE - 1) / BSIZE;\n  dim3 threads(BSIZE);\n  dim3 grid(blocks);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    KernelPool2DGrad<AvgPoolGrad<float>, float, ksize_height, ksize_width,\n                     stride_height, stride_width, padding_height, padding_width,\n                     exclusive><<<grid, threads, 0, 0>>>(\n        nthreads, input_data, output_data, output_grad_data, input_channels,\n        input_height, input_width, output_height, output_width, pool_process,\n        input_grad_data, channel_last);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(input_grad, input_grad_data, input_numel * sizeof(float), cudaMemcpyDeviceToHost);\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  cudaFree(input_data);\n  cudaFree(input_grad_data);\n  cudaFree(output_data);\n  cudaFree(output_grad_data);\n  return 0;\n}\n"}}
{"kernel_name": "pool", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n#include <hip/hip_runtime.h>\n\n#define HOSTDEVICE __host__ __device__\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    HOSTDEVICE inline void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    HOSTDEVICE inline void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\ntemplate <typename PoolProcess, typename T,\n          int ksize_height,\n          int ksize_width,\n          int stride_height,\n          int stride_width,\n          int padding_height,\n          int padding_width,\n          bool exclusive>\n__global__ void KernelPool2DGrad(\n    const int nthreads,\n    const T*__restrict__ input_data,\n    const T*__restrict__ output_data,\n    const T*__restrict__ output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    PoolProcess pool_process,\n    T*__restrict__ input_grad,\n    bool channel_last = false)\n{\n  for (int index = blockIdx.x * blockDim.x + threadIdx.x; index < nthreads;\n           index += blockDim.x * gridDim.x) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = min(h_offset / stride_height + 1, output_height);\n    pwend = min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict__ output_data_t = output_data + output_stride;\n    const T *__restrict__ output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = min(hstart + ksize_height, input_height);\n        int wend = min(wstart + ksize_width, input_width);\n        hstart = max(hstart, 0);\n        wstart = max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 1;\n  const int padding_width = 1;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n  float *input_data, *output_data, *output_grad_data, *input_grad_data;\n  hipMalloc((void **)&input_data, input_numel * sizeof(float));\n  hipMalloc((void **)&input_grad_data, input_numel * sizeof(float));\n  hipMalloc((void **)&output_data, output_numel * sizeof(float));\n  hipMalloc((void **)&output_grad_data, output_numel * sizeof(float));\n  hipMemcpy(input_data, input, input_numel * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(output_data, output, output_numel * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(output_grad_data, output_grad, output_numel * sizeof(float), hipMemcpyHostToDevice);\n\n  int blocks = (nthreads + BSIZE - 1) / BSIZE;\n  dim3 threads(BSIZE);\n  dim3 grid(blocks);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    KernelPool2DGrad<AvgPoolGrad<float>, float, ksize_height, ksize_width,\n                     stride_height, stride_width, padding_height, padding_width,\n                     exclusive><<<grid, threads, 0, 0>>>(\n        nthreads, input_data, output_data, output_grad_data, input_channels,\n        input_height, input_width, output_height, output_width, pool_process,\n        input_grad_data, channel_last);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(input_grad, input_grad_data, input_numel * sizeof(float), hipMemcpyDeviceToHost);\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  hipFree(input_data);\n  hipFree(input_grad_data);\n  hipFree(output_data);\n  hipFree(output_grad_data);\n  return 0;\n}\n"}}
{"kernel_name": "pool", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n#include <omp.h>\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\ntemplate <typename PoolProcess, typename T>\nvoid KernelPool2DGrad(\n    const int nthreads,\n    const T*__restrict input_data,\n    const T*__restrict output_data,\n    const T*__restrict output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    const int ksize_height,\n    const int ksize_width,\n    const int stride_height,\n    const int stride_width,\n    const int padding_height,\n    const int padding_width,\n    PoolProcess pool_process,\n    bool exclusive,\n    T*__restrict input_grad,\n    bool channel_last = false)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BSIZE)\n  for (int index = 0; index < nthreads; index ++) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = std::min(h_offset / stride_height + 1, output_height);\n    pwend = std::min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict output_data_t = output_data + output_stride;\n    const T *__restrict output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = std::min(hstart + ksize_height, input_height);\n        int wend = std::min(wstart + ksize_width, input_width);\n        hstart = std::max(hstart, 0);\n        wstart = std::max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 1;\n  const int padding_width = 1;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n  #pragma omp target data map(to: input[0:input_numel], \\\n                                  output[0:output_numel],\\\n                                  output_grad[0:output_numel]) \\\n                          map(from: input_grad[0:input_numel])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      KernelPool2DGrad<AvgPoolGrad<float>, float>(\n        nthreads, input, output, output_grad, input_channels,\n        input_height, input_width, output_height, output_width, ksize_height,\n        ksize_width, stride_height, stride_width, padding_height, padding_width,\n        pool_process, exclusive, input_grad, channel_last);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  return 0;\n}\n"}}
{"kernel_name": "pool", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\ntemplate <typename PoolProcess, typename T>\nvoid KernelPool2DGrad(\n    const int nthreads,\n    const T*__restrict input_data,\n    const T*__restrict output_data,\n    const T*__restrict output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    const int ksize_height,\n    const int ksize_width,\n    const int stride_height,\n    const int stride_width,\n    const int padding_height,\n    const int padding_width,\n    PoolProcess pool_process,\n    bool exclusive,\n    T*__restrict input_grad,\n    bool channel_last = false)\n{\n    for (int index = 0; index < nthreads; index ++) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = std::min(h_offset / stride_height + 1, output_height);\n    pwend = std::min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict output_data_t = output_data + output_stride;\n    const T *__restrict output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = std::min(hstart + ksize_height, input_height);\n        int wend = std::min(wstart + ksize_width, input_width);\n        hstart = std::max(hstart, 0);\n        wstart = std::max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 1;\n  const int padding_width = 1;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      KernelPool2DGrad<AvgPoolGrad<float>, float>(\n        nthreads, input, output, output_grad, input_channels,\n        input_height, input_width, output_height, output_width, ksize_height,\n        ksize_width, stride_height, stride_width, padding_height, padding_width,\n        pool_process, exclusive, input_grad, channel_last);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  return 0;\n}"}}
{"kernel_name": "pool", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <new>\n#include <string>\n#include <sycl/sycl.hpp>\n\n\n\n#define BSIZE 256\n\ntemplate <class T>\nclass AvgPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += (scale * dy);\n    }\n};\n\ntemplate <class T>\nclass MaxPoolGrad {\n  public:\n    void compute(const T& x, const T& y, const T& dy, T scale, T* dx) {\n      *dx += dy * static_cast<T>(x == y);\n    }\n};\n\n#include \"reference.h\"\n\n\n\ntemplate <typename T>\nclass k;\n\ntemplate <typename T>\nclass k_warmup;\n\ntemplate <typename PoolProcess, typename T>\nvoid KernelPool2DGrad(\n    sycl::nd_item<1> &item,\n    const int nthreads,\n    const T*__restrict input_data,\n    const T*__restrict output_data,\n    const T*__restrict output_grad,\n    const int channels,\n    const int input_height,\n    const int input_width,\n    const int output_height,\n    const int output_width,\n    const int ksize_height,\n    const int ksize_width,\n    const int stride_height,\n    const int stride_width,\n    const int padding_height,\n    const int padding_width,\n    PoolProcess pool_process,\n    bool exclusive,\n    T*__restrict input_grad,\n    bool channel_last = false)\n{\n  for (int index = item.get_global_id(0); index < nthreads;\n           index += item.get_group_range(0) * item.get_local_range(0)) {\n    int w_offset, h_offset, offsetC, batch_idx;\n    int tmp;\n    if (!channel_last) { \n\n      w_offset = index % input_width + padding_width;\n      tmp = index / input_width;\n      h_offset = tmp % input_height + padding_height;\n      tmp = tmp / input_height;\n      offsetC = tmp % channels;\n      batch_idx = tmp / channels;\n    } else { \n\n      offsetC = index % channels;\n      tmp = index / channels;\n      w_offset = tmp % input_width + padding_width;\n      tmp = tmp / input_width;\n      h_offset = tmp % input_height + padding_height;\n      batch_idx = tmp / input_height;\n    }\n\n    int phstart, phend;\n    int pwstart, pwend;\n    phstart = (h_offset < ksize_height) ? 0 : (h_offset - ksize_height) / stride_height + 1;\n    pwstart = (w_offset < ksize_width) ? 0 : (w_offset - ksize_width) / stride_width + 1;\n    phend = sycl::min(h_offset / stride_height + 1, output_height);\n    pwend = sycl::min(w_offset / stride_width + 1, output_width);\n\n    \n\n    T gradient = static_cast<T>(0.0);\n    T input = input_data[index];\n\n    int output_stride = batch_idx * output_height * output_width * channels;\n    if (!channel_last)\n      output_stride += offsetC * output_height * output_width;\n\n    const T *__restrict output_data_t = output_data + output_stride;\n    const T *__restrict output_grad_t = output_grad + output_stride;\n\n    for (int ph = phstart; ph < phend; ++ph) {\n      for (int pw = pwstart; pw < pwend; ++pw) {\n        int pool_size;\n        int hstart = ph * stride_height - padding_height;\n        int wstart = pw * stride_width - padding_width;\n        int hend = sycl::min(hstart + ksize_height, input_height);\n        int wend = sycl::min(wstart + ksize_width, input_width);\n        hstart = sycl::max(hstart, 0);\n        wstart = sycl::max(wstart, 0);\n        pool_size = exclusive ? (hend - hstart) * (wend - wstart)\n          : ksize_height * ksize_width;\n\n        int output_sub_idx = channel_last\n          ? (ph * output_width + pw) * channels + offsetC\n          : ph * output_width + pw;\n        pool_process.compute(input, output_data_t[output_sub_idx],\n            output_grad_t[output_sub_idx],\n            static_cast<T>(1.f / pool_size), &gradient);\n      }\n    }\n    input_grad[index] = gradient;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 8) {\n    printf(\"Usage: %s <batch> <input channels> <input height> \", argv[0]);\n    printf(\"<input width> <output height> <output width> <repeat>\\n\");\n    return 1;\n  }\n  \n\n  const int batch_size = atoi(argv[1]);\n  const int input_channels = atoi(argv[2]);\n  const int input_height = atoi(argv[3]);\n  const int input_width = atoi(argv[4]);\n\n  \n\n  const int output_height = atoi(argv[5]);\n  const int output_width = atoi(argv[6]);\n\n  \n\n  const int repeat = atoi(argv[7]);\n\n  const int input_numel = batch_size*input_channels*input_height*input_width;\n  const int output_numel = batch_size*input_channels*output_height*output_width;\n\n  \n\n  const int ksize_height = 11;\n  const int ksize_width = 11;\n  const int stride_height = 4;\n  const int stride_width = 4;\n  const int padding_height = 0;\n  const int padding_width = 0;\n  const bool exclusive = true;\n  const std::string data_format = \"NCHW\";\n  const bool channel_last = (data_format == \"NHWC\");\n\n  \n\n  int nthreads = batch_size * input_channels * input_height * input_width;\n\n  \n\n  AvgPoolGrad<float> pool_process;\n\n  float * input = new float[input_numel];\n  float * output = new float[output_numel];\n  float * output_grad = new float[output_numel];\n  float * input_grad = new float[input_numel];\n  float * input_grad_ref = new float[input_numel];\n\n  srand(123);\n  for (int i = 0; i < input_numel; ++i) {\n    input[i] = (float)rand() / (float)RAND_MAX;\n    input_grad[i] = 0.f;  \n\n    input_grad_ref[i] = 0.f;  \n\n  }\n\n  for (int i = 0; i < output_numel; ++i) {\n    output[i] = (float)rand() / (float)RAND_MAX;\n    output_grad[i] = input_width * input_height;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_input = sycl::malloc_device<float>(input_numel, q);\n  float *d_input_grad = sycl::malloc_device<float>(input_numel, q);\n  float *d_output = sycl::malloc_device<float>(output_numel, q);\n  float *d_output_grad = sycl::malloc_device<float>(output_numel, q);\n  q.memcpy(d_input, input, input_numel * sizeof(float));\n  q.memcpy(d_output, output, output_numel * sizeof(float));\n  q.memcpy(d_output_grad, output_grad, output_numel * sizeof(float));\n\n  int blocks = (nthreads + BSIZE - 1) / BSIZE;\n  sycl::range<1> gws (blocks * BSIZE);\n  sycl::range<1> lws (BSIZE);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k<float>>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        KernelPool2DGrad<AvgPoolGrad<float>, float>(\n          item, nthreads, d_input, d_output, d_output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, d_input_grad, channel_last);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(input_grad, d_input_grad, input_numel * sizeof(float)).wait();\n\n  \n\n  reference<AvgPoolGrad<float>, float>(\n          nthreads, input, output, output_grad,\n          input_channels, input_height, input_width, output_height, output_width, ksize_height,\n          ksize_width, stride_height, stride_width, padding_height, padding_width,\n          pool_process, exclusive, input_grad_ref, channel_last);\n\n  bool ok = true;\n  for (int i = 0; i < input_numel; ++i) {\n    if (fabsf(input_grad[i] - input_grad_ref[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] input;\n  delete[] output;\n  delete[] input_grad;\n  delete[] input_grad_ref;\n  delete[] output_grad;\n  sycl::free(d_input, q);\n  sycl::free(d_input_grad, q);\n  sycl::free(d_output, q);\n  sycl::free(d_output_grad, q);\n  return 0;\n}\n"}}
{"kernel_name": "scel", "parallel_api": "cuda", "code": {"main.cu": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include <cub/cub.cuh>\n#include \"reference.h\"\n\n#define GPU_NUM_THREADS 256\n\n__global__\nvoid SigmoidCrossEntropyWithLogitsKernel(\n  const int inner_size,\n  const bool log_D_trick,\n  const bool unjoined_lr_loss,\n  const float* logits_ptr,\n  const float* targets_ptr,\n        float* out_ptr)\n{\n  int i = blockIdx.x;\n  int last_idx = (i + 1) * inner_size;\n  float value = 0;\n  for (int in_idx = i * inner_size + threadIdx.x;\n           in_idx < last_idx; in_idx += blockDim.x) {\n    float lgt = logits_ptr[in_idx];\n    float tgt = targets_ptr[in_idx];\n    if (unjoined_lr_loss) {\n      value += unjoined_sigmoid_xent_forward(lgt, tgt);\n    } else {\n      value += log_D_trick ?\n               sigmoid_xent_forward_with_log_d_trick(lgt, tgt) :\n               sigmoid_xent_forward(lgt, tgt);\n    }\n  }\n\n  typedef cub::BlockReduce<float, GPU_NUM_THREADS> BlockReduce;\n  __shared__ typename BlockReduce::TempStorage temp_storage;\n  float sum = BlockReduce(temp_storage).Sum(value);\n  if (threadIdx.x == 0) {\n    out_ptr[i] = -sum / inner_size;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <outer size> <inner_size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int outer_size = atoi(argv[1]);\n  const int inner_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = (outer_size + 1) * inner_size;\n  int input_size_bytes = input_size * sizeof(float);\n  \n  int output_size = outer_size;\n  int output_size_bytes = output_size * sizeof(float);\n\n  std::default_random_engine generator (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float *h_logits = (float*) malloc (input_size_bytes);\n  float *h_targets = (float*) malloc (input_size_bytes);\n  float *h_out = (float*) malloc (output_size_bytes);\n  float *r_out = (float*) malloc (output_size_bytes);\n\n  for (int i = 0; i < input_size; i++) {\n    h_logits[i] = distribution(generator);\n    h_targets[i] = distribution(generator) + 1.f;\n  }\n\n  float *d_logits, *d_targets, *d_out;\n  cudaMalloc((void**)&d_logits, input_size_bytes);\n  cudaMemcpy(d_logits, h_logits, input_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_targets, input_size_bytes);\n  cudaMemcpy(d_targets, h_targets, input_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_out, output_size_bytes);\n\n  bool ok = true;\n\n  for (int unjoined_lr_loss = 0; unjoined_lr_loss <= 1; unjoined_lr_loss++) {\n\n    int logD = (unjoined_lr_loss == 0) ? 1 : 0;\n\n    for (int logD_trick = 0; logD_trick <= logD; logD_trick++) {\n\n      cudaDeviceSynchronize();\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        SigmoidCrossEntropyWithLogitsKernel<<< outer_size, GPU_NUM_THREADS >>>(\n          inner_size,\n          logD_trick,\n          unjoined_lr_loss,\n          d_logits,\n          d_targets,\n          d_out);\n      }\n\n      cudaDeviceSynchronize();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of SigmoidCrossEntropyWithLogits kernel: %f (us)\\n\",\n             (time * 1e-3f) / repeat);\n\n      cudaMemcpy(h_out, d_out, output_size_bytes, cudaMemcpyDeviceToHost);\n\n      reference (outer_size, inner_size, logD_trick, unjoined_lr_loss, h_logits, h_targets, r_out);\n      for (int i = 0; i < output_size; i++) {\n        if (fabsf(r_out[i] - h_out[i]) > 1e-3f) {\n          ok = false;\n          break;\n        }\n      }\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_targets);\n  cudaFree(d_logits);\n  cudaFree(d_out);\n\n  free(h_targets);\n  free(h_logits);\n  free(h_out);\n  free(r_out);\n\n  return 0;\n}\n"}}
{"kernel_name": "scel", "parallel_api": "hip", "code": {"main.cu": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include <hipcub/hipcub.hpp>\n#include \"reference.h\"\n\n#define GPU_NUM_THREADS 256\n\n__global__\nvoid SigmoidCrossEntropyWithLogitsKernel(\n  const int inner_size,\n  const bool log_D_trick,\n  const bool unjoined_lr_loss,\n  const float* logits_ptr,\n  const float* targets_ptr,\n        float* out_ptr)\n{\n  int i = blockIdx.x;\n  int last_idx = (i + 1) * inner_size;\n  float value = 0;\n  for (int in_idx = i * inner_size + threadIdx.x;\n           in_idx < last_idx; in_idx += blockDim.x) {\n    float lgt = logits_ptr[in_idx];\n    float tgt = targets_ptr[in_idx];\n    if (unjoined_lr_loss) {\n      value += unjoined_sigmoid_xent_forward(lgt, tgt);\n    } else {\n      value += log_D_trick ?\n               sigmoid_xent_forward_with_log_d_trick(lgt, tgt) :\n               sigmoid_xent_forward(lgt, tgt);\n    }\n  }\n\n  typedef hipcub::BlockReduce<float, GPU_NUM_THREADS> BlockReduce;\n  __shared__ typename BlockReduce::TempStorage temp_storage;\n  float sum = BlockReduce(temp_storage).Sum(value);\n  if (threadIdx.x == 0) {\n    out_ptr[i] = -sum / inner_size;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <outer size> <inner_size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int outer_size = atoi(argv[1]);\n  const int inner_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = (outer_size + 1) * inner_size;\n  int input_size_bytes = input_size * sizeof(float);\n  \n  int output_size = outer_size;\n  int output_size_bytes = output_size * sizeof(float);\n\n  std::default_random_engine generator (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float *h_logits = (float*) malloc (input_size_bytes);\n  float *h_targets = (float*) malloc (input_size_bytes);\n  float *h_out = (float*) malloc (output_size_bytes);\n  float *r_out = (float*) malloc (output_size_bytes);\n\n  for (int i = 0; i < input_size; i++) {\n    h_logits[i] = distribution(generator);\n    h_targets[i] = distribution(generator) + 1.f;\n  }\n\n  float *d_logits, *d_targets, *d_out;\n  hipMalloc((void**)&d_logits, input_size_bytes);\n  hipMemcpy(d_logits, h_logits, input_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_targets, input_size_bytes);\n  hipMemcpy(d_targets, h_targets, input_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_out, output_size_bytes);\n\n  bool ok = true;\n\n  for (int unjoined_lr_loss = 0; unjoined_lr_loss <= 1; unjoined_lr_loss++) {\n\n    int logD = (unjoined_lr_loss == 0) ? 1 : 0;\n\n    for (int logD_trick = 0; logD_trick <= logD; logD_trick++) {\n\n      hipDeviceSynchronize();\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        SigmoidCrossEntropyWithLogitsKernel<<< outer_size, GPU_NUM_THREADS >>>(\n          inner_size,\n          logD_trick,\n          unjoined_lr_loss,\n          d_logits,\n          d_targets,\n          d_out);\n      }\n\n      hipDeviceSynchronize();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of SigmoidCrossEntropyWithLogits kernel: %f (us)\\n\",\n             (time * 1e-3f) / repeat);\n\n      hipMemcpy(h_out, d_out, output_size_bytes, hipMemcpyDeviceToHost);\n\n      reference (outer_size, inner_size, logD_trick, unjoined_lr_loss, h_logits, h_targets, r_out);\n      for (int i = 0; i < output_size; i++) {\n        if (fabsf(r_out[i] - h_out[i]) > 1e-3f) {\n          ok = false;\n          break;\n        }\n      }\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_targets);\n  hipFree(d_logits);\n  hipFree(d_out);\n\n  free(h_targets);\n  free(h_logits);\n  free(h_out);\n  free(r_out);\n\n  return 0;\n}\n"}}
{"kernel_name": "scel", "parallel_api": "omp", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"reference.h\"\n\n#define GPU_NUM_THREADS 256\n\nvoid SigmoidCrossEntropyWithLogitsKernel(\n  const int outer_size,\n  const int inner_size,\n  const bool log_D_trick,\n  const bool unjoined_lr_loss,\n  const float* logits_ptr,\n  const float* targets_ptr,\n        float* out_ptr)\n{\n  #pragma omp target teams distribute num_teams(outer_size)\n  for (int i = 0; i < outer_size; i++) {\n    float value = 0;\n    #pragma omp parallel for reduction(+:value) num_threads(GPU_NUM_THREADS)\n    for (int in_idx = i * inner_size;\n             in_idx < (i+1) * inner_size; in_idx++) {\n      float lgt = logits_ptr[in_idx];\n      float tgt = targets_ptr[in_idx];\n      if (unjoined_lr_loss) {\n        value += unjoined_sigmoid_xent_forward(lgt, tgt);\n      } else {\n        value += log_D_trick ?\n                 sigmoid_xent_forward_with_log_d_trick(lgt, tgt) :\n                 sigmoid_xent_forward(lgt, tgt);\n      }\n    }\n    out_ptr[i] = -value / inner_size;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <outer size> <inner_size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int outer_size = atoi(argv[1]);\n  const int inner_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = (outer_size + 1) * inner_size;\n  int input_size_bytes = input_size * sizeof(float);\n  \n  int output_size = outer_size;\n  int output_size_bytes = output_size * sizeof(float);\n\n  std::default_random_engine generator (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float *h_logits = (float*) malloc (input_size_bytes);\n  float *h_targets = (float*) malloc (input_size_bytes);\n  float *h_out = (float*) malloc (output_size_bytes);\n  float *r_out = (float*) malloc (output_size_bytes);\n\n  for (int i = 0; i < input_size; i++) {\n    h_logits[i] = distribution(generator);\n    h_targets[i] = distribution(generator) + 1.f;\n  }\n\n  bool ok = true;\n\n  #pragma omp target data map(to: h_logits[0:input_size],\\\n                                  h_targets[0:input_size]) \\\n                          map(alloc: h_out[0:output_size]) \n  {\n    for (int unjoined_lr_loss = 0; unjoined_lr_loss <= 1; unjoined_lr_loss++) {\n\n      int logD = (unjoined_lr_loss == 0) ? 1 : 0;\n\n      for (int logD_trick = 0; logD_trick <= logD; logD_trick++) {\n\n        auto start = std::chrono::steady_clock::now();\n\n        for (int i = 0; i < repeat; i++) {\n          SigmoidCrossEntropyWithLogitsKernel(\n            outer_size,\n            inner_size,\n            logD_trick,\n            unjoined_lr_loss,\n            h_logits,\n            h_targets,\n            h_out);\n        }\n\n        auto end = std::chrono::steady_clock::now();\n        auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        printf(\"Average execution time of SigmoidCrossEntropyWithLogits kernel: %f (us)\\n\",\n               (time * 1e-3f) / repeat);\n\n        #pragma omp target update from (h_out[0:output_size]) \n\n        reference (outer_size, inner_size, logD_trick, unjoined_lr_loss, h_logits, h_targets, r_out);\n        for (int i = 0; i < output_size; i++) {\n          if (fabsf(r_out[i] - h_out[i]) > 1e-3f) {\n            ok = false;\n            break;\n          }\n        }\n      }\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_targets);\n  free(h_logits);\n  free(h_out);\n  free(r_out);\n\n  return 0;\n}\n"}}
{"kernel_name": "scel", "parallel_api": "serial", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\n#define GPU_NUM_THREADS 256\n\nvoid SigmoidCrossEntropyWithLogitsKernel(\n  const int outer_size,\n  const int inner_size,\n  const bool log_D_trick,\n  const bool unjoined_lr_loss,\n  const float* logits_ptr,\n  const float* targets_ptr,\n        float* out_ptr)\n{\n    for (int i = 0; i < outer_size; i++) {\n    float value = 0;\n        for (int in_idx = i * inner_size;\n             in_idx < (i+1) * inner_size; in_idx++) {\n      float lgt = logits_ptr[in_idx];\n      float tgt = targets_ptr[in_idx];\n      if (unjoined_lr_loss) {\n        value += unjoined_sigmoid_xent_forward(lgt, tgt);\n      } else {\n        value += log_D_trick ?\n                 sigmoid_xent_forward_with_log_d_trick(lgt, tgt) :\n                 sigmoid_xent_forward(lgt, tgt);\n      }\n    }\n    out_ptr[i] = -value / inner_size;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <outer size> <inner_size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int outer_size = atoi(argv[1]);\n  const int inner_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = (outer_size + 1) * inner_size;\n  int input_size_bytes = input_size * sizeof(float);\n  \n  int output_size = outer_size;\n  int output_size_bytes = output_size * sizeof(float);\n\n  std::default_random_engine generator (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float *h_logits = (float*) malloc (input_size_bytes);\n  float *h_targets = (float*) malloc (input_size_bytes);\n  float *h_out = (float*) malloc (output_size_bytes);\n  float *r_out = (float*) malloc (output_size_bytes);\n\n  for (int i = 0; i < input_size; i++) {\n    h_logits[i] = distribution(generator);\n    h_targets[i] = distribution(generator) + 1.f;\n  }\n\n  bool ok = true;\n\n    {\n    for (int unjoined_lr_loss = 0; unjoined_lr_loss <= 1; unjoined_lr_loss++) {\n\n      int logD = (unjoined_lr_loss == 0) ? 1 : 0;\n\n      for (int logD_trick = 0; logD_trick <= logD; logD_trick++) {\n\n        auto start = std::chrono::steady_clock::now();\n\n        for (int i = 0; i < repeat; i++) {\n          SigmoidCrossEntropyWithLogitsKernel(\n            outer_size,\n            inner_size,\n            logD_trick,\n            unjoined_lr_loss,\n            h_logits,\n            h_targets,\n            h_out);\n        }\n\n        auto end = std::chrono::steady_clock::now();\n        auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        printf(\"Average execution time of SigmoidCrossEntropyWithLogits kernel: %f (us)\\n\",\n               (time * 1e-3f) / repeat);\n\n        \n        reference (outer_size, inner_size, logD_trick, unjoined_lr_loss, h_logits, h_targets, r_out);\n        for (int i = 0; i < output_size; i++) {\n          if (fabsf(r_out[i] - h_out[i]) > 1e-3f) {\n            ok = false;\n            break;\n          }\n        }\n      }\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_targets);\n  free(h_logits);\n  free(h_out);\n  free(r_out);\n\n  return 0;\n}"}}
{"kernel_name": "scel", "parallel_api": "sycl", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n#define GPU_NUM_THREADS 256\n\nfloat k_sigmoid_xent_forward(float lgt, float tgt) {\n  return lgt * (tgt - (lgt >= 0.f)) - sycl::log(1.f + sycl::exp(lgt - 2.f * lgt * (lgt >= 0.f)));\n}\n\nfloat k_sigmoid_partition(float lgt) {\n  return lgt * (lgt >= 0.f) + sycl::log(1.f + sycl::exp(lgt - 2.f * lgt * (lgt >= 0.f)));\n}\n\nfloat k_sigmoid_xent_forward_with_log_d_trick(float lgt, float tgt) {\n  return (2.f * tgt - 1.f) * (lgt - k_sigmoid_partition(lgt));\n}\n\nfloat k_unjoined_sigmoid_xent_forward(float lgt, float tgt) {\n  return lgt * tgt + (tgt - 1.f) * lgt * (lgt >= 0.f) -\n      (1.f - tgt) * sycl::log(1.f + sycl::exp(lgt - 2.f * lgt * (lgt >= 0.f)));\n}\n\nvoid SigmoidCrossEntropyWithLogitsKernel(\n  sycl::nd_item<1> &item,\n  const int inner_size,\n  const bool log_D_trick,\n  const bool unjoined_lr_loss,\n  const float* logits_ptr,\n  const float* targets_ptr,\n        float* out_ptr)\n{\n  int i = item.get_group(0);\n  int last_idx = (i + 1) * inner_size;\n  float value = 0;\n  for (int in_idx = i * inner_size + item.get_local_id(0);\n           in_idx < last_idx; in_idx += item.get_local_range(0)) {\n    float lgt = logits_ptr[in_idx];\n    float tgt = targets_ptr[in_idx];\n    if (unjoined_lr_loss) {\n      value += k_unjoined_sigmoid_xent_forward(lgt, tgt);\n    } else {\n      value += log_D_trick ?\n               k_sigmoid_xent_forward_with_log_d_trick(lgt, tgt) :\n               k_sigmoid_xent_forward(lgt, tgt);\n    }\n  }\n\n  float sum = reduce_over_group(item.get_group(), value, std::plus<>());\n  if (item.get_local_id(0) == 0) {\n    out_ptr[i] = -sum / inner_size;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <outer size> <inner_size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int outer_size = atoi(argv[1]);\n  const int inner_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  int input_size = (outer_size + 1) * inner_size;\n  int input_size_bytes = input_size * sizeof(float);\n\n  int output_size = outer_size;\n  int output_size_bytes = output_size * sizeof(float);\n\n  std::default_random_engine generator (123);\n  std::normal_distribution<float> distribution(0, 1);\n\n  float *h_logits = (float*) malloc (input_size_bytes);\n  float *h_targets = (float*) malloc (input_size_bytes);\n  float *h_out = (float*) malloc (output_size_bytes);\n  float *r_out = (float*) malloc (output_size_bytes);\n\n  for (int i = 0; i < input_size; i++) {\n    h_logits[i] = distribution(generator);\n    h_targets[i] = distribution(generator) + 1.f;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_logits, *d_targets, *d_out;\n  d_logits = sycl::malloc_device<float>(input_size, q);\n\n  q.memcpy(d_logits, h_logits, input_size_bytes);\n\n  d_targets = sycl::malloc_device<float>(input_size, q);\n  q.memcpy(d_targets, h_targets, input_size_bytes);\n\n  d_out = sycl::malloc_device<float>(output_size, q);\n\n  bool ok = true;\n\n  sycl::range<1> gws (outer_size * GPU_NUM_THREADS);\n  sycl::range<1> lws (GPU_NUM_THREADS);\n\n  for (int unjoined_lr_loss = 0; unjoined_lr_loss <= 1; unjoined_lr_loss++) {\n\n    int logD = (unjoined_lr_loss == 0) ? 1 : 0;\n\n    for (int logD_trick = 0; logD_trick <= logD; logD_trick++) {\n\n      q.wait();\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++) {\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n            SigmoidCrossEntropyWithLogitsKernel(\n              item,\n              inner_size,\n              logD_trick,\n              unjoined_lr_loss,\n              d_logits,\n              d_targets,\n              d_out);\n          });\n        });\n      }\n\n      q.wait();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average execution time of SigmoidCrossEntropyWithLogits kernel: %f (us)\\n\",\n             (time * 1e-3f) / repeat);\n\n      q.memcpy(h_out, d_out, output_size_bytes).wait();\n\n      reference (outer_size, inner_size, logD_trick, unjoined_lr_loss, h_logits, h_targets, r_out);\n      for (int i = 0; i < output_size; i++) {\n        if (fabsf(r_out[i] - h_out[i]) > 1e-3f) {\n          ok = false;\n          break;\n        }\n      }\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_targets, q);\n  sycl::free(d_logits, q);\n  sycl::free(d_out, q);\n\n  free(h_targets);\n  free(h_logits);\n  free(h_out);\n  free(r_out);\n\n  return 0;\n}\n"}}
{"kernel_name": "softmax", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cstdlib>\n#include <cstdio>\n#include <cuda.h>\n#include <cooperative_groups.h>\n#include <cooperative_groups/reduce.h>\n\n#define BLOCK_SIZE 256\n\n\n\nvoid softMax_cpu(const int numSlice, const int sliceSize, const float* src, float* dest) {\n  for (int i = 0; i < numSlice; i++) {\n    float max_ = src[i * sliceSize];\n    for (int j = 0; j < sliceSize; j++) {\n      max_ = (max_ < src[i * sliceSize + j]) ? src[i * sliceSize + j] : max_;\n    }\n    float sum = 0;\n    for (int j = 0; j < sliceSize; j++) {\n      float e = expf(src[i * sliceSize + j] - max_);\n      sum += e;\n      dest[i * sliceSize + j] = e;\n    }\n    for (int j = 0; j < sliceSize; j++) {\n      dest[i * sliceSize + j] /= sum;\n    }\n  }\n}\n\n__global__\nvoid softMax (const int numSlice, const int sliceSize,\n              const float* src, float* dest)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= numSlice) return;\n  float max_ = src[i * sliceSize];\n  for (int j = 0; j < sliceSize; j++) {\n    max_ = max(max_, src[i * sliceSize + j]);\n  }\n  float sum = 0;\n  for (int j = 0; j < sliceSize; j++) {\n    sum += expf(src[i * sliceSize + j] - max_);\n  }\n  for (int j = 0; j < sliceSize; j++) {\n    dest[i * sliceSize + j] = expf(src[i * sliceSize + j] - max_) / sum;\n  }\n}\n\n__global__\nvoid softMax2 (const int numSlice, const int sliceSize,\n              const float* src, float* dest)\n{\n  namespace cg = cooperative_groups;\n  cg::thread_block block = cg::this_thread_block();\n  cg::thread_block_tile<32> warp = cg::tiled_partition<32>(block);\n  int i = blockIdx.x * warp.meta_group_size() + warp.meta_group_rank();\n  if (i >= numSlice) return;\n  float max_ = src[i * sliceSize];\n  for (int j = warp.thread_rank(); j < sliceSize; j += warp.size()) {\n    max_ = max(max_, src[i * sliceSize + j]);\n  }\n  max_ = cg::reduce(warp, max_, cg::greater<float>{});\n  float sum = 0;\n  for (int j = warp.thread_rank(); j < sliceSize; j += warp.size()) {\n    sum += expf(src[i * sliceSize + j] - max_);\n  }\n  sum = cg::reduce(warp, sum, cg::plus<float>{});\n  for (int j = warp.thread_rank(); j < sliceSize; j += warp.size()) {\n    dest[i * sliceSize + j] = expf(src[i * sliceSize + j] - max_) / sum;\n  }\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <number of slices> <slice size> <implementations> <repeat>\\n\", argv[0]);\n    printf(\"implementation 0: naive\\n\");\n    printf(\"implementation 1: optimized\\n\");\n    return 1;\n  }\n\n  int numSlice = atoi(argv[1]);\n  int sliceSize = atoi(argv[2]);\n  int kernel = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n  int numElem = numSlice * sliceSize;\n\n  float* input = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_gpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_cpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n\n  srand(2);\n  for (int i = 0; i < numSlice; i++)\n    for (int j = 0; j < sliceSize; j++)\n      input[i*sliceSize+j] = rand() % 13;\n\n  float *d_input, *d_output;\n  cudaMalloc((void**)&d_input, sizeof(float) * numElem);\n  cudaMalloc((void**)&d_output, sizeof(float) * numElem);\n  cudaMemcpy(d_input, input, sizeof(float) * numElem, cudaMemcpyHostToDevice);\n\n  if (kernel == 1) {\n    dim3 grids ((numSlice+BLOCK_SIZE/32-1)/(BLOCK_SIZE/32));\n    dim3 blocks (BLOCK_SIZE);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      softMax2<<<grids, blocks>>>(numSlice, sliceSize, d_input, d_output);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n  else {\n    dim3 grids ((numSlice+BLOCK_SIZE-1)/BLOCK_SIZE);\n    dim3 blocks (BLOCK_SIZE);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      softMax<<<grids, blocks>>>(numSlice, sliceSize, d_input, d_output);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  cudaMemcpy(output_gpu, d_output, sizeof(float) * numElem, cudaMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  softMax_cpu(numSlice, sliceSize, input, output_cpu);\n  for (int i = 0; i < numElem; i++) {\n    if (fabsf(output_cpu[i] - output_gpu[i]) > 1e-3) {\n      printf(\"@index %d host: %f device: %f\\n\", i, output_cpu[i], output_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(input);\n  free(output_cpu);\n  free(output_gpu);\n  cudaFree(d_input);\n  cudaFree(d_output);\n  return 0;\n}\n"}}
{"kernel_name": "softmax", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cstdlib>\n#include <cstdio>\n#include <hip/hip_runtime.h>\n#include <hip/hip_cooperative_groups.h>\n\n#define BLOCK_SIZE 256\n\n\n\nvoid softMax_cpu(const int numSlice, const int sliceSize, const float* src, float* dest) {\n  for (int i = 0; i < numSlice; i++) {\n    float max_ = src[i * sliceSize];\n    for (int j = 0; j < sliceSize; j++) {\n      max_ = (max_ < src[i * sliceSize + j]) ? src[i * sliceSize + j] : max_;\n    }\n    float sum = 0;\n    for (int j = 0; j < sliceSize; j++) {\n      float e = expf(src[i * sliceSize + j] - max_);\n      sum += e;\n      dest[i * sliceSize + j] = e;\n    }\n    for (int j = 0; j < sliceSize; j++) {\n      dest[i * sliceSize + j] /= sum;\n    }\n  }\n}\n\n__global__\nvoid softMax (const int numSlice, const int sliceSize,\n              const float* src, float* dest)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= numSlice) return;\n  float max_ = src[i * sliceSize];\n  for (int j = 0; j < sliceSize; j++) {\n    max_ = max(max_, src[i * sliceSize + j]);\n  }\n  float sum = 0;\n  for (int j = 0; j < sliceSize; j++) {\n    sum += expf(src[i * sliceSize + j] - max_);\n  }\n  for (int j = 0; j < sliceSize; j++) {\n    dest[i * sliceSize + j] = expf(src[i * sliceSize + j] - max_) / sum;\n  }\n}\n\n__device__ inline float warpReduceSum(cooperative_groups::thread_block_tile<32> &warp, float val) {\n    for (int offset = 16; offset > 0; offset /= 2) {\n        val += warp.shfl_xor(val, offset);\n    }\n    return val;\n}\n\n__device__ inline float warpReduceMax(cooperative_groups::thread_block_tile<32> &warp, float val) {\n    for (int offset = 16; offset > 0; offset /= 2) {\n        val = max(val, warp.shfl_xor(val, offset));\n    }\n    return val;\n}\n\n__global__\nvoid softMax2 (const int numSlice, const int sliceSize,\n              const float* src, float* dest)\n{\n  namespace cg = cooperative_groups;\n  cg::thread_block block = cg::this_thread_block();\n  cg::thread_block_tile<32> warp = cg::tiled_partition<32>(block);\n  int i = blockIdx.x * warp.meta_group_size() + warp.meta_group_rank();\n  if (i >= numSlice) return;\n  float max_ = src[i * sliceSize];\n  for (int j = warp.thread_rank(); j < sliceSize; j += warp.size()) {\n    max_ = max(max_, src[i * sliceSize + j]);\n  }\n  max_ = warpReduceMax(warp, max_);\n  float sum = 0;\n  for (int j = warp.thread_rank(); j < sliceSize; j += warp.size()) {\n    sum += expf(src[i * sliceSize + j] - max_);\n  }\n  sum = warpReduceSum(warp, sum);\n  for (int j = warp.thread_rank(); j < sliceSize; j += warp.size()) {\n    dest[i * sliceSize + j] = expf(src[i * sliceSize + j] - max_) / sum;\n  }\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <number of slices> <slice size> <implementations> <repeat>\\n\", argv[0]);\n    printf(\"implementation 0: naive\\n\");\n    printf(\"implementation 1: optimized\\n\");\n    return 1;\n  }\n\n  int numSlice = atoi(argv[1]);\n  int sliceSize = atoi(argv[2]);\n  int kernel = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n  int numElem = numSlice * sliceSize;\n\n  float* input = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_gpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_cpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n\n  srand(2);\n  for (int i = 0; i < numSlice; i++)\n    for (int j = 0; j < sliceSize; j++)\n      input[i*sliceSize+j] = rand() % 13;\n\n  float *d_input, *d_output;\n  hipMalloc((void**)&d_input, sizeof(float) * numElem);\n  hipMalloc((void**)&d_output, sizeof(float) * numElem);\n  hipMemcpy(d_input, input, sizeof(float) * numElem, hipMemcpyHostToDevice);\n\n  if (kernel == 1) {\n    dim3 grids ((numSlice+BLOCK_SIZE/32-1)/(BLOCK_SIZE/32));\n    dim3 blocks (BLOCK_SIZE);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      softMax2<<<grids, blocks>>>(numSlice, sliceSize, d_input, d_output);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n  else {\n    dim3 grids ((numSlice+BLOCK_SIZE-1)/BLOCK_SIZE);\n    dim3 blocks (BLOCK_SIZE);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      softMax<<<grids, blocks>>>(numSlice, sliceSize, d_input, d_output);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  hipMemcpy(output_gpu, d_output, sizeof(float) * numElem, hipMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  softMax_cpu(numSlice, sliceSize, input, output_cpu);\n  for (int i = 0; i < numElem; i++) {\n    if (fabsf(output_cpu[i] - output_gpu[i]) > 1e-3) {\n      printf(\"@index %d host: %f device: %f\\n\", i, output_cpu[i], output_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(input);\n  free(output_cpu);\n  free(output_gpu);\n  hipFree(d_input);\n  hipFree(d_output);\n  return 0;\n}\n"}}
{"kernel_name": "softmax", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <cstdlib>\n#include <cstdio>\n#include <cmath>\n\n#define BLOCK_SIZE 256\n\n\n\nvoid softMax_cpu(const int numSlice, const int sliceSize, const float* src, float* dest) {\n  for (int i = 0; i < numSlice; i++) {\n    float max_ = src[i * sliceSize];\n    for (int j = 1; j < sliceSize; j++) {\n      max_ = (max_ < src[i * sliceSize + j]) ? src[i * sliceSize + j] : max_;\n    }\n    float sum = 0;\n    for (int j = 0; j < sliceSize; j++) {\n      float e = expf(src[i * sliceSize + j] - max_);\n      sum += e;\n      dest[i * sliceSize + j] = e;\n    }\n    for (int j = 0; j < sliceSize; j++) {\n      dest[i * sliceSize + j] /= sum;\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of slices> <slice size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n   \n  int numSlice = atoi(argv[1]);\n  int sliceSize = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n  int numElem = numSlice * sliceSize;\n\n  float* input = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_gpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_cpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n\n  srand(2);\n  for (int i = 0; i < numSlice; i++)\n    for (int j = 0; j < sliceSize; j++)\n      input[i*sliceSize+j] = rand() % 13; \n\n  #pragma omp target data map(to: input[0:numElem]) map(from: output_gpu[0:numElem])\n  {\n    auto start = std::chrono::steady_clock::now();\n  \n    for (int n = 0; n < repeat; n++) {\n      #pragma omp target teams distribute parallel for simd thread_limit(BLOCK_SIZE)\n      for (int i = 0; i < numSlice; i++) {\n        float max_ = input[i * sliceSize];\n        for (int j = 1; j < sliceSize; j++) {\n          max_ = (max_ < input[i * sliceSize + j]) ? input[i * sliceSize + j] : max_;\n        }\n        float sum = 0;\n        for (int j = 0; j < sliceSize; j++) {\n          sum += expf(input[i * sliceSize + j] - max_);\n        }\n        for (int j = 0; j < sliceSize; j++) {\n          output_gpu[i * sliceSize + j] = expf(input[i * sliceSize + j] - max_) / sum;\n        }\n      }\n    }\n  \n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  bool ok = true;\n  softMax_cpu(numSlice, sliceSize, input, output_cpu);\n  for (int i = 0; i < numElem; i++) {\n    if (fabsf(output_cpu[i] - output_gpu[i]) > 1e-3) {\n      printf(\"@index %d host: %f device: %f\\n\", i, output_cpu[i], output_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(input);\n  free(output_cpu);\n  free(output_gpu);\n  return 0;\n}\n"}}
{"kernel_name": "softmax", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <cstdlib>\n#include <cstdio>\n#include <cmath>\n\n#define BLOCK_SIZE 256\n\n\n\nvoid softMax_cpu(const int numSlice, const int sliceSize, const float* src, float* dest) {\n  for (int i = 0; i < numSlice; i++) {\n    float max_ = src[i * sliceSize];\n    for (int j = 1; j < sliceSize; j++) {\n      max_ = (max_ < src[i * sliceSize + j]) ? src[i * sliceSize + j] : max_;\n    }\n    float sum = 0;\n    for (int j = 0; j < sliceSize; j++) {\n      float e = expf(src[i * sliceSize + j] - max_);\n      sum += e;\n      dest[i * sliceSize + j] = e;\n    }\n    for (int j = 0; j < sliceSize; j++) {\n      dest[i * sliceSize + j] /= sum;\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of slices> <slice size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n   \n  int numSlice = atoi(argv[1]);\n  int sliceSize = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n  int numElem = numSlice * sliceSize;\n\n  float* input = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_gpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_cpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n\n  srand(2);\n  for (int i = 0; i < numSlice; i++)\n    for (int j = 0; j < sliceSize; j++)\n      input[i*sliceSize+j] = rand() % 13; \n\n    {\n    auto start = std::chrono::steady_clock::now();\n  \n    for (int n = 0; n < repeat; n++) {\n            for (int i = 0; i < numSlice; i++) {\n        float max_ = input[i * sliceSize];\n        for (int j = 1; j < sliceSize; j++) {\n          max_ = (max_ < input[i * sliceSize + j]) ? input[i * sliceSize + j] : max_;\n        }\n        float sum = 0;\n        for (int j = 0; j < sliceSize; j++) {\n          sum += expf(input[i * sliceSize + j] - max_);\n        }\n        for (int j = 0; j < sliceSize; j++) {\n          output_gpu[i * sliceSize + j] = expf(input[i * sliceSize + j] - max_) / sum;\n        }\n      }\n    }\n  \n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  bool ok = true;\n  softMax_cpu(numSlice, sliceSize, input, output_cpu);\n  for (int i = 0; i < numElem; i++) {\n    if (fabsf(output_cpu[i] - output_gpu[i]) > 1e-3) {\n      printf(\"@index %d host: %f device: %f\\n\", i, output_cpu[i], output_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(input);\n  free(output_cpu);\n  free(output_gpu);\n  return 0;\n}"}}
{"kernel_name": "softmax", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cstdlib>\n#include <cstdio>\n#include <sycl/sycl.hpp>\n\n#define BLOCK_SIZE 256\n\n\n\nvoid softMax_cpu(const int numSlice, const int sliceSize, const float* src, float* dest) {\n  for (int i = 0; i < numSlice; i++) {\n    float max_ = src[i * sliceSize];\n    for (int j = 1; j < sliceSize; j++) {\n      max_ = (max_ < src[i * sliceSize + j]) ? src[i * sliceSize + j] : max_;\n    }\n    float sum = 0;\n    for (int j = 0; j < sliceSize; j++) {\n      float e = expf(src[i * sliceSize + j] - max_);\n      sum += e;\n      dest[i * sliceSize + j] = e;\n    }\n    for (int j = 0; j < sliceSize; j++) {\n      dest[i * sliceSize + j] /= sum;\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <number of slices> <slice size> <implementations> <repeat>\\n\", argv[0]);\n    printf(\"implementation 0: naive\\n\");\n    printf(\"implementation 1: optimized\\n\");\n    return 1;\n  }\n\n  int numSlice = atoi(argv[1]);\n  int sliceSize = atoi(argv[2]);\n  int kernel = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n  int numElem = numSlice * sliceSize;\n\n  float* input = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_gpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n  float* output_cpu = (float*) aligned_alloc(1024, sizeof(float) * numElem);\n\n  srand(2);\n  for (int i = 0; i < numSlice; i++)\n    for (int j = 0; j < sliceSize; j++)\n      input[i*sliceSize+j] = rand() % 13;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_input = sycl::malloc_device<float>(numElem, q);\n  q.memcpy(d_input, input, sizeof(float) * numElem);\n\n  float *d_output = sycl::malloc_device<float>(numElem, q);\n\n  if (kernel == 1) {\n    sycl::range<1> gws ((numSlice+BLOCK_SIZE/32-1)/(BLOCK_SIZE/32)*BLOCK_SIZE);\n    sycl::range<1> lws (BLOCK_SIZE);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      q.submit([&](sycl::handler &h) {\n        h.parallel_for<class sm2>(\n          sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n          [[sycl::reqd_sub_group_size(32)]] {\n          sycl::sub_group warp = item.get_sub_group();\n          int i = item.get_group(0) * warp.get_group_linear_range() + warp.get_group_linear_id();\n          if (i >= numSlice) return;\n          float max_ = d_input[i * sliceSize];\n          for (int j = warp.get_local_linear_id(); j < sliceSize; j += warp.get_max_local_range()[0]) {\n            max_ = sycl::max(max_, d_input[i * sliceSize + j]);\n          }\n          max_ = sycl::reduce_over_group(warp, max_, sycl::maximum<float>{});\n          float sum = 0;\n          for (int j = warp.get_local_linear_id(); j < sliceSize; j += warp.get_max_local_range()[0]) {\n            sum += sycl::exp(d_input[i * sliceSize + j] - max_);\n          }\n          sum = sycl::reduce_over_group(warp, sum, sycl::plus<float>{});\n          for (int j = warp.get_local_linear_id(); j < sliceSize; j += warp.get_max_local_range()[0]) {\n            d_output[i * sliceSize + j] = sycl::exp(d_input[i * sliceSize + j] - max_) / sum;\n          }\n        });\n      });\n    }\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n  else {\n\n    sycl::range<1> gws ((numSlice+BLOCK_SIZE-1)/BLOCK_SIZE*BLOCK_SIZE);\n    sycl::range<1> lws (BLOCK_SIZE);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      q.submit([&](sycl::handler &h) {\n        h.parallel_for<class sm>(\n          sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n          int i = item.get_global_id(0);\n          if (i >= numSlice) return;\n          float max_ = d_input[i * sliceSize];\n          for (int j = 1; j < sliceSize; j++) {\n            max_ = sycl::max(max_, d_input[i * sliceSize + j]);\n          }\n          float sum = 0;\n          for (int j = 0; j < sliceSize; j++) {\n            sum += sycl::exp(d_input[i * sliceSize + j] - max_);\n          }\n          for (int j = 0; j < sliceSize; j++) {\n            d_output[i * sliceSize + j] = sycl::exp(d_input[i * sliceSize + j] - max_) / sum;\n          }\n        });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n  q.memcpy(output_gpu, d_output, sizeof(float) * numElem).wait();\n\n  \n\n  bool ok = true;\n  softMax_cpu(numSlice, sliceSize, input, output_cpu);\n  for (int i = 0; i < numElem; i++) {\n    if (fabsf(output_cpu[i] - output_gpu[i]) > 1e-3) {\n      printf(\"@index %d host: %f device: %f\\n\", i, output_cpu[i], output_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(input);\n  free(output_cpu);\n  free(output_gpu);\n  sycl::free(d_input, q);\n  sycl::free(d_output, q);\n  return 0;\n}\n"}}
{"kernel_name": "stddev", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType>\n__global__ void sampleKernel (Type *std, IdxType D, IdxType N) {\n  IdxType i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i < D) std[i] = sqrtf(std[i] / N);\n}\n\n\n\ntemplate <typename Type, typename IdxType, int TPB, int ColsPerBlk = 32>\n__global__ void sopKernel(\n        Type *__restrict__ std, \n  const Type *__restrict__ data, \n  IdxType D, \n  IdxType N) \n{\n  const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n  IdxType thisColId = threadIdx.x % ColsPerBlk;\n  IdxType thisRowId = threadIdx.x / ColsPerBlk;\n  IdxType colId = thisColId + ((IdxType)blockIdx.y * ColsPerBlk);\n  IdxType rowId = thisRowId + ((IdxType)blockIdx.x * RowsPerBlkPerIter);\n  Type thread_data = Type(0);\n  const IdxType stride = RowsPerBlkPerIter * gridDim.x;\n  for (IdxType i = rowId; i < N; i += stride) {\n    Type val = (colId < D) ? data[i * D + colId] : Type(0);\n    thread_data += val * val;\n  }\n  __shared__ Type sstd[ColsPerBlk];\n  if (threadIdx.x < ColsPerBlk) sstd[threadIdx.x] = Type(0);\n  __syncthreads();\n\n  atomicAdd(sstd + thisColId, thread_data);\n  __syncthreads();\n\n  if (threadIdx.x < ColsPerBlk) atomicAdd(std + colId, sstd[thisColId]);\n}\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(Type *std, const Type *data, IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n  dim3 grid((N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk, \n            (D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk);\n  dim3 block(TPB);\n\n  cudaMemset(std, 0, sizeof(Type) * D); \n\n\n  sopKernel<Type, IdxType, TPB, ColsPerBlk> <<<grid, block>>>(std, data, D, N);\n\n  IdxType sampleSize = sample ? N-1 : N;\n  sampleKernel<Type, IdxType> <<<(D+TPB-1)/TPB, TPB>>>(std, D, sampleSize);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++) \n      data[i*D + j] = rand() / (float)RAND_MAX; \n\n  float *d_data;\n  cudaMalloc((void**)&d_data, inputSizeByte);\n  cudaMemcpy(d_data, data, inputSizeByte, cudaMemcpyHostToDevice);\n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n  float *d_std;\n  cudaMalloc((void**)&d_std, outputSizeByte);\n\n  \n\n  stddev(d_std, d_data, D, N, sample);\n\n  \n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    stddev(d_std, d_data, D, N, sample);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(std, d_std, outputSizeByte, cudaMemcpyDeviceToHost);\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  cudaFree(d_std);\n  cudaFree(d_data);\n  return 0;\n}\n"}}
{"kernel_name": "stddev", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType>\n__global__ void sampleKernel (Type *std, IdxType D, IdxType N) {\n  IdxType i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i < D) std[i] = sqrtf(std[i] / N);\n}\n\n\n\ntemplate <typename Type, typename IdxType, int TPB, int ColsPerBlk = 32>\n__global__ void sopKernel(\n        Type *__restrict__ std, \n  const Type *__restrict__ data, \n  IdxType D, \n  IdxType N) \n{\n  const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n  IdxType thisColId = threadIdx.x % ColsPerBlk;\n  IdxType thisRowId = threadIdx.x / ColsPerBlk;\n  IdxType colId = thisColId + ((IdxType)blockIdx.y * ColsPerBlk);\n  IdxType rowId = thisRowId + ((IdxType)blockIdx.x * RowsPerBlkPerIter);\n  Type thread_data = Type(0);\n  const IdxType stride = RowsPerBlkPerIter * gridDim.x;\n  for (IdxType i = rowId; i < N; i += stride) {\n    Type val = (colId < D) ? data[i * D + colId] : Type(0);\n    thread_data += val * val;\n  }\n  __shared__ Type sstd[ColsPerBlk];\n  if (threadIdx.x < ColsPerBlk) sstd[threadIdx.x] = Type(0);\n  __syncthreads();\n\n  atomicAdd(sstd + thisColId, thread_data);\n  __syncthreads();\n\n  if (threadIdx.x < ColsPerBlk) atomicAdd(std + colId, sstd[thisColId]);\n}\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(Type *std, const Type *data, IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n  dim3 grid((N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk, \n            (D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk);\n  dim3 block(TPB);\n\n  hipMemset(std, 0, sizeof(Type) * D); \n\n\n  hipLaunchKernelGGL(HIP_KERNEL_NAME(sopKernel<Type, IdxType, TPB, ColsPerBlk>), grid, block, 0, 0, std, data, D, N);\n\n  IdxType sampleSize = sample ? N-1 : N;\n  sampleKernel<Type, IdxType> <<<(D+TPB-1)/TPB, TPB>>>(std, D, sampleSize);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++) \n      data[i*D + j] = rand() / (float)RAND_MAX; \n\n  float *d_data;\n  hipMalloc((void**)&d_data, inputSizeByte);\n  hipMemcpy(d_data, data, inputSizeByte, hipMemcpyHostToDevice);\n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n  float *d_std;\n  hipMalloc((void**)&d_std, outputSizeByte);\n\n  \n\n  stddev(d_std, d_data, D, N, sample);\n\n  \n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    stddev(d_std, d_data, D, N, sample);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(std, d_std, outputSizeByte, hipMemcpyDeviceToHost);\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  hipFree(d_std);\n  hipFree(d_data);\n  return 0;\n}\n"}}
{"kernel_name": "stddev", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(Type *std, const Type *data, IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n\n  static const int TeamX = (N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk;\n  static const int TeamY = (D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk;\n  static const int Teams = TeamX * TeamY;\n\n  \n\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < D; i++)\n    std[i] = (Type)0;\n\n  #pragma omp target teams num_teams(Teams) thread_limit(TPB)\n  {\n    Type sstd[ColsPerBlk];\n    #pragma omp parallel\n    {\n      int tx = omp_get_thread_num();\n      int bx = omp_get_team_num() % TeamX;\n      int by = omp_get_team_num() / TeamX;\n      int gridDim_x = TeamX;\n \n      const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n      IdxType thisColId = tx % ColsPerBlk;\n      IdxType thisRowId = tx / ColsPerBlk;\n      IdxType colId = thisColId + ((IdxType)by * ColsPerBlk);\n      IdxType rowId = thisRowId + ((IdxType)bx * RowsPerBlkPerIter);\n      Type thread_data = Type(0);\n      const IdxType stride = RowsPerBlkPerIter * gridDim_x;\n      for (IdxType i = rowId; i < N; i += stride) {\n        Type val = (colId < D) ? data[i * D + colId] : Type(0);\n        thread_data += val * val;\n      }\n      if (tx < ColsPerBlk) sstd[tx] = Type(0);\n      #pragma omp barrier\n\n      #pragma omp atomic update\n      sstd[thisColId] += thread_data;\n\n      #pragma omp barrier\n\n      if (tx < ColsPerBlk) {\n        #pragma omp atomic update\n        std[colId] += sstd[thisColId];\n      }\n    }\n  }\n\n  IdxType sampleSize = sample ? N-1 : N;\n  #pragma omp target teams distribute parallel for thread_limit(TPB)\n  for (int i = 0; i < D; i++)\n    std[i] = sqrtf(std[i] / sampleSize);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++) \n      data[i*D + j] = rand() / (float)RAND_MAX; \n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n\n  #pragma omp target data map (to: data[0:inputSize]) map (from: std[0:outputSize])\n  {\n    \n\n    stddev(std, data, D, N, sample);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      stddev(std, data, D, N, sample);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  return 0;\n}\n"}}
{"kernel_name": "stddev", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(Type *std, const Type *data, IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n\n  static const int TeamX = (N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk;\n  static const int TeamY = (D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk;\n  static const int Teams = TeamX * TeamY;\n\n  \n\n    for (int i = 0; i < D; i++)\n    std[i] = (Type)0;\n\n    {\n    Type sstd[ColsPerBlk];\n        {\n      int tx = omp_get_thread_num();\n      int bx = omp_get_team_num() % TeamX;\n      int by = omp_get_team_num() / TeamX;\n      int gridDim_x = TeamX;\n \n      const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n      IdxType thisColId = tx % ColsPerBlk;\n      IdxType thisRowId = tx / ColsPerBlk;\n      IdxType colId = thisColId + ((IdxType)by * ColsPerBlk);\n      IdxType rowId = thisRowId + ((IdxType)bx * RowsPerBlkPerIter);\n      Type thread_data = Type(0);\n      const IdxType stride = RowsPerBlkPerIter * gridDim_x;\n      for (IdxType i = rowId; i < N; i += stride) {\n        Type val = (colId < D) ? data[i * D + colId] : Type(0);\n        thread_data += val * val;\n      }\n      if (tx < ColsPerBlk) sstd[tx] = Type(0);\n      \n            sstd[thisColId] += thread_data;\n\n      \n      if (tx < ColsPerBlk) {\n                std[colId] += sstd[thisColId];\n      }\n    }\n  }\n\n  IdxType sampleSize = sample ? N-1 : N;\n    for (int i = 0; i < D; i++)\n    std[i] = sqrtf(std[i] / sampleSize);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++) \n      data[i*D + j] = rand() / (float)RAND_MAX; \n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n\n    {\n    \n\n    stddev(std, data, D, N, sample);\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      stddev(std, data, D, N, sample);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  return 0;\n}"}}
{"kernel_name": "stddev", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n\n\ntemplate <typename Type, typename IdxType>\nclass sampleKernel;\n\n\n\ntemplate <typename Type, typename IdxType, int TPB, int ColsPerBlk = 32>\nclass sopKernel;\n\n\n\ntemplate <typename Type, typename IdxType = int>\nvoid stddev(sycl::queue &q,\n            Type *d_std,\n            const Type *d_data,\n            IdxType D, IdxType N, bool sample) {\n  static const int TPB = 256;\n  static const int RowsPerThread = 4;\n  static const int ColsPerBlk = 32;\n  static const int RowsPerBlk = (TPB / ColsPerBlk) * RowsPerThread;\n\n  sycl::range<2> gws ((D + (IdxType)ColsPerBlk - 1) / (IdxType)ColsPerBlk ,\n                      (N + (IdxType)RowsPerBlk - 1) / (IdxType)RowsPerBlk * TPB);\n\n  sycl::range<2> lws (1, TPB);\n\n  \n\n  q.memset(d_std, 0, sizeof(Type) * D); \n\n\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<Type, 1> sstd (sycl::range<1>(ColsPerBlk), cgh);\n    cgh.parallel_for<class sopKernel<Type, IdxType, TPB, ColsPerBlk>>(\n      sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n      int tx = item.get_local_id(1);\n      int bx = item.get_group(1);\n      int by = item.get_group(0);\n      int gridDim_x = item.get_group_range(1);\n\n      const int RowsPerBlkPerIter = TPB / ColsPerBlk;\n      IdxType thisColId = tx % ColsPerBlk;\n      IdxType thisRowId = tx / ColsPerBlk;\n      IdxType colId = thisColId + ((IdxType)by * ColsPerBlk);\n      IdxType rowId = thisRowId + ((IdxType)bx * RowsPerBlkPerIter);\n      Type thread_data = Type(0);\n      const IdxType stride = RowsPerBlkPerIter * gridDim_x;\n      for (IdxType i = rowId; i < N; i += stride) {\n        Type val = (colId < D) ? d_data[i * D + colId] : Type(0);\n        thread_data += val * val;\n      }\n      if (tx < ColsPerBlk) sstd[tx] = Type(0);\n      item.barrier(sycl::access::fence_space::local_space);\n\n      \n\n      auto atomic_local = sycl::atomic_ref<Type,\n                          sycl::memory_order::relaxed,\n                          sycl::memory_scope::work_group,\n                          sycl::access::address_space::local_space> (sstd[thisColId]);\n          atomic_local.fetch_add(thread_data);\n\n      item.barrier(sycl::access::fence_space::local_space);\n\n      if (tx < ColsPerBlk) {\n        \n\n        auto atomic_global = sycl::atomic_ref<Type,\n                             sycl::memory_order::relaxed,\n                             sycl::memory_scope::device,\n                             sycl::access::address_space::global_space> (d_std[colId]);\n        atomic_global.fetch_add(sstd[thisColId]);\n      }\n    });\n  });\n\n  sycl::range<1> gws2 ((D+TPB-1)/TPB*TPB);\n  sycl::range<1> lws2 (TPB);\n  IdxType sampleSize = sample ? N-1 : N;\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class sampleKernel<Type, IdxType>>(\n      sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n      IdxType i = item.get_global_id(0);\n      if (i < D) d_std[i] = sycl::sqrt(d_std[i] / sampleSize);\n    });\n  });\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <D> <N> <repeat>\\n\", argv[0]);\n    printf(\"D: number of columns of data (must be a multiple of 32)\\n\");\n    printf(\"N: number of rows of data (at least one row)\\n\");\n    return 1;\n  }\n  int D = atoi(argv[1]); \n\n  int N = atoi(argv[2]); \n\n  int repeat = atoi(argv[3]);\n\n  bool sample = true;\n  long inputSize = D * N;\n  long inputSizeByte = inputSize * sizeof(float);\n  float *data = (float*) malloc (inputSizeByte);\n\n  \n\n  srand(123);\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < D; j++)\n      data[i*D + j] = rand() / (float)RAND_MAX;\n\n  \n\n  long outputSize = D;\n  long outputSizeByte = outputSize * sizeof(float);\n  float *std  = (float*) malloc (outputSizeByte);\n  float *std_ref  = (float*) malloc (outputSizeByte);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_data = sycl::malloc_device<float>(inputSize, q);\n  q.memcpy(d_data, data, inputSizeByte);\n\n  float *d_std = sycl::malloc_device<float>(outputSize, q);\n\n  \n\n  stddev(q, d_std, d_data, D, N, sample);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++)\n    stddev(q, d_std, d_data, D, N, sample);\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of stddev kernels: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(std, d_std, outputSizeByte).wait();\n\n  \n\n  stddev_ref(std_ref, data, D, N, sample);\n\n  bool ok = true;\n  for (int i = 0; i < D; i++) {\n    if (fabsf(std_ref[i] - std[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(std_ref);\n  free(std);\n  free(data);\n  sycl::free(d_std, q);\n  sycl::free(d_data, q);\n  return 0;\n}\n\n"}}
{"kernel_name": "streamcluster", "parallel_api": "cuda", "code": {"streamcluster.cu": "\n\n\n#include \"streamcluster.h\"\n#include \"streamcluster_cl.h\"\n\nusing namespace std;\n\n#define MAXNAMESIZE 1024   \n\n#define SEED 1\n\n\n\n\n\n\n#define SP 1               \n\n\n\n\n\n\n#define ITER 3             \n\n\n\n\n\n\n\n\n\n\n\n#define CACHE_LINE 512     \n\n\n\n\nstatic char *switch_membership;  \n\nstatic bool *is_center;            \n\nstatic int  *center_table;          \n\nstatic int nproc;                 \n\n\n\n\nstatic double serial;\nstatic double cpu_gpu_memcpy;\nstatic double memcpy_back;\nstatic double gpu_malloc;\nstatic double kernel_time;\nstatic int cnt_speedy;\n\n\n\n#ifdef PROFILE_TMP\nstatic double gpu_free;\ndouble time_local_search;\ndouble time_speedy;\ndouble time_select_feasible;\ndouble time_gain;\ndouble time_shuffle;\ndouble time_gain_dist;\ndouble time_gain_init;\ndouble time_FL;\n#endif \n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nvoid inttofile(int data, char *filename){\n  FILE *fp = fopen(filename, \"w\");\n  fprintf(fp, \"%d \", data);\n  fclose(fp);  \n}\n\nint isIdentical(float *i, float *j, int D){\n  \n\n\n  int a = 0;\n  int equal = 1;\n\n  while (equal && a < D) {\n    if (i[a] != j[a]) equal = 0;\n    else a++;\n  }\n  if (equal) return 1;\n  else return 0;\n\n}\n\n\n\n\n\n\nvoid shuffle(Points *points)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  Point temp;\n  for (i=0;i<points->num-1;i++) {\n    j=(lrand48()%(points->num - i)) + i;\n    temp = points->p[i];\n    points->p[i] = points->p[j];\n    points->p[j] = temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n\n\nvoid intshuffle(int *intarray, int length)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  int temp;\n  for (i=0;i<length;i++) {\n    j=(lrand48()%(length - i))+i;\n    temp = intarray[i];\n    intarray[i]=intarray[j];\n    intarray[j]=temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n#ifdef INSERT_WASTE\nfloat waste(float s )\n{\n  for( int i =0 ; i< 4; i++ ) {\n    s += pow(s,0.78);\n  }\n  return s;\n}\n#endif\n\n\n\nfloat dist(Point p1, Point p2, int dim)\n{\n  int i;\n  float result=0.0;\n  for (i=0;i<dim;i++)\n    result += (p1.coord[i] - p2.coord[i])*(p1.coord[i] - p2.coord[i]);\n#ifdef INSERT_WASTE\n  float s = waste(result);\n  result += s;\n  result -= s;\n#endif\n  return(result);\n}\n\n\n\nfloat pspeedy(Points *points, float z, long *kcenter, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  cnt_speedy++;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n  static float totalcost;\n\n  static bool open = false;\n  static float* costs; \n\n  static int i;\n\n#ifdef ENABLE_THREADS\n  static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\n  static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 ){\n    fprintf(stderr, \"Speedy: facility cost %lf\\n\", z);\n  }\n#endif\n\n  \n\n  for( int k = k1; k < k2; k++ )    {\n    float distance = dist(points->p[k],points->p[0],points->dim);\n    points->p[k].cost = distance * points->p[k].weight;\n    points->p[k].assign=0;\n  }\n\n  if( pid==0 )   {\n    *kcenter = 1;\n    costs = (float*)malloc(sizeof(float)*nproc);\n  }\n\n  if( pid != 0 ) { \n\n    while(1) {\n#ifdef ENABLE_THREADS\n      pthread_mutex_lock(&mutex);\n      while(!open) pthread_cond_wait(&cond,&mutex);\n      pthread_mutex_unlock(&mutex);\n#endif\n      if( i >= points->num ) break;\n      for( int k = k1; k < k2; k++ )\n      {\n        float distance = dist(points->p[i],points->p[k],points->dim);\n        if( distance*points->p[k].weight < points->p[k].cost )\n        {\n          points->p[k].cost = distance * points->p[k].weight;\n          points->p[k].assign=i;\n        }\n      }\n#ifdef ENABLE_THREADS\n      pthread_barrier_wait(barrier);\n      pthread_barrier_wait(barrier);\n#endif\n    } \n  }\n  else  { \n\n    for(i = 1; i < points->num; i++ )  {\n      bool to_open = ((float)lrand48()/(float)INT_MAX)<(points->p[i].cost/z); \n\n      if( to_open )  {\n        (*kcenter)++;\n#ifdef ENABLE_THREADS\n        pthread_mutex_lock(&mutex);\n#endif\n        open = true;\n#ifdef ENABLE_THREADS\n        pthread_mutex_unlock(&mutex);\n        pthread_cond_broadcast(&cond);\n#endif\n        for( int k = k1; k < k2; k++ )  {  \n\n          float distance = dist(points->p[i],points->p[k],points->dim);\n          if( distance*points->p[k].weight < points->p[k].cost )  {\n            points->p[k].cost = distance * points->p[k].weight;\n            points->p[k].assign=i;\n          }\n        }\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n        open = false;\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n      }\n    }\n#ifdef ENABLE_THREADS\n    pthread_mutex_lock(&mutex);\n#endif\n    open = true;\n#ifdef ENABLE_THREADS\n    pthread_mutex_unlock(&mutex);\n    pthread_cond_broadcast(&cond);\n#endif\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  open = false;\n  float mytotal = 0;\n  for( int k = k1; k < k2; k++ )  {\n    mytotal += points->p[k].cost;\n  }\n  costs[pid] = mytotal;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  if( pid == 0 )\n  {\n    totalcost=z*(*kcenter);\n    for( int i = 0; i < nproc; i++ )\n    {\n      totalcost += costs[i];\n    } \n    free(costs);\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    fprintf(stderr, \"Speedy opened %d facilities for total cost %lf\\n\",\n        *kcenter, totalcost);\n    fprintf(stderr, \"Distance Cost %lf\\n\", totalcost - z*(*kcenter));\n  }\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  if( pid== 0 ) {\n    time_speedy += t2 -t1;\n  }\n#endif\n  return(totalcost);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfloat pFL(Points *points, int *feasible, int numfeasible,\n    float z, long *k, int kmax, float cost, long iter, float e, \n    int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  long i;\n  long x;\n  float change;\n\n  change = cost;\n  \n\n  \n\n  while (change/cost > 1.0*e) {\n    change = 0.0;\n    \n\n\n    if( pid == 0 ) {\n      intshuffle(feasible, numfeasible);\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n\n    \n\n\n\n    for (i=0;i<iter;i++) {\n      x = i%numfeasible;\n      \n\n      change += pgain(feasible[x], points, z, k, kmax, is_center, center_table, switch_membership,\n          &serial, &cpu_gpu_memcpy, &memcpy_back, &gpu_malloc, &kernel_time);\n    }    \n    cost -= change;\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      fprintf(stderr, \"%d centers, cost %lf, total distance %lf\\n\",\n          *k, cost, cost - z*(*k));\n    }\n#endif\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_FL += t2 - t1;\n#endif\n  return(cost);\n}\n\nint selectfeasible_fast(Points *points, int **feasible, int kmin, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  int numfeasible = points->num;\n  if (numfeasible > (ITER*kmin*log((float)kmin)))\n    numfeasible = (int)(ITER*kmin*log((float)kmin));\n  *feasible = (int *)malloc(numfeasible*sizeof(int));\n\n  float* accumweight;\n  float totalweight;\n\n  \n\n  \n\n  long k1 = 0;\n  long k2 = numfeasible;\n\n  float w;\n  int l,r,k;\n\n  \n\n  if (numfeasible == points->num) {\n    for (int i=k1;i<k2;i++)\n      (*feasible)[i] = i;\n    return numfeasible;\n  }\n\n  accumweight= (float*)malloc(sizeof(float)*points->num);\n  accumweight[0] = points->p[0].weight;\n  totalweight=0;\n  for( int i = 1; i < points->num; i++ ) {\n    accumweight[i] = accumweight[i-1] + points->p[i].weight;\n  }\n  totalweight=accumweight[points->num-1];\n\n  for(int i=k1; i<k2; i++ ) {\n    w = (lrand48()/(float)INT_MAX)*totalweight;\n    \n\n    l=0;\n    r=points->num-1;\n    if( accumweight[0] > w )  { \n      (*feasible)[i]=0; \n      continue;\n    }\n    while( l+1 < r ) {\n      k = (l+r)/2;\n      if( accumweight[k] > w ) {\n        r = k;\n      } \n      else {\n        l=k;\n      }\n    }\n    (*feasible)[i]=r;\n  }\n  free(accumweight); \n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_select_feasible += t2-t1;\n#endif\n  return numfeasible;\n}\n\n\n\nfloat pkmedian(Points *points, long kmin, long kmax, long* kfinal,\n    int pid, pthread_barrier_t* barrier )\n{\n  int i;\n  float cost;\n  float hiz, loz, z;\n\n  static long k;\n  static int *feasible;\n  static int numfeasible;\n  static float* hizs;\n\n  if( pid==0 ) hizs = (float*)calloc(nproc,sizeof(float));\n  hiz = loz = 0.0;\n  long ptDimension = points->dim;\n\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    printf(\"Starting Kmedian procedure\\n\");\n    printf(\"%i points in %i dimensions\\n\", points->num, ptDimension);\n  }\n#endif\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  float myhiz = 0;\n  for (long kk=k1;kk < k2; kk++ ) {\n    myhiz += dist(points->p[kk], points->p[0],\n        ptDimension)*points->p[kk].weight;\n  }\n  hizs[pid] = myhiz;\n\n#ifdef ENABLE_THREADS  \n  pthread_barrier_wait(barrier);\n#endif\n\n  for( int i = 0; i < nproc; i++ )   {\n    hiz += hizs[i];\n  }\n\n  loz=0.0; z = (hiz+loz)/2.0;\n  \n\n  if (points->num <= kmax) {  \n\n    \n\n    for (long kk=k1;kk<k2;kk++) {\n      points->p[kk].assign = kk;\n      points->p[kk].cost = 0;\n    }\n    cost = 0;\n    if( pid== 0 ) {\n      free(hizs); \n      *kfinal = k;\n    }\n    return cost;\n  }\n\n  if( pid == 0 ) shuffle(points);  \n\n  cost = pspeedy(points, z, &k, pid, barrier);\n#ifdef PRINTINFO\n  if( pid == 0 )\n    printf(\"thread %d: Finished first call to speedy, cost=%lf, k=%i\\n\",pid,cost,k);\n#endif\n  i=0;\n  \n\n  while ((k < kmin)&&(i<SP)) {\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n#ifdef PRINTINFO\n  if( pid==0)\n    printf(\"thread %d: second call to speedy, cost=%lf, k=%d\\n\",pid,cost,k);\n#endif \n  \n\n  while (k < kmin) {\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      printf(\"%lf %lf\\n\", loz, hiz);\n      printf(\"Speedy indicates we should try lower z\\n\");\n    }\n#endif\n    if (i >= SP) {hiz=z; z=(hiz+loz)/2.0; i=0;}\n    if( pid == 0 ) shuffle(points);\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  if( pid == 0 )\n  {\n    numfeasible = selectfeasible_fast(points,&feasible,kmin,pid,barrier); \n\n    for( int i = 0; i< points->num; i++ ) {\n      is_center[points->p[i].assign]= true;\n    }\n  }\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  while(1) {\n#ifdef PRINTINFO\n    if( pid==0 )\n    {\n      printf(\"loz = %lf, hiz = %lf\\n\", loz, hiz);\n      printf(\"Running Local Search...\\n\");\n    }\n#endif\n    \n\n    cost = pFL(points, feasible, numfeasible,\n        z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.1, pid, barrier);\n    \n\n    if (((k <= (1.1)*kmax)&&(k >= (0.9)*kmin))||\n        ((k <= kmax+2)&&(k >= kmin-2))) {\n#ifdef PRINTINFO\n      if( pid== 0)\n      {\n        printf(\"Trying a more accurate local search...\\n\");\n      }\n#endif\n      \n\n      cost = pFL(points, feasible, numfeasible,\n          z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.001, pid, barrier);\n    }\n\n    if (k > kmax) {\n      \n\n      \n\n      loz = z; z = (hiz+loz)/2.0;\n      cost += (z-loz)*k;\n    }\n    if (k < kmin) {\n      \n\n      \n\n      hiz = z; z = (hiz+loz)/2.0;\n      cost += (z-hiz)*k;\n    }\n\n    \n\n    \n\n    if (((k <= kmax)&&(k >= kmin))||((loz >= (0.999)*hiz)) )\n    { \n      break;\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n\n  \n\n  if( pid==0 ) {\n    free(feasible); \n    free(hizs);\n    *kfinal = k;\n  }\n\n  return cost;\n}\n\n\n\nint contcenters(Points *points)\n{\n  long i, ii;\n  float relweight;\n\n  for (i=0;i<points->num;i++) {\n    \n\n    if (points->p[i].assign != i) {\n      relweight=points->p[points->p[i].assign].weight + points->p[i].weight;\n\n      relweight = points->p[i].weight/relweight;\n      for (ii=0;ii<points->dim;ii++) {\n        points->p[points->p[i].assign].coord[ii]*=1.0-relweight;\n        points->p[points->p[i].assign].coord[ii]+=\n          points->p[i].coord[ii]*relweight;\n      }\n      points->p[points->p[i].assign].weight += points->p[i].weight;\n    }\n  }\n\n  return 0;\n}\n\n\n\nvoid copycenters(Points *points, Points* centers, long* centerIDs, long offset)\n{\n  long i;\n  long k;\n\n  bool *is_a_median = (bool *) calloc(points->num, sizeof(bool));\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    is_a_median[points->p[i].assign] = 1;\n  }\n\n  k=centers->num;\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    if ( is_a_median[i] ) {\n      memcpy( centers->p[k].coord, points->p[i].coord, points->dim * sizeof(float));\n      centers->p[k].weight = points->p[i].weight;\n      centerIDs[k] = i + offset;\n      k++;\n    }\n  }\n\n  centers->num = k;\n  free(is_a_median);\n}\n\n\n\nvoid* localSearchSub(void* arg_) {\n  pkmedian_arg_t* arg= (pkmedian_arg_t*)arg_;\n  pkmedian(arg->points,arg->kmin,arg->kmax,arg->kfinal,arg->pid,arg->barrier);\n\n  return NULL;\n}\n\nvoid localSearch( Points* points, long kmin, long kmax, long* kfinal ) {\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  pthread_barrier_t barrier;\n#ifdef ENABLE_THREADS\n  pthread_barrier_init(&barrier,NULL,nproc);\n#endif\n  pthread_t* threads = new pthread_t[nproc];\n  pkmedian_arg_t* arg = new pkmedian_arg_t[nproc];\n\n\n  for( int i = 0; i < nproc; i++ ) {\n    arg[i].points = points;\n    arg[i].kmin = kmin;\n    arg[i].kmax = kmax;\n    arg[i].pid = i;\n    arg[i].kfinal = kfinal;\n\n    arg[i].barrier = &barrier;\n#ifdef ENABLE_THREADS\n    pthread_create(threads+i,NULL,localSearchSub,(void*)&arg[i]);\n#else\n    localSearchSub(&arg[0]);\n#endif\n  }\n\n  for ( int i = 0; i < nproc; i++) {\n#ifdef ENABLE_THREADS\n    pthread_join(threads[i],NULL);\n#endif\n  }\n\n  delete[] threads;\n  delete[] arg;\n#ifdef ENABLE_THREADS\n  pthread_barrier_destroy(&barrier);\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_local_search += t2-t1;\n#endif\n\n}\n\n\nvoid outcenterIDs( Points* centers, long* centerIDs, char* outfile ) {\n  FILE* fp = fopen(outfile, \"w\");\n  if( fp==NULL ) {\n    fprintf(stderr, \"error opening %s\\n\",outfile);\n    exit(1);\n  }\n  int* is_a_median = (int*)calloc( sizeof(int), centers->num );\n  for( int i =0 ; i< centers->num; i++ ) {\n    is_a_median[centers->p[i].assign] = 1;\n  }\n\n  for( int i = 0; i < centers->num; i++ ) {\n    if( is_a_median[i] ) {\n      fprintf(fp, \"%ld\\n\", centerIDs[i]);\n      fprintf(fp, \"%lf\\n\", centers->p[i].weight);\n      for( int k = 0; k < centers->dim; k++ ) {\n        fprintf(fp, \"%lf \", centers->p[i].coord[k]);\n      }\n      fprintf(fp,\"\\n\\n\");\n    }\n  }\n  fclose(fp);\n}\n\nvoid streamCluster( PStream* stream, \n    long kmin, long kmax, int dim,\n    long chunksize, long centersize, char* outfile )\n{\n\n  float* block = (float*)malloc( chunksize*dim*sizeof(float) );\n  float* centerBlock = (float*)malloc(centersize*dim*sizeof(float) );\n  long* centerIDs = (long*)malloc(centersize*dim*sizeof(long));\n\n  if( block == NULL ) { \n    fprintf(stderr,\"not enough memory for a chunk!\\n\");\n    exit(1);\n  }\n\n  Points points;\n  points.dim = dim;\n  points.num = chunksize;\n  points.p = (Point *)malloc(chunksize*sizeof(Point));\n  for( int i = 0; i < chunksize; i++ ) {\n    points.p[i].coord = &block[i*dim];    \n  }\n\n\n  Points centers;\n  centers.dim = dim;\n  centers.p = (Point *)malloc(centersize*sizeof(Point));\n  centers.num = 0;\n\n  for( int i = 0; i< centersize; i++ ) {\n    centers.p[i].coord = &centerBlock[i*dim];\n    centers.p[i].weight = 1.0;\n  }\n\n  long IDoffset = 0;\n  long kfinal;\n  while(1) {\n\n    size_t numRead  = stream->read(block, dim, chunksize ); \n    fprintf(stderr,\"read %zu points\\n\",numRead);\n\n    if( stream->ferror() || (numRead < (unsigned int)chunksize && !stream->feof()) ) {\n      fprintf(stderr, \"error reading data!\\n\");\n      exit(1);\n    }\n\n    points.num = numRead;\n    for( int i = 0; i < points.num; i++ ) {\n      points.p[i].weight = 1.0;\n    }\n\n    switch_membership = (char*)malloc(points.num*sizeof(char));\n    is_center = (bool*)calloc(points.num,sizeof(bool));\n    center_table = (int*)malloc(points.num*sizeof(int));\n\n    localSearch(&points,kmin, kmax,&kfinal);\n\n    fprintf(stderr,\"finish local search\\n\");\n    contcenters(&points);\n    if( kfinal + centers.num > centersize ) {\n      \n\n      fprintf(stderr,\"oops! no more space for centers\\n\");\n      exit(1);\n    }\n\n#ifdef PRINTINFO\n    printf(\"finish cont center\\n\");\n#endif\n\n    copycenters(&points, &centers, centerIDs, IDoffset);\n    IDoffset += numRead;\n\n#ifdef PRINTINFO\n    printf(\"finish copy centers\\n\"); \n#endif\n    free(is_center);\n    free(switch_membership);\n    free(center_table);\n    if( stream->feof() ) {\n      break;\n    }\n  }\n\n  \n\n  switch_membership = (char*)malloc(centers.num*sizeof(char));\n  is_center = (bool*)calloc(centers.num,sizeof(bool));\n  center_table = (int*)malloc(centers.num*sizeof(int));\n\n  localSearch( &centers, kmin, kmax ,&kfinal );\n  contcenters(&centers);\n  outcenterIDs( &centers, centerIDs, outfile);\n}\n\nint main(int argc, char **argv)\n{\n  char outfilename[MAXNAMESIZE];\n  char infilename[MAXNAMESIZE];\n  long kmin, kmax, n, chunksize, clustersize;\n  int dim;\n#ifdef PARSEC_VERSION\n#define __PARSEC_STRING(x) #x\n#define __PARSEC_XSTRING(x) __PARSEC_STRING(x)\n  printf(\"PARSEC Benchmark Suite Version \"__PARSEC_XSTRING(PARSEC_VERSION)\"\\n\");\n  fflush(NULL);\n#else\n  printf(\"PARSEC Benchmark Suite\\n\");\n  fflush(NULL);\n#endif \n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_begin(__parsec_streamcluster);\n#endif\n\n  if (argc<9) {\n    fprintf(stderr,\"usage: %s k1 k2 d n chunksize clustersize infile outfile nproc\\n\",\n        argv[0]);\n    fprintf(stderr,\"  k1:          Min. number of centers allowed\\n\");\n    fprintf(stderr,\"  k2:          Max. number of centers allowed\\n\");\n    fprintf(stderr,\"  d:           Dimension of each data point\\n\");\n    fprintf(stderr,\"  n:           Number of data points\\n\");\n    fprintf(stderr,\"  chunksize:   Number of data points to handle per step\\n\");\n    fprintf(stderr,\"  clustersize: Maximum number of intermediate centers\\n\");\n    fprintf(stderr,\"  infile:      Input file (if n<=0)\\n\");\n    fprintf(stderr,\"  outfile:     Output file\\n\");\n    fprintf(stderr,\"  nproc:       Number of threads to use\\n\");\n    fprintf(stderr,\"\\n\");\n    fprintf(stderr, \"if n > 0, points will be randomly generated instead of reading from infile.\\n\");\n    exit(1);\n  }\n  kmin = atoi(argv[1]);\n  kmax = atoi(argv[2]);\n  dim = atoi(argv[3]);\n  n = atoi(argv[4]);\n  chunksize = atoi(argv[5]);\n  clustersize = atoi(argv[6]);\n  strcpy(infilename, argv[7]);\n  strcpy(outfilename, argv[8]);\n  nproc = atoi(argv[9]);\n\n  srand48(SEED);\n  PStream* stream;\n  if( n > 0 ) {\n    stream = new SimStream(n);\n  }\n  else {\n    stream = new FileStream(infilename);\n  }\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_begin();\n#endif\n#ifdef PROFILE_TMP\n  serial = 0.0;\n  cpu_gpu_memcpy = 0.0;\n  gpu_malloc = 0.0;\n  gpu_free = 0.0;\n  kernel_time = 0.0;\n  time_FL = 0.0;\n  cnt_speedy = 0;\n#endif\n  double sc_start = gettime();\n  streamCluster(stream, kmin, kmax, dim, chunksize, clustersize, outfilename );\n  double sc_end = gettime();\n  printf(\"Streamcluster time = %lf (s)\\n\", sc_end-sc_start);\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_end();\n#endif\n\n#ifdef PROFILE_TMP \n  gpu_free = gettime();\n#endif\n  free(coord_h);\n  free(gl_lower);\n  free(work_mem_h);\n  free(p_h);\n  cudaFree(work_mem_d);\n  cudaFree(coord_d);\n  cudaFree(center_table_d);\n  cudaFree(switch_membership_d);\n  cudaFree(p_d);\n\n#ifdef PROFILE_TMP\n  gpu_free = gettime() - gpu_free;\n\n  double t2 = gettime();\n  printf(\"Total time = %lf (s)\\n\",t2-t1);\n#endif\n\n  delete stream;\n\n#ifdef PROFILE_TMP\n  printf(\"==== Detailed timing info ====\\n\");\n  printf(\"pgain = %lf (s)\\n\", time_gain);\n  printf(\"pgain_dist = %lf (s)\\n\", time_gain_dist);\n  printf(\"pgain_init = %lf (s)\\n\", time_gain_init);\n  printf(\"pselect = %lf (s)\\n\", time_select_feasible);\n  printf(\"pspeedy = %lf (s)\\n\", time_speedy);\n  printf(\"pshuffle = %lf (s)\\n\", time_shuffle);\n  printf(\"FL = %lf (s)\\n\", time_FL);\n  printf(\"localSearch = %lf (s)\\n\", time_local_search);\n  printf(\"\\n\");\n  printf(\"serial = %lf (s)\\n\", serial);\n  printf(\"CPU to GPU memory copy = %lf (s)\\n\", cpu_gpu_memcpy);\n  printf(\"GPU to CPU memory copy back = %lf (s)\\n\", memcpy_back);\n  printf(\"GPU malloc = %lf (s)\\n\", gpu_malloc);\n  printf(\"GPU free = %lf (s)\\n\", gpu_free);\n  printf(\"GPU kernels = %lf (s)\\n\", kernel_time);\n#endif\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_end();\n#endif\n\n  return 0;\n}\n"}}
{"kernel_name": "streamcluster", "parallel_api": "hip", "code": {"streamcluster.cu": "\n\n\n#include \"streamcluster.h\"\n#include \"streamcluster_cl.h\"\n\nusing namespace std;\n\n#define MAXNAMESIZE 1024   \n\n#define SEED 1\n\n\n\n\n\n\n#define SP 1               \n\n\n\n\n\n\n#define ITER 3             \n\n\n\n\n\n\n\n\n\n\n\n#define CACHE_LINE 512     \n\n\n\n\nstatic char *switch_membership;  \n\nstatic bool *is_center;            \n\nstatic int  *center_table;          \n\nstatic int nproc;                 \n\n\n\n\nstatic double serial;\nstatic double cpu_gpu_memcpy;\nstatic double memcpy_back;\nstatic double gpu_malloc;\nstatic double kernel_time;\nstatic int cnt_speedy;\n\n\n\n#ifdef PROFILE_TMP\nstatic double gpu_free;\ndouble time_local_search;\ndouble time_speedy;\ndouble time_select_feasible;\ndouble time_gain;\ndouble time_shuffle;\ndouble time_gain_dist;\ndouble time_gain_init;\ndouble time_FL;\n#endif \n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nvoid inttofile(int data, char *filename){\n  FILE *fp = fopen(filename, \"w\");\n  fprintf(fp, \"%d \", data);\n  fclose(fp);  \n}\n\nint isIdentical(float *i, float *j, int D){\n  \n\n\n  int a = 0;\n  int equal = 1;\n\n  while (equal && a < D) {\n    if (i[a] != j[a]) equal = 0;\n    else a++;\n  }\n  if (equal) return 1;\n  else return 0;\n\n}\n\n\n\n\n\n\nvoid shuffle(Points *points)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  Point temp;\n  for (i=0;i<points->num-1;i++) {\n    j=(lrand48()%(points->num - i)) + i;\n    temp = points->p[i];\n    points->p[i] = points->p[j];\n    points->p[j] = temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n\n\nvoid intshuffle(int *intarray, int length)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  int temp;\n  for (i=0;i<length;i++) {\n    j=(lrand48()%(length - i))+i;\n    temp = intarray[i];\n    intarray[i]=intarray[j];\n    intarray[j]=temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n#ifdef INSERT_WASTE\nfloat waste(float s )\n{\n  for( int i =0 ; i< 4; i++ ) {\n    s += pow(s,0.78);\n  }\n  return s;\n}\n#endif\n\n\n\nfloat dist(Point p1, Point p2, int dim)\n{\n  int i;\n  float result=0.0;\n  for (i=0;i<dim;i++)\n    result += (p1.coord[i] - p2.coord[i])*(p1.coord[i] - p2.coord[i]);\n#ifdef INSERT_WASTE\n  float s = waste(result);\n  result += s;\n  result -= s;\n#endif\n  return(result);\n}\n\n\n\nfloat pspeedy(Points *points, float z, long *kcenter, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  cnt_speedy++;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n  static float totalcost;\n\n  static bool open = false;\n  static float* costs; \n\n  static int i;\n\n#ifdef ENABLE_THREADS\n  static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\n  static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 ){\n    fprintf(stderr, \"Speedy: facility cost %lf\\n\", z);\n  }\n#endif\n\n  \n\n  for( int k = k1; k < k2; k++ )    {\n    float distance = dist(points->p[k],points->p[0],points->dim);\n    points->p[k].cost = distance * points->p[k].weight;\n    points->p[k].assign=0;\n  }\n\n  if( pid==0 )   {\n    *kcenter = 1;\n    costs = (float*)malloc(sizeof(float)*nproc);\n  }\n\n  if( pid != 0 ) { \n\n    while(1) {\n#ifdef ENABLE_THREADS\n      pthread_mutex_lock(&mutex);\n      while(!open) pthread_cond_wait(&cond,&mutex);\n      pthread_mutex_unlock(&mutex);\n#endif\n      if( i >= points->num ) break;\n      for( int k = k1; k < k2; k++ )\n      {\n        float distance = dist(points->p[i],points->p[k],points->dim);\n        if( distance*points->p[k].weight < points->p[k].cost )\n        {\n          points->p[k].cost = distance * points->p[k].weight;\n          points->p[k].assign=i;\n        }\n      }\n#ifdef ENABLE_THREADS\n      pthread_barrier_wait(barrier);\n      pthread_barrier_wait(barrier);\n#endif\n    } \n  }\n  else  { \n\n    for(i = 1; i < points->num; i++ )  {\n      bool to_open = ((float)lrand48()/(float)INT_MAX)<(points->p[i].cost/z); \n\n      if( to_open )  {\n        (*kcenter)++;\n#ifdef ENABLE_THREADS\n        pthread_mutex_lock(&mutex);\n#endif\n        open = true;\n#ifdef ENABLE_THREADS\n        pthread_mutex_unlock(&mutex);\n        pthread_cond_broadcast(&cond);\n#endif\n        for( int k = k1; k < k2; k++ )  {  \n\n          float distance = dist(points->p[i],points->p[k],points->dim);\n          if( distance*points->p[k].weight < points->p[k].cost )  {\n            points->p[k].cost = distance * points->p[k].weight;\n            points->p[k].assign=i;\n          }\n        }\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n        open = false;\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n      }\n    }\n#ifdef ENABLE_THREADS\n    pthread_mutex_lock(&mutex);\n#endif\n    open = true;\n#ifdef ENABLE_THREADS\n    pthread_mutex_unlock(&mutex);\n    pthread_cond_broadcast(&cond);\n#endif\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  open = false;\n  float mytotal = 0;\n  for( int k = k1; k < k2; k++ )  {\n    mytotal += points->p[k].cost;\n  }\n  costs[pid] = mytotal;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  if( pid == 0 )\n  {\n    totalcost=z*(*kcenter);\n    for( int i = 0; i < nproc; i++ )\n    {\n      totalcost += costs[i];\n    } \n    free(costs);\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    fprintf(stderr, \"Speedy opened %d facilities for total cost %lf\\n\",\n        *kcenter, totalcost);\n    fprintf(stderr, \"Distance Cost %lf\\n\", totalcost - z*(*kcenter));\n  }\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  if( pid== 0 ) {\n    time_speedy += t2 -t1;\n  }\n#endif\n  return(totalcost);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfloat pFL(Points *points, int *feasible, int numfeasible,\n    float z, long *k, int kmax, float cost, long iter, float e, \n    int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  long i;\n  long x;\n  float change;\n\n  change = cost;\n  \n\n  \n\n  while (change/cost > 1.0*e) {\n    change = 0.0;\n    \n\n\n    if( pid == 0 ) {\n      intshuffle(feasible, numfeasible);\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n\n    \n\n\n\n    for (i=0;i<iter;i++) {\n      x = i%numfeasible;\n      \n\n      change += pgain(feasible[x], points, z, k, kmax, is_center, center_table, switch_membership,\n          &serial, &cpu_gpu_memcpy, &memcpy_back, &gpu_malloc, &kernel_time);\n    }    \n    cost -= change;\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      fprintf(stderr, \"%d centers, cost %lf, total distance %lf\\n\",\n          *k, cost, cost - z*(*k));\n    }\n#endif\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_FL += t2 - t1;\n#endif\n  return(cost);\n}\n\nint selectfeasible_fast(Points *points, int **feasible, int kmin, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  int numfeasible = points->num;\n  if (numfeasible > (ITER*kmin*log((float)kmin)))\n    numfeasible = (int)(ITER*kmin*log((float)kmin));\n  *feasible = (int *)malloc(numfeasible*sizeof(int));\n\n  float* accumweight;\n  float totalweight;\n\n  \n\n  \n\n  long k1 = 0;\n  long k2 = numfeasible;\n\n  float w;\n  int l,r,k;\n\n  \n\n  if (numfeasible == points->num) {\n    for (int i=k1;i<k2;i++)\n      (*feasible)[i] = i;\n    return numfeasible;\n  }\n\n  accumweight= (float*)malloc(sizeof(float)*points->num);\n  accumweight[0] = points->p[0].weight;\n  totalweight=0;\n  for( int i = 1; i < points->num; i++ ) {\n    accumweight[i] = accumweight[i-1] + points->p[i].weight;\n  }\n  totalweight=accumweight[points->num-1];\n\n  for(int i=k1; i<k2; i++ ) {\n    w = (lrand48()/(float)INT_MAX)*totalweight;\n    \n\n    l=0;\n    r=points->num-1;\n    if( accumweight[0] > w )  { \n      (*feasible)[i]=0; \n      continue;\n    }\n    while( l+1 < r ) {\n      k = (l+r)/2;\n      if( accumweight[k] > w ) {\n        r = k;\n      } \n      else {\n        l=k;\n      }\n    }\n    (*feasible)[i]=r;\n  }\n  free(accumweight); \n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_select_feasible += t2-t1;\n#endif\n  return numfeasible;\n}\n\n\n\nfloat pkmedian(Points *points, long kmin, long kmax, long* kfinal,\n    int pid, pthread_barrier_t* barrier )\n{\n  int i;\n  float cost;\n  float hiz, loz, z;\n\n  static long k;\n  static int *feasible;\n  static int numfeasible;\n  static float* hizs;\n\n  if( pid==0 ) hizs = (float*)calloc(nproc,sizeof(float));\n  hiz = loz = 0.0;\n  long ptDimension = points->dim;\n\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    printf(\"Starting Kmedian procedure\\n\");\n    printf(\"%i points in %i dimensions\\n\", points->num, ptDimension);\n  }\n#endif\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  float myhiz = 0;\n  for (long kk=k1;kk < k2; kk++ ) {\n    myhiz += dist(points->p[kk], points->p[0],\n        ptDimension)*points->p[kk].weight;\n  }\n  hizs[pid] = myhiz;\n\n#ifdef ENABLE_THREADS  \n  pthread_barrier_wait(barrier);\n#endif\n\n  for( int i = 0; i < nproc; i++ )   {\n    hiz += hizs[i];\n  }\n\n  loz=0.0; z = (hiz+loz)/2.0;\n  \n\n  if (points->num <= kmax) {  \n\n    \n\n    for (long kk=k1;kk<k2;kk++) {\n      points->p[kk].assign = kk;\n      points->p[kk].cost = 0;\n    }\n    cost = 0;\n    if( pid== 0 ) {\n      free(hizs); \n      *kfinal = k;\n    }\n    return cost;\n  }\n\n  if( pid == 0 ) shuffle(points);  \n\n  cost = pspeedy(points, z, &k, pid, barrier);\n#ifdef PRINTINFO\n  if( pid == 0 )\n    printf(\"thread %d: Finished first call to speedy, cost=%lf, k=%i\\n\",pid,cost,k);\n#endif\n  i=0;\n  \n\n  while ((k < kmin)&&(i<SP)) {\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n#ifdef PRINTINFO\n  if( pid==0)\n    printf(\"thread %d: second call to speedy, cost=%lf, k=%d\\n\",pid,cost,k);\n#endif \n  \n\n  while (k < kmin) {\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      printf(\"%lf %lf\\n\", loz, hiz);\n      printf(\"Speedy indicates we should try lower z\\n\");\n    }\n#endif\n    if (i >= SP) {hiz=z; z=(hiz+loz)/2.0; i=0;}\n    if( pid == 0 ) shuffle(points);\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  if( pid == 0 )\n  {\n    numfeasible = selectfeasible_fast(points,&feasible,kmin,pid,barrier); \n\n    for( int i = 0; i< points->num; i++ ) {\n      is_center[points->p[i].assign]= true;\n    }\n  }\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  while(1) {\n#ifdef PRINTINFO\n    if( pid==0 )\n    {\n      printf(\"loz = %lf, hiz = %lf\\n\", loz, hiz);\n      printf(\"Running Local Search...\\n\");\n    }\n#endif\n    \n\n    cost = pFL(points, feasible, numfeasible,\n        z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.1, pid, barrier);\n    \n\n    if (((k <= (1.1)*kmax)&&(k >= (0.9)*kmin))||\n        ((k <= kmax+2)&&(k >= kmin-2))) {\n#ifdef PRINTINFO\n      if( pid== 0)\n      {\n        printf(\"Trying a more accurate local search...\\n\");\n      }\n#endif\n      \n\n      cost = pFL(points, feasible, numfeasible,\n          z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.001, pid, barrier);\n    }\n\n    if (k > kmax) {\n      \n\n      \n\n      loz = z; z = (hiz+loz)/2.0;\n      cost += (z-loz)*k;\n    }\n    if (k < kmin) {\n      \n\n      \n\n      hiz = z; z = (hiz+loz)/2.0;\n      cost += (z-hiz)*k;\n    }\n\n    \n\n    \n\n    if (((k <= kmax)&&(k >= kmin))||((loz >= (0.999)*hiz)) )\n    { \n      break;\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n\n  \n\n  if( pid==0 ) {\n    free(feasible); \n    free(hizs);\n    *kfinal = k;\n  }\n\n  return cost;\n}\n\n\n\nint contcenters(Points *points)\n{\n  long i, ii;\n  float relweight;\n\n  for (i=0;i<points->num;i++) {\n    \n\n    if (points->p[i].assign != i) {\n      relweight=points->p[points->p[i].assign].weight + points->p[i].weight;\n\n      relweight = points->p[i].weight/relweight;\n      for (ii=0;ii<points->dim;ii++) {\n        points->p[points->p[i].assign].coord[ii]*=1.0-relweight;\n        points->p[points->p[i].assign].coord[ii]+=\n          points->p[i].coord[ii]*relweight;\n      }\n      points->p[points->p[i].assign].weight += points->p[i].weight;\n    }\n  }\n\n  return 0;\n}\n\n\n\nvoid copycenters(Points *points, Points* centers, long* centerIDs, long offset)\n{\n  long i;\n  long k;\n\n  bool *is_a_median = (bool *) calloc(points->num, sizeof(bool));\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    is_a_median[points->p[i].assign] = 1;\n  }\n\n  k=centers->num;\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    if ( is_a_median[i] ) {\n      memcpy( centers->p[k].coord, points->p[i].coord, points->dim * sizeof(float));\n      centers->p[k].weight = points->p[i].weight;\n      centerIDs[k] = i + offset;\n      k++;\n    }\n  }\n\n  centers->num = k;\n  free(is_a_median);\n}\n\n\n\nvoid* localSearchSub(void* arg_) {\n  pkmedian_arg_t* arg= (pkmedian_arg_t*)arg_;\n  pkmedian(arg->points,arg->kmin,arg->kmax,arg->kfinal,arg->pid,arg->barrier);\n\n  return NULL;\n}\n\nvoid localSearch( Points* points, long kmin, long kmax, long* kfinal ) {\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  pthread_barrier_t barrier;\n#ifdef ENABLE_THREADS\n  pthread_barrier_init(&barrier,NULL,nproc);\n#endif\n  pthread_t* threads = new pthread_t[nproc];\n  pkmedian_arg_t* arg = new pkmedian_arg_t[nproc];\n\n\n  for( int i = 0; i < nproc; i++ ) {\n    arg[i].points = points;\n    arg[i].kmin = kmin;\n    arg[i].kmax = kmax;\n    arg[i].pid = i;\n    arg[i].kfinal = kfinal;\n\n    arg[i].barrier = &barrier;\n#ifdef ENABLE_THREADS\n    pthread_create(threads+i,NULL,localSearchSub,(void*)&arg[i]);\n#else\n    localSearchSub(&arg[0]);\n#endif\n  }\n\n  for ( int i = 0; i < nproc; i++) {\n#ifdef ENABLE_THREADS\n    pthread_join(threads[i],NULL);\n#endif\n  }\n\n  delete[] threads;\n  delete[] arg;\n#ifdef ENABLE_THREADS\n  pthread_barrier_destroy(&barrier);\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_local_search += t2-t1;\n#endif\n\n}\n\n\nvoid outcenterIDs( Points* centers, long* centerIDs, char* outfile ) {\n  FILE* fp = fopen(outfile, \"w\");\n  if( fp==NULL ) {\n    fprintf(stderr, \"error opening %s\\n\",outfile);\n    exit(1);\n  }\n  int* is_a_median = (int*)calloc( sizeof(int), centers->num );\n  for( int i =0 ; i< centers->num; i++ ) {\n    is_a_median[centers->p[i].assign] = 1;\n  }\n\n  for( int i = 0; i < centers->num; i++ ) {\n    if( is_a_median[i] ) {\n      fprintf(fp, \"%ld\\n\", centerIDs[i]);\n      fprintf(fp, \"%lf\\n\", centers->p[i].weight);\n      for( int k = 0; k < centers->dim; k++ ) {\n        fprintf(fp, \"%lf \", centers->p[i].coord[k]);\n      }\n      fprintf(fp,\"\\n\\n\");\n    }\n  }\n  fclose(fp);\n}\n\nvoid streamCluster( PStream* stream, \n    long kmin, long kmax, int dim,\n    long chunksize, long centersize, char* outfile )\n{\n\n  float* block = (float*)malloc( chunksize*dim*sizeof(float) );\n  float* centerBlock = (float*)malloc(centersize*dim*sizeof(float) );\n  long* centerIDs = (long*)malloc(centersize*dim*sizeof(long));\n\n  if( block == NULL ) { \n    fprintf(stderr,\"not enough memory for a chunk!\\n\");\n    exit(1);\n  }\n\n  Points points;\n  points.dim = dim;\n  points.num = chunksize;\n  points.p = (Point *)malloc(chunksize*sizeof(Point));\n  for( int i = 0; i < chunksize; i++ ) {\n    points.p[i].coord = &block[i*dim];    \n  }\n\n\n  Points centers;\n  centers.dim = dim;\n  centers.p = (Point *)malloc(centersize*sizeof(Point));\n  centers.num = 0;\n\n  for( int i = 0; i< centersize; i++ ) {\n    centers.p[i].coord = &centerBlock[i*dim];\n    centers.p[i].weight = 1.0;\n  }\n\n  long IDoffset = 0;\n  long kfinal;\n  while(1) {\n\n    size_t numRead  = stream->read(block, dim, chunksize ); \n    fprintf(stderr,\"read %zu points\\n\",numRead);\n\n    if( stream->ferror() || (numRead < (unsigned int)chunksize && !stream->feof()) ) {\n      fprintf(stderr, \"error reading data!\\n\");\n      exit(1);\n    }\n\n    points.num = numRead;\n    for( int i = 0; i < points.num; i++ ) {\n      points.p[i].weight = 1.0;\n    }\n\n    switch_membership = (char*)malloc(points.num*sizeof(char));\n    is_center = (bool*)calloc(points.num,sizeof(bool));\n    center_table = (int*)malloc(points.num*sizeof(int));\n\n    localSearch(&points,kmin, kmax,&kfinal);\n\n    fprintf(stderr,\"finish local search\\n\");\n    contcenters(&points);\n    if( kfinal + centers.num > centersize ) {\n      \n\n      fprintf(stderr,\"oops! no more space for centers\\n\");\n      exit(1);\n    }\n\n#ifdef PRINTINFO\n    printf(\"finish cont center\\n\");\n#endif\n\n    copycenters(&points, &centers, centerIDs, IDoffset);\n    IDoffset += numRead;\n\n#ifdef PRINTINFO\n    printf(\"finish copy centers\\n\"); \n#endif\n    free(is_center);\n    free(switch_membership);\n    free(center_table);\n    if( stream->feof() ) {\n      break;\n    }\n  }\n\n  \n\n  switch_membership = (char*)malloc(centers.num*sizeof(char));\n  is_center = (bool*)calloc(centers.num,sizeof(bool));\n  center_table = (int*)malloc(centers.num*sizeof(int));\n\n  localSearch( &centers, kmin, kmax ,&kfinal );\n  contcenters(&centers);\n  outcenterIDs( &centers, centerIDs, outfile);\n}\n\nint main(int argc, char **argv)\n{\n  char outfilename[MAXNAMESIZE];\n  char infilename[MAXNAMESIZE];\n  long kmin, kmax, n, chunksize, clustersize;\n  int dim;\n#ifdef PARSEC_VERSION\n#define __PARSEC_STRING(x) #x\n#define __PARSEC_XSTRING(x) __PARSEC_STRING(x)\n  printf(\"PARSEC Benchmark Suite Version \"__PARSEC_XSTRING(PARSEC_VERSION)\"\\n\");\n  fflush(NULL);\n#else\n  printf(\"PARSEC Benchmark Suite\\n\");\n  fflush(NULL);\n#endif \n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_begin(__parsec_streamcluster);\n#endif\n\n  if (argc<9) {\n    fprintf(stderr,\"usage: %s k1 k2 d n chunksize clustersize infile outfile nproc\\n\",\n        argv[0]);\n    fprintf(stderr,\"  k1:          Min. number of centers allowed\\n\");\n    fprintf(stderr,\"  k2:          Max. number of centers allowed\\n\");\n    fprintf(stderr,\"  d:           Dimension of each data point\\n\");\n    fprintf(stderr,\"  n:           Number of data points\\n\");\n    fprintf(stderr,\"  chunksize:   Number of data points to handle per step\\n\");\n    fprintf(stderr,\"  clustersize: Maximum number of intermediate centers\\n\");\n    fprintf(stderr,\"  infile:      Input file (if n<=0)\\n\");\n    fprintf(stderr,\"  outfile:     Output file\\n\");\n    fprintf(stderr,\"  nproc:       Number of threads to use\\n\");\n    fprintf(stderr,\"\\n\");\n    fprintf(stderr, \"if n > 0, points will be randomly generated instead of reading from infile.\\n\");\n    exit(1);\n  }\n  kmin = atoi(argv[1]);\n  kmax = atoi(argv[2]);\n  dim = atoi(argv[3]);\n  n = atoi(argv[4]);\n  chunksize = atoi(argv[5]);\n  clustersize = atoi(argv[6]);\n  strcpy(infilename, argv[7]);\n  strcpy(outfilename, argv[8]);\n  nproc = atoi(argv[9]);\n\n  srand48(SEED);\n  PStream* stream;\n  if( n > 0 ) {\n    stream = new SimStream(n);\n  }\n  else {\n    stream = new FileStream(infilename);\n  }\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_begin();\n#endif\n#ifdef PROFILE_TMP\n  serial = 0.0;\n  cpu_gpu_memcpy = 0.0;\n  gpu_malloc = 0.0;\n  gpu_free = 0.0;\n  kernel_time = 0.0;\n  time_FL = 0.0;\n  cnt_speedy = 0;\n#endif\n  double sc_start = gettime();\n  streamCluster(stream, kmin, kmax, dim, chunksize, clustersize, outfilename );\n  double sc_end = gettime();\n  printf(\"Streamcluster time = %lf (s)\\n\", sc_end-sc_start);\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_end();\n#endif\n\n#ifdef PROFILE_TMP \n  gpu_free = gettime();\n#endif\n  free(coord_h);\n  free(gl_lower);\n  free(work_mem_h);\n  free(p_h);\n  hipFree(work_mem_d);\n  hipFree(coord_d);\n  hipFree(center_table_d);\n  hipFree(switch_membership_d);\n  hipFree(p_d);\n\n#ifdef PROFILE_TMP\n  gpu_free = gettime() - gpu_free;\n\n  double t2 = gettime();\n  printf(\"Total time = %lf (s)\\n\",t2-t1);\n#endif\n\n  delete stream;\n\n#ifdef PROFILE_TMP\n  printf(\"==== Detailed timing info ====\\n\");\n  printf(\"pgain = %lf (s)\\n\", time_gain);\n  printf(\"pgain_dist = %lf (s)\\n\", time_gain_dist);\n  printf(\"pgain_init = %lf (s)\\n\", time_gain_init);\n  printf(\"pselect = %lf (s)\\n\", time_select_feasible);\n  printf(\"pspeedy = %lf (s)\\n\", time_speedy);\n  printf(\"pshuffle = %lf (s)\\n\", time_shuffle);\n  printf(\"FL = %lf (s)\\n\", time_FL);\n  printf(\"localSearch = %lf (s)\\n\", time_local_search);\n  printf(\"\\n\");\n  printf(\"serial = %lf (s)\\n\", serial);\n  printf(\"CPU to GPU memory copy = %lf (s)\\n\", cpu_gpu_memcpy);\n  printf(\"GPU to CPU memory copy back = %lf (s)\\n\", memcpy_back);\n  printf(\"GPU malloc = %lf (s)\\n\", gpu_malloc);\n  printf(\"GPU free = %lf (s)\\n\", gpu_free);\n  printf(\"GPU kernels = %lf (s)\\n\", kernel_time);\n#endif\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_end();\n#endif\n\n  return 0;\n}\n"}}
{"kernel_name": "streamcluster", "parallel_api": "omp", "code": {"streamcluster.cpp": "\n\n#include <omp.h>\n#include \"streamcluster.h\"\n#include \"streamcluster_cl.h\"\n\nusing namespace std;\n\n#define MAXNAMESIZE 1024   \n\n#define SEED 1\n\n\n\n\n\n\n#define SP 1               \n\n\n\n\n\n\n#define ITER 3             \n\n\n\n\n\n\n\n\n\n\n\n#define CACHE_LINE 512     \n\n\n\n\nstatic char *switch_membership;  \n\nstatic bool *is_center;            \n\nstatic int  *center_table;          \n\nstatic int nproc;                 \n\n\n\n\nstatic double serial;\nstatic double cpu_gpu_memcpy;\nstatic double memcpy_back;\nstatic double gpu_malloc;\nstatic double kernel_time;\nstatic int cnt_speedy;\n\n\n\n#ifdef PROFILE_TMP\nstatic double gpu_free;\ndouble time_local_search;\ndouble time_speedy;\ndouble time_select_feasible;\ndouble time_gain;\ndouble time_shuffle;\ndouble time_gain_dist;\ndouble time_gain_init;\ndouble time_FL;\n#endif \n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nvoid inttofile(int data, char *filename){\n  FILE *fp = fopen(filename, \"w\");\n  fprintf(fp, \"%d \", data);\n  fclose(fp);  \n}\n\nint isIdentical(float *i, float *j, int D){\n  \n\n\n  int a = 0;\n  int equal = 1;\n\n  while (equal && a < D) {\n    if (i[a] != j[a]) equal = 0;\n    else a++;\n  }\n  if (equal) return 1;\n  else return 0;\n\n}\n\n\n\n\n\n\nvoid shuffle(Points *points)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  Point temp;\n  for (i=0;i<points->num-1;i++) {\n    j=(lrand48()%(points->num - i)) + i;\n    temp = points->p[i];\n    points->p[i] = points->p[j];\n    points->p[j] = temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n\n\nvoid intshuffle(int *intarray, int length)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  int temp;\n  for (i=0;i<length;i++) {\n    j=(lrand48()%(length - i))+i;\n    temp = intarray[i];\n    intarray[i]=intarray[j];\n    intarray[j]=temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n#ifdef INSERT_WASTE\nfloat waste(float s )\n{\n  for( int i =0 ; i< 4; i++ ) {\n    s += pow(s,0.78);\n  }\n  return s;\n}\n#endif\n\n\n\nfloat dist(Point p1, Point p2, int dim)\n{\n  int i;\n  float result=0.0;\n  for (i=0;i<dim;i++)\n    result += (p1.coord[i] - p2.coord[i])*(p1.coord[i] - p2.coord[i]);\n#ifdef INSERT_WASTE\n  float s = waste(result);\n  result += s;\n  result -= s;\n#endif\n  return(result);\n}\n\n\n\nfloat pspeedy(Points *points, float z, long *kcenter, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  cnt_speedy++;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n  static float totalcost;\n\n  static bool open = false;\n  static float* costs; \n\n  static int i;\n\n#ifdef ENABLE_THREADS\n  static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\n  static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 ){\n    fprintf(stderr, \"Speedy: facility cost %lf\\n\", z);\n  }\n#endif\n\n  \n\n  for( int k = k1; k < k2; k++ )    {\n    float distance = dist(points->p[k],points->p[0],points->dim);\n    points->p[k].cost = distance * points->p[k].weight;\n    points->p[k].assign=0;\n  }\n\n  if( pid==0 )   {\n    *kcenter = 1;\n    costs = (float*)malloc(sizeof(float)*nproc);\n  }\n\n  if( pid != 0 ) { \n\n    while(1) {\n#ifdef ENABLE_THREADS\n      pthread_mutex_lock(&mutex);\n      while(!open) pthread_cond_wait(&cond,&mutex);\n      pthread_mutex_unlock(&mutex);\n#endif\n      if( i >= points->num ) break;\n      for( int k = k1; k < k2; k++ )\n      {\n        float distance = dist(points->p[i],points->p[k],points->dim);\n        if( distance*points->p[k].weight < points->p[k].cost )\n        {\n          points->p[k].cost = distance * points->p[k].weight;\n          points->p[k].assign=i;\n        }\n      }\n#ifdef ENABLE_THREADS\n      pthread_barrier_wait(barrier);\n      pthread_barrier_wait(barrier);\n#endif\n    } \n  }\n  else  { \n\n    for(i = 1; i < points->num; i++ )  {\n      bool to_open = ((float)lrand48()/(float)INT_MAX)<(points->p[i].cost/z); \n\n      if( to_open )  {\n        (*kcenter)++;\n#ifdef ENABLE_THREADS\n        pthread_mutex_lock(&mutex);\n#endif\n        open = true;\n#ifdef ENABLE_THREADS\n        pthread_mutex_unlock(&mutex);\n        pthread_cond_broadcast(&cond);\n#endif\n        for( int k = k1; k < k2; k++ )  {  \n\n          float distance = dist(points->p[i],points->p[k],points->dim);\n          if( distance*points->p[k].weight < points->p[k].cost )  {\n            points->p[k].cost = distance * points->p[k].weight;\n            points->p[k].assign=i;\n          }\n        }\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n        open = false;\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n      }\n    }\n#ifdef ENABLE_THREADS\n    pthread_mutex_lock(&mutex);\n#endif\n    open = true;\n#ifdef ENABLE_THREADS\n    pthread_mutex_unlock(&mutex);\n    pthread_cond_broadcast(&cond);\n#endif\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  open = false;\n  float mytotal = 0;\n  for( int k = k1; k < k2; k++ )  {\n    mytotal += points->p[k].cost;\n  }\n  costs[pid] = mytotal;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  if( pid == 0 )\n  {\n    totalcost=z*(*kcenter);\n    for( int i = 0; i < nproc; i++ )\n    {\n      totalcost += costs[i];\n    } \n    free(costs);\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    fprintf(stderr, \"Speedy opened %d facilities for total cost %lf\\n\",\n        *kcenter, totalcost);\n    fprintf(stderr, \"Distance Cost %lf\\n\", totalcost - z*(*kcenter));\n  }\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  if( pid== 0 ) {\n    time_speedy += t2 -t1;\n  }\n#endif\n  return(totalcost);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfloat pFL(Points *points, int *feasible, int numfeasible,\n    float z, long *k, int kmax, float cost, long iter, float e, \n    int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  long i;\n  long x;\n  float change;\n\n  change = cost;\n  \n\n  \n\n  while (change/cost > 1.0*e) {\n    change = 0.0;\n    \n\n\n    if( pid == 0 ) {\n      intshuffle(feasible, numfeasible);\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n\n    \n\n\n    for (i=0;i<iter;i++) {\n      x = i%numfeasible;\n      \n\n      change += pgain(feasible[x], points, z, k, kmax, is_center, center_table, switch_membership,\n          &serial, &cpu_gpu_memcpy, &memcpy_back, &gpu_malloc, &kernel_time);\n    }    \n    cost -= change;\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      fprintf(stderr, \"%d centers, cost %lf, total distance %lf\\n\",\n          *k, cost, cost - z*(*k));\n    }\n#endif\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_FL += t2 - t1;\n#endif\n  return(cost);\n}\n\nint selectfeasible_fast(Points *points, int **feasible, int kmin, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  int numfeasible = points->num;\n  if (numfeasible > (ITER*kmin*log((float)kmin)))\n    numfeasible = (int)(ITER*kmin*log((float)kmin));\n  *feasible = (int *)malloc(numfeasible*sizeof(int));\n\n  float* accumweight;\n  float totalweight;\n\n  \n\n  \n\n  long k1 = 0;\n  long k2 = numfeasible;\n\n  float w;\n  int l,r,k;\n\n  \n\n  if (numfeasible == points->num) {\n    for (int i=k1;i<k2;i++)\n      (*feasible)[i] = i;\n    return numfeasible;\n  }\n\n  accumweight= (float*)malloc(sizeof(float)*points->num);\n  accumweight[0] = points->p[0].weight;\n  totalweight=0;\n  for( int i = 1; i < points->num; i++ ) {\n    accumweight[i] = accumweight[i-1] + points->p[i].weight;\n  }\n  totalweight=accumweight[points->num-1];\n\n  for(int i=k1; i<k2; i++ ) {\n    w = (lrand48()/(float)INT_MAX)*totalweight;\n    \n\n    l=0;\n    r=points->num-1;\n    if( accumweight[0] > w )  { \n      (*feasible)[i]=0; \n      continue;\n    }\n    while( l+1 < r ) {\n      k = (l+r)/2;\n      if( accumweight[k] > w ) {\n        r = k;\n      } \n      else {\n        l=k;\n      }\n    }\n    (*feasible)[i]=r;\n  }\n  free(accumweight); \n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_select_feasible += t2-t1;\n#endif\n  return numfeasible;\n}\n\n\n\nfloat pkmedian(Points *points, long kmin, long kmax, long* kfinal,\n    int pid, pthread_barrier_t* barrier )\n{\n  int i;\n  float cost;\n  float hiz, loz, z;\n\n  static long k;\n  static int *feasible;\n  static int numfeasible;\n  static float* hizs;\n\n  if( pid==0 ) hizs = (float*)calloc(nproc,sizeof(float));\n  hiz = loz = 0.0;\n  long ptDimension = points->dim;\n\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    printf(\"Starting Kmedian procedure\\n\");\n    printf(\"%i points in %i dimensions\\n\", points->num, ptDimension);\n  }\n#endif\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  float myhiz = 0;\n  for (long kk=k1;kk < k2; kk++ ) {\n    myhiz += dist(points->p[kk], points->p[0],\n        ptDimension)*points->p[kk].weight;\n  }\n  hizs[pid] = myhiz;\n\n#ifdef ENABLE_THREADS  \n  pthread_barrier_wait(barrier);\n#endif\n\n  for( int i = 0; i < nproc; i++ )   {\n    hiz += hizs[i];\n  }\n\n  loz=0.0; z = (hiz+loz)/2.0;\n  \n\n  if (points->num <= kmax) {  \n\n    \n\n    for (long kk=k1;kk<k2;kk++) {\n      points->p[kk].assign = kk;\n      points->p[kk].cost = 0;\n    }\n    cost = 0;\n    if( pid== 0 ) {\n      free(hizs); \n      *kfinal = k;\n    }\n    return cost;\n  }\n\n  if( pid == 0 ) shuffle(points);  \n\n  cost = pspeedy(points, z, &k, pid, barrier);\n#ifdef PRINTINFO\n  if( pid == 0 )\n    printf(\"thread %d: Finished first call to speedy, cost=%lf, k=%i\\n\",pid,cost,k);\n#endif\n  i=0;\n  \n\n  while ((k < kmin)&&(i<SP)) {\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n#ifdef PRINTINFO\n  if( pid==0)\n    printf(\"thread %d: second call to speedy, cost=%lf, k=%d\\n\",pid,cost,k);\n#endif \n  \n\n  while (k < kmin) {\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      printf(\"%lf %lf\\n\", loz, hiz);\n      printf(\"Speedy indicates we should try lower z\\n\");\n    }\n#endif\n    if (i >= SP) {hiz=z; z=(hiz+loz)/2.0; i=0;}\n    if( pid == 0 ) shuffle(points);\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  if( pid == 0 )\n  {\n    numfeasible = selectfeasible_fast(points,&feasible,kmin,pid,barrier); \n\n    for( int i = 0; i< points->num; i++ ) {\n      is_center[points->p[i].assign]= true;\n    }\n  }\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  while(1) {\n#ifdef PRINTINFO\n    if( pid==0 )\n    {\n      printf(\"loz = %lf, hiz = %lf\\n\", loz, hiz);\n      printf(\"Running Local Search...\\n\");\n    }\n#endif\n    \n\n    \n\n    cost = pFL(points, feasible, numfeasible,\n        z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.1, pid, barrier);\n    \n\n    if (((k <= (1.1)*kmax)&&(k >= (0.9)*kmin))||\n        ((k <= kmax+2)&&(k >= kmin-2))) {\n#ifdef PRINTINFO\n      if( pid== 0)\n      {\n        printf(\"Trying a more accurate local search...\\n\");\n      }\n#endif\n      \n\n\n      cost = pFL(points, feasible, numfeasible,\n          z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.001, pid, barrier);\n    }\n\n    if (k > kmax) {\n      \n\n      \n\n      loz = z; z = (hiz+loz)/2.0;\n      cost += (z-loz)*k;\n    }\n    if (k < kmin) {\n      \n\n      \n\n      hiz = z; z = (hiz+loz)/2.0;\n      cost += (z-hiz)*k;\n    }\n\n    \n\n    \n\n    if (((k <= kmax)&&(k >= kmin))||((loz >= (0.999)*hiz)) )\n    { \n      break;\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n\n  \n\n  if( pid==0 ) {\n    free(feasible); \n    free(hizs);\n    *kfinal = k;\n  }\n\n  return cost;\n}\n\n\n\nint contcenters(Points *points)\n{\n  long i, ii;\n  float relweight;\n\n  for (i=0;i<points->num;i++) {\n    \n\n    if (points->p[i].assign != i) {\n      relweight=points->p[points->p[i].assign].weight + points->p[i].weight;\n\n      relweight = points->p[i].weight/relweight;\n      for (ii=0;ii<points->dim;ii++) {\n        points->p[points->p[i].assign].coord[ii]*=1.0-relweight;\n        points->p[points->p[i].assign].coord[ii]+=\n          points->p[i].coord[ii]*relweight;\n      }\n      points->p[points->p[i].assign].weight += points->p[i].weight;\n    }\n  }\n\n  return 0;\n}\n\n\n\nvoid copycenters(Points *points, Points* centers, long* centerIDs, long offset)\n{\n  long i;\n  long k;\n\n  bool *is_a_median = (bool *) calloc(points->num, sizeof(bool));\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    is_a_median[points->p[i].assign] = 1;\n  }\n\n  k=centers->num;\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    if ( is_a_median[i] ) {\n      memcpy( centers->p[k].coord, points->p[i].coord, points->dim * sizeof(float));\n      centers->p[k].weight = points->p[i].weight;\n      centerIDs[k] = i + offset;\n      k++;\n    }\n  }\n\n  centers->num = k;\n  free(is_a_median);\n}\n\n\n\nvoid* localSearchSub(void* arg_) {\n  pkmedian_arg_t* arg= (pkmedian_arg_t*)arg_;\n  pkmedian(arg->points,arg->kmin,arg->kmax,arg->kfinal,arg->pid,arg->barrier);\n\n  return NULL;\n}\n\nvoid localSearch( Points* points, long kmin, long kmax, long* kfinal ) {\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  pthread_barrier_t barrier;\n#ifdef ENABLE_THREADS\n  pthread_barrier_init(&barrier,NULL,nproc);\n#endif\n  pthread_t* threads = new pthread_t[nproc];\n  pkmedian_arg_t* arg = new pkmedian_arg_t[nproc];\n\n\n  for( int i = 0; i < nproc; i++ ) {\n    arg[i].points = points;\n    arg[i].kmin = kmin;\n    arg[i].kmax = kmax;\n    arg[i].pid = i;\n    arg[i].kfinal = kfinal;\n\n    arg[i].barrier = &barrier;\n#ifdef ENABLE_THREADS\n    pthread_create(threads+i,NULL,localSearchSub,(void*)&arg[i]);\n#else\n    localSearchSub(&arg[0]);\n#endif\n  }\n\n  for ( int i = 0; i < nproc; i++) {\n#ifdef ENABLE_THREADS\n    pthread_join(threads[i],NULL);\n#endif\n  }\n\n  delete[] threads;\n  delete[] arg;\n#ifdef ENABLE_THREADS\n  pthread_barrier_destroy(&barrier);\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_local_search += t2-t1;\n#endif\n\n}\n\n\nvoid outcenterIDs( Points* centers, long* centerIDs, char* outfile ) {\n  FILE* fp = fopen(outfile, \"w\");\n  if( fp==NULL ) {\n    fprintf(stderr, \"error opening %s\\n\",outfile);\n    exit(1);\n  }\n  int* is_a_median = (int*)calloc( sizeof(int), centers->num );\n  for( int i =0 ; i< centers->num; i++ ) {\n    is_a_median[centers->p[i].assign] = 1;\n  }\n\n  for( int i = 0; i < centers->num; i++ ) {\n    if( is_a_median[i] ) {\n      fprintf(fp, \"%ld\\n\", centerIDs[i]);\n      fprintf(fp, \"%lf\\n\", centers->p[i].weight);\n      for( int k = 0; k < centers->dim; k++ ) {\n        fprintf(fp, \"%lf \", centers->p[i].coord[k]);\n      }\n      fprintf(fp,\"\\n\\n\");\n    }\n  }\n  fclose(fp);\n}\n\nvoid streamCluster( PStream* stream, long kmin, long kmax, int dim,\n                    long chunksize, long centersize, char* outfile )\n{\n\n  float* block = (float*)malloc( chunksize*dim*sizeof(float) );\n  float* centerBlock = (float*)malloc(centersize*dim*sizeof(float) );\n  long* centerIDs = (long*)malloc(centersize*dim*sizeof(long));\n\n  if( block == NULL ) { \n    fprintf(stderr,\"not enough memory for a chunk!\\n\");\n    exit(1);\n  }\n\n  Points points;\n  points.dim = dim;\n  points.num = chunksize;\n  points.p = (Point *)malloc(chunksize*sizeof(Point));\n  for( int i = 0; i < chunksize; i++ ) {\n    points.p[i].coord = &block[i*dim];    \n  }\n\n\n  Points centers;\n  centers.dim = dim;\n  centers.p = (Point *)malloc(centersize*sizeof(Point));\n  centers.num = 0;\n\n  for( int i = 0; i< centersize; i++ ) {\n    centers.p[i].coord = &centerBlock[i*dim];\n    centers.p[i].weight = 1.0;\n  }\n\n  long IDoffset = 0;\n  long kfinal;\n  while(1) {\n\n    size_t numRead  = stream->read(block, dim, chunksize ); \n    fprintf(stderr,\"read %zu points\\n\",numRead);\n\n    if( stream->ferror() || (numRead < (unsigned int)chunksize && !stream->feof()) ) {\n      fprintf(stderr, \"error reading data!\\n\");\n      exit(1);\n    }\n\n    points.num = numRead;\n    for( int i = 0; i < points.num; i++ ) {\n      points.p[i].weight = 1.0;\n    }\n\n    switch_membership = (char*)malloc(points.num*sizeof(char));\n    is_center = (bool*)calloc(points.num,sizeof(bool));\n    center_table = (int*)malloc(points.num*sizeof(int));\n\n    localSearch(&points,kmin, kmax,&kfinal);\n\n    #pragma omp target exit data map(release: center_table[0:points.num])\n\n    fprintf(stderr,\"finish local search\\n\");\n    contcenters(&points);\n    if( kfinal + centers.num > centersize ) {\n      \n\n      fprintf(stderr,\"oops! no more space for centers\\n\");\n      exit(1);\n    }\n\n#ifdef PRINTINFO\n    printf(\"finish cont center\\n\");\n#endif\n\n    copycenters(&points, &centers, centerIDs, IDoffset);\n    IDoffset += numRead;\n\n#ifdef PRINTINFO\n    printf(\"finish copy centers\\n\"); \n#endif\n    free(is_center);\n    free(switch_membership);\n    free(center_table);\n    if( stream->feof() ) {\n      break;\n    }\n  }\n\n  \n\n  switch_membership = (char*)malloc(centers.num*sizeof(char));\n  is_center = (bool*)calloc(centers.num,sizeof(bool));\n  center_table = (int*)malloc(centers.num*sizeof(int));\n\n  localSearch( &centers, kmin, kmax ,&kfinal );\n  contcenters(&centers);\n  outcenterIDs( &centers, centerIDs, outfile);\n}\n\nint main(int argc, char **argv)\n{\n  char *outfilename = new char[MAXNAMESIZE];\n  char *infilename = new char[MAXNAMESIZE];\n  long kmin, kmax, n, chunksize, clustersize;\n  int dim;\n#ifdef PARSEC_VERSION\n#define __PARSEC_STRING(x) #x\n#define __PARSEC_XSTRING(x) __PARSEC_STRING(x)\n  printf(\"PARSEC Benchmark Suite Version \"__PARSEC_XSTRING(PARSEC_VERSION)\"\\n\");\n  fflush(NULL);\n#else\n  printf(\"PARSEC Benchmark Suite\\n\");\n  fflush(NULL);\n#endif \n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_begin(__parsec_streamcluster);\n#endif\n\n  if (argc<9) {\n    fprintf(stderr,\"usage: %s k1 k2 d n chunksize clustersize infile outfile nproc\\n\",\n        argv[0]);\n    fprintf(stderr,\"  k1:          Min. number of centers allowed\\n\");\n    fprintf(stderr,\"  k2:          Max. number of centers allowed\\n\");\n    fprintf(stderr,\"  d:           Dimension of each data point\\n\");\n    fprintf(stderr,\"  n:           Number of data points\\n\");\n    fprintf(stderr,\"  chunksize:   Number of data points to handle per step\\n\");\n    fprintf(stderr,\"  clustersize: Maximum number of intermediate centers\\n\");\n    fprintf(stderr,\"  infile:      Input file (if n<=0)\\n\");\n    fprintf(stderr,\"  outfile:     Output file\\n\");\n    fprintf(stderr,\"  nproc:       Number of threads to use\\n\");\n    fprintf(stderr,\"\\n\");\n    fprintf(stderr, \"if n > 0, points will be randomly generated instead of reading from infile.\\n\");\n    exit(1);\n  }\n  kmin = atoi(argv[1]);\n  kmax = atoi(argv[2]);\n  dim = atoi(argv[3]);\n  n = atoi(argv[4]);\n  chunksize = atoi(argv[5]);\n  clustersize = atoi(argv[6]);\n  strcpy(infilename, argv[7]);\n  strcpy(outfilename, argv[8]);\n  nproc = atoi(argv[9]);\n\n\n  srand48(SEED);\n  PStream* stream;\n  if( n > 0 ) {\n    stream = new SimStream(n);\n  }\n  else {\n    stream = new FileStream(infilename);\n  }\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_begin();\n#endif\n#ifdef PROFILE_TMP\n  serial = 0.0;\n  cpu_gpu_memcpy = 0.0;\n  gpu_malloc = 0.0;\n  gpu_free = 0.0;\n  kernel_time = 0.0;\n  time_FL = 0.0;\n  cnt_speedy = 0;\n#endif\n  double sc_start = gettime();\n  streamCluster(stream, kmin, kmax, dim, chunksize, clustersize, outfilename );\n  double sc_end = gettime();\n  printf(\"Streamcluster time = %lf (s)\\n\", sc_end-sc_start);\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_end();\n#endif\n\n#ifdef PROFILE_TMP \n  gpu_free = gettime();\n#endif\n\n  \n\n  \n\n  \n\n  \n\n  #pragma omp target exit data map(release: coord_h[0:dim*chunksize],\\\n                                            work_mem_h[0:(kmax+2)*chunksize], \\\n                                            switch_membership[0:chunksize], \\\n                                            p_h[0:chunksize])\n\n  free(coord_h);\n  free(gl_lower);\n  free(work_mem_h);\n  free(p_h);\n\n#ifdef PROFILE_TMP\n  gpu_free = gettime() - gpu_free;\n\n  double t2 = gettime();\n  printf(\"Total time = %lf (s)\\n\",t2-t1);\n#endif\n\n  delete stream;\n\n#ifdef PROFILE_TMP\n  printf(\"==== Detailed timing info ====\\n\");\n  printf(\"pgain = %lf (s)\\n\", time_gain);\n  printf(\"pgain_dist = %lf (s)\\n\", time_gain_dist);\n  printf(\"pgain_init = %lf (s)\\n\", time_gain_init);\n  printf(\"pselect = %lf (s)\\n\", time_select_feasible);\n  printf(\"pspeedy = %lf (s)\\n\", time_speedy);\n  printf(\"pshuffle = %lf (s)\\n\", time_shuffle);\n  printf(\"FL = %lf (s)\\n\", time_FL);\n  printf(\"localSearch = %lf (s)\\n\", time_local_search);\n  printf(\"\\n\");\n  printf(\"serial = %lf (s)\\n\", serial);\n  printf(\"CPU to GPU memory copy = %lf (s)\\n\", cpu_gpu_memcpy);\n  printf(\"GPU to CPU memory copy back = %lf (s)\\n\", memcpy_back);\n  printf(\"GPU malloc = %lf (s)\\n\", gpu_malloc);\n  printf(\"GPU free = %lf (s)\\n\", gpu_free);\n  printf(\"GPU kernels = %lf (s)\\n\", kernel_time);\n#endif\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_end();\n#endif\n\n  return 0;\n}\n"}}
{"kernel_name": "streamcluster", "parallel_api": "serial", "code": {"streamcluster.cpp": "\n\n#include \"streamcluster.h\"\n#include \"streamcluster_cl.h\"\n\nusing namespace std;\n\n#define MAXNAMESIZE 1024   \n\n#define SEED 1\n\n\n\n\n\n\n#define SP 1               \n\n\n\n\n\n\n#define ITER 3             \n\n\n\n\n\n\n\n\n\n\n\n#define CACHE_LINE 512     \n\n\n\n\nstatic char *switch_membership;  \n\nstatic bool *is_center;            \n\nstatic int  *center_table;          \n\nstatic int nproc;                 \n\n\n\n\nstatic double serial;\nstatic double cpu_gpu_memcpy;\nstatic double memcpy_back;\nstatic double gpu_malloc;\nstatic double kernel_time;\nstatic int cnt_speedy;\n\n\n\n#ifdef PROFILE_TMP\nstatic double gpu_free;\ndouble time_local_search;\ndouble time_speedy;\ndouble time_select_feasible;\ndouble time_gain;\ndouble time_shuffle;\ndouble time_gain_dist;\ndouble time_gain_init;\ndouble time_FL;\n#endif \n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nvoid inttofile(int data, char *filename){\n  FILE *fp = fopen(filename, \"w\");\n  fprintf(fp, \"%d \", data);\n  fclose(fp);  \n}\n\nint isIdentical(float *i, float *j, int D){\n  \n\n\n  int a = 0;\n  int equal = 1;\n\n  while (equal && a < D) {\n    if (i[a] != j[a]) equal = 0;\n    else a++;\n  }\n  if (equal) return 1;\n  else return 0;\n\n}\n\n\n\n\n\n\nvoid shuffle(Points *points)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  Point temp;\n  for (i=0;i<points->num-1;i++) {\n    j=(lrand48()%(points->num - i)) + i;\n    temp = points->p[i];\n    points->p[i] = points->p[j];\n    points->p[j] = temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n\n\nvoid intshuffle(int *intarray, int length)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  int temp;\n  for (i=0;i<length;i++) {\n    j=(lrand48()%(length - i))+i;\n    temp = intarray[i];\n    intarray[i]=intarray[j];\n    intarray[j]=temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n#ifdef INSERT_WASTE\nfloat waste(float s )\n{\n  for( int i =0 ; i< 4; i++ ) {\n    s += pow(s,0.78);\n  }\n  return s;\n}\n#endif\n\n\n\nfloat dist(Point p1, Point p2, int dim)\n{\n  int i;\n  float result=0.0;\n  for (i=0;i<dim;i++)\n    result += (p1.coord[i] - p2.coord[i])*(p1.coord[i] - p2.coord[i]);\n#ifdef INSERT_WASTE\n  float s = waste(result);\n  result += s;\n  result -= s;\n#endif\n  return(result);\n}\n\n\n\nfloat pspeedy(Points *points, float z, long *kcenter, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  cnt_speedy++;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n  static float totalcost;\n\n  static bool open = false;\n  static float* costs; \n\n  static int i;\n\n#ifdef ENABLE_THREADS\n  static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\n  static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 ){\n    fprintf(stderr, \"Speedy: facility cost %lf\\n\", z);\n  }\n#endif\n\n  \n\n  for( int k = k1; k < k2; k++ )    {\n    float distance = dist(points->p[k],points->p[0],points->dim);\n    points->p[k].cost = distance * points->p[k].weight;\n    points->p[k].assign=0;\n  }\n\n  if( pid==0 )   {\n    *kcenter = 1;\n    costs = (float*)malloc(sizeof(float)*nproc);\n  }\n\n  if( pid != 0 ) { \n\n    while(1) {\n#ifdef ENABLE_THREADS\n      pthread_mutex_lock(&mutex);\n      while(!open) pthread_cond_wait(&cond,&mutex);\n      pthread_mutex_unlock(&mutex);\n#endif\n      if( i >= points->num ) break;\n      for( int k = k1; k < k2; k++ )\n      {\n        float distance = dist(points->p[i],points->p[k],points->dim);\n        if( distance*points->p[k].weight < points->p[k].cost )\n        {\n          points->p[k].cost = distance * points->p[k].weight;\n          points->p[k].assign=i;\n        }\n      }\n#ifdef ENABLE_THREADS\n      pthread_barrier_wait(barrier);\n      pthread_barrier_wait(barrier);\n#endif\n    } \n  }\n  else  { \n\n    for(i = 1; i < points->num; i++ )  {\n      bool to_open = ((float)lrand48()/(float)INT_MAX)<(points->p[i].cost/z); \n\n      if( to_open )  {\n        (*kcenter)++;\n#ifdef ENABLE_THREADS\n        pthread_mutex_lock(&mutex);\n#endif\n        open = true;\n#ifdef ENABLE_THREADS\n        pthread_mutex_unlock(&mutex);\n        pthread_cond_broadcast(&cond);\n#endif\n        for( int k = k1; k < k2; k++ )  {  \n\n          float distance = dist(points->p[i],points->p[k],points->dim);\n          if( distance*points->p[k].weight < points->p[k].cost )  {\n            points->p[k].cost = distance * points->p[k].weight;\n            points->p[k].assign=i;\n          }\n        }\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n        open = false;\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n      }\n    }\n#ifdef ENABLE_THREADS\n    pthread_mutex_lock(&mutex);\n#endif\n    open = true;\n#ifdef ENABLE_THREADS\n    pthread_mutex_unlock(&mutex);\n    pthread_cond_broadcast(&cond);\n#endif\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  open = false;\n  float mytotal = 0;\n  for( int k = k1; k < k2; k++ )  {\n    mytotal += points->p[k].cost;\n  }\n  costs[pid] = mytotal;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  if( pid == 0 )\n  {\n    totalcost=z*(*kcenter);\n    for( int i = 0; i < nproc; i++ )\n    {\n      totalcost += costs[i];\n    } \n    free(costs);\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    fprintf(stderr, \"Speedy opened %d facilities for total cost %lf\\n\",\n        *kcenter, totalcost);\n    fprintf(stderr, \"Distance Cost %lf\\n\", totalcost - z*(*kcenter));\n  }\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  if( pid== 0 ) {\n    time_speedy += t2 -t1;\n  }\n#endif\n  return(totalcost);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfloat pFL(Points *points, int *feasible, int numfeasible,\n    float z, long *k, int kmax, float cost, long iter, float e, \n    int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  long i;\n  long x;\n  float change;\n\n  change = cost;\n  \n\n  \n\n  while (change/cost > 1.0*e) {\n    change = 0.0;\n    \n\n\n    if( pid == 0 ) {\n      intshuffle(feasible, numfeasible);\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n\n    \n\n\n    for (i=0;i<iter;i++) {\n      x = i%numfeasible;\n      \n\n      change += pgain(feasible[x], points, z, k, kmax, is_center, center_table, switch_membership,\n          &serial, &cpu_gpu_memcpy, &memcpy_back, &gpu_malloc, &kernel_time);\n    }    \n    cost -= change;\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      fprintf(stderr, \"%d centers, cost %lf, total distance %lf\\n\",\n          *k, cost, cost - z*(*k));\n    }\n#endif\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_FL += t2 - t1;\n#endif\n  return(cost);\n}\n\nint selectfeasible_fast(Points *points, int **feasible, int kmin, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  int numfeasible = points->num;\n  if (numfeasible > (ITER*kmin*log((float)kmin)))\n    numfeasible = (int)(ITER*kmin*log((float)kmin));\n  *feasible = (int *)malloc(numfeasible*sizeof(int));\n\n  float* accumweight;\n  float totalweight;\n\n  \n\n  \n\n  long k1 = 0;\n  long k2 = numfeasible;\n\n  float w;\n  int l,r,k;\n\n  \n\n  if (numfeasible == points->num) {\n    for (int i=k1;i<k2;i++)\n      (*feasible)[i] = i;\n    return numfeasible;\n  }\n\n  accumweight= (float*)malloc(sizeof(float)*points->num);\n  accumweight[0] = points->p[0].weight;\n  totalweight=0;\n  for( int i = 1; i < points->num; i++ ) {\n    accumweight[i] = accumweight[i-1] + points->p[i].weight;\n  }\n  totalweight=accumweight[points->num-1];\n\n  for(int i=k1; i<k2; i++ ) {\n    w = (lrand48()/(float)INT_MAX)*totalweight;\n    \n\n    l=0;\n    r=points->num-1;\n    if( accumweight[0] > w )  { \n      (*feasible)[i]=0; \n      continue;\n    }\n    while( l+1 < r ) {\n      k = (l+r)/2;\n      if( accumweight[k] > w ) {\n        r = k;\n      } \n      else {\n        l=k;\n      }\n    }\n    (*feasible)[i]=r;\n  }\n  free(accumweight); \n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_select_feasible += t2-t1;\n#endif\n  return numfeasible;\n}\n\n\n\nfloat pkmedian(Points *points, long kmin, long kmax, long* kfinal,\n    int pid, pthread_barrier_t* barrier )\n{\n  int i;\n  float cost;\n  float hiz, loz, z;\n\n  static long k;\n  static int *feasible;\n  static int numfeasible;\n  static float* hizs;\n\n  if( pid==0 ) hizs = (float*)calloc(nproc,sizeof(float));\n  hiz = loz = 0.0;\n  long ptDimension = points->dim;\n\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    printf(\"Starting Kmedian procedure\\n\");\n    printf(\"%i points in %i dimensions\\n\", points->num, ptDimension);\n  }\n#endif\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  float myhiz = 0;\n  for (long kk=k1;kk < k2; kk++ ) {\n    myhiz += dist(points->p[kk], points->p[0],\n        ptDimension)*points->p[kk].weight;\n  }\n  hizs[pid] = myhiz;\n\n#ifdef ENABLE_THREADS  \n  pthread_barrier_wait(barrier);\n#endif\n\n  for( int i = 0; i < nproc; i++ )   {\n    hiz += hizs[i];\n  }\n\n  loz=0.0; z = (hiz+loz)/2.0;\n  \n\n  if (points->num <= kmax) {  \n\n    \n\n    for (long kk=k1;kk<k2;kk++) {\n      points->p[kk].assign = kk;\n      points->p[kk].cost = 0;\n    }\n    cost = 0;\n    if( pid== 0 ) {\n      free(hizs); \n      *kfinal = k;\n    }\n    return cost;\n  }\n\n  if( pid == 0 ) shuffle(points);  \n\n  cost = pspeedy(points, z, &k, pid, barrier);\n#ifdef PRINTINFO\n  if( pid == 0 )\n    printf(\"thread %d: Finished first call to speedy, cost=%lf, k=%i\\n\",pid,cost,k);\n#endif\n  i=0;\n  \n\n  while ((k < kmin)&&(i<SP)) {\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n#ifdef PRINTINFO\n  if( pid==0)\n    printf(\"thread %d: second call to speedy, cost=%lf, k=%d\\n\",pid,cost,k);\n#endif \n  \n\n  while (k < kmin) {\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      printf(\"%lf %lf\\n\", loz, hiz);\n      printf(\"Speedy indicates we should try lower z\\n\");\n    }\n#endif\n    if (i >= SP) {hiz=z; z=(hiz+loz)/2.0; i=0;}\n    if( pid == 0 ) shuffle(points);\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  if( pid == 0 )\n  {\n    numfeasible = selectfeasible_fast(points,&feasible,kmin,pid,barrier); \n\n    for( int i = 0; i< points->num; i++ ) {\n      is_center[points->p[i].assign]= true;\n    }\n  }\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  while(1) {\n#ifdef PRINTINFO\n    if( pid==0 )\n    {\n      printf(\"loz = %lf, hiz = %lf\\n\", loz, hiz);\n      printf(\"Running Local Search...\\n\");\n    }\n#endif\n    \n\n    \n\n    cost = pFL(points, feasible, numfeasible,\n        z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.1, pid, barrier);\n    \n\n    if (((k <= (1.1)*kmax)&&(k >= (0.9)*kmin))||\n        ((k <= kmax+2)&&(k >= kmin-2))) {\n#ifdef PRINTINFO\n      if( pid== 0)\n      {\n        printf(\"Trying a more accurate local search...\\n\");\n      }\n#endif\n      \n\n\n      cost = pFL(points, feasible, numfeasible,\n          z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.001, pid, barrier);\n    }\n\n    if (k > kmax) {\n      \n\n      \n\n      loz = z; z = (hiz+loz)/2.0;\n      cost += (z-loz)*k;\n    }\n    if (k < kmin) {\n      \n\n      \n\n      hiz = z; z = (hiz+loz)/2.0;\n      cost += (z-hiz)*k;\n    }\n\n    \n\n    \n\n    if (((k <= kmax)&&(k >= kmin))||((loz >= (0.999)*hiz)) )\n    { \n      break;\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n\n  \n\n  if( pid==0 ) {\n    free(feasible); \n    free(hizs);\n    *kfinal = k;\n  }\n\n  return cost;\n}\n\n\n\nint contcenters(Points *points)\n{\n  long i, ii;\n  float relweight;\n\n  for (i=0;i<points->num;i++) {\n    \n\n    if (points->p[i].assign != i) {\n      relweight=points->p[points->p[i].assign].weight + points->p[i].weight;\n\n      relweight = points->p[i].weight/relweight;\n      for (ii=0;ii<points->dim;ii++) {\n        points->p[points->p[i].assign].coord[ii]*=1.0-relweight;\n        points->p[points->p[i].assign].coord[ii]+=\n          points->p[i].coord[ii]*relweight;\n      }\n      points->p[points->p[i].assign].weight += points->p[i].weight;\n    }\n  }\n\n  return 0;\n}\n\n\n\nvoid copycenters(Points *points, Points* centers, long* centerIDs, long offset)\n{\n  long i;\n  long k;\n\n  bool *is_a_median = (bool *) calloc(points->num, sizeof(bool));\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    is_a_median[points->p[i].assign] = 1;\n  }\n\n  k=centers->num;\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    if ( is_a_median[i] ) {\n      memcpy( centers->p[k].coord, points->p[i].coord, points->dim * sizeof(float));\n      centers->p[k].weight = points->p[i].weight;\n      centerIDs[k] = i + offset;\n      k++;\n    }\n  }\n\n  centers->num = k;\n  free(is_a_median);\n}\n\n\n\nvoid* localSearchSub(void* arg_) {\n  pkmedian_arg_t* arg= (pkmedian_arg_t*)arg_;\n  pkmedian(arg->points,arg->kmin,arg->kmax,arg->kfinal,arg->pid,arg->barrier);\n\n  return NULL;\n}\n\nvoid localSearch( Points* points, long kmin, long kmax, long* kfinal ) {\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  pthread_barrier_t barrier;\n#ifdef ENABLE_THREADS\n  pthread_barrier_init(&barrier,NULL,nproc);\n#endif\n  pthread_t* threads = new pthread_t[nproc];\n  pkmedian_arg_t* arg = new pkmedian_arg_t[nproc];\n\n\n  for( int i = 0; i < nproc; i++ ) {\n    arg[i].points = points;\n    arg[i].kmin = kmin;\n    arg[i].kmax = kmax;\n    arg[i].pid = i;\n    arg[i].kfinal = kfinal;\n\n    arg[i].barrier = &barrier;\n#ifdef ENABLE_THREADS\n    pthread_create(threads+i,NULL,localSearchSub,(void*)&arg[i]);\n#else\n    localSearchSub(&arg[0]);\n#endif\n  }\n\n  for ( int i = 0; i < nproc; i++) {\n#ifdef ENABLE_THREADS\n    pthread_join(threads[i],NULL);\n#endif\n  }\n\n  delete[] threads;\n  delete[] arg;\n#ifdef ENABLE_THREADS\n  pthread_barrier_destroy(&barrier);\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_local_search += t2-t1;\n#endif\n\n}\n\n\nvoid outcenterIDs( Points* centers, long* centerIDs, char* outfile ) {\n  FILE* fp = fopen(outfile, \"w\");\n  if( fp==NULL ) {\n    fprintf(stderr, \"error opening %s\\n\",outfile);\n    exit(1);\n  }\n  int* is_a_median = (int*)calloc( sizeof(int), centers->num );\n  for( int i =0 ; i< centers->num; i++ ) {\n    is_a_median[centers->p[i].assign] = 1;\n  }\n\n  for( int i = 0; i < centers->num; i++ ) {\n    if( is_a_median[i] ) {\n      fprintf(fp, \"%ld\\n\", centerIDs[i]);\n      fprintf(fp, \"%lf\\n\", centers->p[i].weight);\n      for( int k = 0; k < centers->dim; k++ ) {\n        fprintf(fp, \"%lf \", centers->p[i].coord[k]);\n      }\n      fprintf(fp,\"\\n\\n\");\n    }\n  }\n  fclose(fp);\n}\n\nvoid streamCluster( PStream* stream, long kmin, long kmax, int dim,\n                    long chunksize, long centersize, char* outfile )\n{\n\n  float* block = (float*)malloc( chunksize*dim*sizeof(float) );\n  float* centerBlock = (float*)malloc(centersize*dim*sizeof(float) );\n  long* centerIDs = (long*)malloc(centersize*dim*sizeof(long));\n\n  if( block == NULL ) { \n    fprintf(stderr,\"not enough memory for a chunk!\\n\");\n    exit(1);\n  }\n\n  Points points;\n  points.dim = dim;\n  points.num = chunksize;\n  points.p = (Point *)malloc(chunksize*sizeof(Point));\n  for( int i = 0; i < chunksize; i++ ) {\n    points.p[i].coord = &block[i*dim];    \n  }\n\n\n  Points centers;\n  centers.dim = dim;\n  centers.p = (Point *)malloc(centersize*sizeof(Point));\n  centers.num = 0;\n\n  for( int i = 0; i< centersize; i++ ) {\n    centers.p[i].coord = &centerBlock[i*dim];\n    centers.p[i].weight = 1.0;\n  }\n\n  long IDoffset = 0;\n  long kfinal;\n  while(1) {\n\n    size_t numRead  = stream->read(block, dim, chunksize ); \n    fprintf(stderr,\"read %zu points\\n\",numRead);\n\n    if( stream->ferror() || (numRead < (unsigned int)chunksize && !stream->feof()) ) {\n      fprintf(stderr, \"error reading data!\\n\");\n      exit(1);\n    }\n\n    points.num = numRead;\n    for( int i = 0; i < points.num; i++ ) {\n      points.p[i].weight = 1.0;\n    }\n\n    switch_membership = (char*)malloc(points.num*sizeof(char));\n    is_center = (bool*)calloc(points.num,sizeof(bool));\n    center_table = (int*)malloc(points.num*sizeof(int));\n\n    localSearch(&points,kmin, kmax,&kfinal);\n\n    \n    fprintf(stderr,\"finish local search\\n\");\n    contcenters(&points);\n    if( kfinal + centers.num > centersize ) {\n      \n\n      fprintf(stderr,\"oops! no more space for centers\\n\");\n      exit(1);\n    }\n\n#ifdef PRINTINFO\n    printf(\"finish cont center\\n\");\n#endif\n\n    copycenters(&points, &centers, centerIDs, IDoffset);\n    IDoffset += numRead;\n\n#ifdef PRINTINFO\n    printf(\"finish copy centers\\n\"); \n#endif\n    free(is_center);\n    free(switch_membership);\n    free(center_table);\n    if( stream->feof() ) {\n      break;\n    }\n  }\n\n  \n\n  switch_membership = (char*)malloc(centers.num*sizeof(char));\n  is_center = (bool*)calloc(centers.num,sizeof(bool));\n  center_table = (int*)malloc(centers.num*sizeof(int));\n\n  localSearch( &centers, kmin, kmax ,&kfinal );\n  contcenters(&centers);\n  outcenterIDs( &centers, centerIDs, outfile);\n}\n\nint main(int argc, char **argv)\n{\n  char *outfilename = new char[MAXNAMESIZE];\n  char *infilename = new char[MAXNAMESIZE];\n  long kmin, kmax, n, chunksize, clustersize;\n  int dim;\n#ifdef PARSEC_VERSION\n#define __PARSEC_STRING(x) #x\n#define __PARSEC_XSTRING(x) __PARSEC_STRING(x)\n  printf(\"PARSEC Benchmark Suite Version \"__PARSEC_XSTRING(PARSEC_VERSION)\"\\n\");\n  fflush(NULL);\n#else\n  printf(\"PARSEC Benchmark Suite\\n\");\n  fflush(NULL);\n#endif \n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_begin(__parsec_streamcluster);\n#endif\n\n  if (argc<9) {\n    fprintf(stderr,\"usage: %s k1 k2 d n chunksize clustersize infile outfile nproc\\n\",\n        argv[0]);\n    fprintf(stderr,\"  k1:          Min. number of centers allowed\\n\");\n    fprintf(stderr,\"  k2:          Max. number of centers allowed\\n\");\n    fprintf(stderr,\"  d:           Dimension of each data point\\n\");\n    fprintf(stderr,\"  n:           Number of data points\\n\");\n    fprintf(stderr,\"  chunksize:   Number of data points to handle per step\\n\");\n    fprintf(stderr,\"  clustersize: Maximum number of intermediate centers\\n\");\n    fprintf(stderr,\"  infile:      Input file (if n<=0)\\n\");\n    fprintf(stderr,\"  outfile:     Output file\\n\");\n    fprintf(stderr,\"  nproc:       Number of threads to use\\n\");\n    fprintf(stderr,\"\\n\");\n    fprintf(stderr, \"if n > 0, points will be randomly generated instead of reading from infile.\\n\");\n    exit(1);\n  }\n  kmin = atoi(argv[1]);\n  kmax = atoi(argv[2]);\n  dim = atoi(argv[3]);\n  n = atoi(argv[4]);\n  chunksize = atoi(argv[5]);\n  clustersize = atoi(argv[6]);\n  strcpy(infilename, argv[7]);\n  strcpy(outfilename, argv[8]);\n  nproc = atoi(argv[9]);\n\n\n  srand48(SEED);\n  PStream* stream;\n  if( n > 0 ) {\n    stream = new SimStream(n);\n  }\n  else {\n    stream = new FileStream(infilename);\n  }\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_begin();\n#endif\n#ifdef PROFILE_TMP\n  serial = 0.0;\n  cpu_gpu_memcpy = 0.0;\n  gpu_malloc = 0.0;\n  gpu_free = 0.0;\n  kernel_time = 0.0;\n  time_FL = 0.0;\n  cnt_speedy = 0;\n#endif\n  double sc_start = gettime();\n  streamCluster(stream, kmin, kmax, dim, chunksize, clustersize, outfilename );\n  double sc_end = gettime();\n  printf(\"Streamcluster time = %lf (s)\\n\", sc_end-sc_start);\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_end();\n#endif\n\n#ifdef PROFILE_TMP \n  gpu_free = gettime();\n#endif\n\n  \n\n  \n\n  \n\n  \n\n  \n  free(coord_h);\n  free(gl_lower);\n  free(work_mem_h);\n  free(p_h);\n\n#ifdef PROFILE_TMP\n  gpu_free = gettime() - gpu_free;\n\n  double t2 = gettime();\n  printf(\"Total time = %lf (s)\\n\",t2-t1);\n#endif\n\n  delete stream;\n\n#ifdef PROFILE_TMP\n  printf(\"==== Detailed timing info ====\\n\");\n  printf(\"pgain = %lf (s)\\n\", time_gain);\n  printf(\"pgain_dist = %lf (s)\\n\", time_gain_dist);\n  printf(\"pgain_init = %lf (s)\\n\", time_gain_init);\n  printf(\"pselect = %lf (s)\\n\", time_select_feasible);\n  printf(\"pspeedy = %lf (s)\\n\", time_speedy);\n  printf(\"pshuffle = %lf (s)\\n\", time_shuffle);\n  printf(\"FL = %lf (s)\\n\", time_FL);\n  printf(\"localSearch = %lf (s)\\n\", time_local_search);\n  printf(\"\\n\");\n  printf(\"serial = %lf (s)\\n\", serial);\n  printf(\"CPU to GPU memory copy = %lf (s)\\n\", cpu_gpu_memcpy);\n  printf(\"GPU to CPU memory copy back = %lf (s)\\n\", memcpy_back);\n  printf(\"GPU malloc = %lf (s)\\n\", gpu_malloc);\n  printf(\"GPU free = %lf (s)\\n\", gpu_free);\n  printf(\"GPU kernels = %lf (s)\\n\", kernel_time);\n#endif\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_end();\n#endif\n\n  return 0;\n}"}}
{"kernel_name": "streamcluster", "parallel_api": "sycl", "code": {"streamcluster.cpp": "\n\n\n#include <sycl/sycl.hpp>\n#include \"streamcluster.h\"\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n#include \"streamcluster_cl.h\"\n\nusing namespace std;\n\n#define MAXNAMESIZE 1024   \n\n#define SEED 1\n\n\n\n\n\n\n#define SP 1               \n\n\n\n\n\n\n#define ITER 3             \n\n\n\n\n\n\n\n\n\n\n\n#define CACHE_LINE 512     \n\n\n\n\nstatic char *switch_membership;  \n\nstatic bool *is_center;            \n\nstatic int  *center_table;          \n\nstatic int nproc;                 \n\n\n\n\nstatic double serial;\nstatic double cpu_gpu_memcpy;\nstatic double memcpy_back;\nstatic double gpu_malloc;\nstatic double kernel_time;\nstatic int cnt_speedy;\n\n\n\n#ifdef PROFILE_TMP\nstatic double gpu_free;\ndouble time_local_search;\ndouble time_speedy;\ndouble time_select_feasible;\ndouble time_gain;\ndouble time_shuffle;\ndouble time_gain_dist;\ndouble time_gain_init;\ndouble time_FL;\n#endif\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nvoid inttofile(int data, char *filename){\n  FILE *fp = fopen(filename, \"w\");\n  fprintf(fp, \"%d \", data);\n  fclose(fp);\n}\n\nint isIdentical(float *i, float *j, int D){\n  \n\n\n  int a = 0;\n  int equal = 1;\n\n  while (equal && a < D) {\n    if (i[a] != j[a]) equal = 0;\n    else a++;\n  }\n  if (equal) return 1;\n  else return 0;\n\n}\n\n\n\n\n\n\nvoid shuffle(Points *points)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  Point temp;\n  for (i=0;i<points->num-1;i++) {\n    j=(lrand48()%(points->num - i)) + i;\n    temp = points->p[i];\n    points->p[i] = points->p[j];\n    points->p[j] = temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n\n\nvoid intshuffle(int *intarray, int length)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  int temp;\n  for (i=0;i<length;i++) {\n    j=(lrand48()%(length - i))+i;\n    temp = intarray[i];\n    intarray[i]=intarray[j];\n    intarray[j]=temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n#ifdef INSERT_WASTE\nfloat waste(float s )\n{\n  for( int i =0 ; i< 4; i++ ) {\n    s += pow(s,0.78);\n  }\n  return s;\n}\n#endif\n\n\n\nfloat dist(Point p1, Point p2, int dim)\n{\n  int i;\n  float result=0.0;\n  for (i=0;i<dim;i++)\n    result += (p1.coord[i] - p2.coord[i])*(p1.coord[i] - p2.coord[i]);\n#ifdef INSERT_WASTE\n  float s = waste(result);\n  result += s;\n  result -= s;\n#endif\n  return(result);\n}\n\n\n\nfloat pspeedy(Points *points, float z, long *kcenter, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  cnt_speedy++;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n  static float totalcost;\n\n  static bool open = false;\n  static float* costs; \n\n  static int i;\n\n#ifdef ENABLE_THREADS\n  static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\n  static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 ){\n    fprintf(stderr, \"Speedy: facility cost %lf\\n\", z);\n  }\n#endif\n\n  \n\n  for( int k = k1; k < k2; k++ )    {\n    float distance = dist(points->p[k],points->p[0],points->dim);\n    points->p[k].cost = distance * points->p[k].weight;\n    points->p[k].assign=0;\n  }\n\n  if( pid==0 )   {\n    *kcenter = 1;\n    costs = (float*)malloc(sizeof(float)*nproc);\n  }\n\n  if( pid != 0 ) { \n\n    while(1) {\n#ifdef ENABLE_THREADS\n      pthread_mutex_lock(&mutex);\n      while(!open) pthread_cond_wait(&cond,&mutex);\n      pthread_mutex_unlock(&mutex);\n#endif\n      if( i >= points->num ) break;\n      for( int k = k1; k < k2; k++ )\n      {\n        float distance = dist(points->p[i],points->p[k],points->dim);\n        if( distance*points->p[k].weight < points->p[k].cost )\n        {\n          points->p[k].cost = distance * points->p[k].weight;\n          points->p[k].assign=i;\n        }\n      }\n#ifdef ENABLE_THREADS\n      pthread_barrier_wait(barrier);\n      pthread_barrier_wait(barrier);\n#endif\n    }\n  }\n  else  { \n\n    for(i = 1; i < points->num; i++ )  {\n      bool to_open = ((float)lrand48()/(float)INT_MAX)<(points->p[i].cost/z); \n\n      if( to_open )  {\n        (*kcenter)++;\n#ifdef ENABLE_THREADS\n        pthread_mutex_lock(&mutex);\n#endif\n        open = true;\n#ifdef ENABLE_THREADS\n        pthread_mutex_unlock(&mutex);\n        pthread_cond_broadcast(&cond);\n#endif\n        for( int k = k1; k < k2; k++ )  {  \n\n          float distance = dist(points->p[i],points->p[k],points->dim);\n          if( distance*points->p[k].weight < points->p[k].cost )  {\n            points->p[k].cost = distance * points->p[k].weight;\n            points->p[k].assign=i;\n          }\n        }\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n        open = false;\n#ifdef ENABLE_THREADS\n        pthread_barrier_wait(barrier);\n#endif\n      }\n    }\n#ifdef ENABLE_THREADS\n    pthread_mutex_lock(&mutex);\n#endif\n    open = true;\n#ifdef ENABLE_THREADS\n    pthread_mutex_unlock(&mutex);\n    pthread_cond_broadcast(&cond);\n#endif\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  open = false;\n  float mytotal = 0;\n  for( int k = k1; k < k2; k++ )  {\n    mytotal += points->p[k].cost;\n  }\n  costs[pid] = mytotal;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  \n\n  if( pid == 0 )\n  {\n    totalcost=z*(*kcenter);\n    for( int i = 0; i < nproc; i++ )\n    {\n      totalcost += costs[i];\n    }\n    free(costs);\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    fprintf(stderr, \"Speedy opened %d facilities for total cost %lf\\n\",\n        *kcenter, totalcost);\n    fprintf(stderr, \"Distance Cost %lf\\n\", totalcost - z*(*kcenter));\n  }\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  if( pid== 0 ) {\n    time_speedy += t2 -t1;\n  }\n#endif\n  return(totalcost);\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfloat pFL(Points *points, int *feasible, int numfeasible,\n    float z, long *k, int kmax, float cost, long iter, float e,\n    int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  long i;\n  long x;\n  float change;\n\n  change = cost;\n  \n\n  \n\n  while (change/cost > 1.0*e) {\n    change = 0.0;\n    \n\n\n    if( pid == 0 ) {\n      intshuffle(feasible, numfeasible);\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n\n    \n\n\n    for (i=0;i<iter;i++) {\n      x = i%numfeasible;\n      change += pgain(feasible[x], points, z, k, kmax, is_center, center_table, switch_membership,\n          &serial, &cpu_gpu_memcpy, &memcpy_back, &gpu_malloc, &kernel_time);\n    }\n    cost -= change;\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      fprintf(stderr, \"%d centers, cost %lf, total distance %lf\\n\",\n          *k, cost, cost - z*(*k));\n    }\n#endif\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_FL += t2 - t1;\n#endif\n  return(cost);\n}\n\nint selectfeasible_fast(Points *points, int **feasible, int kmin, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  int numfeasible = points->num;\n  if (numfeasible > (ITER*kmin*log((float)kmin)))\n    numfeasible = (int)(ITER*kmin*log((float)kmin));\n  *feasible = (int *)malloc(numfeasible*sizeof(int));\n\n  float* accumweight;\n  float totalweight;\n\n  \n\n  \n\n  long k1 = 0;\n  long k2 = numfeasible;\n\n  float w;\n  int l,r,k;\n\n  \n\n  if (numfeasible == points->num) {\n    for (int i=k1;i<k2;i++)\n      (*feasible)[i] = i;\n    return numfeasible;\n  }\n\n  accumweight= (float*)malloc(sizeof(float)*points->num);\n  accumweight[0] = points->p[0].weight;\n  totalweight=0;\n  for( int i = 1; i < points->num; i++ ) {\n    accumweight[i] = accumweight[i-1] + points->p[i].weight;\n  }\n  totalweight=accumweight[points->num-1];\n\n  for(int i=k1; i<k2; i++ ) {\n    w = (lrand48()/(float)INT_MAX)*totalweight;\n    \n\n    l=0;\n    r=points->num-1;\n    if( accumweight[0] > w )  {\n      (*feasible)[i]=0;\n      continue;\n    }\n    while( l+1 < r ) {\n      k = (l+r)/2;\n      if( accumweight[k] > w ) {\n        r = k;\n      }\n      else {\n        l=k;\n      }\n    }\n    (*feasible)[i]=r;\n  }\n  free(accumweight);\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_select_feasible += t2-t1;\n#endif\n  return numfeasible;\n}\n\n\n\nfloat pkmedian(Points *points, long kmin, long kmax, long* kfinal,\n    int pid, pthread_barrier_t* barrier )\n{\n  int i;\n  float cost;\n  float hiz, loz, z;\n\n  static long k;\n  static int *feasible;\n  static int numfeasible;\n  static float* hizs;\n\n  if( pid==0 ) hizs = (float*)calloc(nproc,sizeof(float));\n  hiz = loz = 0.0;\n  long ptDimension = points->dim;\n\n  \n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n  {\n    printf(\"Starting Kmedian procedure\\n\");\n    printf(\"%i points in %i dimensions\\n\", points->num, ptDimension);\n  }\n#endif\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  float myhiz = 0;\n  for (long kk=k1;kk < k2; kk++ ) {\n    myhiz += dist(points->p[kk], points->p[0],\n        ptDimension)*points->p[kk].weight;\n  }\n  hizs[pid] = myhiz;\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  for( int i = 0; i < nproc; i++ )   {\n    hiz += hizs[i];\n  }\n\n  loz=0.0; z = (hiz+loz)/2.0;\n  \n\n  if (points->num <= kmax) {  \n\n    \n\n    for (long kk=k1;kk<k2;kk++) {\n      points->p[kk].assign = kk;\n      points->p[kk].cost = 0;\n    }\n    cost = 0;\n    if( pid== 0 ) {\n      free(hizs);\n      *kfinal = k;\n    }\n    return cost;\n  }\n\n  if( pid == 0 ) shuffle(points);  \n\n  cost = pspeedy(points, z, &k, pid, barrier);\n#ifdef PRINTINFO\n  if( pid == 0 )\n    printf(\"thread %d: Finished first call to speedy, cost=%lf, k=%i\\n\",pid,cost,k);\n#endif\n  i=0;\n  \n\n  while ((k < kmin)&&(i<SP)) {\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n#ifdef PRINTINFO\n  if( pid==0)\n    printf(\"thread %d: second call to speedy, cost=%lf, k=%d\\n\",pid,cost,k);\n#endif\n  \n\n  while (k < kmin) {\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      printf(\"%lf %lf\\n\", loz, hiz);\n      printf(\"Speedy indicates we should try lower z\\n\");\n    }\n#endif\n    if (i >= SP) {hiz=z; z=(hiz+loz)/2.0; i=0;}\n    if( pid == 0 ) shuffle(points);\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  if( pid == 0 )\n  {\n    numfeasible = selectfeasible_fast(points,&feasible,kmin,pid,barrier); \n\n    for( int i = 0; i< points->num; i++ ) {\n      is_center[points->p[i].assign]= true;\n    }\n  }\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  while(1) {\n#ifdef PRINTINFO\n    if( pid==0 )\n    {\n      printf(\"loz = %lf, hiz = %lf\\n\", loz, hiz);\n      printf(\"Running Local Search...\\n\");\n    }\n#endif\n    \n\n    \n\n    cost = pFL(points, feasible, numfeasible,\n        z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.1, pid, barrier);\n    \n\n    if (((k <= (1.1)*kmax)&&(k >= (0.9)*kmin))||\n        ((k <= kmax+2)&&(k >= kmin-2))) {\n#ifdef PRINTINFO\n      if( pid== 0)\n      {\n        printf(\"Trying a more accurate local search...\\n\");\n      }\n#endif\n      \n\n\n      cost = pFL(points, feasible, numfeasible,\n          z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.001, pid, barrier);\n    }\n\n    if (k > kmax) {\n      \n\n      \n\n      loz = z; z = (hiz+loz)/2.0;\n      cost += (z-loz)*k;\n    }\n    if (k < kmin) {\n      \n\n      \n\n      hiz = z; z = (hiz+loz)/2.0;\n      cost += (z-hiz)*k;\n    }\n\n    \n\n    \n\n    if (((k <= kmax)&&(k >= kmin))||((loz >= (0.999)*hiz)) )\n    {\n      break;\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n\n  \n\n  if( pid==0 ) {\n    free(feasible);\n    free(hizs);\n    *kfinal = k;\n  }\n\n  return cost;\n}\n\n\n\nint contcenters(Points *points)\n{\n  long i, ii;\n  float relweight;\n\n  for (i=0;i<points->num;i++) {\n    \n\n    if (points->p[i].assign != i) {\n      relweight=points->p[points->p[i].assign].weight + points->p[i].weight;\n\n      relweight = points->p[i].weight/relweight;\n      for (ii=0;ii<points->dim;ii++) {\n        points->p[points->p[i].assign].coord[ii]*=1.0-relweight;\n        points->p[points->p[i].assign].coord[ii]+=\n          points->p[i].coord[ii]*relweight;\n      }\n      points->p[points->p[i].assign].weight += points->p[i].weight;\n    }\n  }\n\n  return 0;\n}\n\n\n\nvoid copycenters(Points *points, Points* centers, long* centerIDs, long offset)\n{\n  long i;\n  long k;\n\n  bool *is_a_median = (bool *) calloc(points->num, sizeof(bool));\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    is_a_median[points->p[i].assign] = 1;\n  }\n\n  k=centers->num;\n\n  \n\n  for ( i = 0; i < points->num; i++ ) {\n    if ( is_a_median[i] ) {\n      memcpy( centers->p[k].coord, points->p[i].coord, points->dim * sizeof(float));\n      centers->p[k].weight = points->p[i].weight;\n      centerIDs[k] = i + offset;\n      k++;\n    }\n  }\n\n  centers->num = k;\n  free(is_a_median);\n}\n\nvoid* localSearchSub(void* arg_) {\n  pkmedian_arg_t* arg= (pkmedian_arg_t*)arg_;\n  pkmedian(arg->points,arg->kmin,arg->kmax,arg->kfinal,arg->pid,arg->barrier);\n\n  return NULL;\n}\n\nvoid localSearch( Points* points, long kmin, long kmax, long* kfinal ) {\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  pthread_barrier_t barrier;\n#ifdef ENABLE_THREADS\n  pthread_barrier_init(&barrier,NULL,nproc);\n#endif\n  pthread_t* threads = new pthread_t[nproc];\n  pkmedian_arg_t* arg = new pkmedian_arg_t[nproc];\n\n  for( int i = 0; i < nproc; i++ ) {\n    arg[i].points = points;\n    arg[i].kmin = kmin;\n    arg[i].kmax = kmax;\n    arg[i].pid = i;\n    arg[i].kfinal = kfinal;\n\n    arg[i].barrier = &barrier;\n#ifdef ENABLE_THREADS\n    pthread_create(threads+i,NULL,localSearchSub,(void*)&arg[i]);\n#else\n    localSearchSub(&arg[0]);\n#endif\n  }\n\n  for ( int i = 0; i < nproc; i++) {\n#ifdef ENABLE_THREADS\n    pthread_join(threads[i],NULL);\n#endif\n  }\n\n  delete[] threads;\n  delete[] arg;\n#ifdef ENABLE_THREADS\n  pthread_barrier_destroy(&barrier);\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_local_search += t2-t1;\n#endif\n\n}\n\n\nvoid outcenterIDs( Points* centers, long* centerIDs, char* outfile ) {\n  FILE* fp = fopen(outfile, \"w\");\n  if( fp==NULL ) {\n    fprintf(stderr, \"error opening %s\\n\",outfile);\n    exit(1);\n  }\n  int* is_a_median = (int*)calloc( sizeof(int), centers->num );\n  for( int i =0 ; i< centers->num; i++ ) {\n    is_a_median[centers->p[i].assign] = 1;\n  }\n\n  for( int i = 0; i < centers->num; i++ ) {\n    if( is_a_median[i] ) {\n      fprintf(fp, \"%ld\\n\", centerIDs[i]);\n      fprintf(fp, \"%lf\\n\", centers->p[i].weight);\n      for( int k = 0; k < centers->dim; k++ ) {\n        fprintf(fp, \"%lf \", centers->p[i].coord[k]);\n      }\n      fprintf(fp,\"\\n\\n\");\n    }\n  }\n  fclose(fp);\n}\n\nvoid streamCluster( PStream* stream,\n    long kmin, long kmax, int dim,\n    long chunksize, long centersize, char* outfile )\n{\n\n  float* block = (float*)malloc( chunksize*dim*sizeof(float) );\n  float* centerBlock = (float*)malloc(centersize*dim*sizeof(float) );\n  long* centerIDs = (long*)malloc(centersize*dim*sizeof(long));\n\n  if( block == NULL ) {\n    fprintf(stderr,\"not enough memory for a chunk!\\n\");\n    exit(1);\n  }\n\n  Points points;\n  points.dim = dim;\n  points.num = chunksize;\n  points.p = (Point *)malloc(chunksize*sizeof(Point));\n  for( int i = 0; i < chunksize; i++ ) {\n    points.p[i].coord = &block[i*dim];\n  }\n\n  Points centers;\n  centers.dim = dim;\n  centers.p = (Point *)malloc(centersize*sizeof(Point));\n  centers.num = 0;\n\n  for( int i = 0; i< centersize; i++ ) {\n    centers.p[i].coord = &centerBlock[i*dim];\n    centers.p[i].weight = 1.0;\n  }\n\n  long IDoffset = 0;\n  long kfinal;\n  while(1) {\n\n    size_t numRead  = stream->read(block, dim, chunksize );\n    fprintf(stderr,\"read %zu points\\n\",numRead);\n\n    if( stream->ferror() || (numRead < (unsigned int)chunksize && !stream->feof()) ) {\n      fprintf(stderr, \"error reading data!\\n\");\n      exit(1);\n    }\n\n    points.num = numRead;\n    for( int i = 0; i < points.num; i++ ) {\n      points.p[i].weight = 1.0;\n    }\n\n    switch_membership = (char*)malloc(points.num*sizeof(char));\n    is_center = (bool*)calloc(points.num,sizeof(bool));\n    center_table = (int*)malloc(points.num*sizeof(int));\n\n    localSearch(&points,kmin, kmax,&kfinal);\n\n    fprintf(stderr,\"finish local search\\n\");\n    contcenters(&points);\n    if( kfinal + centers.num > centersize ) {\n      \n\n      fprintf(stderr,\"oops! no more space for centers\\n\");\n      exit(1);\n    }\n\n#ifdef PRINTINFO\n    printf(\"finish cont center\\n\");\n#endif\n\n    copycenters(&points, &centers, centerIDs, IDoffset);\n    IDoffset += numRead;\n\n#ifdef PRINTINFO\n    printf(\"finish copy centers\\n\");\n#endif\n    free(is_center);\n    free(switch_membership);\n    free(center_table);\n    if( stream->feof() ) {\n      break;\n    }\n  }\n\n  \n\n  switch_membership = (char*)malloc(centers.num*sizeof(char));\n  is_center = (bool*)calloc(centers.num,sizeof(bool));\n  center_table = (int*)malloc(centers.num*sizeof(int));\n\n  localSearch( &centers, kmin, kmax ,&kfinal );\n  contcenters(&centers);\n  outcenterIDs( &centers, centerIDs, outfile);\n}\n\nint main(int argc, char **argv)\n{\n  char *outfilename = new char[MAXNAMESIZE];\n  char *infilename = new char[MAXNAMESIZE];\n  long kmin, kmax, n, chunksize, clustersize;\n  int dim;\n#ifdef PARSEC_VERSION\n#define __PARSEC_STRING(x) #x\n#define __PARSEC_XSTRING(x) __PARSEC_STRING(x)\n  printf(\"PARSEC Benchmark Suite Version \"__PARSEC_XSTRING(PARSEC_VERSION)\"\\n\");\n  fflush(NULL);\n#else\n  printf(\"PARSEC Benchmark Suite\\n\");\n  fflush(NULL);\n#endif \n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_begin(__parsec_streamcluster);\n#endif\n\n  if (argc<9) {\n    fprintf(stderr,\"usage: %s k1 k2 d n chunksize clustersize infile outfile nproc\\n\",\n        argv[0]);\n    fprintf(stderr,\"  k1:          Min. number of centers allowed\\n\");\n    fprintf(stderr,\"  k2:          Max. number of centers allowed\\n\");\n    fprintf(stderr,\"  d:           Dimension of each data point\\n\");\n    fprintf(stderr,\"  n:           Number of data points\\n\");\n    fprintf(stderr,\"  chunksize:   Number of data points to handle per step\\n\");\n    fprintf(stderr,\"  clustersize: Maximum number of intermediate centers\\n\");\n    fprintf(stderr,\"  infile:      Input file (if n<=0)\\n\");\n    fprintf(stderr,\"  outfile:     Output file\\n\");\n    fprintf(stderr,\"  nproc:       Number of threads to use\\n\");\n    fprintf(stderr,\"\\n\");\n    fprintf(stderr, \"if n > 0, points will be randomly generated instead of reading from infile.\\n\");\n    exit(1);\n  }\n  kmin = atoi(argv[1]);\n  kmax = atoi(argv[2]);\n  dim = atoi(argv[3]);\n  n = atoi(argv[4]);\n  chunksize = atoi(argv[5]);\n  clustersize = atoi(argv[6]);\n  strcpy(infilename, argv[7]);\n  strcpy(outfilename, argv[8]);\n  nproc = atoi(argv[9]);\n\n  srand48(SEED);\n  PStream* stream;\n  if( n > 0 ) {\n    stream = new SimStream(n);\n  }\n  else {\n    stream = new FileStream(infilename);\n  }\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_begin();\n#endif\n#ifdef PROFILE_TMP\n  serial = 0.0;\n  cpu_gpu_memcpy = 0.0;\n  gpu_malloc = 0.0;\n  gpu_free = 0.0;\n  kernel_time = 0.0;\n  time_FL = 0.0;\n  cnt_speedy = 0;\n#endif\n\n  double sc_start = gettime();\n  streamCluster(stream, kmin, kmax, dim, chunksize, clustersize, outfilename );\n  double sc_end = gettime();\n  printf(\"Streamcluster time = %lf (s)\\n\", sc_end-sc_start);\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_end();\n#endif\n\n#ifdef PROFILE_TMP\n  gpu_free = gettime();\n#endif\n  free(coord_h);\n  free(gl_lower);\n  free(work_mem_h);\n  free(p_h);\n  sycl::free(work_mem_d, q);\n  sycl::free(coord_d, q);\n  sycl::free(center_table_d, q);\n  sycl::free(switch_membership_d, q);\n  sycl::free(p_d, q);\n\n#ifdef PROFILE_TMP\n  gpu_free = gettime() - gpu_free;\n\n  double t2 = gettime();\n  printf(\"Total time = %lf (s)\\n\",t2-t1);\n#endif\n\n  delete stream;\n\n#ifdef PROFILE_TMP\n  printf(\"==== Detailed timing info ====\\n\");\n  printf(\"pgain = %lf (s)\\n\", time_gain);\n  printf(\"pgain_dist = %lf (s)\\n\", time_gain_dist);\n  printf(\"pgain_init = %lf (s)\\n\", time_gain_init);\n  printf(\"pselect = %lf (s)\\n\", time_select_feasible);\n  printf(\"pspeedy = %lf (s)\\n\", time_speedy);\n  printf(\"pshuffle = %lf (s)\\n\", time_shuffle);\n  printf(\"FL = %lf (s)\\n\", time_FL);\n  printf(\"localSearch = %lf (s)\\n\", time_local_search);\n  printf(\"\\n\");\n  printf(\"serial = %lf (s)\\n\", serial);\n  printf(\"CPU to GPU memory copy = %lf (s)\\n\", cpu_gpu_memcpy);\n  printf(\"GPU to CPU memory copy back = %lf (s)\\n\", memcpy_back);\n  printf(\"GPU malloc = %lf (s)\\n\", gpu_malloc);\n  printf(\"GPU free = %lf (s)\\n\", gpu_free);\n  printf(\"GPU kernels = %lf (s)\\n\", kernel_time);\n#endif\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_end();\n#endif\n\n  return 0;\n}\n", "kernel.sycl": "\n\n\n\n\nconst int thread_id = item.get_global_id(0);\nconst int local_id = item.get_local_id(0);\n\nif(thread_id<num){\n  \n\n  if(local_id == 0)\n    for(int i=0; i<dim; i++){ \n      coord_s_acc[i] = coord_d_acc[i*num + x];\n    }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  float x_cost = 0.0;\n  for(int i=0; i<dim; i++)\n    x_cost += (coord_d_acc[(i*num)+thread_id]-coord_s_acc[i]) * (coord_d_acc[(i*num)+thread_id]-coord_s_acc[i]);\n  x_cost = x_cost * p_d_acc[thread_id].weight;\n\n  float current_cost = p_d_acc[thread_id].cost;\n\n  int base = thread_id*(K+1);   \n  \n\n  if ( x_cost < current_cost ){\n    switch_membership_d_acc[thread_id] = '1';\n    int addr_1 = base + K;\n    work_mem_d_acc[addr_1] = x_cost - current_cost;\n  }\n  \n\n  else {\n    int assign = p_d_acc[thread_id].assign;\n    int addr_2 = base + center_table_d_acc[assign];\n    work_mem_d_acc[addr_2] += current_cost - x_cost;\n  }\n}\n"}}
{"kernel_name": "vol2col", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <cuda.h>\n\n#define threadsPerBlock 512\n\n\n\ntemplate <typename T>\n__global__ void vol2col_kernel(\n    const uint64_t range,\n    const T* data_vol,\n    const int depth,\n    const int height,\n    const int width,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    T* data_col)\n{\n  for (int64_t n = blockDim.x * blockIdx.x + threadIdx.x;\n               n < range; n += blockDim.x * gridDim.x) {\n\n    int w_out = n % width_col;\n    int64_t index = n / width_col;\n    int h_out = index % height_col;\n    index = index / height_col;\n    int t_out = index % depth_col;\n    int channel_in = index / depth_col;\n    int channel_out = channel_in * ksize_t * ksize_h * ksize_w;\n    int t_in = t_out * stride_t - pad_t;\n    int h_in = h_out * stride_h - pad_h;\n    int w_in = w_out * stride_w - pad_w;\n    data_vol += ((channel_in * depth + t_in) * height + h_in) * width + w_in;\n    data_col += ((channel_out * depth_col + t_out) * height_col + h_out) * width_col + w_out;\n\n    for (int i = 0; i < ksize_t; ++i) {\n      for (int j = 0; j < ksize_h; ++j) {\n        for (int k = 0; k < ksize_w; ++k) {\n          int t = t_in + i * dilation_t;\n          int h = h_in + j * dilation_h;\n          int w = w_in + k * dilation_w;\n          *data_col = (t >= 0 && h >= 0 && w >= 0 && t < depth && h < height && w < width)\n              ? data_vol[i * dilation_t * height * width +\n                         j * dilation_h * width + k * dilation_w]\n              : static_cast<T>(0);\n          data_col += depth_col * height_col * width_col;\n        }\n      }\n    }\n  }\n}\n\ntemplate <typename T, typename accT>\n__global__ void col2vol_kernel(\n    const uint64_t n,\n    const T* data_col,\n    const unsigned depth,\n    const unsigned height,\n    const unsigned width,\n    const unsigned kernel_t,\n    const unsigned kernel_h,\n    const unsigned kernel_w,\n    const unsigned pad_t,\n    const unsigned pad_h,\n    const unsigned pad_w,\n    const unsigned stride_t,\n    const unsigned stride_h,\n    const unsigned stride_w,\n    const unsigned dilation_t,\n    const unsigned dilation_h,\n    const unsigned dilation_w,\n    const unsigned depth_col,\n    const unsigned height_col,\n    const unsigned width_col,\n    T* data_vol)\n{\n  for (uint64_t index = blockDim.x * blockIdx.x + threadIdx.x;\n                index < n; index += blockDim.x * gridDim.x) {\n    accT val = static_cast<accT>(0);\n    const unsigned w_im = index % width + pad_w;\n    const unsigned h_im = (index / width) % height + pad_h;\n    const unsigned t_im = (index / width / height) % depth + pad_t;\n    const unsigned c_im = index / (width * height * depth);\n    auto kernel_extent_w = (kernel_w - 1) * dilation_w + 1;\n    auto kernel_extent_h = (kernel_h - 1) * dilation_h + 1;\n    auto kernel_extent_t = (kernel_t - 1) * dilation_t + 1;\n    \n\n    const auto w_col_start =\n        (w_im < kernel_extent_w) ? 0 : (w_im - kernel_extent_w) / stride_w + 1;\n    const auto w_col_end = std::min(w_im / stride_w + 1, width_col);\n    const auto h_col_start =\n        (h_im < kernel_extent_h) ? 0 : (h_im - kernel_extent_h) / stride_h + 1;\n    const auto h_col_end = std::min(h_im / stride_h + 1, height_col);\n    const auto t_col_start =\n        (t_im < kernel_extent_t) ? 0 : (t_im - kernel_extent_t) / stride_t + 1;\n    const auto t_col_end = std::min(t_im / stride_t + 1, depth_col);\n    \n\n    for (unsigned t_col = t_col_start; t_col < t_col_end; t_col += 1) {\n      for (unsigned h_col = h_col_start; h_col < h_col_end; h_col += 1) {\n        for (unsigned w_col = w_col_start; w_col < w_col_end; w_col += 1) {\n          uint64_t t_k = (t_im - t_col * stride_t);\n          uint64_t h_k = (h_im - h_col * stride_h);\n          uint64_t w_k = (w_im - w_col * stride_w);\n          if (t_k % dilation_t == 0 && h_k % dilation_h == 0 &&\n              w_k % dilation_w == 0) {\n            t_k /= dilation_t;\n            h_k /= dilation_h;\n            w_k /= dilation_w;\n            const uint64_t idx_k =\n                ((c_im * kernel_t + t_k) * kernel_h + h_k) * kernel_w + w_k;\n            const uint64_t data_col_index =\n                ((idx_k * depth_col + t_col) *\n                    height_col + h_col) *\n                  width_col + w_col;\n            val += data_col[data_col_index];\n          }\n        }\n      }\n    }\n    data_vol[index] = static_cast<T>(val);\n  }\n}\n\nint get_blocks (uint64_t n) {\n  uint64_t numBlocks = (n - threadsPerBlock) / threadsPerBlock + 1;\n  cudaDeviceProp devProp;\n  cudaGetDeviceProperties(&devProp, 0);\n  uint64_t blocksPerGrid = std::min((uint64_t)devProp.maxGridSize[0], numBlocks);\n  return blocksPerGrid;\n}\n\ntemplate <typename T>\nvoid eval (\n    const int repeat,\n    const int channels,\n    const int depth,\n    const int height,\n    const int width,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w)\n{\n  uint64_t vol_size = (uint64_t) channels * (2*pad_t+depth) * (2*pad_h+height) * (2*pad_w+width);\n  uint64_t col_size = ((uint64_t) channels * ksize_t * ksize_h * ksize_w + 1) * \n                    (depth_col+pad_t) * (height_col+pad_h) * (width_col+pad_w);\n                         \n  uint64_t vol_size_bytes = sizeof(T) * vol_size;\n  uint64_t col_size_bytes = sizeof(T) * col_size;\n  \n  T *h_data_vol = (T*) malloc (vol_size_bytes);\n  T *h_data_col = (T*) malloc (col_size_bytes);\n\n  for (uint64_t i = 0; i < vol_size; i++) {\n    h_data_vol[i] = (T)1; \n  }\n\n  T *d_data_vol;\n  cudaMalloc((void**)&d_data_vol, vol_size_bytes);\n  cudaMemcpy(d_data_vol, h_data_vol, vol_size_bytes, cudaMemcpyHostToDevice);\n\n  T *d_data_col;\n  cudaMalloc((void**)&d_data_col, col_size_bytes);\n  cudaMemset(d_data_col, 0, col_size_bytes);\n\n  \n\n  \n\n  \n\n  uint64_t n = static_cast<uint64_t>(channels) * depth_col * height_col * width_col;\n\n  int blocksPerGrid = get_blocks(n);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    vol2col_kernel<T><<<blocksPerGrid, threadsPerBlock>>>(\n      n,\n      d_data_vol,\n      depth, height, width,\n      ksize_t, ksize_h, ksize_w,\n      pad_t, pad_h, pad_w,\n      stride_t, stride_h, stride_w,\n      dilation_t, dilation_h, dilation_w,\n      depth_col, height_col, width_col,\n      d_data_col);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of vol2col kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_data_col, d_data_col, col_size_bytes, cudaMemcpyDeviceToHost);\n\n  float checksum = 0;\n  for (uint64_t i = 0; i < col_size; i++) {\n    checksum += h_data_col[i];\n  }\n  printf(\"Checksum = %f\\n\", checksum / col_size);\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    col2vol_kernel<T, T><<<blocksPerGrid, threadsPerBlock>>>(\n      n,\n      d_data_col,\n      depth, height, width,\n      ksize_t, ksize_h, ksize_w,\n      pad_t, pad_h, pad_w,\n      stride_t, stride_h, stride_w,\n      dilation_t, dilation_h, dilation_w,\n      depth_col, height_col, width_col,\n      d_data_vol);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of col2vol kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_data_vol, d_data_vol, vol_size_bytes, cudaMemcpyDeviceToHost);\n\n  checksum = 0;\n  for (uint64_t i = 0; i < vol_size; i++) {\n    checksum += h_data_vol[i];\n  }\n  printf(\"Checksum = %f\\n\", checksum / vol_size);\n\n  cudaFree(d_data_vol);\n  cudaFree(d_data_col);\n  free(h_data_vol);\n  free(h_data_col);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  \n  int channels = 4;\n  int depth = 3;\n  int height = 255;\n  int width = 255;\n  int pad_t = 1;\n  int pad_h = 1;\n  int pad_w = 1;\n  int stride_t = 2;\n  int stride_h = 2;\n  int stride_w = 2;\n  int dilation_t = 2;\n  int dilation_h = 2;\n  int dilation_w = 2;\n  int depth_col = 3;\n  int height_col = 255;\n  int width_col = 255;\n\n  for (int k = 1; k <= 9; k = k + 2) {\n    printf(\"\\nkernel size: %d\\n\", k);\n    int ksize_t = k;\n    int ksize_h = k;\n    int ksize_w = k;\n\n    eval<float> (repeat,\n                 channels, depth, height, width,\n                 depth_col, height_col, width_col,\n                 ksize_t, ksize_h, ksize_w,\n                 pad_t, pad_h, pad_w,\n                 stride_t, stride_h, stride_w,\n                 dilation_t, dilation_h, dilation_w);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "vol2col", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define threadsPerBlock 512\n\n\n\ntemplate <typename T>\n__global__ void vol2col_kernel(\n    const uint64_t range,\n    const T* data_vol,\n    const int depth,\n    const int height,\n    const int width,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    T* data_col)\n{\n  for (int64_t n = blockDim.x * blockIdx.x + threadIdx.x;\n               n < range; n += blockDim.x * gridDim.x) {\n\n    int w_out = n % width_col;\n    int64_t index = n / width_col;\n    int h_out = index % height_col;\n    index = index / height_col;\n    int t_out = index % depth_col;\n    int channel_in = index / depth_col;\n    int channel_out = channel_in * ksize_t * ksize_h * ksize_w;\n    int t_in = t_out * stride_t - pad_t;\n    int h_in = h_out * stride_h - pad_h;\n    int w_in = w_out * stride_w - pad_w;\n    data_vol += ((channel_in * depth + t_in) * height + h_in) * width + w_in;\n    data_col += ((channel_out * depth_col + t_out) * height_col + h_out) * width_col + w_out;\n\n    for (int i = 0; i < ksize_t; ++i) {\n      for (int j = 0; j < ksize_h; ++j) {\n        for (int k = 0; k < ksize_w; ++k) {\n          int t = t_in + i * dilation_t;\n          int h = h_in + j * dilation_h;\n          int w = w_in + k * dilation_w;\n          *data_col = (t >= 0 && h >= 0 && w >= 0 && t < depth && h < height && w < width)\n              ? data_vol[i * dilation_t * height * width +\n                         j * dilation_h * width + k * dilation_w]\n              : static_cast<T>(0);\n          data_col += depth_col * height_col * width_col;\n        }\n      }\n    }\n  }\n}\n\ntemplate <typename T, typename accT>\n__global__ void col2vol_kernel(\n    const uint64_t n,\n    const T* data_col,\n    const unsigned depth,\n    const unsigned height,\n    const unsigned width,\n    const unsigned kernel_t,\n    const unsigned kernel_h,\n    const unsigned kernel_w,\n    const unsigned pad_t,\n    const unsigned pad_h,\n    const unsigned pad_w,\n    const unsigned stride_t,\n    const unsigned stride_h,\n    const unsigned stride_w,\n    const unsigned dilation_t,\n    const unsigned dilation_h,\n    const unsigned dilation_w,\n    const unsigned depth_col,\n    const unsigned height_col,\n    const unsigned width_col,\n    T* data_vol)\n{\n  for (uint64_t index = blockDim.x * blockIdx.x + threadIdx.x;\n                index < n; index += blockDim.x * gridDim.x) {\n    accT val = static_cast<accT>(0);\n    const unsigned w_im = index % width + pad_w;\n    const unsigned h_im = (index / width) % height + pad_h;\n    const unsigned t_im = (index / width / height) % depth + pad_t;\n    const unsigned c_im = index / (width * height * depth);\n    auto kernel_extent_w = (kernel_w - 1) * dilation_w + 1;\n    auto kernel_extent_h = (kernel_h - 1) * dilation_h + 1;\n    auto kernel_extent_t = (kernel_t - 1) * dilation_t + 1;\n    \n\n    const auto w_col_start =\n        (w_im < kernel_extent_w) ? 0 : (w_im - kernel_extent_w) / stride_w + 1;\n    const auto w_col_end = std::min(w_im / stride_w + 1, width_col);\n    const auto h_col_start =\n        (h_im < kernel_extent_h) ? 0 : (h_im - kernel_extent_h) / stride_h + 1;\n    const auto h_col_end = std::min(h_im / stride_h + 1, height_col);\n    const auto t_col_start =\n        (t_im < kernel_extent_t) ? 0 : (t_im - kernel_extent_t) / stride_t + 1;\n    const auto t_col_end = std::min(t_im / stride_t + 1, depth_col);\n    \n\n    for (unsigned t_col = t_col_start; t_col < t_col_end; t_col += 1) {\n      for (unsigned h_col = h_col_start; h_col < h_col_end; h_col += 1) {\n        for (unsigned w_col = w_col_start; w_col < w_col_end; w_col += 1) {\n          uint64_t t_k = (t_im - t_col * stride_t);\n          uint64_t h_k = (h_im - h_col * stride_h);\n          uint64_t w_k = (w_im - w_col * stride_w);\n          if (t_k % dilation_t == 0 && h_k % dilation_h == 0 &&\n              w_k % dilation_w == 0) {\n            t_k /= dilation_t;\n            h_k /= dilation_h;\n            w_k /= dilation_w;\n            const uint64_t idx_k =\n                ((c_im * kernel_t + t_k) * kernel_h + h_k) * kernel_w + w_k;\n            const uint64_t data_col_index =\n                ((idx_k * depth_col + t_col) *\n                    height_col + h_col) *\n                  width_col + w_col;\n            val += data_col[data_col_index];\n          }\n        }\n      }\n    }\n    data_vol[index] = static_cast<T>(val);\n  }\n}\n\nint get_blocks (uint64_t n) {\n  uint64_t numBlocks = (n - threadsPerBlock) / threadsPerBlock + 1;\n  hipDeviceProp_t devProp;\n  hipGetDeviceProperties(&devProp, 0);\n  uint64_t blocksPerGrid = std::min((uint64_t)devProp.maxGridSize[0], numBlocks);\n  return blocksPerGrid;\n}\n\ntemplate <typename T>\nvoid eval (\n    const int repeat,\n    const int channels,\n    const int depth,\n    const int height,\n    const int width,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w)\n{\n  uint64_t vol_size = (uint64_t) channels * (2*pad_t+depth) * (2*pad_h+height) * (2*pad_w+width);\n  uint64_t col_size = ((uint64_t) channels * ksize_t * ksize_h * ksize_w + 1) * \n                    (depth_col+pad_t) * (height_col+pad_h) * (width_col+pad_w);\n                         \n  uint64_t vol_size_bytes = sizeof(T) * vol_size;\n  uint64_t col_size_bytes = sizeof(T) * col_size;\n  \n  T *h_data_vol = (T*) malloc (vol_size_bytes);\n  T *h_data_col = (T*) malloc (col_size_bytes);\n\n  for (uint64_t i = 0; i < vol_size; i++) {\n    h_data_vol[i] = (T)1; \n  }\n\n  T *d_data_vol;\n  hipMalloc((void**)&d_data_vol, vol_size_bytes);\n  hipMemcpy(d_data_vol, h_data_vol, vol_size_bytes, hipMemcpyHostToDevice);\n\n  T *d_data_col;\n  hipMalloc((void**)&d_data_col, col_size_bytes);\n  hipMemset(d_data_col, 0, col_size_bytes);\n\n  \n\n  \n\n  \n\n  uint64_t n = static_cast<uint64_t>(channels) * depth_col * height_col * width_col;\n\n  int blocksPerGrid = get_blocks(n);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    vol2col_kernel<T><<<blocksPerGrid, threadsPerBlock>>>(\n      n,\n      d_data_vol,\n      depth, height, width,\n      ksize_t, ksize_h, ksize_w,\n      pad_t, pad_h, pad_w,\n      stride_t, stride_h, stride_w,\n      dilation_t, dilation_h, dilation_w,\n      depth_col, height_col, width_col,\n      d_data_col);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of vol2col kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_data_col, d_data_col, col_size_bytes, hipMemcpyDeviceToHost);\n\n  float checksum = 0;\n  for (uint64_t i = 0; i < col_size; i++) {\n    checksum += h_data_col[i];\n  }\n  printf(\"Checksum = %f\\n\", checksum / col_size);\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    col2vol_kernel<T, T><<<blocksPerGrid, threadsPerBlock>>>(\n      n,\n      d_data_col,\n      depth, height, width,\n      ksize_t, ksize_h, ksize_w,\n      pad_t, pad_h, pad_w,\n      stride_t, stride_h, stride_w,\n      dilation_t, dilation_h, dilation_w,\n      depth_col, height_col, width_col,\n      d_data_vol);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of col2vol kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_data_vol, d_data_vol, vol_size_bytes, hipMemcpyDeviceToHost);\n\n  checksum = 0;\n  for (uint64_t i = 0; i < vol_size; i++) {\n    checksum += h_data_vol[i];\n  }\n  printf(\"Checksum = %f\\n\", checksum / vol_size);\n\n  hipFree(d_data_vol);\n  hipFree(d_data_col);\n  free(h_data_vol);\n  free(h_data_col);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  \n  int channels = 4;\n  int depth = 3;\n  int height = 255;\n  int width = 255;\n  int pad_t = 1;\n  int pad_h = 1;\n  int pad_w = 1;\n  int stride_t = 2;\n  int stride_h = 2;\n  int stride_w = 2;\n  int dilation_t = 2;\n  int dilation_h = 2;\n  int dilation_w = 2;\n  int depth_col = 3;\n  int height_col = 255;\n  int width_col = 255;\n\n  for (int k = 1; k <= 9; k = k + 2) {\n    printf(\"\\nkernel size: %d\\n\", k);\n    int ksize_t = k;\n    int ksize_h = k;\n    int ksize_w = k;\n\n    eval<float> (repeat,\n                 channels, depth, height, width,\n                 depth_col, height_col, width_col,\n                 ksize_t, ksize_h, ksize_w,\n                 pad_t, pad_h, pad_w,\n                 stride_t, stride_h, stride_w,\n                 dilation_t, dilation_h, dilation_w);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "vol2col", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <algorithm>\n#include <chrono>\n#include <omp.h>\n\n#define threadsPerBlock 512\n\n\n\ntemplate <typename T>\nvoid vol2col_kernel(\n    const T* data_vol,\n    const int channels,\n    const int depth,\n    const int height,\n    const int width,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    T* data_col)\n{\n  #pragma omp target teams distribute parallel for collapse(4) \\\n  num_threads(threadsPerBlock)\n  for (int channel_in = 0; channel_in < channels; channel_in++) {\n  for (int t_out = 0; t_out < depth_col; t_out++) {\n  for (int h_out = 0; h_out < height_col; h_out++) {\n  for (int w_out = 0; w_out < width_col; w_out++) {\n    int channel_out = channel_in * ksize_t * ksize_h * ksize_w;\n    int t_in = t_out * stride_t - pad_t;\n    int h_in = h_out * stride_h - pad_h;\n    int w_in = w_out * stride_w - pad_w;\n    data_vol += ((channel_in * depth + t_in) * height + h_in) * width + w_in;\n    data_col += ((channel_out * depth_col + t_out) * height_col + h_out) * width_col + w_out;\n\n    for (int i = 0; i < ksize_t; ++i) {\n      for (int j = 0; j < ksize_h; ++j) {\n        for (int k = 0; k < ksize_w; ++k) {\n          int t = t_in + i * dilation_t;\n          int h = h_in + j * dilation_h;\n          int w = w_in + k * dilation_w;\n          *data_col = (t >= 0 && h >= 0 && w >= 0 && t < depth && h < height && w < width)\n              ? data_vol[i * dilation_t * height * width +\n                         j * dilation_h * width + k * dilation_w]\n              : static_cast<T>(0);\n          data_col += depth_col * height_col * width_col;\n        }\n      }\n    }\n  } } } }\n}\n\ntemplate <typename T, typename accT>\nvoid col2vol_kernel(\n    const T* data_col,\n    const uint64_t n,\n    const unsigned depth,\n    const unsigned height,\n    const unsigned width,\n    const unsigned kernel_t,\n    const unsigned kernel_h,\n    const unsigned kernel_w,\n    const unsigned pad_t,\n    const unsigned pad_h,\n    const unsigned pad_w,\n    const unsigned stride_t,\n    const unsigned stride_h,\n    const unsigned stride_w,\n    const unsigned dilation_t,\n    const unsigned dilation_h,\n    const unsigned dilation_w,\n    const unsigned depth_col,\n    const unsigned height_col,\n    const unsigned width_col,\n    T* data_vol)\n{\n  #pragma omp target teams distribute parallel for num_threads(threadsPerBlock)\n  for (uint64_t index = 0; index < n; index ++) {\n    accT val = static_cast<accT>(0);\n    const unsigned w_im = index % width + pad_w;\n    const unsigned h_im = (index / width) % height + pad_h;\n    const unsigned t_im = (index / width / height) % depth + pad_t;\n    const unsigned c_im = index / (width * height * depth);\n    auto kernel_extent_w = (kernel_w - 1) * dilation_w + 1;\n    auto kernel_extent_h = (kernel_h - 1) * dilation_h + 1;\n    auto kernel_extent_t = (kernel_t - 1) * dilation_t + 1;\n    \n\n    const auto w_col_start =\n        (w_im < kernel_extent_w) ? 0 : (w_im - kernel_extent_w) / stride_w + 1;\n    const auto w_col_end = std::min(w_im / stride_w + 1, width_col);\n    const auto h_col_start =\n        (h_im < kernel_extent_h) ? 0 : (h_im - kernel_extent_h) / stride_h + 1;\n    const auto h_col_end = std::min(h_im / stride_h + 1, height_col);\n    const auto t_col_start =\n        (t_im < kernel_extent_t) ? 0 : (t_im - kernel_extent_t) / stride_t + 1;\n    const auto t_col_end = std::min(t_im / stride_t + 1, depth_col);\n    \n\n    for (unsigned t_col = t_col_start; t_col < t_col_end; t_col += 1) {\n      for (unsigned h_col = h_col_start; h_col < h_col_end; h_col += 1) {\n        for (unsigned w_col = w_col_start; w_col < w_col_end; w_col += 1) {\n          uint64_t t_k = (t_im - t_col * stride_t);\n          uint64_t h_k = (h_im - h_col * stride_h);\n          uint64_t w_k = (w_im - w_col * stride_w);\n          if (t_k % dilation_t == 0 && h_k % dilation_h == 0 &&\n              w_k % dilation_w == 0) {\n            t_k /= dilation_t;\n            h_k /= dilation_h;\n            w_k /= dilation_w;\n            const uint64_t idx_k =\n                ((c_im * kernel_t + t_k) * kernel_h + h_k) * kernel_w + w_k;\n            const uint64_t data_col_index =\n                ((idx_k * depth_col + t_col) *\n                    height_col + h_col) *\n                  width_col + w_col;\n            val += data_col[data_col_index];\n          }\n        }\n      }\n    }\n    data_vol[index] = static_cast<T>(val);\n  }\n}\n\ntemplate <typename T>\nvoid eval (\n    const int repeat,\n    const int channels,\n    const int depth,\n    const int height,\n    const int width,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w)\n{\n  uint64_t vol_size = (uint64_t) channels * (2*pad_t+depth) * (2*pad_h+height) * (2*pad_w+width);\n  uint64_t col_size = ((uint64_t) channels * ksize_t * ksize_h * ksize_w + 1) * \n                    (depth_col+pad_t) * (height_col+pad_h) * (width_col+pad_w);\n                         \n  uint64_t vol_size_bytes = sizeof(T) * vol_size;\n  uint64_t col_size_bytes = sizeof(T) * col_size;\n  \n  T *data_vol = (T*) malloc (vol_size_bytes);\n  T *data_col = (T*) malloc (col_size_bytes);\n\n  for (uint64_t i = 0; i < vol_size; i++) {\n    data_vol[i] = (T)1; \n  }\n\n  memset(data_col, 0, col_size_bytes);\n\n  uint64_t n = static_cast<uint64_t>(channels) * depth_col * height_col * width_col;\n\n  #pragma omp target data map(to: data_vol[0:vol_size]) \\\n                          map(to: data_col[0:col_size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      vol2col_kernel<T>(\n        data_vol,\n        channels, depth, height, width,\n        ksize_t, ksize_h, ksize_w,\n        pad_t, pad_h, pad_w,\n        stride_t, stride_h, stride_w,\n        dilation_t, dilation_h, dilation_w,\n        depth_col, height_col, width_col,\n        data_col);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of vol2col kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    #pragma omp target update from (data_col[0:col_size])\n    float checksum = 0;\n    for (uint64_t i = 0; i < col_size; i++) {\n      checksum += data_col[i];\n    }\n    printf(\"Checksum = %f\\n\", checksum / col_size);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      col2vol_kernel<T, T>(\n        data_col,\n        n, depth, height, width,\n        ksize_t, ksize_h, ksize_w,\n        pad_t, pad_h, pad_w,\n        stride_t, stride_h, stride_w,\n        dilation_t, dilation_h, dilation_w,\n        depth_col, height_col, width_col,\n        data_vol);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of col2vol kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    #pragma omp target update from (data_vol[0:vol_size])\n\n    checksum = 0;\n    for (uint64_t i = 0; i < vol_size; i++) {\n      checksum += data_vol[i];\n    }\n    printf(\"Checksum = %f\\n\", checksum / vol_size);\n  }\n\n  free(data_vol);\n  free(data_col);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  \n  int channels = 4;\n  int depth = 3;\n  int height = 255;\n  int width = 255;\n  int pad_t = 1;\n  int pad_h = 1;\n  int pad_w = 1;\n  int stride_t = 2;\n  int stride_h = 2;\n  int stride_w = 2;\n  int dilation_t = 2;\n  int dilation_h = 2;\n  int dilation_w = 2;\n  int depth_col = 3;\n  int height_col = 255;\n  int width_col = 255;\n\n  for (int k = 1; k <= 9; k = k + 2) {\n    printf(\"\\nkernel size: %d\\n\", k);\n    int ksize_t = k;\n    int ksize_h = k;\n    int ksize_w = k;\n\n    eval<float> (repeat,\n                 channels, depth, height, width,\n                 depth_col, height_col, width_col,\n                 ksize_t, ksize_h, ksize_w,\n                 pad_t, pad_h, pad_w,\n                 stride_t, stride_h, stride_w,\n                 dilation_t, dilation_h, dilation_w);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "vol2col", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <algorithm>\n#include <chrono>\n\n#define threadsPerBlock 512\n\n\n\ntemplate <typename T>\nvoid vol2col_kernel(\n    const T* data_vol,\n    const int channels,\n    const int depth,\n    const int height,\n    const int width,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    T* data_col)\n{\n    for (int channel_in = 0; channel_in < channels; channel_in++) {\n  for (int t_out = 0; t_out < depth_col; t_out++) {\n  for (int h_out = 0; h_out < height_col; h_out++) {\n  for (int w_out = 0; w_out < width_col; w_out++) {\n    int channel_out = channel_in * ksize_t * ksize_h * ksize_w;\n    int t_in = t_out * stride_t - pad_t;\n    int h_in = h_out * stride_h - pad_h;\n    int w_in = w_out * stride_w - pad_w;\n    data_vol += ((channel_in * depth + t_in) * height + h_in) * width + w_in;\n    data_col += ((channel_out * depth_col + t_out) * height_col + h_out) * width_col + w_out;\n\n    for (int i = 0; i < ksize_t; ++i) {\n      for (int j = 0; j < ksize_h; ++j) {\n        for (int k = 0; k < ksize_w; ++k) {\n          int t = t_in + i * dilation_t;\n          int h = h_in + j * dilation_h;\n          int w = w_in + k * dilation_w;\n          *data_col = (t >= 0 && h >= 0 && w >= 0 && t < depth && h < height && w < width)\n              ? data_vol[i * dilation_t * height * width +\n                         j * dilation_h * width + k * dilation_w]\n              : static_cast<T>(0);\n          data_col += depth_col * height_col * width_col;\n        }\n      }\n    }\n  } } } }\n}\n\ntemplate <typename T, typename accT>\nvoid col2vol_kernel(\n    const T* data_col,\n    const uint64_t n,\n    const unsigned depth,\n    const unsigned height,\n    const unsigned width,\n    const unsigned kernel_t,\n    const unsigned kernel_h,\n    const unsigned kernel_w,\n    const unsigned pad_t,\n    const unsigned pad_h,\n    const unsigned pad_w,\n    const unsigned stride_t,\n    const unsigned stride_h,\n    const unsigned stride_w,\n    const unsigned dilation_t,\n    const unsigned dilation_h,\n    const unsigned dilation_w,\n    const unsigned depth_col,\n    const unsigned height_col,\n    const unsigned width_col,\n    T* data_vol)\n{\n    for (uint64_t index = 0; index < n; index ++) {\n    accT val = static_cast<accT>(0);\n    const unsigned w_im = index % width + pad_w;\n    const unsigned h_im = (index / width) % height + pad_h;\n    const unsigned t_im = (index / width / height) % depth + pad_t;\n    const unsigned c_im = index / (width * height * depth);\n    auto kernel_extent_w = (kernel_w - 1) * dilation_w + 1;\n    auto kernel_extent_h = (kernel_h - 1) * dilation_h + 1;\n    auto kernel_extent_t = (kernel_t - 1) * dilation_t + 1;\n    \n\n    const auto w_col_start =\n        (w_im < kernel_extent_w) ? 0 : (w_im - kernel_extent_w) / stride_w + 1;\n    const auto w_col_end = std::min(w_im / stride_w + 1, width_col);\n    const auto h_col_start =\n        (h_im < kernel_extent_h) ? 0 : (h_im - kernel_extent_h) / stride_h + 1;\n    const auto h_col_end = std::min(h_im / stride_h + 1, height_col);\n    const auto t_col_start =\n        (t_im < kernel_extent_t) ? 0 : (t_im - kernel_extent_t) / stride_t + 1;\n    const auto t_col_end = std::min(t_im / stride_t + 1, depth_col);\n    \n\n    for (unsigned t_col = t_col_start; t_col < t_col_end; t_col += 1) {\n      for (unsigned h_col = h_col_start; h_col < h_col_end; h_col += 1) {\n        for (unsigned w_col = w_col_start; w_col < w_col_end; w_col += 1) {\n          uint64_t t_k = (t_im - t_col * stride_t);\n          uint64_t h_k = (h_im - h_col * stride_h);\n          uint64_t w_k = (w_im - w_col * stride_w);\n          if (t_k % dilation_t == 0 && h_k % dilation_h == 0 &&\n              w_k % dilation_w == 0) {\n            t_k /= dilation_t;\n            h_k /= dilation_h;\n            w_k /= dilation_w;\n            const uint64_t idx_k =\n                ((c_im * kernel_t + t_k) * kernel_h + h_k) * kernel_w + w_k;\n            const uint64_t data_col_index =\n                ((idx_k * depth_col + t_col) *\n                    height_col + h_col) *\n                  width_col + w_col;\n            val += data_col[data_col_index];\n          }\n        }\n      }\n    }\n    data_vol[index] = static_cast<T>(val);\n  }\n}\n\ntemplate <typename T>\nvoid eval (\n    const int repeat,\n    const int channels,\n    const int depth,\n    const int height,\n    const int width,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w)\n{\n  uint64_t vol_size = (uint64_t) channels * (2*pad_t+depth) * (2*pad_h+height) * (2*pad_w+width);\n  uint64_t col_size = ((uint64_t) channels * ksize_t * ksize_h * ksize_w + 1) * \n                    (depth_col+pad_t) * (height_col+pad_h) * (width_col+pad_w);\n                         \n  uint64_t vol_size_bytes = sizeof(T) * vol_size;\n  uint64_t col_size_bytes = sizeof(T) * col_size;\n  \n  T *data_vol = (T*) malloc (vol_size_bytes);\n  T *data_col = (T*) malloc (col_size_bytes);\n\n  for (uint64_t i = 0; i < vol_size; i++) {\n    data_vol[i] = (T)1; \n  }\n\n  memset(data_col, 0, col_size_bytes);\n\n  uint64_t n = static_cast<uint64_t>(channels) * depth_col * height_col * width_col;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      vol2col_kernel<T>(\n        data_vol,\n        channels, depth, height, width,\n        ksize_t, ksize_h, ksize_w,\n        pad_t, pad_h, pad_w,\n        stride_t, stride_h, stride_w,\n        dilation_t, dilation_h, dilation_w,\n        depth_col, height_col, width_col,\n        data_col);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of vol2col kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n        float checksum = 0;\n    for (uint64_t i = 0; i < col_size; i++) {\n      checksum += data_col[i];\n    }\n    printf(\"Checksum = %f\\n\", checksum / col_size);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      col2vol_kernel<T, T>(\n        data_col,\n        n, depth, height, width,\n        ksize_t, ksize_h, ksize_w,\n        pad_t, pad_h, pad_w,\n        stride_t, stride_h, stride_w,\n        dilation_t, dilation_h, dilation_w,\n        depth_col, height_col, width_col,\n        data_vol);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of col2vol kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    \n    checksum = 0;\n    for (uint64_t i = 0; i < vol_size; i++) {\n      checksum += data_vol[i];\n    }\n    printf(\"Checksum = %f\\n\", checksum / vol_size);\n  }\n\n  free(data_vol);\n  free(data_col);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n  \n  int channels = 4;\n  int depth = 3;\n  int height = 255;\n  int width = 255;\n  int pad_t = 1;\n  int pad_h = 1;\n  int pad_w = 1;\n  int stride_t = 2;\n  int stride_h = 2;\n  int stride_w = 2;\n  int dilation_t = 2;\n  int dilation_h = 2;\n  int dilation_w = 2;\n  int depth_col = 3;\n  int height_col = 255;\n  int width_col = 255;\n\n  for (int k = 1; k <= 9; k = k + 2) {\n    printf(\"\\nkernel size: %d\\n\", k);\n    int ksize_t = k;\n    int ksize_h = k;\n    int ksize_w = k;\n\n    eval<float> (repeat,\n                 channels, depth, height, width,\n                 depth_col, height_col, width_col,\n                 ksize_t, ksize_h, ksize_w,\n                 pad_t, pad_h, pad_w,\n                 stride_t, stride_h, stride_w,\n                 dilation_t, dilation_h, dilation_w);\n  }\n\n  return 0;\n}"}}
{"kernel_name": "vol2col", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <algorithm>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define threadsPerBlock 512\n\n\n\ntemplate <typename T>\nvoid vol2col_kernel(\n    sycl::nd_item<1> &item,\n    const uint64_t range,\n    const T* data_vol,\n    const int depth,\n    const int height,\n    const int width,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    T* data_col)\n{\n  for (int64_t n = item.get_global_id(0); n < range;\n               n += item.get_group_range(0) * item.get_local_range(0)) {\n\n    int w_out = n % width_col;\n    int64_t index = n / width_col;\n    int h_out = index % height_col;\n    index /= height_col;\n    int t_out = index % depth_col;\n    int channel_in = index / depth_col;\n    int channel_out = channel_in * ksize_t * ksize_h * ksize_w;\n    int t_in = t_out * stride_t - pad_t;\n    int h_in = h_out * stride_h - pad_h;\n    int w_in = w_out * stride_w - pad_w;\n    data_vol += ((channel_in * depth + t_in) * height + h_in) * width + w_in;\n    data_col += ((channel_out * depth_col + t_out) * height_col + h_out) * width_col + w_out;\n    for (int i = 0; i < ksize_t; ++i) {\n      for (int j = 0; j < ksize_h; ++j) {\n        for (int k = 0; k < ksize_w; ++k) {\n          int t = t_in + i * dilation_t;\n          int h = h_in + j * dilation_h;\n          int w = w_in + k * dilation_w;\n          *data_col = (t >= 0 && h >= 0 && w >= 0 && t < depth && h < height && w < width)\n              ? data_vol[i * dilation_t * height * width +\n                         j * dilation_h * width + k * dilation_w]\n              : static_cast<T>(0);\n          data_col += depth_col * height_col * width_col;\n        }\n      }\n    }\n  }\n}\n\ntemplate <typename T, typename accT>\nvoid col2vol_kernel(\n    sycl::nd_item<1> &item,\n    const uint64_t n,\n    const T* data_col,\n    const unsigned depth,\n    const unsigned height,\n    const unsigned width,\n    const unsigned kernel_t,\n    const unsigned kernel_h,\n    const unsigned kernel_w,\n    const unsigned pad_t,\n    const unsigned pad_h,\n    const unsigned pad_w,\n    const unsigned stride_t,\n    const unsigned stride_h,\n    const unsigned stride_w,\n    const unsigned dilation_t,\n    const unsigned dilation_h,\n    const unsigned dilation_w,\n    const unsigned depth_col,\n    const unsigned height_col,\n    const unsigned width_col,\n    T* data_vol)\n{\n  for (int64_t index = item.get_global_id(0); index < n;\n               index += item.get_group_range(0) * item.get_local_range(0)) {\n    accT val = static_cast<accT>(0);\n    const unsigned w_im = index % width + pad_w;\n    const unsigned h_im = (index / width) % height + pad_h;\n    const unsigned t_im = (index / width / height) % depth + pad_t;\n    const unsigned c_im = index / (width * height * depth);\n    auto kernel_extent_w = (kernel_w - 1) * dilation_w + 1;\n    auto kernel_extent_h = (kernel_h - 1) * dilation_h + 1;\n    auto kernel_extent_t = (kernel_t - 1) * dilation_t + 1;\n    \n\n    const auto w_col_start =\n        (w_im < kernel_extent_w) ? 0 : (w_im - kernel_extent_w) / stride_w + 1;\n    const auto w_col_end = sycl::min(w_im / stride_w + 1, width_col);\n    const auto h_col_start =\n        (h_im < kernel_extent_h) ? 0 : (h_im - kernel_extent_h) / stride_h + 1;\n    const auto h_col_end = sycl::min(h_im / stride_h + 1, height_col);\n    const auto t_col_start =\n        (t_im < kernel_extent_t) ? 0 : (t_im - kernel_extent_t) / stride_t + 1;\n    const auto t_col_end = sycl::min(t_im / stride_t + 1, depth_col);\n    \n\n    for (unsigned t_col = t_col_start; t_col < t_col_end; t_col += 1) {\n      for (unsigned h_col = h_col_start; h_col < h_col_end; h_col += 1) {\n        for (unsigned w_col = w_col_start; w_col < w_col_end; w_col += 1) {\n          uint64_t t_k = (t_im - t_col * stride_t);\n          uint64_t h_k = (h_im - h_col * stride_h);\n          uint64_t w_k = (w_im - w_col * stride_w);\n          if (t_k % dilation_t == 0 && h_k % dilation_h == 0 &&\n              w_k % dilation_w == 0) {\n            t_k /= dilation_t;\n            h_k /= dilation_h;\n            w_k /= dilation_w;\n            const uint64_t idx_k =\n                ((c_im * kernel_t + t_k) * kernel_h + h_k) * kernel_w + w_k;\n            const uint64_t data_col_index =\n                ((idx_k * depth_col + t_col) *\n                    height_col + h_col) *\n                  width_col + w_col;\n            val += data_col[data_col_index];\n          }\n        }\n      }\n    }\n    data_vol[index] = static_cast<T>(val);\n  }\n}\n\nint get_blocks (sycl::queue &q, uint64_t n) {\n  uint64_t numBlocks = (n - threadsPerBlock) / threadsPerBlock + 1;\n\n#ifdef SYCL_EXT_ONEAPI_MAX_WORK_GROUP_QUERY\n  sycl::id<3> groups = q.get_device().get_info<\n    sycl::ext::oneapi::experimental::info::device::max_work_groups<3>>();\n  uint64_t blocksPerGrid = std::min((uint64_t)groups[2], numBlocks);\n#else\n  uint64_t blocksPerGrid = std::min((uint64_t)0x7FFFFFFF, numBlocks);\n#endif\n\n  return blocksPerGrid;\n}\n\ntemplate <typename T>\nvoid eval (\n    const int repeat,\n    const int channels,\n    const int depth,\n    const int height,\n    const int width,\n    const int depth_col,\n    const int height_col,\n    const int width_col,\n    const int ksize_t,\n    const int ksize_h,\n    const int ksize_w,\n    const int pad_t,\n    const int pad_h,\n    const int pad_w,\n    const int stride_t,\n    const int stride_h,\n    const int stride_w,\n    const int dilation_t,\n    const int dilation_h,\n    const int dilation_w)\n{\n  uint64_t vol_size = (uint64_t) channels * (2*pad_t+depth) * (2*pad_h+height) * (2*pad_w+width);\n  uint64_t col_size = ((uint64_t) channels * ksize_t * ksize_h * ksize_w + 1) *\n                    (depth_col+pad_t) * (height_col+pad_h) * (width_col+pad_w);\n\n  uint64_t vol_size_bytes = sizeof(T) * vol_size;\n  uint64_t col_size_bytes = sizeof(T) * col_size;\n\n  T *h_data_vol = (T*) malloc (vol_size_bytes);\n  T *h_data_col = (T*) malloc (col_size_bytes);\n\n  for (uint64_t i = 0; i < vol_size; i++) {\n    h_data_vol[i] = (T)1;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  T *d_data_vol = sycl::malloc_device<T>(vol_size, q);\n  q.memcpy(d_data_vol, h_data_vol, vol_size_bytes);\n\n  T *d_data_col = sycl::malloc_device<T>(col_size, q);\n  q.memset(d_data_col, 0, col_size_bytes);\n\n  \n\n  \n\n  \n\n  uint64_t n = static_cast<uint64_t>(channels) * depth_col * height_col * width_col;\n\n  int blocksPerGrid = get_blocks(q, n);\n\n  sycl::range<1> gws (blocksPerGrid * threadsPerBlock);\n  sycl::range<1> lws (threadsPerBlock);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class v2c>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        vol2col_kernel<T>(\n          item,\n          n,\n          d_data_vol,\n          depth, height, width,\n          ksize_t, ksize_h, ksize_w,\n          pad_t, pad_h, pad_w,\n          stride_t, stride_h, stride_w,\n          dilation_t, dilation_h, dilation_w,\n          depth_col, height_col, width_col,\n          d_data_col);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of vol2col kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(h_data_col, d_data_col, col_size_bytes).wait();\n\n  float checksum = 0;\n  for (uint64_t i = 0; i < col_size; i++) {\n    checksum += h_data_col[i];\n  }\n  printf(\"Checksum = %f\\n\", checksum / col_size);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class c2v>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        col2vol_kernel<T, T>(\n          item,\n          n,\n          d_data_col,\n          depth, height, width,\n          ksize_t, ksize_h, ksize_w,\n          pad_t, pad_h, pad_w,\n          stride_t, stride_h, stride_w,\n          dilation_t, dilation_h, dilation_w,\n          depth_col, height_col, width_col,\n          d_data_vol);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of col2vol kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(h_data_vol, d_data_vol, vol_size_bytes).wait();\n\n  checksum = 0;\n  for (uint64_t i = 0; i < vol_size; i++) {\n    checksum += h_data_vol[i];\n  }\n  printf(\"Checksum = %f\\n\", checksum / vol_size);\n\n  sycl::free(d_data_vol, q);\n  sycl::free(d_data_col, q);\n  free(h_data_vol);\n  free(h_data_col);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  int channels = 4;\n  int depth = 3;\n  int height = 255;\n  int width = 255;\n  int pad_t = 1;\n  int pad_h = 1;\n  int pad_w = 1;\n  int stride_t = 2;\n  int stride_h = 2;\n  int stride_w = 2;\n  int dilation_t = 2;\n  int dilation_h = 2;\n  int dilation_w = 2;\n  int depth_col = 3;\n  int height_col = 255;\n  int width_col = 255;\n\n  for (int k = 1; k <= 9; k = k + 2) {\n    printf(\"\\nkernel size: %d\\n\", k);\n    int ksize_t = k;\n    int ksize_h = k;\n    int ksize_w = k;\n\n    eval<float> (repeat,\n                 channels, depth, height, width,\n                 depth_col, height_col, width_col,\n                 ksize_t, ksize_h, ksize_w,\n                 pad_t, pad_h, pad_w,\n                 stride_t, stride_h, stride_w,\n                 dilation_t, dilation_h, dilation_w);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "winograd", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cuda.h>\n#include \"utils.h\"\n\n__global__ void winograd_conv2d(\n    const DATA_TYPE *__restrict__ input,\n    const DATA_TYPE *__restrict__ transformed_filter ,\n    DATA_TYPE *__restrict__ output,\n    const int offset_i,\n    const int offset_j)\n{\n  int tile_i = blockIdx.x * blockDim.x + threadIdx.x + offset_i;\n  int tile_j = blockIdx.y * blockDim.y + threadIdx.y + offset_j;\n\n  \n\n\n  DATA_TYPE input_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n  for (int i = 0; i < 4; i ++) {\n    for (int j = 0; j < 4; j ++) { \n      int x = 2 * tile_i + i;\n      int y = 2 * tile_j + j;\n      if (x >= MAP_SIZE || y >= MAP_SIZE) {\n        input_tile[i][j] = 0;\n        continue;\n      }\n      input_tile[i][j] = input[x * MAP_SIZE + y];\n    }\n  } \n\n  \n\n  for (int j = 0; j < 4; j ++) {\n    tmp_tile[0][j] = input_tile[0][j] - input_tile[2][j];\n    tmp_tile[1][j] = input_tile[1][j] + input_tile[2][j];\n    tmp_tile[2][j] = -input_tile[1][j] + input_tile[2][j];\n    tmp_tile[3][j] = input_tile[1][j] - input_tile[3][j];\n  }\n  \n\n  for (int i = 0; i < 4; i ++) {\n    transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n    transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n    transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n    transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n  }\n\n  \n\n\n  DATA_TYPE multiplied_tile[4][4];\n  for (int i = 0; i < 4; i ++) {\n    for (int j = 0; j < 4; j ++) {\n      multiplied_tile[i][j] = transformed_tile[i][j] * transformed_filter[i * 4 + j];\n    }\n  }\n\n  \n\n\n  DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n  \n\n  for (int j = 0; j < 4; j ++) {\n    tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n    tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n  }\n  \n\n  for (int i = 0; i < 2; i ++) {\n    final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n    final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n  }\n\n  for (int i = 0; i < 2; i ++) {\n    for (int j = 0; j < 2; j ++) {\n      int x = 2 * tile_i + i;\n      int y = 2 * tile_j + j;\n      if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n        continue;\n      }\n      output[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n\n  double start = rtclock();\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B_outputFromGpu = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n  DATA_TYPE *d_A;\n  cudaMalloc((void**)&d_A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  cudaMemcpy(d_A, A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n  DATA_TYPE *d_B;\n  cudaMalloc((void**)&d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE));\n\n  DATA_TYPE *d_C;\n  cudaMalloc((void**)&d_C, 16 * sizeof(DATA_TYPE));\n  cudaMemcpy(d_C, C, 16 * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n  int global_offset[2];\n\n  bool pass = true;\n\n  \n\n  double co_time = 0.0;\n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) \n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    global_offset[0] = cpu_global_size[0];\n    global_offset[1] = 0;\n\n    dim3 grid(gpu_global_size[0] / localWorkSize[0], gpu_global_size[1] / localWorkSize[1]);\n    dim3 block(localWorkSize[0], localWorkSize[1]);\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n      winograd_conv2d<<<grid, block>>>(d_A, d_C, d_B, global_offset[0], global_offset[1]);\n    }\n\n    if (cpu_run) {\n      \n\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      cudaMemcpy(d_B, B, gpu_run ? global_offset[0]*2*(MAP_SIZE-2)*sizeof(DATA_TYPE) : \n          (MAP_SIZE-2)*(MAP_SIZE-2)*sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n    }\n\n    cudaMemcpy(B_outputFromGpu, d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE), cudaMemcpyDeviceToHost);\n\n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B, C);\n    pass &= compareResults(B, B_outputFromGpu);\n\n  } \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_A);\n  cudaFree(d_B);\n  cudaFree(d_C);\n  free(A);\n  free(B);\n  free(B_outputFromGpu);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}\n"}}
{"kernel_name": "winograd", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"utils.h\"\n\n__global__ void winograd_conv2d(\n    const DATA_TYPE *__restrict__ input,\n    const DATA_TYPE *__restrict__ transformed_filter ,\n    DATA_TYPE *__restrict__ output,\n    const int offset_i,\n    const int offset_j)\n{\n  int tile_i = blockIdx.x * blockDim.x + threadIdx.x + offset_i;\n  int tile_j = blockIdx.y * blockDim.y + threadIdx.y + offset_j;\n\n  \n\n\n  DATA_TYPE input_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n  for (int i = 0; i < 4; i ++) {\n    for (int j = 0; j < 4; j ++) { \n      int x = 2 * tile_i + i;\n      int y = 2 * tile_j + j;\n      if (x >= MAP_SIZE || y >= MAP_SIZE) {\n        input_tile[i][j] = 0;\n        continue;\n      }\n      input_tile[i][j] = input[x * MAP_SIZE + y];\n    }\n  } \n\n  \n\n  for (int j = 0; j < 4; j ++) {\n    tmp_tile[0][j] = input_tile[0][j] - input_tile[2][j];\n    tmp_tile[1][j] = input_tile[1][j] + input_tile[2][j];\n    tmp_tile[2][j] = -input_tile[1][j] + input_tile[2][j];\n    tmp_tile[3][j] = input_tile[1][j] - input_tile[3][j];\n  }\n  \n\n  for (int i = 0; i < 4; i ++) {\n    transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n    transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n    transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n    transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n  }\n\n  \n\n\n  DATA_TYPE multiplied_tile[4][4];\n  for (int i = 0; i < 4; i ++) {\n    for (int j = 0; j < 4; j ++) {\n      multiplied_tile[i][j] = transformed_tile[i][j] * transformed_filter[i * 4 + j];\n    }\n  }\n\n  \n\n\n  DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n  \n\n  for (int j = 0; j < 4; j ++) {\n    tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n    tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n  }\n  \n\n  for (int i = 0; i < 2; i ++) {\n    final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n    final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n  }\n\n  for (int i = 0; i < 2; i ++) {\n    for (int j = 0; j < 2; j ++) {\n      int x = 2 * tile_i + i;\n      int y = 2 * tile_j + j;\n      if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n        continue;\n      }\n      output[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n\n  double start = rtclock();\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B_outputFromGpu = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n  DATA_TYPE *d_A;\n  hipMalloc((void**)&d_A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  hipMemcpy(d_A, A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE), hipMemcpyHostToDevice);\n\n  DATA_TYPE *d_B;\n  hipMalloc((void**)&d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE));\n\n  DATA_TYPE *d_C;\n  hipMalloc((void**)&d_C, 16 * sizeof(DATA_TYPE));\n  hipMemcpy(d_C, C, 16 * sizeof(DATA_TYPE), hipMemcpyHostToDevice);\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n  int global_offset[2];\n\n  bool pass = true;\n\n  \n\n  double co_time = 0.0;\n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) \n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    global_offset[0] = cpu_global_size[0];\n    global_offset[1] = 0;\n\n    dim3 grid(gpu_global_size[0] / localWorkSize[0], gpu_global_size[1] / localWorkSize[1]);\n    dim3 block(localWorkSize[0], localWorkSize[1]);\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n      hipLaunchKernelGGL(winograd_conv2d, grid, block, 0, 0, d_A, d_C, d_B, global_offset[0], global_offset[1]);\n    }\n\n    if (cpu_run) {\n      \n\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      hipMemcpy(d_B, B, gpu_run ? global_offset[0]*2*(MAP_SIZE-2)*sizeof(DATA_TYPE) : \n          (MAP_SIZE-2)*(MAP_SIZE-2)*sizeof(DATA_TYPE), hipMemcpyHostToDevice);\n    }\n\n    hipMemcpy(B_outputFromGpu, d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE), hipMemcpyDeviceToHost);\n\n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B, C);\n    pass &= compareResults(B, B_outputFromGpu);\n\n  } \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_A);\n  hipFree(d_B);\n  hipFree(d_C);\n  free(A);\n  free(B);\n  free(B_outputFromGpu);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}\n"}}
{"kernel_name": "winograd", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <omp.h>\n#include \"utils.h\"\n\nint main(int argc, char* argv[]) {\n\n  double start = rtclock();\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B_host = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n  size_t global_offset[2];\n\n  bool pass = true;\n\n  double co_time = 0.0;\n\n#pragma omp target data map (to: A[0:MAP_SIZE * MAP_SIZE],C[0:16]), \\\n                        map (alloc: B[0:(MAP_SIZE-2) * (MAP_SIZE-2)])\n\n{\n  \n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) \n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    global_offset[0] = cpu_global_size[0];\n    global_offset[1] = 0;\n\n    const int tile_i_size = gpu_global_size[0];\n    const int tile_j_size = gpu_global_size[1];\n    const int offset_i = global_offset[0];\n    const int offset_j = global_offset[1];\n    const int thread_size = localWorkSize[1] * localWorkSize[0];\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(thread_size)\n      for (int tile_j = 0; tile_j < tile_j_size; tile_j++) {\n        for (int tile_i = 0; tile_i < tile_i_size; tile_i++) {\n          \n\n\n          DATA_TYPE input_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) { \n              int x = 2 * (tile_i + offset_i) + i;\n              int y = 2 * (tile_j + offset_j) + j;\n              if (x >= MAP_SIZE || y >= MAP_SIZE) {\n                input_tile[i][j] = 0;\n                continue;\n              }\n              input_tile[i][j] = A[x * MAP_SIZE + y];\n            }\n          } \n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile[0][j] = input_tile[0][j] - input_tile[2][j];\n            tmp_tile[1][j] = input_tile[1][j] + input_tile[2][j];\n            tmp_tile[2][j] = -input_tile[1][j] + input_tile[2][j];\n            tmp_tile[3][j] = input_tile[1][j] - input_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 4; i ++) {\n            transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n            transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n          }\n\n          \n\n\n          DATA_TYPE multiplied_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) {\n              multiplied_tile[i][j] = transformed_tile[i][j] * C[i * 4 + j];\n            }\n          }\n\n          \n\n\n          DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n            tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 2; i ++) {\n            final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n            final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n          }\n\n          for (int i = 0; i < 2; i ++) {\n            for (int j = 0; j < 2; j ++) {\n              int x = 2 * (tile_i + offset_i) + i;\n              int y = 2 * (tile_j + offset_j) + j;\n              if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n                continue;\n              }\n              B[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n            }\n          }\n        }\n      }\n    }\n\n    if (cpu_run) {\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      if (gpu_run) {\n        #pragma omp target update to (B[0:offset_i*2*(MAP_SIZE-2)])\n      }\n      else {\n        #pragma omp target update to (B[0:(MAP_SIZE-2)*(MAP_SIZE-2)])\n      }\n    }\n\n    #pragma omp target update from (B[0:(MAP_SIZE-2)*(MAP_SIZE-2)])\n\n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B_host, C);\n    pass &= compareResults(B_host, B);\n\n  } \n\n}  \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  free(A);\n  free(B);\n  free(B_host);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}\n"}}
{"kernel_name": "winograd", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include \"utils.h\"\n\nint main(int argc, char* argv[]) {\n\n  double start = rtclock();\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B_host = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n  size_t global_offset[2];\n\n  bool pass = true;\n\n  double co_time = 0.0;\n\n\n{\n  \n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) \n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    global_offset[0] = cpu_global_size[0];\n    global_offset[1] = 0;\n\n    const int tile_i_size = gpu_global_size[0];\n    const int tile_j_size = gpu_global_size[1];\n    const int offset_i = global_offset[0];\n    const int offset_j = global_offset[1];\n    const int thread_size = localWorkSize[1] * localWorkSize[0];\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n            for (int tile_j = 0; tile_j < tile_j_size; tile_j++) {\n        for (int tile_i = 0; tile_i < tile_i_size; tile_i++) {\n          \n\n\n          DATA_TYPE input_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) { \n              int x = 2 * (tile_i + offset_i) + i;\n              int y = 2 * (tile_j + offset_j) + j;\n              if (x >= MAP_SIZE || y >= MAP_SIZE) {\n                input_tile[i][j] = 0;\n                continue;\n              }\n              input_tile[i][j] = A[x * MAP_SIZE + y];\n            }\n          } \n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile[0][j] = input_tile[0][j] - input_tile[2][j];\n            tmp_tile[1][j] = input_tile[1][j] + input_tile[2][j];\n            tmp_tile[2][j] = -input_tile[1][j] + input_tile[2][j];\n            tmp_tile[3][j] = input_tile[1][j] - input_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 4; i ++) {\n            transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n            transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n          }\n\n          \n\n\n          DATA_TYPE multiplied_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) {\n              multiplied_tile[i][j] = transformed_tile[i][j] * C[i * 4 + j];\n            }\n          }\n\n          \n\n\n          DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n            tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 2; i ++) {\n            final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n            final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n          }\n\n          for (int i = 0; i < 2; i ++) {\n            for (int j = 0; j < 2; j ++) {\n              int x = 2 * (tile_i + offset_i) + i;\n              int y = 2 * (tile_j + offset_j) + j;\n              if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n                continue;\n              }\n              B[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n            }\n          }\n        }\n      }\n    }\n\n    if (cpu_run) {\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      if (gpu_run) {\n              }\n      else {\n              }\n    }\n\n    \n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B_host, C);\n    pass &= compareResults(B_host, B);\n\n  } \n\n}  \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  free(A);\n  free(B);\n  free(B_host);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}"}}
{"kernel_name": "winograd", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n\nint main(int argc, char* argv[]) {\n\n  DATA_TYPE *A = (DATA_TYPE*)malloc(MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n  DATA_TYPE *B = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *B_outputFromGpu = (DATA_TYPE*)malloc((MAP_SIZE - 2) * (MAP_SIZE - 2) * sizeof(DATA_TYPE));\n  DATA_TYPE *C = (DATA_TYPE*)malloc(4 * 4 * sizeof(DATA_TYPE));\n\n  for (int i = 0; i < MAP_SIZE; ++i)\n    for (int j = 0; j < MAP_SIZE; ++j)\n      A[i * MAP_SIZE + j] = rand() / (float)RAND_MAX;\n\n  \n\n  WinogradConv2D_2x2_filter_transformation(C);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double start = rtclock();\n\n  DATA_TYPE *d_A = sycl::malloc_device<DATA_TYPE>(MAP_SIZE * MAP_SIZE, q);\n  q.memcpy(d_A, A, MAP_SIZE * MAP_SIZE * sizeof(DATA_TYPE));\n\n  DATA_TYPE *d_B = sycl::malloc_device<DATA_TYPE>((MAP_SIZE-2) * (MAP_SIZE-2), q);\n\n  DATA_TYPE *d_C = sycl::malloc_device<DATA_TYPE>(16, q);\n  q.memcpy(d_C, C, 16 * sizeof(DATA_TYPE));\n\n  const int tile_n = (MAP_SIZE - 2 + 1) / 2;\n\n  \n\n  size_t globalWorkSize[2] = {\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X,\n    (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y };\n\n  size_t localWorkSize[2] = {DIM_LOCAL_WORK_GROUP_X, DIM_LOCAL_WORK_GROUP_Y};\n\n  \n\n  size_t cpu_global_size[2];\n  size_t gpu_global_size[2];\n\n  bool pass = true;\n\n  \n\n  double co_time = 0.0;\n\n  for (int cpu_offset = 0; cpu_offset <= 100; cpu_offset++) {\n\n    cpu_global_size[0] = cpu_offset * (size_t)ceil(((float)tile_n) / ((float)DIM_LOCAL_WORK_GROUP_X))\n      / 100 * DIM_LOCAL_WORK_GROUP_X;\n    cpu_global_size[1] = globalWorkSize[1];\n    gpu_global_size[0] = globalWorkSize[0] - cpu_global_size[0];\n    gpu_global_size[1] = globalWorkSize[1];\n\n    const int offset_j = cpu_global_size[0];\n    const int offset_i = 0;\n\n    sycl::range<2> gpu_gws(gpu_global_size[1], gpu_global_size[0]);\n    sycl::range<2> cpu_gws(cpu_global_size[1], cpu_global_size[0]);\n    sycl::range<2> lws(localWorkSize[1], localWorkSize[0]);\n\n    bool cpu_run = false, gpu_run = false;\n    if (cpu_global_size[0] > 0) {\n      cpu_run = true;\n    }\n    if (gpu_global_size[0] > 0) {\n      gpu_run = true;\n    }\n\n    \n\n    double co_start = rtclock();\n\n    if (gpu_run) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class winograd_conv2d>(\n          sycl::nd_range<2>(gpu_gws, lws), [=] (sycl::nd_item<2> item) {\n\n          int tile_j = item.get_global_id(0) + offset_j;\n          int tile_i = item.get_global_id(1) + offset_i;\n\n          \n\n\n          DATA_TYPE d_A_tile[4][4], tmp_tile[4][4], transformed_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) {\n              int x = 2 * tile_i + i;\n              int y = 2 * tile_j + j;\n              if (x >= MAP_SIZE || y >= MAP_SIZE) {\n                d_A_tile[i][j] = 0;\n                continue;\n              }\n              d_A_tile[i][j] = d_A[x * MAP_SIZE + y];\n            }\n          }\n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile[0][j] = d_A_tile[0][j] - d_A_tile[2][j];\n            tmp_tile[1][j] = d_A_tile[1][j] + d_A_tile[2][j];\n            tmp_tile[2][j] = -d_A_tile[1][j] + d_A_tile[2][j];\n            tmp_tile[3][j] = d_A_tile[1][j] - d_A_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 4; i ++) {\n            transformed_tile[i][0] = tmp_tile[i][0] - tmp_tile[i][2];\n            transformed_tile[i][1] = tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][2] = -tmp_tile[i][1] + tmp_tile[i][2];\n            transformed_tile[i][3] = tmp_tile[i][1] - tmp_tile[i][3];\n          }\n\n          \n\n\n          DATA_TYPE multiplied_tile[4][4];\n          for (int i = 0; i < 4; i ++) {\n            for (int j = 0; j < 4; j ++) {\n              multiplied_tile[i][j] = transformed_tile[i][j] * d_C[i * 4 + j];\n            }\n          }\n\n          \n\n\n          DATA_TYPE tmp_tile_1[2][4], final_tile[2][2];\n\n          \n\n          for (int j = 0; j < 4; j ++) {\n            tmp_tile_1[0][j] = multiplied_tile[0][j] + multiplied_tile[1][j] + multiplied_tile[2][j];\n            tmp_tile_1[1][j] = multiplied_tile[1][j] - multiplied_tile[2][j] - multiplied_tile[3][j];\n          }\n          \n\n          for (int i = 0; i < 2; i ++) {\n            final_tile[i][0] = tmp_tile_1[i][0] + tmp_tile_1[i][1] + tmp_tile_1[i][2];\n            final_tile[i][1] = tmp_tile_1[i][1] - tmp_tile_1[i][2] - tmp_tile_1[i][3];\n          }\n\n          for (int i = 0; i < 2; i ++) {\n            for (int j = 0; j < 2; j ++) {\n              int x = 2 * tile_i + i;\n              int y = 2 * tile_j + j;\n              if (x >= MAP_SIZE - 2 || y >= MAP_SIZE - 2) {\n                continue;\n              }\n              d_B[x * (MAP_SIZE - 2) + y] = final_tile[i][j];\n            }\n          }\n        });\n      });\n\n    }\n\n    if (cpu_run) {\n\n      \n\n      WinogradConv2D_2x2_omp(A, B, C, cpu_global_size);\n\n      q.memcpy(d_B, B, gpu_run ? cpu_global_size[0]*2*(MAP_SIZE-2)*sizeof(DATA_TYPE) : \n               (MAP_SIZE-2)*(MAP_SIZE-2)*sizeof(DATA_TYPE));\n    }\n\n    q.memcpy(B_outputFromGpu, d_B, (MAP_SIZE-2) * (MAP_SIZE-2) * sizeof(DATA_TYPE)).wait();\n\n    co_time += rtclock() - co_start;\n\n#ifdef VERBOSE\n    if (cpu_run) printf(\"run on host\\n\");\n    if (gpu_run) printf(\"run on device\\n\");\n    printf(\"CPU workload size : %d\\n\", cpu_offset);\n#endif\n\n    WinogradConv2D_2x2(A, B, C);\n    pass &= compareResults(B, B_outputFromGpu);\n\n  } \n\n\n  printf(\"%s\\n\", pass ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_A, q);\n  sycl::free(d_B, q);\n  sycl::free(d_C, q);\n  free(A);\n  free(B);\n  free(B_outputFromGpu);\n  free(C);\n\n  double end = rtclock();\n  printf(\"Co-execution time: %lf s\\n\", co_time);\n  printf(\"Total time: %lf s\\n\", end - start);\n  printf(\"Ratio of co-execution time to total time: %.2lf%%\\n\",\n         100.0 * co_time / (end - start));\n\n  return 0;\n}\n"}}
