{"kernel_name": "all-pairs-distance", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cuda.h>\n#include <sys/time.h>\n\n#define INSTANCES 224   \n\n#define ATTRIBUTES 4096 \n\n#define THREADS 128    \n\n\n\n\nvoid CPU(int * data, int * distance) {\n  \n\n#pragma omp parallel for collapse(2)\n  for (int i = 0; i < INSTANCES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      for (int k = 0; k < ATTRIBUTES; k++) {\n        distance[i + INSTANCES * j] += \n          (data[i * ATTRIBUTES + k] != data[j * ATTRIBUTES + k]);\n      }\n    }\n  }\n}\n\n\n\n\n__global__ void GPUregister(const char *data, int *distance) {\n  int idx = threadIdx.x;\n  int gx = blockIdx.x;\n  int gy = blockIdx.y;\n\n  for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n    char4 j = *(char4 *)(data + i + ATTRIBUTES*gx);\n    char4 k = *(char4 *)(data + i + ATTRIBUTES*gy);\n\n    \n\n    char count = 0;\n\n    if(j.x ^ k.x) \n      count++; \n    if(j.y ^ k.y)\n      count++;\n    if(j.z ^ k.z)\n      count++;\n    if(j.w ^ k.w)\n      count++;\n\n    \n\n    atomicAdd(distance + INSTANCES*gx + gy, count);\n  }\n}\n\n\n\n__global__ void GPUshared(const char *data, int *distance) {\n  int idx = threadIdx.x;\n  int gx = blockIdx.x;\n  int gy = blockIdx.y;\n\n  \n\n  __shared__ int dist[THREADS];\n\n  \n \n  dist[idx] = 0;\n\n  \n\n  __syncthreads();\n\n  for(int i = idx*4; i < ATTRIBUTES; i+=THREADS*4) {\n    char4 j = *(char4 *)(data + i + ATTRIBUTES*gx);\n    char4 k = *(char4 *)(data + i + ATTRIBUTES*gy);\n    char count = 0;\n\n    if(j.x ^ k.x) \n      count++;\n    if(j.y ^ k.y)\n      count++;\n    if(j.z ^ k.z)\n      count++;\n    if(j.w ^ k.w)\n      count++;\n\n    \n\n    dist[idx] += count;\n  }\n\n  \n\n  __syncthreads();\n\n  \n \n  if(idx == 0) {\n    for(int i = 1; i < THREADS; i++) {\n      dist[0] += dist[i];\n    }\n\n    \n\n    distance[INSTANCES*gy + gx] = dist[0];\n  }\n}\n\nint main(int argc, char **argv) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]);\n\n  \n\n  int *data; \n  char *data_char;\n  int *cpu_distance; \n  int *gpu_distance; \n\n  \n\n  char *data_char_device;\n  int *distance_device; \n\n  \n\n  dim3 dimBlock; \n  dim3 dimGrid; \n\n  \n\n  double start_cpu, stop_cpu;\n  double start_gpu, stop_gpu;\n  float elapsedTime; \n  struct timeval tp;\n  struct timezone tzp;\n  \n \n  int status;\n\n  \n\n  srand(2);\n\n  \n\n  data = (int *)malloc(INSTANCES * ATTRIBUTES * sizeof(int));\n  data_char = (char *)malloc(INSTANCES * ATTRIBUTES * sizeof(char));\n  cpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n  gpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n\n  \n\n#pragma omp parallel for collapse(2)\n  for (int i = 0; i < ATTRIBUTES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      data[i + ATTRIBUTES * j] = data_char[i + ATTRIBUTES * j] = random() % 3;\n    }\n  }\n\n  \n\n  cudaMalloc((void **)&data_char_device, \n      INSTANCES * ATTRIBUTES * sizeof(char));\n\n  cudaMalloc((void **)&distance_device, \n      INSTANCES * INSTANCES * sizeof(int));\n\n  cudaMemcpy(data_char_device, data_char,\n      INSTANCES * ATTRIBUTES * sizeof(char),\n      cudaMemcpyHostToDevice);\n\n  \n\n  dimBlock.x = THREADS; \n  dimBlock.y = 1; \n  dimGrid.x = INSTANCES;\n  dimGrid.y = INSTANCES;\n\n\n  \n\n  bzero(cpu_distance,INSTANCES*INSTANCES*sizeof(int));\n  gettimeofday(&tp, &tzp);\n  start_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  CPU(data, cpu_distance);\n  gettimeofday(&tp, &tzp);\n  stop_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  elapsedTime = stop_cpu - start_cpu;\n  printf(\"CPU time: %f (us)\\n\",elapsedTime);\n\n  elapsedTime = 0; \n  for (int n = 0; n < iterations; n++) {\n    \n\n    bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n    cudaMemcpy(distance_device, gpu_distance,\n               INSTANCES * INSTANCES * sizeof(int), cudaMemcpyHostToDevice);\n\n    gettimeofday(&tp, &tzp);\n    start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n\n    GPUregister<<<dimGrid,dimBlock>>>(data_char_device, distance_device);\n    cudaDeviceSynchronize();\n\n    gettimeofday(&tp, &tzp);\n    stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n    elapsedTime += stop_gpu - start_gpu;\n\n    cudaMemcpy(gpu_distance, distance_device,\n               INSTANCES * INSTANCES * sizeof(int), cudaMemcpyDeviceToHost); \n  }\n\n  printf(\"Average kernel execution time (w/o shared memory): %f (us)\\n\", elapsedTime / iterations);\n  status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n  if (status != 0) printf(\"FAIL\\n\");\n  else printf(\"PASS\\n\");\n\n  elapsedTime = 0; \n  for (int n = 0; n < iterations; n++) {\n    \n\n    bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n    cudaMemcpy(distance_device, gpu_distance,\n               INSTANCES * INSTANCES * sizeof(int), cudaMemcpyHostToDevice);\n\n    gettimeofday(&tp, &tzp);\n    start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n\n    GPUshared<<<dimGrid,dimBlock>>>(data_char_device, distance_device);\n    cudaDeviceSynchronize();\n\n    gettimeofday(&tp, &tzp);\n    stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n    elapsedTime += stop_gpu - start_gpu;\n\n    cudaMemcpy(gpu_distance, distance_device,\n               INSTANCES * INSTANCES * sizeof(int), cudaMemcpyDeviceToHost); \n  }\n\n  printf(\"Average kernel execution time (w/ shared memory): %f (us)\\n\", elapsedTime / iterations);\n  status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n  if (status != 0) printf(\"FAIL\\n\");\n  else printf(\"PASS\\n\");\n\n  free(cpu_distance);\n  free(gpu_distance);\n  free(data);\n  free(data_char);\n  cudaFree(data_char_device);\n  cudaFree(distance_device);\n\n  return status;\n}\n"}}
{"kernel_name": "all-pairs-distance", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <hip/hip_runtime.h>\n#include <sys/time.h>\n\n#define INSTANCES 224   \n\n#define ATTRIBUTES 4096 \n\n#define THREADS 128    \n\n\n\n\nvoid CPU(int * data, int * distance) {\n  \n\n#pragma omp parallel for collapse(2)\n  for (int i = 0; i < INSTANCES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      for (int k = 0; k < ATTRIBUTES; k++) {\n        distance[i + INSTANCES * j] += \n          (data[i * ATTRIBUTES + k] != data[j * ATTRIBUTES + k]);\n      }\n    }\n  }\n}\n\n\n\n\n__global__ void GPUregister(const char *data, int *distance) {\n  int idx = threadIdx.x;\n  int gx = blockIdx.x;\n  int gy = blockIdx.y;\n\n  for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n    char4 j = *(char4 *)(data + i + ATTRIBUTES*gx);\n    char4 k = *(char4 *)(data + i + ATTRIBUTES*gy);\n\n    \n\n    char count = 0;\n\n    if(j.x ^ k.x) \n      count++; \n    if(j.y ^ k.y)\n      count++;\n    if(j.z ^ k.z)\n      count++;\n    if(j.w ^ k.w)\n      count++;\n\n    \n\n    atomicAdd(distance + INSTANCES*gx + gy, count);\n  }\n}\n\n\n\n__global__ void GPUshared(const char *data, int *distance) {\n  int idx = threadIdx.x;\n  int gx = blockIdx.x;\n  int gy = blockIdx.y;\n\n  \n\n  __shared__ int dist[THREADS];\n\n  \n \n  dist[idx] = 0;\n\n  \n\n  __syncthreads();\n\n  for(int i = idx*4; i < ATTRIBUTES; i+=THREADS*4) {\n    char4 j = *(char4 *)(data + i + ATTRIBUTES*gx);\n    char4 k = *(char4 *)(data + i + ATTRIBUTES*gy);\n    char count = 0;\n\n    if(j.x ^ k.x) \n      count++;\n    if(j.y ^ k.y)\n      count++;\n    if(j.z ^ k.z)\n      count++;\n    if(j.w ^ k.w)\n      count++;\n\n    \n\n    dist[idx] += count;\n  }\n\n  \n\n  __syncthreads();\n\n  \n \n  if(idx == 0) {\n    for(int i = 1; i < THREADS; i++) {\n      dist[0] += dist[i];\n    }\n\n    \n\n    distance[INSTANCES*gy + gx] = dist[0];\n  }\n}\n\nint main(int argc, char **argv) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]);\n\n  \n\n  int *data; \n  char *data_char;\n  int *cpu_distance; \n  int *gpu_distance; \n\n  \n\n  char *data_char_device;\n  int *distance_device; \n\n  \n\n  dim3 dimBlock; \n  dim3 dimGrid; \n\n  \n\n  double start_cpu, stop_cpu;\n  double start_gpu, stop_gpu;\n  float elapsedTime; \n  struct timeval tp;\n  struct timezone tzp;\n  \n \n  int status;\n\n  \n\n  srand(2);\n\n  \n\n  data = (int *)malloc(INSTANCES * ATTRIBUTES * sizeof(int));\n  data_char = (char *)malloc(INSTANCES * ATTRIBUTES * sizeof(char));\n  cpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n  gpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n\n  \n\n#pragma omp parallel for collapse(2)\n  for (int i = 0; i < ATTRIBUTES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      data[i + ATTRIBUTES * j] = data_char[i + ATTRIBUTES * j] = random() % 3;\n    }\n  }\n\n  \n\n  hipMalloc((void **)&data_char_device, \n      INSTANCES * ATTRIBUTES * sizeof(char));\n\n  hipMalloc((void **)&distance_device, \n      INSTANCES * INSTANCES * sizeof(int));\n\n  hipMemcpy(data_char_device, data_char,\n      INSTANCES * ATTRIBUTES * sizeof(char),\n      hipMemcpyHostToDevice);\n\n  \n\n  dimBlock.x = THREADS; \n  dimBlock.y = 1; \n  dimGrid.x = INSTANCES;\n  dimGrid.y = INSTANCES;\n\n\n  \n\n  bzero(cpu_distance,INSTANCES*INSTANCES*sizeof(int));\n  gettimeofday(&tp, &tzp);\n  start_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  CPU(data, cpu_distance);\n  gettimeofday(&tp, &tzp);\n  stop_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  elapsedTime = stop_cpu - start_cpu;\n  printf(\"CPU time: %f (us)\\n\",elapsedTime);\n\n  elapsedTime = 0; \n  for (int n = 0; n < iterations; n++) {\n    \n\n    bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n    hipMemcpy(distance_device, gpu_distance,\n               INSTANCES * INSTANCES * sizeof(int), hipMemcpyHostToDevice);\n\n    gettimeofday(&tp, &tzp);\n    start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n\n    hipLaunchKernelGGL(GPUregister, dimGrid, dimBlock, 0, 0, data_char_device, distance_device);\n    hipDeviceSynchronize();\n\n    gettimeofday(&tp, &tzp);\n    stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n    elapsedTime += stop_gpu - start_gpu;\n\n    hipMemcpy(gpu_distance, distance_device,\n               INSTANCES * INSTANCES * sizeof(int), hipMemcpyDeviceToHost); \n  }\n\n  printf(\"Average kernel execution time (w/o shared memory): %f (us)\\n\", elapsedTime / iterations);\n  status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n  if (status != 0) printf(\"FAIL\\n\");\n  else printf(\"PASS\\n\");\n\n  elapsedTime = 0; \n  for (int n = 0; n < iterations; n++) {\n    \n\n    bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n    hipMemcpy(distance_device, gpu_distance,\n               INSTANCES * INSTANCES * sizeof(int), hipMemcpyHostToDevice);\n\n    gettimeofday(&tp, &tzp);\n    start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n\n    hipLaunchKernelGGL(GPUshared, dimGrid, dimBlock, 0, 0, data_char_device, distance_device);\n    hipDeviceSynchronize();\n\n    gettimeofday(&tp, &tzp);\n    stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n    elapsedTime += stop_gpu - start_gpu;\n\n    hipMemcpy(gpu_distance, distance_device,\n               INSTANCES * INSTANCES * sizeof(int), hipMemcpyDeviceToHost); \n  }\n\n  printf(\"Average kernel execution time (w/ shared memory): %f (us)\\n\", elapsedTime / iterations);\n  status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n  if (status != 0) printf(\"FAIL\\n\");\n  else printf(\"PASS\\n\");\n\n  free(cpu_distance);\n  free(gpu_distance);\n  free(data);\n  free(data_char);\n  hipFree(data_char_device);\n  hipFree(distance_device);\n\n  return status;\n}\n\n\n"}}
{"kernel_name": "all-pairs-distance", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <omp.h>\n#include <sys/time.h>\n\n#define INSTANCES 224   \n\n#define ATTRIBUTES 4096 \n\n#define THREADS 128    \n\n\nstruct char4 { char x; char y; char z; char w; };\n\n\n\n\nvoid CPU(int * data, int * distance) {\n  \n\n  #pragma omp parallel for collapse(2)\n  for (int i = 0; i < INSTANCES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      for (int k = 0; k < ATTRIBUTES; k++) {\n        distance[i + INSTANCES * j] += \n          (data[i * ATTRIBUTES + k] != data[j * ATTRIBUTES + k]);\n      }\n    }\n  }\n}\n\nint main(int argc, char **argv) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]);\n\n  \n\n  int *data; \n  char *data_char;\n  int *cpu_distance, *gpu_distance;\n\n  \n\n  double start_cpu, stop_cpu;\n  double start_gpu, stop_gpu;\n  double elapsedTime; \n  struct timeval tp;\n  struct timezone tzp;\n  \n \n  int status;\n\n  \n\n  srand(2);\n\n  \n\n  data = (int *)malloc(INSTANCES * ATTRIBUTES * sizeof(int));\n  data_char = (char *)malloc(INSTANCES * ATTRIBUTES * sizeof(char));\n  cpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n  gpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n\n  \n\n  #pragma omp parallel for collapse(2)\n  for (int i = 0; i < ATTRIBUTES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      data[i + ATTRIBUTES * j] = data_char[i + ATTRIBUTES * j] = random() % 3;\n    }\n  }\n\n  \n\n  bzero(cpu_distance,INSTANCES*INSTANCES*sizeof(int));\n  gettimeofday(&tp, &tzp);\n  start_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  CPU(data, cpu_distance);\n  gettimeofday(&tp, &tzp);\n  stop_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  elapsedTime = stop_cpu - start_cpu;\n  printf(\"CPU time: %f (us)\\n\",elapsedTime);\n\n  #pragma omp target data map(to: data_char[0:INSTANCES * ATTRIBUTES]) \\\n                          map(alloc: gpu_distance[0:INSTANCES * INSTANCES ])\n  {\n    for (int n = 0; n < iterations; n++) {\n      \n\n      bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n      #pragma omp target update to (gpu_distance[0:INSTANCES * INSTANCES])\n  \n      gettimeofday(&tp, &tzp);\n      start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n  \n      #pragma omp target teams num_teams(INSTANCES*INSTANCES) thread_limit(THREADS)\n      {\n        #pragma omp parallel\n        {\n          int idx = omp_get_thread_num();\n          int gx = omp_get_team_num() % INSTANCES;\n          int gy = omp_get_team_num() / INSTANCES;\n      \n          for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n            char4 j = *(char4 *)(data_char + i + ATTRIBUTES*gx);\n            char4 k = *(char4 *)(data_char + i + ATTRIBUTES*gy);\n      \n            \n\n            char count = 0;\n      \n            if(j.x ^ k.x) \n              count++; \n            if(j.y ^ k.y)\n              count++;\n            if(j.z ^ k.z)\n              count++;\n            if(j.w ^ k.w)\n              count++;\n      \n            \n\n            #pragma omp atomic update\n            gpu_distance[ INSTANCES*gx + gy ] += count;\n          }\n        }\n      }\n  \n      gettimeofday(&tp, &tzp);\n      stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n      elapsedTime += stop_gpu - start_gpu;\n  \n      #pragma omp target update from (gpu_distance[0:INSTANCES * INSTANCES])\n    }\n  \n    printf(\"Average kernel execution time (w/o shared memory): %f (us)\\n\", elapsedTime / iterations);\n    status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n    if (status != 0) printf(\"FAIL\\n\");\n    else printf(\"PASS\\n\");\n  \n    elapsedTime = 0; \n    for (int n = 0; n < iterations; n++) {\n      \n\n      bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n      #pragma omp target update to (gpu_distance[0:INSTANCES * INSTANCES])\n  \n      gettimeofday(&tp, &tzp);\n      start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n  \n      #pragma omp target teams num_teams(INSTANCES*INSTANCES) thread_limit(THREADS)\n      {\n        int dist[THREADS];\n        #pragma omp parallel\n        {\n          int idx = omp_get_thread_num();\n          int gx = omp_get_team_num() % INSTANCES;\n          int gy = omp_get_team_num() / INSTANCES;\n      \n          dist[idx] = 0;\n          #pragma omp barrier\n      \n          for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n            char4 j = *(char4 *)(data_char + i + ATTRIBUTES*gx);\n            char4 k = *(char4 *)(data_char + i + ATTRIBUTES*gy);\n      \n            \n\n            char count = 0;\n      \n            if(j.x ^ k.x) \n              count++; \n            if(j.y ^ k.y)\n              count++;\n            if(j.z ^ k.z)\n              count++;\n            if(j.w ^ k.w)\n              count++;\n      \n            dist[idx] += count;\n          }\n      \n        \n\n          #pragma omp barrier\n      \n        \n \n          if(idx == 0) {\n            for(int i = 1; i < THREADS; i++) {\n              dist[0] += dist[i];\n            }\n      \n            \n\n            gpu_distance[INSTANCES*gy + gx] = dist[0];\n          }\n        }\n      }\n  \n      gettimeofday(&tp, &tzp);\n      stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n      elapsedTime += stop_gpu - start_gpu;\n  \n      #pragma omp target update from (gpu_distance[0:INSTANCES * INSTANCES])\n    }\n  \n    printf(\"Average kernel execution time (w/ shared memory): %f (us)\\n\", elapsedTime / iterations);\n    status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n    if (status != 0) printf(\"FAIL\\n\");\n    else printf(\"PASS\\n\");\n  }\n\n  free(cpu_distance);\n  free(gpu_distance);\n  free(data_char);\n  free(data);\n  return status;\n}\n"}}
{"kernel_name": "all-pairs-distance", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <sys/time.h>\n\n#define INSTANCES 224   \n\n#define ATTRIBUTES 4096 \n\n#define THREADS 128    \n\n\nstruct char4 { char x; char y; char z; char w; };\n\n\n\n\nvoid CPU(int * data, int * distance) {\n  \n\n    for (int i = 0; i < INSTANCES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      for (int k = 0; k < ATTRIBUTES; k++) {\n        distance[i + INSTANCES * j] += \n          (data[i * ATTRIBUTES + k] != data[j * ATTRIBUTES + k]);\n      }\n    }\n  }\n}\n\nint main(int argc, char **argv) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]);\n\n  \n\n  int *data; \n  char *data_char;\n  int *cpu_distance, *gpu_distance;\n\n  \n\n  double start_cpu, stop_cpu;\n  double start_gpu, stop_gpu;\n  double elapsedTime; \n  struct timeval tp;\n  struct timezone tzp;\n  \n \n  int status;\n\n  \n\n  srand(2);\n\n  \n\n  data = (int *)malloc(INSTANCES * ATTRIBUTES * sizeof(int));\n  data_char = (char *)malloc(INSTANCES * ATTRIBUTES * sizeof(char));\n  cpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n  gpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n\n  \n\n    for (int i = 0; i < ATTRIBUTES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      data[i + ATTRIBUTES * j] = data_char[i + ATTRIBUTES * j] = random() % 3;\n    }\n  }\n\n  \n\n  bzero(cpu_distance,INSTANCES*INSTANCES*sizeof(int));\n  gettimeofday(&tp, &tzp);\n  start_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  CPU(data, cpu_distance);\n  gettimeofday(&tp, &tzp);\n  stop_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  elapsedTime = stop_cpu - start_cpu;\n  printf(\"CPU time: %f (us)\\n\",elapsedTime);\n\n    {\n    for (int n = 0; n < iterations; n++) {\n      \n\n      bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n        \n      gettimeofday(&tp, &tzp);\n      start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n  \n            {\n                {\n          int idx = omp_get_thread_num();\n          int gx = omp_get_team_num() % INSTANCES;\n          int gy = omp_get_team_num() / INSTANCES;\n      \n          for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n            char4 j = *(char4 *)(data_char + i + ATTRIBUTES*gx);\n            char4 k = *(char4 *)(data_char + i + ATTRIBUTES*gy);\n      \n            \n\n            char count = 0;\n      \n            if(j.x ^ k.x) \n              count++; \n            if(j.y ^ k.y)\n              count++;\n            if(j.z ^ k.z)\n              count++;\n            if(j.w ^ k.w)\n              count++;\n      \n            \n\n                        gpu_distance[ INSTANCES*gx + gy ] += count;\n          }\n        }\n      }\n  \n      gettimeofday(&tp, &tzp);\n      stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n      elapsedTime += stop_gpu - start_gpu;\n  \n          }\n  \n    printf(\"Average kernel execution time (w/o shared memory): %f (us)\\n\", elapsedTime / iterations);\n    status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n    if (status != 0) printf(\"FAIL\\n\");\n    else printf(\"PASS\\n\");\n  \n    elapsedTime = 0; \n    for (int n = 0; n < iterations; n++) {\n      \n\n      bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n        \n      gettimeofday(&tp, &tzp);\n      start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n  \n            {\n        int dist[THREADS];\n                {\n          int idx = omp_get_thread_num();\n          int gx = omp_get_team_num() % INSTANCES;\n          int gy = omp_get_team_num() / INSTANCES;\n      \n          dist[idx] = 0;\n                \n          for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n            char4 j = *(char4 *)(data_char + i + ATTRIBUTES*gx);\n            char4 k = *(char4 *)(data_char + i + ATTRIBUTES*gy);\n      \n            \n\n            char count = 0;\n      \n            if(j.x ^ k.x) \n              count++; \n            if(j.y ^ k.y)\n              count++;\n            if(j.z ^ k.z)\n              count++;\n            if(j.w ^ k.w)\n              count++;\n      \n            dist[idx] += count;\n          }\n      \n        \n\n                \n        \n \n          if(idx == 0) {\n            for(int i = 1; i < THREADS; i++) {\n              dist[0] += dist[i];\n            }\n      \n            \n\n            gpu_distance[INSTANCES*gy + gx] = dist[0];\n          }\n        }\n      }\n  \n      gettimeofday(&tp, &tzp);\n      stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n      elapsedTime += stop_gpu - start_gpu;\n  \n          }\n  \n    printf(\"Average kernel execution time (w/ shared memory): %f (us)\\n\", elapsedTime / iterations);\n    status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n    if (status != 0) printf(\"FAIL\\n\");\n    else printf(\"PASS\\n\");\n  }\n\n  free(cpu_distance);\n  free(gpu_distance);\n  free(data_char);\n  free(data);\n  return status;\n}"}}
{"kernel_name": "all-pairs-distance", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <sys/time.h>\n#include <sycl/sycl.hpp>\n\n#ifdef __NVPTX__\n  #include <sycl/ext/oneapi/experimental/cuda/builtins.hpp>\n  using namespace sycl::ext::oneapi::experimental::cuda;\n#else\n  #define ldg(a) (*(a))\n#endif\n\n#define INSTANCES 224   \n\n#define ATTRIBUTES 4096 \n\n#define THREADS 128    \n\n\n\n\nvoid CPU(int * data, int * distance) {\n  \n\n#pragma omp parallel for collapse(2)\n  for (int i = 0; i < INSTANCES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      for (int k = 0; k < ATTRIBUTES; k++) {\n        distance[i + INSTANCES * j] += \n          (data[i * ATTRIBUTES + k] != data[j * ATTRIBUTES + k]);\n      }\n    }\n  }\n}\n\nint main(int argc, char **argv) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]);\n\n  \n\n  int *data; \n  char *data_char;\n  int *cpu_distance; \n  int *gpu_distance; \n\n  \n\n  double start_cpu, stop_cpu;\n  double start_gpu, stop_gpu;\n  float elapsedTime; \n  struct timeval tp;\n  struct timezone tzp;\n  \n \n  int status;\n\n  \n\n  srand(2);\n\n  \n\n  const size_t distance_bytes = INSTANCES * INSTANCES * sizeof(int);\n  const size_t int32_data_bytes = INSTANCES * ATTRIBUTES * sizeof(int);\n  const size_t int8_data_bytes = INSTANCES * ATTRIBUTES * sizeof(char);\n\n  data = (int *)malloc(int32_data_bytes);\n  data_char = (char *)malloc(int8_data_bytes);\n  cpu_distance = (int *)malloc(distance_bytes);\n  gpu_distance = (int *)malloc(distance_bytes);\n\n  \n\n#pragma omp parallel for collapse(2)\n  for (int i = 0; i < ATTRIBUTES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      data[i + ATTRIBUTES * j] = data_char[i + ATTRIBUTES * j] = random() % 3;\n    }\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  char *d_data = sycl::malloc_device<char>(INSTANCES * ATTRIBUTES, q);\n  q.memcpy(d_data, data_char, int8_data_bytes);\n\n  int *d_distance = sycl::malloc_device<int>(INSTANCES * INSTANCES, q);\n\n  sycl::range<2> gws (INSTANCES, INSTANCES*THREADS);\n  sycl::range<2> lws (1, THREADS);\n\n  \n\n  bzero(cpu_distance,INSTANCES*INSTANCES*sizeof(int));\n  gettimeofday(&tp, &tzp);\n  start_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  CPU(data, cpu_distance);\n  gettimeofday(&tp, &tzp);\n  stop_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  elapsedTime = stop_cpu - start_cpu;\n  printf(\"CPU time: %f (us)\\n\",elapsedTime);\n\n  elapsedTime = 0; \n  for (int n = 0; n < iterations; n++) {\n    \n\n    bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n\n    q.memcpy(d_distance, gpu_distance, distance_bytes).wait();\n\n    gettimeofday(&tp, &tzp);\n    start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n\n    q.submit([&] (sycl::handler &h) {\n      h.parallel_for<class GPUregister>(\n        sycl::nd_range<2> (gws, lws), [=] (sycl::nd_item<2> item) {\n        int idx = item.get_local_id(1);\n        int gx = item.get_group(1);\n        int gy = item.get_group(0);\n\n        for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n          sycl::char4 j = ldg((sycl::char4 *)(d_data + i + ATTRIBUTES*gx));\n          sycl::char4 k = ldg((sycl::char4 *)(d_data + i + ATTRIBUTES*gy));\n\n        \n\n          int count = 0;\n\n          if(j.x() ^ k.x()) \n            count++; \n          if(j.y() ^ k.y())\n            count++;\n          if(j.z() ^ k.z())\n            count++;\n          if(j.w() ^ k.w())\n            count++;\n\n          \n\n          auto ao = sycl::atomic_ref<int, \n            sycl::memory_order::relaxed,\n            sycl::memory_scope::device,\n            sycl::access::address_space::global_space> (d_distance[INSTANCES*gx + gy]);\n           \n          ao.fetch_add(count);\n        }\n      });\n    }).wait();\n\n    gettimeofday(&tp, &tzp);\n    stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n    elapsedTime += stop_gpu - start_gpu;\n\n    q.memcpy(gpu_distance, d_distance, distance_bytes).wait();\n  }\n\n  printf(\"Average kernel execution time (w/o shared memory): %f (us)\\n\", elapsedTime / iterations);\n  status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n  if (status != 0) printf(\"FAIL\\n\");\n  else printf(\"PASS\\n\");\n\n  elapsedTime = 0; \n  for (int n = 0; n < iterations; n++) {\n    \n\n    bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n\n    q.memcpy(d_distance, gpu_distance, distance_bytes).wait();\n\n    gettimeofday(&tp, &tzp);\n    start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n\n    \n\n    q.submit([&] (sycl::handler &h) {\n      sycl::local_accessor<int, 1> dist(sycl::range<1>(THREADS), h); \n      h.parallel_for<class GPUshared>(\n        sycl::nd_range<2> (gws, lws), [=] (sycl::nd_item<2> item) {\n        int idx = item.get_local_id(1);\n        int gx = item.get_group(1);\n        int gy = item.get_group(0);\n\n        \n \n        dist[idx] = 0;\n\n        \n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        for(int i = idx*4; i < ATTRIBUTES; i+=THREADS*4) {\n          sycl::char4 j = ldg((sycl::char4 *)(d_data + i + ATTRIBUTES*gx));\n          sycl::char4 k = ldg((sycl::char4 *)(d_data + i + ATTRIBUTES*gy));\n\n        \n\n          char count = 0;\n          if(j.x() ^ k.x()) \n            count++; \n          if(j.y() ^ k.y())\n            count++;\n          if(j.z() ^ k.z())\n            count++;\n          if(j.w() ^ k.w())\n            count++;\n\n          \n\n          dist[idx] += count;\n        }\n\n        \n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        \n \n        if(idx == 0) {\n          for(int i = 1; i < THREADS; i++) {\n            dist[0] += dist[i];\n          }\n\n          \n\n          d_distance[INSTANCES*gy + gx] = dist[0];\n        }\n      });\n    }).wait();\n\n    gettimeofday(&tp, &tzp);\n    stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n    elapsedTime += stop_gpu - start_gpu;\n\n    q.memcpy(gpu_distance, d_distance, distance_bytes).wait();\n  }\n\n  printf(\"Average kernel execution time (w/ shared memory): %f (us)\\n\", elapsedTime / iterations);\n  status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n  if (status != 0) printf(\"FAIL\\n\");\n  else printf(\"PASS\\n\");\n\n  free(cpu_distance);\n  free(gpu_distance);\n  free(data);\n  free(data_char);\n  sycl::free(d_data, q);\n  sycl::free(d_distance, q);\n\n  return status;\n}\n"}}
{"kernel_name": "diamond", "parallel_api": "cuda", "code": {"masking.cu": "\n\n#include <cuda.h>\n#include \"../diamond-sycl/src/basic/masking.h\"\n\n\n#define SEQ_LEN 33\n\n__device__\ninline double firstRepeatOffsetProb(const double probMult, const int maxRepeatOffset) {\n  if (probMult < 1 || probMult > 1)\n    return (1 - probMult) / (1 - pow(probMult, (double)maxRepeatOffset));\n  else\n    return 1.0 / maxRepeatOffset;\n}\n\n__device__\nvoid maskProbableLetters(const int size,\n    unsigned char *seqBeg,\n    const float *probabilities, \n    const unsigned char *maskTable) {\n\n  const double minMaskProb = 0.5;\n  for (int i=0; i<size; i++)\n    if (probabilities[i] >= minMaskProb)\n      seqBeg[i] = maskTable[seqBeg[i]];\n}\n\n__device__\nint calcRepeatProbs(float *letterProbs,\n    const unsigned char *seqBeg, \n    const int size, \n    const int maxRepeatOffset,\n    const double *likelihoodRatioMatrix, \n\n    const double b2b,\n    const double f2f0,\n    const double f2b,\n    const double b2fLast_inv,\n    const double *pow_lkp,\n    double *foregroundProbs,\n    const int scaleStepSize,\n    double *scaleFactors)\t\t      \t\n{\n\n  double backgroundProb = 1.0;\n  for (int k=0; k < size ; k++) {\n\n    const int v0 = seqBeg[k];\n    const int k_cap = k < maxRepeatOffset ? k : maxRepeatOffset;\n\n    const int pad1 = k_cap - 1;\n    const int pad2 = maxRepeatOffset - k_cap; \n\n    const int pad3 = k - k_cap;               \n\n\n    double accu = 0;\n\n    for (int i = 0; i < k; i++) {\n\n      const int idx1 = pad1 - i;\n      const int idx2 = pad2 + i;\n      const int idx3 = pad3 + i;\n\n      const int v1 = seqBeg[idx3];\n      accu += foregroundProbs[idx1];\n      foregroundProbs[idx1] = ( (f2f0 * foregroundProbs[idx1]) +  \n          (backgroundProb * pow_lkp[idx2]) ) * \n        likelihoodRatioMatrix[v0*size+v1];\n    }\n\n    backgroundProb = (backgroundProb * b2b) + (accu * f2b);\n\n    if (k % scaleStepSize == scaleStepSize - 1) {\n      const double scale = 1 / backgroundProb;\n      scaleFactors[k / scaleStepSize] = scale;\n\n      for (int i=0; i< k_cap; i++)\n        foregroundProbs[i] = foregroundProbs[i] * scale;\n\n      backgroundProb = 1;\n    }\n\n    letterProbs[k] = (float)(backgroundProb);\n  }\n\n  double accu = 0;\n  for (int i=0 ; i < maxRepeatOffset; i++) {\n    accu += foregroundProbs[i];\n    foregroundProbs[i] = f2b;\n  }\n\n  const double fTot = backgroundProb * b2b + accu * f2b;\n  backgroundProb = b2b;\n\n  const double fTot_inv = 1/ fTot ;\n  for (int k=(size-1) ; k >= 0 ; k--){\n\n\n    double nonRepeatProb = letterProbs[k] * backgroundProb * fTot_inv;\n    letterProbs[k] = 1 - (float)(nonRepeatProb);\n\n    \n\n    const int k_cap = k < maxRepeatOffset ? k : maxRepeatOffset;\n\n    if (k % scaleStepSize == scaleStepSize - 1) {\n      const double scale = scaleFactors[k/ scaleStepSize];\n\n      for (int i=0; i< k_cap; i++)\n        foregroundProbs[i] = foregroundProbs[i] * scale;\n\n      backgroundProb *= scale;\n    }\n\n    const double c0 = f2b * backgroundProb;\n    const int v0= seqBeg[k];\n\n    double accu = 0;\n    for (int i = 0; i < k_cap; i++) {\n\n\n      const int v1 =  seqBeg[k-(i+1)];\n      const double f = foregroundProbs[i] * likelihoodRatioMatrix[v0*size+v1];\n\n      accu += pow_lkp[k_cap-(i+1)]*f;\n      foregroundProbs[i] = c0 + f2f0 * f;\n    }\n\n    const double p = k > maxRepeatOffset ? 1. : pow_lkp[maxRepeatOffset - k]*b2fLast_inv;\n    backgroundProb = (b2b * backgroundProb) + accu*p;\n  }\n\n  const double bTot = backgroundProb;\n  return (fabs(fTot - bTot) > fmax(fTot, bTot) / 1e6);\n}\n\n  __global__ void\nmaskSequences(unsigned char * seqs, \n    const double * likelihoodRatioMatrix,\n    const unsigned char * maskTable,\n    const int size                     ,\n    const int maxRepeatOffset          ,\n    const double repeatProb            ,\n    const double repeatEndProb         ,\n    const double repeatOffsetProbDecay ,\n    const double firstGapProb          ,\n    const double otherGapProb          ,\n    const double minMaskProb           ,\n    int seqs_len )\n{\n  int gid = blockIdx.x*blockDim.x+threadIdx.x;\n  if (gid >= seqs_len) return;\n\n  unsigned char* seqBeg = seqs+gid*33;\n\n  float probabilities[SEQ_LEN];\n\n  const double b2b = 1 - repeatProb;\n  const double f2f0 = 1 - repeatEndProb;\n  const double f2b = repeatEndProb;\n\n  const double b2fGrowth = 1 / repeatOffsetProbDecay;\n\n  const double  b2fLast = repeatProb * firstRepeatOffsetProb(b2fGrowth, maxRepeatOffset);\n  const double b2fLast_inv = 1 / b2fLast ;\n\n  double p = b2fLast;\n  double ar_1[50];\n\n  for (int i=0 ; i < maxRepeatOffset; i++){\n    ar_1[i] = p ;\n    p *= b2fGrowth;\n  }\n\n  const int scaleStepSize = 16;\n\n  double scaleFactors[SEQ_LEN / scaleStepSize];\n\n  double foregroundProbs[50];\n\n  for (int i=0 ; i < maxRepeatOffset; i++){\n    foregroundProbs[i] = 0;\n  };\n\n  const int err  = calcRepeatProbs(probabilities,seqBeg, size, \n      maxRepeatOffset, likelihoodRatioMatrix,\n      b2b, f2f0, f2b,\n      b2fLast_inv,ar_1,foregroundProbs,scaleStepSize, scaleFactors);\n\n  \n\n\n  maskProbableLetters(size,seqBeg, probabilities, maskTable);\n}\n\n\nauto_ptr<Masking> Masking::instance;\nconst uint8_t Masking::bit_mask = 128;\n\nMasking::Masking(const Score_matrix &score_matrix)\n{\n  const double lambda = score_matrix.lambda(); \n\n  for (unsigned i = 0; i < size; ++i) {\n    mask_table_x_[i] = value_traits.mask_char;\n    mask_table_bit_[i] = (uint8_t)i | bit_mask;\n    for (unsigned j = 0; j < size; ++j)\n      if (i < value_traits.alphabet_size && j < value_traits.alphabet_size)\n        likelihoodRatioMatrix_[i][j] = exp(lambda * score_matrix(i, j));\n  }\n  std::copy(likelihoodRatioMatrix_, likelihoodRatioMatrix_ + size, probMatrixPointers_);\n  int firstGapCost = score_matrix.gap_extend() + score_matrix.gap_open();\n  firstGapProb_ = exp(-lambda * firstGapCost);\n  otherGapProb_ = exp(-lambda * score_matrix.gap_extend());\n  firstGapProb_ /= (1 - otherGapProb_);\n}\n\nvoid Masking::operator()(Letter *seq, size_t len) const\n{\n\n  tantan::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5, (const tantan::uchar*)mask_table_x_);\n}\n\nunsigned char* Masking::call_opt(Sequence_set &seqs) const\n{\n  const int n = seqs.get_length();\n  int total = 0;\n  for (int i=0; i < n; i++)\n    total += seqs.length(i);\n\n  printf(\"There are %d sequences and the total sequence length is %d\\n\", n, total);\n  unsigned char *seqs_device = NULL;\n  posix_memalign((void**)&seqs_device, 1024, total);\n\n  unsigned char *p = seqs_device;\n  for (int i=0; i < n; i++) {\n    memcpy(p, seqs.ptr(i), seqs.length(i));\n    p += seqs.length(i);\n  }\n\n  double *probMat_device = NULL;\n  posix_memalign((void**)&probMat_device, 1024, size*size*sizeof(double));\n  for (int i = 0; i < size; i++)\n    for (int j = 0; j < size; j++)\n      probMat_device[i*size+j] = probMatrixPointers_[i][j];\n\n  unsigned char *mask_table_device = NULL;\n  posix_memalign((void**)&mask_table_device, 1024, size*sizeof(unsigned char));\n  for (int i = 0; i < size; i++)\n    mask_table_device[i] = mask_table_x_[i];\n\n  int len = 33;\n\n  printf(\"Timing the mask sequences on device...\\n\"); \n  Timer t;\n  t.start();\n\n  const int size = len;\n  const int maxRepeatOffset = 50;\n  const double repeatProb = 0.005; \n  const double repeatEndProb = 0.05;\n  const double repeatOffsetProbDecay = 0.9;\n  const double firstGapProb = 0; \n  const double otherGapProb = 0;\n  const double minMaskProb = 0.5; \n  const int seqs_len = n;\n\n  unsigned char* d_seqs;\n  cudaMalloc((void**)&d_seqs, total);\n  cudaMemcpy(d_seqs, seqs_device, total, cudaMemcpyHostToDevice);\n\n  unsigned char* d_maskTable;\n  cudaMalloc((void**)&d_maskTable, size*size);\n  cudaMemcpy(d_maskTable, mask_table_device, size, cudaMemcpyHostToDevice);\n\n  double* d_probMat;\n  cudaMalloc((void **)&d_probMat, sizeof(double) * size * size);\n  cudaMemcpy(d_probMat, probMat_device, sizeof(double)*size*size, cudaMemcpyHostToDevice);\n\n  dim3 grids ((seqs_len+128)/128);\n  dim3 threads (128);\n\n  maskSequences<<<grids, threads>>>(d_seqs, \n      d_probMat, \n      d_maskTable, \n      size,\n      maxRepeatOffset,\n      repeatProb, \n      repeatEndProb, \n      repeatOffsetProbDecay,\n      firstGapProb,\n      otherGapProb,\n      minMaskProb,\n      seqs_len);\n\n  cudaMemcpy(seqs_device, d_seqs, total, cudaMemcpyDeviceToHost);\n  cudaFree(d_seqs);\n  cudaFree(d_maskTable);\n  cudaFree(d_probMat);\n\n  message_stream << \"Total time (maskSequences) on the device = \" << \n    t.getElapsedTimeInMicroSec() / 1e6 << \" s\" << std::endl;\n\n  free(probMat_device);\n  free(mask_table_device);\n  return seqs_device;\n}\n\nvoid Masking::call_opt(Letter *seq, size_t len) const\n{\n  \n\n  tantale::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5, (const tantan::uchar*)mask_table_x_);\n}\n\n\n\nvoid Masking::mask_bit(Letter *seq, size_t len) const\n{\n\n  tantan::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5,\t\t(const tantan::uchar*)mask_table_bit_);\n}\n\nvoid Masking::bit_to_hard_mask(Letter *seq, size_t len, size_t &n) const\n{\n  for (size_t i = 0; i < len; ++i)\n    if (seq[i] & bit_mask) {\n      seq[i] = value_traits.mask_char;\n      ++n;\n    }\n}\n\nvoid Masking::remove_bit_mask(Letter *seq, size_t len) const\n{\n  for (size_t i = 0; i < len; ++i)\n    if (seq[i] & bit_mask)\n      seq[i] &= ~bit_mask;\n}\n\nvoid mask_worker(Atomic<size_t> *next, Sequence_set *seqs, const Masking *masking, bool hard_mask)\n{\n  size_t i;\n  int cnt = 0;\n\n  while ((i = (*next)++) < seqs->get_length()) \n  {\n    if (hard_mask)\n      \n\n      masking->call_opt(seqs->ptr(i), seqs->length(i));\n    else\n      masking->mask_bit(seqs->ptr(i), seqs->length(i));\n    \n\n    \n\n  }\n}\n\nvoid mask_seqs(Sequence_set &seqs, const Masking &masking, bool hard_mask)\n{\n\n  assert(hard_mask==true);\n  const int n = seqs.get_length();\n\n  printf(\"Timing the mask sequences on CPU...\\n\"); \n  Timer total;\n  total.start();\n\n#if not defined(_OPENMP)\n  Thread_pool threads;\n  Atomic<size_t> next(0);\n  for (size_t i = 0; i < config.threads_; ++i)\n    threads.push_back(launch_thread(mask_worker, &next, &seqs, &masking, hard_mask));\n  threads.join_all();\n\n#else\n\n#pragma omp parallel for num_threads(config.threads_)\n  for (int i=0; i < n; i++){\n    masking.call_opt(seqs.ptr(i), seqs.length(i));\n  }\n\n#endif\n\n  message_stream << \"Total time (maskSequences) on the CPU = \" << \n    total.getElapsedTimeInMicroSec() / 1e6 << \" s\" << std::endl;\n\n  \n\n  unsigned char* seqs_device = masking.call_opt(seqs);\n\n  printf(\"Verify the sequences...\\n\");\n  unsigned char* p = seqs_device;\n  int error = 0;\n  for (int i = 0; i < n; i++) {\n    if (0 != strncmp((const char*)p, seqs.ptr(i), seqs.length(i))) {\n      printf(\"error at i=%d  length=%zu\\n\", i, seqs.length(i)); \n      printf(\"host=\");\n      char* s = seqs.ptr(i);\n      for (int j = 0; j < seqs.length(i); j++) {\n        printf(\"%02d\", s[j]); \n      }\n      printf(\"\\ndevice=\");\n      for (int j = 0; j < seqs.length(i); j++)\n        printf(\"%02d\", *(seqs_device+i*33+j)); \n      printf(\"\\n\");\n      error++;\n    }\n    p += seqs.length(i);\n  }\n  if (error == 0) printf(\"Success\\n\");\n}\n"}}
{"kernel_name": "diamond", "parallel_api": "hip", "code": {"masking.cu": "\n\n#include <hip/hip_runtime.h>\n#include \"../diamond-sycl/src/basic/masking.h\"\n\n\n#define SEQ_LEN 33\n\n__device__\ninline double firstRepeatOffsetProb(const double probMult, const int maxRepeatOffset) {\n  if (probMult < 1 || probMult > 1)\n    return (1 - probMult) / (1 - pow(probMult, (double)maxRepeatOffset));\n  else\n    return 1.0 / maxRepeatOffset;\n}\n\n__device__\nvoid maskProbableLetters(const int size,\n    unsigned char *seqBeg,\n    const float *probabilities, \n    const unsigned char *maskTable) {\n\n  const double minMaskProb = 0.5;\n  for (int i=0; i<size; i++)\n    if (probabilities[i] >= minMaskProb)\n      seqBeg[i] = maskTable[seqBeg[i]];\n}\n\n__device__\nint calcRepeatProbs(float *letterProbs,\n    const unsigned char *seqBeg, \n    const int size, \n    const int maxRepeatOffset,\n    const double *likelihoodRatioMatrix, \n\n    const double b2b,\n    const double f2f0,\n    const double f2b,\n    const double b2fLast_inv,\n    const double *pow_lkp,\n    double *foregroundProbs,\n    const int scaleStepSize,\n    double *scaleFactors)\t\t      \t\n{\n\n  double backgroundProb = 1.0;\n  for (int k=0; k < size ; k++) {\n\n    const int v0 = seqBeg[k];\n    const int k_cap = k < maxRepeatOffset ? k : maxRepeatOffset;\n\n    const int pad1 = k_cap - 1;\n    const int pad2 = maxRepeatOffset - k_cap; \n\n    const int pad3 = k - k_cap;               \n\n\n    double accu = 0;\n\n    for (int i = 0; i < k; i++) {\n\n      const int idx1 = pad1 - i;\n      const int idx2 = pad2 + i;\n      const int idx3 = pad3 + i;\n\n      const int v1 = seqBeg[idx3];\n      accu += foregroundProbs[idx1];\n      foregroundProbs[idx1] = ( (f2f0 * foregroundProbs[idx1]) +  \n          (backgroundProb * pow_lkp[idx2]) ) * \n        likelihoodRatioMatrix[v0*size+v1];\n    }\n\n    backgroundProb = (backgroundProb * b2b) + (accu * f2b);\n\n    if (k % scaleStepSize == scaleStepSize - 1) {\n      const double scale = 1 / backgroundProb;\n      scaleFactors[k / scaleStepSize] = scale;\n\n      for (int i=0; i< k_cap; i++)\n        foregroundProbs[i] = foregroundProbs[i] * scale;\n\n      backgroundProb = 1;\n    }\n\n    letterProbs[k] = (float)(backgroundProb);\n  }\n\n  double accu = 0;\n  for (int i=0 ; i < maxRepeatOffset; i++) {\n    accu += foregroundProbs[i];\n    foregroundProbs[i] = f2b;\n  }\n\n  const double fTot = backgroundProb * b2b + accu * f2b;\n  backgroundProb = b2b;\n\n  const double fTot_inv = 1/ fTot ;\n  for (int k=(size-1) ; k >= 0 ; k--){\n\n\n    double nonRepeatProb = letterProbs[k] * backgroundProb * fTot_inv;\n    letterProbs[k] = 1 - (float)(nonRepeatProb);\n\n    \n\n    const int k_cap = k < maxRepeatOffset ? k : maxRepeatOffset;\n\n    if (k % scaleStepSize == scaleStepSize - 1) {\n      const double scale = scaleFactors[k/ scaleStepSize];\n\n      for (int i=0; i< k_cap; i++)\n        foregroundProbs[i] = foregroundProbs[i] * scale;\n\n      backgroundProb *= scale;\n    }\n\n    const double c0 = f2b * backgroundProb;\n    const int v0= seqBeg[k];\n\n    double accu = 0;\n    for (int i = 0; i < k_cap; i++) {\n\n\n      const int v1 =  seqBeg[k-(i+1)];\n      const double f = foregroundProbs[i] * likelihoodRatioMatrix[v0*size+v1];\n\n      accu += pow_lkp[k_cap-(i+1)]*f;\n      foregroundProbs[i] = c0 + f2f0 * f;\n    }\n\n    const double p = k > maxRepeatOffset ? 1. : pow_lkp[maxRepeatOffset - k]*b2fLast_inv;\n    backgroundProb = (b2b * backgroundProb) + accu*p;\n  }\n\n  const double bTot = backgroundProb;\n  return (fabs(fTot - bTot) > fmax(fTot, bTot) / 1e6);\n}\n\n  __global__ void\nmaskSequences(unsigned char * seqs, \n    const double * likelihoodRatioMatrix,\n    const unsigned char * maskTable,\n    const int size                     ,\n    const int maxRepeatOffset          ,\n    const double repeatProb            ,\n    const double repeatEndProb         ,\n    const double repeatOffsetProbDecay ,\n    const double firstGapProb          ,\n    const double otherGapProb          ,\n    const double minMaskProb           ,\n    int seqs_len )\n{\n  int gid = blockIdx.x*blockDim.x+threadIdx.x;\n  if (gid >= seqs_len) return;\n\n  unsigned char* seqBeg = seqs+gid*33;\n\n  float probabilities[SEQ_LEN];\n\n  const double b2b = 1 - repeatProb;\n  const double f2f0 = 1 - repeatEndProb;\n  const double f2b = repeatEndProb;\n\n  const double b2fGrowth = 1 / repeatOffsetProbDecay;\n\n  const double  b2fLast = repeatProb * firstRepeatOffsetProb(b2fGrowth, maxRepeatOffset);\n  const double b2fLast_inv = 1 / b2fLast ;\n\n  double p = b2fLast;\n  double ar_1[50];\n\n  for (int i=0 ; i < maxRepeatOffset; i++){\n    ar_1[i] = p ;\n    p *= b2fGrowth;\n  }\n\n  const int scaleStepSize = 16;\n\n  double scaleFactors[SEQ_LEN / scaleStepSize];\n\n  double foregroundProbs[50];\n\n  for (int i=0 ; i < maxRepeatOffset; i++){\n    foregroundProbs[i] = 0;\n  };\n\n  const int err  = calcRepeatProbs(probabilities,seqBeg, size, \n      maxRepeatOffset, likelihoodRatioMatrix,\n      b2b, f2f0, f2b,\n      b2fLast_inv,ar_1,foregroundProbs,scaleStepSize, scaleFactors);\n\n  \n\n\n  maskProbableLetters(size,seqBeg, probabilities, maskTable);\n}\n\n\nauto_ptr<Masking> Masking::instance;\nconst uint8_t Masking::bit_mask = 128;\n\nMasking::Masking(const Score_matrix &score_matrix)\n{\n  const double lambda = score_matrix.lambda(); \n\n  for (unsigned i = 0; i < size; ++i) {\n    mask_table_x_[i] = value_traits.mask_char;\n    mask_table_bit_[i] = (uint8_t)i | bit_mask;\n    for (unsigned j = 0; j < size; ++j)\n      if (i < value_traits.alphabet_size && j < value_traits.alphabet_size)\n        likelihoodRatioMatrix_[i][j] = exp(lambda * score_matrix(i, j));\n  }\n  std::copy(likelihoodRatioMatrix_, likelihoodRatioMatrix_ + size, probMatrixPointers_);\n  int firstGapCost = score_matrix.gap_extend() + score_matrix.gap_open();\n  firstGapProb_ = exp(-lambda * firstGapCost);\n  otherGapProb_ = exp(-lambda * score_matrix.gap_extend());\n  firstGapProb_ /= (1 - otherGapProb_);\n}\n\nvoid Masking::operator()(Letter *seq, size_t len) const\n{\n\n  tantan::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5, (const tantan::uchar*)mask_table_x_);\n}\n\nunsigned char* Masking::call_opt(Sequence_set &seqs) const\n{\n  const int n = seqs.get_length();\n  int total = 0;\n  for (int i=0; i < n; i++)\n    total += seqs.length(i);\n\n  printf(\"There are %d sequences and the total sequence length is %d\\n\", n, total);\n  unsigned char *seqs_device = NULL;\n  posix_memalign((void**)&seqs_device, 1024, total);\n\n  unsigned char *p = seqs_device;\n  for (int i=0; i < n; i++) {\n    memcpy(p, seqs.ptr(i), seqs.length(i));\n    p += seqs.length(i);\n  }\n\n  double *probMat_device = NULL;\n  posix_memalign((void**)&probMat_device, 1024, size*size*sizeof(double));\n  for (int i = 0; i < size; i++)\n    for (int j = 0; j < size; j++)\n      probMat_device[i*size+j] = probMatrixPointers_[i][j];\n\n  unsigned char *mask_table_device = NULL;\n  posix_memalign((void**)&mask_table_device, 1024, size*sizeof(unsigned char));\n  for (int i = 0; i < size; i++)\n    mask_table_device[i] = mask_table_x_[i];\n\n  int len = 33;\n\n  printf(\"Timing the mask sequences on device...\\n\"); \n  Timer t;\n  t.start();\n\n  const int size = len;\n  const int maxRepeatOffset = 50;\n  const double repeatProb = 0.005; \n  const double repeatEndProb = 0.05;\n  const double repeatOffsetProbDecay = 0.9;\n  const double firstGapProb = 0; \n  const double otherGapProb = 0;\n  const double minMaskProb = 0.5; \n  const int seqs_len = n;\n\n  unsigned char* d_seqs;\n  hipMalloc((void**)&d_seqs, total);\n  hipMemcpy(d_seqs, seqs_device, total, hipMemcpyHostToDevice);\n\n  unsigned char* d_maskTable;\n  hipMalloc((void**)&d_maskTable, size*size);\n  hipMemcpy(d_maskTable, mask_table_device, size, hipMemcpyHostToDevice);\n\n  double* d_probMat;\n  hipMalloc((void **)&d_probMat, sizeof(double) * size * size);\n  hipMemcpy(d_probMat, probMat_device, sizeof(double)*size*size, hipMemcpyHostToDevice);\n\n  dim3 grids ((seqs_len+128)/128);\n  dim3 threads (128);\n\n  hipLaunchKernelGGL(maskSequences, grids, threads, 0, 0, d_seqs, \n      d_probMat, \n      d_maskTable, \n      size,\n      maxRepeatOffset,\n      repeatProb, \n      repeatEndProb, \n      repeatOffsetProbDecay,\n      firstGapProb,\n      otherGapProb,\n      minMaskProb,\n      seqs_len);\n\n  hipMemcpy(seqs_device, d_seqs, total, hipMemcpyDeviceToHost);\n  hipFree(d_seqs);\n  hipFree(d_maskTable);\n  hipFree(d_probMat);\n\n  message_stream << \"Total time (maskSequences) on the device = \" << \n    t.getElapsedTimeInMicroSec() / 1e6 << \" s\" << std::endl;\n\n  free(probMat_device);\n  free(mask_table_device);\n  return seqs_device;\n}\n\nvoid Masking::call_opt(Letter *seq, size_t len) const\n{\n  \n\n  tantale::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5, (const tantan::uchar*)mask_table_x_);\n}\n\n\n\nvoid Masking::mask_bit(Letter *seq, size_t len) const\n{\n\n  tantan::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5,\t\t(const tantan::uchar*)mask_table_bit_);\n}\n\nvoid Masking::bit_to_hard_mask(Letter *seq, size_t len, size_t &n) const\n{\n  for (size_t i = 0; i < len; ++i)\n    if (seq[i] & bit_mask) {\n      seq[i] = value_traits.mask_char;\n      ++n;\n    }\n}\n\nvoid Masking::remove_bit_mask(Letter *seq, size_t len) const\n{\n  for (size_t i = 0; i < len; ++i)\n    if (seq[i] & bit_mask)\n      seq[i] &= ~bit_mask;\n}\n\nvoid mask_worker(Atomic<size_t> *next, Sequence_set *seqs, const Masking *masking, bool hard_mask)\n{\n  size_t i;\n  int cnt = 0;\n\n  while ((i = (*next)++) < seqs->get_length()) \n  {\n    if (hard_mask)\n      \n\n      masking->call_opt(seqs->ptr(i), seqs->length(i));\n    else\n      masking->mask_bit(seqs->ptr(i), seqs->length(i));\n    \n\n    \n\n  }\n}\n\nvoid mask_seqs(Sequence_set &seqs, const Masking &masking, bool hard_mask)\n{\n\n  assert(hard_mask==true);\n  const int n = seqs.get_length();\n\n  printf(\"Timing the mask sequences on CPU...\\n\"); \n  Timer total;\n  total.start();\n\n#if not defined(_OPENMP)\n  Thread_pool threads;\n  Atomic<size_t> next(0);\n  for (size_t i = 0; i < config.threads_; ++i)\n    threads.push_back(launch_thread(mask_worker, &next, &seqs, &masking, hard_mask));\n  threads.join_all();\n\n#else\n\n#pragma omp parallel for num_threads(config.threads_)\n  for (int i=0; i < n; i++){\n    masking.call_opt(seqs.ptr(i), seqs.length(i));\n  }\n\n#endif\n\n  message_stream << \"Total time (maskSequences) on the CPU = \" << \n    total.getElapsedTimeInMicroSec() / 1e6 << \" s\" << std::endl;\n\n  \n\n  unsigned char* seqs_device = masking.call_opt(seqs);\n\n  printf(\"Verify the sequences...\\n\");\n  unsigned char* p = seqs_device;\n  int error = 0;\n  for (int i = 0; i < n; i++) {\n    if (0 != strncmp((const char*)p, seqs.ptr(i), seqs.length(i))) {\n      printf(\"error at i=%d  length=%zu\\n\", i, seqs.length(i)); \n      printf(\"host=\");\n      char* s = seqs.ptr(i);\n      for (int j = 0; j < seqs.length(i); j++) {\n        printf(\"%02d\", s[j]); \n      }\n      printf(\"\\ndevice=\");\n      for (int j = 0; j < seqs.length(i); j++)\n        printf(\"%02d\", *(seqs_device+i*33+j)); \n      printf(\"\\n\");\n      error++;\n    }\n    p += seqs.length(i);\n  }\n  if (error == 0) printf(\"Success\\n\");\n}\n"}}
{"kernel_name": "diamond", "parallel_api": "omp", "code": {"masking.cpp": "\n\n\n#include \"../diamond-sycl/src/basic/masking.h\"\n\n\n#define SEQ_LEN 33\ninline double firstRepeatOffsetProb(const double probMult, const int maxRepeatOffset) {\n  if (probMult < 1 || probMult > 1)\n    return (1 - probMult) / (1 - pow(probMult, (double)maxRepeatOffset));\n  else\n    return 1.0 / maxRepeatOffset;\n}\n\nvoid maskProbableLetters(const int size,\n    unsigned char *seqBeg,\n    const float *probabilities, \n    const unsigned char *maskTable) {\n\n  const double minMaskProb = 0.5;\n  for (int i=0; i<size; i++)\n    if (probabilities[i] >= minMaskProb)\n      seqBeg[i] = maskTable[seqBeg[i]];\n}\n\nint calcRepeatProbs(float *letterProbs,\n    const unsigned char *seqBeg, \n    const int size, \n    const int maxRepeatOffset,\n    const double *likelihoodRatioMatrix, \n\n    const double b2b,\n    const double f2f0,\n    const double f2b,\n    const double b2fLast_inv,\n    const double *pow_lkp,\n    double *foregroundProbs,\n    const int scaleStepSize,\n    double *scaleFactors)\t\t      \t\n{\n\n  double backgroundProb = 1.0;\n  for (int k=0; k < size ; k++) {\n\n    const int v0 = seqBeg[k];\n    const int k_cap = k < maxRepeatOffset ? k : maxRepeatOffset;\n\n    const int pad1 = k_cap - 1;\n    const int pad2 = maxRepeatOffset - k_cap; \n\n    const int pad3 = k - k_cap;               \n\n\n    double accu = 0;\n\n    for (int i = 0; i < k; i++) {\n\n      const int idx1 = pad1 - i;\n      const int idx2 = pad2 + i;\n      const int idx3 = pad3 + i;\n\n      const int v1 = seqBeg[idx3];\n      accu += foregroundProbs[idx1];\n      foregroundProbs[idx1] = ( (f2f0 * foregroundProbs[idx1]) +  \n          (backgroundProb * pow_lkp[idx2]) ) * \n        likelihoodRatioMatrix[v0*size+v1];\n    }\n\n    backgroundProb = (backgroundProb * b2b) + (accu * f2b);\n\n    if (k % scaleStepSize == scaleStepSize - 1) {\n      const double scale = 1 / backgroundProb;\n      scaleFactors[k / scaleStepSize] = scale;\n\n      for (int i=0; i< k_cap; i++)\n        foregroundProbs[i] = foregroundProbs[i] * scale;\n\n      backgroundProb = 1;\n    }\n\n    letterProbs[k] = (float)(backgroundProb);\n  }\n\n  double accu = 0;\n  for (int i=0 ; i < maxRepeatOffset; i++) {\n    accu += foregroundProbs[i];\n    foregroundProbs[i] = f2b;\n  }\n\n  const double fTot = backgroundProb * b2b + accu * f2b;\n  backgroundProb = b2b;\n\n  const double fTot_inv = 1/ fTot ;\n  for (int k=(size-1) ; k >= 0 ; k--){\n\n\n    double nonRepeatProb = letterProbs[k] * backgroundProb * fTot_inv;\n    letterProbs[k] = 1 - (float)(nonRepeatProb);\n\n    \n\n    const int k_cap = k < maxRepeatOffset ? k : maxRepeatOffset;\n\n    if (k % scaleStepSize == scaleStepSize - 1) {\n      const double scale = scaleFactors[k/ scaleStepSize];\n\n      for (int i=0; i< k_cap; i++)\n        foregroundProbs[i] = foregroundProbs[i] * scale;\n\n      backgroundProb *= scale;\n    }\n\n    const double c0 = f2b * backgroundProb;\n    const int v0= seqBeg[k];\n\n    double accu = 0;\n    for (int i = 0; i < k_cap; i++) {\n\n\n      const int v1 =  seqBeg[k-(i+1)];\n      const double f = foregroundProbs[i] * likelihoodRatioMatrix[v0*size+v1];\n\n      accu += pow_lkp[k_cap-(i+1)]*f;\n      foregroundProbs[i] = c0 + f2f0 * f;\n    }\n\n    const double p = k > maxRepeatOffset ? 1. : pow_lkp[maxRepeatOffset - k]*b2fLast_inv;\n    backgroundProb = (b2b * backgroundProb) + accu*p;\n  }\n\n  const double bTot = backgroundProb;\n  return (fabs(fTot - bTot) > fmax(fTot, bTot) / 1e6);\n}\n\nauto_ptr<Masking> Masking::instance;\nconst uint8_t Masking::bit_mask = 128;\n\nMasking::Masking(const Score_matrix &score_matrix)\n{\n  const double lambda = score_matrix.lambda(); \n\n  for (unsigned i = 0; i < size; ++i) {\n    mask_table_x_[i] = value_traits.mask_char;\n    mask_table_bit_[i] = (uint8_t)i | bit_mask;\n    for (unsigned j = 0; j < size; ++j)\n      if (i < value_traits.alphabet_size && j < value_traits.alphabet_size)\n        likelihoodRatioMatrix_[i][j] = exp(lambda * score_matrix(i, j));\n  }\n  std::copy(likelihoodRatioMatrix_, likelihoodRatioMatrix_ + size, probMatrixPointers_);\n  int firstGapCost = score_matrix.gap_extend() + score_matrix.gap_open();\n  firstGapProb_ = exp(-lambda * firstGapCost);\n  otherGapProb_ = exp(-lambda * score_matrix.gap_extend());\n  firstGapProb_ /= (1 - otherGapProb_);\n}\n\nvoid Masking::operator()(Letter *seq, size_t len) const\n{\n\n  tantan::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5, (const tantan::uchar*)mask_table_x_);\n}\n\nunsigned char* Masking::call_opt(Sequence_set &seqs) const\n{\n  const int n = seqs.get_length();\n  int total = 0;\n  for (int i=0; i < n; i++)\n    total += seqs.length(i);\n\n  printf(\"There are %d sequences and the total sequence length is %d\\n\", n, total);\n  unsigned char *seqs_device = NULL;\n  posix_memalign((void**)&seqs_device, 1024, total);\n\n  unsigned char *p = seqs_device;\n  for (int i=0; i < n; i++) {\n    memcpy(p, seqs.ptr(i), seqs.length(i));\n    p += seqs.length(i);\n  }\n\n  double *probMat_device = NULL;\n  posix_memalign((void**)&probMat_device, 1024, size*size*sizeof(double));\n  for (int i = 0; i < size; i++)\n    for (int j = 0; j < size; j++)\n      probMat_device[i*size+j] = probMatrixPointers_[i][j];\n\n  unsigned char *mask_table_device = NULL;\n  posix_memalign((void**)&mask_table_device, 1024, size*sizeof(unsigned char));\n  for (int i = 0; i < size; i++)\n    mask_table_device[i] = mask_table_x_[i];\n\n  int len = 33;\n\n  printf(\"Timing the mask sequences on device...\\n\"); \n  Timer t;\n  t.start();\n\n  unsigned char *s = seqs_device;\n  const unsigned char *maskTable = mask_table_device;\n  const double *likelihoodRatioMatrix = probMat_device;\n\n\n  const int size = len;\n  const int maxRepeatOffset = 50;\n  const double repeatProb = 0.005; \n  const double repeatEndProb = 0.05;\n  const double repeatOffsetProbDecay = 0.9;\n  const double firstGapProb = 0; \n  const double otherGapProb = 0;\n  const double minMaskProb = 0.5; \n  const int seqs_len = n;\n\n  #pragma omp target data map(tofrom: s[0:total]) \\\n                          map(to: likelihoodRatioMatrix[0:size*size], maskTable[0:size])\n  {\n    #pragma omp target teams distribute parallel for thread_limit(128)\n    for (int gid = 0; gid < seqs_len; gid++) {\n\n      unsigned char* seqBeg = s+gid*33;\n\n      float probabilities[SEQ_LEN];\n\n      const double b2b = 1 - repeatProb;\n      const double f2f0 = 1 - repeatEndProb;\n      const double f2b = repeatEndProb;\n\n      const double b2fGrowth = 1 / repeatOffsetProbDecay;\n\n      const double  b2fLast = repeatProb * firstRepeatOffsetProb(b2fGrowth, maxRepeatOffset);\n      const double b2fLast_inv = 1 / b2fLast ;\n\n      double p = b2fLast;\n      double ar_1[50];\n\n      for (int i=0 ; i < maxRepeatOffset; i++){\n        ar_1[i] = p ;\n        p *= b2fGrowth;\n      }\n\n      const int scaleStepSize = 16;\n\n      double scaleFactors[SEQ_LEN / scaleStepSize];\n\n      double foregroundProbs[50];\n\n      for (int i=0 ; i < maxRepeatOffset; i++){\n        foregroundProbs[i] = 0;\n      };\n\n      const int err  = calcRepeatProbs(probabilities,seqBeg, size, \n          maxRepeatOffset, likelihoodRatioMatrix,\n          b2b, f2f0, f2b,\n          b2fLast_inv,ar_1,foregroundProbs,scaleStepSize, scaleFactors);\n\n      \n\n\n      maskProbableLetters(size,seqBeg, probabilities, maskTable);\n    }\n  }\n\n  message_stream << \"Total time (maskSequences) on the device = \" << \n    t.getElapsedTimeInMicroSec() / 1e6 << \" s\" << std::endl;\n\n  free(probMat_device);\n  free(mask_table_device);\n  return seqs_device;\n}\n\nvoid Masking::call_opt(Letter *seq, size_t len) const\n{\n  \n\n  tantale::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5, (const tantan::uchar*)mask_table_x_);\n}\n\n\n\nvoid Masking::mask_bit(Letter *seq, size_t len) const\n{\n\n  tantan::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5,\t\t(const tantan::uchar*)mask_table_bit_);\n}\n\nvoid Masking::bit_to_hard_mask(Letter *seq, size_t len, size_t &n) const\n{\n  for (size_t i = 0; i < len; ++i)\n    if (seq[i] & bit_mask) {\n      seq[i] = value_traits.mask_char;\n      ++n;\n    }\n}\n\nvoid Masking::remove_bit_mask(Letter *seq, size_t len) const\n{\n  for (size_t i = 0; i < len; ++i)\n    if (seq[i] & bit_mask)\n      seq[i] &= ~bit_mask;\n}\n\nvoid mask_worker(Atomic<size_t> *next, Sequence_set *seqs, const Masking *masking, bool hard_mask)\n{\n  size_t i;\n  int cnt = 0;\n\n  while ((i = (*next)++) < seqs->get_length()) \n  {\n    if (hard_mask)\n      \n\n      masking->call_opt(seqs->ptr(i), seqs->length(i));\n    else\n      masking->mask_bit(seqs->ptr(i), seqs->length(i));\n    \n\n    \n\n  }\n}\n\nvoid mask_seqs(Sequence_set &seqs, const Masking &masking, bool hard_mask)\n{\n\n  assert(hard_mask==true);\n  const int n = seqs.get_length();\n\n  printf(\"Timing the mask sequences on CPU...\\n\"); \n  Timer total;\n  total.start();\n\n#if not defined(_OPENMP)\n  Thread_pool threads;\n  Atomic<size_t> next(0);\n  for (size_t i = 0; i < config.threads_; ++i)\n    threads.push_back(launch_thread(mask_worker, &next, &seqs, &masking, hard_mask));\n  threads.join_all();\n\n#else\n\n#pragma omp parallel for num_threads(config.threads_)\n  for (int i=0; i < n; i++){\n    masking.call_opt(seqs.ptr(i), seqs.length(i));\n  }\n\n#endif\n\n  message_stream << \"Total time (maskSequences) on the CPU = \" << \n    total.getElapsedTimeInMicroSec() / 1e6 << \" s\" << std::endl;\n\n  \n\n  unsigned char* seqs_device = masking.call_opt(seqs);\n\n  printf(\"Verify the sequences...\\n\");\n  unsigned char* p = seqs_device;\n  int error = 0;\n  for (int i = 0; i < n; i++) {\n    if (0 != strncmp((const char*)p, seqs.ptr(i), seqs.length(i))) {\n      printf(\"error at i=%d  length=%zu\\n\", i, seqs.length(i)); \n      printf(\"host=\");\n      char* s = seqs.ptr(i);\n      for (int j = 0; j < seqs.length(i); j++) {\n        printf(\"%02d\", s[j]); \n      }\n      printf(\"\\ndevice=\");\n      for (int j = 0; j < seqs.length(i); j++)\n        printf(\"%02d\", *(seqs_device+i*33+j)); \n      printf(\"\\n\");\n      error++;\n    }\n    p += seqs.length(i);\n  }\n  if (error == 0) printf(\"Success\\n\");\n}\n"}}
{"kernel_name": "diamond", "parallel_api": "serial", "code": {"masking.cpp": "\n\n\n#include \"../diamond-sycl/src/basic/masking.h\"\n\n\n#define SEQ_LEN 33\ninline double firstRepeatOffsetProb(const double probMult, const int maxRepeatOffset) {\n  if (probMult < 1 || probMult > 1)\n    return (1 - probMult) / (1 - pow(probMult, (double)maxRepeatOffset));\n  else\n    return 1.0 / maxRepeatOffset;\n}\n\nvoid maskProbableLetters(const int size,\n    unsigned char *seqBeg,\n    const float *probabilities, \n    const unsigned char *maskTable) {\n\n  const double minMaskProb = 0.5;\n  for (int i=0; i<size; i++)\n    if (probabilities[i] >= minMaskProb)\n      seqBeg[i] = maskTable[seqBeg[i]];\n}\n\nint calcRepeatProbs(float *letterProbs,\n    const unsigned char *seqBeg, \n    const int size, \n    const int maxRepeatOffset,\n    const double *likelihoodRatioMatrix, \n\n    const double b2b,\n    const double f2f0,\n    const double f2b,\n    const double b2fLast_inv,\n    const double *pow_lkp,\n    double *foregroundProbs,\n    const int scaleStepSize,\n    double *scaleFactors)\t\t      \t\n{\n\n  double backgroundProb = 1.0;\n  for (int k=0; k < size ; k++) {\n\n    const int v0 = seqBeg[k];\n    const int k_cap = k < maxRepeatOffset ? k : maxRepeatOffset;\n\n    const int pad1 = k_cap - 1;\n    const int pad2 = maxRepeatOffset - k_cap; \n\n    const int pad3 = k - k_cap;               \n\n\n    double accu = 0;\n\n    for (int i = 0; i < k; i++) {\n\n      const int idx1 = pad1 - i;\n      const int idx2 = pad2 + i;\n      const int idx3 = pad3 + i;\n\n      const int v1 = seqBeg[idx3];\n      accu += foregroundProbs[idx1];\n      foregroundProbs[idx1] = ( (f2f0 * foregroundProbs[idx1]) +  \n          (backgroundProb * pow_lkp[idx2]) ) * \n        likelihoodRatioMatrix[v0*size+v1];\n    }\n\n    backgroundProb = (backgroundProb * b2b) + (accu * f2b);\n\n    if (k % scaleStepSize == scaleStepSize - 1) {\n      const double scale = 1 / backgroundProb;\n      scaleFactors[k / scaleStepSize] = scale;\n\n      for (int i=0; i< k_cap; i++)\n        foregroundProbs[i] = foregroundProbs[i] * scale;\n\n      backgroundProb = 1;\n    }\n\n    letterProbs[k] = (float)(backgroundProb);\n  }\n\n  double accu = 0;\n  for (int i=0 ; i < maxRepeatOffset; i++) {\n    accu += foregroundProbs[i];\n    foregroundProbs[i] = f2b;\n  }\n\n  const double fTot = backgroundProb * b2b + accu * f2b;\n  backgroundProb = b2b;\n\n  const double fTot_inv = 1/ fTot ;\n  for (int k=(size-1) ; k >= 0 ; k--){\n\n\n    double nonRepeatProb = letterProbs[k] * backgroundProb * fTot_inv;\n    letterProbs[k] = 1 - (float)(nonRepeatProb);\n\n    \n\n    const int k_cap = k < maxRepeatOffset ? k : maxRepeatOffset;\n\n    if (k % scaleStepSize == scaleStepSize - 1) {\n      const double scale = scaleFactors[k/ scaleStepSize];\n\n      for (int i=0; i< k_cap; i++)\n        foregroundProbs[i] = foregroundProbs[i] * scale;\n\n      backgroundProb *= scale;\n    }\n\n    const double c0 = f2b * backgroundProb;\n    const int v0= seqBeg[k];\n\n    double accu = 0;\n    for (int i = 0; i < k_cap; i++) {\n\n\n      const int v1 =  seqBeg[k-(i+1)];\n      const double f = foregroundProbs[i] * likelihoodRatioMatrix[v0*size+v1];\n\n      accu += pow_lkp[k_cap-(i+1)]*f;\n      foregroundProbs[i] = c0 + f2f0 * f;\n    }\n\n    const double p = k > maxRepeatOffset ? 1. : pow_lkp[maxRepeatOffset - k]*b2fLast_inv;\n    backgroundProb = (b2b * backgroundProb) + accu*p;\n  }\n\n  const double bTot = backgroundProb;\n  return (fabs(fTot - bTot) > fmax(fTot, bTot) / 1e6);\n}\n\nauto_ptr<Masking> Masking::instance;\nconst uint8_t Masking::bit_mask = 128;\n\nMasking::Masking(const Score_matrix &score_matrix)\n{\n  const double lambda = score_matrix.lambda(); \n\n  for (unsigned i = 0; i < size; ++i) {\n    mask_table_x_[i] = value_traits.mask_char;\n    mask_table_bit_[i] = (uint8_t)i | bit_mask;\n    for (unsigned j = 0; j < size; ++j)\n      if (i < value_traits.alphabet_size && j < value_traits.alphabet_size)\n        likelihoodRatioMatrix_[i][j] = exp(lambda * score_matrix(i, j));\n  }\n  std::copy(likelihoodRatioMatrix_, likelihoodRatioMatrix_ + size, probMatrixPointers_);\n  int firstGapCost = score_matrix.gap_extend() + score_matrix.gap_open();\n  firstGapProb_ = exp(-lambda * firstGapCost);\n  otherGapProb_ = exp(-lambda * score_matrix.gap_extend());\n  firstGapProb_ /= (1 - otherGapProb_);\n}\n\nvoid Masking::operator()(Letter *seq, size_t len) const\n{\n\n  tantan::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5, (const tantan::uchar*)mask_table_x_);\n}\n\nunsigned char* Masking::call_opt(Sequence_set &seqs) const\n{\n  const int n = seqs.get_length();\n  int total = 0;\n  for (int i=0; i < n; i++)\n    total += seqs.length(i);\n\n  printf(\"There are %d sequences and the total sequence length is %d\\n\", n, total);\n  unsigned char *seqs_device = NULL;\n  posix_memalign((void**)&seqs_device, 1024, total);\n\n  unsigned char *p = seqs_device;\n  for (int i=0; i < n; i++) {\n    memcpy(p, seqs.ptr(i), seqs.length(i));\n    p += seqs.length(i);\n  }\n\n  double *probMat_device = NULL;\n  posix_memalign((void**)&probMat_device, 1024, size*size*sizeof(double));\n  for (int i = 0; i < size; i++)\n    for (int j = 0; j < size; j++)\n      probMat_device[i*size+j] = probMatrixPointers_[i][j];\n\n  unsigned char *mask_table_device = NULL;\n  posix_memalign((void**)&mask_table_device, 1024, size*sizeof(unsigned char));\n  for (int i = 0; i < size; i++)\n    mask_table_device[i] = mask_table_x_[i];\n\n  int len = 33;\n\n  printf(\"Timing the mask sequences on device...\\n\"); \n  Timer t;\n  t.start();\n\n  unsigned char *s = seqs_device;\n  const unsigned char *maskTable = mask_table_device;\n  const double *likelihoodRatioMatrix = probMat_device;\n\n\n  const int size = len;\n  const int maxRepeatOffset = 50;\n  const double repeatProb = 0.005; \n  const double repeatEndProb = 0.05;\n  const double repeatOffsetProbDecay = 0.9;\n  const double firstGapProb = 0; \n  const double otherGapProb = 0;\n  const double minMaskProb = 0.5; \n  const int seqs_len = n;\n\n    {\n        for (int gid = 0; gid < seqs_len; gid++) {\n\n      unsigned char* seqBeg = s+gid*33;\n\n      float probabilities[SEQ_LEN];\n\n      const double b2b = 1 - repeatProb;\n      const double f2f0 = 1 - repeatEndProb;\n      const double f2b = repeatEndProb;\n\n      const double b2fGrowth = 1 / repeatOffsetProbDecay;\n\n      const double  b2fLast = repeatProb * firstRepeatOffsetProb(b2fGrowth, maxRepeatOffset);\n      const double b2fLast_inv = 1 / b2fLast ;\n\n      double p = b2fLast;\n      double ar_1[50];\n\n      for (int i=0 ; i < maxRepeatOffset; i++){\n        ar_1[i] = p ;\n        p *= b2fGrowth;\n      }\n\n      const int scaleStepSize = 16;\n\n      double scaleFactors[SEQ_LEN / scaleStepSize];\n\n      double foregroundProbs[50];\n\n      for (int i=0 ; i < maxRepeatOffset; i++){\n        foregroundProbs[i] = 0;\n      };\n\n      const int err  = calcRepeatProbs(probabilities,seqBeg, size, \n          maxRepeatOffset, likelihoodRatioMatrix,\n          b2b, f2f0, f2b,\n          b2fLast_inv,ar_1,foregroundProbs,scaleStepSize, scaleFactors);\n\n      \n\n\n      maskProbableLetters(size,seqBeg, probabilities, maskTable);\n    }\n  }\n\n  message_stream << \"Total time (maskSequences) on the device = \" << \n    t.getElapsedTimeInMicroSec() / 1e6 << \" s\" << std::endl;\n\n  free(probMat_device);\n  free(mask_table_device);\n  return seqs_device;\n}\n\nvoid Masking::call_opt(Letter *seq, size_t len) const\n{\n  \n\n  tantale::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5, (const tantan::uchar*)mask_table_x_);\n}\n\n\n\nvoid Masking::mask_bit(Letter *seq, size_t len) const\n{\n\n  tantan::maskSequences((tantan::uchar*)seq, (tantan::uchar*)(seq + len), 50,\n      (tantan::const_double_ptr*)probMatrixPointers_,\n      0.005, 0.05,\n      0.9,\n      0, 0,\n      0.5,\t\t(const tantan::uchar*)mask_table_bit_);\n}\n\nvoid Masking::bit_to_hard_mask(Letter *seq, size_t len, size_t &n) const\n{\n  for (size_t i = 0; i < len; ++i)\n    if (seq[i] & bit_mask) {\n      seq[i] = value_traits.mask_char;\n      ++n;\n    }\n}\n\nvoid Masking::remove_bit_mask(Letter *seq, size_t len) const\n{\n  for (size_t i = 0; i < len; ++i)\n    if (seq[i] & bit_mask)\n      seq[i] &= ~bit_mask;\n}\n\nvoid mask_worker(Atomic<size_t> *next, Sequence_set *seqs, const Masking *masking, bool hard_mask)\n{\n  size_t i;\n  int cnt = 0;\n\n  while ((i = (*next)++) < seqs->get_length()) \n  {\n    if (hard_mask)\n      \n\n      masking->call_opt(seqs->ptr(i), seqs->length(i));\n    else\n      masking->mask_bit(seqs->ptr(i), seqs->length(i));\n    \n\n    \n\n  }\n}\n\nvoid mask_seqs(Sequence_set &seqs, const Masking &masking, bool hard_mask)\n{\n\n  assert(hard_mask==true);\n  const int n = seqs.get_length();\n\n  printf(\"Timing the mask sequences on CPU...\\n\"); \n  Timer total;\n  total.start();\n\n#if not defined(_OPENMP)\n  Thread_pool threads;\n  Atomic<size_t> next(0);\n  for (size_t i = 0; i < config.threads_; ++i)\n    threads.push_back(launch_thread(mask_worker, &next, &seqs, &masking, hard_mask));\n  threads.join_all();\n\n#else\n\n  for (int i=0; i < n; i++){\n    masking.call_opt(seqs.ptr(i), seqs.length(i));\n  }\n\n#endif\n\n  message_stream << \"Total time (maskSequences) on the CPU = \" << \n    total.getElapsedTimeInMicroSec() / 1e6 << \" s\" << std::endl;\n\n  \n\n  unsigned char* seqs_device = masking.call_opt(seqs);\n\n  printf(\"Verify the sequences...\\n\");\n  unsigned char* p = seqs_device;\n  int error = 0;\n  for (int i = 0; i < n; i++) {\n    if (0 != strncmp((const char*)p, seqs.ptr(i), seqs.length(i))) {\n      printf(\"error at i=%d  length=%zu\\n\", i, seqs.length(i)); \n      printf(\"host=\");\n      char* s = seqs.ptr(i);\n      for (int j = 0; j < seqs.length(i); j++) {\n        printf(\"%02d\", s[j]); \n      }\n      printf(\"\\ndevice=\");\n      for (int j = 0; j < seqs.length(i); j++)\n        printf(\"%02d\", *(seqs_device+i*33+j)); \n      printf(\"\\n\");\n      error++;\n    }\n    p += seqs.length(i);\n  }\n  if (error == 0) printf(\"Success\\n\");\n}"}}
{"kernel_name": "epistasis", "parallel_api": "cuda", "code": {"main.cu": "#include <math.h>\n#include <float.h>\n#include <fstream>\n#include <string>\n#include <cstring>\n#include <sstream>\n#include <iostream>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\nusing namespace std::chrono;\ntypedef high_resolution_clock myclock;\ntypedef duration<float> myduration;\n\n#define MAX_WG_SIZE 256\n\ntemplate <typename T>\nT* mem_alloc (const int align, const size_t size) {\n  return (T*) aligned_alloc(align, size * sizeof(T));\n}\n\ntemplate <typename T>\nvoid mem_free (T* p) {\n  free(p);\n}\n\n__device__\nfloat gammafunction(unsigned int n)\n{   \n  if(n == 0)\n    return 0.0f;\n  float x = ((float)n + 0.5f) * logf((float) n) - ((float)n - 1.0f);\n  return x;\n}\n\n__global__ void epi(const unsigned int* dev_data_zeros, \n                    const unsigned int* dev_data_ones, \n                    float* dev_scores, \n                    const int num_snp, \n                    const int PP_zeros, \n                    const int PP_ones,\n                    const int mask_zeros, \n                    const int mask_ones) \n{\n  int i, j, tid, p, k;\n\n  j = blockDim.x * blockIdx.x + threadIdx.x; \n  i = blockDim.y * blockIdx.y + threadIdx.y;\n  tid = i * num_snp + j;\n\n  if (j > i && i < num_snp && j < num_snp) {\n    unsigned int ft[2 * 9];\n    for(k = 0; k < 2 * 9; k++) ft[k] = 0;\n\n    unsigned int t00, t01, t02, t10, t11, t12, t20, t21, t22;\n    unsigned int di2, dj2;\n    unsigned int* SNPi;\n    unsigned int* SNPj;\n\n    \n\n    SNPi = (unsigned int*) &dev_data_zeros[i * 2];\n    SNPj = (unsigned int*) &dev_data_zeros[j * 2];\n\n    #pragma unroll 1\n    for (p = 0; p < 2 * PP_zeros * num_snp - 2 * num_snp; p += 2 * num_snp) {\n      di2 = ~(SNPi[p] | SNPi[p + 1]);\n      dj2 = ~(SNPj[p] | SNPj[p + 1]);\n\n      t00 = SNPi[p] & SNPj[p];\n      t01 = SNPi[p] & SNPj[p + 1];\n      t02 = SNPi[p] & dj2;\n      t10 = SNPi[p + 1] & SNPj[p];\n      t11 = SNPi[p + 1] & SNPj[p + 1];\n      t12 = SNPi[p + 1] & dj2;\n      t20 = di2 & SNPj[p];\n      t21 = di2 & SNPj[p + 1];\n      t22 = di2 & dj2;\n\n      ft[0] += __popc(t00);\n      ft[1] += __popc(t01);\n      ft[2] += __popc(t02);\n      ft[3] += __popc(t10);\n      ft[4] += __popc(t11);\n      ft[5] += __popc(t12);\n      ft[6] += __popc(t20);\n      ft[7] += __popc(t21);\n      ft[8] += __popc(t22);\n    }\n\n    \n\n    p = 2 * PP_zeros * num_snp - 2 * num_snp;\n    di2 = ~(SNPi[p] | SNPi[p + 1]);\n    dj2 = ~(SNPj[p] | SNPj[p + 1]);\n    di2 = di2 & mask_zeros;\n    dj2 = dj2 & mask_zeros;\n\n    t00 = SNPi[p] & SNPj[p];\n    t01 = SNPi[p] & SNPj[p + 1];\n    t02 = SNPi[p] & dj2;\n    t10 = SNPi[p + 1] & SNPj[p];\n    t11 = SNPi[p + 1] & SNPj[p + 1];\n    t12 = SNPi[p + 1] & dj2;\n    t20 = di2 & SNPj[p];\n    t21 = di2 & SNPj[p + 1];\n    t22 = di2 & dj2;\n\n    ft[0] += __popc(t00);\n    ft[1] += __popc(t01);\n    ft[2] += __popc(t02);\n    ft[3] += __popc(t10);\n    ft[4] += __popc(t11);\n    ft[5] += __popc(t12);\n    ft[6] += __popc(t20);\n    ft[7] += __popc(t21);\n    ft[8] += __popc(t22);\n\n    \n\n    SNPi = (unsigned int*) &dev_data_ones[i * 2];\n    SNPj = (unsigned int*) &dev_data_ones[j * 2];\n\n    #pragma unroll 1\n    for(p = 0; p < 2 * PP_ones * num_snp - 2 * num_snp; p += 2 * num_snp)\n    {\n      di2 = ~(SNPi[p] | SNPi[p + 1]);\n      dj2 = ~(SNPj[p] | SNPj[p + 1]);\n\n      t00 = SNPi[p] & SNPj[p];\n      t01 = SNPi[p] & SNPj[p + 1];\n      t02 = SNPi[p] & dj2;\n      t10 = SNPi[p + 1] & SNPj[p];\n      t11 = SNPi[p + 1] & SNPj[p + 1];\n      t12 = SNPi[p + 1] & dj2;\n      t20 = di2 & SNPj[p];\n      t21 = di2 & SNPj[p + 1];\n      t22 = di2 & dj2;\n\n      ft[9]  += __popc(t00);\n      ft[10] += __popc(t01);\n      ft[11] += __popc(t02);\n      ft[12] += __popc(t10);\n      ft[13] += __popc(t11);\n      ft[14] += __popc(t12);\n      ft[15] += __popc(t20);\n      ft[16] += __popc(t21);\n      ft[17] += __popc(t22);\n    }\n    p = 2 * PP_ones * num_snp - 2 * num_snp;\n    di2 = ~(SNPi[p] | SNPi[p + 1]);\n    dj2 = ~(SNPj[p] | SNPj[p + 1]);\n    di2 = di2 & mask_ones;\n    dj2 = dj2 & mask_ones;\n\n    t00 = SNPi[p] & SNPj[p];\n    t01 = SNPi[p] & SNPj[p + 1];\n    t02 = SNPi[p] & dj2;\n    t10 = SNPi[p + 1] & SNPj[p];\n    t11 = SNPi[p + 1] & SNPj[p + 1];\n    t12 = SNPi[p + 1] & dj2;\n    t20 = di2 & SNPj[p];\n    t21 = di2 & SNPj[p + 1];\n    t22 = di2 & dj2;\n\n    ft[9]  += __popc(t00);\n    ft[10] += __popc(t01);\n    ft[11] += __popc(t02);\n    ft[12] += __popc(t10);\n    ft[13] += __popc(t11);\n    ft[14] += __popc(t12);\n    ft[15] += __popc(t20);\n    ft[16] += __popc(t21);\n    ft[17] += __popc(t22);\n\n    \n\n    float score = 0.0f;\n\n    #pragma unroll\n    for(k = 0; k < 9; k++)\n      score += gammafunction(ft[k] + ft[9 + k] + 1) -\n               gammafunction(ft[k]) - gammafunction(ft[9 + k]);\n    score = fabsf(score);\n    if(score == 0.0f)\n      score = FLT_MAX;\n    dev_scores[tid] = score;\n  }\n}\n\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of samples> <number of SNPs> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int i, j, x;\n  int num_pac = atoi(argv[1]);  \n\n  int num_snp = atoi(argv[2]);  \n\n  int iteration = atoi(argv[3]);\n\n  int block_snp = 64;\n\n  srand(100);\n  unsigned char *SNP_Data = mem_alloc<unsigned char>(64, num_pac * num_snp);\n  unsigned char *Ph_Data = mem_alloc<unsigned char>(64, num_pac);\n\n  \n\n  for (i = 0; i < num_pac; i++)\n    for(j = 0; j < num_snp; j++)\n      SNP_Data[i * num_snp + j] = rand() % 3;\n\n  \n\n  for(int i = 0; i < num_pac; i++) Ph_Data[i] = rand() % 2;\n\n  \n\n  unsigned char *SNP_Data_trans = mem_alloc<unsigned char>(64, num_pac * num_snp);\n\n  for (i = 0; i < num_pac; i++) \n    for(j = 0; j < num_snp; j++) \n      SNP_Data_trans[j * num_pac + i] = SNP_Data[i * num_snp + j];\n\n  int phen_ones = 0;\n  for(i = 0; i < num_pac; i++)\n    if(Ph_Data[i] == 1)\n      phen_ones++;\n\n  \n\n\n  int PP_zeros = ceil((1.0*(num_pac - phen_ones))/32.0);\n  int PP_ones = ceil((1.0*phen_ones)/32.0);\n\n  unsigned int *bin_data_zeros = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n  unsigned int *bin_data_ones = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n  memset(bin_data_zeros, 0, num_snp*PP_zeros*2*sizeof(unsigned int));\n  memset(bin_data_ones, 0, num_snp*PP_ones*2*sizeof(unsigned int));\n\n  for(i = 0; i < num_snp; i++)\n  {\n    int x_zeros = -1;\n    int x_ones = -1;\n    int n_zeros = 0;\n    int n_ones = 0;\n\n    for(j = 0; j < num_pac; j++){\n      unsigned int temp = (unsigned int) SNP_Data_trans[i * num_pac + j];\n\n      if(Ph_Data[j] == 1){\n        if(n_ones%32 == 0){\n          x_ones ++;\n        }\n        \n\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 0] <<= 1;\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_ones[i * PP_ones * 2 + x_ones*2 + temp ] |= 1;\n        }\n        n_ones ++;\n      } else {\n        if(n_zeros%32 == 0){\n          x_zeros ++;\n        }\n        \n\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 0] <<= 1;\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + temp] |= 1;\n        }\n        n_zeros ++;\n      }\n    }\n  }\n\n  unsigned int mask_zeros = 0xFFFFFFFF;\n  for(int x = num_pac - phen_ones; x < PP_zeros * 32; x++)\n    mask_zeros = mask_zeros >> 1;\n\n  unsigned int mask_ones = 0xFFFFFFFF;\n  for(x = phen_ones; x < PP_ones * 32; x++)\n    mask_ones = mask_ones >> 1;\n\n  \n\n  unsigned int* bin_data_ones_trans = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_ones; j++)\n    {\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 0] = bin_data_ones[(i * PP_ones + j) * 2 + 0];\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 1] = bin_data_ones[(i * PP_ones + j) * 2 + 1];\n    }\n\n  unsigned int* bin_data_zeros_trans = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_zeros; j++)\n    {\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 0] = bin_data_zeros[(i * PP_zeros + j) * 2 + 0];\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 1] = bin_data_zeros[(i * PP_zeros + j) * 2 + 1];\n    }\n\n  float *scores = mem_alloc<float>(64, num_snp * num_snp);\n  float *scores_ref = mem_alloc<float>(64, num_snp * num_snp);\n  for(x = 0; x < num_snp * num_snp; x++) {\n    scores[x] = scores_ref[x] = FLT_MAX;\n  }\n\n  unsigned int* d_data_zeros;\n  cudaMalloc((void**)&d_data_zeros, num_snp*PP_zeros*2*sizeof(unsigned int));\n  cudaMemcpy(d_data_zeros, bin_data_zeros_trans, \n             num_snp*PP_zeros*2*sizeof(unsigned int), cudaMemcpyHostToDevice);\n\n  unsigned int* d_data_ones;\n  cudaMalloc((void**)&d_data_ones, num_snp*PP_ones*2*sizeof(unsigned int));\n  cudaMemcpy(d_data_ones, bin_data_ones_trans, \n             num_snp*PP_ones*2*sizeof(unsigned int), cudaMemcpyHostToDevice);\n\n  float* d_scores;\n  cudaMalloc((void**)&d_scores, num_snp*num_snp*sizeof(float));\n  cudaMemcpy(d_scores, scores, sizeof(float) * num_snp * num_snp, cudaMemcpyHostToDevice);\n\n  \n\n  int num_snp_m = num_snp;\n  while(num_snp_m % block_snp != 0) num_snp_m++;\n\n  dim3 grid(num_snp_m / block_snp, num_snp_m);\n  dim3 block(block_snp, 1);\n\n  \n\n\n  auto kstart = myclock::now();\n\n  for (int i = 0; i < iteration; i++) {\n    epi<<<grid, block>>>(d_data_zeros, d_data_ones, d_scores, num_snp, \n                         PP_zeros, PP_ones, mask_zeros, mask_ones);\n  }\n\n  cudaDeviceSynchronize();\n  myduration ktime = myclock::now() - kstart;\n  auto total_ktime = ktime.count();\n\n  std::cout << \"Average kernel execution time: \"\n            << total_ktime / iteration << \" (s)\" << std::endl;\n\n  cudaMemcpy(scores, d_scores, sizeof(float) * num_snp * num_snp, cudaMemcpyDeviceToHost);\n\n  int p1 = min_score(scores, num_snp, num_snp);\n\n  reference (bin_data_zeros_trans, bin_data_ones_trans, scores_ref, num_snp, \n             PP_zeros, PP_ones, mask_zeros, mask_ones);\n\n  int p2 = min_score(scores_ref, num_snp, num_snp);\n  \n  bool ok = (p1 == p2) && (fabsf(scores[p1] - scores_ref[p2]) < 1e-3f);\n  std::cout << (ok ? \"PASS\" : \"FAIL\") << std::endl;\n\n  cudaFree(d_data_zeros);\n  cudaFree(d_data_ones);\n  cudaFree(d_scores);\n\n  mem_free(bin_data_zeros);\n  mem_free(bin_data_ones);\n  mem_free(bin_data_zeros_trans);\n  mem_free(bin_data_ones_trans);\n  mem_free(scores);\n  mem_free(scores_ref);\n  mem_free(SNP_Data);\n  mem_free(SNP_Data_trans);\n  mem_free(Ph_Data);\n  return 0;\n}\n"}}
{"kernel_name": "epistasis", "parallel_api": "hip", "code": {"main.cu": "#include <math.h>\n#include <float.h>\n#include <fstream>\n#include <string>\n#include <cstring>\n#include <sstream>\n#include <iostream>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\nusing namespace std::chrono;\ntypedef high_resolution_clock myclock;\ntypedef duration<float> myduration;\n\n#define MAX_WG_SIZE 256\n\ntemplate <typename T>\nT* mem_alloc (const int align, const size_t size) {\n  return (T*) aligned_alloc(align, size * sizeof(T));\n}\n\ntemplate <typename T>\nvoid mem_free (T* p) {\n  free(p);\n}\n\n__device__\nfloat gammafunction(unsigned int n)\n{   \n  if(n == 0)\n    return 0.0f;\n  float x = ((float)n + 0.5f) * logf((float) n) - ((float)n - 1.0f);\n  return x;\n}\n\n__global__ void epi(const unsigned int* dev_data_zeros, \n                    const unsigned int* dev_data_ones, \n                    float* dev_scores, \n                    const int num_snp, \n                    const int PP_zeros, \n                    const int PP_ones,\n                    const int mask_zeros, \n                    const int mask_ones) \n{\n  int i, j, tid, p, k;\n\n  j = blockDim.x * blockIdx.x + threadIdx.x; \n  i = blockDim.y * blockIdx.y + threadIdx.y;\n  tid = i * num_snp + j;\n\n  if (j > i && i < num_snp && j < num_snp) {\n    unsigned int ft[2 * 9];\n    for(k = 0; k < 2 * 9; k++) ft[k] = 0;\n\n    unsigned int t00, t01, t02, t10, t11, t12, t20, t21, t22;\n    unsigned int di2, dj2;\n    unsigned int* SNPi;\n    unsigned int* SNPj;\n\n    \n\n    SNPi = (unsigned int*) &dev_data_zeros[i * 2];\n    SNPj = (unsigned int*) &dev_data_zeros[j * 2];\n\n    #pragma unroll 1\n    for (p = 0; p < 2 * PP_zeros * num_snp - 2 * num_snp; p += 2 * num_snp) {\n      di2 = ~(SNPi[p] | SNPi[p + 1]);\n      dj2 = ~(SNPj[p] | SNPj[p + 1]);\n\n      t00 = SNPi[p] & SNPj[p];\n      t01 = SNPi[p] & SNPj[p + 1];\n      t02 = SNPi[p] & dj2;\n      t10 = SNPi[p + 1] & SNPj[p];\n      t11 = SNPi[p + 1] & SNPj[p + 1];\n      t12 = SNPi[p + 1] & dj2;\n      t20 = di2 & SNPj[p];\n      t21 = di2 & SNPj[p + 1];\n      t22 = di2 & dj2;\n\n      ft[0] += __popc(t00);\n      ft[1] += __popc(t01);\n      ft[2] += __popc(t02);\n      ft[3] += __popc(t10);\n      ft[4] += __popc(t11);\n      ft[5] += __popc(t12);\n      ft[6] += __popc(t20);\n      ft[7] += __popc(t21);\n      ft[8] += __popc(t22);\n    }\n\n    \n\n    p = 2 * PP_zeros * num_snp - 2 * num_snp;\n    di2 = ~(SNPi[p] | SNPi[p + 1]);\n    dj2 = ~(SNPj[p] | SNPj[p + 1]);\n    di2 = di2 & mask_zeros;\n    dj2 = dj2 & mask_zeros;\n\n    t00 = SNPi[p] & SNPj[p];\n    t01 = SNPi[p] & SNPj[p + 1];\n    t02 = SNPi[p] & dj2;\n    t10 = SNPi[p + 1] & SNPj[p];\n    t11 = SNPi[p + 1] & SNPj[p + 1];\n    t12 = SNPi[p + 1] & dj2;\n    t20 = di2 & SNPj[p];\n    t21 = di2 & SNPj[p + 1];\n    t22 = di2 & dj2;\n\n    ft[0] += __popc(t00);\n    ft[1] += __popc(t01);\n    ft[2] += __popc(t02);\n    ft[3] += __popc(t10);\n    ft[4] += __popc(t11);\n    ft[5] += __popc(t12);\n    ft[6] += __popc(t20);\n    ft[7] += __popc(t21);\n    ft[8] += __popc(t22);\n\n    \n\n    SNPi = (unsigned int*) &dev_data_ones[i * 2];\n    SNPj = (unsigned int*) &dev_data_ones[j * 2];\n\n    #pragma unroll 1\n    for(p = 0; p < 2 * PP_ones * num_snp - 2 * num_snp; p += 2 * num_snp)\n    {\n      di2 = ~(SNPi[p] | SNPi[p + 1]);\n      dj2 = ~(SNPj[p] | SNPj[p + 1]);\n\n      t00 = SNPi[p] & SNPj[p];\n      t01 = SNPi[p] & SNPj[p + 1];\n      t02 = SNPi[p] & dj2;\n      t10 = SNPi[p + 1] & SNPj[p];\n      t11 = SNPi[p + 1] & SNPj[p + 1];\n      t12 = SNPi[p + 1] & dj2;\n      t20 = di2 & SNPj[p];\n      t21 = di2 & SNPj[p + 1];\n      t22 = di2 & dj2;\n\n      ft[9]  += __popc(t00);\n      ft[10] += __popc(t01);\n      ft[11] += __popc(t02);\n      ft[12] += __popc(t10);\n      ft[13] += __popc(t11);\n      ft[14] += __popc(t12);\n      ft[15] += __popc(t20);\n      ft[16] += __popc(t21);\n      ft[17] += __popc(t22);\n    }\n    p = 2 * PP_ones * num_snp - 2 * num_snp;\n    di2 = ~(SNPi[p] | SNPi[p + 1]);\n    dj2 = ~(SNPj[p] | SNPj[p + 1]);\n    di2 = di2 & mask_ones;\n    dj2 = dj2 & mask_ones;\n\n    t00 = SNPi[p] & SNPj[p];\n    t01 = SNPi[p] & SNPj[p + 1];\n    t02 = SNPi[p] & dj2;\n    t10 = SNPi[p + 1] & SNPj[p];\n    t11 = SNPi[p + 1] & SNPj[p + 1];\n    t12 = SNPi[p + 1] & dj2;\n    t20 = di2 & SNPj[p];\n    t21 = di2 & SNPj[p + 1];\n    t22 = di2 & dj2;\n\n    ft[9]  += __popc(t00);\n    ft[10] += __popc(t01);\n    ft[11] += __popc(t02);\n    ft[12] += __popc(t10);\n    ft[13] += __popc(t11);\n    ft[14] += __popc(t12);\n    ft[15] += __popc(t20);\n    ft[16] += __popc(t21);\n    ft[17] += __popc(t22);\n\n    \n\n    float score = 0.0f;\n\n    #pragma unroll\n    for(k = 0; k < 9; k++)\n      score += gammafunction(ft[k] + ft[9 + k] + 1) -\n               gammafunction(ft[k]) - gammafunction(ft[9 + k]);\n    score = fabsf(score);\n    if(score == 0.0f)\n      score = FLT_MAX;\n    dev_scores[tid] = score;\n  }\n}\n\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of samples> <number of SNPs> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int i, j, x;\n  int num_pac = atoi(argv[1]);  \n\n  int num_snp = atoi(argv[2]);  \n\n  int iteration = atoi(argv[3]);\n\n  int block_snp = 64;\n\n  srand(100);\n  unsigned char *SNP_Data = mem_alloc<unsigned char>(64, num_pac * num_snp);\n  unsigned char *Ph_Data = mem_alloc<unsigned char>(64, num_pac);\n\n  \n\n  for (i = 0; i < num_pac; i++)\n    for(j = 0; j < num_snp; j++)\n      SNP_Data[i * num_snp + j] = rand() % 3;\n\n  \n\n  for(int i = 0; i < num_pac; i++) Ph_Data[i] = rand() % 2;\n\n  \n\n  unsigned char *SNP_Data_trans = mem_alloc<unsigned char>(64, num_pac * num_snp);\n\n  for (i = 0; i < num_pac; i++) \n    for(j = 0; j < num_snp; j++) \n      SNP_Data_trans[j * num_pac + i] = SNP_Data[i * num_snp + j];\n\n  int phen_ones = 0;\n  for(i = 0; i < num_pac; i++)\n    if(Ph_Data[i] == 1)\n      phen_ones++;\n\n  \n\n\n  int PP_zeros = ceil((1.0*(num_pac - phen_ones))/32.0);\n  int PP_ones = ceil((1.0*phen_ones)/32.0);\n\n  unsigned int *bin_data_zeros = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n  unsigned int *bin_data_ones = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n  memset(bin_data_zeros, 0, num_snp*PP_zeros*2*sizeof(unsigned int));\n  memset(bin_data_ones, 0, num_snp*PP_ones*2*sizeof(unsigned int));\n\n  for(i = 0; i < num_snp; i++)\n  {\n    int x_zeros = -1;\n    int x_ones = -1;\n    int n_zeros = 0;\n    int n_ones = 0;\n\n    for(j = 0; j < num_pac; j++){\n      unsigned int temp = (unsigned int) SNP_Data_trans[i * num_pac + j];\n\n      if(Ph_Data[j] == 1){\n        if(n_ones%32 == 0){\n          x_ones ++;\n        }\n        \n\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 0] <<= 1;\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_ones[i * PP_ones * 2 + x_ones*2 + temp ] |= 1;\n        }\n        n_ones ++;\n      } else {\n        if(n_zeros%32 == 0){\n          x_zeros ++;\n        }\n        \n\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 0] <<= 1;\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + temp] |= 1;\n        }\n        n_zeros ++;\n      }\n    }\n  }\n\n  unsigned int mask_zeros = 0xFFFFFFFF;\n  for(int x = num_pac - phen_ones; x < PP_zeros * 32; x++)\n    mask_zeros = mask_zeros >> 1;\n\n  unsigned int mask_ones = 0xFFFFFFFF;\n  for(x = phen_ones; x < PP_ones * 32; x++)\n    mask_ones = mask_ones >> 1;\n\n  \n\n  unsigned int* bin_data_ones_trans = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_ones; j++)\n    {\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 0] = bin_data_ones[(i * PP_ones + j) * 2 + 0];\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 1] = bin_data_ones[(i * PP_ones + j) * 2 + 1];\n    }\n\n  unsigned int* bin_data_zeros_trans = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_zeros; j++)\n    {\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 0] = bin_data_zeros[(i * PP_zeros + j) * 2 + 0];\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 1] = bin_data_zeros[(i * PP_zeros + j) * 2 + 1];\n    }\n\n  float *scores = mem_alloc<float>(64, num_snp * num_snp);\n  float *scores_ref = mem_alloc<float>(64, num_snp * num_snp);\n  for(x = 0; x < num_snp * num_snp; x++) {\n    scores[x] = scores_ref[x] = FLT_MAX;\n  }\n\n  unsigned int* d_data_zeros;\n  hipMalloc((void**)&d_data_zeros, num_snp*PP_zeros*2*sizeof(unsigned int));\n  hipMemcpy(d_data_zeros, bin_data_zeros_trans, \n             num_snp*PP_zeros*2*sizeof(unsigned int), hipMemcpyHostToDevice);\n\n  unsigned int* d_data_ones;\n  hipMalloc((void**)&d_data_ones, num_snp*PP_ones*2*sizeof(unsigned int));\n  hipMemcpy(d_data_ones, bin_data_ones_trans, \n             num_snp*PP_ones*2*sizeof(unsigned int), hipMemcpyHostToDevice);\n\n  float* d_scores;\n  hipMalloc((void**)&d_scores, num_snp*num_snp*sizeof(float));\n  hipMemcpy(d_scores, scores, sizeof(float) * num_snp * num_snp, hipMemcpyHostToDevice);\n\n  \n\n  int num_snp_m = num_snp;\n  while(num_snp_m % block_snp != 0) num_snp_m++;\n\n  dim3 grid(num_snp_m / block_snp, num_snp_m);\n  dim3 block(block_snp, 1);\n\n  \n\n\n  auto kstart = myclock::now();\n\n  for (int i = 0; i < iteration; i++) {\n    epi<<<grid, block>>>(d_data_zeros, d_data_ones, d_scores, num_snp, \n                         PP_zeros, PP_ones, mask_zeros, mask_ones);\n  }\n\n  hipDeviceSynchronize();\n  myduration ktime = myclock::now() - kstart;\n  auto total_ktime = ktime.count();\n\n  std::cout << \"Average kernel execution time: \"\n            << total_ktime / iteration << \" (s)\" << std::endl;\n\n  hipMemcpy(scores, d_scores, sizeof(float) * num_snp * num_snp, hipMemcpyDeviceToHost);\n\n  int p1 = min_score(scores, num_snp, num_snp);\n\n  reference (bin_data_zeros_trans, bin_data_ones_trans, scores_ref, num_snp, \n             PP_zeros, PP_ones, mask_zeros, mask_ones);\n\n  int p2 = min_score(scores_ref, num_snp, num_snp);\n  \n  bool ok = (p1 == p2) && (fabsf(scores[p1] - scores_ref[p2]) < 1e-3f);\n  std::cout << (ok ? \"PASS\" : \"FAIL\") << std::endl;\n\n  hipFree(d_data_zeros);\n  hipFree(d_data_ones);\n  hipFree(d_scores);\n\n  mem_free(bin_data_zeros);\n  mem_free(bin_data_ones);\n  mem_free(bin_data_zeros_trans);\n  mem_free(bin_data_ones_trans);\n  mem_free(scores);\n  mem_free(scores_ref);\n  mem_free(SNP_Data);\n  mem_free(SNP_Data_trans);\n  mem_free(Ph_Data);\n  return 0;\n}\n"}}
{"kernel_name": "epistasis", "parallel_api": "omp", "code": {"main.cpp": "#include <math.h>\n#include <string.h>\n#include <float.h>\n#include <iostream>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\nusing namespace std::chrono;\ntypedef high_resolution_clock myclock;\ntypedef duration<float> myduration;\n\n#define MAX_WG_SIZE 256\n\ntemplate <typename T>\nT* mem_alloc (const int align, const size_t size) {\n  return (T*) aligned_alloc(align, size * sizeof(T));\n}\n\ntemplate <typename T>\nvoid mem_free (T* p) {\n  free(p);\n}\n\n#pragma omp declare target\nfloat gammafunction(unsigned int n)\n{   \n  if(n == 0) return 0.0f;\n  float x = ((float)n + 0.5f) * logf((float)n) - ((float)n - 1.0f);\n  return x;\n}\n\n\n\n\ninline unsigned int popcount (unsigned int x)\n{\n  \n\n  unsigned count = 0;\n  for (char i = 0; i < 32; i++)\n  {\n    count += (x & 0x1);\n    x = x >> 1;\n  }\n  return count;\n}\n#pragma omp end declare target\n\nint main(int argc, char **argv)\n{\n  int i, j, x;\n  int num_pac = atoi(argv[1]);  \n\n  int num_snp = atoi(argv[2]);  \n\n  int iteration = atoi(argv[3]);\n\n  int block_snp = 64;\n\n  srand(100);\n  unsigned char *SNP_Data = mem_alloc<unsigned char>(64, num_pac * num_snp);\n  unsigned char *Ph_Data = mem_alloc<unsigned char>(64, num_pac);\n\n  \n\n  for (i = 0; i < num_pac; i++)\n    for(j = 0; j < num_snp; j++)\n      SNP_Data[i * num_snp + j] = rand() % 3;\n\n  \n\n  for(int i = 0; i < num_pac; i++) Ph_Data[i] = rand() % 2;\n\n  \n\n  unsigned char *SNP_Data_trans = mem_alloc<unsigned char>(64, num_pac * num_snp);\n\n  for (i = 0; i < num_pac; i++) \n    for(j = 0; j < num_snp; j++) \n      SNP_Data_trans[j * num_pac + i] = SNP_Data[i * num_snp + j];\n\n  int phen_ones = 0;\n  for(i = 0; i < num_pac; i++)\n    if(Ph_Data[i] == 1)\n      phen_ones++;\n\n  \n\n\n  int PP_zeros = ceil((1.0*(num_pac - phen_ones))/32.0);\n  int PP_ones = ceil((1.0*phen_ones)/32.0);\n\n  unsigned int *bin_data_zeros = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n  unsigned int *bin_data_ones = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n  memset(bin_data_zeros, 0, num_snp*PP_zeros*2*sizeof(unsigned int));\n  memset(bin_data_ones, 0, num_snp*PP_ones*2*sizeof(unsigned int));\n\n  for(i = 0; i < num_snp; i++)\n  {\n    int x_zeros = -1;\n    int x_ones = -1;\n    int n_zeros = 0;\n    int n_ones = 0;\n\n    for(j = 0; j < num_pac; j++){\n      unsigned int temp = (unsigned int) SNP_Data_trans[i * num_pac + j];\n\n      if(Ph_Data[j] == 1){\n        if(n_ones%32 == 0){\n          x_ones ++;\n        }\n        \n\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 0] <<= 1;\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_ones[i * PP_ones * 2 + x_ones*2 + temp ] |= 1;\n        }\n        n_ones ++;\n      } else {\n        if(n_zeros%32 == 0){\n          x_zeros ++;\n        }\n        \n\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 0] <<= 1;\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + temp] |= 1;\n        }\n        n_zeros ++;\n      }\n    }\n  }\n\n  unsigned int mask_zeros = 0xFFFFFFFF;\n  for(int x = num_pac - phen_ones; x < PP_zeros * 32; x++)\n    mask_zeros = mask_zeros >> 1;\n\n  unsigned int mask_ones = 0xFFFFFFFF;\n  for(x = phen_ones; x < PP_ones * 32; x++)\n    mask_ones = mask_ones >> 1;\n\n  \n\n  unsigned int* bin_data_ones_trans = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_ones; j++)\n    {\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 0] = bin_data_ones[(i * PP_ones + j) * 2 + 0];\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 1] = bin_data_ones[(i * PP_ones + j) * 2 + 1];\n    }\n\n  unsigned int* bin_data_zeros_trans = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_zeros; j++)\n    {\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 0] = bin_data_zeros[(i * PP_zeros + j) * 2 + 0];\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 1] = bin_data_zeros[(i * PP_zeros + j) * 2 + 1];\n    }\n\n  float *scores = mem_alloc<float>(64, num_snp * num_snp);\n  float *scores_ref = mem_alloc<float>(64, num_snp * num_snp);\n  for(x = 0; x < num_snp * num_snp; x++) {\n    scores[x] = scores_ref[x] = FLT_MAX;\n  }\n\n  unsigned int* dev_data_zeros = bin_data_zeros_trans;\n  unsigned int* dev_data_ones = bin_data_ones_trans;\n  float *dev_scores = scores;\n\n  #pragma omp target data map(to: dev_data_zeros[0:num_snp * PP_zeros * 2], \\\n                                  dev_data_ones[0:num_snp * PP_ones * 2]) \\\n                          map(tofrom: dev_scores[0:num_snp * num_snp])\n  {\n    int num_snp_m = num_snp;\n    while(num_snp_m % block_snp != 0) num_snp_m++;\n\n    \n\n\n    auto kstart = myclock::now();\n\n    for (int i = 0; i < iteration; i++) {\n\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(block_snp)\n      for (int i = 0; i < num_snp_m; i++) {\n        for (int j = 0; j < num_snp_m; j++) {\n\n          float score = FLT_MAX;\n\n          int tid = i * num_snp + j;\n\n          if (j > i && i < num_snp && j < num_snp) {\n            unsigned int ft[2 * 9];\n            for(int k = 0; k < 2 * 9; k++) ft[k] = 0;\n\n            unsigned int t00, t01, t02, t10, t11, t12, t20, t21, t22;\n            unsigned int di2, dj2;\n            unsigned int* SNPi;\n            unsigned int* SNPj;\n\n            \n\n            SNPi = (unsigned int*) &dev_data_zeros[i * 2];\n            SNPj = (unsigned int*) &dev_data_zeros[j * 2];\n            #pragma unroll 1\n            for (int p = 0; p < 2 * PP_zeros * num_snp - 2 * num_snp; p += 2 * num_snp) {\n              di2 = ~(SNPi[p] | SNPi[p + 1]);\n              dj2 = ~(SNPj[p] | SNPj[p + 1]);\n\n              t00 = SNPi[p] & SNPj[p];\n              t01 = SNPi[p] & SNPj[p + 1];\n              t02 = SNPi[p] & dj2;\n              t10 = SNPi[p + 1] & SNPj[p];\n              t11 = SNPi[p + 1] & SNPj[p + 1];\n              t12 = SNPi[p + 1] & dj2;\n              t20 = di2 & SNPj[p];\n              t21 = di2 & SNPj[p + 1];\n              t22 = di2 & dj2;\n\n              ft[0] += popcount(t00);\n              ft[1] += popcount(t01);\n              ft[2] += popcount(t02);\n              ft[3] += popcount(t10);\n              ft[4] += popcount(t11);\n              ft[5] += popcount(t12);\n              ft[6] += popcount(t20);\n              ft[7] += popcount(t21);\n              ft[8] += popcount(t22);\n            }\n\n            \n\n            int p = 2 * PP_zeros * num_snp - 2 * num_snp;\n            di2 = ~(SNPi[p] | SNPi[p + 1]);\n            dj2 = ~(SNPj[p] | SNPj[p + 1]);\n            di2 = di2 & mask_zeros;\n            dj2 = dj2 & mask_zeros;\n\n            t00 = SNPi[p] & SNPj[p];\n            t01 = SNPi[p] & SNPj[p + 1];\n            t02 = SNPi[p] & dj2;\n            t10 = SNPi[p + 1] & SNPj[p];\n            t11 = SNPi[p + 1] & SNPj[p + 1];\n            t12 = SNPi[p + 1] & dj2;\n            t20 = di2 & SNPj[p];\n            t21 = di2 & SNPj[p + 1];\n            t22 = di2 & dj2;\n\n            ft[0] += popcount(t00);\n            ft[1] += popcount(t01);\n            ft[2] += popcount(t02);\n            ft[3] += popcount(t10);\n            ft[4] += popcount(t11);\n            ft[5] += popcount(t12);\n            ft[6] += popcount(t20);\n            ft[7] += popcount(t21);\n            ft[8] += popcount(t22);\n\n            \n\n            SNPi = (unsigned int*) &dev_data_ones[i * 2];\n            SNPj = (unsigned int*) &dev_data_ones[j * 2];\n            #pragma unroll 1\n            for(p = 0; p < 2 * PP_ones * num_snp - 2 * num_snp; p += 2 * num_snp)\n            {\n              di2 = ~(SNPi[p] | SNPi[p + 1]);\n              dj2 = ~(SNPj[p] | SNPj[p + 1]);\n\n              t00 = SNPi[p] & SNPj[p];\n              t01 = SNPi[p] & SNPj[p + 1];\n              t02 = SNPi[p] & dj2;\n              t10 = SNPi[p + 1] & SNPj[p];\n              t11 = SNPi[p + 1] & SNPj[p + 1];\n              t12 = SNPi[p + 1] & dj2;\n              t20 = di2 & SNPj[p];\n              t21 = di2 & SNPj[p + 1];\n              t22 = di2 & dj2;\n\n              ft[9]  += popcount(t00);\n              ft[10] += popcount(t01);\n              ft[11] += popcount(t02);\n              ft[12] += popcount(t10);\n              ft[13] += popcount(t11);\n              ft[14] += popcount(t12);\n              ft[15] += popcount(t20);\n              ft[16] += popcount(t21);\n              ft[17] += popcount(t22);\n            }\n            p = 2 * PP_ones * num_snp - 2 * num_snp;\n            di2 = ~(SNPi[p] | SNPi[p + 1]);\n            dj2 = ~(SNPj[p] | SNPj[p + 1]);\n            di2 = di2 & mask_ones;\n            dj2 = dj2 & mask_ones;\n\n            t00 = SNPi[p] & SNPj[p];\n            t01 = SNPi[p] & SNPj[p + 1];\n            t02 = SNPi[p] & dj2;\n            t10 = SNPi[p + 1] & SNPj[p];\n            t11 = SNPi[p + 1] & SNPj[p + 1];\n            t12 = SNPi[p + 1] & dj2;\n            t20 = di2 & SNPj[p];\n            t21 = di2 & SNPj[p + 1];\n            t22 = di2 & dj2;\n\n            ft[9]  += popcount(t00);\n            ft[10] += popcount(t01);\n            ft[11] += popcount(t02);\n            ft[12] += popcount(t10);\n            ft[13] += popcount(t11);\n            ft[14] += popcount(t12);\n            ft[15] += popcount(t20);\n            ft[16] += popcount(t21);\n            ft[17] += popcount(t22);\n\n            \n\n            score = 0.0f;\n            #pragma unroll\n            for(int k = 0; k < 9; k++)\n              score += gammafunction(ft[k] + ft[9 + k] + 1) - gammafunction(ft[k]) - gammafunction(ft[9 + k]);\n            score = fabs((float) score);\n            if(score == 0.0f)\n              score = FLT_MAX;\n            dev_scores[tid] = score;\n          }\n        }\n      }\n    }\n    myduration ktime = myclock::now() - kstart;\n    auto total_ktime = ktime.count();\n    std::cout << \"Average kernel execution time: \"\n              << total_ktime / iteration << \" (s)\" << std::endl;\n  }\n\n  int p1 = min_score(scores, num_snp, num_snp);\n\n  reference (bin_data_zeros_trans, bin_data_ones_trans, scores_ref, num_snp, \n             PP_zeros, PP_ones, mask_zeros, mask_ones);\n\n  int p2 = min_score(scores_ref, num_snp, num_snp);\n  \n  bool ok = (p1 == p2) && (fabsf(scores[p1] - scores_ref[p2]) < 1e-3f);\n  std::cout << (ok ? \"PASS\" : \"FAIL\") << std::endl;\n\n  mem_free(bin_data_zeros);\n  mem_free(bin_data_ones);\n  mem_free(bin_data_zeros_trans);\n  mem_free(bin_data_ones_trans);\n  mem_free(scores);\n  mem_free(scores_ref);\n  mem_free(SNP_Data);\n  mem_free(SNP_Data_trans);\n  mem_free(Ph_Data);\n  return 0;\n}\n"}}
{"kernel_name": "epistasis", "parallel_api": "serial", "code": {"main.cpp": "#include <math.h>\n#include <string.h>\n#include <float.h>\n#include <iostream>\n#include <chrono>\n#include \"reference.h\"\n\nusing namespace std::chrono;\ntypedef high_resolution_clock myclock;\ntypedef duration<float> myduration;\n\n#define MAX_WG_SIZE 256\n\ntemplate <typename T>\nT* mem_alloc (const int align, const size_t size) {\n  return (T*) aligned_alloc(align, size * sizeof(T));\n}\n\ntemplate <typename T>\nvoid mem_free (T* p) {\n  free(p);\n}\n\nfloat gammafunction(unsigned int n)\n{   \n  if(n == 0) return 0.0f;\n  float x = ((float)n + 0.5f) * logf((float)n) - ((float)n - 1.0f);\n  return x;\n}\n\n\n\n\ninline unsigned int popcount (unsigned int x)\n{\n  \n\n  unsigned count = 0;\n  for (char i = 0; i < 32; i++)\n  {\n    count += (x & 0x1);\n    x = x >> 1;\n  }\n  return count;\n}\n\nint main(int argc, char **argv)\n{\n  int i, j, x;\n  int num_pac = atoi(argv[1]);  \n\n  int num_snp = atoi(argv[2]);  \n\n  int iteration = atoi(argv[3]);\n\n  int block_snp = 64;\n\n  srand(100);\n  unsigned char *SNP_Data = mem_alloc<unsigned char>(64, num_pac * num_snp);\n  unsigned char *Ph_Data = mem_alloc<unsigned char>(64, num_pac);\n\n  \n\n  for (i = 0; i < num_pac; i++)\n    for(j = 0; j < num_snp; j++)\n      SNP_Data[i * num_snp + j] = rand() % 3;\n\n  \n\n  for(int i = 0; i < num_pac; i++) Ph_Data[i] = rand() % 2;\n\n  \n\n  unsigned char *SNP_Data_trans = mem_alloc<unsigned char>(64, num_pac * num_snp);\n\n  for (i = 0; i < num_pac; i++) \n    for(j = 0; j < num_snp; j++) \n      SNP_Data_trans[j * num_pac + i] = SNP_Data[i * num_snp + j];\n\n  int phen_ones = 0;\n  for(i = 0; i < num_pac; i++)\n    if(Ph_Data[i] == 1)\n      phen_ones++;\n\n  \n\n\n  int PP_zeros = ceil((1.0*(num_pac - phen_ones))/32.0);\n  int PP_ones = ceil((1.0*phen_ones)/32.0);\n\n  unsigned int *bin_data_zeros = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n  unsigned int *bin_data_ones = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n  memset(bin_data_zeros, 0, num_snp*PP_zeros*2*sizeof(unsigned int));\n  memset(bin_data_ones, 0, num_snp*PP_ones*2*sizeof(unsigned int));\n\n  for(i = 0; i < num_snp; i++)\n  {\n    int x_zeros = -1;\n    int x_ones = -1;\n    int n_zeros = 0;\n    int n_ones = 0;\n\n    for(j = 0; j < num_pac; j++){\n      unsigned int temp = (unsigned int) SNP_Data_trans[i * num_pac + j];\n\n      if(Ph_Data[j] == 1){\n        if(n_ones%32 == 0){\n          x_ones ++;\n        }\n        \n\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 0] <<= 1;\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_ones[i * PP_ones * 2 + x_ones*2 + temp ] |= 1;\n        }\n        n_ones ++;\n      } else {\n        if(n_zeros%32 == 0){\n          x_zeros ++;\n        }\n        \n\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 0] <<= 1;\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + temp] |= 1;\n        }\n        n_zeros ++;\n      }\n    }\n  }\n\n  unsigned int mask_zeros = 0xFFFFFFFF;\n  for(int x = num_pac - phen_ones; x < PP_zeros * 32; x++)\n    mask_zeros = mask_zeros >> 1;\n\n  unsigned int mask_ones = 0xFFFFFFFF;\n  for(x = phen_ones; x < PP_ones * 32; x++)\n    mask_ones = mask_ones >> 1;\n\n  \n\n  unsigned int* bin_data_ones_trans = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_ones; j++)\n    {\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 0] = bin_data_ones[(i * PP_ones + j) * 2 + 0];\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 1] = bin_data_ones[(i * PP_ones + j) * 2 + 1];\n    }\n\n  unsigned int* bin_data_zeros_trans = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_zeros; j++)\n    {\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 0] = bin_data_zeros[(i * PP_zeros + j) * 2 + 0];\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 1] = bin_data_zeros[(i * PP_zeros + j) * 2 + 1];\n    }\n\n  float *scores = mem_alloc<float>(64, num_snp * num_snp);\n  float *scores_ref = mem_alloc<float>(64, num_snp * num_snp);\n  for(x = 0; x < num_snp * num_snp; x++) {\n    scores[x] = scores_ref[x] = FLT_MAX;\n  }\n\n  unsigned int* dev_data_zeros = bin_data_zeros_trans;\n  unsigned int* dev_data_ones = bin_data_ones_trans;\n  float *dev_scores = scores;\n\n    {\n    int num_snp_m = num_snp;\n    while(num_snp_m % block_snp != 0) num_snp_m++;\n\n    \n\n\n    auto kstart = myclock::now();\n\n    for (int i = 0; i < iteration; i++) {\n\n            for (int i = 0; i < num_snp_m; i++) {\n        for (int j = 0; j < num_snp_m; j++) {\n\n          float score = FLT_MAX;\n\n          int tid = i * num_snp + j;\n\n          if (j > i && i < num_snp && j < num_snp) {\n            unsigned int ft[2 * 9];\n            for(int k = 0; k < 2 * 9; k++) ft[k] = 0;\n\n            unsigned int t00, t01, t02, t10, t11, t12, t20, t21, t22;\n            unsigned int di2, dj2;\n            unsigned int* SNPi;\n            unsigned int* SNPj;\n\n            \n\n            SNPi = (unsigned int*) &dev_data_zeros[i * 2];\n            SNPj = (unsigned int*) &dev_data_zeros[j * 2];\n                        for (int p = 0; p < 2 * PP_zeros * num_snp - 2 * num_snp; p += 2 * num_snp) {\n              di2 = ~(SNPi[p] | SNPi[p + 1]);\n              dj2 = ~(SNPj[p] | SNPj[p + 1]);\n\n              t00 = SNPi[p] & SNPj[p];\n              t01 = SNPi[p] & SNPj[p + 1];\n              t02 = SNPi[p] & dj2;\n              t10 = SNPi[p + 1] & SNPj[p];\n              t11 = SNPi[p + 1] & SNPj[p + 1];\n              t12 = SNPi[p + 1] & dj2;\n              t20 = di2 & SNPj[p];\n              t21 = di2 & SNPj[p + 1];\n              t22 = di2 & dj2;\n\n              ft[0] += popcount(t00);\n              ft[1] += popcount(t01);\n              ft[2] += popcount(t02);\n              ft[3] += popcount(t10);\n              ft[4] += popcount(t11);\n              ft[5] += popcount(t12);\n              ft[6] += popcount(t20);\n              ft[7] += popcount(t21);\n              ft[8] += popcount(t22);\n            }\n\n            \n\n            int p = 2 * PP_zeros * num_snp - 2 * num_snp;\n            di2 = ~(SNPi[p] | SNPi[p + 1]);\n            dj2 = ~(SNPj[p] | SNPj[p + 1]);\n            di2 = di2 & mask_zeros;\n            dj2 = dj2 & mask_zeros;\n\n            t00 = SNPi[p] & SNPj[p];\n            t01 = SNPi[p] & SNPj[p + 1];\n            t02 = SNPi[p] & dj2;\n            t10 = SNPi[p + 1] & SNPj[p];\n            t11 = SNPi[p + 1] & SNPj[p + 1];\n            t12 = SNPi[p + 1] & dj2;\n            t20 = di2 & SNPj[p];\n            t21 = di2 & SNPj[p + 1];\n            t22 = di2 & dj2;\n\n            ft[0] += popcount(t00);\n            ft[1] += popcount(t01);\n            ft[2] += popcount(t02);\n            ft[3] += popcount(t10);\n            ft[4] += popcount(t11);\n            ft[5] += popcount(t12);\n            ft[6] += popcount(t20);\n            ft[7] += popcount(t21);\n            ft[8] += popcount(t22);\n\n            \n\n            SNPi = (unsigned int*) &dev_data_ones[i * 2];\n            SNPj = (unsigned int*) &dev_data_ones[j * 2];\n                        for(p = 0; p < 2 * PP_ones * num_snp - 2 * num_snp; p += 2 * num_snp)\n            {\n              di2 = ~(SNPi[p] | SNPi[p + 1]);\n              dj2 = ~(SNPj[p] | SNPj[p + 1]);\n\n              t00 = SNPi[p] & SNPj[p];\n              t01 = SNPi[p] & SNPj[p + 1];\n              t02 = SNPi[p] & dj2;\n              t10 = SNPi[p + 1] & SNPj[p];\n              t11 = SNPi[p + 1] & SNPj[p + 1];\n              t12 = SNPi[p + 1] & dj2;\n              t20 = di2 & SNPj[p];\n              t21 = di2 & SNPj[p + 1];\n              t22 = di2 & dj2;\n\n              ft[9]  += popcount(t00);\n              ft[10] += popcount(t01);\n              ft[11] += popcount(t02);\n              ft[12] += popcount(t10);\n              ft[13] += popcount(t11);\n              ft[14] += popcount(t12);\n              ft[15] += popcount(t20);\n              ft[16] += popcount(t21);\n              ft[17] += popcount(t22);\n            }\n            p = 2 * PP_ones * num_snp - 2 * num_snp;\n            di2 = ~(SNPi[p] | SNPi[p + 1]);\n            dj2 = ~(SNPj[p] | SNPj[p + 1]);\n            di2 = di2 & mask_ones;\n            dj2 = dj2 & mask_ones;\n\n            t00 = SNPi[p] & SNPj[p];\n            t01 = SNPi[p] & SNPj[p + 1];\n            t02 = SNPi[p] & dj2;\n            t10 = SNPi[p + 1] & SNPj[p];\n            t11 = SNPi[p + 1] & SNPj[p + 1];\n            t12 = SNPi[p + 1] & dj2;\n            t20 = di2 & SNPj[p];\n            t21 = di2 & SNPj[p + 1];\n            t22 = di2 & dj2;\n\n            ft[9]  += popcount(t00);\n            ft[10] += popcount(t01);\n            ft[11] += popcount(t02);\n            ft[12] += popcount(t10);\n            ft[13] += popcount(t11);\n            ft[14] += popcount(t12);\n            ft[15] += popcount(t20);\n            ft[16] += popcount(t21);\n            ft[17] += popcount(t22);\n\n            \n\n            score = 0.0f;\n                        for(int k = 0; k < 9; k++)\n              score += gammafunction(ft[k] + ft[9 + k] + 1) - gammafunction(ft[k]) - gammafunction(ft[9 + k]);\n            score = fabs((float) score);\n            if(score == 0.0f)\n              score = FLT_MAX;\n            dev_scores[tid] = score;\n          }\n        }\n      }\n    }\n    myduration ktime = myclock::now() - kstart;\n    auto total_ktime = ktime.count();\n    std::cout << \"Average kernel execution time: \"\n              << total_ktime / iteration << \" (s)\" << std::endl;\n  }\n\n  int p1 = min_score(scores, num_snp, num_snp);\n\n  reference (bin_data_zeros_trans, bin_data_ones_trans, scores_ref, num_snp, \n             PP_zeros, PP_ones, mask_zeros, mask_ones);\n\n  int p2 = min_score(scores_ref, num_snp, num_snp);\n  \n  bool ok = (p1 == p2) && (fabsf(scores[p1] - scores_ref[p2]) < 1e-3f);\n  std::cout << (ok ? \"PASS\" : \"FAIL\") << std::endl;\n\n  mem_free(bin_data_zeros);\n  mem_free(bin_data_ones);\n  mem_free(bin_data_zeros_trans);\n  mem_free(bin_data_ones_trans);\n  mem_free(scores);\n  mem_free(scores_ref);\n  mem_free(SNP_Data);\n  mem_free(SNP_Data_trans);\n  mem_free(Ph_Data);\n  return 0;\n}"}}
{"kernel_name": "epistasis", "parallel_api": "sycl", "code": {"main.cpp": "#include <math.h>\n#include <float.h>\n#include <iostream>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nusing namespace std::chrono;\ntypedef high_resolution_clock myclock;\ntypedef duration<float> myduration;\n\n#define MAX_WG_SIZE 256\n\ntemplate <typename T>\nT* mem_alloc (const int align, const size_t size) {\n  return (T*) aligned_alloc(align, size * sizeof(T));\n}\n\ntemplate <typename T>\nvoid mem_free (T* p) {\n  free(p);\n}\n\nfloat gammafunction(unsigned int n)\n{   \n  if(n == 0)\n    return 0.0f;\n  float x = ((float)n + 0.5f) * sycl::log((float) n) - ((float)n - 1.0f);\n  return x;\n}\n\n\nint main(int argc, char **argv)\n{\n  int i, j, x;\n  int num_pac = atoi(argv[1]);  \n\n  int num_snp = atoi(argv[2]);  \n\n  int iteration = atoi(argv[3]);\n\n  int block_snp = 64;\n\n  srand(100);\n  unsigned char *SNP_Data = mem_alloc<unsigned char>(64, num_pac * num_snp);\n  unsigned char *Ph_Data = mem_alloc<unsigned char>(64, num_pac);\n\n  \n\n  for (i = 0; i < num_pac; i++)\n    for(j = 0; j < num_snp; j++)\n      SNP_Data[i * num_snp + j] = rand() % 3;\n\n  \n\n  for(int i = 0; i < num_pac; i++) Ph_Data[i] = rand() % 2;\n\n  \n\n  unsigned char *SNP_Data_trans = mem_alloc<unsigned char>(64, num_pac * num_snp);\n\n  for (i = 0; i < num_pac; i++) \n    for(j = 0; j < num_snp; j++) \n      SNP_Data_trans[j * num_pac + i] = SNP_Data[i * num_snp + j];\n\n  int phen_ones = 0;\n  for(i = 0; i < num_pac; i++)\n    if(Ph_Data[i] == 1)\n      phen_ones++;\n\n  \n\n\n  int PP_zeros = ceil((1.0*(num_pac - phen_ones))/32.0);\n  int PP_ones = ceil((1.0*phen_ones)/32.0);\n\n  unsigned int *bin_data_zeros = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n  unsigned int *bin_data_ones = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n  memset(bin_data_zeros, 0, num_snp*PP_zeros*2*sizeof(unsigned int));\n  memset(bin_data_ones, 0, num_snp*PP_ones*2*sizeof(unsigned int));\n\n  for(i = 0; i < num_snp; i++)\n  {\n    int x_zeros = -1;\n    int x_ones = -1;\n    int n_zeros = 0;\n    int n_ones = 0;\n\n    for(j = 0; j < num_pac; j++){\n      unsigned int temp = (unsigned int) SNP_Data_trans[i * num_pac + j];\n\n      if(Ph_Data[j] == 1){\n        if(n_ones%32 == 0){\n          x_ones ++;\n        }\n        \n\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 0] <<= 1;\n        bin_data_ones[i * PP_ones * 2 + x_ones*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_ones[i * PP_ones * 2 + x_ones*2 + temp ] |= 1;\n        }\n        n_ones ++;\n      } else {\n        if(n_zeros%32 == 0){\n          x_zeros ++;\n        }\n        \n\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 0] <<= 1;\n        bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + 1] <<= 1;\n        \n\n        if(temp == 0 || temp == 1){\n          bin_data_zeros[i * PP_zeros * 2 + x_zeros*2 + temp] |= 1;\n        }\n        n_zeros ++;\n      }\n    }\n  }\n\n  unsigned int mask_zeros = 0xFFFFFFFF;\n  for(int x = num_pac - phen_ones; x < PP_zeros * 32; x++)\n    mask_zeros = mask_zeros >> 1;\n\n  unsigned int mask_ones = 0xFFFFFFFF;\n  for(x = phen_ones; x < PP_ones * 32; x++)\n    mask_ones = mask_ones >> 1;\n\n  \n\n  unsigned int* bin_data_ones_trans = mem_alloc<unsigned int>(64, num_snp * PP_ones * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_ones; j++)\n    {\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 0] = bin_data_ones[(i * PP_ones + j) * 2 + 0];\n      bin_data_ones_trans[(j * num_snp + i) * 2 + 1] = bin_data_ones[(i * PP_ones + j) * 2 + 1];\n    }\n\n  unsigned int* bin_data_zeros_trans = mem_alloc<unsigned int>(64, num_snp * PP_zeros * 2);\n\n  for(i = 0; i < num_snp; i++)\n    for(j = 0; j < PP_zeros; j++)\n    {\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 0] = bin_data_zeros[(i * PP_zeros + j) * 2 + 0];\n      bin_data_zeros_trans[(j * num_snp + i) * 2 + 1] = bin_data_zeros[(i * PP_zeros + j) * 2 + 1];\n    }\n\n  float *scores = mem_alloc<float>(64, num_snp * num_snp);\n  float *scores_ref = mem_alloc<float>(64, num_snp * num_snp);\n  for(x = 0; x < num_snp * num_snp; x++) {\n    scores[x] = scores_ref[x] = FLT_MAX;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  unsigned int* d_data_zeros = sycl::malloc_device<unsigned int>(num_snp*PP_zeros*2, q);\n  q.memcpy(d_data_zeros, bin_data_zeros_trans,\n           num_snp*PP_zeros*2*sizeof(unsigned int));\n\n  unsigned int* d_data_ones = sycl::malloc_device<unsigned int>(num_snp*PP_ones*2, q);\n  q.memcpy(d_data_ones, bin_data_ones_trans,\n           num_snp*PP_ones*2*sizeof(unsigned int));\n\n  float *d_scores= sycl::malloc_device<float>(num_snp * num_snp, q);\n  q.memcpy(d_scores, scores, sizeof(float) * num_snp * num_snp);\n\n  \n\n  int num_snp_m = num_snp;\n  while(num_snp_m % block_snp != 0) num_snp_m++;\n  sycl::range<2> global_epi(num_snp_m, num_snp_m);\n  sycl::range<2> local_epi(1, block_snp);\n\n  \n\n\n  auto kstart = myclock::now();\n\n  for (int i = 0; i < iteration; i++) {\n\n    q.submit([&](sycl::handler& h) {\n      h.parallel_for<class kernel_epi>(\n      sycl::nd_range<2>(global_epi, local_epi), [=](sycl::nd_item<2> id) {\n        int i, j, tid, p, k;\n\n        i = id.get_global_id(0);\n        j = id.get_global_id(1);\n        tid = i * num_snp + j;\n\n        if (j > i && i < num_snp && j < num_snp) {\n\n          unsigned int ft[2 * 9];\n          for(k = 0; k < 2 * 9; k++) ft[k] = 0;\n\n          unsigned int t00, t01, t02, t10, t11, t12, t20, t21, t22;\n          unsigned int di2, dj2;\n          unsigned int* SNPi;\n          unsigned int* SNPj;\n          unsigned int SNPi_p, SNPi_p1, SNPj_p, SNPj_p1;\n          \n\n          SNPi = (unsigned int*) &d_data_zeros[i * 2];\n          SNPj = (unsigned int*) &d_data_zeros[j * 2];\n          for (p = 0; p < 2 * PP_zeros * num_snp - 2 * num_snp; p += 2 * num_snp) {\n            SNPi_p = SNPi[p];\n            SNPi_p1 = SNPi[p+1];\n            SNPj_p = SNPj[p];\n            SNPj_p1 = SNPj[p+1];\n\n            di2 = ~(SNPi_p | SNPi_p1);\n            dj2 = ~(SNPj_p | SNPj_p1);\n\n            t00 = SNPi_p & SNPj_p;\n            t01 = SNPi_p & SNPj_p1;\n            t02 = SNPi_p & dj2;\n            t10 = SNPi_p1 & SNPj_p;\n            t11 = SNPi_p1 & SNPj_p1;\n            t12 = SNPi_p1 & dj2;\n            t20 = di2 & SNPj_p;\n            t21 = di2 & SNPj_p1;\n            t22 = di2 & dj2;\n\n            ft[0] += sycl::popcount(t00);\n            ft[1] += sycl::popcount(t01);\n            ft[2] += sycl::popcount(t02);\n            ft[3] += sycl::popcount(t10);\n            ft[4] += sycl::popcount(t11);\n            ft[5] += sycl::popcount(t12);\n            ft[6] += sycl::popcount(t20);\n            ft[7] += sycl::popcount(t21);\n            ft[8] += sycl::popcount(t22);\n          }\n\n          \n\n          p = 2 * PP_zeros * num_snp - 2 * num_snp;\n          SNPi_p = SNPi[p];\n          SNPi_p1 = SNPi[p+1];\n          SNPj_p = SNPj[p];\n          SNPj_p1 = SNPj[p+1];\n          di2 = ~(SNPi_p | SNPi_p1);\n          dj2 = ~(SNPj_p | SNPj_p1);\n          di2 = di2 & mask_zeros;\n          dj2 = dj2 & mask_zeros;\n\n          t00 = SNPi_p & SNPj_p;\n          t01 = SNPi_p & SNPj_p1;\n          t02 = SNPi_p & dj2;\n          t10 = SNPi_p1 & SNPj_p;\n          t11 = SNPi_p1 & SNPj_p1;\n          t12 = SNPi_p1 & dj2;\n          t20 = di2 & SNPj_p;\n          t21 = di2 & SNPj_p1;\n          t22 = di2 & dj2;\n\n          ft[0] += sycl::popcount(t00);\n          ft[1] += sycl::popcount(t01);\n          ft[2] += sycl::popcount(t02);\n          ft[3] += sycl::popcount(t10);\n          ft[4] += sycl::popcount(t11);\n          ft[5] += sycl::popcount(t12);\n          ft[6] += sycl::popcount(t20);\n          ft[7] += sycl::popcount(t21);\n          ft[8] += sycl::popcount(t22);\n\n          \n\n          SNPi = (unsigned int*) &d_data_ones[i * 2];\n          SNPj = (unsigned int*) &d_data_ones[j * 2];\n          for(p = 0; p < 2 * PP_ones * num_snp - 2 * num_snp; p += 2 * num_snp)\n          {\n            SNPi_p = SNPi[p];\n            SNPi_p1 = SNPi[p+1];\n            SNPj_p = SNPj[p];\n            SNPj_p1 = SNPj[p+1];\n\n            di2 = ~(SNPi_p | SNPi_p1);\n            dj2 = ~(SNPj_p | SNPj_p1);\n\n            t00 = SNPi_p & SNPj_p;\n            t01 = SNPi_p & SNPj_p1;\n            t02 = SNPi_p & dj2;\n            t10 = SNPi_p1 & SNPj_p;\n            t11 = SNPi_p1 & SNPj_p1;\n            t12 = SNPi_p1 & dj2;\n            t20 = di2 & SNPj_p;\n            t21 = di2 & SNPj_p1;\n            t22 = di2 & dj2;\n\n            ft[9]  += sycl::popcount(t00);\n            ft[10] += sycl::popcount(t01);\n            ft[11] += sycl::popcount(t02);\n            ft[12] += sycl::popcount(t10);\n            ft[13] += sycl::popcount(t11);\n            ft[14] += sycl::popcount(t12);\n            ft[15] += sycl::popcount(t20);\n            ft[16] += sycl::popcount(t21);\n            ft[17] += sycl::popcount(t22);\n          }\n          p = 2 * PP_ones * num_snp - 2 * num_snp;\n          SNPi_p = SNPi[p];\n          SNPi_p1 = SNPi[p+1];\n          SNPj_p = SNPj[p];\n          SNPj_p1 = SNPj[p+1];\n\n          di2 = ~(SNPi_p | SNPi_p1);\n          dj2 = ~(SNPj_p | SNPj_p1);\n          di2 = di2 & mask_ones;\n          dj2 = dj2 & mask_ones;\n\n          t00 = SNPi_p & SNPj_p;\n          t01 = SNPi_p & SNPj_p1;\n          t02 = SNPi_p & dj2;\n          t10 = SNPi_p1 & SNPj_p;\n          t11 = SNPi_p1 & SNPj_p1;\n          t12 = SNPi_p1 & dj2;\n          t20 = di2 & SNPj_p;\n          t21 = di2 & SNPj_p1;\n          t22 = di2 & dj2;\n\n          ft[9]  += sycl::popcount(t00);\n          ft[10] += sycl::popcount(t01);\n          ft[11] += sycl::popcount(t02);\n          ft[12] += sycl::popcount(t10);\n          ft[13] += sycl::popcount(t11);\n          ft[14] += sycl::popcount(t12);\n          ft[15] += sycl::popcount(t20);\n          ft[16] += sycl::popcount(t21);\n          ft[17] += sycl::popcount(t22);\n\n          \n\n          float score = 0.0f;\n          #pragma unroll\n          for(k = 0; k < 9; k++)\n            score += gammafunction(ft[k] + ft[9 + k] + 1) -\n                     gammafunction(ft[k]) - gammafunction(ft[9 + k]);\n          score = sycl::fabs(score);\n          if(score == 0.0f)\n            score = FLT_MAX;\n          d_scores[tid] = score;\n        }\n      });\n    });\n  }\n\n  q.wait();\n  myduration ktime = myclock::now() - kstart;\n  auto total_ktime = ktime.count();\n\n  std::cout << \"Average kernel execution time: \"\n            << total_ktime / iteration << \" (s)\" << std::endl;\n\n  q.memcpy(scores, d_scores, sizeof(float) * num_snp * num_snp).wait();\n\n  int p1 = min_score(scores, num_snp, num_snp);\n\n  reference (bin_data_zeros_trans, bin_data_ones_trans, scores_ref, num_snp, \n             PP_zeros, PP_ones, mask_zeros, mask_ones);\n\n  int p2 = min_score(scores_ref, num_snp, num_snp);\n  \n  bool ok = (p1 == p2) && (fabsf(scores[p1] - scores_ref[p2]) < 1e-3f);\n  std::cout << (ok ? \"PASS\" : \"FAIL\") << std::endl;\n\n  sycl::free(d_data_zeros, q);\n  sycl::free(d_data_ones, q);\n  sycl::free(d_scores, q);\n\n  mem_free(bin_data_zeros);\n  mem_free(bin_data_ones);\n  mem_free(bin_data_zeros_trans);\n  mem_free(bin_data_ones_trans);\n  mem_free(scores);\n  mem_free(scores_ref);\n  mem_free(SNP_Data);\n  mem_free(SNP_Data_trans);\n  mem_free(Ph_Data);\n  return 0;\n}\n"}}
{"kernel_name": "extend2", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"read_data.h\"\n\nstatic void check(int a, int b, const char *s)\n{\n  if (a != b) printf(\"Error: %s %d %d\\n\", s, a, b);\n}\n\ntypedef struct {\n  int h, e;\n} eh_t;\n\n__global__ void\nkernel_extend2(\n    const unsigned char* query,\n    const unsigned char* target,\n    const char* mat,\n    eh_t* eh,\n    char* qp,\n    int* qle_acc,\n    int* tle_acc,\n    int* gtle_acc,\n    int* gscore_acc,\n    int* max_off_acc,\n    int* score_acc,\n    const int qlen, \n    const int tlen, \n    const int m, \n    const int o_del, \n    const int e_del, \n    const int o_ins, \n    const int e_ins, \n    int w, \n    const int end_bonus, \n    const int zdrop, \n    const int h0)\n{\n  int oe_del = o_del + e_del;\n  int oe_ins = o_ins + e_ins; \n  int i, j, k;\n  int beg, end;\n  int max, max_i, max_j, max_ins, max_del, max_ie;\n  int gscore;\n  int max_off;\n\n  \n\n  for (k = i = 0; k < m; ++k) {\n    const char *p = mat + k * m;\n    for (j = 0; j < qlen; ++j)\n      qp[i++] = p[query[j]];\n  }\n\n  \n\n  eh[0].h = h0; \n  eh[1].h = h0 > oe_ins? h0 - oe_ins : 0;\n\n  for (j = 2; j <= qlen && eh[j-1].h > e_ins; ++j)\n    eh[j].h = eh[j-1].h - e_ins;\n\n  \n\n  k = m * m;\n  for (i = 0, max = 0; i < k; ++i) \n\n    max = max > mat[i]? max : mat[i];\n  max_ins = (int)((float)(qlen * max + end_bonus - o_ins) / e_ins + 1.f);\n  max_ins = max_ins > 1? max_ins : 1;\n  w = w < max_ins? w : max_ins;\n  max_del = (int)((float)(qlen * max + end_bonus - o_del) / e_del + 1.f);\n  max_del = max_del > 1? max_del : 1;\n  w = w < max_del? w : max_del; \n\n  \n\n  max = h0, max_i = max_j = -1; max_ie = -1, gscore = -1;\n  max_off = 0;\n  beg = 0, end = qlen;\n  for (i = 0; i < tlen; ++i) {\n    int t, f = 0, h1, m = 0, mj = -1;\n    char *q = qp + target[i] * qlen;\n\n    \n\n    if (beg < i - w) beg = i - w;\n    if (end > i + w + 1) end = i + w + 1;\n    if (end > qlen) end = qlen;\n\n    \n\n    if (beg == 0) {\n      h1 = h0 - (o_del + e_del * (i + 1));\n      if (h1 < 0) h1 = 0;\n    } \n    else \n      h1 = 0;\n\n    for (j = beg; j < end; ++j) {\n      \n\n      \n\n      \n\n      \n\n      \n\n      eh_t *p = eh+j;\n      int h, M = p->h, e = p->e; \n\n      p->h = h1;          \n\n      M = M? M + q[j] : 0;\n\n      h = M > e? M : e;   \n\n      h = h > f? h : f;\n      h1 = h;             \n\n      mj = m > h? mj : j; \n\n      m = m > h? m : h;   \n\n      t = M - oe_del;\n      t = t > 0? t : 0;\n      e -= e_del;\n      e = e > t? e : t;   \n\n      p->e = e;           \n\n      t = M - oe_ins;\n      t = t > 0? t : 0;\n      f -= e_ins;\n      f = f > t? f : t;   \n\n    }\n    eh[end].h = h1; eh[end].e = 0;\n    if (j == qlen) {\n      max_ie = gscore > h1? max_ie : i;\n      gscore = gscore > h1? gscore : h1;\n    }\n    if (m == 0) break;\n    if (m > max) {\n      max = m, max_i = i, max_j = mj;\n      max_off = max_off > abs(mj - i)? max_off : abs(mj - i);\n    } else if (zdrop > 0) {\n      if (i - max_i > mj - max_j) {\n        if (max - m - ((i - max_i) - (mj - max_j)) * e_del > zdrop) break;\n      } else {\n        if (max - m - ((mj - max_j) - (i - max_i)) * e_ins > zdrop) break;\n      }\n    }\n    \n\n    for (j = beg; j < end && eh[j].h == 0 && eh[j].e == 0; ++j);\n    beg = j;\n    for (j = end; j >= beg && eh[j].h == 0 && eh[j].e == 0; --j);\n    end = j + 2 < qlen? j + 2 : qlen;\n    \n\n  }\n  *qle_acc = max_j + 1;\n  *tle_acc = max_i + 1;\n  *gtle_acc = max_ie + 1;\n  *gscore_acc = gscore;\n  *max_off_acc = max_off;\n  *score_acc = max;\n}\n\nfloat extend2(struct extend2_dat *d)\n{\n  eh_t *eh = NULL; \n\n  char *qp = NULL; \n\n  posix_memalign((void**)&eh, 64, (d->qlen+1) * 8);\n  posix_memalign((void**)&qp, 64, d->qlen * d->m);\n  memset(eh, 0, (d->qlen+1) * 8);\n\n  int qle, tle, gtle, gscore, max_off, score;\n\n  const int qlen = d->qlen;\n  const int tlen = d->tlen;\n  const int m = d->m;\n  const int o_del = d->o_del; \n  const int e_del = d->e_del; \n  const int o_ins = d->o_ins; \n  const int e_ins = d->e_ins; \n  const int w = d->w;\n  const int end_bonus = d->end_bonus;\n  const int zdrop = d->zdrop;\n  const int h0 = d->h0;\n\n  auto start = std::chrono::steady_clock::now();\n\n  unsigned char *d_query;\n  cudaMalloc((void**)&d_query, qlen);\n  cudaMemcpyAsync(d_query, d->query, qlen, cudaMemcpyHostToDevice, 0);\n\n  unsigned char *d_target;\n  cudaMalloc((void**)&d_target, tlen);\n  cudaMemcpyAsync(d_target, d->target, tlen, cudaMemcpyHostToDevice, 0);\n\n  char *d_mat;\n  cudaMalloc((void**)&d_mat, m*m);\n  cudaMemcpyAsync(d_mat, d->mat, m*m, cudaMemcpyHostToDevice, 0);\n\n  eh_t *d_eh;\n  cudaMalloc((void**)&d_eh, (qlen+1)*sizeof(eh_t));\n  cudaMemcpyAsync(d_eh, eh, (qlen+1)*sizeof(eh_t), cudaMemcpyHostToDevice, 0);\n\n  char *d_qp;\n  cudaMalloc((void**)&d_qp, qlen*m);\n  cudaMemcpyAsync(d_qp, qp, qlen*m, cudaMemcpyHostToDevice, 0);\n\n  int *d_qle;\n  cudaMalloc((void**)&d_qle, 4);\n\n  int *d_tle;\n  cudaMalloc((void**)&d_tle, 4);\n\n  int *d_gtle;\n  cudaMalloc((void**)&d_gtle, 4);\n\n  int *d_gscore;\n  cudaMalloc((void**)&d_gscore, 4);\n\n  int *d_max_off;\n  cudaMalloc((void**)&d_max_off, 4);\n\n  int *d_score;\n  cudaMalloc((void**)&d_score, 4);\n\n  kernel_extend2<<<1,1>>>(\n      d_query,\n      d_target,\n      d_mat,\n      d_eh,\n      d_qp,\n      d_qle,\n      d_tle,\n      d_gtle,\n      d_gscore,\n      d_max_off,\n      d_score,\n      qlen,\n      tlen,\n      m, \n      o_del, \n      e_del, \n      o_ins, \n      e_ins, \n      w, \n      end_bonus, \n      zdrop, \n      h0);\n\n  cudaMemcpyAsync(&qle, d_qle, 4, cudaMemcpyDeviceToHost, 0);\n  cudaMemcpyAsync(&tle, d_tle, 4, cudaMemcpyDeviceToHost, 0);\n  cudaMemcpyAsync(&gtle, d_gtle, 4, cudaMemcpyDeviceToHost, 0);\n  cudaMemcpyAsync(&max_off, d_max_off, 4, cudaMemcpyDeviceToHost, 0);\n  cudaMemcpyAsync(&gscore, d_gscore, 4, cudaMemcpyDeviceToHost, 0);\n  cudaMemcpyAsync(&score, d_score, 4, cudaMemcpyDeviceToHost, 0);\n\n  cudaFree(d_query);\n  cudaFree(d_target);\n  cudaFree(d_mat);\n  cudaFree(d_eh);\n  cudaFree(d_qp);\n  cudaFree(d_qle);\n  cudaFree(d_tle);\n  cudaFree(d_gtle);\n  cudaFree(d_gscore);\n  cudaFree(d_max_off);\n  cudaFree(d_score);\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  check(d->qle, qle, \"qle\");\n  check(d->tle, tle, \"tle\");\n  check(d->gtle, gtle, \"gtle\");\n  check(d->gscore, gscore, \"gscore\");\n  check(d->max_off, max_off, \"max_off\");\n  check(d->score, score, \"score\");\n\n  free(eh);\n  free(qp);\n\n#ifdef VERBOSE\n  printf(\"device: qle=%d, tle=%d, gtle=%d, gscore=%d, max_off=%d, score=%d\\n\",\n      qle, tle, gtle, gscore, max_off, score);\n#endif\n\n return time;\n}\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int repeat = atoi(argv[1]);\n\n  struct extend2_dat d;\n\n  \n\n  const char* files[] = {\n#include \"filelist.txt\"\n  };\n\n  float time = 0.f;\n  for (int f = 0; f < repeat; f++) {\n    read_data(files[f%17], &d);\n    time += extend2(&d);\n  }\n  printf(\"Average offload time %f (us)\\n\", (time * 1e-3f) / repeat);\n  return 0;\n}\n"}}
{"kernel_name": "extend2", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"read_data.h\"\n\nstatic void check(int a, int b, const char *s)\n{\n  if (a != b) printf(\"Error: %s %d %d\\n\", s, a, b);\n}\n\ntypedef struct {\n  int h, e;\n} eh_t;\n\n__global__ void\nkernel_extend2(\n    const unsigned char* query,\n    const unsigned char* target,\n    const char* mat,\n    eh_t* eh,\n    char* qp,\n    int* qle_acc,\n    int* tle_acc,\n    int* gtle_acc,\n    int* gscore_acc,\n    int* max_off_acc,\n    int* score_acc,\n    const int qlen, \n    const int tlen, \n    const int m, \n    const int o_del, \n    const int e_del, \n    const int o_ins, \n    const int e_ins, \n    int w, \n    const int end_bonus, \n    const int zdrop, \n    const int h0)\n{\n  int oe_del = o_del + e_del;\n  int oe_ins = o_ins + e_ins; \n  int i, j, k;\n  int beg, end;\n  int max, max_i, max_j, max_ins, max_del, max_ie;\n  int gscore;\n  int max_off;\n\n  \n\n  for (k = i = 0; k < m; ++k) {\n    const char *p = mat + k * m;\n    for (j = 0; j < qlen; ++j)\n      qp[i++] = p[query[j]];\n  }\n\n  \n\n  eh[0].h = h0; \n  eh[1].h = h0 > oe_ins? h0 - oe_ins : 0;\n\n  for (j = 2; j <= qlen && eh[j-1].h > e_ins; ++j)\n    eh[j].h = eh[j-1].h - e_ins;\n\n  \n\n  k = m * m;\n  for (i = 0, max = 0; i < k; ++i) \n\n    max = max > mat[i]? max : mat[i];\n  max_ins = (int)((float)(qlen * max + end_bonus - o_ins) / e_ins + 1.f);\n  max_ins = max_ins > 1? max_ins : 1;\n  w = w < max_ins? w : max_ins;\n  max_del = (int)((float)(qlen * max + end_bonus - o_del) / e_del + 1.f);\n  max_del = max_del > 1? max_del : 1;\n  w = w < max_del? w : max_del; \n\n  \n\n  max = h0, max_i = max_j = -1; max_ie = -1, gscore = -1;\n  max_off = 0;\n  beg = 0, end = qlen;\n  for (i = 0; i < tlen; ++i) {\n    int t, f = 0, h1, m = 0, mj = -1;\n    char *q = qp + target[i] * qlen;\n\n    \n\n    if (beg < i - w) beg = i - w;\n    if (end > i + w + 1) end = i + w + 1;\n    if (end > qlen) end = qlen;\n\n    \n\n    if (beg == 0) {\n      h1 = h0 - (o_del + e_del * (i + 1));\n      if (h1 < 0) h1 = 0;\n    } \n    else \n      h1 = 0;\n\n    for (j = beg; j < end; ++j) {\n      \n\n      \n\n      \n\n      \n\n      \n\n      eh_t *p = eh+j;\n      int h, M = p->h, e = p->e; \n\n      p->h = h1;          \n\n      M = M? M + q[j] : 0;\n\n      h = M > e? M : e;   \n\n      h = h > f? h : f;\n      h1 = h;             \n\n      mj = m > h? mj : j; \n\n      m = m > h? m : h;   \n\n      t = M - oe_del;\n      t = t > 0? t : 0;\n      e -= e_del;\n      e = e > t? e : t;   \n\n      p->e = e;           \n\n      t = M - oe_ins;\n      t = t > 0? t : 0;\n      f -= e_ins;\n      f = f > t? f : t;   \n\n    }\n    eh[end].h = h1; eh[end].e = 0;\n    if (j == qlen) {\n      max_ie = gscore > h1? max_ie : i;\n      gscore = gscore > h1? gscore : h1;\n    }\n    if (m == 0) break;\n    if (m > max) {\n      max = m, max_i = i, max_j = mj;\n      max_off = max_off > abs(mj - i)? max_off : abs(mj - i);\n    } else if (zdrop > 0) {\n      if (i - max_i > mj - max_j) {\n        if (max - m - ((i - max_i) - (mj - max_j)) * e_del > zdrop) break;\n      } else {\n        if (max - m - ((mj - max_j) - (i - max_i)) * e_ins > zdrop) break;\n      }\n    }\n    \n\n    for (j = beg; j < end && eh[j].h == 0 && eh[j].e == 0; ++j);\n    beg = j;\n    for (j = end; j >= beg && eh[j].h == 0 && eh[j].e == 0; --j);\n    end = j + 2 < qlen? j + 2 : qlen;\n    \n\n  }\n  *qle_acc = max_j + 1;\n  *tle_acc = max_i + 1;\n  *gtle_acc = max_ie + 1;\n  *gscore_acc = gscore;\n  *max_off_acc = max_off;\n  *score_acc = max;\n}\n\nfloat extend2(struct extend2_dat *d)\n{\n  eh_t *eh = NULL; \n\n  char *qp = NULL; \n\n  posix_memalign((void**)&eh, 64, (d->qlen+1) * 8);\n  posix_memalign((void**)&qp, 64, d->qlen * d->m);\n  memset(eh, 0, (d->qlen+1) * 8);\n\n  int qle, tle, gtle, gscore, max_off, score;\n\n  const int qlen = d->qlen;\n  const int tlen = d->tlen;\n  const int m = d->m;\n  const int o_del = d->o_del; \n  const int e_del = d->e_del; \n  const int o_ins = d->o_ins; \n  const int e_ins = d->e_ins; \n  const int w = d->w;\n  const int end_bonus = d->end_bonus;\n  const int zdrop = d->zdrop;\n  const int h0 = d->h0;\n\n  auto start = std::chrono::steady_clock::now();\n\n  unsigned char *d_query;\n  hipMalloc((void**)&d_query, qlen);\n  hipMemcpyAsync(d_query, d->query, qlen, hipMemcpyHostToDevice, 0);\n\n  unsigned char *d_target;\n  hipMalloc((void**)&d_target, tlen);\n  hipMemcpyAsync(d_target, d->target, tlen, hipMemcpyHostToDevice, 0);\n\n  char *d_mat;\n  hipMalloc((void**)&d_mat, m*m);\n  hipMemcpyAsync(d_mat, d->mat, m*m, hipMemcpyHostToDevice, 0);\n\n  eh_t *d_eh;\n  hipMalloc((void**)&d_eh, (qlen+1)*sizeof(eh_t));\n  hipMemcpyAsync(d_eh, eh, (qlen+1)*sizeof(eh_t), hipMemcpyHostToDevice, 0);\n\n  char *d_qp;\n  hipMalloc((void**)&d_qp, qlen*m);\n  hipMemcpyAsync(d_qp, qp, qlen*m, hipMemcpyHostToDevice, 0);\n\n  int *d_qle;\n  hipMalloc((void**)&d_qle, 4);\n\n  int *d_tle;\n  hipMalloc((void**)&d_tle, 4);\n\n  int *d_gtle;\n  hipMalloc((void**)&d_gtle, 4);\n\n  int *d_gscore;\n  hipMalloc((void**)&d_gscore, 4);\n\n  int *d_max_off;\n  hipMalloc((void**)&d_max_off, 4);\n\n  int *d_score;\n  hipMalloc((void**)&d_score, 4);\n\n  kernel_extend2<<<1,1>>>(\n      d_query,\n      d_target,\n      d_mat,\n      d_eh,\n      d_qp,\n      d_qle,\n      d_tle,\n      d_gtle,\n      d_gscore,\n      d_max_off,\n      d_score,\n      qlen,\n      tlen,\n      m, \n      o_del, \n      e_del, \n      o_ins, \n      e_ins, \n      w, \n      end_bonus, \n      zdrop, \n      h0);\n\n  hipMemcpyAsync(&qle, d_qle, 4, hipMemcpyDeviceToHost, 0);\n  hipMemcpyAsync(&tle, d_tle, 4, hipMemcpyDeviceToHost, 0);\n  hipMemcpyAsync(&gtle, d_gtle, 4, hipMemcpyDeviceToHost, 0);\n  hipMemcpyAsync(&max_off, d_max_off, 4, hipMemcpyDeviceToHost, 0);\n  hipMemcpyAsync(&gscore, d_gscore, 4, hipMemcpyDeviceToHost, 0);\n  hipMemcpyAsync(&score, d_score, 4, hipMemcpyDeviceToHost, 0);\n\n  hipFree(d_query);\n  hipFree(d_target);\n  hipFree(d_mat);\n  hipFree(d_eh);\n  hipFree(d_qp);\n  hipFree(d_qle);\n  hipFree(d_tle);\n  hipFree(d_gtle);\n  hipFree(d_gscore);\n  hipFree(d_max_off);\n  hipFree(d_score);\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  check(d->qle, qle, \"qle\");\n  check(d->tle, tle, \"tle\");\n  check(d->gtle, gtle, \"gtle\");\n  check(d->gscore, gscore, \"gscore\");\n  check(d->max_off, max_off, \"max_off\");\n  check(d->score, score, \"score\");\n\n  free(eh);\n  free(qp);\n\n#ifdef VERBOSE\n  printf(\"device: qle=%d, tle=%d, gtle=%d, gscore=%d, max_off=%d, score=%d\\n\",\n      qle, tle, gtle, gscore, max_off, score);\n#endif\n\n return time;\n}\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int repeat = atoi(argv[1]);\n\n  struct extend2_dat d;\n\n  \n\n  const char* files[] = {\n#include \"filelist.txt\"\n  };\n\n  float time = 0.f;\n  for (int f = 0; f < repeat; f++) {\n    read_data(files[f%17], &d);\n    time += extend2(&d);\n  }\n  printf(\"Average offload time %f (us)\\n\", (time * 1e-3f) / repeat);\n  return 0;\n}\n"}}
{"kernel_name": "extend2", "parallel_api": "omp", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <math.h>\n#include <unistd.h>\n#include \"read_data.h\"\n#include <chrono>\n#include <omp.h>\n\nstatic void check(int a, int b, const char *s)\n{\n  if (a != b) printf(\"Error: %s %d %d\\n\", s, a, b);\n}\n\ntypedef struct {\n  int h, e;\n} eh_t;\n\nfloat extend2(struct extend2_dat *d)\n{\n  eh_t *eh = NULL; \n\n  char *qp = NULL; \n\n  posix_memalign((void**)&eh, 64, (d->qlen+1) * 8);\n  posix_memalign((void**)&qp, 64, d->qlen * d->m);\n  memset(eh, 0, (d->qlen+1) * 8);\n\n  int d_qle, \n      d_tle, \n      d_gtle, \n      d_gscore, \n      d_max_off, \n      d_score;\n\n  const int qlen = d->qlen;\n  const int tlen = d->tlen;\n  const int m = d->m;\n  const int o_del = d->o_del; \n  const int e_del = d->e_del; \n  const int o_ins = d->o_ins; \n  const int e_ins = d->e_ins; \n  int w = d->w;\n  const int end_bonus = d->end_bonus;\n  const int zdrop = d->zdrop;\n  const int h0 = d->h0;\n\n  unsigned char *query = d->query;\n  unsigned char *target = d->target;\n  char* mat = d->mat;\n\n  auto start = std::chrono::steady_clock::now();\n\n  #pragma omp target map(to: query[0:qlen], \\\n                             target[0:tlen], \\\n                             mat[0:m*m], \\\n                             eh[0:qlen+1], \\\n                             qp[0:qlen*m])\\\n  map(from: d_qle, d_tle, d_gtle, d_gscore, d_score, d_max_off) \n  {\n    int oe_del = o_del + e_del;\n    int oe_ins = o_ins + e_ins; \n    int i, j, k;\n    int beg, end;\n    int max, max_i, max_j, max_ins, max_del, max_ie;\n    int gscore;\n    int max_off;\n\n    \n\n    for (k = i = 0; k < m; ++k) {\n      char *p = mat + k * m;\n      for (j = 0; j < qlen; ++j)\n        qp[i++] = p[query[j]];\n    }\n\n    \n\n    eh[0].h = h0; \n    eh[1].h = h0 > oe_ins? h0 - oe_ins : 0;\n\n    for (j = 2; j <= qlen && eh[j-1].h > e_ins; ++j)\n      eh[j].h = eh[j-1].h - e_ins;\n\n    \n\n    k = m * m;\n    for (i = 0, max = 0; i < k; ++i) \n\n      max = max > mat[i]? max : mat[i];\n    max_ins = (int)((float)(qlen * max + end_bonus - o_ins) / e_ins + 1.f);\n    max_ins = max_ins > 1? max_ins : 1;\n    w = w < max_ins? w : max_ins;\n    max_del = (int)((float)(qlen * max + end_bonus - o_del) / e_del + 1.f);\n    max_del = max_del > 1? max_del : 1;\n    w = w < max_del? w : max_del; \n\n    \n\n    max = h0, max_i = max_j = -1; max_ie = -1, gscore = -1;\n    max_off = 0;\n    beg = 0, end = qlen;\n    for (i = 0; i < tlen; ++i) {\n      int t, f = 0, h1, m = 0, mj = -1;\n      char *q = qp + target[i] * qlen;\n\n      \n\n      if (beg < i - w) beg = i - w;\n      if (end > i + w + 1) end = i + w + 1;\n      if (end > qlen) end = qlen;\n\n      \n\n      if (beg == 0) {\n        h1 = h0 - (o_del + e_del * (i + 1));\n        if (h1 < 0) h1 = 0;\n      } \n      else \n        h1 = 0;\n\n      for (j = beg; j < end; ++j) {\n        \n\n        \n\n        \n\n        \n\n        \n\n        eh_t *p = eh+j;\n        int h, M = p->h, e = p->e; \n\n        p->h = h1;          \n\n        M = M? M + q[j] : 0;\n\n        h = M > e? M : e;   \n\n        h = h > f? h : f;\n        h1 = h;             \n\n        mj = m > h? mj : j; \n\n        m = m > h? m : h;   \n\n        t = M - oe_del;\n        t = t > 0? t : 0;\n        e -= e_del;\n        e = e > t? e : t;   \n\n        p->e = e;           \n\n        t = M - oe_ins;\n        t = t > 0? t : 0;\n        f -= e_ins;\n        f = f > t? f : t;   \n\n      }\n      eh[end].h = h1; eh[end].e = 0;\n      if (j == qlen) {\n        max_ie = gscore > h1? max_ie : i;\n        gscore = gscore > h1? gscore : h1;\n      }\n      if (m == 0) break;\n      if (m > max) {\n        max = m, max_i = i, max_j = mj;\n        max_off = max_off > abs(mj - i)? max_off : abs(mj - i);\n      } else if (zdrop > 0) {\n        if (i - max_i > mj - max_j) {\n          if (max - m - ((i - max_i) - (mj - max_j)) * e_del > zdrop) break;\n        } else {\n          if (max - m - ((mj - max_j) - (i - max_i)) * e_ins > zdrop) break;\n        }\n      }\n      \n\n      for (j = beg; j < end && eh[j].h == 0 && eh[j].e == 0; ++j);\n      beg = j;\n      for (j = end; j >= beg && eh[j].h == 0 && eh[j].e == 0; --j);\n      end = j + 2 < qlen? j + 2 : qlen;\n      \n\n    }\n    d_qle = max_j + 1;\n    d_tle = max_i + 1;\n    d_gtle = max_ie + 1;\n    d_gscore = gscore;\n    d_max_off = max_off;\n    d_score = max;\n  }\n\n  auto stop = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(stop - start).count();\n\n  check(d->qle, d_qle, \"qle\");\n  check(d->tle, d_tle, \"tle\");\n  check(d->gtle, d_gtle, \"gtle\");\n  check(d->gscore, d_gscore, \"gscore\");\n  check(d->max_off, d_max_off, \"max_off\");\n  check(d->score, d_score, \"score\");\n\n  free(eh);\n  free(qp);\n\n#ifdef VERBOSE\n  printf(\"device: qle=%d, tle=%d, gtle=%d, gscore=%d, max_off=%d, score=%d\\n\",\n      d_qle, d_tle, d_gtle, d_gscore, d_max_off, d_score);\n#endif\n\n  return time;\n}\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int repeat = atoi(argv[1]);\n\n  struct extend2_dat d;\n\n  \n\n  const char* files[] = {\n#include \"filelist.txt\"\n  };\n\n  float time = 0.f;\n  for (int f = 0; f < repeat; f++) {\n    read_data(files[f%17], &d);\n    time += extend2(&d);\n  }\n  printf(\"Average offload time %f (us)\\n\", (time * 1e-3f) / repeat);\n  return 0;\n}\n"}}
{"kernel_name": "extend2", "parallel_api": "serial", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <math.h>\n#include <unistd.h>\n#include \"read_data.h\"\n#include <chrono>\n\nstatic void check(int a, int b, const char *s)\n{\n  if (a != b) printf(\"Error: %s %d %d\\n\", s, a, b);\n}\n\ntypedef struct {\n  int h, e;\n} eh_t;\n\nfloat extend2(struct extend2_dat *d)\n{\n  eh_t *eh = NULL; \n\n  char *qp = NULL; \n\n  posix_memalign((void**)&eh, 64, (d->qlen+1) * 8);\n  posix_memalign((void**)&qp, 64, d->qlen * d->m);\n  memset(eh, 0, (d->qlen+1) * 8);\n\n  int d_qle, \n      d_tle, \n      d_gtle, \n      d_gscore, \n      d_max_off, \n      d_score;\n\n  const int qlen = d->qlen;\n  const int tlen = d->tlen;\n  const int m = d->m;\n  const int o_del = d->o_del; \n  const int e_del = d->e_del; \n  const int o_ins = d->o_ins; \n  const int e_ins = d->e_ins; \n  int w = d->w;\n  const int end_bonus = d->end_bonus;\n  const int zdrop = d->zdrop;\n  const int h0 = d->h0;\n\n  unsigned char *query = d->query;\n  unsigned char *target = d->target;\n  char* mat = d->mat;\n\n  auto start = std::chrono::steady_clock::now();\n\n    {\n    int oe_del = o_del + e_del;\n    int oe_ins = o_ins + e_ins; \n    int i, j, k;\n    int beg, end;\n    int max, max_i, max_j, max_ins, max_del, max_ie;\n    int gscore;\n    int max_off;\n\n    \n\n    for (k = i = 0; k < m; ++k) {\n      char *p = mat + k * m;\n      for (j = 0; j < qlen; ++j)\n        qp[i++] = p[query[j]];\n    }\n\n    \n\n    eh[0].h = h0; \n    eh[1].h = h0 > oe_ins? h0 - oe_ins : 0;\n\n    for (j = 2; j <= qlen && eh[j-1].h > e_ins; ++j)\n      eh[j].h = eh[j-1].h - e_ins;\n\n    \n\n    k = m * m;\n    for (i = 0, max = 0; i < k; ++i) \n\n      max = max > mat[i]? max : mat[i];\n    max_ins = (int)((float)(qlen * max + end_bonus - o_ins) / e_ins + 1.f);\n    max_ins = max_ins > 1? max_ins : 1;\n    w = w < max_ins? w : max_ins;\n    max_del = (int)((float)(qlen * max + end_bonus - o_del) / e_del + 1.f);\n    max_del = max_del > 1? max_del : 1;\n    w = w < max_del? w : max_del; \n\n    \n\n    max = h0, max_i = max_j = -1; max_ie = -1, gscore = -1;\n    max_off = 0;\n    beg = 0, end = qlen;\n    for (i = 0; i < tlen; ++i) {\n      int t, f = 0, h1, m = 0, mj = -1;\n      char *q = qp + target[i] * qlen;\n\n      \n\n      if (beg < i - w) beg = i - w;\n      if (end > i + w + 1) end = i + w + 1;\n      if (end > qlen) end = qlen;\n\n      \n\n      if (beg == 0) {\n        h1 = h0 - (o_del + e_del * (i + 1));\n        if (h1 < 0) h1 = 0;\n      } \n      else \n        h1 = 0;\n\n      for (j = beg; j < end; ++j) {\n        \n\n        \n\n        \n\n        \n\n        \n\n        eh_t *p = eh+j;\n        int h, M = p->h, e = p->e; \n\n        p->h = h1;          \n\n        M = M? M + q[j] : 0;\n\n        h = M > e? M : e;   \n\n        h = h > f? h : f;\n        h1 = h;             \n\n        mj = m > h? mj : j; \n\n        m = m > h? m : h;   \n\n        t = M - oe_del;\n        t = t > 0? t : 0;\n        e -= e_del;\n        e = e > t? e : t;   \n\n        p->e = e;           \n\n        t = M - oe_ins;\n        t = t > 0? t : 0;\n        f -= e_ins;\n        f = f > t? f : t;   \n\n      }\n      eh[end].h = h1; eh[end].e = 0;\n      if (j == qlen) {\n        max_ie = gscore > h1? max_ie : i;\n        gscore = gscore > h1? gscore : h1;\n      }\n      if (m == 0) break;\n      if (m > max) {\n        max = m, max_i = i, max_j = mj;\n        max_off = max_off > abs(mj - i)? max_off : abs(mj - i);\n      } else if (zdrop > 0) {\n        if (i - max_i > mj - max_j) {\n          if (max - m - ((i - max_i) - (mj - max_j)) * e_del > zdrop) break;\n        } else {\n          if (max - m - ((mj - max_j) - (i - max_i)) * e_ins > zdrop) break;\n        }\n      }\n      \n\n      for (j = beg; j < end && eh[j].h == 0 && eh[j].e == 0; ++j);\n      beg = j;\n      for (j = end; j >= beg && eh[j].h == 0 && eh[j].e == 0; --j);\n      end = j + 2 < qlen? j + 2 : qlen;\n      \n\n    }\n    d_qle = max_j + 1;\n    d_tle = max_i + 1;\n    d_gtle = max_ie + 1;\n    d_gscore = gscore;\n    d_max_off = max_off;\n    d_score = max;\n  }\n\n  auto stop = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(stop - start).count();\n\n  check(d->qle, d_qle, \"qle\");\n  check(d->tle, d_tle, \"tle\");\n  check(d->gtle, d_gtle, \"gtle\");\n  check(d->gscore, d_gscore, \"gscore\");\n  check(d->max_off, d_max_off, \"max_off\");\n  check(d->score, d_score, \"score\");\n\n  free(eh);\n  free(qp);\n\n#ifdef VERBOSE\n  printf(\"device: qle=%d, tle=%d, gtle=%d, gscore=%d, max_off=%d, score=%d\\n\",\n      d_qle, d_tle, d_gtle, d_gscore, d_max_off, d_score);\n#endif\n\n  return time;\n}\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int repeat = atoi(argv[1]);\n\n  struct extend2_dat d;\n\n  \n\n  const char* files[] = {\n#include \"filelist.txt\"\n  };\n\n  float time = 0.f;\n  for (int f = 0; f < repeat; f++) {\n    read_data(files[f%17], &d);\n    time += extend2(&d);\n  }\n  printf(\"Average offload time %f (us)\\n\", (time * 1e-3f) / repeat);\n  return 0;\n}"}}
{"kernel_name": "extend2", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"read_data.h\"\n\nstatic void check(int a, int b, const char *s)\n{\n  if (a != b) printf(\"Error: %s %d %d\\n\", s, a, b);\n}\n\ntypedef struct {\n  int h, e;\n} eh_t;\n\n\nfloat extend2(sycl::queue &q, struct extend2_dat *d)\n{\n  eh_t *eh = NULL; \n\n  char *qp = NULL; \n\n  posix_memalign((void**)&eh, 64, (d->qlen+1) * 8);\n  posix_memalign((void**)&qp, 64, d->qlen * d->m);\n  memset(eh, 0, (d->qlen+1) * 8);\n\n  int qle, tle, gtle, gscore, max_off, score;\n\n  const int qlen = d->qlen;\n  const int tlen = d->tlen;\n  const int m = d->m;\n  const int o_del = d->o_del; \n  const int e_del = d->e_del; \n  const int o_ins = d->o_ins; \n  const int e_ins = d->e_ins; \n  int w = d->w;\n  const int end_bonus = d->end_bonus;\n  const int zdrop = d->zdrop;\n  const int h0 = d->h0;\n\n  auto start = std::chrono::steady_clock::now();\n\n  unsigned char *d_query = sycl::malloc_device<unsigned char>(qlen, q);\n  q.memcpy(d_query, d->query, qlen);\n\n  unsigned char *d_target = sycl::malloc_device<unsigned char>(tlen, q);\n  q.memcpy(d_target, d->target, tlen);\n\n  char *d_mat = sycl::malloc_device<char>(m*m, q);\n  q.memcpy(d_mat, d->mat, m*m);\n\n  int *d_qle = sycl::malloc_device<int>(1, q);\n  q.memcpy(d_qle, &qle, sizeof(int));\n\n  int *d_tle = sycl::malloc_device<int>(1, q);\n  q.memcpy(d_tle, &tle, sizeof(int));\n\n  int *d_gtle = sycl::malloc_device<int>(1, q);\n  q.memcpy(d_gtle, &gtle, sizeof(int));\n\n  int *d_gscore = sycl::malloc_device<int>(1, q);\n  q.memcpy(d_gscore, &gscore, sizeof(int));\n\n  int *d_max_off = sycl::malloc_device<int>(1, q);\n  q.memcpy(d_max_off, &max_off, sizeof(int));\n\n  int *d_score = sycl::malloc_device<int>(1, q);\n  q.memcpy(d_score, &score, sizeof(int));\n\n  eh_t *d_eh = sycl::malloc_device<eh_t>(qlen + 1, q);\n  q.memcpy(d_eh, eh, sizeof(eh_t) * (qlen + 1));\n\n  char *d_qp = sycl::malloc_device<char>(qlen*m, q);\n  q.memcpy(d_qp, qp, qlen*m);\n\n  q.submit([&](sycl::handler &h) {\n    h.single_task<class ebwa>([=]() {\n      int oe_del = o_del + e_del;\n      int oe_ins = o_ins + e_ins; \n      int i, j, k;\n      int beg, end;\n      int max, max_i, max_j, max_ins, max_del, max_ie;\n      int max_w; \n\n      int gscore;\n      int max_off;\n      int abs_v;\n\n      \n\n      for (k = i = 0; k < m; ++k) {\n        char *p = d_mat + k * m;\n        for (j = 0; j < qlen; ++j)\n        d_qp[i++] = p[d_query[j]];\n      }\n\n      \n\n      d_eh[0].h = h0; \n      d_eh[1].h = h0 > oe_ins? h0 - oe_ins : 0;\n\n      for (j = 2; j <= qlen && d_eh[j-1].h > e_ins; ++j)\n        d_eh[j].h = d_eh[j-1].h - e_ins;\n\n      \n\n      k = m * m;\n      for (i = 0, max = 0; i < k; ++i) \n\n        max = max > d_mat[i]? max : d_mat[i];\n      max_ins = (int)((float)(qlen * max + end_bonus - o_ins) / e_ins + 1.f);\n      max_ins = max_ins > 1? max_ins : 1;\n      max_w = w < max_ins? w : max_ins;\n      max_del = (int)((float)(qlen * max + end_bonus - o_del) / e_del + 1.f);\n      max_del = max_del > 1? max_del : 1;\n      max_w = max_w < max_del? max_w : max_del; \n\n      \n\n      max = h0, max_i = max_j = -1; max_ie = -1, gscore = -1;\n      max_off = 0;\n      beg = 0, end = qlen;\n      for (i = 0; i < tlen; ++i) {\n        int t, f = 0, h1, m = 0, mj = -1;\n        char *q = d_qp + d_target[i] * qlen;\n\n        \n\n        if (beg < i - max_w) beg = i - max_w;\n        if (end > i + max_w + 1) end = i + max_w + 1;\n        if (end > qlen) end = qlen;\n\n        \n\n        if (beg == 0) {\n          h1 = h0 - (o_del + e_del * (i + 1));\n          if (h1 < 0) h1 = 0;\n        } \n        else \n          h1 = 0;\n\n        for (j = beg; j < end; ++j) {\n          \n\n          \n\n          \n\n          \n\n          \n\n          eh_t *p = d_eh+j;\n          int h, M = p->h, e = p->e; \n\n          p->h = h1;          \n\n          M = M? M + q[j] : 0;\n\n          h = M > e? M : e;   \n\n          h = h > f? h : f;\n          h1 = h;             \n\n          mj = m > h? mj : j; \n\n          m = m > h? m : h;   \n\n          t = M - oe_del;\n          t = t > 0? t : 0;\n          e -= e_del;\n          e = e > t? e : t;   \n\n          p->e = e;           \n\n          t = M - oe_ins;\n          t = t > 0? t : 0;\n          f -= e_ins;\n          f = f > t? f : t;   \n\n        }\n        d_eh[end].h = h1; d_eh[end].e = 0;\n        if (j == qlen) {\n          max_ie = gscore > h1? max_ie : i;\n          gscore = gscore > h1? gscore : h1;\n        }\n        if (m == 0) break;\n        if (m > max) {\n          max = m, max_i = i, max_j = mj;\n          abs_v = ( mj -i ) < 0 ? i - mj : mj - i;\n          max_off = max_off > abs_v ? max_off : abs_v;\n        } else if (zdrop > 0) {\n          if (i - max_i > mj - max_j) {\n            if (max - m - ((i - max_i) - (mj - max_j)) * e_del > zdrop) break;\n          } else {\n            if (max - m - ((mj - max_j) - (i - max_i)) * e_ins > zdrop) break;\n          }\n        }\n        \n\n        for (j = beg; j < end && d_eh[j].h == 0 && d_eh[j].e == 0; ++j);\n        beg = j;\n        for (j = end; j >= beg && d_eh[j].h == 0 && d_eh[j].e == 0; --j);\n        end = j + 2 < qlen? j + 2 : qlen;\n        \n\n      }\n      d_qle[0] = max_j + 1;\n      d_tle[0] = max_i + 1;\n      d_gtle[0] = max_ie + 1;\n      d_gscore[0] = gscore;\n      d_max_off[0] = max_off;\n      d_score[0] = max;\n    });\n  });\n  \n  q.memcpy(&qle, d_qle, 4);\n  q.memcpy(&tle, d_tle, 4);\n  q.memcpy(&gtle, d_gtle, 4);\n  q.memcpy(&max_off, d_max_off, 4);\n  q.memcpy(&gscore, d_gscore, 4);\n  q.memcpy(&score, d_score, 4);\n  q.wait();\n\n  sycl::free(d_query, q);\n  sycl::free(d_target, q);\n  sycl::free(d_mat, q);\n  sycl::free(d_eh, q);\n  sycl::free(d_qp, q);\n  sycl::free(d_qle, q);\n  sycl::free(d_tle, q);\n  sycl::free(d_gtle, q);\n  sycl::free(d_gscore, q);\n  sycl::free(d_max_off, q);\n  sycl::free(d_score, q);\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  check(d->qle, qle, \"qle\");\n  check(d->tle, tle, \"tle\");\n  check(d->gtle, gtle, \"gtle\");\n  check(d->gscore, gscore, \"gscore\");\n  check(d->max_off, max_off, \"max_off\");\n  check(d->score, score, \"score\");\n\n  free(eh);\n  free(qp);\n\n#ifdef VERBOSE\n  printf(\"device: qle=%d, tle=%d, gtle=%d, gscore=%d, max_off=%d, score=%d\\n\",\n      qle, tle, gtle, gscore, max_off, score);\n#endif\n  return time;\n}\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int repeat = atoi(argv[1]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  struct extend2_dat d;\n\n  \n\n  const char* files[] = {\n#include \"filelist.txt\"\n  };\n\n  float time = 0.f;\n  for (int f = 0; f < repeat; f++) {\n    read_data(files[f%17], &d);\n    time += extend2(q, &d);\n  }\n  printf(\"Average offload time %f (us)\\n\", (time * 1e-3f) / repeat);\n  return 0;\n}\n", "read_data.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <assert.h>\n\n#include \"read_data.h\"\n\n\n\nstatic int read_check(int fd, void *buf, size_t sz)\n{\n  if(read(fd, buf, sz) != (ssize_t)sz) return 0;\n  return 1;\n}\n\n\n\nint read_data(const char *fn, struct extend2_dat *d)\n{\n  if (!d) return 0;\n  int fd = open(fn, O_RDONLY);\n  if (fd < 0) {\n    perror(\"Cannot open output file\\n\");\n    return 0;\n  }\n\n  \n\n  assert( read_check(fd, (void*)&d->qlen, sizeof(int)) );\n  d->query = (uint8_t*)malloc(d->qlen);\n  assert( read_check(fd, d->query, d->qlen) );\n  assert( read_check(fd, (void*)&d->tlen, sizeof(int)) );\n  d->target = (uint8_t*)malloc(d->tlen);\n  assert( read_check(fd, d->target, d->tlen) );\n  assert( read_check(fd, (void*)&d->m, sizeof(int)) );\n  assert( read_check(fd, (void*)d->mat, 25) );\n  assert( read_check(fd, (void*)&d->o_del, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->e_del, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->o_ins, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->e_ins, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->w, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->end_bonus, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->zdrop, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->h0, sizeof(int)) );\n\n  \n\n  assert( read_check(fd, (void*)&d->qle, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->tle, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->gtle, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->gscore, sizeof(int)) );\n  assert( read_check(fd, (void*)&d->max_off, sizeof(int)) );\n\n  \n\n  assert( read_check(fd, (void*)&d->score, sizeof(int)) );\n\n  \n\n  assert( read_check(fd, (void*)&d->tsc, sizeof(uint64_t)) );\n  assert( read_check(fd, (void*)&d->sec, sizeof(double)) );\n\n  close(fd);\n  return 1;\n}\n\n"}}
{"kernel_name": "fsm", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <cuda.h>\n#include \"parameters.h\"\n#include \"kernels.h\"\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {fprintf(stderr, \"usage: %s trace_length\\n\", argv[0]); exit(-1);}\n  int length = atoi(argv[1]);\n\n  assert(sizeof(unsigned short) == 2);\n  assert(0 < length);\n  assert((FSMSIZE & (FSMSIZE - 1)) == 0);\n  assert((TABSIZE & (TABSIZE - 1)) == 0);\n  assert((0 < FSMSIZE) && (FSMSIZE <= 256));\n  assert((0 < TABSIZE) && (TABSIZE <= 32768));\n  assert(0 < POPCNT);\n  assert((0 < POPSIZE) && (POPSIZE <= 1024));\n  assert(0 < CUTOFF);\n\n  int i, j, d, s, bit, pc, misses, besthits, generations;\n  unsigned short *data, *d_data;\n  unsigned char state[TABSIZE], fsm[FSMSIZE * 2];\n  int *d_best, best[FSMSIZE * 2 + 3], trans[FSMSIZE][2];\n  unsigned int *d_state;\n  unsigned char *d_bfsm, *d_same;\n  int *d_smax, *d_sbest, *d_oldmax;\n  double runtime;\n  struct timeval starttime, endtime;\n\n  data = (unsigned short*) malloc (sizeof(unsigned short) * length);\n\n  srand(123);\n  for (int i = 0; i < length; i++) data[i] = rand();\n\n  printf(\"%d\\t#kernel execution times\\n\", REPEAT);\n  printf(\"%d\\t#fsm size\\n\", FSMSIZE);\n  printf(\"%d\\t#entries\\n\", length);\n  printf(\"%d\\t#tab size\\n\", TABSIZE);\n  printf(\"%d\\t#blocks\\n\", POPCNT);\n  printf(\"%d\\t#threads\\n\", POPSIZE);\n  printf(\"%d\\t#cutoff\\n\", CUTOFF);\n\n  cudaMalloc((void **)&d_data, sizeof(unsigned short) * length);\n  cudaMemcpy(d_data, data, sizeof(unsigned short) * length, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void **)&d_best, sizeof(int) * (FSMSIZE * 2 + 3));\n  cudaMalloc((void **)&d_state, POPCNT * POPSIZE * sizeof(unsigned int));\n  cudaMalloc((void **)&d_bfsm, POPCNT * FSMSIZE * 2 * sizeof(unsigned char));\n  cudaMalloc((void **)&d_same, POPCNT * sizeof(unsigned char));\n  cudaMalloc((void **)&d_smax, POPCNT * sizeof(int));\n  cudaMalloc((void **)&d_sbest, POPCNT * sizeof(int));\n  cudaMalloc((void **)&d_oldmax, POPCNT * sizeof(int));\n\n  cudaDeviceSynchronize();\n  gettimeofday(&starttime, NULL);\n\n  for (int i = 0; i < REPEAT; i++) {\n    cudaMemset(d_best, 0, sizeof(int) * (FSMSIZE * 2 + 3));\n    FSMKernel<<<POPCNT, POPSIZE>>>(length, d_data, d_best, d_state, \n      d_bfsm, d_same, d_smax, d_sbest, d_oldmax);\n    MaxKernel<<<1, 1>>>(d_best, d_bfsm);\n  }\n\n  cudaDeviceSynchronize();\n  gettimeofday(&endtime, NULL);\n\n  runtime = endtime.tv_sec + endtime.tv_usec / 1000000.0 - starttime.tv_sec - starttime.tv_usec / 1000000.0;\n  printf(\"%.6lf\\t#runtime [s]\\n\", runtime / REPEAT);\n\n  cudaMemcpy(best, d_best, sizeof(int) * (FSMSIZE * 2 + 3), cudaMemcpyDeviceToHost);\n  besthits = best[1];\n  generations = best[2];\n  printf(\"%.6lf\\t#throughput [Gtr/s]\\n\", 0.000000001 * POPSIZE * generations * length / (runtime / REPEAT));\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    fsm[i * 2 + 0] = i - 1;\n    fsm[i * 2 + 1] = i + 1;\n  }\n  fsm[0] = 0;\n  fsm[(FSMSIZE - 1) * 2 + 1] = FSMSIZE - 1;\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    misses += bit ^ (((s + s) / FSMSIZE) & 1);\n    state[pc] = fsm[s + s + bit];\n  }\n  printf(\"%d\\t#sudcnt hits\\n\", length-misses);\n  printf(\"%d\\t#GAfsm hits\\n\", besthits);\n\n  printf(\"%.3lf%%\\t#sudcnt hits\\n\", 100.0 * (length - misses) / length);\n  printf(\"%.3lf%%\\t#GAfsm hits\\n\\n\", 100.0 * besthits / length);\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    for (j = 0; j < 2; j++) {\n      trans[i][j] = 0;\n    }\n  }\n  for (i = 0; i < FSMSIZE * 2; i++) {\n    fsm[i] = best[i + 3];\n  }\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    trans[s][bit]++;\n    misses += bit ^ (s & 1);\n    state[pc] = (unsigned char)fsm[s + s + bit];\n  }\n\n  bool ok = ((length - misses) == besthits);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n#ifdef DEBUG\n  \n\n  for (bit = 0; bit < 2; bit++) {\n    for (s = 0; s < FSMSIZE; s++) {\n      d = fsm[s + s + bit];\n      printf(\"%c%d %c%d %d\\n\", (s & 1) ? 'P' : 'N', s / 2, (d & 1) ? 'P' : 'N', d / 2, ((bit * 2) - 1) * trans[s][bit]);\n    }\n  }\n#endif\n\n  free(data);\n  cudaFree(d_data);\n  cudaFree(d_best);\n  cudaFree(d_state);  \n  cudaFree(d_bfsm);\n  cudaFree(d_same);\n  cudaFree(d_smax);\n  cudaFree(d_sbest);\n  cudaFree(d_oldmax);\n  return 0;\n}\n"}}
{"kernel_name": "fsm", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <hip/hip_runtime.h>\n#include \"parameters.h\"\n#include \"kernels.h\"\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {fprintf(stderr, \"usage: %s trace_length\\n\", argv[0]); exit(-1);}\n  int length = atoi(argv[1]);\n\n  assert(sizeof(unsigned short) == 2);\n  assert(0 < length);\n  assert((FSMSIZE & (FSMSIZE - 1)) == 0);\n  assert((TABSIZE & (TABSIZE - 1)) == 0);\n  assert((0 < FSMSIZE) && (FSMSIZE <= 256));\n  assert((0 < TABSIZE) && (TABSIZE <= 32768));\n  assert(0 < POPCNT);\n  assert((0 < POPSIZE) && (POPSIZE <= 1024));\n  assert(0 < CUTOFF);\n\n  int i, j, d, s, bit, pc, misses, besthits, generations;\n  unsigned short *data, *d_data;\n  unsigned char state[TABSIZE], fsm[FSMSIZE * 2];\n  int *d_best, best[FSMSIZE * 2 + 3], trans[FSMSIZE][2];\n  unsigned int *d_state;\n  unsigned char *d_bfsm, *d_same;\n  int *d_smax, *d_sbest, *d_oldmax;\n  double runtime;\n  struct timeval starttime, endtime;\n\n  data = (unsigned short*) malloc (sizeof(unsigned short) * length);\n\n  srand(123);\n  for (int i = 0; i < length; i++) data[i] = rand();\n\n  printf(\"%d\\t#kernel execution times\\n\", REPEAT);\n  printf(\"%d\\t#fsm size\\n\", FSMSIZE);\n  printf(\"%d\\t#entries\\n\", length);\n  printf(\"%d\\t#tab size\\n\", TABSIZE);\n  printf(\"%d\\t#blocks\\n\", POPCNT);\n  printf(\"%d\\t#threads\\n\", POPSIZE);\n  printf(\"%d\\t#cutoff\\n\", CUTOFF);\n\n  hipMalloc((void **)&d_data, sizeof(unsigned short) * length);\n  hipMemcpy(d_data, data, sizeof(unsigned short) * length, hipMemcpyHostToDevice);\n\n  hipMalloc((void **)&d_best, sizeof(int) * (FSMSIZE * 2 + 3));\n  hipMalloc((void **)&d_state, POPCNT * POPSIZE * sizeof(unsigned int));\n  hipMalloc((void **)&d_bfsm, POPCNT * FSMSIZE * 2 * sizeof(unsigned char));\n  hipMalloc((void **)&d_same, POPCNT * sizeof(unsigned char));\n  hipMalloc((void **)&d_smax, POPCNT * sizeof(int));\n  hipMalloc((void **)&d_sbest, POPCNT * sizeof(int));\n  hipMalloc((void **)&d_oldmax, POPCNT * sizeof(int));\n\n  hipDeviceSynchronize();\n  gettimeofday(&starttime, NULL);\n\n  for (int i = 0; i < REPEAT; i++) {\n    hipMemset(d_best, 0, sizeof(int) * (FSMSIZE * 2 + 3));\n    hipLaunchKernelGGL(FSMKernel, POPCNT, POPSIZE, 0, 0, length, d_data, d_best, d_state, \n      d_bfsm, d_same, d_smax, d_sbest, d_oldmax);\n    hipLaunchKernelGGL(MaxKernel, 1, 1, 0, 0, d_best, d_bfsm);\n  }\n  hipDeviceSynchronize();\n  gettimeofday(&endtime, NULL);\n\n  runtime = endtime.tv_sec + endtime.tv_usec / 1000000.0 - starttime.tv_sec - starttime.tv_usec / 1000000.0;\n  printf(\"%.6lf\\t#runtime [s]\\n\", runtime / REPEAT);\n\n  hipMemcpy(best, d_best, sizeof(int) * (FSMSIZE * 2 + 3), hipMemcpyDeviceToHost);\n  besthits = best[1];\n  generations = best[2];\n  printf(\"%.6lf\\t#throughput [Gtr/s]\\n\", 0.000000001 * POPSIZE * generations * length / (runtime / REPEAT));\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    fsm[i * 2 + 0] = i - 1;\n    fsm[i * 2 + 1] = i + 1;\n  }\n  fsm[0] = 0;\n  fsm[(FSMSIZE - 1) * 2 + 1] = FSMSIZE - 1;\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    misses += bit ^ (((s + s) / FSMSIZE) & 1);\n    state[pc] = fsm[s + s + bit];\n  }\n  printf(\"%d\\t#sudcnt hits\\n\", length-misses);\n  printf(\"%d\\t#GAfsm hits\\n\", besthits);\n\n  printf(\"%.3lf%%\\t#sudcnt hits\\n\", 100.0 * (length - misses) / length);\n  printf(\"%.3lf%%\\t#GAfsm hits\\n\\n\", 100.0 * besthits / length);\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    for (j = 0; j < 2; j++) {\n      trans[i][j] = 0;\n    }\n  }\n  for (i = 0; i < FSMSIZE * 2; i++) {\n    fsm[i] = best[i + 3];\n  }\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    trans[s][bit]++;\n    misses += bit ^ (s & 1);\n    state[pc] = (unsigned char)fsm[s + s + bit];\n  }\n\n  bool ok = ((length - misses) == besthits);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n#ifdef DEBUG\n  \n\n  for (bit = 0; bit < 2; bit++) {\n    for (s = 0; s < FSMSIZE; s++) {\n      d = fsm[s + s + bit];\n      printf(\"%c%d %c%d %d\\n\", (s & 1) ? 'P' : 'N', s / 2, (d & 1) ? 'P' : 'N', d / 2, ((bit * 2) - 1) * trans[s][bit]);\n    }\n  }\n#endif\n\n  free(data);\n  hipFree(d_data);\n  hipFree(d_best);\n  hipFree(d_state);  \n  hipFree(d_bfsm);\n  hipFree(d_same);\n  hipFree(d_smax);\n  hipFree(d_sbest);\n  hipFree(d_oldmax);\n  return 0;\n}\n"}}
{"kernel_name": "fsm", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <omp.h>\n#include \"parameters.h\"\n#include \"kernels.h\"\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {fprintf(stderr, \"usage: %s trace_length\\n\", argv[0]); exit(-1);}\n  int length = atoi(argv[1]);\n\n  assert(sizeof(unsigned short) == 2);\n  assert(0 < length);\n  assert((FSMSIZE & (FSMSIZE - 1)) == 0);\n  assert((TABSIZE & (TABSIZE - 1)) == 0);\n  assert((0 < FSMSIZE) && (FSMSIZE <= 256));\n  assert((0 < TABSIZE) && (TABSIZE <= 32768));\n  assert(0 < POPCNT);\n  assert((0 < POPSIZE) && (POPSIZE <= 1024));\n  assert(0 < CUTOFF);\n\n  int i, j, d, s, bit, pc, misses, besthits, generations;\n  unsigned short *data;\n  unsigned char state[TABSIZE], fsm[FSMSIZE * 2];\n  int best[FSMSIZE * 2 + 3], trans[FSMSIZE][2];\n  double runtime;\n  struct timeval starttime, endtime;\n\n  data = (unsigned short*) malloc (sizeof(unsigned short) * length);\n\n  srand(123);\n  for (int i = 0; i < length; i++) data[i] = rand();\n\n  printf(\"%d\\t#kernel execution times\\n\", REPEAT);\n  printf(\"%d\\t#fsm size\\n\", FSMSIZE);\n  printf(\"%d\\t#entries\\n\", length);\n  printf(\"%d\\t#tab size\\n\", TABSIZE);\n  printf(\"%d\\t#blocks\\n\", POPCNT);\n  printf(\"%d\\t#threads\\n\", POPSIZE);\n  printf(\"%d\\t#cutoff\\n\", CUTOFF);\n\n  unsigned int *rndstate = (unsigned int*) malloc (POPCNT * POPSIZE * sizeof(unsigned int));\n  unsigned char *bfsm = (unsigned char*) malloc (POPCNT * FSMSIZE * 2 * sizeof(unsigned char));\n  unsigned char *same = (unsigned char*) malloc (POPCNT * sizeof(unsigned char));\n  int *smax = (int*) malloc (POPCNT * sizeof(int));\n  int *sbest = (int*) malloc (POPCNT * sizeof(int));\n  int *oldmax = (int*) malloc (POPCNT * sizeof(int));\n\n  #pragma omp target data map (to: data[0:length]) \\\n                          map (from: best[0:FSMSIZE * 2 + 3]) \\\n                          map (alloc: rndstate[0:POPCNT * POPSIZE],\\\n                                      bfsm[0:POPCNT * FSMSIZE * 2],\\\n                                      same[0:POPCNT],\\\n                                      smax[0:POPCNT],\\\n                                      sbest[0:POPCNT],\\\n                                      oldmax[0:POPCNT])\n  {\n    gettimeofday(&starttime, NULL);\n\n    for (int i = 0; i < REPEAT; i++) {\n      #pragma omp target teams distribute parallel for\n      for (int i = 0; i < FSMSIZE * 2 + 3; i++) best[i] = 0;\n      FSMKernel(length, data, best, rndstate, bfsm, same, smax, sbest, oldmax);\n      MaxKernel(best, bfsm);\n    }\n\n    gettimeofday(&endtime, NULL);\n    runtime = endtime.tv_sec + endtime.tv_usec / 1000000.0 - starttime.tv_sec - starttime.tv_usec / 1000000.0;\n    printf(\"%.6lf\\t#runtime [s]\\n\", runtime / REPEAT);\n  }\n\n  besthits = best[1];\n  generations = best[2];\n\n  printf(\"%.6lf\\t#throughput [Gtr/s]\\n\", 0.000000001 * POPSIZE * generations * length / (runtime / REPEAT));\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    fsm[i * 2 + 0] = i - 1;\n    fsm[i * 2 + 1] = i + 1;\n  }\n  fsm[0] = 0;\n  fsm[(FSMSIZE - 1) * 2 + 1] = FSMSIZE - 1;\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    misses += bit ^ (((s + s) / FSMSIZE) & 1);\n    state[pc] = fsm[s + s + bit];\n  }\n  printf(\"%d\\t#sudcnt hits\\n\", length-misses);\n  printf(\"%d\\t#GAfsm hits\\n\", besthits);\n\n  printf(\"%.3lf%%\\t#sudcnt hits\\n\", 100.0 * (length - misses) / length);\n  printf(\"%.3lf%%\\t#GAfsm hits\\n\\n\", 100.0 * besthits / length);\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    for (j = 0; j < 2; j++) {\n      trans[i][j] = 0;\n    }\n  }\n  for (i = 0; i < FSMSIZE * 2; i++) {\n    fsm[i] = best[i + 3];\n  }\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    trans[s][bit]++;\n    misses += bit ^ (s & 1);\n    state[pc] = (unsigned char)fsm[s + s + bit];\n  }\n\n  bool ok = ((length - misses) == besthits);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n#ifdef DEBUG\n  \n\n  for (bit = 0; bit < 2; bit++) {\n    for (s = 0; s < FSMSIZE; s++) {\n      d = fsm[s + s + bit];\n      printf(\"%c%d %c%d %d\\n\", (s & 1) ? 'P' : 'N', s / 2, (d & 1) ? 'P' : 'N', d / 2, ((bit * 2) - 1) * trans[s][bit]);\n    }\n  }\n#endif\n\n  free(data);\n  free(rndstate);\n  free(bfsm);\n  free(same);\n  free(smax);\n  free(sbest);\n  free(oldmax);\n  return 0;\n}\n"}}
{"kernel_name": "fsm", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <assert.h>\n#include <sys/time.h>\n#include \"parameters.h\"\n#include \"kernels.h\"\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {fprintf(stderr, \"usage: %s trace_length\\n\", argv[0]); exit(-1);}\n  int length = atoi(argv[1]);\n\n  assert(sizeof(unsigned short) == 2);\n  assert(0 < length);\n  assert((FSMSIZE & (FSMSIZE - 1)) == 0);\n  assert((TABSIZE & (TABSIZE - 1)) == 0);\n  assert((0 < FSMSIZE) && (FSMSIZE <= 256));\n  assert((0 < TABSIZE) && (TABSIZE <= 32768));\n  assert(0 < POPCNT);\n  assert((0 < POPSIZE) && (POPSIZE <= 1024));\n  assert(0 < CUTOFF);\n\n  int i, j, d, s, bit, pc, misses, besthits, generations;\n  unsigned short *data;\n  unsigned char state[TABSIZE], fsm[FSMSIZE * 2];\n  int best[FSMSIZE * 2 + 3], trans[FSMSIZE][2];\n  double runtime;\n  struct timeval starttime, endtime;\n\n  data = (unsigned short*) malloc (sizeof(unsigned short) * length);\n\n  srand(123);\n  for (int i = 0; i < length; i++) data[i] = rand();\n\n  printf(\"%d\\t#kernel execution times\\n\", REPEAT);\n  printf(\"%d\\t#fsm size\\n\", FSMSIZE);\n  printf(\"%d\\t#entries\\n\", length);\n  printf(\"%d\\t#tab size\\n\", TABSIZE);\n  printf(\"%d\\t#blocks\\n\", POPCNT);\n  printf(\"%d\\t#threads\\n\", POPSIZE);\n  printf(\"%d\\t#cutoff\\n\", CUTOFF);\n\n  unsigned int *rndstate = (unsigned int*) malloc (POPCNT * POPSIZE * sizeof(unsigned int));\n  unsigned char *bfsm = (unsigned char*) malloc (POPCNT * FSMSIZE * 2 * sizeof(unsigned char));\n  unsigned char *same = (unsigned char*) malloc (POPCNT * sizeof(unsigned char));\n  int *smax = (int*) malloc (POPCNT * sizeof(int));\n  int *sbest = (int*) malloc (POPCNT * sizeof(int));\n  int *oldmax = (int*) malloc (POPCNT * sizeof(int));\n\n    {\n    gettimeofday(&starttime, NULL);\n\n    for (int i = 0; i < REPEAT; i++) {\n            for (int i = 0; i < FSMSIZE * 2 + 3; i++) best[i] = 0;\n      FSMKernel(length, data, best, rndstate, bfsm, same, smax, sbest, oldmax);\n      MaxKernel(best, bfsm);\n    }\n\n    gettimeofday(&endtime, NULL);\n    runtime = endtime.tv_sec + endtime.tv_usec / 1000000.0 - starttime.tv_sec - starttime.tv_usec / 1000000.0;\n    printf(\"%.6lf\\t#runtime [s]\\n\", runtime / REPEAT);\n  }\n\n  besthits = best[1];\n  generations = best[2];\n\n  printf(\"%.6lf\\t#throughput [Gtr/s]\\n\", 0.000000001 * POPSIZE * generations * length / (runtime / REPEAT));\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    fsm[i * 2 + 0] = i - 1;\n    fsm[i * 2 + 1] = i + 1;\n  }\n  fsm[0] = 0;\n  fsm[(FSMSIZE - 1) * 2 + 1] = FSMSIZE - 1;\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    misses += bit ^ (((s + s) / FSMSIZE) & 1);\n    state[pc] = fsm[s + s + bit];\n  }\n  printf(\"%d\\t#sudcnt hits\\n\", length-misses);\n  printf(\"%d\\t#GAfsm hits\\n\", besthits);\n\n  printf(\"%.3lf%%\\t#sudcnt hits\\n\", 100.0 * (length - misses) / length);\n  printf(\"%.3lf%%\\t#GAfsm hits\\n\\n\", 100.0 * besthits / length);\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    for (j = 0; j < 2; j++) {\n      trans[i][j] = 0;\n    }\n  }\n  for (i = 0; i < FSMSIZE * 2; i++) {\n    fsm[i] = best[i + 3];\n  }\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    trans[s][bit]++;\n    misses += bit ^ (s & 1);\n    state[pc] = (unsigned char)fsm[s + s + bit];\n  }\n\n  bool ok = ((length - misses) == besthits);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n#ifdef DEBUG\n  \n\n  for (bit = 0; bit < 2; bit++) {\n    for (s = 0; s < FSMSIZE; s++) {\n      d = fsm[s + s + bit];\n      printf(\"%c%d %c%d %d\\n\", (s & 1) ? 'P' : 'N', s / 2, (d & 1) ? 'P' : 'N', d / 2, ((bit * 2) - 1) * trans[s][bit]);\n    }\n  }\n#endif\n\n  free(data);\n  free(rndstate);\n  free(bfsm);\n  free(same);\n  free(smax);\n  free(sbest);\n  free(oldmax);\n  return 0;\n}"}}
{"kernel_name": "fsm", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <sycl/sycl.hpp>\n#include \"parameters.h\"\n#include \"kernels.h\"\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {fprintf(stderr, \"usage: %s trace_length\\n\", argv[0]); exit(-1);}\n  int length = atoi(argv[1]);\n\n  assert(sizeof(unsigned short) == 2);\n  assert(0 < length);\n  assert((FSMSIZE & (FSMSIZE - 1)) == 0);\n  assert((TABSIZE & (TABSIZE - 1)) == 0);\n  assert((0 < FSMSIZE) && (FSMSIZE <= 256));\n  assert((0 < TABSIZE) && (TABSIZE <= 32768));\n  assert(0 < POPCNT);\n  assert((0 < POPSIZE) && (POPSIZE <= 1024));\n  assert(0 < CUTOFF);\n\n  int i, j, d, s, bit, pc, misses, besthits, generations;\n  unsigned short *data;\n  unsigned char state[TABSIZE], fsm[FSMSIZE * 2];\n  int best[FSMSIZE * 2 + 3], trans[FSMSIZE][2];\n  double runtime;\n  struct timeval starttime, endtime;\n\n  data = (unsigned short*) malloc (sizeof(unsigned short) * length);\n\n  srand(123);\n  for (int i = 0; i < length; i++) data[i] = rand();\n\n  printf(\"%d\\t#kernel execution times\\n\", REPEAT);\n  printf(\"%d\\t#fsm size\\n\", FSMSIZE);\n  printf(\"%d\\t#entries\\n\", length);\n  printf(\"%d\\t#tab size\\n\", TABSIZE);\n  printf(\"%d\\t#blocks\\n\", POPCNT);\n  printf(\"%d\\t#threads\\n\", POPSIZE);\n  printf(\"%d\\t#cutoff\\n\", CUTOFF);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  unsigned short *d_data = sycl::malloc_device<unsigned short>(length, q);\n  q.memcpy(d_data, data, sizeof(unsigned short) * length);\n\n  int *d_best = sycl::malloc_device<int>(FSMSIZE*2+3, q);\n  unsigned int *d_state = sycl::malloc_device<unsigned  int>(POPCNT * POPSIZE, q);\n  unsigned char *d_bfsm = sycl::malloc_device<unsigned char>(POPCNT * FSMSIZE *2, q);\n  unsigned char *d_same = sycl::malloc_device<unsigned char>(POPCNT, q);\n  int *d_smax = sycl::malloc_device<int>(POPCNT, q);\n  int *d_sbest = sycl::malloc_device<int>(POPCNT, q);\n  int *d_oldmax = sycl::malloc_device<int>(POPCNT, q);\n\n  q.wait();\n  gettimeofday(&starttime, NULL);\n\n  for (int i = 0; i < REPEAT; i++) {\n    q.memset(d_best, 0, sizeof(int) * (FSMSIZE*2+3));\n\n    sycl::range<1> lws (POPSIZE);\n    sycl::range<1> gws (POPCNT * POPSIZE);\n\n    q.submit([&](sycl::handler& cgh) {\n      sycl::local_accessor<unsigned char, 1> sm (sycl::range<1>(FSMSIZE*2*POPSIZE), cgh);\n      cgh.parallel_for<class fsm>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        FSMKernel(item,\n                  length,\n                  d_data,\n                  d_best,\n                  d_state,\n                  d_bfsm,\n                  d_same,\n                  d_smax,\n                  d_sbest,\n                  d_oldmax,\n                  sm.get_pointer());\n      });\n    });\n\n    q.submit([&](sycl::handler& cgh) {\n      cgh.single_task([=] () {\n         MaxKernel(d_best, d_bfsm);\n      });\n    });\n  }\n  q.wait();\n  gettimeofday(&endtime, NULL);\n\n  runtime = endtime.tv_sec + endtime.tv_usec / 1000000.0 - starttime.tv_sec - starttime.tv_usec / 1000000.0;\n  printf(\"%.6lf\\t#runtime [s]\\n\", runtime / REPEAT);\n\n  q.memcpy(best, d_best, sizeof(int) * (FSMSIZE * 2 + 3)).wait();\n\n  besthits = best[1];\n  generations = best[2];\n  printf(\"%.6lf\\t#throughput [Gtr/s]\\n\", 0.000000001 * POPSIZE * generations * length / (runtime / REPEAT));\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    fsm[i * 2 + 0] = i - 1;\n    fsm[i * 2 + 1] = i + 1;\n  }\n  fsm[0] = 0;\n  fsm[(FSMSIZE - 1) * 2 + 1] = FSMSIZE - 1;\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    misses += bit ^ (((s + s) / FSMSIZE) & 1);\n    state[pc] = fsm[s + s + bit];\n  }\n  printf(\"%d\\t#sudcnt hits\\n\", length-misses);\n  printf(\"%d\\t#GAfsm hits\\n\", besthits);\n\n  printf(\"%.3lf%%\\t#sudcnt hits\\n\", 100.0 * (length - misses) / length);\n  printf(\"%.3lf%%\\t#GAfsm hits\\n\\n\", 100.0 * besthits / length);\n\n  \n\n  for (i = 0; i < FSMSIZE; i++) {\n    for (j = 0; j < 2; j++) {\n      trans[i][j] = 0;\n    }\n  }\n  for (i = 0; i < FSMSIZE * 2; i++) {\n    fsm[i] = best[i + 3];\n  }\n  memset(state, 0, TABSIZE);\n  misses = 0;\n  for (i = 0; i < length; i++) {\n    d = (int)data[i];\n    pc = (d >> 1) & (TABSIZE - 1);\n    bit = d & 1;\n    s = (int)state[pc];\n    trans[s][bit]++;\n    misses += bit ^ (s & 1);\n    state[pc] = (unsigned char)fsm[s + s + bit];\n  }\n\n  bool ok = ((length - misses) == besthits);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  \n#ifdef DEBUG\n  \n\n  for (bit = 0; bit < 2; bit++) {\n    for (s = 0; s < FSMSIZE; s++) {\n      d = fsm[s + s + bit];\n      printf(\"%c%d %c%d %d\\n\", (s & 1) ? 'P' : 'N', s / 2, (d & 1) ? 'P' : 'N', d / 2, ((bit * 2) - 1) * trans[s][bit]);\n    }\n  }\n#endif\n\n  free(data);\n  sycl::free(d_data, q);\n  sycl::free(d_best, q);\n  sycl::free(d_state, q);  \n  sycl::free(d_bfsm, q);\n  sycl::free(d_same, q);\n  sycl::free(d_smax, q);\n  sycl::free(d_sbest, q);\n  sycl::free(d_oldmax, q);\n  return 0;\n}\n"}}
{"kernel_name": "ga", "parallel_api": "cuda", "code": {"main.cu": "#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <vector>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n__global__ \nvoid ga(const char *__restrict__ target,\n        const char *__restrict__ query,\n              char *__restrict__ batch_result,\n              uint32_t length,\n              int query_sequence_length,\n              int coarse_match_length,\n              int coarse_match_threshold,\n              int current_position)\n{\n  uint tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid > length) return;\n  bool match = false;\n  int max_length = query_sequence_length - coarse_match_length;\n\n  for (int i = 0; i <= max_length; i++) {\n    int distance = 0;\n    for (int j = 0; j < coarse_match_length; j++) {\n      if (target[current_position + tid + j] != query[i + j]) {\n        distance++;\n      }\n    }\n\n    if (distance < coarse_match_threshold) {\n      match = true;\n      break;\n    }\n  }\n  if (match) {\n    batch_result[tid] = 1;\n  }\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 5) {\n    printf(\"Usage: %s <target sequence length> <query sequence length> \"\n           \"<coarse match length> <coarse match threshold>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int kBatchSize = 1024;\n  char seq[] = {'A', 'C', 'T', 'G'};\n  const int tseq_size = atoi(argv[1]);\n  const int qseq_size = atoi(argv[2]);\n  const int coarse_match_length = atoi(argv[3]);\n  const int coarse_match_threshold = atoi(argv[4]);\n  \n  std::vector<char> target_sequence(tseq_size);\n  std::vector<char> query_sequence(qseq_size);\n\n  srand(123);\n  for (int i = 0; i < tseq_size; i++) target_sequence[i] = seq[rand()%4];\n  for (int i = 0; i < qseq_size; i++) query_sequence[i] = seq[rand()%4];\n\n  char *d_target, *d_query, *d_batch_result;\n  cudaMalloc((void**)&d_target, tseq_size * sizeof(char));\n  cudaMalloc((void**)&d_query, qseq_size * sizeof(char));\n  cudaMalloc((void**)&d_batch_result, kBatchSize * sizeof(char));\n\n  cudaMemcpy(d_target, target_sequence.data(), tseq_size * sizeof(char), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_query, query_sequence.data(), qseq_size * sizeof(char), cudaMemcpyHostToDevice);\n\n  uint32_t max_searchable_length = tseq_size - coarse_match_length;\n  uint32_t current_position = 0;\n\n  \n\n  char batch_result[kBatchSize];\n  char batch_result_ref[kBatchSize];\n\n  float total_time = 0.f;\n\n  int error = 0;\n  while (current_position < max_searchable_length) {\n    cudaMemset(d_batch_result, 0, kBatchSize);\n    memset(batch_result_ref, 0, kBatchSize);\n\n    uint32_t end_position = current_position + kBatchSize;\n    if (end_position >= max_searchable_length) {\n      end_position = max_searchable_length;\n    }\n    uint32_t length = end_position - current_position;\n\n    dim3 block_size(256);\n    dim3 grid_size((length + block_size.x - 1) / block_size.x);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    ga<<<grid_size, block_size>>>(\n        d_target, d_query, d_batch_result, length, qseq_size,\n        coarse_match_length, coarse_match_threshold, current_position);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n\n    reference(target_sequence.data(), query_sequence.data(), batch_result_ref, length, qseq_size,\n              coarse_match_length, coarse_match_threshold, current_position);\n\n    cudaMemcpy(batch_result, d_batch_result, kBatchSize * sizeof(char), cudaMemcpyDeviceToHost);\n\n    error = memcmp(batch_result_ref, batch_result, kBatchSize * sizeof(char));\n    if (error) break;\n\n    current_position = end_position;\n  }\n  printf(\"Total kernel execution time %f (s)\\n\", total_time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  cudaFree(d_target);\n  cudaFree(d_query);\n  cudaFree(d_batch_result);\n  return 0;\n}\n"}}
{"kernel_name": "ga", "parallel_api": "hip", "code": {"main.cu": "#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <vector>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n__global__ \nvoid ga(const char *__restrict__ target,\n        const char *__restrict__ query,\n              char *__restrict__ batch_result,\n              uint32_t length,\n              int query_sequence_length,\n              int coarse_match_length,\n              int coarse_match_threshold,\n              int current_position)\n{\n  uint tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid > length) return;\n  bool match = false;\n  int max_length = query_sequence_length - coarse_match_length;\n\n  for (int i = 0; i <= max_length; i++) {\n    int distance = 0;\n    for (int j = 0; j < coarse_match_length; j++) {\n      if (target[current_position + tid + j] != query[i + j]) {\n        distance++;\n      }\n    }\n\n    if (distance < coarse_match_threshold) {\n      match = true;\n      break;\n    }\n  }\n  if (match) {\n    batch_result[tid] = 1;\n  }\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 5) {\n    printf(\"Usage: %s <target sequence length> <query sequence length> \"\n           \"<coarse match length> <coarse match threshold>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int kBatchSize = 1024;\n  char seq[] = {'A', 'C', 'T', 'G'};\n  const int tseq_size = atoi(argv[1]);\n  const int qseq_size = atoi(argv[2]);\n  const int coarse_match_length = atoi(argv[3]);\n  const int coarse_match_threshold = atoi(argv[4]);\n  \n  std::vector<char> target_sequence(tseq_size);\n  std::vector<char> query_sequence(qseq_size);\n\n  srand(123);\n  for (int i = 0; i < tseq_size; i++) target_sequence[i] = seq[rand()%4];\n  for (int i = 0; i < qseq_size; i++) query_sequence[i] = seq[rand()%4];\n\n  char *d_target, *d_query, *d_batch_result;\n  hipMalloc((void**)&d_target, tseq_size * sizeof(char));\n  hipMalloc((void**)&d_query, qseq_size * sizeof(char));\n  hipMalloc((void**)&d_batch_result, kBatchSize * sizeof(char));\n\n  hipMemcpy(d_target, target_sequence.data(), tseq_size * sizeof(char), hipMemcpyHostToDevice);\n  hipMemcpy(d_query, query_sequence.data(), qseq_size * sizeof(char), hipMemcpyHostToDevice);\n\n  uint32_t max_searchable_length = tseq_size - coarse_match_length;\n  uint32_t current_position = 0;\n\n  \n\n  char batch_result[kBatchSize];\n  char batch_result_ref[kBatchSize];\n\n  float total_time = 0.f;\n\n  int error = 0;\n  while (current_position < max_searchable_length) {\n    hipMemset(d_batch_result, 0, kBatchSize);\n    memset(batch_result_ref, 0, kBatchSize);\n\n    uint32_t end_position = current_position + kBatchSize;\n    if (end_position >= max_searchable_length) {\n      end_position = max_searchable_length;\n    }\n    uint32_t length = end_position - current_position;\n\n    dim3 block_size(256);\n    dim3 grid_size((length + block_size.x - 1) / block_size.x);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    hipLaunchKernelGGL(ga, grid_size, block_size, 0, 0, \n        d_target, d_query, d_batch_result, length, qseq_size,\n        coarse_match_length, coarse_match_threshold, current_position);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n\n    reference(target_sequence.data(), query_sequence.data(), batch_result_ref, length, qseq_size,\n              coarse_match_length, coarse_match_threshold, current_position);\n\n    hipMemcpy(batch_result, d_batch_result, kBatchSize * sizeof(char), hipMemcpyDeviceToHost);\n\n    error = memcmp(batch_result_ref, batch_result, kBatchSize * sizeof(char));\n    if (error) break;\n\n    current_position = end_position;\n  }\n  printf(\"Total kernel execution time %f (s)\\n\", total_time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  hipFree(d_target);\n  hipFree(d_query);\n  hipFree(d_batch_result);\n  return 0;\n}\n"}}
{"kernel_name": "ga", "parallel_api": "omp", "code": {"main.cpp": "#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <vector>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\nvoid ga(const char *__restrict target,\n        const char *__restrict query,\n              char *__restrict batch_result,\n              uint32_t length,\n              int query_sequence_length,\n              int coarse_match_length,\n              int coarse_match_threshold,\n              int current_position)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (uint tid = 0; tid < length; tid++) { \n    bool match = false;\n    int max_length = query_sequence_length - coarse_match_length;\n\n    for (int i = 0; i <= max_length; i++) {\n      int distance = 0;\n      for (int j = 0; j < coarse_match_length; j++) {\n        if (target[current_position + tid + j] != query[i + j]) {\n          distance++;\n        }\n      }\n\n      if (distance < coarse_match_threshold) {\n        match = true;\n        break;\n      }\n    }\n    if (match) {\n      batch_result[tid] = 1;\n    }\n  }\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 5) {\n    printf(\"Usage: %s <target sequence length> <query sequence length> \"\n           \"<coarse match length> <coarse match threshold>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int kBatchSize = 1024;\n  char seq[] = {'A', 'C', 'T', 'G'};\n  const int tseq_size = atoi(argv[1]);\n  const int qseq_size = atoi(argv[2]);\n  const int coarse_match_length = atoi(argv[3]);\n  const int coarse_match_threshold = atoi(argv[4]);\n  \n  std::vector<char> target_sequence(tseq_size);\n  std::vector<char> query_sequence(qseq_size);\n\n  srand(123);\n  for (int i = 0; i < tseq_size; i++) target_sequence[i] = seq[rand()%4];\n  for (int i = 0; i < qseq_size; i++) query_sequence[i] = seq[rand()%4];\n\n  char *d_target = target_sequence.data(); \n  char *d_query = query_sequence.data();\n\n  uint32_t max_searchable_length = tseq_size - coarse_match_length;\n  uint32_t current_position = 0;\n\n  \n\n  char d_batch_result[kBatchSize];\n  char batch_result_ref[kBatchSize];\n\n  float total_time = 0.f;\n\n  int error = 0;\n\n  #pragma omp target data map (to: d_target[0:tseq_size], \\\n                                   d_query[0:qseq_size]) \\\n                          map (alloc: d_batch_result[0:kBatchSize])\n  {\n    while (current_position < max_searchable_length) {\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (int i = 0; i < kBatchSize; i++)\n        d_batch_result[i] = 0;\n      \n      memset(batch_result_ref, 0, kBatchSize);\n\n      uint32_t end_position = current_position + kBatchSize;\n      if (end_position >= max_searchable_length) {\n        end_position = max_searchable_length;\n      }\n      uint32_t length = end_position - current_position;\n\n      auto start = std::chrono::steady_clock::now();\n\n      ga( d_target, d_query, d_batch_result, length, qseq_size,\n          coarse_match_length, coarse_match_threshold, current_position);\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      total_time += time;\n\n      reference(target_sequence.data(), query_sequence.data(), batch_result_ref, length, qseq_size,\n                coarse_match_length, coarse_match_threshold, current_position);\n\n      #pragma omp target update from (d_batch_result[0:kBatchSize])\n      error = memcmp(batch_result_ref, d_batch_result, kBatchSize * sizeof(char));\n      if (error) break;\n\n      current_position = end_position;\n    }\n  }\n  printf(\"Total kernel execution time %f (s)\\n\", total_time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  return 0;\n}\n"}}
{"kernel_name": "ga", "parallel_api": "serial", "code": {"main.cpp": "#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <vector>\n#include <chrono>\n#include \"reference.h\"\n\nvoid ga(const char *__restrict target,\n        const char *__restrict query,\n              char *__restrict batch_result,\n              uint32_t length,\n              int query_sequence_length,\n              int coarse_match_length,\n              int coarse_match_threshold,\n              int current_position)\n{\n    for (uint tid = 0; tid < length; tid++) { \n    bool match = false;\n    int max_length = query_sequence_length - coarse_match_length;\n\n    for (int i = 0; i <= max_length; i++) {\n      int distance = 0;\n      for (int j = 0; j < coarse_match_length; j++) {\n        if (target[current_position + tid + j] != query[i + j]) {\n          distance++;\n        }\n      }\n\n      if (distance < coarse_match_threshold) {\n        match = true;\n        break;\n      }\n    }\n    if (match) {\n      batch_result[tid] = 1;\n    }\n  }\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 5) {\n    printf(\"Usage: %s <target sequence length> <query sequence length> \"\n           \"<coarse match length> <coarse match threshold>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int kBatchSize = 1024;\n  char seq[] = {'A', 'C', 'T', 'G'};\n  const int tseq_size = atoi(argv[1]);\n  const int qseq_size = atoi(argv[2]);\n  const int coarse_match_length = atoi(argv[3]);\n  const int coarse_match_threshold = atoi(argv[4]);\n  \n  std::vector<char> target_sequence(tseq_size);\n  std::vector<char> query_sequence(qseq_size);\n\n  srand(123);\n  for (int i = 0; i < tseq_size; i++) target_sequence[i] = seq[rand()%4];\n  for (int i = 0; i < qseq_size; i++) query_sequence[i] = seq[rand()%4];\n\n  char *d_target = target_sequence.data(); \n  char *d_query = query_sequence.data();\n\n  uint32_t max_searchable_length = tseq_size - coarse_match_length;\n  uint32_t current_position = 0;\n\n  \n\n  char d_batch_result[kBatchSize];\n  char batch_result_ref[kBatchSize];\n\n  float total_time = 0.f;\n\n  int error = 0;\n\n    {\n    while (current_position < max_searchable_length) {\n            for (int i = 0; i < kBatchSize; i++)\n        d_batch_result[i] = 0;\n      \n      memset(batch_result_ref, 0, kBatchSize);\n\n      uint32_t end_position = current_position + kBatchSize;\n      if (end_position >= max_searchable_length) {\n        end_position = max_searchable_length;\n      }\n      uint32_t length = end_position - current_position;\n\n      auto start = std::chrono::steady_clock::now();\n\n      ga( d_target, d_query, d_batch_result, length, qseq_size,\n          coarse_match_length, coarse_match_threshold, current_position);\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      total_time += time;\n\n      reference(target_sequence.data(), query_sequence.data(), batch_result_ref, length, qseq_size,\n                coarse_match_length, coarse_match_threshold, current_position);\n\n            error = memcmp(batch_result_ref, d_batch_result, kBatchSize * sizeof(char));\n      if (error) break;\n\n      current_position = end_position;\n    }\n  }\n  printf(\"Total kernel execution time %f (s)\\n\", total_time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  return 0;\n}"}}
{"kernel_name": "ga", "parallel_api": "sycl", "code": {"main.cpp": "#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <vector>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n#ifdef __NVPTX__\n  #include <sycl/ext/oneapi/experimental/cuda/builtins.hpp>\n  using namespace sycl::ext::oneapi::experimental::cuda;\n#else\n  #define ldg(a) (*(a))\n#endif\n\nvoid ga(sycl::nd_item<1> &item,\n        const char *__restrict target,\n        const char *__restrict query,\n              char *__restrict batch_result,\n              uint32_t length,\n              int query_sequence_length,\n              int coarse_match_length,\n              int coarse_match_threshold,\n              int current_position)\n{\n  uint tid = item.get_global_id(0);\n  if (tid > length) return;\n  bool match = false;\n  const int max_length = query_sequence_length - coarse_match_length;\n  const int base = current_position + tid;\n\n  for (int i = 0; i <= max_length; i++) {\n    int distance = 0;\n    for (int j = 0; j < coarse_match_length; j++) {\n      if (ldg(&target[base + j]) != ldg(&query[i + j])) {\n        distance++;\n      }\n    }\n\n    if (distance < coarse_match_threshold) {\n      match = true;\n      break;\n    }\n  }\n  if (match) {\n    batch_result[tid] = 1;\n  }\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 5) {\n    printf(\"Usage: %s <target sequence length> <query sequence length> \"\n           \"<coarse match length> <coarse match threshold>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int kBatchSize = 1024;\n  char seq[] = {'A', 'C', 'T', 'G'};\n  const int tseq_size = atoi(argv[1]);\n  const int qseq_size = atoi(argv[2]);\n  const int coarse_match_length = atoi(argv[3]);\n  const int coarse_match_threshold = atoi(argv[4]);\n  \n  std::vector<char> target_sequence(tseq_size);\n  std::vector<char> query_sequence(qseq_size);\n\n  srand(123);\n  for (int i = 0; i < tseq_size; i++) target_sequence[i] = seq[rand()%4];\n  for (int i = 0; i < qseq_size; i++) query_sequence[i] = seq[rand()%4];\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  char *d_target = sycl::malloc_device<char>(tseq_size, q);\n  char *d_query = sycl::malloc_device<char>(qseq_size, q);\n  char *d_batch_result = sycl::malloc_device<char>(kBatchSize, q);\n\n  q.memcpy(d_target, target_sequence.data(), tseq_size * sizeof(char));\n  q.memcpy(d_query, query_sequence.data(), qseq_size * sizeof(char));\n\n  uint32_t max_searchable_length = tseq_size - coarse_match_length;\n  uint32_t current_position = 0;\n\n  \n\n  char batch_result[kBatchSize];\n  char batch_result_ref[kBatchSize];\n\n  float total_time = 0.f;\n\n  int error = 0;\n  while (current_position < max_searchable_length) {\n    q.memset(d_batch_result, 0, kBatchSize);\n    memset(batch_result_ref, 0, kBatchSize);\n\n    uint32_t end_position = current_position + kBatchSize;\n    if (end_position >= max_searchable_length) {\n      end_position = max_searchable_length;\n    }\n    uint32_t length = end_position - current_position;\n\n    sycl::range<1> lws (256);\n    sycl::range<1> gws ((length + 255) / 256 * 256);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class genetic>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        ga (item, d_target, d_query, d_batch_result,\n            length, qseq_size, coarse_match_length,\n            coarse_match_threshold, current_position);\n      });\n    }).wait();\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n\n    reference(target_sequence.data(), query_sequence.data(), batch_result_ref, length, qseq_size,\n              coarse_match_length, coarse_match_threshold, current_position);\n\n    q.memcpy(batch_result, d_batch_result, kBatchSize * sizeof(char)).wait();\n\n    error = memcmp(batch_result_ref, batch_result, kBatchSize * sizeof(char));\n    if (error) break;\n\n    current_position = end_position;\n  }\n  printf(\"Total kernel execution time %f (s)\\n\", total_time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  sycl::free(d_target, q);\n  sycl::free(d_query, q);\n  sycl::free(d_batch_result, q);\n  return 0;\n}\n"}}
{"kernel_name": "nw", "parallel_api": "cuda", "code": {"nw.cu": "#ifdef RD_WG_SIZE_0_0\n#define BLOCK_SIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n#define BLOCK_SIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n#define BLOCK_SIZE RD_WG_SIZE\n#else\n#define BLOCK_SIZE 16\n#endif\n\n#define LIMIT -999\n\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.cpp\"\n\n\n\n#define SCORE(i, j) input_itemsets_l[j + i * (BLOCK_SIZE+1)]\n#define REF(i, j)   reference_l[j + i * BLOCK_SIZE]\n\n__device__ __host__\nint maximum( int a, int b, int c){\n\n  int k;\n  if( a <= b )\n    k = b;\n  else \n    k = a;\n  if( k <=c )\n    return(c);\n  else\n    return(k);\n}\n\n\n\n\nint blosum62[24][24] = {\n  { 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0, -3, -2,  0, -2, -1,  0, -4},\n  {-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -3, -2, -3, -1,  0, -1, -4},\n  {-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -4, -2, -3,  3,  0, -1, -4},\n  {-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  { 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1, -3, -3, -2, -4},\n  {-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -2, -1, -2,  0,  3, -1, -4},\n  {-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3, -1, -2, -1, -4},\n  {-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3,  0,  0, -1, -4},\n  {-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -3, -1,  3, -3, -3, -1, -4},\n  {-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -2, -1, -2, -1,  1, -4, -3, -1, -4},\n  {-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -3, -2, -2,  0,  1, -1, -4},\n  {-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -1, -1, -1, -1,  1, -3, -1, -1, -4},\n  {-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2,  1,  3, -1, -3, -3, -1, -4},\n  {-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -4, -3, -2, -2, -1, -2, -4},\n  { 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -2,  0, -1, -2, -1,  4,  1, -3, -2, -2,  0,  0,  0, -4},\n  { 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5, -2, -2,  0, -1, -1,  0, -4},\n  {-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3, -4, -3, -2, -4},\n  {-2, -2, -2, -3, -2, -1, -2, -3,  2, -1, -1, -2, -1,  3, -3, -2, -2,  2,  7, -1, -3, -2, -1, -4},\n  { 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1, -1, -2, -2,  0, -3, -1,  4, -3, -2, -1, -4},\n  {-2, -1,  3,  4, -3,  0,  1, -1,  0, -3, -4,  0, -3, -3, -2,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  {-1,  0,  0,  1, -3,  3,  4, -2,  0, -3, -3,  1, -1, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -1, -1, -1, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -2,  0,  0, -2, -1, -1, -1, -1, -1, -4},\n  {-4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4,  1}\n};\n\n\n\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <max_rows/max_cols> <penalty> \\n\", argv[0]);\n  fprintf(stderr, \"\\t<dimension>  - x and y dimensions\\n\");\n  fprintf(stderr, \"\\t<penalty> - penalty(positive integer)\\n\");\n  fprintf(stderr, \"\\t<file> - filename\\n\");\n  exit(1);\n}\n\n__global__ void \nkernel1 (int*__restrict__ d_input_itemsets,\n         const int*__restrict__ d_reference,\n         const int offset_r,\n         const int offset_c,\n         const int max_cols,\n         const int blk,\n         const int penalty)\n{\n  __shared__ int input_itemsets_l [(BLOCK_SIZE + 1) *(BLOCK_SIZE+1)];\n  __shared__ int reference_l [BLOCK_SIZE*BLOCK_SIZE];\n\n  int bx = blockIdx.x;\n  int tx = threadIdx.x;\n  \n  \n\n  int base = offset_r * max_cols + offset_c;\n  \n  int b_index_x = bx;\n  int b_index_y = blk - 1 - bx;\n  \n  int index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\n  int index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n  int index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\n  int index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n  \n  if (tx == 0) SCORE(tx, 0) = d_input_itemsets[index_nw + tx];\n  \n  for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)  {\n    REF(ty, tx) =  d_reference[index + max_cols * ty];\n  }\n  \n  SCORE((tx + 1), 0) = d_input_itemsets[index_w + max_cols * tx];\n  \n  SCORE(0, (tx + 1)) = d_input_itemsets[index_n];\n  \n  __syncthreads();\n\n  for( int m = 0 ; m < BLOCK_SIZE ; m++){\n     if ( tx <= m ){\n        int t_index_x =  tx + 1;\n        int t_index_y =  m - tx + 1;\n  \n        SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n              SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n              SCORE((t_index_y-1), (t_index_x))   - (penalty));\n     }\n     __syncthreads();\n  }\n  \n  for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n  \n     if ( tx <= m){\n        int t_index_x =  tx + BLOCK_SIZE - m ;\n        int t_index_y =  BLOCK_SIZE - tx;\n  \n        SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n              SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n              SCORE((t_index_y-1), (t_index_x))   - (penalty));\n     }\n     __syncthreads();\n  }\n  \n  for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++) {\n     d_input_itemsets[index + max_cols * ty] = SCORE((ty+1), (tx+1));\n  }\n  \n}\n\n__global__ void \nkernel2 (int*__restrict__ d_input_itemsets,\n         const int*__restrict__ d_reference,\n         const int block_width,\n         const int offset_r,\n         const int offset_c,\n         const int max_cols,\n         const int blk,\n         const int penalty)\n{\n   __shared__ int input_itemsets_l [(BLOCK_SIZE + 1) *(BLOCK_SIZE+1)];\n   __shared__ int reference_l [BLOCK_SIZE*BLOCK_SIZE];\n   int bx = blockIdx.x;\n   int tx = threadIdx.x;\n\n   \n\n   int base = offset_r * max_cols + offset_c;\n   int b_index_x = bx + block_width - blk  ;\n   int b_index_y = block_width - bx -1;\n\n   int index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\n   int index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n   int index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\n   int index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n\n   if (tx == 0)\n      SCORE(tx, 0) = d_input_itemsets[index_nw];\n\n   for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n      REF(ty, tx) =  d_reference[index + max_cols * ty];\n\n   SCORE((tx + 1), 0) = d_input_itemsets[index_w + max_cols * tx];\n\n   SCORE(0, (tx + 1)) = d_input_itemsets[index_n];\n\n   __syncthreads();\n\n   for( int m = 0 ; m < BLOCK_SIZE ; m++){\n      if ( tx <= m ){\n\n         int t_index_x =  tx + 1;\n         int t_index_y =  m - tx + 1;\n\n         SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n               SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n               SCORE((t_index_y-1), (t_index_x))   - (penalty));\n      }\n      __syncthreads();\n   }\n\n   for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n\n      if ( tx <= m){\n\n         int t_index_x =  tx + BLOCK_SIZE - m ;\n         int t_index_y =  BLOCK_SIZE - tx;\n\n         SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n               SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n               SCORE((t_index_y-1), (t_index_x))   - (penalty));\n\n      }\n      __syncthreads();\n   }\n\n   for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n      d_input_itemsets[index + ty * max_cols] = SCORE((ty+1), (tx+1));\n}\n\nint main(int argc, char **argv){\n\n  printf(\"WG size of kernel = %d \\n\", BLOCK_SIZE);\n\n  int max_rows_t, max_cols_t, penalty_t;\n  \n\n  \n\n  if (argc == 3)\n  {\n    max_rows_t = atoi(argv[1]);\n    max_cols_t = atoi(argv[1]);\n    penalty_t = atoi(argv[2]);\n  }\n  else{\n    usage(argc, argv);\n  }\n\n  if(atoi(argv[1])%16!=0){\n    fprintf(stderr,\"The dimension values must be a multiple of 16\\n\");\n    exit(1);\n  }\n\n  \n\n  const int max_rows = max_rows_t + 1;\n  const int max_cols = max_cols_t + 1;\n  const int penalty = penalty_t;  \n\n  int *reference;\n  int *input_itemsets;\n  int *output_itemsets;\n\n  reference = (int *)malloc( max_rows * max_cols * sizeof(int) );\n  input_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n  output_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n\n  srand(7);\n\n  \n\n  for (int i = 0 ; i < max_cols; i++){\n    for (int j = 0 ; j < max_rows; j++){\n      input_itemsets[i*max_cols+j] = 0;\n    }\n  }\n\n  for( int i=1; i< max_rows ; i++){    \n\n    input_itemsets[i*max_cols] = rand() % 10 + 1;\n  }\n\n  for( int j=1; j< max_cols ; j++){    \n\n    input_itemsets[j] = rand() % 10 + 1;\n  }\n\n  for (int i = 1 ; i < max_cols; i++){\n    for (int j = 1 ; j < max_rows; j++){\n      reference[i*max_cols+j] = blosum62[input_itemsets[i*max_cols]][input_itemsets[j]];\n    }\n  }\n\n  for( int i = 1; i< max_rows ; i++)\n    input_itemsets[i*max_cols] = -i * penalty;\n  for( int j = 1; j< max_cols ; j++)\n    input_itemsets[j] = -j * penalty;\n\n  int workgroupsize = BLOCK_SIZE;\n#ifdef DEBUG\n  if(workgroupsize < 0){\n     printf(\"ERROR: invalid or missing <num_work_items>[/<work_group_size>]\\n\"); \n     return -1;\n  }\n#endif\n  \n\n  const size_t local_work = (size_t)workgroupsize;\n  size_t global_work;\n\n  const int worksize = max_cols - 1;\n#ifdef DEBUG\n  printf(\"worksize = %d\\n\", worksize);\n#endif\n  \n\n  const int offset_r = 0;\n  const int offset_c = 0;\n  const int block_width = worksize/BLOCK_SIZE ;\n  printf(\"block width = %d\\n\", block_width);\n\n  int *d_input_itemsets; \n  int *d_reference; \n  cudaMalloc((void**)&d_input_itemsets, max_cols * max_rows * sizeof(int));\n  cudaMalloc((void**)&d_reference, max_cols * max_rows * sizeof(int));\n\n  cudaMemcpy(d_input_itemsets, input_itemsets, max_cols * max_rows * sizeof(int), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_reference, reference, max_cols * max_rows * sizeof(int), cudaMemcpyHostToDevice);\n\n  \n\n  for( int blk = 1 ; blk <= block_width ; blk++){\n    global_work = blk;\n    kernel1<<<global_work, local_work>>>(d_input_itemsets, d_reference, offset_r, offset_c, max_cols, blk, penalty);\n  }\n  for( int blk = block_width - 1 ; blk >= 1 ; blk--){      \n    global_work = blk;\n    kernel2<<<global_work, local_work>>>(d_input_itemsets, d_reference, block_width, offset_r, offset_c, max_cols, blk, penalty);\n  }\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n#ifdef DEBUG\n  printf(\"Processing upper-left matrix\\n\");\n#endif\n  for( int blk = 1 ; blk <= block_width ; blk++){\n    global_work = blk;\n    kernel1<<<global_work, local_work>>>(d_input_itemsets, d_reference, offset_r, offset_c, max_cols, blk, penalty);\n  }\n\n#ifdef DEBUG\n  printf(\"Processing lower-right matrix\\n\");\n#endif\n  for( int blk = block_width - 1 ; blk >= 1 ; blk--){      \n    global_work = blk;\n    kernel2<<<global_work, local_work>>>(d_input_itemsets, d_reference, block_width, offset_r, offset_c, max_cols, blk, penalty);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  cudaMemcpy(output_itemsets, d_input_itemsets, max_cols * max_rows * sizeof(int), cudaMemcpyDeviceToHost);\n\n  \n\n  nw_host(input_itemsets, reference, max_cols, penalty);\n  int err = memcmp(input_itemsets, output_itemsets, max_cols * max_rows * sizeof(int));\n  printf(\"%s\\n\", err ? \"FAIL\" : \"PASS\");\n\n#ifdef TRACEBACK\n\n  FILE *fpo = fopen(\"result.txt\",\"w\");\n  fprintf(fpo, \"print traceback value:\\n\");\n\n  for (int i = max_rows - 2,  j = max_rows - 2; i>=0, j>=0;){\n    int nw, n, w, traceback;\n    if ( i == max_rows - 2 && j == max_rows - 2 )\n      fprintf(fpo, \"%d \", output_itemsets[ i * max_cols + j]); \n\n    if ( i == 0 && j == 0 )\n      break;\n    if ( i > 0 && j > 0 ){\n      nw = output_itemsets[(i - 1) * max_cols + j - 1];\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else if ( i == 0 ){\n      nw = n = LIMIT;\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n    }\n    else if ( j == 0 ){\n      nw = w = LIMIT;\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else{\n    }\n\n    int new_nw, new_w, new_n;\n    new_nw = nw + reference[i * max_cols + j];\n    new_w = w - penalty;\n    new_n = n - penalty;\n\n    traceback = maximum(new_nw, new_w, new_n);\n    if(traceback == new_nw)\n      traceback = nw;\n    if(traceback == new_w)\n      traceback = w;\n    if(traceback == new_n)\n      traceback = n;\n\n    fprintf(fpo, \"%d \", traceback);\n\n    if(traceback == nw )\n    {i--; j--; continue;}\n\n    else if(traceback == w )\n    {j--; continue;}\n\n    else if(traceback == n )\n    {i--; continue;}\n\n    else\n      ;\n  }\n\n  fclose(fpo);\n\n#endif\n\n  \n\n\n  free(reference);\n  free(input_itemsets);\n  free(output_itemsets);\n  cudaFree(d_input_itemsets);\n  cudaFree(d_reference);\n  return 0;\n}\n\n"}}
{"kernel_name": "nw", "parallel_api": "hip", "code": {"nw.cu": "#ifdef RD_WG_SIZE_0_0\n#define BLOCK_SIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n#define BLOCK_SIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n#define BLOCK_SIZE RD_WG_SIZE\n#else\n#define BLOCK_SIZE 16\n#endif\n\n#define LIMIT -999\n\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.cpp\"\n\n\n\n#define SCORE(i, j) input_itemsets_l[j + i * (BLOCK_SIZE+1)]\n#define REF(i, j)   reference_l[j + i * BLOCK_SIZE]\n\n__device__ __host__\nint maximum( int a, int b, int c){\n\n  int k;\n  if( a <= b )\n    k = b;\n  else \n    k = a;\n  if( k <=c )\n    return(c);\n  else\n    return(k);\n}\n\n\n\n\nint blosum62[24][24] = {\n  { 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0, -3, -2,  0, -2, -1,  0, -4},\n  {-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -3, -2, -3, -1,  0, -1, -4},\n  {-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -4, -2, -3,  3,  0, -1, -4},\n  {-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  { 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1, -3, -3, -2, -4},\n  {-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -2, -1, -2,  0,  3, -1, -4},\n  {-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3, -1, -2, -1, -4},\n  {-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3,  0,  0, -1, -4},\n  {-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -3, -1,  3, -3, -3, -1, -4},\n  {-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -2, -1, -2, -1,  1, -4, -3, -1, -4},\n  {-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -3, -2, -2,  0,  1, -1, -4},\n  {-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -1, -1, -1, -1,  1, -3, -1, -1, -4},\n  {-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2,  1,  3, -1, -3, -3, -1, -4},\n  {-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -4, -3, -2, -2, -1, -2, -4},\n  { 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -2,  0, -1, -2, -1,  4,  1, -3, -2, -2,  0,  0,  0, -4},\n  { 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5, -2, -2,  0, -1, -1,  0, -4},\n  {-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3, -4, -3, -2, -4},\n  {-2, -2, -2, -3, -2, -1, -2, -3,  2, -1, -1, -2, -1,  3, -3, -2, -2,  2,  7, -1, -3, -2, -1, -4},\n  { 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1, -1, -2, -2,  0, -3, -1,  4, -3, -2, -1, -4},\n  {-2, -1,  3,  4, -3,  0,  1, -1,  0, -3, -4,  0, -3, -3, -2,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  {-1,  0,  0,  1, -3,  3,  4, -2,  0, -3, -3,  1, -1, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -1, -1, -1, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -2,  0,  0, -2, -1, -1, -1, -1, -1, -4},\n  {-4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4,  1}\n};\n\n\n\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <max_rows/max_cols> <penalty> \\n\", argv[0]);\n  fprintf(stderr, \"\\t<dimension>  - x and y dimensions\\n\");\n  fprintf(stderr, \"\\t<penalty> - penalty(positive integer)\\n\");\n  fprintf(stderr, \"\\t<file> - filename\\n\");\n  exit(1);\n}\n\n__global__ void \nkernel1 (int*__restrict__ d_input_itemsets,\n         const int*__restrict__ d_reference,\n         const int offset_r,\n         const int offset_c,\n         const int max_cols,\n         const int blk,\n         const int penalty)\n{\n  __shared__ int input_itemsets_l [(BLOCK_SIZE + 1) *(BLOCK_SIZE+1)];\n  __shared__ int reference_l [BLOCK_SIZE*BLOCK_SIZE];\n\n  int bx = blockIdx.x;\n  int tx = threadIdx.x;\n  \n  \n\n  int base = offset_r * max_cols + offset_c;\n  \n  int b_index_x = bx;\n  int b_index_y = blk - 1 - bx;\n  \n  int index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\n  int index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n  int index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\n  int index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n  \n  if (tx == 0) SCORE(tx, 0) = d_input_itemsets[index_nw + tx];\n  \n  for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)  {\n    REF(ty, tx) =  d_reference[index + max_cols * ty];\n  }\n  \n  SCORE((tx + 1), 0) = d_input_itemsets[index_w + max_cols * tx];\n  \n  SCORE(0, (tx + 1)) = d_input_itemsets[index_n];\n  \n  __syncthreads();\n\n  for( int m = 0 ; m < BLOCK_SIZE ; m++){\n     if ( tx <= m ){\n        int t_index_x =  tx + 1;\n        int t_index_y =  m - tx + 1;\n  \n        SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n              SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n              SCORE((t_index_y-1), (t_index_x))   - (penalty));\n     }\n     __syncthreads();\n  }\n  \n  for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n     if ( tx <= m){\n        int t_index_x =  tx + BLOCK_SIZE - m ;\n        int t_index_y =  BLOCK_SIZE - tx;\n  \n        SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n              SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n              SCORE((t_index_y-1), (t_index_x))   - (penalty));\n     }\n     __syncthreads();\n  }\n  \n  for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++) {\n     d_input_itemsets[index + max_cols * ty] = SCORE((ty+1), (tx+1));\n  }\n}\n\n__global__ void \nkernel2 (int*__restrict__ d_input_itemsets,\n         const int*__restrict__ d_reference,\n         const int block_width,\n         const int offset_r,\n         const int offset_c,\n         const int max_cols,\n         const int blk,\n         const int penalty)\n{\n   __shared__ int input_itemsets_l [(BLOCK_SIZE + 1) *(BLOCK_SIZE+1)];\n   __shared__ int reference_l [BLOCK_SIZE*BLOCK_SIZE];\n   int bx = blockIdx.x;\n   int tx = threadIdx.x;\n\n   \n\n   int base = offset_r * max_cols + offset_c;\n   int b_index_x = bx + block_width - blk  ;\n   int b_index_y = block_width - bx -1;\n\n   int index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\n   int index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n   int index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\n   int index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n\n   if (tx == 0)\n      SCORE(tx, 0) = d_input_itemsets[index_nw];\n\n   for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n      REF(ty, tx) =  d_reference[index + max_cols * ty];\n\n   SCORE((tx + 1), 0) = d_input_itemsets[index_w + max_cols * tx];\n\n   SCORE(0, (tx + 1)) = d_input_itemsets[index_n];\n\n   __syncthreads();\n\n   for( int m = 0 ; m < BLOCK_SIZE ; m++){\n\n      if ( tx <= m ){\n\n         int t_index_x =  tx + 1;\n         int t_index_y =  m - tx + 1;\n\n         SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n               SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n               SCORE((t_index_y-1), (t_index_x))   - (penalty));\n      }\n      __syncthreads();\n   }\n\n   for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n      if ( tx <= m){\n         int t_index_x =  tx + BLOCK_SIZE - m ;\n         int t_index_y =  BLOCK_SIZE - tx;\n\n         SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n               SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n               SCORE((t_index_y-1), (t_index_x))   - (penalty));\n\n      }\n      __syncthreads();\n   }\n\n   for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n      d_input_itemsets[index + ty * max_cols] = SCORE((ty+1), (tx+1));\n}\n\nint main(int argc, char **argv){\n\n  printf(\"WG size of kernel = %d \\n\", BLOCK_SIZE);\n\n  int max_rows_t, max_cols_t, penalty_t;\n  \n\n  \n\n  if (argc == 3)\n  {\n    max_rows_t = atoi(argv[1]);\n    max_cols_t = atoi(argv[1]);\n    penalty_t = atoi(argv[2]);\n  }\n  else{\n    usage(argc, argv);\n  }\n\n  if(atoi(argv[1])%16!=0){\n    fprintf(stderr,\"The dimension values must be a multiple of 16\\n\");\n    exit(1);\n  }\n\n  \n\n  const int max_rows = max_rows_t + 1;\n  const int max_cols = max_cols_t + 1;\n  const int penalty = penalty_t;  \n\n  int *reference;\n  int *input_itemsets;\n  int *output_itemsets;\n\n  reference = (int *)malloc( max_rows * max_cols * sizeof(int) );\n  input_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n  output_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n\n  srand(7);\n\n  \n\n  for (int i = 0 ; i < max_cols; i++){\n    for (int j = 0 ; j < max_rows; j++){\n      input_itemsets[i*max_cols+j] = 0;\n    }\n  }\n\n  for( int i=1; i< max_rows ; i++){    \n\n    input_itemsets[i*max_cols] = rand() % 10 + 1;\n  }\n\n  for( int j=1; j< max_cols ; j++){    \n\n    input_itemsets[j] = rand() % 10 + 1;\n  }\n\n  for (int i = 1 ; i < max_cols; i++){\n    for (int j = 1 ; j < max_rows; j++){\n      reference[i*max_cols+j] = blosum62[input_itemsets[i*max_cols]][input_itemsets[j]];\n    }\n  }\n\n  for( int i = 1; i< max_rows ; i++)\n    input_itemsets[i*max_cols] = -i * penalty;\n  for( int j = 1; j< max_cols ; j++)\n    input_itemsets[j] = -j * penalty;\n\n  int workgroupsize = BLOCK_SIZE;\n#ifdef DEBUG\n  if(workgroupsize < 0){\n     printf(\"ERROR: invalid or missing <num_work_items>[/<work_group_size>]\\n\"); \n     return -1;\n  }\n#endif\n  \n\n  const size_t local_work = (size_t)workgroupsize;\n  size_t global_work;\n\n  const int worksize = max_cols - 1;\n#ifdef DEBUG\n  printf(\"worksize = %d\\n\", worksize);\n#endif\n  \n\n  const int offset_r = 0;\n  const int offset_c = 0;\n  const int block_width = worksize/BLOCK_SIZE ;\n\n  int *d_input_itemsets; \n  int *d_reference; \n  hipMalloc((void**)&d_input_itemsets, max_cols * max_rows * sizeof(int));\n  hipMalloc((void**)&d_reference, max_cols * max_rows * sizeof(int));\n\n  hipMemcpy(d_input_itemsets, input_itemsets, max_cols * max_rows * sizeof(int), hipMemcpyHostToDevice);\n  hipMemcpy(d_reference, reference, max_cols * max_rows * sizeof(int), hipMemcpyHostToDevice);\n\n  \n\n  for( int blk = 1 ; blk <= block_width ; blk++){\n    global_work = blk;\n    hipLaunchKernelGGL(kernel1, global_work, local_work, 0, 0,\n                       d_input_itemsets, d_reference, offset_r, offset_c, max_cols, blk, penalty);\n  }\n  for( int blk = block_width - 1 ; blk >= 1 ; blk--){      \n    global_work = blk;\n    hipLaunchKernelGGL(kernel2, global_work, local_work, 0, 0,\n                       d_input_itemsets, d_reference, block_width, offset_r, offset_c, max_cols, blk, penalty);\n  }\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n#ifdef DEBUG\n  printf(\"Processing upper-left matrix\\n\");\n#endif\n  for( int blk = 1 ; blk <= block_width ; blk++){\n    global_work = blk;\n    hipLaunchKernelGGL(kernel1, global_work, local_work, 0, 0,\n                       d_input_itemsets, d_reference, offset_r, offset_c, max_cols, blk, penalty);\n  }\n\n#ifdef DEBUG\n  printf(\"Processing lower-right matrix\\n\");\n#endif\n  for( int blk = block_width - 1 ; blk >= 1 ; blk--){      \n    global_work = blk;\n    hipLaunchKernelGGL(kernel2, global_work, local_work, 0, 0,\n                       d_input_itemsets, d_reference, block_width, offset_r, offset_c, max_cols, blk, penalty);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  hipMemcpy(output_itemsets, d_input_itemsets, max_cols * max_rows * sizeof(int), hipMemcpyDeviceToHost);\n\n  \n\n  nw_host(input_itemsets, reference, max_cols, penalty);\n  int err = memcmp(input_itemsets, output_itemsets, max_cols * max_rows * sizeof(int));\n  printf(\"%s\\n\", err ? \"FAIL\" : \"PASS\");\n\n#ifdef TRACEBACK\n\n  FILE *fpo = fopen(\"result.txt\",\"w\");\n  fprintf(fpo, \"print traceback value:\\n\");\n\n  for (int i = max_rows - 2,  j = max_rows - 2; i>=0, j>=0;){\n    int nw, n, w, traceback;\n    if ( i == max_rows - 2 && j == max_rows - 2 )\n      fprintf(fpo, \"%d \", output_itemsets[ i * max_cols + j]); \n\n    if ( i == 0 && j == 0 )\n      break;\n    if ( i > 0 && j > 0 ){\n      nw = output_itemsets[(i - 1) * max_cols + j - 1];\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else if ( i == 0 ){\n      nw = n = LIMIT;\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n    }\n    else if ( j == 0 ){\n      nw = w = LIMIT;\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else{\n    }\n\n    int new_nw, new_w, new_n;\n    new_nw = nw + reference[i * max_cols + j];\n    new_w = w - penalty;\n    new_n = n - penalty;\n\n    traceback = maximum(new_nw, new_w, new_n);\n    if(traceback == new_nw)\n      traceback = nw;\n    if(traceback == new_w)\n      traceback = w;\n    if(traceback == new_n)\n      traceback = n;\n\n    fprintf(fpo, \"%d \", traceback);\n\n    if(traceback == nw )\n    {i--; j--; continue;}\n\n    else if(traceback == w )\n    {j--; continue;}\n\n    else if(traceback == n )\n    {i--; continue;}\n\n    else\n      ;\n  }\n\n  fclose(fpo);\n\n#endif\n\n  \n\n\n  free(reference);\n  free(input_itemsets);\n  free(output_itemsets);\n  hipFree(d_input_itemsets);\n  hipFree(d_reference);\n  return 0;\n}\n\n"}}
{"kernel_name": "nw", "parallel_api": "omp", "code": {"nw.cpp": "#ifdef RWG_SIZE_0_0\n#define BLOCK_SIZE RWG_SIZE_0_0\n#elif defined(RWG_SIZE_0)\n#define BLOCK_SIZE RWG_SIZE_0\n#elif defined(RWG_SIZE)\n#define BLOCK_SIZE RWG_SIZE\n#else\n#define BLOCK_SIZE 16\n#endif\n\n#define LIMIT -999\n\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.cpp\"\n\n\n\n#define SCORE(i, j) input_itemsets_l[j + i * (BLOCK_SIZE+1)]\n#define REF(i, j)   reference_l[j + i * BLOCK_SIZE]\n\nint maximum( int a, int b, int c){\n\n  int k;\n  if( a <= b )\n    k = b;\n  else \n    k = a;\n  if( k <=c )\n    return(c);\n  else\n    return(k);\n}\n\n\n\n\nint blosum62[24][24] = {\n  { 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0, -3, -2,  0, -2, -1,  0, -4},\n  {-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -3, -2, -3, -1,  0, -1, -4},\n  {-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -4, -2, -3,  3,  0, -1, -4},\n  {-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  { 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1, -3, -3, -2, -4},\n  {-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -2, -1, -2,  0,  3, -1, -4},\n  {-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3, -1, -2, -1, -4},\n  {-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3,  0,  0, -1, -4},\n  {-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -3, -1,  3, -3, -3, -1, -4},\n  {-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -2, -1, -2, -1,  1, -4, -3, -1, -4},\n  {-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -3, -2, -2,  0,  1, -1, -4},\n  {-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -1, -1, -1, -1,  1, -3, -1, -1, -4},\n  {-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2,  1,  3, -1, -3, -3, -1, -4},\n  {-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -4, -3, -2, -2, -1, -2, -4},\n  { 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -2,  0, -1, -2, -1,  4,  1, -3, -2, -2,  0,  0,  0, -4},\n  { 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5, -2, -2,  0, -1, -1,  0, -4},\n  {-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3, -4, -3, -2, -4},\n  {-2, -2, -2, -3, -2, -1, -2, -3,  2, -1, -1, -2, -1,  3, -3, -2, -2,  2,  7, -1, -3, -2, -1, -4},\n  { 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1, -1, -2, -2,  0, -3, -1,  4, -3, -2, -1, -4},\n  {-2, -1,  3,  4, -3,  0,  1, -1,  0, -3, -4,  0, -3, -3, -2,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  {-1,  0,  0,  1, -3,  3,  4, -2,  0, -3, -3,  1, -1, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -1, -1, -1, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -2,  0,  0, -2, -1, -1, -1, -1, -1, -4},\n  {-4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4,  1}\n};\n\n\n\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <max_rows/max_cols> <penalty> \\n\", argv[0]);\n  fprintf(stderr, \"\\t<dimension>  - x and y dimensions\\n\");\n  fprintf(stderr, \"\\t<penalty> - penalty(positive integer)\\n\");\n  fprintf(stderr, \"\\t<file> - filename\\n\");\n  exit(1);\n}\n\nint main(int argc, char **argv){\n\n  printf(\"WG size of kernel = %d \\n\", BLOCK_SIZE);\n\n  int max_rows_t, max_cols_t, penalty_t;\n  \n\n  \n\n  if (argc == 3)\n  {\n    max_rows_t = atoi(argv[1]);\n    max_cols_t = atoi(argv[1]);\n    penalty_t = atoi(argv[2]);\n  }\n  else{\n    usage(argc, argv);\n  }\n\n  if(atoi(argv[1])%16!=0){\n    fprintf(stderr,\"The dimension values must be a multiple of 16\\n\");\n    exit(1);\n  }\n\n  \n\n  const int max_rows = max_rows_t + 1;\n  const int max_cols = max_cols_t + 1;\n  const int penalty = penalty_t;  \n\n  int *reference = (int *)malloc( max_rows * max_cols * sizeof(int) );\n  \n\n  int *h_input_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n  int *input_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n\n  srand(7);\n\n  \n\n  for (int i = 0 ; i < max_cols; i++){\n    for (int j = 0 ; j < max_rows; j++){\n      input_itemsets[i*max_cols+j] = 0;\n      h_input_itemsets[i*max_cols+j] = 0;\n    }\n  }\n\n  for( int i=1; i< max_rows ; i++){    \n\n    h_input_itemsets[i*max_cols] = input_itemsets[i*max_cols] = rand() % 10 + 1;\n  }\n\n  for( int j=1; j< max_cols ; j++){    \n\n    h_input_itemsets[j] = input_itemsets[j] = rand() % 10 + 1;\n  }\n\n  for (int i = 1 ; i < max_cols; i++){\n    for (int j = 1 ; j < max_rows; j++){\n      reference[i*max_cols+j] = blosum62[input_itemsets[i*max_cols]][input_itemsets[j]];\n    }\n  }\n\n  for( int i = 1; i< max_rows ; i++)\n    h_input_itemsets[i*max_cols] = input_itemsets[i*max_cols] = -i * penalty;\n  for( int j = 1; j< max_cols ; j++)\n    h_input_itemsets[j] = input_itemsets[j] = -j * penalty;\n\n  int workgroupsize = BLOCK_SIZE;\n#ifdef DEBUG\n  if(workgroupsize < 0){\n     printf(\"ERROR: invalid or missing <num_work_items>[/<work_group_size>]\\n\"); \n     return -1;\n  }\n#endif\n  \n\n  const size_t local_work = (size_t)workgroupsize;\n  size_t global_work;\n\n  const int worksize = max_cols - 1;\n#ifdef DEBUG\n  printf(\"worksize = %d\\n\", worksize);\n#endif\n  \n\n  const int offset_r = 0;\n  const int offset_c = 0;\n  const int block_width = worksize/BLOCK_SIZE ;\n\n  #pragma omp target data map(tofrom: input_itemsets[0:max_cols * max_rows]) \\\n                          map(to: reference[0:max_cols * max_rows])\n  {\n  #ifdef DEBUG\n    printf(\"Processing upper-left matrix\\n\");\n  #endif\n    \n    auto start = std::chrono::steady_clock::now();\n  \n    for(int blk = 1 ; blk <= block_width ; blk++){\n      global_work = blk;\n      #pragma omp target teams num_teams(global_work) thread_limit(local_work)\n      {\n        int input_itemsets_l [(BLOCK_SIZE + 1) *(BLOCK_SIZE+1)];\n        int reference_l [BLOCK_SIZE*BLOCK_SIZE];\n        #pragma omp parallel\n        {\n          int bx = omp_get_team_num(); \n          int tx = omp_get_thread_num();\n          \n          \n\n          int base = offset_r * max_cols + offset_c;\n          \n          int b_index_x = bx;\n          int b_index_y = blk - 1 - bx;\n          \n          int index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\n          int index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n          int index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\n          int index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n          \n          if (tx == 0) SCORE(tx, 0) = input_itemsets[index_nw + tx];\n          \n          for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)  {\n            REF(ty, tx) =  reference[index + max_cols * ty];\n          }\n          \n          SCORE((tx + 1), 0) = input_itemsets[index_w + max_cols * tx];\n          \n          SCORE(0, (tx + 1)) = input_itemsets[index_n];\n          \n          #pragma omp barrier\n      \n          for( int m = 0 ; m < BLOCK_SIZE ; m++){\n             if ( tx <= m ){\n                int t_index_x =  tx + 1;\n                int t_index_y =  m - tx + 1;\n          \n                SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n                      SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n                      SCORE((t_index_y-1), (t_index_x))   - (penalty));\n             }\n             #pragma omp barrier\n          }\n          \n          for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n             if ( tx <= m){\n                int t_index_x =  tx + BLOCK_SIZE - m ;\n                int t_index_y =  BLOCK_SIZE - tx;\n          \n                SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n                      SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n                      SCORE((t_index_y-1), (t_index_x))   - (penalty));\n             }\n             #pragma omp barrier\n          }\n          \n          for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++) {\n             input_itemsets[index + max_cols * ty] = SCORE((ty+1), (tx+1));\n          }\n        }\n      }\n    }\n  \n  #ifdef DEBUG\n    printf(\"Processing lower-right matrix\\n\");\n  #endif\n  \n    for( int blk = block_width - 1 ; blk >= 1 ; blk--){      \n      global_work = blk;\n      #pragma omp target teams num_teams(global_work) thread_limit(local_work)\n      {\n        int input_itemsets_l [(BLOCK_SIZE + 1) *(BLOCK_SIZE+1)];\n        int reference_l [BLOCK_SIZE*BLOCK_SIZE];\n        #pragma omp parallel\n        {\n          int bx = omp_get_team_num(); \n          int tx = omp_get_thread_num();\n  \n         \n\n         int base = offset_r * max_cols + offset_c;\n  \n         int b_index_x = bx + block_width - blk  ;\n         int b_index_y = block_width - bx -1;\n  \n  \n         int index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\n         int index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n         int index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\n         int index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n  \n         if (tx == 0)\n            SCORE(tx, 0) = input_itemsets[index_nw];\n  \n         for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n            REF(ty, tx) =  reference[index + max_cols * ty];\n  \n         SCORE((tx + 1), 0) = input_itemsets[index_w + max_cols * tx];\n  \n         SCORE(0, (tx + 1)) = input_itemsets[index_n];\n  \n         #pragma omp barrier\n  \n         for( int m = 0 ; m < BLOCK_SIZE ; m++){\n            if ( tx <= m ){\n  \n               int t_index_x =  tx + 1;\n               int t_index_y =  m - tx + 1;\n  \n               SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n                     SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n                     SCORE((t_index_y-1), (t_index_x))   - (penalty));\n            }\n            #pragma omp barrier\n         }\n  \n         for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n            if ( tx <= m){\n               int t_index_x =  tx + BLOCK_SIZE - m ;\n               int t_index_y =  BLOCK_SIZE - tx;\n  \n               SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n                     SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n                     SCORE((t_index_y-1), (t_index_x))   - (penalty));\n            }\n            #pragma omp barrier\n         }\n  \n         for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n            input_itemsets[index + ty * max_cols] = SCORE((ty+1), (tx+1));\n        }\n      }\n    }\n  \n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  }\n\n  \n\n  nw_host(h_input_itemsets, reference, max_cols, penalty);\n  int err = memcmp(input_itemsets, h_input_itemsets, max_cols * max_rows * sizeof(int));\n  printf(\"%s\\n\", err ? \"FAIL\" : \"PASS\");\n\n#ifdef TRACEBACK\n  int *output_itemsets = input_itemsets;\n\n  FILE *fpo = fopen(\"result.txt\",\"w\");\n  fprintf(fpo, \"print traceback value:\\n\");\n\n  for (int i = max_rows - 2,  j = max_rows - 2; i>=0, j>=0;){\n    int nw, n, w, traceback;\n    if ( i == max_rows - 2 && j == max_rows - 2 )\n      fprintf(fpo, \"%d \", output_itemsets[ i * max_cols + j]); \n\n    if ( i == 0 && j == 0 )\n      break;\n    if ( i > 0 && j > 0 ){\n      nw = output_itemsets[(i - 1) * max_cols + j - 1];\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else if ( i == 0 ){\n      nw = n = LIMIT;\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n    }\n    else if ( j == 0 ){\n      nw = w = LIMIT;\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else{\n    }\n\n    \n\n    int new_nw, new_w, new_n;\n    new_nw = nw + reference[i * max_cols + j];\n    new_w = w - penalty;\n    new_n = n - penalty;\n\n    traceback = maximum(new_nw, new_w, new_n);\n    if(traceback == new_nw)\n      traceback = nw;\n    if(traceback == new_w)\n      traceback = w;\n    if(traceback == new_n)\n      traceback = n;\n\n    fprintf(fpo, \"%d \", traceback);\n\n    if(traceback == nw )\n    {i--; j--; continue;}\n\n    else if(traceback == w )\n    {j--; continue;}\n\n    else if(traceback == n )\n    {i--; continue;}\n\n    else\n      ;\n  }\n\n  fclose(fpo);\n\n#endif\n\n  \n\n\n  free(reference);\n  free(input_itemsets);\n  free(h_input_itemsets);\n  return 0;\n}\n\n"}}
{"kernel_name": "nw", "parallel_api": "serial", "code": {"nw.cpp": "#ifdef RWG_SIZE_0_0\n#define BLOCK_SIZE RWG_SIZE_0_0\n#elif defined(RWG_SIZE_0)\n#define BLOCK_SIZE RWG_SIZE_0\n#elif defined(RWG_SIZE)\n#define BLOCK_SIZE RWG_SIZE\n#else\n#define BLOCK_SIZE 16\n#endif\n\n#define LIMIT -999\n\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <chrono>\n#include \"reference.cpp\"\n\n\n\n#define SCORE(i, j) input_itemsets_l[j + i * (BLOCK_SIZE+1)]\n#define REF(i, j)   reference_l[j + i * BLOCK_SIZE]\n\nint maximum( int a, int b, int c){\n\n  int k;\n  if( a <= b )\n    k = b;\n  else \n    k = a;\n  if( k <=c )\n    return(c);\n  else\n    return(k);\n}\n\n\n\n\nint blosum62[24][24] = {\n  { 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0, -3, -2,  0, -2, -1,  0, -4},\n  {-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -3, -2, -3, -1,  0, -1, -4},\n  {-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -4, -2, -3,  3,  0, -1, -4},\n  {-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  { 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1, -3, -3, -2, -4},\n  {-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -2, -1, -2,  0,  3, -1, -4},\n  {-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3, -1, -2, -1, -4},\n  {-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3,  0,  0, -1, -4},\n  {-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -3, -1,  3, -3, -3, -1, -4},\n  {-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -2, -1, -2, -1,  1, -4, -3, -1, -4},\n  {-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -3, -2, -2,  0,  1, -1, -4},\n  {-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -1, -1, -1, -1,  1, -3, -1, -1, -4},\n  {-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2,  1,  3, -1, -3, -3, -1, -4},\n  {-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -4, -3, -2, -2, -1, -2, -4},\n  { 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -2,  0, -1, -2, -1,  4,  1, -3, -2, -2,  0,  0,  0, -4},\n  { 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5, -2, -2,  0, -1, -1,  0, -4},\n  {-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3, -4, -3, -2, -4},\n  {-2, -2, -2, -3, -2, -1, -2, -3,  2, -1, -1, -2, -1,  3, -3, -2, -2,  2,  7, -1, -3, -2, -1, -4},\n  { 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1, -1, -2, -2,  0, -3, -1,  4, -3, -2, -1, -4},\n  {-2, -1,  3,  4, -3,  0,  1, -1,  0, -3, -4,  0, -3, -3, -2,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  {-1,  0,  0,  1, -3,  3,  4, -2,  0, -3, -3,  1, -1, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -1, -1, -1, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -2,  0,  0, -2, -1, -1, -1, -1, -1, -4},\n  {-4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4,  1}\n};\n\n\n\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <max_rows/max_cols> <penalty> \\n\", argv[0]);\n  fprintf(stderr, \"\\t<dimension>  - x and y dimensions\\n\");\n  fprintf(stderr, \"\\t<penalty> - penalty(positive integer)\\n\");\n  fprintf(stderr, \"\\t<file> - filename\\n\");\n  exit(1);\n}\n\nint main(int argc, char **argv){\n\n  printf(\"WG size of kernel = %d \\n\", BLOCK_SIZE);\n\n  int max_rows_t, max_cols_t, penalty_t;\n  \n\n  \n\n  if (argc == 3)\n  {\n    max_rows_t = atoi(argv[1]);\n    max_cols_t = atoi(argv[1]);\n    penalty_t = atoi(argv[2]);\n  }\n  else{\n    usage(argc, argv);\n  }\n\n  if(atoi(argv[1])%16!=0){\n    fprintf(stderr,\"The dimension values must be a multiple of 16\\n\");\n    exit(1);\n  }\n\n  \n\n  const int max_rows = max_rows_t + 1;\n  const int max_cols = max_cols_t + 1;\n  const int penalty = penalty_t;  \n\n  int *reference = (int *)malloc( max_rows * max_cols * sizeof(int) );\n  \n\n  int *h_input_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n  int *input_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n\n  srand(7);\n\n  \n\n  for (int i = 0 ; i < max_cols; i++){\n    for (int j = 0 ; j < max_rows; j++){\n      input_itemsets[i*max_cols+j] = 0;\n      h_input_itemsets[i*max_cols+j] = 0;\n    }\n  }\n\n  for( int i=1; i< max_rows ; i++){    \n\n    h_input_itemsets[i*max_cols] = input_itemsets[i*max_cols] = rand() % 10 + 1;\n  }\n\n  for( int j=1; j< max_cols ; j++){    \n\n    h_input_itemsets[j] = input_itemsets[j] = rand() % 10 + 1;\n  }\n\n  for (int i = 1 ; i < max_cols; i++){\n    for (int j = 1 ; j < max_rows; j++){\n      reference[i*max_cols+j] = blosum62[input_itemsets[i*max_cols]][input_itemsets[j]];\n    }\n  }\n\n  for( int i = 1; i< max_rows ; i++)\n    h_input_itemsets[i*max_cols] = input_itemsets[i*max_cols] = -i * penalty;\n  for( int j = 1; j< max_cols ; j++)\n    h_input_itemsets[j] = input_itemsets[j] = -j * penalty;\n\n  int workgroupsize = BLOCK_SIZE;\n#ifdef DEBUG\n  if(workgroupsize < 0){\n     printf(\"ERROR: invalid or missing <num_work_items>[/<work_group_size>]\\n\"); \n     return -1;\n  }\n#endif\n  \n\n  const size_t local_work = (size_t)workgroupsize;\n  size_t global_work;\n\n  const int worksize = max_cols - 1;\n#ifdef DEBUG\n  printf(\"worksize = %d\\n\", worksize);\n#endif\n  \n\n  const int offset_r = 0;\n  const int offset_c = 0;\n  const int block_width = worksize/BLOCK_SIZE ;\n\n    {\n  #ifdef DEBUG\n    printf(\"Processing upper-left matrix\\n\");\n  #endif\n    \n    auto start = std::chrono::steady_clock::now();\n  \n    for(int blk = 1 ; blk <= block_width ; blk++){\n      global_work = blk;\n            {\n        int input_itemsets_l [(BLOCK_SIZE + 1) *(BLOCK_SIZE+1)];\n        int reference_l [BLOCK_SIZE*BLOCK_SIZE];\n                {\n          int bx = omp_get_team_num(); \n          int tx = omp_get_thread_num();\n          \n          \n\n          int base = offset_r * max_cols + offset_c;\n          \n          int b_index_x = bx;\n          int b_index_y = blk - 1 - bx;\n          \n          int index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\n          int index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n          int index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\n          int index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n          \n          if (tx == 0) SCORE(tx, 0) = input_itemsets[index_nw + tx];\n          \n          for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)  {\n            REF(ty, tx) =  reference[index + max_cols * ty];\n          }\n          \n          SCORE((tx + 1), 0) = input_itemsets[index_w + max_cols * tx];\n          \n          SCORE(0, (tx + 1)) = input_itemsets[index_n];\n          \n                \n          for( int m = 0 ; m < BLOCK_SIZE ; m++){\n             if ( tx <= m ){\n                int t_index_x =  tx + 1;\n                int t_index_y =  m - tx + 1;\n          \n                SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n                      SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n                      SCORE((t_index_y-1), (t_index_x))   - (penalty));\n             }\n                       }\n          \n          for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n             if ( tx <= m){\n                int t_index_x =  tx + BLOCK_SIZE - m ;\n                int t_index_y =  BLOCK_SIZE - tx;\n          \n                SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n                      SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n                      SCORE((t_index_y-1), (t_index_x))   - (penalty));\n             }\n                       }\n          \n          for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++) {\n             input_itemsets[index + max_cols * ty] = SCORE((ty+1), (tx+1));\n          }\n        }\n      }\n    }\n  \n  #ifdef DEBUG\n    printf(\"Processing lower-right matrix\\n\");\n  #endif\n  \n    for( int blk = block_width - 1 ; blk >= 1 ; blk--){      \n      global_work = blk;\n            {\n        int input_itemsets_l [(BLOCK_SIZE + 1) *(BLOCK_SIZE+1)];\n        int reference_l [BLOCK_SIZE*BLOCK_SIZE];\n                {\n          int bx = omp_get_team_num(); \n          int tx = omp_get_thread_num();\n  \n         \n\n         int base = offset_r * max_cols + offset_c;\n  \n         int b_index_x = bx + block_width - blk  ;\n         int b_index_y = block_width - bx -1;\n  \n  \n         int index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\n         int index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n         int index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\n         int index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n  \n         if (tx == 0)\n            SCORE(tx, 0) = input_itemsets[index_nw];\n  \n         for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n            REF(ty, tx) =  reference[index + max_cols * ty];\n  \n         SCORE((tx + 1), 0) = input_itemsets[index_w + max_cols * tx];\n  \n         SCORE(0, (tx + 1)) = input_itemsets[index_n];\n  \n           \n         for( int m = 0 ; m < BLOCK_SIZE ; m++){\n            if ( tx <= m ){\n  \n               int t_index_x =  tx + 1;\n               int t_index_y =  m - tx + 1;\n  \n               SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n                     SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n                     SCORE((t_index_y-1), (t_index_x))   - (penalty));\n            }\n                     }\n  \n         for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n            if ( tx <= m){\n               int t_index_x =  tx + BLOCK_SIZE - m ;\n               int t_index_y =  BLOCK_SIZE - tx;\n  \n               SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n                     SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n                     SCORE((t_index_y-1), (t_index_x))   - (penalty));\n            }\n                     }\n  \n         for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n            input_itemsets[index + ty * max_cols] = SCORE((ty+1), (tx+1));\n        }\n      }\n    }\n  \n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  }\n\n  \n\n  nw_host(h_input_itemsets, reference, max_cols, penalty);\n  int err = memcmp(input_itemsets, h_input_itemsets, max_cols * max_rows * sizeof(int));\n  printf(\"%s\\n\", err ? \"FAIL\" : \"PASS\");\n\n#ifdef TRACEBACK\n  int *output_itemsets = input_itemsets;\n\n  FILE *fpo = fopen(\"result.txt\",\"w\");\n  fprintf(fpo, \"print traceback value:\\n\");\n\n  for (int i = max_rows - 2,  j = max_rows - 2; i>=0, j>=0;){\n    int nw, n, w, traceback;\n    if ( i == max_rows - 2 && j == max_rows - 2 )\n      fprintf(fpo, \"%d \", output_itemsets[ i * max_cols + j]); \n\n    if ( i == 0 && j == 0 )\n      break;\n    if ( i > 0 && j > 0 ){\n      nw = output_itemsets[(i - 1) * max_cols + j - 1];\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else if ( i == 0 ){\n      nw = n = LIMIT;\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n    }\n    else if ( j == 0 ){\n      nw = w = LIMIT;\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else{\n    }\n\n    \n\n    int new_nw, new_w, new_n;\n    new_nw = nw + reference[i * max_cols + j];\n    new_w = w - penalty;\n    new_n = n - penalty;\n\n    traceback = maximum(new_nw, new_w, new_n);\n    if(traceback == new_nw)\n      traceback = nw;\n    if(traceback == new_w)\n      traceback = w;\n    if(traceback == new_n)\n      traceback = n;\n\n    fprintf(fpo, \"%d \", traceback);\n\n    if(traceback == nw )\n    {i--; j--; continue;}\n\n    else if(traceback == w )\n    {j--; continue;}\n\n    else if(traceback == n )\n    {i--; continue;}\n\n    else\n      ;\n  }\n\n  fclose(fpo);\n\n#endif\n\n  \n\n\n  free(reference);\n  free(input_itemsets);\n  free(h_input_itemsets);\n  return 0;\n}\n"}}
{"kernel_name": "nw", "parallel_api": "sycl", "code": {"nw.cpp": "#ifdef RD_WG_SIZE_0_0\n#define BLOCK_SIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n#define BLOCK_SIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n#define BLOCK_SIZE RD_WG_SIZE\n#else\n#define BLOCK_SIZE 16\n#endif\n\n#define LIMIT -999\n\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <iostream>\n#include <string>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.cpp\"\n\n\n\n#define SCORE(i, j) input_itemsets_l[j + i * (BLOCK_SIZE+1)]\n#define REF(i, j)   reference_l[j + i * BLOCK_SIZE]\nint max3( int a, int b, int c){\n\n  int k;\n  if( a <= b )\n    k = b;\n  else \n    k = a;\n  if( k <=c )\n    return(c);\n  else\n    return(k);\n}\n\n\n\n\n\nint blosum62[24][24] = {\n  { 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0, -3, -2,  0, -2, -1,  0, -4},\n  {-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -3, -2, -3, -1,  0, -1, -4},\n  {-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -4, -2, -3,  3,  0, -1, -4},\n  {-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  { 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1, -3, -3, -2, -4},\n  {-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -2, -1, -2,  0,  3, -1, -4},\n  {-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3, -1, -2, -1, -4},\n  {-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3,  0,  0, -1, -4},\n  {-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -3, -1,  3, -3, -3, -1, -4},\n  {-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -2, -1, -2, -1,  1, -4, -3, -1, -4},\n  {-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -3, -2, -2,  0,  1, -1, -4},\n  {-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -1, -1, -1, -1,  1, -3, -1, -1, -4},\n  {-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2,  1,  3, -1, -3, -3, -1, -4},\n  {-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -4, -3, -2, -2, -1, -2, -4},\n  { 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -2,  0, -1, -2, -1,  4,  1, -3, -2, -2,  0,  0,  0, -4},\n  { 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5, -2, -2,  0, -1, -1,  0, -4},\n  {-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3, -4, -3, -2, -4},\n  {-2, -2, -2, -3, -2, -1, -2, -3,  2, -1, -1, -2, -1,  3, -3, -2, -2,  2,  7, -1, -3, -2, -1, -4},\n  { 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1, -1, -2, -2,  0, -3, -1,  4, -3, -2, -1, -4},\n  {-2, -1,  3,  4, -3,  0,  1, -1,  0, -3, -4,  0, -3, -3, -2,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n  {-1,  0,  0,  1, -3,  3,  4, -2,  0, -3, -3,  1, -1, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n  { 0, -1, -1, -1, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -2,  0,  0, -2, -1, -1, -1, -1, -1, -4},\n  {-4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4,  1}\n};\n\n\n\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <max_rows/max_cols> <penalty> \\n\", argv[0]);\n  fprintf(stderr, \"\\t<dimension>  - x and y dimensions\\n\");\n  fprintf(stderr, \"\\t<penalty> - penalty(positive integer)\\n\");\n  exit(1);\n}\n\nint main(int argc, char **argv){\n\n  printf(\"WG size of kernel = %d \\n\", BLOCK_SIZE);\n\n  int max_rows_t, max_cols_t, penalty_t;\n  \n\n  \n\n  if (argc == 3)\n  {\n    max_rows_t = atoi(argv[1]);\n    max_cols_t = atoi(argv[1]);\n    penalty_t = atoi(argv[2]);\n  }\n  else{\n    usage(argc, argv);\n  }\n\n  if(atoi(argv[1])%16!=0){\n    fprintf(stderr,\"The dimension values must be a multiple of 16\\n\");\n    exit(1);\n  }\n\n  \n\n  const int max_rows = max_rows_t + 1;\n  const int max_cols = max_cols_t + 1;\n  const int penalty = penalty_t;  \n\n  int *reference;\n  int *input_itemsets;\n  int *output_itemsets;\n\n  const int matrix_size = max_rows * max_cols;\n  const size_t matrix_size_bytes = matrix_size * sizeof(int);\n\n  reference = (int *)malloc( matrix_size_bytes );\n  input_itemsets = (int *)malloc( matrix_size_bytes );\n  output_itemsets = (int *)malloc( matrix_size_bytes );\n\n  srand(7);\n\n  \n\n  for (int i = 0 ; i < max_cols; i++){\n    for (int j = 0 ; j < max_rows; j++){\n      input_itemsets[i*max_cols+j] = 0;\n    }\n  }\n\n  for( int i=1; i< max_rows ; i++){    \n\n    input_itemsets[i*max_cols] = rand() % 10 + 1;\n  }\n\n  for( int j=1; j< max_cols ; j++){    \n\n    input_itemsets[j] = rand() % 10 + 1;\n  }\n\n  for (int i = 1 ; i < max_cols; i++){\n    for (int j = 1 ; j < max_rows; j++){\n      reference[i*max_cols+j] = blosum62[input_itemsets[i*max_cols]][input_itemsets[j]];\n    }\n  }\n\n  for( int i = 1; i< max_rows ; i++)\n    input_itemsets[i*max_cols] = -i * penalty;\n  for( int j = 1; j< max_cols ; j++)\n    input_itemsets[j] = -j * penalty;\n\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int workgroupsize = BLOCK_SIZE;\n#ifdef DEBUG\n  if (workgroupsize < 0) {\n    printf(\"ERROR: invalid or missing <num_work_items>[/<work_group_size>]\\n\"); \n    return -1;\n  }\n#endif\n  \n\n  const size_t local_work = (size_t)workgroupsize;\n  size_t global_work;\n\n  const int worksize = max_cols - 1;\n#ifdef DEBUG\n  printf(\"worksize = %d\\n\", worksize);\n#endif\n  \n\n  const int offset_r = 0;\n  const int offset_c = 0;\n  const int block_width = worksize/BLOCK_SIZE ;\n\n  int *d_input_itemsets_acc = sycl::malloc_device<int>(matrix_size, q);\n  q.memcpy(d_input_itemsets_acc, input_itemsets, matrix_size_bytes);\n\n  int *d_reference_acc = sycl::malloc_device<int>(matrix_size, q);\n  q.memcpy(d_reference_acc, reference,  matrix_size_bytes);\n\n  \n\n  for(int blk = 1 ; blk <= block_width ; blk++){\n    global_work = BLOCK_SIZE * blk; \n\n    q.submit([&](sycl::handler& cgh) {\n      sycl::local_accessor <int, 1> input_itemsets_l (sycl::range<1>((BLOCK_SIZE + 1) *(BLOCK_SIZE+1)), cgh);\n      sycl::local_accessor <int, 1> reference_l (sycl::range<1>(BLOCK_SIZE * BLOCK_SIZE), cgh);\n      cgh.parallel_for<class kernel1_warmup>(\n        sycl::nd_range<1>(sycl::range<1>(global_work), sycl::range<1>(local_work)), [=] (sycl::nd_item<1> item) {\n          #include \"kernel1.sycl\"\n      });\n    });\n  }\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n#ifdef DEBUG\n  printf(\"Processing upper-left matrix\\n\");\n#endif\n\n  for(int blk = 1 ; blk <= block_width ; blk++){\n    global_work = BLOCK_SIZE * blk; \n\n#ifdef DEBUG\n    printf(\"global size: %d local size: %d\\n\", global_work, local_work);\n#endif\n    q.submit([&](sycl::handler& cgh) {\n      sycl::local_accessor <int, 1> input_itemsets_l (sycl::range<1>((BLOCK_SIZE + 1) *(BLOCK_SIZE+1)), cgh);\n      sycl::local_accessor <int, 1> reference_l (sycl::range<1>(BLOCK_SIZE * BLOCK_SIZE), cgh);\n      cgh.parallel_for<class kernel1>(\n        sycl::nd_range<1>(sycl::range<1>(global_work), sycl::range<1>(local_work)), [=] (sycl::nd_item<1> item) {\n          #include \"kernel1.sycl\"\n      });\n    });\n  }\n\n#ifdef DEBUG\n  printf(\"Processing lower-right matrix\\n\");\n#endif\n\n  for(int blk = block_width - 1 ; blk >= 1 ; blk--){\t   \n    global_work = BLOCK_SIZE * blk;\n    q.submit([&](sycl::handler& cgh) {\n      sycl::local_accessor <int, 1> input_itemsets_l (sycl::range<1>((BLOCK_SIZE + 1) *(BLOCK_SIZE+1)), cgh);\n      sycl::local_accessor <int, 1> reference_l (sycl::range<1>(BLOCK_SIZE * BLOCK_SIZE), cgh);\n      cgh.parallel_for<class kernel2>(\n        sycl::nd_range<1>(sycl::range<1>(global_work), sycl::range<1>(local_work)), [=] (sycl::nd_item<1> item) {\n          #include \"kernel2.sycl\"\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  q.memcpy(output_itemsets, d_input_itemsets_acc, matrix_size_bytes).wait();\n\n  \n\n  nw_host(input_itemsets, reference, max_cols, penalty);\n  int err = memcmp(input_itemsets, output_itemsets, max_cols * max_rows * sizeof(int));\n  printf(\"%s\\n\", err ? \"FAIL\" : \"PASS\");\n\n#ifdef TRACEBACK\n\n#ifdef USE_GPU\n  FILE *fpo = fopen(\"gpu_result.txt\",\"w\");\n#else\n  FILE *fpo = fopen(\"cpu_result.txt\",\"w\");\n#endif\n  fprintf(fpo, \"print traceback value:\\n\");\n\n  for (int i = max_rows - 2,  j = max_rows - 2; i>=0, j>=0;){\n    int nw, n, w, traceback;\n    if ( i == max_rows - 2 && j == max_rows - 2 )\n      fprintf(fpo, \"%d \", output_itemsets[ i * max_cols + j]); \n\n    if ( i == 0 && j == 0 )\n      break;\n    if ( i > 0 && j > 0 ){\n      nw = output_itemsets[(i - 1) * max_cols + j - 1];\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else if ( i == 0 ){\n      nw = n = LIMIT;\n      w  = output_itemsets[ i * max_cols + j - 1 ];\n    }\n    else if ( j == 0 ){\n      nw = w = LIMIT;\n      n  = output_itemsets[(i - 1) * max_cols + j];\n    }\n    else{\n    }\n\n    \n\n    int new_nw, new_w, new_n;\n    new_nw = nw + reference[i * max_cols + j];\n    new_w = w - penalty;\n    new_n = n - penalty;\n\n    traceback = max3(new_nw, new_w, new_n);\n    if(traceback == new_nw)\n      traceback = nw;\n    if(traceback == new_w)\n      traceback = w;\n    if(traceback == new_n)\n      traceback = n;\n\n    fprintf(fpo, \"%d \", traceback);\n\n    if(traceback == nw )\n    {i--; j--; continue;}\n\n    else if(traceback == w )\n    {j--; continue;}\n\n    else if(traceback == n )\n    {i--; continue;}\n\n    else\n      ;\n  }\n\n  fclose(fpo);\n\n#endif\n\n  \n\n\n  free(reference);\n  free(input_itemsets);\n  free(output_itemsets);\n  sycl::free(d_input_itemsets_acc, q);\n  sycl::free(d_reference_acc, q);\n  return 0;\n}\n", "kernel1.sycl": "\n\nint bx = item.get_group(0);  \n\n\n\nint tx = item.get_local_id(0);\n\n\n\nint base = offset_r * max_cols + offset_c;\n\nint b_index_x = bx;\nint b_index_y = blk - 1 - bx;\n\nint index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\nint index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\nint index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\nint index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n\nif (tx == 0) SCORE(tx, 0) = d_input_itemsets_acc[index_nw + tx];\n\nfor ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n  REF(ty, tx) =  d_reference_acc[index + max_cols * ty];\n\nSCORE((tx + 1), 0) = d_input_itemsets_acc[index_w + max_cols * tx];\n\nSCORE(0, (tx + 1)) = d_input_itemsets_acc[index_n];\n\nitem.barrier(sycl::access::fence_space::local_space);\n\nfor( int m = 0 ; m < BLOCK_SIZE ; m++){\n\n  if ( tx <= m ){\n\n    int t_index_x =  tx + 1;\n    int t_index_y =  m - tx + 1;\n\n    SCORE(t_index_y, t_index_x) = max3( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n        SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n        SCORE((t_index_y-1), (t_index_x))   - (penalty));\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n}\n\nfor( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n\n  if ( tx <= m){\n\n    int t_index_x =  tx + BLOCK_SIZE - m ;\n    int t_index_y =  BLOCK_SIZE - tx;\n\n    SCORE(t_index_y, t_index_x) = max3(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n        SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n        SCORE((t_index_y-1), (t_index_x))   - (penalty));\n\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n}\n\nfor ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n  d_input_itemsets_acc[index + max_cols * ty] = SCORE((ty+1), (tx+1));\n", "kernel2.sycl": "\n\nint bx = item.get_group(0);  \n\n\n\nint tx = item.get_local_id(0);\n\n\n\nint base = offset_r * max_cols + offset_c;\n\nint b_index_x = bx + block_width - blk  ;\nint b_index_y = block_width - bx -1;\n\nint index   =   base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( max_cols + 1 );\nint index_n   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\nint index_w   = base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( max_cols );\nint index_nw =  base + max_cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n\nif (tx == 0) SCORE(tx, 0) = d_input_itemsets_acc[index_nw];\n\nfor ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n  REF(ty, tx) =  d_reference_acc[index + max_cols * ty];\n\nSCORE((tx + 1), 0) = d_input_itemsets_acc[index_w + max_cols * tx];\n\nSCORE(0, (tx + 1)) = d_input_itemsets_acc[index_n];\n\nitem.barrier(sycl::access::fence_space::local_space);\n\nfor( int m = 0 ; m < BLOCK_SIZE ; m++){\n\n  if ( tx <= m ){\n\n    int t_index_x =  tx + 1;\n    int t_index_y =  m - tx + 1;\n\n    SCORE(t_index_y, t_index_x) = max3(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n        SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n        SCORE((t_index_y-1), (t_index_x))   - (penalty));\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n}\n\nfor( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n\n  if ( tx <= m){\n\n    int t_index_x =  tx + BLOCK_SIZE - m ;\n    int t_index_y =  BLOCK_SIZE - tx;\n\n    SCORE(t_index_y, t_index_x) = max3( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n        SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n        SCORE((t_index_y-1), (t_index_x))   - (penalty));\n\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n}\n\nfor ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n  d_input_itemsets_acc[index + ty * max_cols] = SCORE((ty+1), (tx+1));\n"}}
{"kernel_name": "snake", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stddef.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n#include <time.h>\n#include <unistd.h>\n#include <chrono>\n#include <cuda.h>\n\nusing namespace std::chrono;\n\n#define warp_size 32\n#define NBytes 8\n\n__host__ __device__\ninline uint lsr(uint x, int sa) {\n  if(sa > 0 && sa < 32) return (x >> sa);\n  return x;\n}\n\n__host__ __device__\ninline uint lsl(uint x, int sa) {\n  if (sa > 0 && sa < 32) return (x << sa);\n  return x;\n}\n\n__host__ __device__\ninline uint set_bit(uint &data, int y) {\n  data |= lsl(1, y);\n  return data;\n}\n\n#include \"kernel.h\"\n#include \"reference.h\"\n\nint main(int argc, const char * const argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s [ReadLength] [ReadandRefFile] [#reads] [repeat]\\n\", argv[0]);\n    exit(-1);\n  }\n\n  int ReadLength = atoi(argv[1]);\n\n  int NumReads = atoi(argv[3]); \n\n  int repeat = atoi(argv[4]);\n  int Size_of_int_in_Bit = 32; \n\n\n  FILE * fp;\n  char * line = NULL;\n  size_t len = 0;\n  ssize_t read;\n  char *p;\n\n\n  int Number_of_warps_inside_each_block = 8; \n  int Concurrent_threads_In_Block = warp_size * Number_of_warps_inside_each_block;\n  int Number_of_blocks_inside_each_kernel = (NumReads + Concurrent_threads_In_Block - 1) / \n                                            Concurrent_threads_In_Block;\n\n  int F_ErrorThreshold =0;\n\n  uint* ReadSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  uint* RefSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  int* DFinal_Results = (int *) calloc(NumReads, sizeof(int));\n  int* HFinal_Results = (int *) calloc(NumReads, sizeof(int));\n\n  int tokenIndex=1;\n  fp = fopen(argv[2], \"r\");\n  if (!fp){\n    printf(\"The file %s does not exist or you do not have access permission\\n\", argv[2]);\n    return 0;\n  }\n  for(int this_read = 0; this_read < NumReads; this_read++) {\n    read = getline(&line, &len, fp);\n    tokenIndex=1;\n    for (p = strtok(line, \"\\t\"); p != NULL; p = strtok(NULL, \"\\t\"))\n    {\n      if (tokenIndex==1)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2));\n\n            ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      else if(tokenIndex==2)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2));\n\n            RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      tokenIndex=tokenIndex+1;\n    }\n  }\n  fclose(fp);\n\n  uint* Dev_ReadSeq;\n  uint* Dev_RefSeq;\n  int* Dev_Results;\n  cudaMalloc((void**)&Dev_ReadSeq, sizeof(uint) * NumReads * 8);\n  cudaMalloc((void**)&Dev_RefSeq, sizeof(uint) * NumReads * 8);\n  cudaMalloc((void**)&Dev_Results, sizeof(int) * NumReads);\n\n  dim3 grid (Number_of_blocks_inside_each_kernel);\n  dim3 block (Concurrent_threads_In_Block);\n\n  cudaMemcpy(Dev_ReadSeq, ReadSeq, sizeof(int) * NumReads * 8, cudaMemcpyHostToDevice);\n  cudaMemcpy(Dev_RefSeq, RefSeq, sizeof(int) * NumReads * 8, cudaMemcpyHostToDevice);\n\n  bool error = false;\n  for (int loopPar = 0; loopPar <= 25; loopPar++) {\n\n    F_ErrorThreshold = (loopPar*ReadLength)/100;\n\n    auto t1 = high_resolution_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      sneaky_snake<<<grid, block>>>(Dev_ReadSeq, Dev_RefSeq, Dev_Results, NumReads, F_ErrorThreshold);\n    }\n\n    cudaDeviceSynchronize();\n    auto t2 = high_resolution_clock::now();\n    double elapsed_time = duration_cast<microseconds>(t2 - t1).count();\n    \n    cudaMemcpy(DFinal_Results, Dev_Results, sizeof(int) * NumReads, cudaMemcpyDeviceToHost);\n\n    \n\n    sneaky_snake_ref(ReadSeq, RefSeq, HFinal_Results, NumReads, F_ErrorThreshold);\n    error = memcmp(DFinal_Results, HFinal_Results, NumReads * sizeof(int));\n    if (error) break;\n\n    \n\n    int D_accepted = 0;\n    for(int i = 0; i < NumReads; i++) if(DFinal_Results[i] == 1) D_accepted++;\n\n    printf(\"Error threshold: %2d | Average kernel time (us): %5.4f | Accepted: %10d | Rejected: %10d\\n\", \n          F_ErrorThreshold, elapsed_time / repeat, D_accepted, NumReads - D_accepted);\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  free(ReadSeq);\n  free(RefSeq);\n  free(DFinal_Results);\n  free(HFinal_Results);\n  cudaFree(Dev_ReadSeq);\n  cudaFree(Dev_RefSeq);\n  cudaFree(Dev_Results);\n  return 0;\n}\n"}}
{"kernel_name": "snake", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stddef.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n#include <time.h>\n#include <unistd.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\nusing namespace std::chrono;\n\n#define warp_size 32\n#define NBytes 8\n\n__host__ __device__\ninline uint lsr(uint x, int sa) {\n  if(sa > 0 && sa < 32) return (x >> sa);\n  return x;\n}\n\n__host__ __device__\ninline uint lsl(uint x, int sa) {\n  if (sa > 0 && sa < 32) return (x << sa);\n  return x;\n}\n\n__host__ __device__\ninline uint set_bit(uint &data, int y) {\n  data |= lsl(1, y);\n  return data;\n}\n\n#include \"kernel.h\"\n#include \"reference.h\"\n\nint main(int argc, const char * const argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s [ReadLength] [ReadandRefFile] [#reads] [repeat]\\n\", argv[0]);\n    exit(-1);\n  }\n\n  int ReadLength = atoi(argv[1]);\n\n  int NumReads = atoi(argv[3]); \n\n  int repeat = atoi(argv[4]);\n  int Size_of_int_in_Bit = 32; \n\n\n  FILE * fp;\n  char * line = NULL;\n  size_t len = 0;\n  ssize_t read;\n  char *p;\n\n\n  int Number_of_warps_inside_each_block = 8; \n  int Concurrent_threads_In_Block = warp_size * Number_of_warps_inside_each_block;\n  int Number_of_blocks_inside_each_kernel = (NumReads + Concurrent_threads_In_Block - 1) / \n                                            Concurrent_threads_In_Block;\n\n  int F_ErrorThreshold =0;\n\n  uint* ReadSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  uint* RefSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  int* DFinal_Results = (int *) calloc(NumReads, sizeof(int));\n  int* HFinal_Results = (int *) calloc(NumReads, sizeof(int));\n\n  int tokenIndex=1;\n  fp = fopen(argv[2], \"r\");\n  if (!fp){\n    printf(\"The file %s does not exist or you do not have access permission\\n\", argv[2]);\n    return 0;\n  }\n  for(int this_read = 0; this_read < NumReads; this_read++) {\n    read = getline(&line, &len, fp);\n    tokenIndex=1;\n    for (p = strtok(line, \"\\t\"); p != NULL; p = strtok(NULL, \"\\t\"))\n    {\n      if (tokenIndex==1)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2));\n\n            ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      else if(tokenIndex==2)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2));\n\n            RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_int_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_int_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      tokenIndex=tokenIndex+1;\n    }\n  }\n  fclose(fp);\n\n  uint* Dev_ReadSeq;\n  uint* Dev_RefSeq;\n  int* Dev_Results;\n  hipMalloc((void**)&Dev_ReadSeq, sizeof(uint) * NumReads * 8);\n  hipMalloc((void**)&Dev_RefSeq, sizeof(uint) * NumReads * 8);\n  hipMalloc((void**)&Dev_Results, sizeof(int) * NumReads);\n\n  dim3 grid (Number_of_blocks_inside_each_kernel);\n  dim3 block (Concurrent_threads_In_Block);\n\n  hipMemcpy(Dev_ReadSeq, ReadSeq, sizeof(int) * NumReads * 8, hipMemcpyHostToDevice);\n  hipMemcpy(Dev_RefSeq, RefSeq, sizeof(int) * NumReads * 8, hipMemcpyHostToDevice);\n\n  bool error = false;\n  for (int loopPar = 0; loopPar <= 25; loopPar++) {\n\n    F_ErrorThreshold = (loopPar*ReadLength)/100;\n\n    auto t1 = high_resolution_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      hipLaunchKernelGGL(sneaky_snake, grid, block, 0, 0, Dev_ReadSeq, Dev_RefSeq, Dev_Results, NumReads, F_ErrorThreshold);\n    }\n\n    hipDeviceSynchronize();\n    auto t2 = high_resolution_clock::now();\n    double elapsed_time = duration_cast<microseconds>(t2 - t1).count();\n    \n    hipMemcpy(DFinal_Results, Dev_Results, sizeof(int) * NumReads, hipMemcpyDeviceToHost);\n\n    \n\n    sneaky_snake_ref(ReadSeq, RefSeq, HFinal_Results, NumReads, F_ErrorThreshold);\n    error = memcmp(DFinal_Results, HFinal_Results, NumReads * sizeof(int));\n    if (error) break;\n\n    \n\n    int D_accepted = 0;\n    for(int i = 0; i < NumReads; i++) if(DFinal_Results[i] == 1) D_accepted++;\n\n    printf(\"Error threshold: %2d | Average kernel time (us): %5.4f | Accepted: %10d | Rejected: %10d\\n\", \n          F_ErrorThreshold, elapsed_time / repeat, D_accepted, NumReads - D_accepted);\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  free(ReadSeq);\n  free(RefSeq);\n  free(DFinal_Results);\n  free(HFinal_Results);\n  hipFree(Dev_ReadSeq);\n  hipFree(Dev_RefSeq);\n  hipFree(Dev_Results);\n  return 0;\n}\n"}}
{"kernel_name": "snake", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stddef.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n#include <time.h>\n#include <unistd.h>\n#include <chrono>\n\nusing namespace std::chrono;\n\n#define warp_size 32\n#define NBytes 8\n\n#pragma omp declare target\ninline uint lsr(uint x, int sa) {\n  if(sa > 0 && sa < 32) return (x >> sa);\n  return x;\n}\n\ninline uint lsl(uint x, int sa) {\n  if (sa > 0 && sa < 32) return (x << sa);\n  return x;\n}\n\ninline uint set_bit(uint &data, int y) {\n  data |= lsl(1, y);\n  return data;\n}\n\n\n\nuint popcnt( uint x )\n{\n  x -= ((x >> 1) & 0x55555555);\n  x = (((x >> 2) & 0x33333333) + (x & 0x33333333));\n  x = (((x >> 4) + x) & 0x0f0f0f0f);\n  x += (x >> 8);\n  x += (x >> 16);\n  return x & 0x0000003f;\n}\n\ninline int __clz( int x )\n{\n  x |= (x >> 1);\n  x |= (x >> 2);\n  x |= (x >> 4);\n  x |= (x >> 8);\n  x |= (x >> 16);\n  return 32 - popcnt(x);\n}\n#pragma omp end declare target\n\n#include \"kernel.h\"\n#include \"reference.h\"\n\nint main(int argc, const char * const argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s [ReadLength] [ReadandRefFile] [#reads] [repeat]\\n\", argv[0]);\n    exit(-1);\n  }\n\n  int ReadLength = atoi(argv[1]);\n\n  int NumReads = atoi(argv[3]); \n\n  int repeat = atoi(argv[4]);\n  int Size_of_uint_in_Bit = 32; \n\n\n  FILE * fp;\n  char * line = NULL;\n  size_t len = 0;\n  ssize_t read;\n  char *p;\n\n\n  int Number_of_warps_inside_each_block = 8; \n  int Concurrent_threads_In_Block = warp_size * Number_of_warps_inside_each_block;\n  int Number_of_blocks_inside_each_kernel = (NumReads + Concurrent_threads_In_Block - 1) / \n                                            Concurrent_threads_In_Block;\n\n  int F_ErrorThreshold =0;\n\n  uint* ReadSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  uint* RefSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  int* DFinal_Results = (int *) calloc(NumReads, sizeof(int));\n  int* HFinal_Results = (int *) calloc(NumReads, sizeof(int));\n\n  int tokenIndex=1;\n  fp = fopen(argv[2], \"r\");\n  if (!fp){\n    printf(\"The file %s does not exist or you do not have access permission\\n\", argv[2]);\n    return 0;\n  }\n  for(int this_read = 0; this_read < NumReads; this_read++) {\n    read = getline(&line, &len, fp);\n    tokenIndex=1;\n    for (p = strtok(line, \"\\t\"); p != NULL; p = strtok(NULL, \"\\t\"))\n    {\n      if (tokenIndex==1)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      else if(tokenIndex==2)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      tokenIndex=tokenIndex+1;\n    }\n  }\n  fclose(fp);\n\n  #pragma omp target data map(to: ReadSeq[0:NumReads*8], RefSeq[0:NumReads*8]) \\\n                          map(alloc: DFinal_Results[0:NumReads])\n  {\n\n  bool error = false;\n  for (int loopPar = 0; loopPar <= 25; loopPar++) {\n\n    F_ErrorThreshold = (loopPar*ReadLength)/100;\n\n    auto t1 = high_resolution_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      sneaky_snake(Number_of_blocks_inside_each_kernel, Concurrent_threads_In_Block,\n                   ReadSeq, RefSeq, DFinal_Results, NumReads, F_ErrorThreshold);\n    }\n\n    auto t2 = high_resolution_clock::now();\n    double elapsed_time = duration_cast<microseconds>(t2 - t1).count();\n\n    #pragma omp target update from (DFinal_Results[0:NumReads])\n\n    \n\n    sneaky_snake_ref(ReadSeq, RefSeq, HFinal_Results, NumReads, F_ErrorThreshold);\n    error = memcmp(DFinal_Results, HFinal_Results, NumReads * sizeof(int));\n    if (error) break;\n\n    \n\n    int D_accepted = 0;\n    for(int i = 0; i < NumReads; i++) if(DFinal_Results[i] == 1) D_accepted++;\n\n    printf(\"Error threshold: %2d | Average kernel time (us): %5.4f | Accepted: %10d | Rejected: %10d\\n\", \n          F_ErrorThreshold, elapsed_time / repeat, D_accepted, NumReads - D_accepted);\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  }\n\n  free(ReadSeq);\n  free(RefSeq);\n  free(DFinal_Results);\n  free(HFinal_Results);\n  return 0;\n}\n"}}
{"kernel_name": "snake", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stddef.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n#include <time.h>\n#include <unistd.h>\n#include <chrono>\n\nusing namespace std::chrono;\n\n#define warp_size 32\n#define NBytes 8\n\ninline uint lsr(uint x, int sa) {\n  if(sa > 0 && sa < 32) return (x >> sa);\n  return x;\n}\n\ninline uint lsl(uint x, int sa) {\n  if (sa > 0 && sa < 32) return (x << sa);\n  return x;\n}\n\ninline uint set_bit(uint &data, int y) {\n  data |= lsl(1, y);\n  return data;\n}\n\n\n\nuint popcnt( uint x )\n{\n  x -= ((x >> 1) & 0x55555555);\n  x = (((x >> 2) & 0x33333333) + (x & 0x33333333));\n  x = (((x >> 4) + x) & 0x0f0f0f0f);\n  x += (x >> 8);\n  x += (x >> 16);\n  return x & 0x0000003f;\n}\n\ninline int __clz( int x )\n{\n  x |= (x >> 1);\n  x |= (x >> 2);\n  x |= (x >> 4);\n  x |= (x >> 8);\n  x |= (x >> 16);\n  return 32 - popcnt(x);\n}\n\n#include \"kernel.h\"\n#include \"reference.h\"\n\nint main(int argc, const char * const argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s [ReadLength] [ReadandRefFile] [#reads] [repeat]\\n\", argv[0]);\n    exit(-1);\n  }\n\n  int ReadLength = atoi(argv[1]);\n\n  int NumReads = atoi(argv[3]); \n\n  int repeat = atoi(argv[4]);\n  int Size_of_uint_in_Bit = 32; \n\n\n  FILE * fp;\n  char * line = NULL;\n  size_t len = 0;\n  ssize_t read;\n  char *p;\n\n\n  int Number_of_warps_inside_each_block = 8; \n  int Concurrent_threads_In_Block = warp_size * Number_of_warps_inside_each_block;\n  int Number_of_blocks_inside_each_kernel = (NumReads + Concurrent_threads_In_Block - 1) / \n                                            Concurrent_threads_In_Block;\n\n  int F_ErrorThreshold =0;\n\n  uint* ReadSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  uint* RefSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  int* DFinal_Results = (int *) calloc(NumReads, sizeof(int));\n  int* HFinal_Results = (int *) calloc(NumReads, sizeof(int));\n\n  int tokenIndex=1;\n  fp = fopen(argv[2], \"r\");\n  if (!fp){\n    printf(\"The file %s does not exist or you do not have access permission\\n\", argv[2]);\n    return 0;\n  }\n  for(int this_read = 0; this_read < NumReads; this_read++) {\n    read = getline(&line, &len, fp);\n    tokenIndex=1;\n    for (p = strtok(line, \"\\t\"); p != NULL; p = strtok(NULL, \"\\t\"))\n    {\n      if (tokenIndex==1)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      else if(tokenIndex==2)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      tokenIndex=tokenIndex+1;\n    }\n  }\n  fclose(fp);\n\n    {\n\n  bool error = false;\n  for (int loopPar = 0; loopPar <= 25; loopPar++) {\n\n    F_ErrorThreshold = (loopPar*ReadLength)/100;\n\n    auto t1 = high_resolution_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      sneaky_snake(Number_of_blocks_inside_each_kernel, Concurrent_threads_In_Block,\n                   ReadSeq, RefSeq, DFinal_Results, NumReads, F_ErrorThreshold);\n    }\n\n    auto t2 = high_resolution_clock::now();\n    double elapsed_time = duration_cast<microseconds>(t2 - t1).count();\n\n    \n    \n\n    sneaky_snake_ref(ReadSeq, RefSeq, HFinal_Results, NumReads, F_ErrorThreshold);\n    error = memcmp(DFinal_Results, HFinal_Results, NumReads * sizeof(int));\n    if (error) break;\n\n    \n\n    int D_accepted = 0;\n    for(int i = 0; i < NumReads; i++) if(DFinal_Results[i] == 1) D_accepted++;\n\n    printf(\"Error threshold: %2d | Average kernel time (us): %5.4f | Accepted: %10d | Rejected: %10d\\n\", \n          F_ErrorThreshold, elapsed_time / repeat, D_accepted, NumReads - D_accepted);\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  }\n\n  free(ReadSeq);\n  free(RefSeq);\n  free(DFinal_Results);\n  free(HFinal_Results);\n  return 0;\n}"}}
{"kernel_name": "snake", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stddef.h>\n#include <stdlib.h>\n#include <string.h>\n#include <stdio.h>\n#include <time.h>\n#include <unistd.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nusing namespace std::chrono;\n\n#define warp_size 32\n#define NBytes 8\n\ninline uint lsr(uint x, int sa) {\n  if(sa > 0 && sa < 32) return (x >> sa);\n  return x;\n}\n\ninline uint lsl(uint x, int sa) {\n  if (sa > 0 && sa < 32) return (x << sa);\n  return x;\n}\n\ninline uint set_bit(uint &data, int y) {\n  data |= lsl(1, y);\n  return data;\n}\n\n#include \"kernel.h\"\n#include \"reference.h\"\n\nint main(int argc, const char * const argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: ./%s [ReadLength] [ReadandRefFile] [#reads] [repeat]\\n\", argv[0]);\n    exit(-1);\n  }\n\n  int ReadLength = atoi(argv[1]);\n\n  int NumReads = atoi(argv[3]); \n\n  int repeat = atoi(argv[4]);\n  int Size_of_uint_in_Bit = 32; \n\n\n  FILE * fp;\n  char * line = NULL;\n  size_t len = 0;\n  ssize_t read;\n  char *p;\n\n\n  int Number_of_warps_inside_each_block = 8;\n  int Concurrent_threads_In_Block = warp_size * Number_of_warps_inside_each_block;\n  int Number_of_blocks_inside_each_kernel = (NumReads + Concurrent_threads_In_Block - 1) /\n                                            Concurrent_threads_In_Block;\n\n  int F_ErrorThreshold =0;\n\n  uint* ReadSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  uint* RefSeq = (uint *) calloc(NumReads * 8, sizeof(uint));\n  int* DFinal_Results = (int *) calloc(NumReads, sizeof(int));\n  int* HFinal_Results = (int *) calloc(NumReads, sizeof(int));\n\n  int tokenIndex=1;\n  fp = fopen(argv[2], \"r\");\n  if (!fp){\n    printf(\"Sorry, the file does not exist or you do not have access permission\\n\");\n    return 0;\n  }\n  for(int this_read = 0; this_read < NumReads; this_read++) {\n    read = getline(&line, &len, fp);\n    tokenIndex=1;\n    for (p = strtok(line, \"\\t\"); p != NULL; p = strtok(NULL, \"\\t\"))\n    {\n      if (tokenIndex==1)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n\n            ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(ReadSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      else if(tokenIndex==2)\n      {\n        for (int j = 0; j < ReadLength; j++)\n        {\n          if(p[j] == 'A')\n          {\n            \n\n          }\n          else if (p[j] == 'C')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n          else if (p[j] == 'G')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n          }\n          else if (p[j] == 'T')\n          {\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2));\n\n            RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)] = set_bit(RefSeq[((j*2/Size_of_uint_in_Bit) + this_read * NBytes)], 31 - ((j%(Size_of_uint_in_Bit/2)) * 2 + 1));\n          }\n        }\n      }\n      tokenIndex=tokenIndex+1;\n    }\n  }\n  fclose(fp);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  uint *d_ReadSeq = sycl::malloc_device<uint>(NumReads * 8, q);\n  q.memcpy(d_ReadSeq, ReadSeq, sizeof(int) * NumReads * 8);\n\n  uint *d_RefSeq = sycl::malloc_device<uint>(NumReads * 8, q);\n  q.memcpy(d_RefSeq, RefSeq, sizeof(int) * NumReads * 8);\n\n   int *d_Results = sycl::malloc_device<int>(NumReads, q);\n\n  sycl::range<1> gws(Concurrent_threads_In_Block * Number_of_blocks_inside_each_kernel);\n  sycl::range<1> lws(Concurrent_threads_In_Block);\n\n  q.wait();\n\n  bool error = false;\n  for (int loopPar = 0; loopPar <= 25; loopPar++) {\n\n    F_ErrorThreshold = (loopPar*ReadLength)/100;\n\n    auto t1 = high_resolution_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class filter>(\n          sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n          sneaky_snake (item, d_ReadSeq, d_RefSeq, d_Results,\n                        NumReads, F_ErrorThreshold);\n       });\n      });\n    }\n\n    q.wait();\n    auto t2 = high_resolution_clock::now();\n    double elapsed_time = duration_cast<microseconds>(t2 - t1).count();\n\n    q.memcpy(DFinal_Results, d_Results, sizeof(int) * NumReads).wait();\n\n    \n\n    sneaky_snake_ref(ReadSeq, RefSeq, HFinal_Results, NumReads, F_ErrorThreshold);\n    error = memcmp(DFinal_Results, HFinal_Results, NumReads * sizeof(int));\n    if (error) break;\n\n    \n\n    int D_accepted = 0;\n    for(int i = 0; i < NumReads; i++) if(DFinal_Results[i] == 1) D_accepted++;\n\n    printf(\"Error threshold: %2d | Average kernel time (us): %5.4f | Accepted: %10d | Rejected: %10d\\n\",\n          F_ErrorThreshold, elapsed_time / repeat, D_accepted, NumReads - D_accepted);\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(ReadSeq);\n  free(RefSeq);\n  free(DFinal_Results);\n  free(HFinal_Results);\n  sycl::free(d_ReadSeq, q);\n  sycl::free(d_RefSeq, q);\n  sycl::free(d_Results, q);\n  return 0;\n}\n"}}
