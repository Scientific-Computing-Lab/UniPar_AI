{"kernel_name": "all-pairs-distance", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cuda.h>\n#include <sys/time.h>\n\n#define INSTANCES 224   \n\n#define ATTRIBUTES 4096 \n\n#define THREADS 128    \n\n\n\n\nvoid CPU(int * data, int * distance) {\n  \n\n#pragma omp parallel for collapse(2)\n  for (int i = 0; i < INSTANCES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      for (int k = 0; k < ATTRIBUTES; k++) {\n        distance[i + INSTANCES * j] += \n          (data[i * ATTRIBUTES + k] != data[j * ATTRIBUTES + k]);\n      }\n    }\n  }\n}\n\n\n\n\n__global__ void GPUregister(const char *data, int *distance) {\n  int idx = threadIdx.x;\n  int gx = blockIdx.x;\n  int gy = blockIdx.y;\n\n  for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n    char4 j = *(char4 *)(data + i + ATTRIBUTES*gx);\n    char4 k = *(char4 *)(data + i + ATTRIBUTES*gy);\n\n    \n\n    char count = 0;\n\n    if(j.x ^ k.x) \n      count++; \n    if(j.y ^ k.y)\n      count++;\n    if(j.z ^ k.z)\n      count++;\n    if(j.w ^ k.w)\n      count++;\n\n    \n\n    atomicAdd(distance + INSTANCES*gx + gy, count);\n  }\n}\n\n\n\n__global__ void GPUshared(const char *data, int *distance) {\n  int idx = threadIdx.x;\n  int gx = blockIdx.x;\n  int gy = blockIdx.y;\n\n  \n\n  __shared__ int dist[THREADS];\n\n  \n \n  dist[idx] = 0;\n\n  \n\n  __syncthreads();\n\n  for(int i = idx*4; i < ATTRIBUTES; i+=THREADS*4) {\n    char4 j = *(char4 *)(data + i + ATTRIBUTES*gx);\n    char4 k = *(char4 *)(data + i + ATTRIBUTES*gy);\n    char count = 0;\n\n    if(j.x ^ k.x) \n      count++;\n    if(j.y ^ k.y)\n      count++;\n    if(j.z ^ k.z)\n      count++;\n    if(j.w ^ k.w)\n      count++;\n\n    \n\n    dist[idx] += count;\n  }\n\n  \n\n  __syncthreads();\n\n  \n \n  if(idx == 0) {\n    for(int i = 1; i < THREADS; i++) {\n      dist[0] += dist[i];\n    }\n\n    \n\n    distance[INSTANCES*gy + gx] = dist[0];\n  }\n}\n\nint main(int argc, char **argv) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]);\n\n  \n\n  int *data; \n  char *data_char;\n  int *cpu_distance; \n  int *gpu_distance; \n\n  \n\n  char *data_char_device;\n  int *distance_device; \n\n  \n\n  dim3 dimBlock; \n  dim3 dimGrid; \n\n  \n\n  double start_cpu, stop_cpu;\n  double start_gpu, stop_gpu;\n  float elapsedTime; \n  struct timeval tp;\n  struct timezone tzp;\n  \n \n  int status;\n\n  \n\n  srand(2);\n\n  \n\n  data = (int *)malloc(INSTANCES * ATTRIBUTES * sizeof(int));\n  data_char = (char *)malloc(INSTANCES * ATTRIBUTES * sizeof(char));\n  cpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n  gpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n\n  \n\n#pragma omp parallel for collapse(2)\n  for (int i = 0; i < ATTRIBUTES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      data[i + ATTRIBUTES * j] = data_char[i + ATTRIBUTES * j] = random() % 3;\n    }\n  }\n\n  \n\n  cudaMalloc((void **)&data_char_device, \n      INSTANCES * ATTRIBUTES * sizeof(char));\n\n  cudaMalloc((void **)&distance_device, \n      INSTANCES * INSTANCES * sizeof(int));\n\n  cudaMemcpy(data_char_device, data_char,\n      INSTANCES * ATTRIBUTES * sizeof(char),\n      cudaMemcpyHostToDevice);\n\n  \n\n  dimBlock.x = THREADS; \n  dimBlock.y = 1; \n  dimGrid.x = INSTANCES;\n  dimGrid.y = INSTANCES;\n\n\n  \n\n  bzero(cpu_distance,INSTANCES*INSTANCES*sizeof(int));\n  gettimeofday(&tp, &tzp);\n  start_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  CPU(data, cpu_distance);\n  gettimeofday(&tp, &tzp);\n  stop_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  elapsedTime = stop_cpu - start_cpu;\n  printf(\"CPU time: %f (us)\\n\",elapsedTime);\n\n  elapsedTime = 0; \n  for (int n = 0; n < iterations; n++) {\n    \n\n    bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n    cudaMemcpy(distance_device, gpu_distance,\n               INSTANCES * INSTANCES * sizeof(int), cudaMemcpyHostToDevice);\n\n    gettimeofday(&tp, &tzp);\n    start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n\n    GPUregister<<<dimGrid,dimBlock>>>(data_char_device, distance_device);\n    cudaDeviceSynchronize();\n\n    gettimeofday(&tp, &tzp);\n    stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n    elapsedTime += stop_gpu - start_gpu;\n\n    cudaMemcpy(gpu_distance, distance_device,\n               INSTANCES * INSTANCES * sizeof(int), cudaMemcpyDeviceToHost); \n  }\n\n  printf(\"Average kernel execution time (w/o shared memory): %f (us)\\n\", elapsedTime / iterations);\n  status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n  if (status != 0) printf(\"FAIL\\n\");\n  else printf(\"PASS\\n\");\n\n  elapsedTime = 0; \n  for (int n = 0; n < iterations; n++) {\n    \n\n    bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n    cudaMemcpy(distance_device, gpu_distance,\n               INSTANCES * INSTANCES * sizeof(int), cudaMemcpyHostToDevice);\n\n    gettimeofday(&tp, &tzp);\n    start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n\n    GPUshared<<<dimGrid,dimBlock>>>(data_char_device, distance_device);\n    cudaDeviceSynchronize();\n\n    gettimeofday(&tp, &tzp);\n    stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n    elapsedTime += stop_gpu - start_gpu;\n\n    cudaMemcpy(gpu_distance, distance_device,\n               INSTANCES * INSTANCES * sizeof(int), cudaMemcpyDeviceToHost); \n  }\n\n  printf(\"Average kernel execution time (w/ shared memory): %f (us)\\n\", elapsedTime / iterations);\n  status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n  if (status != 0) printf(\"FAIL\\n\");\n  else printf(\"PASS\\n\");\n\n  free(cpu_distance);\n  free(gpu_distance);\n  free(data);\n  free(data_char);\n  cudaFree(data_char_device);\n  cudaFree(distance_device);\n\n  return status;\n}\n"}}
{"kernel_name": "all-pairs-distance", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <omp.h>\n#include <sys/time.h>\n\n#define INSTANCES 224   \n\n#define ATTRIBUTES 4096 \n\n#define THREADS 128    \n\n\nstruct char4 { char x; char y; char z; char w; };\n\n\n\n\nvoid CPU(int * data, int * distance) {\n  \n\n  #pragma omp parallel for collapse(2)\n  for (int i = 0; i < INSTANCES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      for (int k = 0; k < ATTRIBUTES; k++) {\n        distance[i + INSTANCES * j] += \n          (data[i * ATTRIBUTES + k] != data[j * ATTRIBUTES + k]);\n      }\n    }\n  }\n}\n\nint main(int argc, char **argv) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]);\n\n  \n\n  int *data; \n  char *data_char;\n  int *cpu_distance, *gpu_distance;\n\n  \n\n  double start_cpu, stop_cpu;\n  double start_gpu, stop_gpu;\n  double elapsedTime; \n  struct timeval tp;\n  struct timezone tzp;\n  \n \n  int status;\n\n  \n\n  srand(2);\n\n  \n\n  data = (int *)malloc(INSTANCES * ATTRIBUTES * sizeof(int));\n  data_char = (char *)malloc(INSTANCES * ATTRIBUTES * sizeof(char));\n  cpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n  gpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n\n  \n\n  #pragma omp parallel for collapse(2)\n  for (int i = 0; i < ATTRIBUTES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      data[i + ATTRIBUTES * j] = data_char[i + ATTRIBUTES * j] = random() % 3;\n    }\n  }\n\n  \n\n  bzero(cpu_distance,INSTANCES*INSTANCES*sizeof(int));\n  gettimeofday(&tp, &tzp);\n  start_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  CPU(data, cpu_distance);\n  gettimeofday(&tp, &tzp);\n  stop_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  elapsedTime = stop_cpu - start_cpu;\n  printf(\"CPU time: %f (us)\\n\",elapsedTime);\n\n  #pragma omp target data map(to: data_char[0:INSTANCES * ATTRIBUTES]) \\\n                          map(alloc: gpu_distance[0:INSTANCES * INSTANCES ])\n  {\n    for (int n = 0; n < iterations; n++) {\n      \n\n      bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n      #pragma omp target update to (gpu_distance[0:INSTANCES * INSTANCES])\n  \n      gettimeofday(&tp, &tzp);\n      start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n  \n      #pragma omp target teams num_teams(INSTANCES*INSTANCES) thread_limit(THREADS)\n      {\n        #pragma omp parallel\n        {\n          int idx = omp_get_thread_num();\n          int gx = omp_get_team_num() % INSTANCES;\n          int gy = omp_get_team_num() / INSTANCES;\n      \n          for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n            char4 j = *(char4 *)(data_char + i + ATTRIBUTES*gx);\n            char4 k = *(char4 *)(data_char + i + ATTRIBUTES*gy);\n      \n            \n\n            char count = 0;\n      \n            if(j.x ^ k.x) \n              count++; \n            if(j.y ^ k.y)\n              count++;\n            if(j.z ^ k.z)\n              count++;\n            if(j.w ^ k.w)\n              count++;\n      \n            \n\n            #pragma omp atomic update\n            gpu_distance[ INSTANCES*gx + gy ] += count;\n          }\n        }\n      }\n  \n      gettimeofday(&tp, &tzp);\n      stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n      elapsedTime += stop_gpu - start_gpu;\n  \n      #pragma omp target update from (gpu_distance[0:INSTANCES * INSTANCES])\n    }\n  \n    printf(\"Average kernel execution time (w/o shared memory): %f (us)\\n\", elapsedTime / iterations);\n    status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n    if (status != 0) printf(\"FAIL\\n\");\n    else printf(\"PASS\\n\");\n  \n    elapsedTime = 0; \n    for (int n = 0; n < iterations; n++) {\n      \n\n      bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n      #pragma omp target update to (gpu_distance[0:INSTANCES * INSTANCES])\n  \n      gettimeofday(&tp, &tzp);\n      start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n  \n      #pragma omp target teams num_teams(INSTANCES*INSTANCES) thread_limit(THREADS)\n      {\n        int dist[THREADS];\n        #pragma omp parallel\n        {\n          int idx = omp_get_thread_num();\n          int gx = omp_get_team_num() % INSTANCES;\n          int gy = omp_get_team_num() / INSTANCES;\n      \n          dist[idx] = 0;\n          #pragma omp barrier\n      \n          for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n            char4 j = *(char4 *)(data_char + i + ATTRIBUTES*gx);\n            char4 k = *(char4 *)(data_char + i + ATTRIBUTES*gy);\n      \n            \n\n            char count = 0;\n      \n            if(j.x ^ k.x) \n              count++; \n            if(j.y ^ k.y)\n              count++;\n            if(j.z ^ k.z)\n              count++;\n            if(j.w ^ k.w)\n              count++;\n      \n            dist[idx] += count;\n          }\n      \n        \n\n          #pragma omp barrier\n      \n        \n \n          if(idx == 0) {\n            for(int i = 1; i < THREADS; i++) {\n              dist[0] += dist[i];\n            }\n      \n            \n\n            gpu_distance[INSTANCES*gy + gx] = dist[0];\n          }\n        }\n      }\n  \n      gettimeofday(&tp, &tzp);\n      stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n      elapsedTime += stop_gpu - start_gpu;\n  \n      #pragma omp target update from (gpu_distance[0:INSTANCES * INSTANCES])\n    }\n  \n    printf(\"Average kernel execution time (w/ shared memory): %f (us)\\n\", elapsedTime / iterations);\n    status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n    if (status != 0) printf(\"FAIL\\n\");\n    else printf(\"PASS\\n\");\n  }\n\n  free(cpu_distance);\n  free(gpu_distance);\n  free(data_char);\n  free(data);\n  return status;\n}\n"}}
{"kernel_name": "all-pairs-distance", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <sys/time.h>\n\n#define INSTANCES 224   \n\n#define ATTRIBUTES 4096 \n\n#define THREADS 128    \n\n\nstruct char4 { char x; char y; char z; char w; };\n\n\n\n\nvoid CPU(int * data, int * distance) {\n  \n\n    for (int i = 0; i < INSTANCES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      for (int k = 0; k < ATTRIBUTES; k++) {\n        distance[i + INSTANCES * j] += \n          (data[i * ATTRIBUTES + k] != data[j * ATTRIBUTES + k]);\n      }\n    }\n  }\n}\n\nint main(int argc, char **argv) {\n\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]);\n\n  \n\n  int *data; \n  char *data_char;\n  int *cpu_distance, *gpu_distance;\n\n  \n\n  double start_cpu, stop_cpu;\n  double start_gpu, stop_gpu;\n  double elapsedTime; \n  struct timeval tp;\n  struct timezone tzp;\n  \n \n  int status;\n\n  \n\n  srand(2);\n\n  \n\n  data = (int *)malloc(INSTANCES * ATTRIBUTES * sizeof(int));\n  data_char = (char *)malloc(INSTANCES * ATTRIBUTES * sizeof(char));\n  cpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n  gpu_distance = (int *)malloc(INSTANCES * INSTANCES * sizeof(int));\n\n  \n\n    for (int i = 0; i < ATTRIBUTES; i++) {\n    for (int j = 0; j < INSTANCES; j++) {\n      data[i + ATTRIBUTES * j] = data_char[i + ATTRIBUTES * j] = random() % 3;\n    }\n  }\n\n  \n\n  bzero(cpu_distance,INSTANCES*INSTANCES*sizeof(int));\n  gettimeofday(&tp, &tzp);\n  start_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  CPU(data, cpu_distance);\n  gettimeofday(&tp, &tzp);\n  stop_cpu = tp.tv_sec*1000000+tp.tv_usec;\n  elapsedTime = stop_cpu - start_cpu;\n  printf(\"CPU time: %f (us)\\n\",elapsedTime);\n\n    {\n    for (int n = 0; n < iterations; n++) {\n      \n\n      bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n        \n      gettimeofday(&tp, &tzp);\n      start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n  \n            {\n                {\n          int idx = omp_get_thread_num();\n          int gx = omp_get_team_num() % INSTANCES;\n          int gy = omp_get_team_num() / INSTANCES;\n      \n          for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n            char4 j = *(char4 *)(data_char + i + ATTRIBUTES*gx);\n            char4 k = *(char4 *)(data_char + i + ATTRIBUTES*gy);\n      \n            \n\n            char count = 0;\n      \n            if(j.x ^ k.x) \n              count++; \n            if(j.y ^ k.y)\n              count++;\n            if(j.z ^ k.z)\n              count++;\n            if(j.w ^ k.w)\n              count++;\n      \n            \n\n                        gpu_distance[ INSTANCES*gx + gy ] += count;\n          }\n        }\n      }\n  \n      gettimeofday(&tp, &tzp);\n      stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n      elapsedTime += stop_gpu - start_gpu;\n  \n          }\n  \n    printf(\"Average kernel execution time (w/o shared memory): %f (us)\\n\", elapsedTime / iterations);\n    status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n    if (status != 0) printf(\"FAIL\\n\");\n    else printf(\"PASS\\n\");\n  \n    elapsedTime = 0; \n    for (int n = 0; n < iterations; n++) {\n      \n\n      bzero(gpu_distance,INSTANCES*INSTANCES*sizeof(int));\n        \n      gettimeofday(&tp, &tzp);\n      start_gpu = tp.tv_sec*1000000+tp.tv_usec;\n  \n            {\n        int dist[THREADS];\n                {\n          int idx = omp_get_thread_num();\n          int gx = omp_get_team_num() % INSTANCES;\n          int gy = omp_get_team_num() / INSTANCES;\n      \n          dist[idx] = 0;\n                \n          for(int i = 4*idx; i < ATTRIBUTES; i+=THREADS*4) {\n            char4 j = *(char4 *)(data_char + i + ATTRIBUTES*gx);\n            char4 k = *(char4 *)(data_char + i + ATTRIBUTES*gy);\n      \n            \n\n            char count = 0;\n      \n            if(j.x ^ k.x) \n              count++; \n            if(j.y ^ k.y)\n              count++;\n            if(j.z ^ k.z)\n              count++;\n            if(j.w ^ k.w)\n              count++;\n      \n            dist[idx] += count;\n          }\n      \n        \n\n                \n        \n \n          if(idx == 0) {\n            for(int i = 1; i < THREADS; i++) {\n              dist[0] += dist[i];\n            }\n      \n            \n\n            gpu_distance[INSTANCES*gy + gx] = dist[0];\n          }\n        }\n      }\n  \n      gettimeofday(&tp, &tzp);\n      stop_gpu = tp.tv_sec*1000000+tp.tv_usec;\n      elapsedTime += stop_gpu - start_gpu;\n  \n          }\n  \n    printf(\"Average kernel execution time (w/ shared memory): %f (us)\\n\", elapsedTime / iterations);\n    status = memcmp(cpu_distance, gpu_distance, INSTANCES * INSTANCES * sizeof(int));\n    if (status != 0) printf(\"FAIL\\n\");\n    else printf(\"PASS\\n\");\n  }\n\n  free(cpu_distance);\n  free(gpu_distance);\n  free(data_char);\n  free(data);\n  return status;\n}"}}