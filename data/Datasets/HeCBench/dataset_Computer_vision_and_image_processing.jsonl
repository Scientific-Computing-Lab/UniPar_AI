{"kernel_name": "affine", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <cstring>\n#include <cmath>\n#include <iostream>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n#include \"kernel.h\"\n\nint main(int argc, char** argv)\n{\n  if (argc != 4)\n  {\n    printf(\"Usage: %s <input image> <output image> <iterations>\\n\", argv[0]) ;\n    return -1 ;\n  }\n\n  unsigned short input_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short output_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short output_image_ref[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n\n  \n\n  std::cout << \"Reading input image...\\n\";\n\n  \n\n  const char *inputImageFilename = argv[1];\n  FILE *input_file = fopen(inputImageFilename, \"rb\");\n  if (!input_file)\n  {\n    printf(\"Error: Unable to open input image file %s!\\n\", inputImageFilename);\n    return 1;\n  }\n\n  printf(\"\\n\");\n  printf(\"   Reading RAW Image\\n\");\n  size_t items_read = fread(input_image, sizeof(input_image), 1, input_file);\n  printf(\"   Bytes read = %d\\n\\n\", (int)(items_read * sizeof(input_image)));\n  fclose(input_file);\n\n  const int iterations = atoi(argv[3]);\n\n  size_t image_size_bytes = sizeof(unsigned short) * X_SIZE * Y_SIZE;\n\n  unsigned short *d_input_image;\n  cudaMalloc((void**)&d_input_image, image_size_bytes);\n  cudaMemcpy(d_input_image, input_image, image_size_bytes, cudaMemcpyHostToDevice);\n\n  unsigned short *d_output_image;\n  cudaMalloc((void**)&d_output_image, image_size_bytes);\n\n  dim3 grids (X_SIZE/16,Y_SIZE/16);\n  dim3 threads (16,16);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++) {\n    affine<<<grids, threads>>>(d_input_image, d_output_image);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"   Average kernel execution time \" << (time * 1e-9f) / iterations << \" (s)\\n\";\n\n  cudaMemcpy(output_image, d_output_image, image_size_bytes, cudaMemcpyDeviceToHost);\n  cudaFree(d_input_image);\n  cudaFree(d_output_image);\n\n  \n\n  affine_reference(input_image, output_image_ref);\n  int max_error = 0;\n  for (int y = 0; y < Y_SIZE; y++) {\n    for (int x = 0; x < X_SIZE; x++) {\n      max_error = std::max(max_error, std::abs(output_image[y*X_SIZE+x] - output_image_ref[y*X_SIZE+x]));\n    }\n  }\n  printf(\"   Max output error is %d\\n\\n\", max_error);\n\n  printf(\"   Writing RAW Image\\n\");\n  const char *outputImageFilename = argv[2];\n  FILE *output_file = fopen(outputImageFilename, \"wb\");\n  if (!output_file)\n  {\n    printf(\"Error: Unable to write  image file %s!\\n\", outputImageFilename);\n    return 1;\n  }\n  size_t items_written = fwrite(output_image, sizeof(output_image), 1, output_file);\n  printf(\"   Bytes written = %d\\n\\n\", (int)(items_written * sizeof(output_image)));\n  fclose(output_file);\n\n  return 0 ;\n}\n"}}
{"kernel_name": "affine", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <cstring>\n#include <cmath>\n#include <iostream>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n#include \"kernel.h\"\n\nint main(int argc, char** argv)\n{\n  if (argc != 4)\n  {\n    printf(\"Usage: %s <input image> <output image> <iterations>\\n\", argv[0]) ;\n    return -1 ;\n  }\n\n  unsigned short input_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short output_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short output_image_ref[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n\n  \n\n  std::cout << \"Reading input image...\\n\";\n\n  \n\n  const char *inputImageFilename = argv[1];\n  FILE *input_file = fopen(inputImageFilename, \"rb\");\n  if (!input_file)\n  {\n    printf(\"Error: Unable to open input image file %s!\\n\", inputImageFilename);\n    return 1;\n  }\n\n  printf(\"\\n\");\n  printf(\"   Reading RAW Image\\n\");\n  size_t items_read = fread(input_image, sizeof(input_image), 1, input_file);\n  printf(\"   Bytes read = %d\\n\\n\", (int)(items_read * sizeof(input_image)));\n  fclose(input_file);\n\n  const int iterations = atoi(argv[3]);\n\n  size_t image_size_bytes = sizeof(unsigned short) * X_SIZE * Y_SIZE;\n\n  unsigned short *d_input_image;\n  hipMalloc((void**)&d_input_image, image_size_bytes);\n  hipMemcpy(d_input_image, input_image, image_size_bytes, hipMemcpyHostToDevice);\n\n  unsigned short *d_output_image;\n  hipMalloc((void**)&d_output_image, image_size_bytes);\n\n  dim3 grids (X_SIZE/16,Y_SIZE/16);\n  dim3 threads (16,16);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++) {\n    hipLaunchKernelGGL(affine, grids, threads, 0, 0, d_input_image, d_output_image);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"   Average kernel execution time \" << (time * 1e-9f) / iterations << \" (s)\\n\";\n\n  hipMemcpy(output_image, d_output_image, image_size_bytes, hipMemcpyDeviceToHost);\n  hipFree(d_input_image);\n  hipFree(d_output_image);\n\n  \n\n  affine_reference(input_image, output_image_ref);\n  int max_error = 0;\n  for (int y = 0; y < Y_SIZE; y++) {\n    for (int x = 0; x < X_SIZE; x++) {\n      max_error = std::max(max_error, std::abs(output_image[y*X_SIZE+x] - output_image_ref[y*X_SIZE+x]));\n    }\n  }\n  printf(\"   Max output error is %d\\n\\n\", max_error);\n\n  printf(\"   Writing RAW Image\\n\");\n  const char *outputImageFilename = argv[2];\n  FILE *output_file = fopen(outputImageFilename, \"wb\");\n  if (!output_file)\n  {\n    printf(\"Error: Unable to write  image file %s!\\n\", outputImageFilename);\n    return 1;\n  }\n  size_t items_written = fwrite(output_image, sizeof(output_image), 1, output_file);\n  printf(\"   Bytes written = %d\\n\\n\", (int)(items_written * sizeof(output_image)));\n  fclose(output_file);\n\n  return 0 ;\n}\n"}}
{"kernel_name": "affine", "parallel_api": "omp", "code": {"main.cpp": "\n\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <cstring>\n#include <cmath>\n#include <chrono>\n#include <iostream>\n#include \"reference.h\"\n\nint main(int argc, char** argv)\n{\n  if (argc != 4)\n  {\n    printf(\"Usage: %s <input image> <output image> <iterations>\\n\", argv[0]) ;\n    return -1 ;\n  }\n\n  unsigned short    input_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short    output_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short    output_image_ref[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n\n  \n\n  std::cout << \"Reading input image...\\n\";\n\n  \n\n  const char *inputImageFilename = argv[1];\n  FILE *input_file = fopen(inputImageFilename, \"rb\");\n  if (!input_file)\n  {\n    printf(\"Error: Unable to open input image file %s!\\n\", inputImageFilename);\n    return 1;\n  }\n\n  printf(\"\\n\");\n  printf(\"   Reading RAW Image\\n\");\n  size_t items_read = fread(input_image, sizeof(input_image), 1, input_file);\n  printf(\"   Bytes read = %d\\n\\n\", (int)(items_read * sizeof(input_image)));\n  fclose(input_file);\n\n  const int iterations = atoi(argv[3]);\n\n  #pragma omp target data map(to: input_image[0:X_SIZE*Y_SIZE]) \\\n                          map(from:output_image[0:X_SIZE*Y_SIZE])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < iterations; i++) {\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n      for (int y = 0; y < Y_SIZE; y++)\n        for (int x = 0; x < X_SIZE; x++) {\n\n          const float lx_rot   = 30.0f;\n          const float ly_rot   = 0.0f; \n          const float lx_expan = 0.5f;\n          const float ly_expan = 0.5f; \n          int   lx_move  = 0;\n          int   ly_move  = 0;\n          float affine[2][2];   \n\n          float i_affine[2][2];\n          float beta[2];\n          float i_beta[2];\n          float det;\n          float x_new, y_new;\n          float x_frac, y_frac;\n          float gray_new;\n          int   m, n;\n          unsigned short output_buffer;\n\n          \n\n          affine[0][0] = lx_expan * cosf(lx_rot*PI/180.0f);\n          affine[0][1] = ly_expan * sinf(ly_rot*PI/180.0f);\n          affine[1][0] = lx_expan * sinf(lx_rot*PI/180.0f);\n          affine[1][1] = ly_expan * cosf(ly_rot*PI/180.0f);\n          beta[0]      = lx_move;\n          beta[1]      = ly_move;\n\n          \n\n          det = (affine[0][0] * affine[1][1]) - (affine[0][1] * affine[1][0]);\n          if (det == 0.0f)\n          {\n            i_affine[0][0] = 1.0f;\n            i_affine[0][1] = 0.0f;\n            i_affine[1][0] = 0.0f;\n            i_affine[1][1] = 1.0f;\n            i_beta[0]      = -beta[0];\n            i_beta[1]      = -beta[1];\n          } \n          else \n          {\n            i_affine[0][0] =  affine[1][1]/det;\n            i_affine[0][1] = -affine[0][1]/det;\n            i_affine[1][0] = -affine[1][0]/det;\n            i_affine[1][1] =  affine[0][0]/det;\n            i_beta[0]      = -i_affine[0][0]*beta[0]-i_affine[0][1]*beta[1];\n            i_beta[1]      = -i_affine[1][0]*beta[0]-i_affine[1][1]*beta[1];\n          }\n\n          \n\n\n          x_new  = i_beta[0] + i_affine[0][0]*(x-X_SIZE/2.0f) + i_affine[0][1]*(y-Y_SIZE/2.0f) + X_SIZE/2.0f;\n          y_new  = i_beta[1] + i_affine[1][0]*(x-X_SIZE/2.0f) + i_affine[1][1]*(y-Y_SIZE/2.0f) + Y_SIZE/2.0f;\n\n          m      = (int)floorf(x_new);\n          n      = (int)floorf(y_new);\n\n          x_frac = x_new - m;\n          y_frac = y_new - n;\n\n          if ((m >= 0) && (m + 1 < X_SIZE) && (n >= 0) && (n+1 < Y_SIZE))\n          {\n            gray_new = (1.0f - y_frac) * ((1.0f - x_frac) * (input_image[(n * X_SIZE) + m])  + \n                x_frac * (input_image[(n * X_SIZE) + m + 1])) + \n              y_frac  * ((1.0f - x_frac) * (input_image[((n + 1) * X_SIZE) + m]) + \n                  x_frac * (input_image[((n + 1) * X_SIZE) + m + 1]));\n\n            output_buffer = (unsigned short)gray_new;\n          } \n          else if (((m + 1 == X_SIZE) && (n >= 0) && (n < Y_SIZE)) || ((n + 1 == Y_SIZE) && (m >= 0) && (m < X_SIZE))) \n          {\n            output_buffer = input_image[(n * X_SIZE) + m];\n          } \n          else \n          {\n            output_buffer = WHITE;\n          }\n\n          output_image[(y * X_SIZE)+x] = output_buffer;\n        }\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"   Average kernel execution time \" << (time * 1e-9f) / iterations << \" (s)\\n\";\n  }\n\n  \n\n  affine_reference(input_image, output_image_ref);\n  int max_error = 0;\n  for (int y = 0; y < Y_SIZE; y++) {\n    for (int x = 0; x < X_SIZE; x++) {\n      max_error = std::max(max_error, std::abs(output_image[y*X_SIZE+x] - output_image_ref[y*X_SIZE+x]));\n    }\n  }\n  printf(\"   Max output error is %d\\n\\n\", max_error);\n\n  printf(\"   Writing RAW Image\\n\");\n  const char *outputImageFilename = argv[2];\n  FILE *output_file = fopen(outputImageFilename, \"wb\");\n  if (!output_file)\n  {\n    printf(\"Error: Unable to write  image file %s!\\n\", outputImageFilename);\n    return 1;\n  }\n  size_t items_written = fwrite(output_image, sizeof(output_image), 1, output_file);\n  printf(\"   Bytes written = %d\\n\\n\", (int)(items_written * sizeof(output_image)));\n  fclose(output_file);\n\n  return 0 ;\n}\n"}}
{"kernel_name": "affine", "parallel_api": "serial", "code": {"main.cpp": "\n\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <cstring>\n#include <cmath>\n#include <chrono>\n#include <iostream>\n#include \"reference.h\"\n\nint main(int argc, char** argv)\n{\n  if (argc != 4)\n  {\n    printf(\"Usage: %s <input image> <output image> <iterations>\\n\", argv[0]) ;\n    return -1 ;\n  }\n\n  unsigned short    input_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short    output_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short    output_image_ref[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n\n  \n\n  std::cout << \"Reading input image...\\n\";\n\n  \n\n  const char *inputImageFilename = argv[1];\n  FILE *input_file = fopen(inputImageFilename, \"rb\");\n  if (!input_file)\n  {\n    printf(\"Error: Unable to open input image file %s!\\n\", inputImageFilename);\n    return 1;\n  }\n\n  printf(\"\\n\");\n  printf(\"   Reading RAW Image\\n\");\n  size_t items_read = fread(input_image, sizeof(input_image), 1, input_file);\n  printf(\"   Bytes read = %d\\n\\n\", (int)(items_read * sizeof(input_image)));\n  fclose(input_file);\n\n  const int iterations = atoi(argv[3]);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < iterations; i++) {\n            for (int y = 0; y < Y_SIZE; y++)\n        for (int x = 0; x < X_SIZE; x++) {\n\n          const float lx_rot   = 30.0f;\n          const float ly_rot   = 0.0f; \n          const float lx_expan = 0.5f;\n          const float ly_expan = 0.5f; \n          int   lx_move  = 0;\n          int   ly_move  = 0;\n          float affine[2][2];   \n\n          float i_affine[2][2];\n          float beta[2];\n          float i_beta[2];\n          float det;\n          float x_new, y_new;\n          float x_frac, y_frac;\n          float gray_new;\n          int   m, n;\n          unsigned short output_buffer;\n\n          \n\n          affine[0][0] = lx_expan * cosf(lx_rot*PI/180.0f);\n          affine[0][1] = ly_expan * sinf(ly_rot*PI/180.0f);\n          affine[1][0] = lx_expan * sinf(lx_rot*PI/180.0f);\n          affine[1][1] = ly_expan * cosf(ly_rot*PI/180.0f);\n          beta[0]      = lx_move;\n          beta[1]      = ly_move;\n\n          \n\n          det = (affine[0][0] * affine[1][1]) - (affine[0][1] * affine[1][0]);\n          if (det == 0.0f)\n          {\n            i_affine[0][0] = 1.0f;\n            i_affine[0][1] = 0.0f;\n            i_affine[1][0] = 0.0f;\n            i_affine[1][1] = 1.0f;\n            i_beta[0]      = -beta[0];\n            i_beta[1]      = -beta[1];\n          } \n          else \n          {\n            i_affine[0][0] =  affine[1][1]/det;\n            i_affine[0][1] = -affine[0][1]/det;\n            i_affine[1][0] = -affine[1][0]/det;\n            i_affine[1][1] =  affine[0][0]/det;\n            i_beta[0]      = -i_affine[0][0]*beta[0]-i_affine[0][1]*beta[1];\n            i_beta[1]      = -i_affine[1][0]*beta[0]-i_affine[1][1]*beta[1];\n          }\n\n          \n\n\n          x_new  = i_beta[0] + i_affine[0][0]*(x-X_SIZE/2.0f) + i_affine[0][1]*(y-Y_SIZE/2.0f) + X_SIZE/2.0f;\n          y_new  = i_beta[1] + i_affine[1][0]*(x-X_SIZE/2.0f) + i_affine[1][1]*(y-Y_SIZE/2.0f) + Y_SIZE/2.0f;\n\n          m      = (int)floorf(x_new);\n          n      = (int)floorf(y_new);\n\n          x_frac = x_new - m;\n          y_frac = y_new - n;\n\n          if ((m >= 0) && (m + 1 < X_SIZE) && (n >= 0) && (n+1 < Y_SIZE))\n          {\n            gray_new = (1.0f - y_frac) * ((1.0f - x_frac) * (input_image[(n * X_SIZE) + m])  + \n                x_frac * (input_image[(n * X_SIZE) + m + 1])) + \n              y_frac  * ((1.0f - x_frac) * (input_image[((n + 1) * X_SIZE) + m]) + \n                  x_frac * (input_image[((n + 1) * X_SIZE) + m + 1]));\n\n            output_buffer = (unsigned short)gray_new;\n          } \n          else if (((m + 1 == X_SIZE) && (n >= 0) && (n < Y_SIZE)) || ((n + 1 == Y_SIZE) && (m >= 0) && (m < X_SIZE))) \n          {\n            output_buffer = input_image[(n * X_SIZE) + m];\n          } \n          else \n          {\n            output_buffer = WHITE;\n          }\n\n          output_image[(y * X_SIZE)+x] = output_buffer;\n        }\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    std::cout << \"   Average kernel execution time \" << (time * 1e-9f) / iterations << \" (s)\\n\";\n  }\n\n  \n\n  affine_reference(input_image, output_image_ref);\n  int max_error = 0;\n  for (int y = 0; y < Y_SIZE; y++) {\n    for (int x = 0; x < X_SIZE; x++) {\n      max_error = std::max(max_error, std::abs(output_image[y*X_SIZE+x] - output_image_ref[y*X_SIZE+x]));\n    }\n  }\n  printf(\"   Max output error is %d\\n\\n\", max_error);\n\n  printf(\"   Writing RAW Image\\n\");\n  const char *outputImageFilename = argv[2];\n  FILE *output_file = fopen(outputImageFilename, \"wb\");\n  if (!output_file)\n  {\n    printf(\"Error: Unable to write  image file %s!\\n\", outputImageFilename);\n    return 1;\n  }\n  size_t items_written = fwrite(output_image, sizeof(output_image), 1, output_file);\n  printf(\"   Bytes written = %d\\n\\n\", (int)(items_written * sizeof(output_image)));\n  fclose(output_file);\n\n  return 0 ;\n}"}}
{"kernel_name": "affine", "parallel_api": "sycl", "code": {"Makefile.hipsycl": "#===============================================================================\n# User Options\n#===============================================================================\n\n# Compiler can be set below, or via environment variable\nCC        = syclcc\nOPTIMIZE  = yes\nDEBUG     = no\nMARCH     = gfx906\nPLATFORM  = rocm\nDEVICE    = gpu\n\n#===============================================================================\n# Program name & source code list\n#===============================================================================\n\nprogram = main\n\nsource = main.cpp\n\nobj = $(source:.cpp=.o)\n\n#===============================================================================\n# Sets Flags\n#===============================================================================\n\n# Standard Flags\nCFLAGS := $(EXTRA_CFLAGS) -Wall -I../include \\\n          --hipsycl-platform=$(PLATFORM) \\\n\t  --hipsycl-gpu-arch=$(MARCH)\n\n# Linker Flags\nLDFLAGS = \n\n# Debug Flags\nifeq ($(DEBUG),yes)\n  CFLAGS += -g\n  LDFLAGS  += -g\nendif\n\n\n# Optimization Flags\nifeq ($(OPTIMIZE),yes)\n  CFLAGS += -O3\nendif\n\nifeq ($(DEVICE),gpu)\n  CFLAGS +=-DUSE_GPU\nendif\n\n#===============================================================================\n# Targets to Build\n#===============================================================================\n\n$(program): $(obj) Makefile\n\t$(CC) $(CFLAGS) $(obj) -o $@ $(LDFLAGS)\n\n%.o: %.cpp Makefile\n\t$(CC) $(CFLAGS) -c $< -o $@\n\nclean:\n\trm -rf $(program) $(obj) result.raw\n\nrun: $(program)\n\t./$(program) data/CT-MONO2-16-brain.raw result.raw\n", "main.cpp": "\n\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <cstring>\n#include <cmath>\n#include <chrono>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nint main(int argc, char** argv)\n{\n  if (argc != 4)\n  {\n    printf(\"Usage: %s <input image> <output image> <iterations>\\n\", argv[0]) ;\n    return -1 ;\n  }\n\n  unsigned short input_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short output_image[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n  unsigned short output_image_ref[Y_SIZE*X_SIZE] __attribute__((aligned(1024)));\n\n  \n\n  std::cout << \"Reading input image...\\n\";\n\n  \n\n  const char *inputImageFilename = argv[1];\n  FILE *input_file = fopen(inputImageFilename, \"rb\");\n  if (!input_file)\n  {\n    printf(\"Error: Unable to open input image file %s!\\n\", inputImageFilename);\n    return 1;\n  }\n\n  printf(\"\\n\");\n  printf(\"   Reading RAW Image\\n\");\n  size_t items_read = fread(input_image, sizeof(input_image), 1, input_file);\n  printf(\"   Bytes read = %d\\n\\n\", (int)(items_read * sizeof(input_image)));\n  fclose(input_file);\n\n  const int iterations = atoi(argv[3]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  size_t image_size_bytes = sizeof(unsigned short) * X_SIZE * Y_SIZE;\n  \n  unsigned short *d_input_image = sycl::malloc_device<unsigned short>(X_SIZE * Y_SIZE, q);\n  q.memcpy(d_input_image, input_image, image_size_bytes); \n\n  unsigned short *d_output_image = sycl::malloc_device<unsigned short>(X_SIZE*Y_SIZE, q);\n\n  sycl::range<2> globalSize(Y_SIZE,X_SIZE);\n  sycl::range<2> localSize(16,16);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class affine_transform> (\n        sycl::nd_range<2>(globalSize, localSize), [=](sycl::nd_item<2> item) {\n        int y = item.get_global_id(0); \n        int x = item.get_global_id(1); \n\n        const float lx_rot   = 30.0f;\n        const float ly_rot   = 0.0f; \n        const float lx_expan = 0.5f;\n        const float ly_expan = 0.5f; \n        int   lx_move  = 0;\n        int   ly_move  = 0;\n        float affine[2][2];   \n\n        float i_affine[2][2];\n        float beta[2];\n        float i_beta[2];\n        float det;\n        float x_new, y_new;\n        float x_frac, y_frac;\n        float gray_new;\n        int   m, n;\n        unsigned short output_buffer;\n\n        \n\n        affine[0][0] = lx_expan * sycl::cos(lx_rot*PI/180.0f);\n        affine[0][1] = ly_expan * sycl::sin(ly_rot*PI/180.0f);\n        affine[1][0] = lx_expan * sycl::sin(lx_rot*PI/180.0f);\n        affine[1][1] = ly_expan * sycl::cos(ly_rot*PI/180.0f);\n        beta[0]      = lx_move;\n        beta[1]      = ly_move;\n\n        \n\n        det = (affine[0][0] * affine[1][1]) - (affine[0][1] * affine[1][0]);\n        if (det == 0.0f)\n        {\n          i_affine[0][0] = 1.0f;\n          i_affine[0][1] = 0.0f;\n          i_affine[1][0] = 0.0f;\n          i_affine[1][1] = 1.0f;\n          i_beta[0]      = -beta[0];\n          i_beta[1]      = -beta[1];\n        } \n        else \n        {\n          i_affine[0][0] =  affine[1][1]/det;\n          i_affine[0][1] = -affine[0][1]/det;\n          i_affine[1][0] = -affine[1][0]/det;\n          i_affine[1][1] =  affine[0][0]/det;\n          i_beta[0]      = -i_affine[0][0]*beta[0]-i_affine[0][1]*beta[1];\n          i_beta[1]      = -i_affine[1][0]*beta[0]-i_affine[1][1]*beta[1];\n        }\n\n        \n\n\n        x_new  = i_beta[0] + i_affine[0][0]*(x-X_SIZE/2.0f) + i_affine[0][1]*(y-Y_SIZE/2.0f) + X_SIZE/2.0f;\n        y_new  = i_beta[1] + i_affine[1][0]*(x-X_SIZE/2.0f) + i_affine[1][1]*(y-Y_SIZE/2.0f) + Y_SIZE/2.0f;\n\n        m      = (int)sycl::floor(x_new);\n        n      = (int)sycl::floor(y_new);\n\n        x_frac = x_new - m;\n        y_frac = y_new - n;\n\n        if ((m >= 0) && (m + 1 < X_SIZE) && (n >= 0) && (n+1 < Y_SIZE))\n        {\n          gray_new = (1.0f - y_frac) * ((1.0f - x_frac) * d_input_image[(n * X_SIZE) + m] +\n                     x_frac * d_input_image[(n * X_SIZE) + m + 1]) +\n                     y_frac  * ((1.0f - x_frac) * (d_input_image[((n + 1) * X_SIZE) + m]) +\n                     x_frac * (d_input_image[((n + 1) * X_SIZE) + m + 1]));\n\n          output_buffer = (unsigned short)gray_new;\n        } \n        else if (((m + 1 == X_SIZE) && (n >= 0) && (n < Y_SIZE)) || ((n + 1 == Y_SIZE) && (m >= 0) && (m < X_SIZE))) \n        {\n          output_buffer = d_input_image[(n * X_SIZE) + m];\n        } \n        else \n        {\n          output_buffer = WHITE;\n        }\n\n        d_output_image[(y * X_SIZE)+x] = output_buffer;\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"   Average kernel execution time \" << (time * 1e-9f) / iterations << \" (s)\\n\";\n\n  q.memcpy(output_image, d_output_image, image_size_bytes).wait();\n\n  sycl::free(d_input_image, q);\n  sycl::free(d_output_image, q);\n\n  \n\n  affine_reference(input_image, output_image_ref);\n  int max_error = 0;\n  for (int y = 0; y < Y_SIZE; y++) {\n    for (int x = 0; x < X_SIZE; x++) {\n      max_error = std::max(max_error, std::abs(output_image[y*X_SIZE+x] - output_image_ref[y*X_SIZE+x]));\n    }\n  }\n  printf(\"   Max output error is %d\\n\\n\", max_error);\n\n  printf(\"   Writing RAW Image\\n\");\n  const char *outputImageFilename = argv[2];\n  FILE *output_file = fopen(outputImageFilename, \"wb\");\n  if (!output_file)\n  {\n    printf(\"Error: Unable to write  image file %s!\\n\", outputImageFilename);\n    return 1;\n  }\n  size_t items_written = fwrite(output_image, sizeof(output_image), 1, output_file);\n  printf(\"   Bytes written = %d\\n\\n\", (int)(items_written * sizeof(output_image)));\n  fclose(output_file);\n\n  return 0 ;\n}\n"}}
{"kernel_name": "aobench", "parallel_api": "cuda", "code": {"ao.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <assert.h>\n#include <math.h>\n#include <time.h>\n#include <cuda.h>\n\n#define WIDTH        256\n#define HEIGHT       256\n#define NSUBSAMPLES  2\n#define NAO_SAMPLES  8\n#define BLOCK_SIZE   16\n\ntypedef struct _vec\n{\n  float x;\n  float y;\n  float z;\n} vec;\n\n\ntypedef struct _Isect\n{\n  float t;\n  vec    p;\n  vec    n;\n  int    hit; \n} Isect;\n\ntypedef struct _Sphere\n{\n  vec    center;\n  float radius;\n\n} Sphere;\n\ntypedef struct _Plane\n{\n  vec    p;\n  vec    n;\n\n} Plane;\n\ntypedef struct _Ray\n{\n  vec    org;\n  vec    dir;\n} Ray;\n\n\n  __device__\nstatic float vdot(vec v0, vec v1)\n{\n  return v0.x * v1.x + v0.y * v1.y + v0.z * v1.z;\n}\n\n  __device__\nstatic void vcross(vec *c, vec v0, vec v1)\n{\n\n  c->x = v0.y * v1.z - v0.z * v1.y;\n  c->y = v0.z * v1.x - v0.x * v1.z;\n  c->z = v0.x * v1.y - v0.y * v1.x;\n}\n\n  __device__\nstatic void vnormalize(vec *c)\n{\n  float length = sqrtf(vdot((*c), (*c)));\n\n  if (fabs(length) > 1.0e-17f) {\n    c->x /= length;\n    c->y /= length;\n    c->z /= length;\n  }\n}\n\n  __device__\nvoid ray_sphere_intersect(Isect *isect, const Ray *ray, const Sphere *sphere)\n{\n  vec rs;\n\n  rs.x = ray->org.x - sphere->center.x;\n  rs.y = ray->org.y - sphere->center.y;\n  rs.z = ray->org.z - sphere->center.z;\n\n  float B = vdot(rs, ray->dir);\n  float C = vdot(rs, rs) - sphere->radius * sphere->radius;\n  float D = B * B - C;\n\n  if (D > 0.f) {\n    float t = -B - sqrtf(D);\n\n    if ((t > 0.f) && (t < isect->t)) {\n      isect->t = t;\n      isect->hit = 1;\n\n      isect->p.x = ray->org.x + ray->dir.x * t;\n      isect->p.y = ray->org.y + ray->dir.y * t;\n      isect->p.z = ray->org.z + ray->dir.z * t;\n\n      isect->n.x = isect->p.x - sphere->center.x;\n      isect->n.y = isect->p.y - sphere->center.y;\n      isect->n.z = isect->p.z - sphere->center.z;\n\n      vnormalize(&(isect->n));\n    }\n  }\n}\n\n  __device__\nvoid ray_plane_intersect(Isect *isect, const Ray *ray, const Plane *plane)\n{\n  float d = -vdot(plane->p, plane->n);\n  float v = vdot(ray->dir, plane->n);\n\n  if (fabsf(v) < 1.0e-17f) return;\n\n  float t = -(vdot(ray->org, plane->n) + d) / v;\n\n  if ((t > 0.f) && (t < isect->t)) {\n    isect->t = t;\n    isect->hit = 1;\n\n    isect->p.x = ray->org.x + ray->dir.x * t;\n    isect->p.y = ray->org.y + ray->dir.y * t;\n    isect->p.z = ray->org.z + ray->dir.z * t;\n\n    isect->n = plane->n;\n  }\n}\n\n  __device__\nvoid orthoBasis(vec *basis, vec n)\n{\n  basis[2] = n;\n  basis[1].x = 0.f; basis[1].y = 0.f; basis[1].z = 0.f;\n\n  if ((n.x < 0.6f) && (n.x > -0.6f)) {\n    basis[1].x = 1.0f;\n  } else if ((n.y < 0.6f) && (n.y > -0.6f)) {\n    basis[1].y = 1.0f;\n  } else if ((n.z < 0.6f) && (n.z > -0.6f)) {\n    basis[1].z = 1.0f;\n  } else {\n    basis[1].x = 1.0f;\n  }\n\n  vcross(&basis[0], basis[1], basis[2]);\n  vnormalize(&basis[0]);\n\n  vcross(&basis[1], basis[2], basis[0]);\n  vnormalize(&basis[1]);\n}\n\nclass RNG {\n  public:\n    unsigned int x;\n    const int fmask = (1 << 23) - 1;   \n    __device__\n      RNG(const unsigned int seed) { x = seed; }   \n    __device__\n      int next() {     \n        x ^= x >> 6;\n        x ^= x << 17;     \n        x ^= x >> 9;\n        return int(x);\n      }\n    __device__\n      float operator()(void) {\n        union {\n          float f;\n          int i;\n        } u;\n        u.i = (next() & fmask) | 0x3f800000;\n        return u.f - 1.f;\n      }\n};\n\n\n  __device__\nvoid ambient_occlusion(vec *col, const Isect *isect, const Sphere *spheres, const Plane *plane, RNG &rng)\n{\n  int    i, j;\n  int    ntheta = NAO_SAMPLES;\n  int    nphi   = NAO_SAMPLES;\n  float eps = 0.0001f;\n\n  vec p;\n\n  p.x = isect->p.x + eps * isect->n.x;\n  p.y = isect->p.y + eps * isect->n.y;\n  p.z = isect->p.z + eps * isect->n.z;\n\n  vec basis[3];\n  orthoBasis(basis, isect->n);\n\n\n  float occlusion = 0.f;\n\n  for (j = 0; j < ntheta; j++) {\n    for (i = 0; i < nphi; i++) {\n      float theta = sqrtf(rng());\n      float phi = 2.0f * (float)M_PI * rng();\n      float x = cosf(phi) * theta;\n      float y = sinf(phi) * theta;\n      float z = sqrtf(1.0f - theta * theta);\n\n      \n\n      float rx = x * basis[0].x + y * basis[1].x + z * basis[2].x;\n      float ry = x * basis[0].y + y * basis[1].y + z * basis[2].y;\n      float rz = x * basis[0].z + y * basis[1].z + z * basis[2].z;\n\n      Ray ray;\n\n      ray.org = p;\n      ray.dir.x = rx;\n      ray.dir.y = ry;\n      ray.dir.z = rz;\n\n      Isect occIsect;\n      occIsect.t   = 1.0e+17f;\n      occIsect.hit = 0;\n\n      ray_sphere_intersect(&occIsect, &ray, spheres); \n      ray_sphere_intersect(&occIsect, &ray, spheres+1); \n      ray_sphere_intersect(&occIsect, &ray, spheres+2); \n      ray_plane_intersect (&occIsect, &ray, plane); \n\n      if (occIsect.hit) occlusion += 1.f;\n\n    }\n  }\n\n  occlusion = (ntheta * nphi - occlusion) / (float)(ntheta * nphi);\n\n  col->x = occlusion;\n  col->y = occlusion;\n  col->z = occlusion;\n}\n\n  __device__\nunsigned char clamp(float f)\n{\n  int i = (int)(f * 255.5f);\n\n  if (i < 0) i = 0;\n  if (i > 255) i = 255;\n\n  return (unsigned char)i;\n}\n\n\nvoid init_scene(Sphere* spheres, Plane &plane)\n{\n  spheres[0].center.x = -2.0f;\n  spheres[0].center.y =  0.0f;\n  spheres[0].center.z = -3.5f;\n  spheres[0].radius = 0.5f;\n\n  spheres[1].center.x = -0.5f;\n  spheres[1].center.y =  0.0f;\n  spheres[1].center.z = -3.0f;\n  spheres[1].radius = 0.5f;\n\n  spheres[2].center.x =  1.0f;\n  spheres[2].center.y =  0.0f;\n  spheres[2].center.z = -2.2f;\n  spheres[2].radius = 0.5f;\n\n  plane.p.x = 0.0f;\n  plane.p.y = -0.5f;\n  plane.p.z = 0.0f;\n\n  plane.n.x = 0.0f;\n  plane.n.y = 1.0f;\n  plane.n.z = 0.0f;\n\n}\n\nvoid saveppm(const char *fname, int w, int h, unsigned char *img)\n{\n  FILE *fp;\n\n  fp = fopen(fname, \"wb\");\n  assert(fp);\n\n  fprintf(fp, \"P6\\n\");\n  fprintf(fp, \"%d %d\\n\", w, h);\n  fprintf(fp, \"255\\n\");\n  fwrite(img, w * h * 3, 1, fp);\n  fclose(fp);\n}\n\n  __global__ void\nrender_kernel (unsigned char *fimg, const Sphere *spheres, const Plane plane, \n    const int h, const int w, const int nsubsamples)\n{\n  int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n  if (y < h && x < w) {\n\n    RNG rng(y * w + x);\n    float s0 = 0;\n    float s1 = 0;\n    float s2 = 0;\n\n    for(int  v = 0; v < nsubsamples; v++ ) {\n      for(int  u = 0; u < nsubsamples; u++ ) {\n        float px = ( x + ( u / ( float )nsubsamples ) - ( w / 2.0f ) ) / ( w / 2.0f );\n        float py = -( y + ( v / ( float )nsubsamples ) - ( h / 2.0f ) ) / ( h / 2.0f );\n\n        Ray ray;\n        ray.org.x = 0.f;\n        ray.org.y = 0.f;\n        ray.org.z = 0.f;\n        ray.dir.x = px;\n        ray.dir.y = py;\n        ray.dir.z = -1.f;\n        vnormalize( &( ray.dir ) );\n\n        Isect isect;\n        isect.t = 1.0e+17f;\n        isect.hit = 0;\n\n        ray_sphere_intersect( &isect, &ray, spheres   );\n        ray_sphere_intersect( &isect, &ray, spheres + 1  );\n        ray_sphere_intersect( &isect, &ray, spheres + 2  );\n        ray_plane_intersect ( &isect, &ray, &plane );\n\n        if( isect.hit ) {\n          vec col;\n          ambient_occlusion( &col, &isect, spheres, &plane, rng );\n          s0 += col.x;\n          s1 += col.y;\n          s2 += col.z;\n        }\n\n      }\n    }\n    fimg[ 3 * ( y * w + x ) + 0 ] = clamp ( s0 / ( float )( nsubsamples * nsubsamples ) );\n    fimg[ 3 * ( y * w + x ) + 1 ] = clamp ( s1 / ( float )( nsubsamples * nsubsamples ) );\n    fimg[ 3 * ( y * w + x ) + 2 ] = clamp ( s2 / ( float )( nsubsamples * nsubsamples ) );\n  }\n}\n\n#ifdef DEBUG\n#define gpuErrchk(ans) gpuAssert((ans), __FILE__, __LINE__)\n\ninline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n{\n  if (code != cudaSuccess) \n  {\n    fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n    if (abort) exit(code);\n  }\n}\n#else\n#define gpuErrchk(ans) ans\n#endif\n\nvoid render(unsigned char *img, int w, int h, int nsubsamples, const Sphere* spheres, const Plane &plane)\n{\n  unsigned char *d_img;\n  Sphere *d_spheres;\n\n  gpuErrchk( cudaMalloc((void**)&d_img, sizeof(unsigned char) * w * h * 3) );\n  gpuErrchk( cudaMalloc((void**)&d_spheres, sizeof(Sphere) * 3) );\n  gpuErrchk( cudaMemcpy(d_spheres, spheres, sizeof(Sphere) * 3, cudaMemcpyHostToDevice) );\n\n  render_kernel <<< dim3((w+BLOCK_SIZE-1)/BLOCK_SIZE, (h+BLOCK_SIZE-1)/BLOCK_SIZE), \n                    dim3(BLOCK_SIZE, BLOCK_SIZE) >>> (d_img, d_spheres, plane, h, w, nsubsamples);\n\n#ifdef DEBUG\n  gpuErrchk( cudaPeekAtLastError() );\n#endif\n\n  gpuErrchk( cudaMemcpy(img, d_img, sizeof(unsigned char) * w * h * 3, cudaMemcpyDeviceToHost) );\n  cudaFree(d_img);\n  cudaFree(d_spheres);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  const int LOOPMAX = atoi(argv[1]);\n\n  \n\n  Sphere spheres[3];\n  Plane plane;\n\n  init_scene(spheres, plane);\n\n  unsigned char *img = ( unsigned char * )malloc( WIDTH * HEIGHT * 3 );\n\n  clock_t start;\n  start = clock();\n  for( int i = 0; i < LOOPMAX; ++i ){\n    render( img, WIDTH, HEIGHT, NSUBSAMPLES, spheres, plane );\n  }\n  clock_t end = clock();\n  float delta = ( float )end - ( float )start;\n  float msec = delta * 1000.0 / ( float )CLOCKS_PER_SEC;\n\n  printf( \"Total render time (%d iterations): %f sec.\\n\", LOOPMAX, msec / 1000.0 );\n  printf( \"Average render time: %f sec.\\n\", msec / 1000.0 / (float)LOOPMAX );\n\n  saveppm( \"ao.ppm\", WIDTH, HEIGHT, img );\n  free( img );\n\n  return 0;\n}\n"}}
{"kernel_name": "aobench", "parallel_api": "hip", "code": {"ao.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <assert.h>\n#include <math.h>\n#include <time.h>\n#include <hip/hip_runtime.h>\n\n#define WIDTH        256\n#define HEIGHT       256\n#define NSUBSAMPLES  2\n#define NAO_SAMPLES  8\n#define BLOCK_SIZE   16\n\ntypedef struct _vec\n{\n  float x;\n  float y;\n  float z;\n} vec;\n\n\ntypedef struct _Isect\n{\n  float t;\n  vec    p;\n  vec    n;\n  int    hit; \n} Isect;\n\ntypedef struct _Sphere\n{\n  vec    center;\n  float radius;\n\n} Sphere;\n\ntypedef struct _Plane\n{\n  vec    p;\n  vec    n;\n\n} Plane;\n\ntypedef struct _Ray\n{\n  vec    org;\n  vec    dir;\n} Ray;\n\n\n  __device__\nstatic float vdot(vec v0, vec v1)\n{\n  return v0.x * v1.x + v0.y * v1.y + v0.z * v1.z;\n}\n\n  __device__\nstatic void vcross(vec *c, vec v0, vec v1)\n{\n\n  c->x = v0.y * v1.z - v0.z * v1.y;\n  c->y = v0.z * v1.x - v0.x * v1.z;\n  c->z = v0.x * v1.y - v0.y * v1.x;\n}\n\n  __device__\nstatic void vnormalize(vec *c)\n{\n  float length = sqrtf(vdot((*c), (*c)));\n\n  if (fabs(length) > 1.0e-17f) {\n    c->x /= length;\n    c->y /= length;\n    c->z /= length;\n  }\n}\n\n  __device__\nvoid ray_sphere_intersect(Isect *isect, const Ray *ray, const Sphere *sphere)\n{\n  vec rs;\n\n  rs.x = ray->org.x - sphere->center.x;\n  rs.y = ray->org.y - sphere->center.y;\n  rs.z = ray->org.z - sphere->center.z;\n\n  float B = vdot(rs, ray->dir);\n  float C = vdot(rs, rs) - sphere->radius * sphere->radius;\n  float D = B * B - C;\n\n  if (D > 0.f) {\n    float t = -B - sqrtf(D);\n\n    if ((t > 0.f) && (t < isect->t)) {\n      isect->t = t;\n      isect->hit = 1;\n\n      isect->p.x = ray->org.x + ray->dir.x * t;\n      isect->p.y = ray->org.y + ray->dir.y * t;\n      isect->p.z = ray->org.z + ray->dir.z * t;\n\n      isect->n.x = isect->p.x - sphere->center.x;\n      isect->n.y = isect->p.y - sphere->center.y;\n      isect->n.z = isect->p.z - sphere->center.z;\n\n      vnormalize(&(isect->n));\n    }\n  }\n}\n\n  __device__\nvoid ray_plane_intersect(Isect *isect, const Ray *ray, const Plane *plane)\n{\n  float d = -vdot(plane->p, plane->n);\n  float v = vdot(ray->dir, plane->n);\n\n  if (fabsf(v) < 1.0e-17f) return;\n\n  float t = -(vdot(ray->org, plane->n) + d) / v;\n\n  if ((t > 0.f) && (t < isect->t)) {\n    isect->t = t;\n    isect->hit = 1;\n\n    isect->p.x = ray->org.x + ray->dir.x * t;\n    isect->p.y = ray->org.y + ray->dir.y * t;\n    isect->p.z = ray->org.z + ray->dir.z * t;\n\n    isect->n = plane->n;\n  }\n}\n\n  __device__\nvoid orthoBasis(vec *basis, vec n)\n{\n  basis[2] = n;\n  basis[1].x = 0.f; basis[1].y = 0.f; basis[1].z = 0.f;\n\n  if ((n.x < 0.6f) && (n.x > -0.6f)) {\n    basis[1].x = 1.0f;\n  } else if ((n.y < 0.6f) && (n.y > -0.6f)) {\n    basis[1].y = 1.0f;\n  } else if ((n.z < 0.6f) && (n.z > -0.6f)) {\n    basis[1].z = 1.0f;\n  } else {\n    basis[1].x = 1.0f;\n  }\n\n  vcross(&basis[0], basis[1], basis[2]);\n  vnormalize(&basis[0]);\n\n  vcross(&basis[1], basis[2], basis[0]);\n  vnormalize(&basis[1]);\n}\n\nclass RNG {\n  public:\n    unsigned int x;\n    const int fmask = (1 << 23) - 1;   \n    __device__\n      RNG(const unsigned int seed) { x = seed; }   \n    __device__\n      int next() {     \n        x ^= x >> 6;\n        x ^= x << 17;     \n        x ^= x >> 9;\n        return int(x);\n      }\n    __device__\n      float operator()(void) {\n        union {\n          float f;\n          int i;\n        } u;\n        u.i = (next() & fmask) | 0x3f800000;\n        return u.f - 1.f;\n      }\n};\n\n\n  __device__\nvoid ambient_occlusion(vec *col, const Isect *isect, const Sphere *spheres, const Plane *plane, RNG &rng)\n{\n  int    i, j;\n  int    ntheta = NAO_SAMPLES;\n  int    nphi   = NAO_SAMPLES;\n  float eps = 0.0001f;\n\n  vec p;\n\n  p.x = isect->p.x + eps * isect->n.x;\n  p.y = isect->p.y + eps * isect->n.y;\n  p.z = isect->p.z + eps * isect->n.z;\n\n  vec basis[3];\n  orthoBasis(basis, isect->n);\n\n\n  float occlusion = 0.f;\n\n  for (j = 0; j < ntheta; j++) {\n    for (i = 0; i < nphi; i++) {\n      float theta = sqrtf(rng());\n      float phi = 2.0f * (float)M_PI * rng();\n      float x = cosf(phi) * theta;\n      float y = sinf(phi) * theta;\n      float z = sqrtf(1.0f - theta * theta);\n\n      \n\n      float rx = x * basis[0].x + y * basis[1].x + z * basis[2].x;\n      float ry = x * basis[0].y + y * basis[1].y + z * basis[2].y;\n      float rz = x * basis[0].z + y * basis[1].z + z * basis[2].z;\n\n      Ray ray;\n\n      ray.org = p;\n      ray.dir.x = rx;\n      ray.dir.y = ry;\n      ray.dir.z = rz;\n\n      Isect occIsect;\n      occIsect.t   = 1.0e+17f;\n      occIsect.hit = 0;\n\n      ray_sphere_intersect(&occIsect, &ray, spheres); \n      ray_sphere_intersect(&occIsect, &ray, spheres+1); \n      ray_sphere_intersect(&occIsect, &ray, spheres+2); \n      ray_plane_intersect (&occIsect, &ray, plane); \n\n      if (occIsect.hit) occlusion += 1.f;\n\n    }\n  }\n\n  occlusion = (ntheta * nphi - occlusion) / (float)(ntheta * nphi);\n\n  col->x = occlusion;\n  col->y = occlusion;\n  col->z = occlusion;\n}\n\n  __device__\nunsigned char clamp(float f)\n{\n  int i = (int)(f * 255.5f);\n\n  if (i < 0) i = 0;\n  if (i > 255) i = 255;\n\n  return (unsigned char)i;\n}\n\n\nvoid init_scene(Sphere* spheres, Plane &plane)\n{\n  spheres[0].center.x = -2.0f;\n  spheres[0].center.y =  0.0f;\n  spheres[0].center.z = -3.5f;\n  spheres[0].radius = 0.5f;\n\n  spheres[1].center.x = -0.5f;\n  spheres[1].center.y =  0.0f;\n  spheres[1].center.z = -3.0f;\n  spheres[1].radius = 0.5f;\n\n  spheres[2].center.x =  1.0f;\n  spheres[2].center.y =  0.0f;\n  spheres[2].center.z = -2.2f;\n  spheres[2].radius = 0.5f;\n\n  plane.p.x = 0.0f;\n  plane.p.y = -0.5f;\n  plane.p.z = 0.0f;\n\n  plane.n.x = 0.0f;\n  plane.n.y = 1.0f;\n  plane.n.z = 0.0f;\n\n}\n\nvoid saveppm(const char *fname, int w, int h, unsigned char *img)\n{\n  FILE *fp;\n\n  fp = fopen(fname, \"wb\");\n  assert(fp);\n\n  fprintf(fp, \"P6\\n\");\n  fprintf(fp, \"%d %d\\n\", w, h);\n  fprintf(fp, \"255\\n\");\n  fwrite(img, w * h * 3, 1, fp);\n  fclose(fp);\n}\n\n  __global__ void\nrender_kernel (unsigned char *fimg, const Sphere *spheres, const Plane plane, \n    const int h, const int w, const int nsubsamples)\n{\n  int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n  if (y < h && x < w) {\n\n    RNG rng(y * w + x);\n    float s0 = 0.f;\n    float s1 = 0.f;\n    float s2 = 0.f;\n\n    for(int  v = 0; v < nsubsamples; v++ ) {\n      for(int  u = 0; u < nsubsamples; u++ ) {\n        float px = ( x + ( u / ( float )nsubsamples ) - ( w / 2.0f ) ) / ( w / 2.0f );\n        float py = -( y + ( v / ( float )nsubsamples ) - ( h / 2.0f ) ) / ( h / 2.0f );\n\n        Ray ray;\n        ray.org.x = 0.f;\n        ray.org.y = 0.f;\n        ray.org.z = 0.f;\n        ray.dir.x = px;\n        ray.dir.y = py;\n        ray.dir.z = -1.f;\n        vnormalize( &( ray.dir ) );\n\n        Isect isect;\n        isect.t = 1.0e+17f;\n        isect.hit = 0;\n\n        ray_sphere_intersect( &isect, &ray, spheres   );\n        ray_sphere_intersect( &isect, &ray, spheres + 1  );\n        ray_sphere_intersect( &isect, &ray, spheres + 2  );\n        ray_plane_intersect ( &isect, &ray, &plane );\n\n        if( isect.hit ) {\n          vec col;\n          ambient_occlusion( &col, &isect, spheres, &plane, rng );\n          s0 += col.x;\n          s1 += col.y;\n          s2 += col.z;\n        }\n\n      }\n    }\n    fimg[ 3 * ( y * w + x ) + 0 ] = clamp ( s0 / ( float )( nsubsamples * nsubsamples ) );\n    fimg[ 3 * ( y * w + x ) + 1 ] = clamp ( s1 / ( float )( nsubsamples * nsubsamples ) );\n    fimg[ 3 * ( y * w + x ) + 2 ] = clamp ( s2 / ( float )( nsubsamples * nsubsamples ) );\n  }\n}\n\n#ifdef DEBUG\n#define gpuErrchk(ans) gpuAssert((ans), __FILE__, __LINE__)\ninline void gpuAssert(hipError_t code, const char *file, int line, bool abort=true)\n{\n  if (code != hipSuccess) \n  {\n    fprintf(stderr,\"GPUassert: %s %s %d\\n\", hipGetErrorString(code), file, line);\n    if (abort) exit(code);\n  }\n}\n#else\n#define gpuErrchk(ans) ans\n#endif\n\nvoid render(unsigned char *img, int w, int h, int nsubsamples, const Sphere* spheres, const Plane &plane)\n{\n  unsigned char *d_img;\n  Sphere *d_spheres;\n\n  gpuErrchk( hipMalloc((void**)&d_img, sizeof(unsigned char) * w * h * 3) );\n  gpuErrchk( hipMalloc((void**)&d_spheres, sizeof(Sphere) * 3) );\n  gpuErrchk( hipMemcpy(d_spheres, spheres, sizeof(Sphere) * 3, hipMemcpyHostToDevice) );\n\n  hipLaunchKernelGGL(render_kernel, dim3((w+BLOCK_SIZE-1)/BLOCK_SIZE, (h+BLOCK_SIZE-1)/BLOCK_SIZE), \n                                    dim3(BLOCK_SIZE, BLOCK_SIZE), 0, 0, d_img, d_spheres, plane, h, w, nsubsamples);\n\n#ifdef DEBUG\n  gpuErrchk( hipPeekAtLastError() );\n#endif\n\n  gpuErrchk( hipMemcpy(img, d_img, sizeof(unsigned char) * w * h * 3, hipMemcpyDeviceToHost) );\n  hipFree(d_img);\n  hipFree(d_spheres);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  const int LOOPMAX = atoi(argv[1]);\n\n  \n\n  Sphere spheres[3];\n  Plane plane;\n\n  init_scene(spheres, plane);\n\n  unsigned char *img = ( unsigned char * )malloc( WIDTH * HEIGHT * 3 );\n\n  clock_t start;\n  start = clock();\n  for( int i = 0; i < LOOPMAX; ++i ){\n    render( img, WIDTH, HEIGHT, NSUBSAMPLES, spheres, plane );\n  }\n  clock_t end = clock();\n  float delta = ( float )end - ( float )start;\n  float msec = delta * 1000.0 / ( float )CLOCKS_PER_SEC;\n\n  printf( \"Total render time (%d iterations): %f sec.\\n\", LOOPMAX, msec / 1000.0 );\n  printf( \"Average render time: %f sec.\\n\", msec / 1000.0 / (float)LOOPMAX );\n\n  saveppm( \"ao.ppm\", WIDTH, HEIGHT, img );\n  free( img );\n\n  return 0;\n}\n"}}
{"kernel_name": "aobench", "parallel_api": "omp", "code": {"ao.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <assert.h>\n#include <math.h>\n#include <time.h>\n\n#define WIDTH        256\n#define HEIGHT       256\n#define NSUBSAMPLES  2\n#define NAO_SAMPLES  8\n#define BLOCK_SIZE   16\n\ntypedef struct _vec\n{\n  float x;\n  float y;\n  float z;\n} Vec;\n\n\ntypedef struct _Isect\n{\n  float t;\n  Vec    p;\n  Vec    n;\n  int    hit; \n} Isect;\n\ntypedef struct _Sphere\n{\n  Vec    center;\n  float radius;\n\n} Sphere;\n\ntypedef struct _Plane\n{\n  Vec    p;\n  Vec    n;\n\n} Plane;\n\ntypedef struct _Ray\n{\n  Vec    org;\n  Vec    dir;\n} Ray;\n\n\nstatic float vdot(Vec v0, Vec v1)\n{\n  return v0.x * v1.x + v0.y * v1.y + v0.z * v1.z;\n}\n\nstatic void vcross(Vec *c, Vec v0, Vec v1)\n{\n\n  c->x = v0.y * v1.z - v0.z * v1.y;\n  c->y = v0.z * v1.x - v0.x * v1.z;\n  c->z = v0.x * v1.y - v0.y * v1.x;\n}\n\n#pragma omp declare target\nstatic void vnormalize(Vec *c)\n{\n  float length = sqrtf(vdot((*c), (*c)));\n\n  if (fabsf(length) > 1.0e-17f) {\n    c->x /= length;\n    c->y /= length;\n    c->z /= length;\n  }\n}\n#pragma omp end declare target\n\n#pragma omp declare target\nvoid ray_sphere_intersect(Isect *isect, const Ray *ray, const Sphere *sphere)\n{\n  Vec rs;\n\n  rs.x = ray->org.x - sphere->center.x;\n  rs.y = ray->org.y - sphere->center.y;\n  rs.z = ray->org.z - sphere->center.z;\n\n  float B = vdot(rs, ray->dir);\n  float C = vdot(rs, rs) - sphere->radius * sphere->radius;\n  float D = B * B - C;\n\n  if (D > 0.f) {\n    float t = -B - sqrtf(D);\n\n    if ((t > 0.f) && (t < isect->t)) {\n      isect->t = t;\n      isect->hit = 1;\n\n      isect->p.x = ray->org.x + ray->dir.x * t;\n      isect->p.y = ray->org.y + ray->dir.y * t;\n      isect->p.z = ray->org.z + ray->dir.z * t;\n\n      isect->n.x = isect->p.x - sphere->center.x;\n      isect->n.y = isect->p.y - sphere->center.y;\n      isect->n.z = isect->p.z - sphere->center.z;\n\n      vnormalize(&(isect->n));\n    }\n  }\n}\n#pragma omp end declare target\n\n  \n#pragma omp declare target\nvoid ray_plane_intersect(Isect *isect, const Ray *ray, const Plane *plane)\n{\n  float d = -vdot(plane->p, plane->n);\n  float v = vdot(ray->dir, plane->n);\n\n  if (fabs(v) < 1.0e-17f) return;\n\n  float t = -(vdot(ray->org, plane->n) + d) / v;\n\n  if ((t > 0.f) && (t < isect->t)) {\n    isect->t = t;\n    isect->hit = 1;\n\n    isect->p.x = ray->org.x + ray->dir.x * t;\n    isect->p.y = ray->org.y + ray->dir.y * t;\n    isect->p.z = ray->org.z + ray->dir.z * t;\n\n    isect->n = plane->n;\n  }\n}\n#pragma omp end declare target\n\nvoid orthoBasis(Vec *basis, Vec n)\n{\n  basis[2] = n;\n  basis[1].x = 0.f; basis[1].y = 0.f; basis[1].z = 0.f;\n\n  if ((n.x < 0.6f) && (n.x > -0.6f)) {\n    basis[1].x = 1.0f;\n  } else if ((n.y < 0.6f) && (n.y > -0.6f)) {\n    basis[1].y = 1.0f;\n  } else if ((n.z < 0.6f) && (n.z > -0.6f)) {\n    basis[1].z = 1.0f;\n  } else {\n    basis[1].x = 1.0f;\n  }\n\n  vcross(&basis[0], basis[1], basis[2]);\n  vnormalize(&basis[0]);\n\n  vcross(&basis[1], basis[2], basis[0]);\n  vnormalize(&basis[1]);\n}\n\n#pragma omp declare target\nclass RNG {\n  public:\n    unsigned int x;\n    const int fmask = (1 << 23) - 1;   \n      RNG(const unsigned int seed) { x = seed; }   \n      int next() {     \n        x ^= x >> 6;\n        x ^= x << 17;     \n        x ^= x >> 9;\n        return int(x);\n      }\n      float operator()(void) {\n        union {\n          float f;\n          int i;\n        } u;\n        u.i = (next() & fmask) | 0x3f800000;\n        return u.f - 1.f;\n      }\n};\n#pragma omp end declare target\n\n\n#pragma omp declare target\nvoid ambient_occlusion(Vec *col, const Isect *isect, \n\t\t       const Sphere *spheres, const Plane *plane, RNG &rng)\n{\n  int    i, j;\n  int    ntheta = NAO_SAMPLES;\n  int    nphi   = NAO_SAMPLES;\n  float eps = 0.0001f;\n\n  Vec p;\n\n  p.x = isect->p.x + eps * isect->n.x;\n  p.y = isect->p.y + eps * isect->n.y;\n  p.z = isect->p.z + eps * isect->n.z;\n\n  Vec basis[3];\n  orthoBasis(basis, isect->n);\n\n\n  float occlusion = 0.0;\n\n  for (j = 0; j < ntheta; j++) {\n    for (i = 0; i < nphi; i++) {\n      float theta = sqrtf(rng());\n      float phi = 2.0f * (float)M_PI * rng();\n      float x = cosf(phi) * theta;\n      float y = sinf(phi) * theta;\n      float z = sqrtf(1.0f - theta * theta);\n\n      \n\n      float rx = x * basis[0].x + y * basis[1].x + z * basis[2].x;\n      float ry = x * basis[0].y + y * basis[1].y + z * basis[2].y;\n      float rz = x * basis[0].z + y * basis[1].z + z * basis[2].z;\n\n      Ray ray;\n\n      ray.org = p;\n      ray.dir.x = rx;\n      ray.dir.y = ry;\n      ray.dir.z = rz;\n\n      Isect occIsect;\n      occIsect.t   = 1.0e+17f;\n      occIsect.hit = 0;\n\n      ray_sphere_intersect(&occIsect, &ray, spheres); \n      ray_sphere_intersect(&occIsect, &ray, spheres+1); \n      ray_sphere_intersect(&occIsect, &ray, spheres+2); \n      ray_plane_intersect (&occIsect, &ray, plane); \n\n      if (occIsect.hit) occlusion += 1.f;\n\n    }\n  }\n\n  occlusion = (ntheta * nphi - occlusion) / (float)(ntheta * nphi);\n\n  col->x = occlusion;\n  col->y = occlusion;\n  col->z = occlusion;\n}\n#pragma omp end declare target\n\n  \n#pragma omp declare target\nunsigned char my_clamp(float f)\n{\n  int i = (int)(f * 255.5f);\n\n  if (i < 0) i = 0;\n  if (i > 255) i = 255;\n\n  return (unsigned char)i;\n}\n#pragma omp end declare target\n\n\nvoid init_scene(Sphere* spheres, Plane &plane)\n{\n  spheres[0].center.x = -2.0f;\n  spheres[0].center.y =  0.0f;\n  spheres[0].center.z = -3.5f;\n  spheres[0].radius = 0.5f;\n\n  spheres[1].center.x = -0.5f;\n  spheres[1].center.y =  0.0f;\n  spheres[1].center.z = -3.0f;\n  spheres[1].radius = 0.5f;\n\n  spheres[2].center.x =  1.0f;\n  spheres[2].center.y =  0.0f;\n  spheres[2].center.z = -2.2f;\n  spheres[2].radius = 0.5f;\n\n  plane.p.x = 0.0f;\n  plane.p.y = -0.5f;\n  plane.p.z = 0.0f;\n\n  plane.n.x = 0.0f;\n  plane.n.y = 1.0f;\n  plane.n.z = 0.0f;\n\n}\n\nvoid saveppm(const char *fname, int w, int h, unsigned char *img)\n{\n  FILE *fp;\n\n  fp = fopen(fname, \"wb\");\n  assert(fp);\n\n  fprintf(fp, \"P6\\n\");\n  fprintf(fp, \"%d %d\\n\", w, h);\n  fprintf(fp, \"255\\n\");\n  fwrite(img, w * h * 3, 1, fp);\n  fclose(fp);\n}\n\n\nvoid render(unsigned char *img, int w, int h, int nsubsamples, \n            const Sphere* spheres, const Plane &plane)\n{\n  #pragma omp target map(from: img[0:w*h*3]) map(to:spheres[0:3])\n  {\n  #pragma omp teams distribute parallel for simd collapse(2) thread_limit(256) \n  for (int x = 0; x < w; x++) \n    for (int y = 0; y < h; y++) {\n          RNG rng(y * w + x);\n          float s0 = 0;\n          float s1 = 0;\n          float s2 = 0;\n\n          for(int  v = 0; v < nsubsamples; v++ ) {\n            for(int  u = 0; u < nsubsamples; u++ ) {\n              float px = ( x + ( u / ( float )nsubsamples ) - ( w / 2.0f ) ) / ( w / 2.0f );\n              float py = -( y + ( v / ( float )nsubsamples ) - ( h / 2.0f ) ) / ( h / 2.0f );\n\n              Ray ray;\n              ray.org.x = 0.0;\n              ray.org.y = 0.0;\n              ray.org.z = 0.0;\n              ray.dir.x = px;\n              ray.dir.y = py;\n              ray.dir.z = -1.0;\n              vnormalize( &( ray.dir ) );\n\n              Isect isect;\n              isect.t = 1.0e+17f;\n              isect.hit = 0;\n\n              ray_sphere_intersect( &isect, &ray, spheres   );\n              ray_sphere_intersect( &isect, &ray, spheres + 1  );\n              ray_sphere_intersect( &isect, &ray, spheres + 2  );\n              ray_plane_intersect ( &isect, &ray, &plane );\n\n              if( isect.hit ) {\n                Vec col;\n                ambient_occlusion( &col, &isect, spheres, &plane, rng );\n                s0 += col.x;\n                s1 += col.y;\n                s2 += col.z;\n              }\n            }\n          }\n          img[ 3 * ( y * w + x ) + 0 ] = my_clamp ( s0 / ( float )( nsubsamples * nsubsamples ) );\n          img[ 3 * ( y * w + x ) + 1 ] = my_clamp ( s1 / ( float )( nsubsamples * nsubsamples ) );\n          img[ 3 * ( y * w + x ) + 2 ] = my_clamp ( s2 / ( float )( nsubsamples * nsubsamples ) );\n        }\n     }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  const int LOOPMAX = atoi(argv[1]);\n\n  \n\n  Sphere spheres[3];\n  Plane plane;\n\n  init_scene(spheres, plane);\n\n  unsigned char *img = ( unsigned char * )malloc( WIDTH * HEIGHT * 3 );\n\n  clock_t start;\n  start = clock();\n  for( int i = 0; i < LOOPMAX; ++i ){\n    render( img, WIDTH, HEIGHT, NSUBSAMPLES, spheres, plane );\n  }\n  clock_t end = clock();\n  float delta = ( float )end - ( float )start;\n  float msec = delta * 1000.0 / ( float )CLOCKS_PER_SEC;\n\n  printf( \"Total render time (%d iterations): %f sec.\\n\", LOOPMAX, msec / 1000.0 );\n  printf( \"Average render time: %f sec.\\n\", msec / 1000.0 / (float)LOOPMAX );\n\n  saveppm( \"ao.ppm\", WIDTH, HEIGHT, img );\n  free( img );\n\n  return 0;\n}\n"}}
{"kernel_name": "aobench", "parallel_api": "serial", "code": {"ao.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <assert.h>\n#include <math.h>\n#include <time.h>\n\n#define WIDTH        256\n#define HEIGHT       256\n#define NSUBSAMPLES  2\n#define NAO_SAMPLES  8\n#define BLOCK_SIZE   16\n\ntypedef struct _vec\n{\n  float x;\n  float y;\n  float z;\n} Vec;\n\n\ntypedef struct _Isect\n{\n  float t;\n  Vec    p;\n  Vec    n;\n  int    hit; \n} Isect;\n\ntypedef struct _Sphere\n{\n  Vec    center;\n  float radius;\n\n} Sphere;\n\ntypedef struct _Plane\n{\n  Vec    p;\n  Vec    n;\n\n} Plane;\n\ntypedef struct _Ray\n{\n  Vec    org;\n  Vec    dir;\n} Ray;\n\n\nstatic float vdot(Vec v0, Vec v1)\n{\n  return v0.x * v1.x + v0.y * v1.y + v0.z * v1.z;\n}\n\nstatic void vcross(Vec *c, Vec v0, Vec v1)\n{\n\n  c->x = v0.y * v1.z - v0.z * v1.y;\n  c->y = v0.z * v1.x - v0.x * v1.z;\n  c->z = v0.x * v1.y - v0.y * v1.x;\n}\n\nstatic void vnormalize(Vec *c)\n{\n  float length = sqrtf(vdot((*c), (*c)));\n\n  if (fabsf(length) > 1.0e-17f) {\n    c->x /= length;\n    c->y /= length;\n    c->z /= length;\n  }\n}\n\nvoid ray_sphere_intersect(Isect *isect, const Ray *ray, const Sphere *sphere)\n{\n  Vec rs;\n\n  rs.x = ray->org.x - sphere->center.x;\n  rs.y = ray->org.y - sphere->center.y;\n  rs.z = ray->org.z - sphere->center.z;\n\n  float B = vdot(rs, ray->dir);\n  float C = vdot(rs, rs) - sphere->radius * sphere->radius;\n  float D = B * B - C;\n\n  if (D > 0.f) {\n    float t = -B - sqrtf(D);\n\n    if ((t > 0.f) && (t < isect->t)) {\n      isect->t = t;\n      isect->hit = 1;\n\n      isect->p.x = ray->org.x + ray->dir.x * t;\n      isect->p.y = ray->org.y + ray->dir.y * t;\n      isect->p.z = ray->org.z + ray->dir.z * t;\n\n      isect->n.x = isect->p.x - sphere->center.x;\n      isect->n.y = isect->p.y - sphere->center.y;\n      isect->n.z = isect->p.z - sphere->center.z;\n\n      vnormalize(&(isect->n));\n    }\n  }\n}\n\n  \nvoid ray_plane_intersect(Isect *isect, const Ray *ray, const Plane *plane)\n{\n  float d = -vdot(plane->p, plane->n);\n  float v = vdot(ray->dir, plane->n);\n\n  if (fabs(v) < 1.0e-17f) return;\n\n  float t = -(vdot(ray->org, plane->n) + d) / v;\n\n  if ((t > 0.f) && (t < isect->t)) {\n    isect->t = t;\n    isect->hit = 1;\n\n    isect->p.x = ray->org.x + ray->dir.x * t;\n    isect->p.y = ray->org.y + ray->dir.y * t;\n    isect->p.z = ray->org.z + ray->dir.z * t;\n\n    isect->n = plane->n;\n  }\n}\n\nvoid orthoBasis(Vec *basis, Vec n)\n{\n  basis[2] = n;\n  basis[1].x = 0.f; basis[1].y = 0.f; basis[1].z = 0.f;\n\n  if ((n.x < 0.6f) && (n.x > -0.6f)) {\n    basis[1].x = 1.0f;\n  } else if ((n.y < 0.6f) && (n.y > -0.6f)) {\n    basis[1].y = 1.0f;\n  } else if ((n.z < 0.6f) && (n.z > -0.6f)) {\n    basis[1].z = 1.0f;\n  } else {\n    basis[1].x = 1.0f;\n  }\n\n  vcross(&basis[0], basis[1], basis[2]);\n  vnormalize(&basis[0]);\n\n  vcross(&basis[1], basis[2], basis[0]);\n  vnormalize(&basis[1]);\n}\n\nclass RNG {\n  public:\n    unsigned int x;\n    const int fmask = (1 << 23) - 1;   \n      RNG(const unsigned int seed) { x = seed; }   \n      int next() {     \n        x ^= x >> 6;\n        x ^= x << 17;     \n        x ^= x >> 9;\n        return int(x);\n      }\n      float operator()(void) {\n        union {\n          float f;\n          int i;\n        } u;\n        u.i = (next() & fmask) | 0x3f800000;\n        return u.f - 1.f;\n      }\n};\n\n\nvoid ambient_occlusion(Vec *col, const Isect *isect, \n\t\t       const Sphere *spheres, const Plane *plane, RNG &rng)\n{\n  int    i, j;\n  int    ntheta = NAO_SAMPLES;\n  int    nphi   = NAO_SAMPLES;\n  float eps = 0.0001f;\n\n  Vec p;\n\n  p.x = isect->p.x + eps * isect->n.x;\n  p.y = isect->p.y + eps * isect->n.y;\n  p.z = isect->p.z + eps * isect->n.z;\n\n  Vec basis[3];\n  orthoBasis(basis, isect->n);\n\n\n  float occlusion = 0.0;\n\n  for (j = 0; j < ntheta; j++) {\n    for (i = 0; i < nphi; i++) {\n      float theta = sqrtf(rng());\n      float phi = 2.0f * (float)M_PI * rng();\n      float x = cosf(phi) * theta;\n      float y = sinf(phi) * theta;\n      float z = sqrtf(1.0f - theta * theta);\n\n      \n\n      float rx = x * basis[0].x + y * basis[1].x + z * basis[2].x;\n      float ry = x * basis[0].y + y * basis[1].y + z * basis[2].y;\n      float rz = x * basis[0].z + y * basis[1].z + z * basis[2].z;\n\n      Ray ray;\n\n      ray.org = p;\n      ray.dir.x = rx;\n      ray.dir.y = ry;\n      ray.dir.z = rz;\n\n      Isect occIsect;\n      occIsect.t   = 1.0e+17f;\n      occIsect.hit = 0;\n\n      ray_sphere_intersect(&occIsect, &ray, spheres); \n      ray_sphere_intersect(&occIsect, &ray, spheres+1); \n      ray_sphere_intersect(&occIsect, &ray, spheres+2); \n      ray_plane_intersect (&occIsect, &ray, plane); \n\n      if (occIsect.hit) occlusion += 1.f;\n\n    }\n  }\n\n  occlusion = (ntheta * nphi - occlusion) / (float)(ntheta * nphi);\n\n  col->x = occlusion;\n  col->y = occlusion;\n  col->z = occlusion;\n}\n\n  \nunsigned char my_clamp(float f)\n{\n  int i = (int)(f * 255.5f);\n\n  if (i < 0) i = 0;\n  if (i > 255) i = 255;\n\n  return (unsigned char)i;\n}\n\n\nvoid init_scene(Sphere* spheres, Plane &plane)\n{\n  spheres[0].center.x = -2.0f;\n  spheres[0].center.y =  0.0f;\n  spheres[0].center.z = -3.5f;\n  spheres[0].radius = 0.5f;\n\n  spheres[1].center.x = -0.5f;\n  spheres[1].center.y =  0.0f;\n  spheres[1].center.z = -3.0f;\n  spheres[1].radius = 0.5f;\n\n  spheres[2].center.x =  1.0f;\n  spheres[2].center.y =  0.0f;\n  spheres[2].center.z = -2.2f;\n  spheres[2].radius = 0.5f;\n\n  plane.p.x = 0.0f;\n  plane.p.y = -0.5f;\n  plane.p.z = 0.0f;\n\n  plane.n.x = 0.0f;\n  plane.n.y = 1.0f;\n  plane.n.z = 0.0f;\n\n}\n\nvoid saveppm(const char *fname, int w, int h, unsigned char *img)\n{\n  FILE *fp;\n\n  fp = fopen(fname, \"wb\");\n  assert(fp);\n\n  fprintf(fp, \"P6\\n\");\n  fprintf(fp, \"%d %d\\n\", w, h);\n  fprintf(fp, \"255\\n\");\n  fwrite(img, w * h * 3, 1, fp);\n  fclose(fp);\n}\n\n\nvoid render(unsigned char *img, int w, int h, int nsubsamples, \n            const Sphere* spheres, const Plane &plane)\n{\n    {\n    for (int x = 0; x < w; x++) \n    for (int y = 0; y < h; y++) {\n          RNG rng(y * w + x);\n          float s0 = 0;\n          float s1 = 0;\n          float s2 = 0;\n\n          for(int  v = 0; v < nsubsamples; v++ ) {\n            for(int  u = 0; u < nsubsamples; u++ ) {\n              float px = ( x + ( u / ( float )nsubsamples ) - ( w / 2.0f ) ) / ( w / 2.0f );\n              float py = -( y + ( v / ( float )nsubsamples ) - ( h / 2.0f ) ) / ( h / 2.0f );\n\n              Ray ray;\n              ray.org.x = 0.0;\n              ray.org.y = 0.0;\n              ray.org.z = 0.0;\n              ray.dir.x = px;\n              ray.dir.y = py;\n              ray.dir.z = -1.0;\n              vnormalize( &( ray.dir ) );\n\n              Isect isect;\n              isect.t = 1.0e+17f;\n              isect.hit = 0;\n\n              ray_sphere_intersect( &isect, &ray, spheres   );\n              ray_sphere_intersect( &isect, &ray, spheres + 1  );\n              ray_sphere_intersect( &isect, &ray, spheres + 2  );\n              ray_plane_intersect ( &isect, &ray, &plane );\n\n              if( isect.hit ) {\n                Vec col;\n                ambient_occlusion( &col, &isect, spheres, &plane, rng );\n                s0 += col.x;\n                s1 += col.y;\n                s2 += col.z;\n              }\n            }\n          }\n          img[ 3 * ( y * w + x ) + 0 ] = my_clamp ( s0 / ( float )( nsubsamples * nsubsamples ) );\n          img[ 3 * ( y * w + x ) + 1 ] = my_clamp ( s1 / ( float )( nsubsamples * nsubsamples ) );\n          img[ 3 * ( y * w + x ) + 2 ] = my_clamp ( s2 / ( float )( nsubsamples * nsubsamples ) );\n        }\n     }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  const int LOOPMAX = atoi(argv[1]);\n\n  \n\n  Sphere spheres[3];\n  Plane plane;\n\n  init_scene(spheres, plane);\n\n  unsigned char *img = ( unsigned char * )malloc( WIDTH * HEIGHT * 3 );\n\n  clock_t start;\n  start = clock();\n  for( int i = 0; i < LOOPMAX; ++i ){\n    render( img, WIDTH, HEIGHT, NSUBSAMPLES, spheres, plane );\n  }\n  clock_t end = clock();\n  float delta = ( float )end - ( float )start;\n  float msec = delta * 1000.0 / ( float )CLOCKS_PER_SEC;\n\n  printf( \"Total render time (%d iterations): %f sec.\\n\", LOOPMAX, msec / 1000.0 );\n  printf( \"Average render time: %f sec.\\n\", msec / 1000.0 / (float)LOOPMAX );\n\n  saveppm( \"ao.ppm\", WIDTH, HEIGHT, img );\n  free( img );\n\n  return 0;\n}"}}
{"kernel_name": "aobench", "parallel_api": "sycl", "code": {"Makefile.hipsycl": "#===============================================================================\n# User Options\n#===============================================================================\n\n# Compiler can be set below, or via environment variable\nCC        = syclcc\nOPTIMIZE  = yes\nDEBUG     = no\nMARCH     = gfx906\nPLATFORM  = rocm\nDEVICE    = gpu\n\n#===============================================================================\n# Program name & source code list\n#===============================================================================\n\nprogram = ao\n\nsource = ao.cpp\n\nobj = $(source:.cpp=.o)\n\n#===============================================================================\n# Sets Flags\n#===============================================================================\n\n# Standard Flags\nCFLAGS := $(EXTRA_CFLAGS) -Wall -I../include \\\n          --hipsycl-platform=$(PLATFORM) \\\n\t  --hipsycl-gpu-arch=$(MARCH)\n\n# Linker Flags\nLDFLAGS = \n\n# Debug Flags\nifeq ($(DEBUG),yes)\n  CFLAGS += -g\n  LDFLAGS  += -g\nendif\n\n\n# Optimization Flags\nifeq ($(OPTIMIZE),yes)\n  CFLAGS += -O3\nendif\n\n\nifeq ($(DEVICE),gpu)\n  CFLAGS +=-DUSE_GPU\nendif\n#===============================================================================\n# Targets to Build\n#===============================================================================\n\n$(program): $(obj) Makefile\n\t$(CC) $(CFLAGS) $(obj) -o $@ $(LDFLAGS)\n\n%.o: %.cpp Makefile\n\t$(CC) $(CFLAGS) -c $< -o $@\n\nclean:\n\trm -rf $(program) $(obj)\n\nrun: $(program)\n\t./$(program) \n", "ao.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <assert.h>\n#include <math.h>\n#include <time.h>\n#include <sycl/sycl.hpp>\n\n#define WIDTH        256\n#define HEIGHT       256\n#define NSUBSAMPLES  2\n#define NAO_SAMPLES  8\n#define BLOCK_SIZE   16\n\ntypedef struct _vec\n{\n  float x;\n  float y;\n  float z;\n} Vec;\n\n\ntypedef struct _Isect\n{\n  float t;\n  Vec    p;\n  Vec    n;\n  int    hit; \n} Isect;\n\ntypedef struct _Sphere\n{\n  Vec    center;\n  float radius;\n\n} Sphere;\n\ntypedef struct _Plane\n{\n  Vec    p;\n  Vec    n;\n\n} Plane;\n\ntypedef struct _Ray\n{\n  Vec    org;\n  Vec    dir;\n} Ray;\n\n\nstatic float vdot(Vec v0, Vec v1)\n{\n  return v0.x * v1.x + v0.y * v1.y + v0.z * v1.z;\n}\n\nstatic void vcross(Vec *c, Vec v0, Vec v1)\n{\n\n  c->x = v0.y * v1.z - v0.z * v1.y;\n  c->y = v0.z * v1.x - v0.x * v1.z;\n  c->z = v0.x * v1.y - v0.y * v1.x;\n}\n\nstatic void vnormalize(Vec *c)\n{\n  float length = sycl::sqrt(vdot((*c), (*c)));\n\n  if (sycl::fabs(length) > 1.0e-17f) {\n    c->x /= length;\n    c->y /= length;\n    c->z /= length;\n  }\n}\n\nvoid ray_sphere_intersect(Isect *isect, const Ray *ray, const Sphere *sphere)\n{\n  Vec rs;\n\n  rs.x = ray->org.x - sphere->center.x;\n  rs.y = ray->org.y - sphere->center.y;\n  rs.z = ray->org.z - sphere->center.z;\n\n  float B = vdot(rs, ray->dir);\n  float C = vdot(rs, rs) - sphere->radius * sphere->radius;\n  float D = B * B - C;\n\n  if (D > 0.0) {\n    float t = -B - sycl::sqrt(D);\n\n    if ((t > 0.0) && (t < isect->t)) {\n      isect->t = t;\n      isect->hit = 1;\n\n      isect->p.x = ray->org.x + ray->dir.x * t;\n      isect->p.y = ray->org.y + ray->dir.y * t;\n      isect->p.z = ray->org.z + ray->dir.z * t;\n\n      isect->n.x = isect->p.x - sphere->center.x;\n      isect->n.y = isect->p.y - sphere->center.y;\n      isect->n.z = isect->p.z - sphere->center.z;\n\n      vnormalize(&(isect->n));\n    }\n  }\n}\n\n  \nvoid ray_plane_intersect(Isect *isect, const Ray *ray, const Plane *plane)\n{\n  float d = -vdot(plane->p, plane->n);\n  float v = vdot(ray->dir, plane->n);\n\n  if (sycl::fabs(v) < 1.0e-17f) return;\n\n  float t = -(vdot(ray->org, plane->n) + d) / v;\n\n  if ((t > 0.f) && (t < isect->t)) {\n    isect->t = t;\n    isect->hit = 1;\n\n    isect->p.x = ray->org.x + ray->dir.x * t;\n    isect->p.y = ray->org.y + ray->dir.y * t;\n    isect->p.z = ray->org.z + ray->dir.z * t;\n\n    isect->n = plane->n;\n  }\n}\n\nvoid orthoBasis(Vec *basis, Vec n)\n{\n  basis[2] = n;\n  basis[1].x = 0.f; basis[1].y = 0.f; basis[1].z = 0.f;\n\n  if ((n.x < 0.6f) && (n.x > -0.6f)) {\n    basis[1].x = 1.0f;\n  } else if ((n.y < 0.6f) && (n.y > -0.6f)) {\n    basis[1].y = 1.0f;\n  } else if ((n.z < 0.6f) && (n.z > -0.6f)) {\n    basis[1].z = 1.0f;\n  } else {\n    basis[1].x = 1.0f;\n  }\n\n  vcross(&basis[0], basis[1], basis[2]);\n  vnormalize(&basis[0]);\n\n  vcross(&basis[1], basis[2], basis[0]);\n  vnormalize(&basis[1]);\n}\n\nclass RNG {\n  public:\n    unsigned int x;\n    const int fmask = (1 << 23) - 1;   \n      RNG(const unsigned int seed) { x = seed; }   \n      int next() {     \n        x ^= x >> 6;\n        x ^= x << 17;     \n        x ^= x >> 9;\n        return int(x);\n      }\n      float operator()(void) {\n        union {\n          float f;\n          int i;\n        } u;\n        u.i = (next() & fmask) | 0x3f800000;\n        return u.f - 1.f;\n      }\n};\n\n\nvoid ambient_occlusion(Vec *col, const Isect *isect, \n\t\t       Sphere *spheres, const Plane *plane, RNG &rng)\n{\n  int    i, j;\n  int    ntheta = NAO_SAMPLES;\n  int    nphi   = NAO_SAMPLES;\n  float eps = 0.0001f;\n\n  Vec p;\n\n  p.x = isect->p.x + eps * isect->n.x;\n  p.y = isect->p.y + eps * isect->n.y;\n  p.z = isect->p.z + eps * isect->n.z;\n\n  Vec basis[3];\n  orthoBasis(basis, isect->n);\n\n\n  float occlusion = 0.f;\n\n  for (j = 0; j < ntheta; j++) {\n    for (i = 0; i < nphi; i++) {\n      float theta = sycl::sqrt(rng());\n      float phi = 2.0f * (float)M_PI * rng();\n      float x = sycl::cos(phi) * theta;\n      float y = sycl::sin(phi) * theta;\n      float z = sycl::sqrt(1.0f - theta * theta);\n\n      \n\n      float rx = x * basis[0].x + y * basis[1].x + z * basis[2].x;\n      float ry = x * basis[0].y + y * basis[1].y + z * basis[2].y;\n      float rz = x * basis[0].z + y * basis[1].z + z * basis[2].z;\n\n      Ray ray;\n\n      ray.org = p;\n      ray.dir.x = rx;\n      ray.dir.y = ry;\n      ray.dir.z = rz;\n\n      Isect occIsect;\n      occIsect.t   = 1.0e+17f;\n      occIsect.hit = 0;\n\n      ray_sphere_intersect(&occIsect, &ray, spheres); \n      ray_sphere_intersect(&occIsect, &ray, spheres+1); \n      ray_sphere_intersect(&occIsect, &ray, spheres+2); \n      ray_plane_intersect (&occIsect, &ray, plane); \n\n      if (occIsect.hit) occlusion += 1.f;\n\n    }\n  }\n\n  occlusion = (ntheta * nphi - occlusion) / (float)(ntheta * nphi);\n\n  col->x = occlusion;\n  col->y = occlusion;\n  col->z = occlusion;\n}\n\n  \nunsigned char my_clamp(float f)\n{\n  int i = (int)(f * 255.5f);\n\n  if (i < 0) i = 0;\n  if (i > 255) i = 255;\n\n  return (unsigned char)i;\n}\n\n\nvoid init_scene(Sphere* spheres, Plane &plane)\n{\n  spheres[0].center.x = -2.0f;\n  spheres[0].center.y =  0.0f;\n  spheres[0].center.z = -3.5f;\n  spheres[0].radius = 0.5f;\n\n  spheres[1].center.x = -0.5f;\n  spheres[1].center.y =  0.0f;\n  spheres[1].center.z = -3.0f;\n  spheres[1].radius = 0.5f;\n\n  spheres[2].center.x =  1.0f;\n  spheres[2].center.y =  0.0f;\n  spheres[2].center.z = -2.2f;\n  spheres[2].radius = 0.5f;\n\n  plane.p.x = 0.0f;\n  plane.p.y = -0.5f;\n  plane.p.z = 0.0f;\n\n  plane.n.x = 0.0f;\n  plane.n.y = 1.0f;\n  plane.n.z = 0.0f;\n\n}\n\nvoid saveppm(const char *fname, int w, int h, unsigned char *img)\n{\n  FILE *fp;\n\n  fp = fopen(fname, \"wb\");\n  assert(fp);\n\n  fprintf(fp, \"P6\\n\");\n  fprintf(fp, \"%d %d\\n\", w, h);\n  fprintf(fp, \"255\\n\");\n  fwrite(img, w * h * 3, 1, fp);\n  fclose(fp);\n}\n\n\nvoid render(sycl::queue &q, unsigned char *img, int w, int h, int nsubsamples, \n            const Sphere* spheres, const Plane &plane)\n{\n  unsigned char *d_img = sycl::malloc_device<unsigned char>(w * h * 3, q);\n  q.memcpy(d_img, img, sizeof(unsigned char) * w * h * 3);\n\n  Sphere *d_spheres = sycl::malloc_device<Sphere>(3, q);\n  q.memcpy(d_spheres, spheres, sizeof(Sphere) * 3);\n\n  sycl::range<2> gws ((h+BLOCK_SIZE-1)/BLOCK_SIZE*BLOCK_SIZE,\n                      (w+BLOCK_SIZE-1)/BLOCK_SIZE*BLOCK_SIZE);\n  sycl::range<2> lws (BLOCK_SIZE, BLOCK_SIZE);\n\n  q.submit([&](sycl::handler& cgh) {\n    cgh.parallel_for<class render_kernel>(\n      sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        int x = item.get_global_id(1);\n        int y = item.get_global_id(0);\n        if (y < h && x < w) {\n\n          RNG rng(y * w + x);\n          float s0 = 0.f;\n          float s1 = 0.f;\n          float s2 = 0.f;\n\n          for(int  v = 0; v < nsubsamples; v++ ) {\n            for(int  u = 0; u < nsubsamples; u++ ) {\n              float px = ( x + ( u / ( float )nsubsamples ) - ( w / 2.0f ) ) / ( w / 2.0f );\n              float py = -( y + ( v / ( float )nsubsamples ) - ( h / 2.0f ) ) / ( h / 2.0f );\n\n              Ray ray;\n              ray.org.x = 0.f;\n              ray.org.y = 0.f;\n              ray.org.z = 0.f;\n              ray.dir.x = px;\n              ray.dir.y = py;\n              ray.dir.z = -1.f;\n              vnormalize( &( ray.dir ) );\n\n              Isect isect;\n              isect.t = 1.0e+17f;\n              isect.hit = 0;\n\n              ray_sphere_intersect( &isect, &ray, d_spheres   );\n              ray_sphere_intersect( &isect, &ray, d_spheres + 1  );\n              ray_sphere_intersect( &isect, &ray, d_spheres + 2  );\n              ray_plane_intersect ( &isect, &ray, &plane );\n\n              if( isect.hit ) {\n                Vec col;\n                ambient_occlusion( &col, &isect, d_spheres, &plane, rng );\n                s0 += col.x;\n                s1 += col.y;\n                s2 += col.z;\n              }\n            }\n          }\n          d_img[ 3 * ( y * w + x ) + 0 ] = my_clamp ( s0 / ( float )( nsubsamples * nsubsamples ) );\n          d_img[ 3 * ( y * w + x ) + 1 ] = my_clamp ( s1 / ( float )( nsubsamples * nsubsamples ) );\n          d_img[ 3 * ( y * w + x ) + 2 ] = my_clamp ( s2 / ( float )( nsubsamples * nsubsamples ) );\n        }\n     });\n  });\n\n  q.memcpy(img, d_img, sizeof(unsigned char) * w * h * 3).wait();\n  sycl::free(d_img, q);\n  sycl::free(d_spheres, q);\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n  const int LOOPMAX = atoi(argv[1]);\n\n  \n\n  Sphere spheres[3];\n  Plane plane;\n\n  init_scene(spheres, plane);\n\n  unsigned char *img = ( unsigned char * )malloc( WIDTH * HEIGHT * 3 );\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  clock_t start;\n  start = clock();\n  for( int i = 0; i < LOOPMAX; ++i ){\n    render( q, img, WIDTH, HEIGHT, NSUBSAMPLES, spheres, plane );\n  }\n  clock_t end = clock();\n  float delta = ( float )end - ( float )start;\n  float msec = delta * 1000.0 / ( float )CLOCKS_PER_SEC;\n\n  printf( \"Total render time (%d iterations): %f sec.\\n\", LOOPMAX, msec / 1000.0 );\n  printf( \"Average render time: %f sec.\\n\", msec / 1000.0 / (float)LOOPMAX );\n\n  saveppm( \"ao.ppm\", WIDTH, HEIGHT, img );\n  free( img );\n\n  return 0;\n}\n"}}
{"kernel_name": "asmooth", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n#include \"reference.cpp\"\n\n__global__ void smoothingFilter(\n    int Lx, int Ly, \n    int Threshold, int MaxRad, \n    const float*__restrict__ Img,\n            int*__restrict__ Box,\n          float*__restrict__ Norm)\n{\n  int tid = threadIdx.x;\n  int tjd = threadIdx.y;\n  int i = blockIdx.x * blockDim.x + tid;\n  int j = blockIdx.y * blockDim.y + tjd;\n  int stid = tjd * blockDim.x + tid;\n  int gtid = j * Lx + i;  \n\n  \n\n  __shared__ float s_Img[1024];\n\n  if ( i < Lx && j < Ly )\n    s_Img[stid] = Img[gtid];\n\n  __syncthreads();\n\n  if ( i < Lx && j < Ly )\n  {\n    \n\n    float sum = 0.f;\n    int q = 1;\n    int s = q;\n    int ksum = 0;\n\n    \n\n    while (sum < Threshold && q < MaxRad)\n    {\n      s = q;\n      sum = 0.f;\n      ksum = 0;\n\n      \n\n      for (int ii = -s; ii < s+1; ii++)\n        for (int jj = -s; jj < s+1; jj++)\n          if ( (i-s >= 0) && (i+s < Ly) && (j-s >= 0) && (j+s < Lx) )\n          {\n            ksum++;\n            \n\n            if( tid-s >= 0 && tid+s < blockDim.x && tjd-s >= 0 && tjd+s < blockDim.y )\n              sum += s_Img[stid + ii*blockDim.x + jj];\n            \n\n            else\n              sum += Img[gtid + ii*Lx + jj];\n          }\n      q++;\n    }\n    Box[gtid] = s;\n\n    \n\n    for (int ii = -s; ii < s+1; ii++)\n      for (int jj = -s; jj < s+1; jj++)\n        if (ksum != 0) \n          atomicAdd(&Norm[gtid + ii*Lx + jj], __fdividef(1.f, (float)ksum));\n  }\n}\n\n__global__ void normalizeFilter(\n    int Lx, int Ly, \n          float*__restrict__ Img,\n    const float*__restrict__ Norm)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  if ( i < Lx && j < Ly ) {\n    int gtid = j * Lx + i;  \n    const float norm = Norm[gtid];\n    if (norm != 0) Img[gtid] = __fdividef(Img[gtid], norm);\n  }\n}\n\n__global__ void outFilter( \n    int Lx, int Ly,\n    const float*__restrict__ Img,\n    const   int*__restrict__ Box,\n          float*__restrict__ Out )\n{\n  int tid = threadIdx.x;\n  int tjd = threadIdx.y;\n  int i = blockIdx.x * blockDim.x + tid;\n  int j = blockIdx.y * blockDim.y + tjd;\n  int stid = tjd * blockDim.x + tid;\n  int gtid = j * Lx + i;  \n\n  \n\n  __shared__ float s_Img[1024];\n\n  if ( i < Lx && j < Ly )\n    s_Img[stid] = Img[gtid];\n\n  __syncthreads();\n\n  if ( i < Lx && j < Ly )\n  {\n    const int s = Box[gtid];\n    float sum = 0.f;\n    int ksum  = 0;\n\n    for (int ii = -s; ii < s+1; ii++)\n      for (int jj = -s; jj < s+1; jj++)\n        if ( (i-s >= 0) && (i+s < Lx) && (j-s >= 0) && (j+s < Ly) )\n        {\n          ksum++;\n          if( tid-s >= 0 && tid+s < blockDim.x && tjd-s >= 0 && tjd+s < blockDim.y )\n            sum += s_Img[stid + ii*blockDim.y + jj];\n          else\n            sum += Img[gtid + ii*Ly + jj];\n        }\n    if ( ksum != 0 ) Out[gtid] = __fdividef(sum , (float)ksum);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n     printf(\"./%s <image dimension> <threshold> <max box size> <iterations>\\n\", argv[0]);\n     exit(1);\n  }\n\n  \n\n  const int Lx = atoi(argv[1]);\n  const int Ly = Lx;\n  const int size = Lx * Ly;\n\n  const int Threshold = atoi(argv[2]);\n  const int MaxRad = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n \n  const size_t size_bytes = size * sizeof(float);\n  const size_t box_bytes = size * sizeof(int);\n\n  \n\n  float *img = (float*) malloc (size_bytes);\n\n  \n\n  float *norm = (float*) malloc (size_bytes);\n  float *h_norm = (float*) malloc (size_bytes);\n\n  int *box = (int*) malloc (box_bytes);\n  int *h_box = (int*) malloc (box_bytes);\n\n  float *out = (float*) malloc (size_bytes);\n  float *h_out = (float*) malloc (size_bytes);\n\n  srand(123);\n  for (int i = 0; i < size; i++) {\n    img[i] = rand() % 256;\n    norm[i] = box[i] = out[i] = 0;\n  }\n\n  float *d_img;\n  cudaMalloc((void**)&d_img, size_bytes);\n\n  float *d_norm;\n  cudaMalloc((void**)&d_norm, size_bytes);\n\n  int *d_box;\n  cudaMalloc((void**)&d_box, box_bytes);\n\n  float *d_out;\n  cudaMalloc((void**)&d_out, size_bytes);\n\n  dim3 grids ((Lx+15)/16, (Ly+15)/16);\n  dim3 blocks (16, 16);\n\n  \n\n  cudaMemcpy(d_out, out, size_bytes, cudaMemcpyHostToDevice);\n\n  double time = 0;\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    cudaMemcpy(d_img, img, size_bytes, cudaMemcpyHostToDevice);\n    \n\n    cudaMemcpy(d_norm, norm, size_bytes, cudaMemcpyHostToDevice);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    \n\n    smoothingFilter<<<grids, blocks>>>(Lx, Ly, Threshold, MaxRad, d_img, d_box, d_norm);\n    normalizeFilter<<<grids, blocks>>>(Lx, Ly, d_img, d_norm);\n    outFilter<<<grids, blocks>>>(Lx, Ly, d_img, d_box, d_out);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  printf(\"Average filtering time %lf (s)\\n\", (time * 1e-9) / repeat);\n\n  cudaMemcpy(out, d_out, size_bytes, cudaMemcpyDeviceToHost);\n  cudaMemcpy(box, d_box, box_bytes, cudaMemcpyDeviceToHost);\n  cudaMemcpy(norm, d_norm, size_bytes, cudaMemcpyDeviceToHost);\n\n  \n\n  reference (Lx, Ly, Threshold, MaxRad, img, h_box, h_norm, h_out);\n  verify(size, MaxRad, norm, h_norm, out, h_out, box, h_box);\n\n  cudaFree(d_img);\n  cudaFree(d_norm);\n  cudaFree(d_box);\n  cudaFree(d_out);\n  free(img);\n  free(norm);\n  free(h_norm);\n  free(box);\n  free(h_box);\n  free(out);\n  free(h_out);\n  return 0;\n}\n"}}
{"kernel_name": "asmooth", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#include \"reference.cpp\"\n\n__global__ void smoothingFilter(\n    int Lx, int Ly, \n    int Threshold, int MaxRad, \n    const float*__restrict__ Img,\n            int*__restrict__ Box,\n          float*__restrict__ Norm)\n{\n  int tid = threadIdx.x;\n  int tjd = threadIdx.y;\n  int i = blockIdx.x * blockDim.x + tid;\n  int j = blockIdx.y * blockDim.y + tjd;\n  int stid = tjd * blockDim.x + tid;\n  int gtid = j * Lx + i;  \n\n  \n\n  __shared__ float s_Img[1024];\n\n  if ( i < Lx && j < Ly )\n    s_Img[stid] = Img[gtid];\n\n  __syncthreads();\n\n  if ( i < Lx && j < Ly )\n  {\n    \n\n    float sum = 0.f;\n    int q = 1;\n    int s = q;\n    int ksum = 0;\n\n    \n\n    while (sum < Threshold && q < MaxRad)\n    {\n      s = q;\n      sum = 0.f;\n      ksum = 0;\n\n      \n\n      for (int ii = -s; ii < s+1; ii++)\n        for (int jj = -s; jj < s+1; jj++)\n          if ( (i-s >= 0) && (i+s < Ly) && (j-s >= 0) && (j+s < Lx) )\n          {\n            ksum++;\n            \n\n            if( tid-s >= 0 && tid+s < blockDim.x && tjd-s >= 0 && tjd+s < blockDim.y )\n              sum += s_Img[stid + ii*blockDim.x + jj];\n            \n\n            else\n              sum += Img[gtid + ii*Lx + jj];\n          }\n      q++;\n    }\n    Box[gtid] = s;\n\n    \n\n    for (int ii = -s; ii < s+1; ii++)\n      for (int jj = -s; jj < s+1; jj++)\n        if (ksum != 0) \n          atomicAdd(&Norm[gtid + ii*Lx + jj], __fdividef(1.f, (float)ksum));\n  }\n}\n\n__global__ void normalizeFilter(\n    int Lx, int Ly, \n          float*__restrict__ Img,\n    const float*__restrict__ Norm)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  if ( i < Lx && j < Ly ) {\n    int gtid = j * Lx + i;  \n    const float norm = Norm[gtid];\n    if (norm != 0) Img[gtid] = __fdividef(Img[gtid], norm);\n  }\n}\n\n__global__ void outFilter( \n    int Lx, int Ly,\n    const float*__restrict__ Img,\n    const   int*__restrict__ Box,\n          float*__restrict__ Out )\n{\n  int tid = threadIdx.x;\n  int tjd = threadIdx.y;\n  int i = blockIdx.x * blockDim.x + tid;\n  int j = blockIdx.y * blockDim.y + tjd;\n  int stid = tjd * blockDim.x + tid;\n  int gtid = j * Lx + i;  \n\n  \n\n  __shared__ float s_Img[1024];\n\n  if ( i < Lx && j < Ly )\n    s_Img[stid] = Img[gtid];\n\n  __syncthreads();\n\n  if ( i < Lx && j < Ly )\n  {\n    const int s = Box[gtid];\n    float sum = 0.f;\n    int ksum  = 0;\n\n    for (int ii = -s; ii < s+1; ii++)\n      for (int jj = -s; jj < s+1; jj++)\n        if ( (i-s >= 0) && (i+s < Lx) && (j-s >= 0) && (j+s < Ly) )\n        {\n          ksum++;\n          if( tid-s >= 0 && tid+s < blockDim.x && tjd-s >= 0 && tjd+s < blockDim.y )\n            sum += s_Img[stid + ii*blockDim.y + jj];\n          else\n            sum += Img[gtid + ii*Ly + jj];\n        }\n    if ( ksum != 0 ) Out[gtid] = __fdividef(sum , (float)ksum);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n     printf(\"./%s <image dimension> <threshold> <max box size> <iterations>\\n\", argv[0]);\n     exit(1);\n  }\n\n  \n\n  const int Lx = atoi(argv[1]);\n  const int Ly = Lx;\n  const int size = Lx * Ly;\n\n  const int Threshold = atoi(argv[2]);\n  const int MaxRad = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n \n  const size_t size_bytes = size * sizeof(float);\n  const size_t box_bytes = size * sizeof(int);\n\n  \n\n  float *img = (float*) malloc (size_bytes);\n\n  \n\n  float *norm = (float*) malloc (size_bytes);\n  float *h_norm = (float*) malloc (size_bytes);\n\n  int *box = (int*) malloc (box_bytes);\n  int *h_box = (int*) malloc (box_bytes);\n\n  float *out = (float*) malloc (size_bytes);\n  float *h_out = (float*) malloc (size_bytes);\n\n  srand(123);\n  for (int i = 0; i < size; i++) {\n    img[i] = rand() % 256;\n    norm[i] = box[i] = out[i] = 0;\n  }\n\n  float *d_img;\n  hipMalloc((void**)&d_img, size_bytes);\n\n  float *d_norm;\n  hipMalloc((void**)&d_norm, size_bytes);\n\n  int *d_box;\n  hipMalloc((void**)&d_box, box_bytes);\n\n  float *d_out;\n  hipMalloc((void**)&d_out, size_bytes);\n\n  dim3 grids ((Lx+15)/16, (Ly+15)/16);\n  dim3 blocks (16, 16);\n\n  \n\n  hipMemcpy(d_out, out, size_bytes, hipMemcpyHostToDevice);\n\n  double time = 0;\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    hipMemcpy(d_img, img, size_bytes, hipMemcpyHostToDevice);\n    \n\n    hipMemcpy(d_norm, norm, size_bytes, hipMemcpyHostToDevice);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    \n\n    smoothingFilter<<<grids, blocks>>>(Lx, Ly, Threshold, MaxRad, d_img, d_box, d_norm);\n    normalizeFilter<<<grids, blocks>>>(Lx, Ly, d_img, d_norm);\n    outFilter<<<grids, blocks>>>(Lx, Ly, d_img, d_box, d_out);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  printf(\"Average filtering time %lf (s)\\n\", (time * 1e-9) / repeat);\n\n  hipMemcpy(out, d_out, size_bytes, hipMemcpyDeviceToHost);\n  hipMemcpy(box, d_box, box_bytes, hipMemcpyDeviceToHost);\n  hipMemcpy(norm, d_norm, size_bytes, hipMemcpyDeviceToHost);\n\n  \n\n  reference (Lx, Ly, Threshold, MaxRad, img, h_box, h_norm, h_out);\n  verify(size, MaxRad, norm, h_norm, out, h_out, box, h_box);\n\n  hipFree(d_img);\n  hipFree(d_norm);\n  hipFree(d_box);\n  hipFree(d_out);\n  free(img);\n  free(norm);\n  free(h_norm);\n  free(box);\n  free(h_box);\n  free(out);\n  free(h_out);\n  return 0;\n}\n"}}
{"kernel_name": "asmooth", "parallel_api": "omp", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#include \"reference.cpp\"\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"./%s <image dimension> <threshold> <max box size> <iterations>\\n\", argv[0]);\n    exit(1);\n  }\n\n  \n\n  const int Lx = atoi(argv[1]);\n  const int Ly = Lx;\n  const int size = Lx * Ly;\n\n  const int Threshold = atoi(argv[2]);\n  const int MaxRad = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const size_t size_bytes = size * sizeof(float);\n  const size_t box_bytes = size * sizeof(int);\n\n  \n\n  float *img = (float*) malloc (size_bytes);\n\n  \n\n  float *norm = (float*) malloc (size_bytes);\n  float *h_norm = (float*) malloc (size_bytes);\n\n  int *box = (int*) malloc (box_bytes);\n  int *h_box = (int*) malloc (box_bytes);\n\n  float *out = (float*) malloc (size_bytes);\n  float *h_out = (float*) malloc (size_bytes);\n\n  srand(123);\n  for (int i = 0; i < size; i++) {\n    img[i] = rand() % 256;\n    norm[i] = box[i] = out[i] = 0;\n  }\n\n  double time = 0;\n\n  #pragma omp target data map(alloc: img[0:size], norm[0:size], box[0:size]) \\\n                          map(to: out[0:size]) \n  {\n    for (int i = 0; i < repeat; i++) {\n      \n\n      #pragma omp target update to(img[0:size])\n      \n\n      #pragma omp target update to(norm[0:size])\n\n      auto start = std::chrono::steady_clock::now();\n\n      \n\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n      for (int x = 0; x < Lx; x++) {\n        for (int y = 0; y < Ly; y++) {\n          float sum = 0.f;\n          int s = 1;\n          int q = 1;\n          int ksum = 0;\n\n          while (sum < Threshold && q < MaxRad) {\n            s = q;\n            sum = 0.f;\n            ksum = 0;\n\n            for (int i = -s; i < s+1; i++)\n              for (int j = -s; j < s+1; j++)\n                if (x-s >=0 && x+s < Lx && y-s >=0 && y+s < Ly) {\n                  sum += img[(x+i)*Ly+y+j];\n                  ksum++;\n                }\n            q++;\n          }\n\n          box[x*Ly+y] = s;  \n\n\n          for (int i = -s; i < s+1; i++)\n            for (int j = -s; j < s+1; j++)\n              if (x-s >=0 && x+s < Lx && y-s >=0 && y+s < Ly)\n                if (ksum != 0) {\n                  #pragma omp atomic update\n                  norm[(x+i)*Ly+y+j] += 1.f / (float)ksum;\n                }\n        }\n      }\n\n      \n\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n      for (int x = 0; x < Lx; x++)\n        for (int y = 0; y < Ly; y++) \n          if (norm[x*Ly+y] != 0) img[x*Ly+y] /= norm[x*Ly+y];\n\n      \n\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n      for (int x = 0; x < Lx; x++) {\n        for (int y = 0; y < Ly; y++) {\n          int s = box[x*Ly+y];\n          float sum = 0.f;\n          int ksum = 0;\n\n          \n\n          for (int i = -s; i < s+1; i++)\n            for (int j = -s; j < s+1; j++) {\n              if (x-s >=0 && x+s < Lx && y-s >=0 && y+s < Ly) {\n                sum += img[(x+i)*Ly+y+j];\n                ksum++;\n              }\n            }\n          if (ksum != 0) out[x*Ly+y] = sum / (float)ksum;\n        }\n      }\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    }\n\n    printf(\"Average filtering time %lf (s)\\n\", (time * 1e-9) / repeat);\n\n    #pragma omp target update from(out[0:size])\n    #pragma omp target update from(box[0:size])\n    #pragma omp target update from(norm[0:size])\n  }\n\n  \n\n  reference (Lx, Ly, Threshold, MaxRad, img, h_box, h_norm, h_out);\n  verify(size, MaxRad, norm, h_norm, out, h_out, box, h_box);\n\n  free(img);\n  free(norm);\n  free(h_norm);\n  free(box);\n  free(h_box);\n  free(out);\n  free(h_out);\n  return 0;\n}\n"}}
{"kernel_name": "asmooth", "parallel_api": "serial", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n\n#include \"reference.cpp\"\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"./%s <image dimension> <threshold> <max box size> <iterations>\\n\", argv[0]);\n    exit(1);\n  }\n\n  \n\n  const int Lx = atoi(argv[1]);\n  const int Ly = Lx;\n  const int size = Lx * Ly;\n\n  const int Threshold = atoi(argv[2]);\n  const int MaxRad = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const size_t size_bytes = size * sizeof(float);\n  const size_t box_bytes = size * sizeof(int);\n\n  \n\n  float *img = (float*) malloc (size_bytes);\n\n  \n\n  float *norm = (float*) malloc (size_bytes);\n  float *h_norm = (float*) malloc (size_bytes);\n\n  int *box = (int*) malloc (box_bytes);\n  int *h_box = (int*) malloc (box_bytes);\n\n  float *out = (float*) malloc (size_bytes);\n  float *h_out = (float*) malloc (size_bytes);\n\n  srand(123);\n  for (int i = 0; i < size; i++) {\n    img[i] = rand() % 256;\n    norm[i] = box[i] = out[i] = 0;\n  }\n\n  double time = 0;\n\n    {\n    for (int i = 0; i < repeat; i++) {\n      \n\n            \n\n      \n      auto start = std::chrono::steady_clock::now();\n\n      \n\n            for (int x = 0; x < Lx; x++) {\n        for (int y = 0; y < Ly; y++) {\n          float sum = 0.f;\n          int s = 1;\n          int q = 1;\n          int ksum = 0;\n\n          while (sum < Threshold && q < MaxRad) {\n            s = q;\n            sum = 0.f;\n            ksum = 0;\n\n            for (int i = -s; i < s+1; i++)\n              for (int j = -s; j < s+1; j++)\n                if (x-s >=0 && x+s < Lx && y-s >=0 && y+s < Ly) {\n                  sum += img[(x+i)*Ly+y+j];\n                  ksum++;\n                }\n            q++;\n          }\n\n          box[x*Ly+y] = s;  \n\n\n          for (int i = -s; i < s+1; i++)\n            for (int j = -s; j < s+1; j++)\n              if (x-s >=0 && x+s < Lx && y-s >=0 && y+s < Ly)\n                if (ksum != 0) {\n                                    norm[(x+i)*Ly+y+j] += 1.f / (float)ksum;\n                }\n        }\n      }\n\n      \n\n            for (int x = 0; x < Lx; x++)\n        for (int y = 0; y < Ly; y++) \n          if (norm[x*Ly+y] != 0) img[x*Ly+y] /= norm[x*Ly+y];\n\n      \n\n            for (int x = 0; x < Lx; x++) {\n        for (int y = 0; y < Ly; y++) {\n          int s = box[x*Ly+y];\n          float sum = 0.f;\n          int ksum = 0;\n\n          \n\n          for (int i = -s; i < s+1; i++)\n            for (int j = -s; j < s+1; j++) {\n              if (x-s >=0 && x+s < Lx && y-s >=0 && y+s < Ly) {\n                sum += img[(x+i)*Ly+y+j];\n                ksum++;\n              }\n            }\n          if (ksum != 0) out[x*Ly+y] = sum / (float)ksum;\n        }\n      }\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    }\n\n    printf(\"Average filtering time %lf (s)\\n\", (time * 1e-9) / repeat);\n\n              }\n\n  \n\n  reference (Lx, Ly, Threshold, MaxRad, img, h_box, h_norm, h_out);\n  verify(size, MaxRad, norm, h_norm, out, h_out, box, h_box);\n\n  free(img);\n  free(norm);\n  free(h_norm);\n  free(box);\n  free(h_box);\n  free(out);\n  free(h_out);\n  return 0;\n}"}}
{"kernel_name": "asmooth", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#include \"reference.cpp\"\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n     printf(\"./%s <image dimension> <threshold> <max box size> <iterations>\\n\", argv[0]);\n     exit(1);\n  }\n\n  \n\n  const int Lx = atoi(argv[1]);\n  const int Ly = Lx;\n  const int size = Lx * Ly;\n\n  const int Threshold = atoi(argv[2]);\n  const int MaxRad = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const size_t size_bytes = size * sizeof(float);\n  const size_t box_bytes = size * sizeof(int);\n \n  \n\n  float *img = (float*) malloc (size_bytes);\n\n  \n\n  float *norm = (float*) malloc (size_bytes);\n  float *h_norm = (float*) malloc (size_bytes);\n\n  int *box = (int*) malloc (box_bytes);\n  int *h_box = (int*) malloc (box_bytes);\n\n  float *out = (float*) malloc (size_bytes);\n  float *h_out = (float*) malloc (size_bytes);\n\n  srand(123);\n  for (int i = 0; i < size; i++) {\n    img[i] = rand() % 256;\n    norm[i] = box[i] = out[i] = 0;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_img = sycl::malloc_device<float>(size, q);\n  float *d_norm = sycl::malloc_device<float>(size, q);\n    int *d_box = sycl::malloc_device<int>(size, q);\n  float *d_out = sycl::malloc_device<float>(size, q);\n\n  sycl::range<2> gws ((Ly+15)/16*16, (Lx+15)/16*16);\n  sycl::range<2> lws (16, 16);\n\n  double time = 0;\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    q.memcpy(d_img, img, size_bytes);\n\n    \n\n    q.memcpy(d_norm, norm, size_bytes);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    \n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> s_Img(sycl::range<1>(1024), cgh);\n      cgh.parallel_for<class smoothing>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        int tid = item.get_local_id(1);\n        int tjd = item.get_local_id(0);\n        int i = item.get_global_id(1);\n        int j = item.get_global_id(0);\n        int blockDim_x = item.get_local_range(1);\n        int blockDim_y = item.get_local_range(0);\n        int stid = tjd * blockDim_x + tid;\n        int gtid = j * Lx + i;  \n\n        \n\n\n        if ( i < Lx && j < Ly )\n          s_Img[stid] = d_img[gtid];\n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        if ( i < Lx && j < Ly )\n        {\n          \n\n          float sum = 0.f;\n          int q = 1;\n          int s = q;\n          int ksum = 0;\n\n          \n\n          while (sum < Threshold && q < MaxRad)\n          {\n            s = q;\n            sum = 0.f;\n            ksum = 0;\n\n            \n\n            for (int ii = -s; ii < s+1; ii++)\n              for (int jj = -s; jj < s+1; jj++)\n                if ( (i-s >= 0) && (i+s < Ly) && (j-s >= 0) && (j+s < Lx) )\n                {\n                  ksum++;\n                  \n\n                  if( tid-s >= 0 && tid+s < blockDim_x && tjd-s >= 0 && tjd+s < blockDim_y )\n                    sum += s_Img[stid + ii*blockDim_x + jj];\n                  \n\n                  else\n                    sum += d_img[gtid + ii*Lx + jj];\n                }\n            q++;\n          }\n          d_box[gtid] = s;\n\n          \n\n          for (int ii = -s; ii < s+1; ii++)\n            for (int jj = -s; jj < s+1; jj++)\n              if (ksum != 0) {\n                auto ao = sycl::atomic_ref<float, \n                  sycl::memory_order::relaxed,\n                  sycl::memory_scope::device,\n                  sycl::access::address_space::global_space> (d_norm[gtid + ii*Lx + jj]);\n                ao.fetch_add(sycl::native::divide(1.f, (float)ksum));\n              }\n        }\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class normalize>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        int i = item.get_global_id(1);\n        int j = item.get_global_id(0); \n        if ( i < Lx && j < Ly ) {\n          int gtid = j * Lx + i;  \n          const float norm = d_norm[gtid];\n          if (norm != 0) d_img[gtid] = sycl::native::divide(d_img[gtid], norm);\n        }\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> s_Img(1024, cgh);\n      cgh.parallel_for<class output>(sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        int tid = item.get_local_id(1);\n        int tjd = item.get_local_id(0);\n        int i = item.get_global_id(1);\n        int j = item.get_global_id(0);\n        int blockDim_x = item.get_local_range(1);\n        int blockDim_y = item.get_local_range(0);\n        int stid = tjd * blockDim_x + tid;\n        int gtid = j * Lx + i;  \n\n        if ( i < Lx && j < Ly )\n          s_Img[stid] = d_img[gtid];\n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        if ( i < Lx && j < Ly )\n        {\n          const int s = d_box[gtid];\n          float sum = 0.f;\n          int ksum  = 0;\n\n          for (int ii = -s; ii < s+1; ii++)\n            for (int jj = -s; jj < s+1; jj++)\n              if ( (i-s >= 0) && (i+s < Lx) && (j-s >= 0) && (j+s < Ly) )\n              {\n                ksum++;\n                if( tid-s >= 0 && tid+s < blockDim_x && tjd-s >= 0 && tjd+s < blockDim_y )\n                  sum += s_Img[stid + ii*blockDim_y + jj];\n                else\n                  sum += d_img[gtid + ii*Ly + jj];\n              }\n          if ( ksum != 0 ) d_out[gtid] = sycl::native::divide(sum, (float)ksum);\n        }\n      });\n    });\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  printf(\"Average filtering time %lf (s)\\n\", (time * 1e-9) / repeat);\n\n  q.memcpy(out, d_out, size_bytes);\n  q.memcpy(box, d_box, box_bytes);\n  q.memcpy(norm, d_norm, size_bytes);\n\n  q.wait();\n\n  \n\n  reference (Lx, Ly, Threshold, MaxRad, img, h_box, h_norm, h_out);\n  verify(size, MaxRad, norm, h_norm, out, h_out, box, h_box);\n\n  sycl::free(d_img, q);\n  sycl::free(d_norm, q);\n  sycl::free(d_box, q);\n  sycl::free(d_out, q);\n  free(img);\n  free(norm);\n  free(h_norm);\n  free(box);\n  free(h_box);\n  free(out);\n  free(h_out);\n  return 0;\n}\n"}}
{"kernel_name": "background-subtract", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n\n#define BLOCK_SIZE 256\n\n__global__ void findMovingPixels(\n  const size_t imgSize,\n  const unsigned char *__restrict__ Img,\n  const unsigned char *__restrict__ Img1,\n  const unsigned char *__restrict__ Img2,\n  const unsigned char *__restrict__ Tn,\n        unsigned char *__restrict__ Mp) \n\n{\n  size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= imgSize) return;\n  if ( abs(Img[i] - Img1[i]) > Tn[i] || abs(Img[i] - Img2[i]) > Tn[i] )\n    Mp[i] = 255;\n  else {\n    Mp[i] = 0;\n  }\n}\n\n\n\n__global__ void updateBackground(\n  const size_t imgSize,\n  const unsigned char *__restrict__ Img,\n  const unsigned char *__restrict__ Mp,\n        unsigned char *__restrict__ Bn)\n{\n  size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= imgSize) return;\n  if ( Mp[i] == 0 ) Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n}\n\n\n\n__global__ void updateThreshold(\n  const size_t imgSize,\n  const unsigned char *__restrict__ Img,\n  const unsigned char *__restrict__ Mp,\n  const unsigned char *__restrict__ Bn,\n        unsigned char *__restrict__ Tn)\n{\n  size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= imgSize) return;\n  if (Mp[i] == 0) {\n    float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n    Tn[i] = fmaxf(th, 20.f);\n  }\n}\n\n\n\n\n\n\n\n__global__ void merge(\n  const size_t imgSize,\n  const unsigned char *__restrict__ Img,\n  const unsigned char *__restrict__ Img1,\n  const unsigned char *__restrict__ Img2,\n        unsigned char *__restrict__ Tn,\n        unsigned char *__restrict__ Bn)\n{\n  size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= imgSize) return;\n  if ( abs(Img[i] - Img1[i]) <= Tn[i] && abs(Img[i] - Img2[i]) <= Tn[i] ) {\n    \n\n    Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n\n    \n\n    float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n    Tn[i] = fmaxf(th, 20.f);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <merge> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int merged = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int imgSize = width * height;\n  const size_t imgSize_bytes = imgSize * sizeof(char);\n  unsigned char *Img = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Bn = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Tn = (unsigned char*) malloc (imgSize_bytes);\n\n  unsigned char *d_Img, *d_Img1, *d_Img2;\n  unsigned char *d_Bn, *d_Mp, *d_Tn;\n  cudaMalloc((void**)&d_Img, imgSize_bytes);\n  cudaMalloc((void**)&d_Img1, imgSize_bytes);\n  cudaMalloc((void**)&d_Img2, imgSize_bytes);\n  cudaMalloc((void**)&d_Bn, imgSize_bytes);\n  cudaMalloc((void**)&d_Mp, imgSize_bytes);\n  cudaMalloc((void**)&d_Tn, imgSize_bytes);\n\n  std::mt19937 generator( 123 );\n  std::uniform_int_distribution<int> distribute( 0, 255 );\n\n  for (int j = 0; j < imgSize; j++) {\n    Bn[j] = distribute(generator);\n    Tn[j] = 128;\n  }\n\n  cudaMemcpy(d_Bn, Bn, imgSize_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_Tn, Tn, imgSize_bytes, cudaMemcpyHostToDevice);\n\n  dim3 grids ((imgSize + BLOCK_SIZE - 1) / BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  long time = 0;\n\n  for (int i = 0; i < repeat; i++) {\n\n    for (int j = 0; j < imgSize; j++) {\n      Img[j] = distribute(generator);\n    }\n\n    cudaMemcpy(d_Img, Img, imgSize_bytes, cudaMemcpyHostToDevice);\n\n    \n\n    \n\n    \n\n    unsigned char *t = d_Img2;\n    d_Img2 = d_Img1;\n    d_Img1 = d_Img;\n    d_Img = t;\n\n    if (i >= 2) {\n      if (merged) {\n        auto start = std::chrono::steady_clock::now();\n        merge <<< grids, blocks >>> ( imgSize, d_Img, d_Img1, d_Img2, d_Tn, d_Bn );\n        cudaDeviceSynchronize();\n        auto end = std::chrono::steady_clock::now();\n        time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      }\n      else {\n        auto start = std::chrono::steady_clock::now();\n        findMovingPixels <<< grids, blocks >>> ( imgSize, d_Img, d_Img1, d_Img2, d_Tn, d_Mp );\n        updateBackground <<< grids, blocks >>> ( imgSize, d_Img, d_Mp, d_Bn );\n        updateThreshold <<< grids, blocks >>> ( imgSize, d_Img, d_Mp, d_Bn, d_Tn );\n        cudaDeviceSynchronize();\n        auto end = std::chrono::steady_clock::now();\n        time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      }\n    }\n  }\n\n  float kernel_time = (repeat <= 2) ? 0 : (time * 1e-3f) / (repeat - 2);\n  printf(\"Average kernel execution time: %f (us)\\n\", kernel_time);\n\n  cudaMemcpy(Tn, d_Tn, imgSize_bytes, cudaMemcpyDeviceToHost);\n\n  \n\n  int sum = 0;\n  int bin[4] = {0, 0, 0, 0};\n  for (int j = 0; j < imgSize; j++) {\n    sum += abs(Tn[j] - 128);\n    if (Tn[j] < 64)\n      bin[0]++;\n    else if (Tn[j] < 128)\n      bin[1]++;\n    else if (Tn[j] < 192)\n      bin[2]++;\n    else\n      bin[3]++;\n  }\n  sum = sum / imgSize;\n  printf(\"Average threshold change is %d\\n\", sum);\n  printf(\"Bin counts are %d %d %d %d\\n\", bin[0], bin[1], bin[2], bin[3]);\n     \n  free(Img);\n  free(Tn);\n  free(Bn);\n  cudaFree(d_Img);\n  cudaFree(d_Img1);\n  cudaFree(d_Img2);\n  cudaFree(d_Tn);\n  cudaFree(d_Mp);\n  cudaFree(d_Bn);\n\n  return 0;\n}\n"}}
{"kernel_name": "background-subtract", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n\n#define BLOCK_SIZE 256\n\n__global__ void findMovingPixels(\n  const size_t imgSize,\n  const unsigned char *__restrict__ Img,\n  const unsigned char *__restrict__ Img1,\n  const unsigned char *__restrict__ Img2,\n  const unsigned char *__restrict__ Tn,\n        unsigned char *__restrict__ Mp) \n\n{\n  size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= imgSize) return;\n  if ( abs(Img[i] - Img1[i]) > Tn[i] || abs(Img[i] - Img2[i]) > Tn[i] )\n    Mp[i] = 255;\n  else {\n    Mp[i] = 0;\n  }\n}\n\n\n\n__global__ void updateBackground(\n  const size_t imgSize,\n  const unsigned char *__restrict__ Img,\n  const unsigned char *__restrict__ Mp,\n        unsigned char *__restrict__ Bn)\n{\n  size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= imgSize) return;\n  if ( Mp[i] == 0 ) Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n}\n\n\n\n__global__ void updateThreshold(\n  const size_t imgSize,\n  const unsigned char *__restrict__ Img,\n  const unsigned char *__restrict__ Mp,\n  const unsigned char *__restrict__ Bn,\n        unsigned char *__restrict__ Tn)\n{\n  size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= imgSize) return;\n  if (Mp[i] == 0) {\n    float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n    Tn[i] = fmaxf(th, 20.f);\n  }\n}\n\n\n\n\n\n\n\n__global__ void merge(\n  const size_t imgSize,\n  const unsigned char *__restrict__ Img,\n  const unsigned char *__restrict__ Img1,\n  const unsigned char *__restrict__ Img2,\n        unsigned char *__restrict__ Tn,\n        unsigned char *__restrict__ Bn)\n{\n  size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= imgSize) return;\n  if ( abs(Img[i] - Img1[i]) <= Tn[i] && abs(Img[i] - Img2[i]) <= Tn[i] ) {\n    \n\n    Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n\n    \n\n    float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n    Tn[i] = fmaxf(th, 20.f);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <merge> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int merged = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int imgSize = width * height;\n  const size_t imgSize_bytes = imgSize * sizeof(char);\n  unsigned char *Img = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Bn = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Tn = (unsigned char*) malloc (imgSize_bytes);\n\n  unsigned char *d_Img, *d_Img1, *d_Img2;\n  unsigned char *d_Bn, *d_Mp, *d_Tn;\n  hipMalloc((void**)&d_Img, imgSize_bytes);\n  hipMalloc((void**)&d_Img1, imgSize_bytes);\n  hipMalloc((void**)&d_Img2, imgSize_bytes);\n  hipMalloc((void**)&d_Bn, imgSize_bytes);\n  hipMalloc((void**)&d_Mp, imgSize_bytes);\n  hipMalloc((void**)&d_Tn, imgSize_bytes);\n\n  std::mt19937 generator( 123 );\n  std::uniform_int_distribution<int> distribute( 0, 255 );\n\n  for (int j = 0; j < imgSize; j++) {\n    Bn[j] = distribute(generator);\n    Tn[j] = 128;\n  }\n\n  hipMemcpy(d_Bn, Bn, imgSize_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_Tn, Tn, imgSize_bytes, hipMemcpyHostToDevice);\n\n  dim3 grids ((imgSize + BLOCK_SIZE - 1) / BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  long time = 0;\n\n  for (int i = 0; i < repeat; i++) {\n\n    for (int j = 0; j < imgSize; j++) {\n      Img[j] = distribute(generator);\n    }\n\n    hipMemcpy(d_Img, Img, imgSize_bytes, hipMemcpyHostToDevice);\n\n    \n\n    \n\n    \n\n    unsigned char *t = d_Img2;\n    d_Img2 = d_Img1;\n    d_Img1 = d_Img;\n    d_Img = t;\n\n    if (i >= 2) {\n      if (merged) {\n        auto start = std::chrono::steady_clock::now();\n        hipLaunchKernelGGL(merge, grids, blocks , 0, 0,  imgSize, d_Img, d_Img1, d_Img2, d_Tn, d_Bn );\n        hipDeviceSynchronize();\n        auto end = std::chrono::steady_clock::now();\n        time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      }\n      else {\n        auto start = std::chrono::steady_clock::now();\n        hipLaunchKernelGGL(findMovingPixels, grids, blocks , 0, 0,  imgSize, d_Img, d_Img1, d_Img2, d_Tn, d_Mp );\n        hipLaunchKernelGGL(updateBackground, grids, blocks , 0, 0,  imgSize, d_Img, d_Mp, d_Bn );\n        hipLaunchKernelGGL(updateThreshold, grids, blocks , 0, 0,  imgSize, d_Img, d_Mp, d_Bn, d_Tn );\n        hipDeviceSynchronize();\n        auto end = std::chrono::steady_clock::now();\n        time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      }\n    }\n  }\n\n  float kernel_time = (repeat <= 2) ? 0 : (time * 1e-3f) / (repeat - 2);\n  printf(\"Average kernel execution time: %f (us)\\n\", kernel_time);\n\n  hipMemcpy(Tn, d_Tn, imgSize_bytes, hipMemcpyDeviceToHost);\n\n  \n\n  int sum = 0;\n  int bin[4] = {0, 0, 0, 0};\n  for (int j = 0; j < imgSize; j++) {\n    sum += abs(Tn[j] - 128);\n    if (Tn[j] < 64)\n      bin[0]++;\n    else if (Tn[j] < 128)\n      bin[1]++;\n    else if (Tn[j] < 192)\n      bin[2]++;\n    else\n      bin[3]++;\n  }\n  sum = sum / imgSize;\n  printf(\"Average threshold change is %d\\n\", sum);\n  printf(\"Bin counts are %d %d %d %d\\n\", bin[0], bin[1], bin[2], bin[3]);\n     \n  free(Img);\n  free(Tn);\n  free(Bn);\n  hipFree(d_Img);\n  hipFree(d_Img1);\n  hipFree(d_Img2);\n  hipFree(d_Tn);\n  hipFree(d_Mp);\n  hipFree(d_Bn);\n\n  return 0;\n}\n"}}
{"kernel_name": "background-subtract", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n\n#define BLOCK_SIZE 256\n\nvoid findMovingPixels(\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Img1,\n  const unsigned char *__restrict Img2,\n  const unsigned char *__restrict Tn,\n        unsigned char *__restrict Mp) \n\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for (size_t i = 0; i < imgSize; i++) {\n    if ( abs(Img[i] - Img1[i]) > Tn[i] || abs(Img[i] - Img2[i]) > Tn[i] )\n      Mp[i] = 255;\n    else \n      Mp[i] = 0;\n  }\n}\n\n\n\nvoid updateBackground(\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Mp,\n        unsigned char *__restrict Bn)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for (size_t i = 0; i < imgSize; i++) {\n    if ( Mp[i] == 0 ) Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n  }\n}\n\n\n\nvoid updateThreshold(\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Mp,\n  const unsigned char *__restrict Bn,\n        unsigned char *__restrict Tn)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for (size_t i = 0; i < imgSize; i++) {\n    if (Mp[i] == 0) {\n      float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n      Tn[i] = fmaxf(th, 20.f);\n    }\n  }\n}\n\n\n\n\n\n\n\nvoid merge(\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Img1,\n  const unsigned char *__restrict Img2,\n        unsigned char *__restrict Tn,\n        unsigned char *__restrict Bn)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for (size_t i = 0; i < imgSize; i++) {\n    if ( abs(Img[i] - Img1[i]) <= Tn[i] && abs(Img[i] - Img2[i]) <= Tn[i] ) {\n      \n\n      Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n\n      \n\n      float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n      Tn[i] = fmaxf(th, 20.f);\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <merge> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int merged = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int imgSize = width * height;\n  const size_t imgSize_bytes = imgSize * sizeof(char);\n  unsigned char *Img = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Img1 = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Img2 = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Bn = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Mp = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Tn = (unsigned char*) malloc (imgSize_bytes);\n\n  std::mt19937 generator( 123 );\n  std::uniform_int_distribution<int> distribute( 0, 255 );\n\n  for (int j = 0; j < imgSize; j++) {\n    Bn[j] = distribute(generator);\n    Tn[j] = 128;\n  }\n\n  long time = 0;\n\n  #pragma omp target data map (to: Bn[0:imgSize]) \\\n                          map (tofrom: Tn[0:imgSize]) \\\n                          map (alloc: Mp[0:imgSize], \\\n                                      Img[0:imgSize], \\\n                                      Img1[0:imgSize], \\\n                                      Img2[0:imgSize])\n  {\n    for (int i = 0; i < repeat; i++) {\n\n      for (int j = 0; j < imgSize; j++) {\n        Img[j] = distribute(generator);\n      }\n\n      #pragma omp target update to (Img[0:imgSize])\n\n    \n\n    \n\n    \n\n      unsigned char *t = Img2;\n      Img2 = Img1;\n      Img1 = Img;\n      Img = t;\n\n      if (i >= 2) {\n        if (merged) {\n          auto start = std::chrono::steady_clock::now();\n          merge ( imgSize, Img, Img1, Img2, Tn, Bn );\n          auto end = std::chrono::steady_clock::now();\n          time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        }\n        else {\n          auto start = std::chrono::steady_clock::now();\n          findMovingPixels ( imgSize, Img, Img1, Img2, Tn, Mp );\n          updateBackground ( imgSize, Img, Mp, Bn );\n          updateThreshold ( imgSize, Img, Mp, Bn, Tn );\n          auto end = std::chrono::steady_clock::now();\n          time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        }\n      }\n    }\n\n    float kernel_time = (repeat <= 2) ? 0 : (time * 1e-3f) / (repeat - 2);\n    printf(\"Average kernel execution time: %f (us)\\n\", kernel_time);\n  }\n\n  \n\n  int sum = 0;\n  int bin[4] = {0, 0, 0, 0};\n  for (int j = 0; j < imgSize; j++) {\n    sum += abs(Tn[j] - 128);\n    if (Tn[j] < 64)\n      bin[0]++;\n    else if (Tn[j] < 128)\n      bin[1]++;\n    else if (Tn[j] < 192)\n      bin[2]++;\n    else\n      bin[3]++;\n  }\n  sum = sum / imgSize;\n  printf(\"Average threshold change is %d\\n\", sum);\n  printf(\"Bin counts are %d %d %d %d\\n\", bin[0], bin[1], bin[2], bin[3]);\n     \n  free(Img);\n  free(Img1);\n  free(Img2);\n  free(Tn);\n  free(Bn);\n  free(Mp);\n\n  return 0;\n}\n"}}
{"kernel_name": "background-subtract", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n\n#define BLOCK_SIZE 256\n\nvoid findMovingPixels(\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Img1,\n  const unsigned char *__restrict Img2,\n  const unsigned char *__restrict Tn,\n        unsigned char *__restrict Mp) \n\n{\n    for (size_t i = 0; i < imgSize; i++) {\n    if ( abs(Img[i] - Img1[i]) > Tn[i] || abs(Img[i] - Img2[i]) > Tn[i] )\n      Mp[i] = 255;\n    else \n      Mp[i] = 0;\n  }\n}\n\n\n\nvoid updateBackground(\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Mp,\n        unsigned char *__restrict Bn)\n{\n    for (size_t i = 0; i < imgSize; i++) {\n    if ( Mp[i] == 0 ) Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n  }\n}\n\n\n\nvoid updateThreshold(\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Mp,\n  const unsigned char *__restrict Bn,\n        unsigned char *__restrict Tn)\n{\n    for (size_t i = 0; i < imgSize; i++) {\n    if (Mp[i] == 0) {\n      float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n      Tn[i] = fmaxf(th, 20.f);\n    }\n  }\n}\n\n\n\n\n\n\n\nvoid merge(\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Img1,\n  const unsigned char *__restrict Img2,\n        unsigned char *__restrict Tn,\n        unsigned char *__restrict Bn)\n{\n    for (size_t i = 0; i < imgSize; i++) {\n    if ( abs(Img[i] - Img1[i]) <= Tn[i] && abs(Img[i] - Img2[i]) <= Tn[i] ) {\n      \n\n      Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n\n      \n\n      float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n      Tn[i] = fmaxf(th, 20.f);\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <merge> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int merged = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int imgSize = width * height;\n  const size_t imgSize_bytes = imgSize * sizeof(char);\n  unsigned char *Img = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Img1 = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Img2 = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Bn = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Mp = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Tn = (unsigned char*) malloc (imgSize_bytes);\n\n  std::mt19937 generator( 123 );\n  std::uniform_int_distribution<int> distribute( 0, 255 );\n\n  for (int j = 0; j < imgSize; j++) {\n    Bn[j] = distribute(generator);\n    Tn[j] = 128;\n  }\n\n  long time = 0;\n\n    {\n    for (int i = 0; i < repeat; i++) {\n\n      for (int j = 0; j < imgSize; j++) {\n        Img[j] = distribute(generator);\n      }\n\n      \n    \n\n    \n\n    \n\n      unsigned char *t = Img2;\n      Img2 = Img1;\n      Img1 = Img;\n      Img = t;\n\n      if (i >= 2) {\n        if (merged) {\n          auto start = std::chrono::steady_clock::now();\n          merge ( imgSize, Img, Img1, Img2, Tn, Bn );\n          auto end = std::chrono::steady_clock::now();\n          time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        }\n        else {\n          auto start = std::chrono::steady_clock::now();\n          findMovingPixels ( imgSize, Img, Img1, Img2, Tn, Mp );\n          updateBackground ( imgSize, Img, Mp, Bn );\n          updateThreshold ( imgSize, Img, Mp, Bn, Tn );\n          auto end = std::chrono::steady_clock::now();\n          time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n        }\n      }\n    }\n\n    float kernel_time = (repeat <= 2) ? 0 : (time * 1e-3f) / (repeat - 2);\n    printf(\"Average kernel execution time: %f (us)\\n\", kernel_time);\n  }\n\n  \n\n  int sum = 0;\n  int bin[4] = {0, 0, 0, 0};\n  for (int j = 0; j < imgSize; j++) {\n    sum += abs(Tn[j] - 128);\n    if (Tn[j] < 64)\n      bin[0]++;\n    else if (Tn[j] < 128)\n      bin[1]++;\n    else if (Tn[j] < 192)\n      bin[2]++;\n    else\n      bin[3]++;\n  }\n  sum = sum / imgSize;\n  printf(\"Average threshold change is %d\\n\", sum);\n  printf(\"Bin counts are %d %d %d %d\\n\", bin[0], bin[1], bin[2], bin[3]);\n     \n  free(Img);\n  free(Img1);\n  free(Img2);\n  free(Tn);\n  free(Bn);\n  free(Mp);\n\n  return 0;\n}"}}
{"kernel_name": "background-subtract", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n\n#define BLOCK_SIZE 256\n\nvoid findMovingPixels(\n  sycl::nd_item<1> &item,\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Img1,\n  const unsigned char *__restrict Img2,\n  const unsigned char *__restrict Tn,\n        unsigned char *__restrict Mp) \n\n{\n  size_t i = item.get_global_id(0);\n  if (i >= imgSize) return;\n  if ( sycl::abs(Img[i] - Img1[i]) > Tn[i] || sycl::abs(Img[i] - Img2[i]) > Tn[i] )\n    Mp[i] = 255;\n  else {\n    Mp[i] = 0;\n  }\n}\n\n\n\nvoid updateBackground(\n  sycl::nd_item<1> &item,\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Mp,\n        unsigned char *__restrict Bn)\n{\n  size_t i = item.get_global_id(0);\n  if (i >= imgSize) return;\n  if ( Mp[i] == 0 ) Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n}\n\n\n\nvoid updateThreshold(\n  sycl::nd_item<1> &item,\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Mp,\n  const unsigned char *__restrict Bn,\n        unsigned char *__restrict Tn)\n{\n  size_t i = item.get_global_id(0);\n  if (i >= imgSize) return;\n  if (Mp[i] == 0) {\n    float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n    Tn[i] = sycl::fmax(th, 20.f);\n  }\n}\n\n\n\n\n\n\n\nvoid merge(\n  sycl::nd_item<1> &item,\n  const size_t imgSize,\n  const unsigned char *__restrict Img,\n  const unsigned char *__restrict Img1,\n  const unsigned char *__restrict Img2,\n        unsigned char *__restrict Tn,\n        unsigned char *__restrict Bn)\n{\n  size_t i = item.get_global_id(0);\n  if (i >= imgSize) return;\n  if ( sycl::abs(Img[i] - Img1[i]) <= Tn[i] && sycl::abs(Img[i] - Img2[i]) <= Tn[i] ) {\n    \n\n    Bn[i] = 0.92f * Bn[i] + 0.08f * Img[i];\n\n    \n\n    float th = 0.92f * Tn[i] + 0.24f * (Img[i] - Bn[i]);\n    Tn[i] = sycl::fmax(th, 20.f);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <image width> <image height> <merge> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int merged = atoi(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int imgSize = width * height;\n  const size_t imgSize_bytes = imgSize * sizeof(char);\n  unsigned char *Img = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Bn = (unsigned char*) malloc (imgSize_bytes);\n  unsigned char *Tn = (unsigned char*) malloc (imgSize_bytes);\n\n  std::mt19937 generator (123);\n  std::uniform_int_distribution<int> distribute( 0, 255 );\n\n  for (int j = 0; j < imgSize; j++) {\n    Bn[j] = distribute(generator);\n    Tn[j] = 128;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  unsigned char *d_Img, *d_Img1, *d_Img2;\n  unsigned char *d_Bn, *d_Mp, *d_Tn;\n  d_Img = sycl::malloc_device<unsigned char>(imgSize, q);\n  d_Img1 = sycl::malloc_device<unsigned char>(imgSize, q);\n  d_Img2 = sycl::malloc_device<unsigned char>(imgSize, q);\n  d_Bn = sycl::malloc_device<unsigned char>(imgSize, q);\n  d_Mp = sycl::malloc_device<unsigned char>(imgSize, q);\n  d_Tn = sycl::malloc_device<unsigned char>(imgSize, q);\n\n  q.memcpy(d_Bn, Bn, imgSize_bytes);\n  q.memcpy(d_Tn, Tn, imgSize_bytes);\n\n  sycl::range<1> gws ((imgSize + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE);\n  sycl::range<1> lws (BLOCK_SIZE);\n\n  long time = 0;\n\n  for (int i = 0; i < repeat; i++) {\n\n    for (int j = 0; j < imgSize; j++) {\n      Img[j] = distribute(generator);\n    }\n\n    q.memcpy(d_Img, Img, imgSize_bytes).wait();\n\n    \n\n    \n\n    \n\n    unsigned char *t = d_Img2;\n    d_Img2 = d_Img1;\n    d_Img1 = d_Img;\n    d_Img = t;\n\n    if (i >= 2) {\n      if (merged) {\n        auto start = std::chrono::steady_clock::now();\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for<class merged_kernel>(\n            sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n            merge ( item, imgSize, d_Img, d_Img1, d_Img2, d_Tn, d_Bn );\n          });\n        }).wait();\n        auto end = std::chrono::steady_clock::now();\n        time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      }\n      else {\n        auto start = std::chrono::steady_clock::now();\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for<class k1>(\n            sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n            findMovingPixels ( item, imgSize, d_Img, d_Img1, d_Img2, d_Tn, d_Mp );\n          });\n        });\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for<class k2>(\n            sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n            updateBackground  ( item, imgSize, d_Img, d_Mp, d_Bn );\n          });\n        });\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for<class k3>(\n            sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n            updateThreshold  ( item, imgSize, d_Img, d_Mp, d_Bn, d_Tn );\n          });\n        });\n        q.wait();\n        auto end = std::chrono::steady_clock::now();\n        time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      }\n    }\n  }\n\n  float kernel_time = (repeat <= 2) ? 0 : (time * 1e-3f) / (repeat - 2);\n  printf(\"Average kernel execution time: %f (us)\\n\", kernel_time);\n\n  q.memcpy(Tn, d_Tn, imgSize_bytes).wait();\n\n  \n\n  int sum = 0;\n  int bin[4] = {0, 0, 0, 0};\n  for (int j = 0; j < imgSize; j++) {\n    sum += abs(Tn[j] - 128);\n    if (Tn[j] < 64)\n      bin[0]++;\n    else if (Tn[j] < 128)\n      bin[1]++;\n    else if (Tn[j] < 192)\n      bin[2]++;\n    else\n      bin[3]++;\n  }\n  sum = sum / imgSize;\n  printf(\"Average threshold change is %d\\n\", sum);\n  printf(\"Bin counts are %d %d %d %d\\n\", bin[0], bin[1], bin[2], bin[3]);\n     \n  free(Img);\n  free(Tn);\n  free(Bn);\n  sycl::free(d_Img, q);\n  sycl::free(d_Img1, q);\n  sycl::free(d_Img2, q);\n  sycl::free(d_Tn, q);\n  sycl::free(d_Mp, q);\n  sycl::free(d_Bn, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "bezier-surface", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n#include <cuda.h>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\n__host__ __device__\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n    blend *= pow(mu, (FLOAT)k);\n  if(n - k > 0)\n    blend *= pow(1 - mu, (FLOAT)(n - k));\n  return (blend);\n}\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\n__global__\nvoid BezierGPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n\n  i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i > RESOLUTIONI) return;\n\n  mui = i / (FLOAT)(RESOLUTIONI - 1);\n  for(j = 0; j < RESOLUTIONJ; j++) {\n    muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n    XYZ out = {0, 0, 0};\n    \n\n    for(ki = 0; ki <= NI; ki++) {\n      bi = BezierBlend(ki, mui, NI);\n      \n\n      for(kj = 0; kj <= NJ; kj++) {\n        bj = BezierBlend(kj, muj, NJ);\n        out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n        out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n        out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n      }\n    }\n    outp[i * RESOLUTIONJ + j] = out;\n  }\n\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n  \n\n\n  XYZ *d_in;\n  XYZ *d_out;\n  int in_size   = (in_size_i + 1) * (in_size_j + 1) * sizeof(XYZ);\n  int out_size  = out_size_i * out_size_j * sizeof(XYZ);\n\n  cudaMalloc((void**)&d_in, in_size);\n  cudaMalloc((void**)&d_out, out_size);\n\n  cudaMemcpy(d_in, in, in_size, cudaMemcpyHostToDevice);\n\n  dim3 block(p.work_group_size);\n  dim3 grid((out_size_i + p.work_group_size - 1) / p.work_group_size);\n\n  cudaDeviceSynchronize();\n  auto kstart = std::chrono::steady_clock::now();\n\n  BezierGPU <<< grid, block >>> (d_in, d_out, in_size_i, in_size_j, out_size_i, out_size_j);\n\n  cudaDeviceSynchronize();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n  std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n\n  cudaMemcpy(gpu_out, d_out, out_size, cudaMemcpyDeviceToHost);\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n  cudaFree(d_in);\n  cudaFree(d_out);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}\n"}}
{"kernel_name": "bezier-surface", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n#include <hip/hip_runtime.h>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\n__host__ __device__\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n    blend *= pow(mu, (FLOAT)k);\n  if(n - k > 0)\n    blend *= pow(1 - mu, (FLOAT)(n - k));\n  return (blend);\n}\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\n__global__\nvoid BezierGPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n\n  i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i > RESOLUTIONI) return;\n\n  mui = i / (FLOAT)(RESOLUTIONI - 1);\n  for(j = 0; j < RESOLUTIONJ; j++) {\n    muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n    XYZ out = {0, 0, 0};\n    \n\n    for(ki = 0; ki <= NI; ki++) {\n      bi = BezierBlend(ki, mui, NI);\n      \n\n      for(kj = 0; kj <= NJ; kj++) {\n        bj = BezierBlend(kj, muj, NJ);\n        out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n        out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n        out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n      }\n    }\n    outp[i * RESOLUTIONJ + j] = out;\n  }\n\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n  \n\n\n  XYZ *d_in;\n  XYZ *d_out;\n  int in_size   = (in_size_i + 1) * (in_size_j + 1) * sizeof(XYZ);\n  int out_size  = out_size_i * out_size_j * sizeof(XYZ);\n\n  hipMalloc((void**)&d_in, in_size);\n  hipMalloc((void**)&d_out, out_size);\n\n  hipMemcpy(d_in, in, in_size, hipMemcpyHostToDevice);\n\n  dim3 block(p.work_group_size);\n  dim3 grid((out_size_i + p.work_group_size - 1) / p.work_group_size);\n\n  hipDeviceSynchronize();\n  auto kstart = std::chrono::steady_clock::now();\n\n  hipLaunchKernelGGL(BezierGPU, grid, block , 0, 0, d_in, d_out, in_size_i, in_size_j, out_size_i, out_size_j);\n\n  hipDeviceSynchronize();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n  std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n\n  hipMemcpy(gpu_out, d_out, out_size, hipMemcpyDeviceToHost);\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n  hipFree(d_in);\n  hipFree(d_out);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}\n"}}
{"kernel_name": "bezier-surface", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\n#pragma omp declare target\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n#if DOUBLE_PRECISION\n    blend *= pow(mu, (FLOAT)k);\n#else\n  blend *= powf(mu, (FLOAT)k);\n#endif\n  if(n - k > 0)\n#if DOUBLE_PRECISION\n    blend *= pow(1 - mu, (FLOAT)(n - k));\n#else\n  blend *= powf(1 - mu, (FLOAT)(n - k));\n#endif\n  return (blend);\n}\n#pragma omp end declare target\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n  #pragma omp target data map(to: in[0:(in_size_i+1)*(in_size_j+1)]) \\\n                          map(from: gpu_out [0:out_size_i*out_size_j])\n  {\n    auto kstart = std::chrono::steady_clock::now();\n\n    #pragma omp target teams distribute parallel for simd thread_limit(256)\n    for (int i = 0; i < out_size_i; i++) {\n      FLOAT   mui = i / (FLOAT)(out_size_i - 1);\n      for(int j = 0; j < out_size_j; j++) {\n        FLOAT muj     = j / (FLOAT)(out_size_j - 1);\n        XYZ out = {0, 0, 0};\n        \n\n        for(int ki = 0; ki <= in_size_i; ki++) {\n          FLOAT bi = BezierBlend(ki, mui, in_size_i);\n          \n\n          for(int kj = 0; kj <= in_size_j; kj++) {\n            FLOAT bj = BezierBlend(kj, muj, in_size_j);\n            out.x += (in[ki * (in_size_j + 1) + kj].x * bi * bj);\n            out.y += (in[ki * (in_size_j + 1) + kj].y * bi * bj);\n            out.z += (in[ki * (in_size_j + 1) + kj].z * bi * bj);\n          }\n        }\n        gpu_out[i * out_size_j + j] = out;\n      }\n    }\n\n    auto kend = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n    std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n  }\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}\n"}}
{"kernel_name": "bezier-surface", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n#if DOUBLE_PRECISION\n    blend *= pow(mu, (FLOAT)k);\n#else\n  blend *= powf(mu, (FLOAT)k);\n#endif\n  if(n - k > 0)\n#if DOUBLE_PRECISION\n    blend *= pow(1 - mu, (FLOAT)(n - k));\n#else\n  blend *= powf(1 - mu, (FLOAT)(n - k));\n#endif\n  return (blend);\n}\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n    {\n    auto kstart = std::chrono::steady_clock::now();\n\n        for (int i = 0; i < out_size_i; i++) {\n      FLOAT   mui = i / (FLOAT)(out_size_i - 1);\n      for(int j = 0; j < out_size_j; j++) {\n        FLOAT muj     = j / (FLOAT)(out_size_j - 1);\n        XYZ out = {0, 0, 0};\n        \n\n        for(int ki = 0; ki <= in_size_i; ki++) {\n          FLOAT bi = BezierBlend(ki, mui, in_size_i);\n          \n\n          for(int kj = 0; kj <= in_size_j; kj++) {\n            FLOAT bj = BezierBlend(kj, muj, in_size_j);\n            out.x += (in[ki * (in_size_j + 1) + kj].x * bi * bj);\n            out.y += (in[ki * (in_size_j + 1) + kj].y * bi * bj);\n            out.z += (in[ki * (in_size_j + 1) + kj].z * bi * bj);\n          }\n        }\n        gpu_out[i * out_size_j + j] = out;\n      }\n    }\n\n    auto kend = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n    std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n  }\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}"}}
{"kernel_name": "bezier-surface", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n#include <sycl/sycl.hpp>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name     = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += std::fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += std::fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += std::fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += std::fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += std::fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += std::fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n    blend *= sycl::pow(mu, (FLOAT)k);\n  if(n - k > 0)\n    blend *= sycl::pow(1 - mu, (FLOAT)(n - k));\n  return (blend);\n}\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n  \n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int in_size   = (in_size_i + 1) * (in_size_j + 1);\n  int out_size  = out_size_i * out_size_j;\n\n  XYZ *d_in = sycl::malloc_device<XYZ>(in_size, q);\n  q.memcpy(d_in, in, sizeof(XYZ) * in_size);\n\n  XYZ *d_out = sycl::malloc_device<XYZ>(out_size, q);\n\n  size_t lws = p.work_group_size;\n  size_t gws = (out_size_i + p.work_group_size - 1) / p.work_group_size * p.work_group_size;\n\n  q.wait();\n  auto kstart = std::chrono::steady_clock::now();\n\n  q.submit([&](sycl::handler& cgh) {\n    cgh.parallel_for<class bs>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      int i, j, ki, kj;\n      FLOAT   mui, muj, bi, bj;\n\n      i = item.get_global_id(0);\n      if (i >= out_size_i) return;\n\n      mui = i / (FLOAT)(out_size_i - 1);\n      for(j = 0; j < out_size_j; j++) {\n        muj     = j / (FLOAT)(out_size_j - 1);\n        XYZ out = {0, 0, 0};\n\n        \n\n        for(ki = 0; ki <= in_size_i; ki++) {\n          bi = BezierBlend(ki, mui, in_size_i);\n          \n\n          for(kj = 0; kj <= in_size_j; kj++) {\n            bj = BezierBlend(kj, muj, in_size_j);\n            out.x += (d_in[ki * (in_size_j + 1) + kj].x * bi * bj);\n            out.y += (d_in[ki * (in_size_j + 1) + kj].y * bi * bj);\n            out.z += (d_in[ki * (in_size_j + 1) + kj].z * bi * bj);\n          }\n        }\n        d_out[i * out_size_j + j] = out;\n      }\n    });\n  });\n\n  q.wait();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n  std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n\n  q.memcpy(gpu_out, d_out, sizeof(XYZ) * out_size).wait();\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n  sycl::free(d_in, q);\n  sycl::free(d_out, q);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}\n"}}
{"kernel_name": "bilateral", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <cuda.h>\n#include <chrono>\n#include \"reference.h\"\n\ntemplate<int R>\n__global__ void bilateralFilter(\n    const float *__restrict__ in,\n    float *__restrict__ out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n  const int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  const int idy = blockIdx.y*blockDim.y + threadIdx.y;\n\n  if(idx >= w || idy >= h) return;\n\n  int id = idy*w + idx;\n  float I = in[id];\n  float res = 0;\n  float normalization = 0;\n\n  \n\n#ifdef LOOP_UNROLL\n  #pragma unroll\n#endif\n  for(int i = -R; i <= R; i++) {\n#ifdef LOOP_UNROLL\n    #pragma unroll\n#endif\n    for(int j = -R; j <= R; j++) {\n\n      int idk = idx+i;\n      int idl = idy+j;\n\n      \n\n      if( idk < 0) idk = -idk;\n      if( idl < 0) idl = -idl;\n      if( idk > w - 1) idk = w - 1 - i;\n      if( idl > h - 1) idl = h - 1 - j;\n\n      int id_w = idl*w + idk;\n      float I_w = in[id_w];\n\n      \n\n      float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n      \n\n      float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n                      (2.f * variance_spatial);\n\n      \n\n      \n\n      float weight = a_square * expf(spatial + range);\n\n      normalization += weight;\n      res += (I_w * weight);\n    }\n  }\n  out[id] = res/normalization;\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n   \n\n   \n\n   \n\n   \n\n  float variance_I = atof(argv[3]);\n\n   \n\n  float variance_spatial = atof(argv[4]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  int repeat = atoi(argv[5]);\n\n  float *d_src, *d_dst;\n  cudaMalloc((void**)&d_dst, img_size * sizeof(float));\n  cudaMalloc((void**)&d_src, img_size * sizeof(float));\n\n  float *h_src = (float*) malloc (img_size * sizeof(float));\n  \n\n  float *h_dst = (float*) malloc (img_size * sizeof(float));\n  float *r_dst = (float*) malloc (img_size * sizeof(float));\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n  cudaMemcpy(d_src, h_src, img_size * sizeof(float), cudaMemcpyHostToDevice); \n\n  dim3 threads (16, 16);\n  dim3 blocks ((w+15)/16, (h+15)/16);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<3><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(h_dst, d_dst, img_size * sizeof(float), cudaMemcpyDeviceToHost); \n\n  \n\n  bool ok = true;\n  reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<6><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(h_dst, d_dst, img_size * sizeof(float), cudaMemcpyDeviceToHost); \n\n  reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<9><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(h_dst, d_dst, img_size * sizeof(float), cudaMemcpyDeviceToHost); \n\n  reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  cudaFree(d_dst);\n  cudaFree(d_src);\n  return 0;\n}\n"}}
{"kernel_name": "bilateral", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <hip/hip_runtime.h>\n#include <chrono>\n#include \"reference.h\"\n\ntemplate<int R>\n__global__ void bilateralFilter(\n    const float *__restrict__ in,\n    float *__restrict__ out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n  const int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  const int idy = blockIdx.y*blockDim.y + threadIdx.y;\n\n  if(idx >= w || idy >= h) return;\n\n  int id = idy*w + idx;\n  float I = in[id];\n  float res = 0;\n  float normalization = 0;\n\n  \n\n#ifdef LOOP_UNROLL\n  #pragma unroll\n#endif\n  for(int i = -R; i <= R; i++) {\n#ifdef LOOP_UNROLL\n    #pragma unroll\n#endif\n    for(int j = -R; j <= R; j++) {\n\n      int idk = idx+i;\n      int idl = idy+j;\n\n      \n\n      if( idk < 0) idk = -idk;\n      if( idl < 0) idl = -idl;\n      if( idk > w - 1) idk = w - 1 - i;\n      if( idl > h - 1) idl = h - 1 - j;\n\n      int id_w = idl*w + idk;\n      float I_w = in[id_w];\n\n      \n\n      float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n      \n\n      float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n                      (2.f * variance_spatial);\n\n      \n\n      \n\n      float weight = a_square * expf(spatial + range);\n\n      normalization += weight;\n      res += (I_w * weight);\n    }\n  }\n  out[id] = res/normalization;\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n   \n\n   \n\n   \n\n   \n\n  float variance_I = atof(argv[3]);\n\n   \n\n  float variance_spatial = atof(argv[4]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  int repeat = atoi(argv[5]);\n\n  float *d_src, *d_dst;\n  hipMalloc((void**)&d_dst, img_size * sizeof(float));\n  hipMalloc((void**)&d_src, img_size * sizeof(float));\n\n  float *h_src = (float*) malloc (img_size * sizeof(float));\n  \n\n  float *h_dst = (float*) malloc (img_size * sizeof(float));\n  float *r_dst = (float*) malloc (img_size * sizeof(float));\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n  hipMemcpy(d_src, h_src, img_size * sizeof(float), hipMemcpyHostToDevice); \n\n  dim3 threads (16, 16);\n  dim3 blocks ((w+15)/16, (h+15)/16);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<3><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(h_dst, d_dst, img_size * sizeof(float), hipMemcpyDeviceToHost); \n\n  \n\n  bool ok = true;\n  reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<6><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(h_dst, d_dst, img_size * sizeof(float), hipMemcpyDeviceToHost); \n\n  reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<9><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(h_dst, d_dst, img_size * sizeof(float), hipMemcpyDeviceToHost); \n\n  reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  hipFree(d_dst);\n  hipFree(d_src);\n  return 0;\n}\n"}}
{"kernel_name": "bilateral", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\ntemplate<int R>\nvoid bilateralFilter(\n    const float *__restrict in,\n    float *__restrict out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n  #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n  for (int idy = 0; idy < h; idy++)\n    for (int idx = 0; idx < w; idx++) {\n\n      int id = idy*w + idx;\n      float I = in[id];\n      float res = 0;\n      float normalization = 0;\n\n      \n\n      #ifdef LOOP_UNROLL\n      #pragma unroll\n      #endif\n      for(int i = -R; i <= R; i++) {\n      #ifdef LOOP_UNROLL\n      #pragma unroll\n      #endif\n        for(int j = -R; j <= R; j++) {\n\n          int idk = idx+i;\n          int idl = idy+j;\n\n          \n\n          if( idk < 0) idk = -idk;\n          if( idl < 0) idl = -idl;\n          if( idk > w - 1) idk = w - 1 - i;\n          if( idl > h - 1) idl = h - 1 - j;\n\n          int id_w = idl*w + idk;\n          float I_w = in[id_w];\n\n          \n\n          float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n          \n\n          float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n            (2.f * variance_spatial);\n\n          \n\n          \n\n          float weight = a_square * expf(spatial + range);\n\n          normalization += weight;\n          res += (I_w * weight);\n        }\n      }\n      out[id] = res/normalization;\n    }\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n  \n\n  \n\n  \n\n  \n\n  float variance_I = atof(argv[3]);\n\n  \n\n  float variance_spatial = atof(argv[4]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  int repeat = atoi(argv[5]);\n\n  float *h_src = (float*) malloc (img_size * sizeof(float));\n  \n\n  float *h_dst = (float*) malloc (img_size * sizeof(float));\n  float *r_dst = (float*) malloc (img_size * sizeof(float));\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n  #pragma omp target data map(to: h_src[0:img_size]) \\\n                          map(alloc: h_dst[0:img_size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<3>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    #pragma omp target update from (h_dst[0:img_size])\n\n    \n\n    bool ok = true;\n    reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<6>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    #pragma omp target update from (h_dst[0:img_size])\n\n    reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<9>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    #pragma omp target update from (h_dst[0:img_size])\n\n    reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  return 0;\n}\n"}}
{"kernel_name": "bilateral", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\ntemplate<int R>\nvoid bilateralFilter(\n    const float *__restrict in,\n    float *__restrict out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n    for (int idy = 0; idy < h; idy++)\n    for (int idx = 0; idx < w; idx++) {\n\n      int id = idy*w + idx;\n      float I = in[id];\n      float res = 0;\n      float normalization = 0;\n\n      \n\n      #ifdef LOOP_UNROLL\n            #endif\n      for(int i = -R; i <= R; i++) {\n      #ifdef LOOP_UNROLL\n            #endif\n        for(int j = -R; j <= R; j++) {\n\n          int idk = idx+i;\n          int idl = idy+j;\n\n          \n\n          if( idk < 0) idk = -idk;\n          if( idl < 0) idl = -idl;\n          if( idk > w - 1) idk = w - 1 - i;\n          if( idl > h - 1) idl = h - 1 - j;\n\n          int id_w = idl*w + idk;\n          float I_w = in[id_w];\n\n          \n\n          float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n          \n\n          float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n            (2.f * variance_spatial);\n\n          \n\n          \n\n          float weight = a_square * expf(spatial + range);\n\n          normalization += weight;\n          res += (I_w * weight);\n        }\n      }\n      out[id] = res/normalization;\n    }\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n  \n\n  \n\n  \n\n  \n\n  float variance_I = atof(argv[3]);\n\n  \n\n  float variance_spatial = atof(argv[4]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  int repeat = atoi(argv[5]);\n\n  float *h_src = (float*) malloc (img_size * sizeof(float));\n  \n\n  float *h_dst = (float*) malloc (img_size * sizeof(float));\n  float *r_dst = (float*) malloc (img_size * sizeof(float));\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<3>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    \n    \n\n    bool ok = true;\n    reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<6>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    \n    reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<9>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    \n    reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  return 0;\n}"}}
{"kernel_name": "bilateral", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\ntemplate<int R>\nvoid bilateralFilter(\n    sycl::nd_item<2> &item,\n    const float *__restrict in,\n    float *__restrict out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n  const int idx = item.get_global_id(1);\n  const int idy = item.get_global_id(0);\n\n  if(idx >= w || idy >= h) return;\n\n  int id = idy*w + idx;\n  float I = in[id];\n  float res = 0;\n  float normalization = 0;\n\n  \n\n#ifdef LOOP_UNROLL\n  #pragma unroll\n#endif\n  for(int i = -R; i <= R; i++) {\n#ifdef LOOP_UNROLL\n    #pragma unroll\n#endif\n    for(int j = -R; j <= R; j++) {\n\n      int idk = idx+i;\n      int idl = idy+j;\n\n      \n\n      if( idk < 0) idk = -idk;\n      if( idl < 0) idl = -idl;\n      if( idk > w - 1) idk = w - 1 - i;\n      if( idl > h - 1) idl = h - 1 - j;\n\n      int id_w = idl*w + idk;\n      float I_w = in[id_w];\n\n      \n\n      float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n      \n\n      float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n                      (2.f * variance_spatial);\n\n      \n\n      \n\n      float weight = a_square * sycl::exp(spatial + range);\n\n      normalization += weight;\n      res += (I_w * weight);\n    }\n  }\n  out[id] = res/normalization;\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n   \n\n   \n\n   \n\n   \n\n  float variance_I = atof(argv[3]);\n\n   \n\n  float variance_spatial = atof(argv[4]);\n\n  int repeat = atoi(argv[5]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  const size_t img_size_bytes = img_size * sizeof(float);\n\n  float *h_src = (float*) malloc (img_size_bytes);\n  \n\n  float *h_dst = (float*) malloc (img_size_bytes);\n  float *r_dst = (float*) malloc (img_size_bytes);\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_src = sycl::malloc_device<float>(img_size, q);\n  q.memcpy(d_src, h_src, img_size_bytes);\n\n  float *d_dst = sycl::malloc_device<float>(img_size, q);\n\n  sycl::range<2> lws (16, 16);\n  sycl::range<2> gws ((h+15)/16*16, (w+15)/16*16);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class radius3x3>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        bilateralFilter<3>(item, d_src, d_dst,\n                           w, h, a_square, variance_I, variance_spatial);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(h_dst, d_dst, img_size_bytes).wait();\n\n  \n\n  bool ok = true;\n  reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class radius6x6>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        bilateralFilter<6>(item, d_src, d_dst,\n                           w, h, a_square, variance_I, variance_spatial);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(h_dst, d_dst, img_size_bytes).wait();\n\n  reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class radius9x9>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        bilateralFilter<9>(item, d_src, d_dst,\n                           w, h, a_square, variance_I, variance_spatial);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(h_dst, d_dst, img_size_bytes).wait();\n\n  reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  sycl::free(d_dst, q);\n  sycl::free(d_src, q);\n  return 0;\n}\n"}}
{"kernel_name": "boxfilter", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <chrono>\n#include <memory>\n#include <iostream>\n#include <cuda.h>\n#include \"shrUtils.h\"\n#include \"helper_math.h\"\n\nextern void BoxFilterHost(unsigned int* uiInputImage, unsigned int* uiTempImage, unsigned int* uiOutputImage, \n                          unsigned int uiWidth, unsigned int uiHeight, int iRadius, float fScale );\n\n\nconst unsigned int RADIUS = 10;                   \n\nconst float SCALE = 1.0f/(2.0f * RADIUS + 1.0f);  \n\n\ninline uint DivUp(const uint a, const uint b){\n  return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n\n\n__device__\nfloat4 rgbaUintToFloat4(const unsigned int c)\n{\n  float4 rgba;\n  rgba.x = c & 0xff;\n  rgba.y = (c >> 8) & 0xff;\n  rgba.z = (c >> 16) & 0xff;\n  rgba.w = (c >> 24) & 0xff;\n  return rgba;\n}\n\n\n\n__device__\nunsigned int rgbaFloat4ToUint(const float4 rgba, const float fScale)\n{\n  unsigned int uiPackedPix = 0U;\n  uiPackedPix |= 0x000000FF & (unsigned int)(rgba.x * fScale);\n  uiPackedPix |= 0x0000FF00 & (((unsigned int)(rgba.y * fScale)) << 8);\n  uiPackedPix |= 0x00FF0000 & (((unsigned int)(rgba.z * fScale)) << 16);\n  uiPackedPix |= 0xFF000000 & (((unsigned int)(rgba.w * fScale)) << 24);\n  return uiPackedPix;\n}\n\n__global__ void row_kernel (\n    const uchar4* __restrict__ ucSource, \n            uint* __restrict__ uiDest,\n    const unsigned int uiWidth,\n    const unsigned int uiHeight,\n    const int iRadius,\n    const int iRadiusAligned, \n    const float fScale, \n    const unsigned int uiNumOutputPix)\n{\n  extern __shared__ uchar4 uc4LocalData[];\n\n  int lid = threadIdx.x;\n  int gidx = blockIdx.x;\n  int gidy = blockIdx.y; \n\n  int globalPosX = gidx * uiNumOutputPix + lid - iRadiusAligned;\n  int globalPosY = gidy;\n  int iGlobalOffset = globalPosY * uiWidth + globalPosX;\n\n  \n\n  if (globalPosX >= 0 && globalPosX < uiWidth)\n  {\n    uc4LocalData[lid] = ucSource[iGlobalOffset];\n  }\n  else\n    uc4LocalData[lid] = {0, 0, 0, 0}; \n\n  __syncthreads();\n\n  if((globalPosX >= 0) && (globalPosX < uiWidth) && (lid >= iRadiusAligned) && \n      (lid < (iRadiusAligned + (int)uiNumOutputPix)))\n  {\n    \n\n    float4 f4Sum = {0.0f, 0.0f, 0.0f, 0.0f};\n\n    \n\n    int iOffsetX = lid - iRadius;\n    int iLimit = iOffsetX + (2 * iRadius) + 1;\n    for(; iOffsetX < iLimit; iOffsetX++)\n    {\n      f4Sum.x += uc4LocalData[iOffsetX].x;\n      f4Sum.y += uc4LocalData[iOffsetX].y;\n      f4Sum.z += uc4LocalData[iOffsetX].z;\n      f4Sum.w += uc4LocalData[iOffsetX].w; \n    }\n\n    \n\n    \n\n    uiDest[iGlobalOffset] = rgbaFloat4ToUint(f4Sum, fScale);\n  }\n}\n\n__global__ void col_kernel (\n    const uint* __restrict__ uiSource,\n          uint* __restrict__ uiDest,\n    const unsigned int uiWidth, \n    const unsigned int uiHeight, \n    const int iRadius, \n    const float fScale)\n{\n  size_t globalPosX = blockIdx.x * blockDim.x + threadIdx.x;\n  const uint* uiInputImage = &uiSource[globalPosX];\n  uint* uiOutputImage = &uiDest[globalPosX];\n\n  float4 f4Sum;\n\n  float4 top_color = rgbaUintToFloat4(uiInputImage[0]);\n  float4 bot_color = rgbaUintToFloat4(uiInputImage[(uiHeight - 1) * uiWidth]);\n\n  f4Sum = top_color *\n          make_float4((float)iRadius, (float)iRadius, (float)iRadius, (float)iRadius); \n  for (int y = 0; y < iRadius + 1; y++) \n  {\n    f4Sum += rgbaUintToFloat4(uiInputImage[y * uiWidth]);\n  }\n  uiOutputImage[0] = rgbaFloat4ToUint(f4Sum, fScale);\n\n  for(int y = 1; y < iRadius + 1; y++) \n  {\n    f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n    f4Sum -= top_color;\n    uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n  }\n\n  for(int y = iRadius + 1; y < uiHeight - iRadius; y++) \n  {\n    f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n    f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n    uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n  }\n\n  for (int y = uiHeight - iRadius; y < uiHeight; y++) \n  {\n    f4Sum += bot_color;\n    f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n    uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n  }\n}\n\nvoid BoxFilterGPU (uchar4* cmBufIn,\n    unsigned int* cmBufTmp,\n    unsigned int* cmBufOut,\n    const unsigned int uiWidth, \n    const unsigned int uiHeight, \n    const int iRadius, \n    const float fScale,\n    const int iCycles )\n{\n  const int szMaxWorkgroupSize = 256;\n  const int iRadiusAligned = ((iRadius + 15)/16) * 16;  \n\n  unsigned int uiNumOutputPix = 64;  \n\n  if (szMaxWorkgroupSize < (iRadiusAligned + uiNumOutputPix + iRadius))\n    uiNumOutputPix = szMaxWorkgroupSize - iRadiusAligned - iRadius;\n\n  \n\n  dim3 row_grid(DivUp((size_t)uiWidth, (size_t)uiNumOutputPix), uiHeight); \n  dim3 row_block((size_t)(iRadiusAligned + uiNumOutputPix + iRadius), 1);\n\n  \n\n  dim3 col_grid(DivUp((size_t)uiWidth, 64));\n  dim3 col_block(64);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iCycles; i++) {\n    \n\n    row_kernel<<<row_grid, row_block, sizeof(uchar4)*(iRadiusAligned+uiNumOutputPix+iRadius)>>> (\n        cmBufIn, cmBufTmp, uiWidth, uiHeight, iRadius, iRadiusAligned, fScale, uiNumOutputPix);\n\n\n    \n\n    col_kernel<<<col_grid, col_block>>>(cmBufTmp, cmBufOut, uiWidth, uiHeight, iRadius, fScale);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (us)\\n\", (time * 1e-3f) / iCycles);\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 3) {\n    printf(\"Usage %s <PPM image> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  unsigned int uiImageWidth = 0;     \n\n  unsigned int uiImageHeight = 0;    \n\n  unsigned int* uiInput = NULL;      \n\n  unsigned int* uiTmp = NULL;        \n\n  unsigned int* uiDevOutput = NULL;      \n  unsigned int* uiHostOutput = NULL;      \n\n  shrLoadPPM4ub(argv[1], (unsigned char**)&uiInput, &uiImageWidth, &uiImageHeight);\n  printf(\"Image Width = %u, Height = %u, bpp = %u, Mask Radius = %u\\n\", \n      uiImageWidth, uiImageHeight, unsigned(sizeof(unsigned int) * 8), RADIUS);\n  printf(\"Using Local Memory for Row Processing\\n\\n\");\n\n  size_t szBuff= uiImageWidth * uiImageHeight;\n  size_t szBuffBytes = szBuff * sizeof (unsigned int);\n\n  \n\n  uiTmp = (unsigned int*)malloc(szBuffBytes);\n  uiDevOutput = (unsigned int*)malloc(szBuffBytes);\n  uiHostOutput = (unsigned int*)malloc(szBuffBytes);\n\n  uchar4* cmDevBufIn;\n  unsigned int* cmDevBufTmp;\n  unsigned int* cmDevBufOut;\n\n  cudaMalloc((void**)&cmDevBufIn, szBuffBytes);\n  cudaMalloc((void**)&cmDevBufTmp, szBuffBytes);\n  cudaMalloc((void**)&cmDevBufOut, szBuffBytes);\n\n  \n\n  cudaMemcpy(cmDevBufIn, uiInput, szBuffBytes, cudaMemcpyHostToDevice);\n\n  const int iCycles = atoi(argv[2]);\n\n  printf(\"Warmup..\\n\");\n  BoxFilterGPU (cmDevBufIn, cmDevBufTmp, cmDevBufOut, \n                uiImageWidth, uiImageHeight, RADIUS, SCALE, iCycles);\n\n  printf(\"\\nRunning BoxFilterGPU for %d cycles...\\n\\n\", iCycles);\n  BoxFilterGPU (cmDevBufIn, cmDevBufTmp, cmDevBufOut, \n                uiImageWidth, uiImageHeight, RADIUS, SCALE, iCycles);\n\n  \n\n  cudaMemcpy(uiDevOutput, cmDevBufOut, szBuffBytes, cudaMemcpyDeviceToHost);\n\n  cudaFree(cmDevBufIn);\n  cudaFree(cmDevBufTmp);\n  cudaFree(cmDevBufOut);\n\n  \n\n  BoxFilterHost(uiInput, uiTmp, uiHostOutput, uiImageWidth, uiImageHeight, RADIUS, SCALE);\n\n  \n\n  \n\n  int error = 0;\n  for (unsigned i = RADIUS * uiImageWidth; i < (uiImageHeight-RADIUS)*uiImageWidth; i++)\n  {\n    if (uiDevOutput[i] != uiHostOutput[i]) {\n      printf(\"%d %08x %08x\\n\", i, uiDevOutput[i], uiHostOutput[i]);\n      error = 1;\n      break;\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(uiInput);\n  free(uiTmp);\n  free(uiDevOutput);\n  free(uiHostOutput);\n  return 0;\n}\n"}}
{"kernel_name": "boxfilter", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <chrono>\n#include <memory>\n#include <iostream>\n#include <hip/hip_runtime.h>\n#include \"shrUtils.h\"\n\nextern void BoxFilterHost(unsigned int* uiInputImage, unsigned int* uiTempImage, unsigned int* uiOutputImage, \n                          unsigned int uiWidth, unsigned int uiHeight, int iRadius, float fScale );\n\n\nconst unsigned int RADIUS = 10;                   \n\nconst float SCALE = 1.0f/(2.0f * RADIUS + 1.0f);  \n\n\ninline uint DivUp(const uint a, const uint b){\n  return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n\n\n__device__\nfloat4 rgbaUintToFloat4(const unsigned int c)\n{\n  float4 rgba;\n  rgba.x = c & 0xff;\n  rgba.y = (c >> 8) & 0xff;\n  rgba.z = (c >> 16) & 0xff;\n  rgba.w = (c >> 24) & 0xff;\n  return rgba;\n}\n\n\n\n__device__\nunsigned int rgbaFloat4ToUint(const float4 rgba, const float fScale)\n{\n  unsigned int uiPackedPix = 0U;\n  uiPackedPix |= 0x000000FF & (unsigned int)(rgba.x * fScale);\n  uiPackedPix |= 0x0000FF00 & (((unsigned int)(rgba.y * fScale)) << 8);\n  uiPackedPix |= 0x00FF0000 & (((unsigned int)(rgba.z * fScale)) << 16);\n  uiPackedPix |= 0xFF000000 & (((unsigned int)(rgba.w * fScale)) << 24);\n  return uiPackedPix;\n}\n\n__global__ void row_kernel (\n    const uchar4* __restrict__ ucSource, \n            uint* __restrict__ uiDest,\n    const unsigned int uiWidth,\n    const unsigned int uiHeight,\n    const int iRadius,\n    const int iRadiusAligned, \n    const float fScale, \n    const unsigned int uiNumOutputPix)\n{\n  extern __shared__ uchar4 uc4LocalData[];\n\n  int lid = threadIdx.x;\n  int gidx = blockIdx.x;\n  int gidy = blockIdx.y; \n\n  int globalPosX = gidx * uiNumOutputPix + lid - iRadiusAligned;\n  int globalPosY = gidy;\n  int iGlobalOffset = globalPosY * uiWidth + globalPosX;\n\n  \n\n  if (globalPosX >= 0 && globalPosX < uiWidth)\n  {\n    uc4LocalData[lid] = ucSource[iGlobalOffset];\n  }\n  else\n    uc4LocalData[lid] = {0, 0, 0, 0}; \n\n  __syncthreads();\n\n  if((globalPosX >= 0) && (globalPosX < uiWidth) && (lid >= iRadiusAligned) && \n      (lid < (iRadiusAligned + (int)uiNumOutputPix)))\n  {\n    \n\n    float4 f4Sum = {0.0f, 0.0f, 0.0f, 0.0f};\n\n    \n\n    int iOffsetX = lid - iRadius;\n    int iLimit = iOffsetX + (2 * iRadius) + 1;\n    for(; iOffsetX < iLimit; iOffsetX++)\n    {\n      f4Sum.x += uc4LocalData[iOffsetX].x;\n      f4Sum.y += uc4LocalData[iOffsetX].y;\n      f4Sum.z += uc4LocalData[iOffsetX].z;\n      f4Sum.w += uc4LocalData[iOffsetX].w; \n    }\n\n    \n\n    \n\n    uiDest[iGlobalOffset] = rgbaFloat4ToUint(f4Sum, fScale);\n  }\n}\n\n__global__ void col_kernel (\n    const uint* __restrict__ uiSource,\n          uint* __restrict__ uiDest,\n    const unsigned int uiWidth, \n    const unsigned int uiHeight, \n    const int iRadius, \n    const float fScale)\n{\n  size_t globalPosX = blockIdx.x * blockDim.x + threadIdx.x;\n  const uint* uiInputImage = &uiSource[globalPosX];\n  uint* uiOutputImage = &uiDest[globalPosX];\n\n  float4 f4Sum;\n\n  float4 top_color = rgbaUintToFloat4(uiInputImage[0]);\n  float4 bot_color = rgbaUintToFloat4(uiInputImage[(uiHeight - 1) * uiWidth]);\n\n  f4Sum = top_color *\n          make_float4((float)iRadius, (float)iRadius, (float)iRadius, (float)iRadius); \n  for (int y = 0; y < iRadius + 1; y++) \n  {\n    f4Sum += rgbaUintToFloat4(uiInputImage[y * uiWidth]);\n  }\n  uiOutputImage[0] = rgbaFloat4ToUint(f4Sum, fScale);\n\n  for(int y = 1; y < iRadius + 1; y++) \n  {\n    f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n    f4Sum -= top_color;\n    uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n  }\n\n  for(int y = iRadius + 1; y < uiHeight - iRadius; y++) \n  {\n    f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n    f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n    uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n  }\n\n  for (int y = uiHeight - iRadius; y < uiHeight; y++) \n  {\n    f4Sum += bot_color;\n    f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n    uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n  }\n}\n\nvoid BoxFilterGPU (uchar4* cmBufIn,\n    unsigned int* cmBufTmp,\n    unsigned int* cmBufOut,\n    const unsigned int uiWidth, \n    const unsigned int uiHeight, \n    const int iRadius, \n    const float fScale,\n    const int iCycles )\n{\n  const int szMaxWorkgroupSize = 256;\n  const int iRadiusAligned = ((iRadius + 15)/16) * 16;  \n\n  unsigned int uiNumOutputPix = 64;  \n\n  if (szMaxWorkgroupSize < (iRadiusAligned + uiNumOutputPix + iRadius))\n    uiNumOutputPix = szMaxWorkgroupSize - iRadiusAligned - iRadius;\n\n  \n\n  dim3 row_grid(DivUp((size_t)uiWidth, (size_t)uiNumOutputPix), uiHeight); \n  dim3 row_block((size_t)(iRadiusAligned + uiNumOutputPix + iRadius), 1);\n\n  \n\n  dim3 col_grid(DivUp((size_t)uiWidth, 64));\n  dim3 col_block(64);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iCycles; i++) {\n    \n\n    row_kernel<<<row_grid, row_block, sizeof(uchar4)*(iRadiusAligned+uiNumOutputPix+iRadius)>>> (\n        cmBufIn, cmBufTmp, uiWidth, uiHeight, iRadius, iRadiusAligned, fScale, uiNumOutputPix);\n\n\n    \n\n    col_kernel<<<col_grid, col_block>>>(cmBufTmp, cmBufOut, uiWidth, uiHeight, iRadius, fScale);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (us)\\n\", (time * 1e-3f) / iCycles);\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 3) {\n    printf(\"Usage %s <PPM image> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  unsigned int uiImageWidth = 0;     \n\n  unsigned int uiImageHeight = 0;    \n\n  unsigned int* uiInput = NULL;      \n\n  unsigned int* uiTmp = NULL;        \n\n  unsigned int* uiDevOutput = NULL;      \n  unsigned int* uiHostOutput = NULL;      \n\n  shrLoadPPM4ub(argv[1], (unsigned char**)&uiInput, &uiImageWidth, &uiImageHeight);\n  printf(\"Image Width = %u, Height = %u, bpp = %u, Mask Radius = %u\\n\", \n      uiImageWidth, uiImageHeight, unsigned(sizeof(unsigned int) * 8), RADIUS);\n  printf(\"Using Local Memory for Row Processing\\n\\n\");\n\n  size_t szBuff= uiImageWidth * uiImageHeight;\n  size_t szBuffBytes = szBuff * sizeof (unsigned int);\n\n  \n\n  uiTmp = (unsigned int*)malloc(szBuffBytes);\n  uiDevOutput = (unsigned int*)malloc(szBuffBytes);\n  uiHostOutput = (unsigned int*)malloc(szBuffBytes);\n\n  uchar4* cmDevBufIn;\n  unsigned int* cmDevBufTmp;\n  unsigned int* cmDevBufOut;\n\n  hipMalloc((void**)&cmDevBufIn, szBuffBytes);\n  hipMalloc((void**)&cmDevBufTmp, szBuffBytes);\n  hipMalloc((void**)&cmDevBufOut, szBuffBytes);\n\n  \n\n  hipMemcpy(cmDevBufIn, uiInput, szBuffBytes, hipMemcpyHostToDevice);\n\n  const int iCycles = atoi(argv[2]);\n\n  printf(\"Warmup..\\n\");\n  BoxFilterGPU (cmDevBufIn, cmDevBufTmp, cmDevBufOut, \n                uiImageWidth, uiImageHeight, RADIUS, SCALE, iCycles);\n\n  printf(\"\\nRunning BoxFilterGPU for %d cycles...\\n\\n\", iCycles);\n  BoxFilterGPU (cmDevBufIn, cmDevBufTmp, cmDevBufOut, \n                uiImageWidth, uiImageHeight, RADIUS, SCALE, iCycles);\n\n  \n\n  hipMemcpy(uiDevOutput, cmDevBufOut, szBuffBytes, hipMemcpyDeviceToHost);\n\n  hipFree(cmDevBufIn);\n  hipFree(cmDevBufTmp);\n  hipFree(cmDevBufOut);\n\n  \n\n  BoxFilterHost(uiInput, uiTmp, uiHostOutput, uiImageWidth, uiImageHeight, RADIUS, SCALE);\n\n  \n\n  \n\n  int error = 0;\n  for (unsigned i = RADIUS * uiImageWidth; i < (uiImageHeight-RADIUS)*uiImageWidth; i++)\n  {\n    if (uiDevOutput[i] != uiHostOutput[i]) {\n      printf(\"%d %08x %08x\\n\", i, uiDevOutput[i], uiHostOutput[i]);\n      error = 1;\n      break;\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(uiInput);\n  free(uiTmp);\n  free(uiDevOutput);\n  free(uiHostOutput);\n  return 0;\n}\n"}}
{"kernel_name": "boxfilter", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <chrono>\n#include <memory>\n#include <iostream>\n#include <omp.h>\n#include \"shrUtils.h\"\n\ntypedef struct __attribute__((__aligned__(4)))\n{\n  unsigned char x;\n  unsigned char y;\n  unsigned char z;\n  unsigned char w;\n} uchar4;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x;\n  float y;\n  float z;\n  float w;\n} float4;\n\nextern\nvoid BoxFilterHost( unsigned int* uiInputImage, unsigned int* uiTempImage, unsigned int* uiOutputImage, \n                    unsigned int uiWidth, unsigned int uiHeight, int iRadius, float fScale );\n\n\nconst unsigned int RADIUS = 10;                    \n\nconst float SCALE = 1.0f/(2.0f * RADIUS + 1.0f);  \n\n\ninline uint DivUp(uint a, uint b){\n    return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n#pragma omp declare target\n\n\n\n\nfloat4 rgbaUintToFloat4(unsigned int c)\n{\n    float4 rgba;\n    rgba.x = c & 0xff;\n    rgba.y = (c >> 8) & 0xff;\n    rgba.z = (c >> 16) & 0xff;\n    rgba.w = (c >> 24) & 0xff;\n    return rgba;\n}\n\nuchar4 rgbaUintToUchar4(unsigned int c)\n{\n    uchar4 rgba;\n    rgba.x = c & 0xff;\n    rgba.y = (c >> 8) & 0xff;\n    rgba.z = (c >> 16) & 0xff;\n    rgba.w = (c >> 24) & 0xff;\n    return rgba;\n}\n\n\n\nunsigned int rgbaFloat4ToUint(float4 rgba, float fScale)\n{\n    unsigned int uiPackedPix = 0U;\n    uiPackedPix |= 0x000000FF & (unsigned int)(rgba.x * fScale);\n    uiPackedPix |= 0x0000FF00 & (((unsigned int)(rgba.y * fScale)) << 8);\n    uiPackedPix |= 0x00FF0000 & (((unsigned int)(rgba.z * fScale)) << 16);\n    uiPackedPix |= 0xFF000000 & (((unsigned int)(rgba.w * fScale)) << 24);\n    return uiPackedPix;\n}\n\ninline float4 operator*(float4 a, float4 b)\n{\n    return {a.x * b.x, a.y * b.y, a.z * b.z,  a.w * b.w};\n}\n\ninline void operator+=(float4 &a, float4 b)\n{\n    a.x += b.x;\n    a.y += b.y;\n    a.z += b.z;\n    a.w += b.w;\n}\n\ninline void operator-=(float4 &a, float4 b)\n{\n    a.x -= b.x;\n    a.y -= b.y;\n    a.z -= b.z;\n    a.w -= b.w;\n}\n#pragma omp end declare target\n\nvoid BoxFilterGPU ( unsigned int *uiInput,\n                    unsigned int *uiTmp,\n                    unsigned int *uiDevOutput,\n                    const unsigned int uiWidth, \n                    const unsigned int uiHeight, \n                    const int iRadius,\n                    const float fScale,\n                    const float iCycles )\n{\n  const int szMaxWorkgroupSize = 256;\n  const int iRadiusAligned = ((iRadius + 15)/16) * 16;  \n\n  unsigned int uiNumOutputPix = 64;  \n\n\n  if (szMaxWorkgroupSize < (iRadiusAligned + uiNumOutputPix + iRadius))\n    uiNumOutputPix = szMaxWorkgroupSize - iRadiusAligned - iRadius;\n\n  \n\n  const int uiBlockWidth = DivUp((size_t)uiWidth, (size_t)uiNumOutputPix);\n  const int numTeams = uiHeight * uiBlockWidth;\n  const int blockSize = iRadiusAligned + uiNumOutputPix + iRadius;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iCycles; i++) {\n    \n\n    #pragma omp target teams num_teams(numTeams) thread_limit(blockSize)\n    {\n      uchar4 uc4LocalData[90]; \n\n      #pragma omp parallel \n      {\n        int lid = omp_get_thread_num(); \n        int gidx = omp_get_team_num() % uiBlockWidth;\n        int gidy = omp_get_team_num() / uiBlockWidth;\n\n        int globalPosX = gidx * uiNumOutputPix + lid - iRadiusAligned;\n        int globalPosY = gidy;\n        int iGlobalOffset = globalPosY * uiWidth + globalPosX;\n\n        \n\n        if (globalPosX >= 0 && globalPosX < uiWidth)\n            \n\n            uc4LocalData[lid] = rgbaUintToUchar4(uiInput[iGlobalOffset]);\n        else\n            uc4LocalData[lid] = {0, 0, 0, 0}; \n\n        #pragma omp barrier\n\n        if((globalPosX >= 0) && (globalPosX < uiWidth) && (lid >= iRadiusAligned) && \n           (lid < (iRadiusAligned + (int)uiNumOutputPix)))\n        {\n            \n\n            float4 f4Sum = {0.0f, 0.0f, 0.0f, 0.0f};\n\n            \n\n            int iOffsetX = lid - iRadius;\n            int iLimit = iOffsetX + (2 * iRadius) + 1;\n            for(; iOffsetX < iLimit; iOffsetX++)\n            {\n                f4Sum.x += uc4LocalData[iOffsetX].x;\n                f4Sum.y += uc4LocalData[iOffsetX].y;\n                f4Sum.z += uc4LocalData[iOffsetX].z;\n                f4Sum.w += uc4LocalData[iOffsetX].w; \n            }\n\n            \n\n            \n\n            uiTmp[iGlobalOffset] = rgbaFloat4ToUint(f4Sum, fScale);\n        }\n      }\n    }\n\n    \n\n    #pragma omp target teams distribute parallel for thread_limit(64)\n    for (size_t globalPosX = 0; globalPosX < uiWidth; globalPosX++) {\n      unsigned int* uiInputImage = &uiTmp[globalPosX];\n      unsigned int* uiOutputImage = &uiDevOutput[globalPosX];\n\n      float4 f4Sum;\n      float4 f4iRadius = {(float)iRadius, (float)iRadius, (float)iRadius, (float)iRadius};\n      float4 top_color = rgbaUintToFloat4(uiInputImage[0]);\n      float4 bot_color = rgbaUintToFloat4(uiInputImage[(uiHeight - 1) * uiWidth]);\n\n      f4Sum = top_color * f4iRadius;\n      for (int y = 0; y < iRadius + 1; y++) \n      {\n          f4Sum += rgbaUintToFloat4(uiInputImage[y * uiWidth]);\n      }\n      uiOutputImage[0] = rgbaFloat4ToUint(f4Sum, fScale);\n      for(int y = 1; y < iRadius + 1; y++) \n      {\n          f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n          f4Sum -= top_color;\n          uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n      }\n      \n      for(int y = iRadius + 1; y < uiHeight - iRadius; y++) \n      {\n          f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n          f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n          uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n      }\n\n      for (int y = uiHeight - iRadius; y < uiHeight; y++) \n      {\n          f4Sum += bot_color;\n          f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n          uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n      }\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (us)\\n\", (time * 1e-3f) / iCycles);\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 3) {\n    printf(\"Usage %s <PPM image> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  unsigned int uiImageWidth = 0;     \n\n  unsigned int uiImageHeight = 0;    \n\n  unsigned int* uiInput = NULL;      \n\n  unsigned int* uiTmp = NULL;        \n\n  unsigned int* uiDevOutput = NULL;      \n  unsigned int* uiHostOutput = NULL;      \n\n  shrLoadPPM4ub(argv[1], (unsigned char **)&uiInput, &uiImageWidth, &uiImageHeight);\n  printf(\"Image Width = %u, Height = %u, bpp = %u, Mask Radius = %u\\n\", \n      uiImageWidth, uiImageHeight, unsigned(sizeof(unsigned int) * 8), RADIUS);\n  printf(\"Using Local Memory for Row Processing\\n\\n\");\n\n  size_t szBuff= uiImageWidth * uiImageHeight;\n  size_t szBuffBytes = szBuff * sizeof (unsigned int);\n\n  \n\n  uiTmp = (unsigned int*)malloc(szBuffBytes);\n  uiDevOutput = (unsigned int*)malloc(szBuffBytes);\n  uiHostOutput = (unsigned int*)malloc(szBuffBytes);\n\n  #pragma omp target data map(to: uiInput[0:szBuff]) \\\n                          map(alloc: uiTmp[0:szBuff]) \\\n                          map(from: uiDevOutput[0:szBuff])\n  {\n    const int iCycles = atoi(argv[2]);\n\n    printf(\"Warmup..\\n\");\n    BoxFilterGPU (uiInput, uiTmp, uiDevOutput, \n                  uiImageWidth, uiImageHeight, RADIUS, SCALE, iCycles);\n\n\n    printf(\"\\nRunning BoxFilterGPU for %d cycles...\\n\\n\", iCycles);\n    BoxFilterGPU (uiInput, uiTmp, uiDevOutput,\n                  uiImageWidth, uiImageHeight, RADIUS, SCALE, iCycles);\n  }\n\n  \n\n  BoxFilterHost(uiInput, uiTmp, uiHostOutput, uiImageWidth, uiImageHeight, RADIUS, SCALE);\n\n  \n\n  \n\n  int error = 0;\n  for (unsigned i = RADIUS * uiImageWidth; i < (uiImageHeight-RADIUS)*uiImageWidth; i++)\n  {\n    if (uiDevOutput[i] != uiHostOutput[i]) {\n      printf(\"%d %08x %08x\\n\", i, uiDevOutput[i], uiHostOutput[i]);\n      error = 1;\n      break;\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(uiInput);\n  free(uiTmp);\n  free(uiDevOutput);\n  free(uiHostOutput);\n  return 0;\n}\n"}}
{"kernel_name": "boxfilter", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <chrono>\n#include <memory>\n#include <iostream>\n#include \"shrUtils.h\"\n\ntypedef struct __attribute__((__aligned__(4)))\n{\n  unsigned char x;\n  unsigned char y;\n  unsigned char z;\n  unsigned char w;\n} uchar4;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x;\n  float y;\n  float z;\n  float w;\n} float4;\n\nextern\nvoid BoxFilterHost( unsigned int* uiInputImage, unsigned int* uiTempImage, unsigned int* uiOutputImage, \n                    unsigned int uiWidth, unsigned int uiHeight, int iRadius, float fScale );\n\n\nconst unsigned int RADIUS = 10;                    \n\nconst float SCALE = 1.0f/(2.0f * RADIUS + 1.0f);  \n\n\ninline uint DivUp(uint a, uint b){\n    return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n\n\n\n\nfloat4 rgbaUintToFloat4(unsigned int c)\n{\n    float4 rgba;\n    rgba.x = c & 0xff;\n    rgba.y = (c >> 8) & 0xff;\n    rgba.z = (c >> 16) & 0xff;\n    rgba.w = (c >> 24) & 0xff;\n    return rgba;\n}\n\nuchar4 rgbaUintToUchar4(unsigned int c)\n{\n    uchar4 rgba;\n    rgba.x = c & 0xff;\n    rgba.y = (c >> 8) & 0xff;\n    rgba.z = (c >> 16) & 0xff;\n    rgba.w = (c >> 24) & 0xff;\n    return rgba;\n}\n\n\n\nunsigned int rgbaFloat4ToUint(float4 rgba, float fScale)\n{\n    unsigned int uiPackedPix = 0U;\n    uiPackedPix |= 0x000000FF & (unsigned int)(rgba.x * fScale);\n    uiPackedPix |= 0x0000FF00 & (((unsigned int)(rgba.y * fScale)) << 8);\n    uiPackedPix |= 0x00FF0000 & (((unsigned int)(rgba.z * fScale)) << 16);\n    uiPackedPix |= 0xFF000000 & (((unsigned int)(rgba.w * fScale)) << 24);\n    return uiPackedPix;\n}\n\ninline float4 operator*(float4 a, float4 b)\n{\n    return {a.x * b.x, a.y * b.y, a.z * b.z,  a.w * b.w};\n}\n\ninline void operator+=(float4 &a, float4 b)\n{\n    a.x += b.x;\n    a.y += b.y;\n    a.z += b.z;\n    a.w += b.w;\n}\n\ninline void operator-=(float4 &a, float4 b)\n{\n    a.x -= b.x;\n    a.y -= b.y;\n    a.z -= b.z;\n    a.w -= b.w;\n}\n\nvoid BoxFilterGPU ( unsigned int *uiInput,\n                    unsigned int *uiTmp,\n                    unsigned int *uiDevOutput,\n                    const unsigned int uiWidth, \n                    const unsigned int uiHeight, \n                    const int iRadius,\n                    const float fScale,\n                    const float iCycles )\n{\n  const int szMaxWorkgroupSize = 256;\n  const int iRadiusAligned = ((iRadius + 15)/16) * 16;  \n\n  unsigned int uiNumOutputPix = 64;  \n\n\n  if (szMaxWorkgroupSize < (iRadiusAligned + uiNumOutputPix + iRadius))\n    uiNumOutputPix = szMaxWorkgroupSize - iRadiusAligned - iRadius;\n\n  \n\n  const int uiBlockWidth = DivUp((size_t)uiWidth, (size_t)uiNumOutputPix);\n  const int numTeams = uiHeight * uiBlockWidth;\n  const int blockSize = iRadiusAligned + uiNumOutputPix + iRadius;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iCycles; i++) {\n    \n\n        {\n      uchar4 uc4LocalData[90]; \n\n            {\n        int lid = omp_get_thread_num(); \n        int gidx = omp_get_team_num() % uiBlockWidth;\n        int gidy = omp_get_team_num() / uiBlockWidth;\n\n        int globalPosX = gidx * uiNumOutputPix + lid - iRadiusAligned;\n        int globalPosY = gidy;\n        int iGlobalOffset = globalPosY * uiWidth + globalPosX;\n\n        \n\n        if (globalPosX >= 0 && globalPosX < uiWidth)\n            \n\n            uc4LocalData[lid] = rgbaUintToUchar4(uiInput[iGlobalOffset]);\n        else\n            uc4LocalData[lid] = {0, 0, 0, 0}; \n\n        \n        if((globalPosX >= 0) && (globalPosX < uiWidth) && (lid >= iRadiusAligned) && \n           (lid < (iRadiusAligned + (int)uiNumOutputPix)))\n        {\n            \n\n            float4 f4Sum = {0.0f, 0.0f, 0.0f, 0.0f};\n\n            \n\n            int iOffsetX = lid - iRadius;\n            int iLimit = iOffsetX + (2 * iRadius) + 1;\n            for(; iOffsetX < iLimit; iOffsetX++)\n            {\n                f4Sum.x += uc4LocalData[iOffsetX].x;\n                f4Sum.y += uc4LocalData[iOffsetX].y;\n                f4Sum.z += uc4LocalData[iOffsetX].z;\n                f4Sum.w += uc4LocalData[iOffsetX].w; \n            }\n\n            \n\n            \n\n            uiTmp[iGlobalOffset] = rgbaFloat4ToUint(f4Sum, fScale);\n        }\n      }\n    }\n\n    \n\n        for (size_t globalPosX = 0; globalPosX < uiWidth; globalPosX++) {\n      unsigned int* uiInputImage = &uiTmp[globalPosX];\n      unsigned int* uiOutputImage = &uiDevOutput[globalPosX];\n\n      float4 f4Sum;\n      float4 f4iRadius = {(float)iRadius, (float)iRadius, (float)iRadius, (float)iRadius};\n      float4 top_color = rgbaUintToFloat4(uiInputImage[0]);\n      float4 bot_color = rgbaUintToFloat4(uiInputImage[(uiHeight - 1) * uiWidth]);\n\n      f4Sum = top_color * f4iRadius;\n      for (int y = 0; y < iRadius + 1; y++) \n      {\n          f4Sum += rgbaUintToFloat4(uiInputImage[y * uiWidth]);\n      }\n      uiOutputImage[0] = rgbaFloat4ToUint(f4Sum, fScale);\n      for(int y = 1; y < iRadius + 1; y++) \n      {\n          f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n          f4Sum -= top_color;\n          uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n      }\n      \n      for(int y = iRadius + 1; y < uiHeight - iRadius; y++) \n      {\n          f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n          f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n          uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n      }\n\n      for (int y = uiHeight - iRadius; y < uiHeight; y++) \n      {\n          f4Sum += bot_color;\n          f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n          uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n      }\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (us)\\n\", (time * 1e-3f) / iCycles);\n}\n\nint main(int argc, char** argv)\n{\n  if (argc != 3) {\n    printf(\"Usage %s <PPM image> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  unsigned int uiImageWidth = 0;     \n\n  unsigned int uiImageHeight = 0;    \n\n  unsigned int* uiInput = NULL;      \n\n  unsigned int* uiTmp = NULL;        \n\n  unsigned int* uiDevOutput = NULL;      \n  unsigned int* uiHostOutput = NULL;      \n\n  shrLoadPPM4ub(argv[1], (unsigned char **)&uiInput, &uiImageWidth, &uiImageHeight);\n  printf(\"Image Width = %u, Height = %u, bpp = %u, Mask Radius = %u\\n\", \n      uiImageWidth, uiImageHeight, unsigned(sizeof(unsigned int) * 8), RADIUS);\n  printf(\"Using Local Memory for Row Processing\\n\\n\");\n\n  size_t szBuff= uiImageWidth * uiImageHeight;\n  size_t szBuffBytes = szBuff * sizeof (unsigned int);\n\n  \n\n  uiTmp = (unsigned int*)malloc(szBuffBytes);\n  uiDevOutput = (unsigned int*)malloc(szBuffBytes);\n  uiHostOutput = (unsigned int*)malloc(szBuffBytes);\n\n    {\n    const int iCycles = atoi(argv[2]);\n\n    printf(\"Warmup..\\n\");\n    BoxFilterGPU (uiInput, uiTmp, uiDevOutput, \n                  uiImageWidth, uiImageHeight, RADIUS, SCALE, iCycles);\n\n\n    printf(\"\\nRunning BoxFilterGPU for %d cycles...\\n\\n\", iCycles);\n    BoxFilterGPU (uiInput, uiTmp, uiDevOutput,\n                  uiImageWidth, uiImageHeight, RADIUS, SCALE, iCycles);\n  }\n\n  \n\n  BoxFilterHost(uiInput, uiTmp, uiHostOutput, uiImageWidth, uiImageHeight, RADIUS, SCALE);\n\n  \n\n  \n\n  int error = 0;\n  for (unsigned i = RADIUS * uiImageWidth; i < (uiImageHeight-RADIUS)*uiImageWidth; i++)\n  {\n    if (uiDevOutput[i] != uiHostOutput[i]) {\n      printf(\"%d %08x %08x\\n\", i, uiDevOutput[i], uiHostOutput[i]);\n      error = 1;\n      break;\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(uiInput);\n  free(uiTmp);\n  free(uiDevOutput);\n  free(uiHostOutput);\n  return 0;\n}"}}
{"kernel_name": "car", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n#include \"utils.h\"\n#include \"reference.h\"\n\n__global__ void car (\n    const float *__restrict__ img,\n    const float *__restrict__ kernels,\n    const float *__restrict__ offsets_h,\n    const float *__restrict__ offsets_v,\n          float *__restrict__ output,\n    const params p,\n    const int offset_unit,\n    const int padding,\n    const size_t n)\n{\n  size_t global_idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if(global_idx >= n) return;\n\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const size_t vol_size = (size_t)dim_c * dim_h * dim_w;\n  const size_t img_size = (size_t)dim_h * dim_w;\n\n  const int idb = (global_idx / vol_size) % dim_b;\n  const int idc = (global_idx / img_size) % dim_c;\n  const int idy = (global_idx / dim_w) % dim_h;\n  const int idx = global_idx % dim_w;\n\n  const int k_size = (int)sqrtf(float(kernels_size));\n  const int w = img_w - 2 * padding;\n  const int h = img_h - 2 * padding;\n\n  float result = 0;\n  for(int k_y = 0; k_y < k_size; ++k_y)\n  {\n    for(int k_x = 0; k_x < k_size; ++k_x)\n    {\n      const float offset_h = offsets_h(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n      const float offset_v = offsets_v(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n\n      const float p_x = static_cast<float>(idx + 0.5f) / dim_w * w + k_x + offset_h - 0.5f;\n      const float p_y = static_cast<float>(idy + 0.5f) / dim_h * h + k_y + offset_v - 0.5f;\n      const float alpha = p_x - floorf(p_x);\n      const float beta = p_y - floorf(p_y);\n\n      const int xL = max(min(int(floorf(p_x)), w + 2 * padding - 1), 0);\n      const int xR = max(min(xL + 1, w + 2 * padding - 1), 0);\n      const int yT = max(min(int(floorf(p_y)), h + 2 * padding - 1), 0);\n      const int yB = max(min(yT + 1, h + 2 * padding - 1), 0);\n\n      float val = (1.f - alpha) * (1.f - beta) * img(idb,idc,yT,xL);\n      val += alpha * (1.f - beta) * img(idb,idc,yT,xR);\n      val += (1.f - alpha) * beta * img(idb,idc,yB,xL);\n      val += alpha * beta * img(idb,idc,yB,xR);\n      result += val * kernels(idb,k_size * k_y + k_x,idy,idx);\n    }\n  }\n  output(idb,idc,idy,idx) = result;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  params p = {128, 3, 480, 640, 9, 1024, 1024};\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const int padding = 1;\n\n  size_t image_size = (size_t)dim_b * dim_c * (img_w + padding) * (img_h + padding);\n  size_t offset_size = (size_t)dim_b * kernels_size * dim_w * dim_h;\n  size_t kernel_size = (size_t)dim_b * kernels_size * dim_w * dim_h;\n  size_t output_size = (size_t)dim_b * dim_c * dim_w * dim_h;\n\n  size_t image_size_byte = sizeof(float) * image_size;\n  size_t offset_size_byte = sizeof(float) * offset_size;\n  size_t kernel_size_byte = sizeof(float) * kernel_size;\n  size_t output_size_byte = sizeof(float) * output_size;\n\n  float *img = (float*) malloc (image_size_byte);\n  float *offsets_h = (float*) malloc (offset_size_byte);\n  float *offsets_v = (float*) malloc (offset_size_byte);\n  float *kernel = (float*) malloc (kernel_size_byte);\n  float *output = (float*) malloc (output_size_byte);\n  float *output_ref = (float*) malloc (output_size_byte);\n\n  unsigned long long seed = 123;\n  for (size_t i = 0; i < image_size; i++) img[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < kernel_size; i++) kernel[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < offset_size; i++) {\n    offsets_h[i] = LCG_random_double(&seed);\n    offsets_v[i] = LCG_random_double(&seed);\n  }\n\n  float *d_img, *d_offsets_h, *d_offsets_v, *d_kernel, *d_output;\n  cudaMalloc((void**)&d_img, image_size_byte);\n  cudaMemcpy(d_img, img, image_size_byte, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_offsets_h, offset_size_byte);\n  cudaMemcpy(d_offsets_h, offsets_h, offset_size_byte, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_offsets_v, offset_size_byte);\n  cudaMemcpy(d_offsets_v, offsets_v, offset_size_byte, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_kernel, kernel_size_byte);\n  cudaMemcpy(d_kernel, kernel, kernel_size_byte, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_output, output_size_byte);\n\n  dim3 grid ((output_size + 255) / 256);\n  dim3 block (256);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    car <<<grid, block>>> (\n        d_img,\n        d_kernel,\n        d_offsets_h,\n        d_offsets_v,\n        d_output,\n        p,\n        1, \n\n        padding,\n        output_size);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n\n  reference (img, kernel, offsets_h, offsets_v, output_ref, p, 1, padding);\n\n  cudaMemcpy(output, d_output, output_size_byte, cudaMemcpyDeviceToHost);\n\n  float rmse = 0;\n  for (size_t i = 0; i < output_size; i++)\n    rmse += (output_ref[i] - output[i]) * (output_ref[i] - output[i]);\n  printf(\"RMSE: %f\\n\", sqrtf(rmse/output_size));\n\n  cudaFree(d_img);\n  cudaFree(d_offsets_h);\n  cudaFree(d_offsets_v);\n  cudaFree(d_kernel);\n  cudaFree(d_output);\n\n  free(img);\n  free(offsets_h);\n  free(offsets_v);\n  free(kernel);\n  free(output);\n  free(output_ref);\n  return 0;\n}\n"}}
{"kernel_name": "car", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"utils.h\"\n#include \"reference.h\"\n\n__global__ void car (\n    const float *__restrict__ img,\n    const float *__restrict__ kernels,\n    const float *__restrict__ offsets_h,\n    const float *__restrict__ offsets_v,\n          float *__restrict__ output,\n    const params p,\n    const int offset_unit,\n    const int padding,\n    const size_t n)\n{\n  size_t global_idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if(global_idx >= n) return;\n\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const size_t vol_size = (size_t)dim_c * dim_h * dim_w;\n  const size_t img_size = (size_t)dim_h * dim_w;\n\n  const int idb = (global_idx / vol_size) % dim_b;\n  const int idc = (global_idx / img_size) % dim_c;\n  const int idy = (global_idx / dim_w) % dim_h;\n  const int idx = global_idx % dim_w;\n\n  const int k_size = (int)sqrtf(float(kernels_size));\n  const int w = img_w - 2 * padding;\n  const int h = img_h - 2 * padding;\n\n  float result = 0;\n  for(int k_y = 0; k_y < k_size; ++k_y)\n  {\n    for(int k_x = 0; k_x < k_size; ++k_x)\n    {\n      const float offset_h = offsets_h(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n      const float offset_v = offsets_v(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n\n      const float p_x = static_cast<float>(idx + 0.5f) / dim_w * w + k_x + offset_h - 0.5f;\n      const float p_y = static_cast<float>(idy + 0.5f) / dim_h * h + k_y + offset_v - 0.5f;\n      const float alpha = p_x - floorf(p_x);\n      const float beta = p_y - floorf(p_y);\n\n      const int xL = max(min(int(floorf(p_x)), w + 2 * padding - 1), 0);\n      const int xR = max(min(xL + 1, w + 2 * padding - 1), 0);\n      const int yT = max(min(int(floorf(p_y)), h + 2 * padding - 1), 0);\n      const int yB = max(min(yT + 1, h + 2 * padding - 1), 0);\n\n      float val = (1.f - alpha) * (1.f - beta) * img(idb,idc,yT,xL);\n      val += alpha * (1.f - beta) * img(idb,idc,yT,xR);\n      val += (1.f - alpha) * beta * img(idb,idc,yB,xL);\n      val += alpha * beta * img(idb,idc,yB,xR);\n      result += val * kernels(idb,k_size * k_y + k_x,idy,idx);\n    }\n  }\n  output(idb,idc,idy,idx) = result;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  params p = {128, 3, 480, 640, 9, 1024, 1024};\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const int padding = 1;\n\n  size_t image_size = (size_t)dim_b * dim_c * (img_w + padding) * (img_h + padding);\n  size_t offset_size = (size_t)dim_b * kernels_size * dim_w * dim_h;\n  size_t kernel_size = (size_t)dim_b * kernels_size * dim_w * dim_h;\n  size_t output_size = (size_t)dim_b * dim_c * dim_w * dim_h;\n\n  size_t image_size_byte = sizeof(float) * image_size;\n  size_t offset_size_byte = sizeof(float) * offset_size;\n  size_t kernel_size_byte = sizeof(float) * kernel_size;\n  size_t output_size_byte = sizeof(float) * output_size;\n\n  float *img = (float*) malloc (image_size_byte);\n  float *offsets_h = (float*) malloc (offset_size_byte);\n  float *offsets_v = (float*) malloc (offset_size_byte);\n  float *kernel = (float*) malloc (kernel_size_byte);\n  float *output = (float*) malloc (output_size_byte);\n  float *output_ref = (float*) malloc (output_size_byte);\n\n  unsigned long long seed = 123;\n  for (size_t i = 0; i < image_size; i++) img[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < kernel_size; i++) kernel[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < offset_size; i++) {\n    offsets_h[i] = LCG_random_double(&seed);\n    offsets_v[i] = LCG_random_double(&seed);\n  }\n\n  float *d_img, *d_offsets_h, *d_offsets_v, *d_kernel, *d_output;\n  hipMalloc((void**)&d_img, image_size_byte);\n  hipMemcpy(d_img, img, image_size_byte, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_offsets_h, offset_size_byte);\n  hipMemcpy(d_offsets_h, offsets_h, offset_size_byte, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_offsets_v, offset_size_byte);\n  hipMemcpy(d_offsets_v, offsets_v, offset_size_byte, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_kernel, kernel_size_byte);\n  hipMemcpy(d_kernel, kernel, kernel_size_byte, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_output, output_size_byte);\n\n  dim3 grid ((output_size + 255) / 256);\n  dim3 block (256);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    car <<<grid, block>>> (\n        d_img,\n        d_kernel,\n        d_offsets_h,\n        d_offsets_v,\n        d_output,\n        p,\n        1, \n\n        padding,\n        output_size);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n\n  reference (img, kernel, offsets_h, offsets_v, output_ref, p, 1, padding);\n\n  hipMemcpy(output, d_output, output_size_byte, hipMemcpyDeviceToHost);\n\n  float rmse = 0;\n  for (size_t i = 0; i < output_size; i++)\n    rmse += (output_ref[i] - output[i]) * (output_ref[i] - output[i]);\n  printf(\"RMSE: %f\\n\", sqrtf(rmse/output_size));\n\n  hipFree(d_img);\n  hipFree(d_offsets_h);\n  hipFree(d_offsets_v);\n  hipFree(d_kernel);\n  hipFree(d_output);\n\n  free(img);\n  free(offsets_h);\n  free(offsets_v);\n  free(kernel);\n  free(output);\n  free(output_ref);\n  return 0;\n}\n"}}
{"kernel_name": "car", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"utils.h\"\n#include \"reference.h\"\n\n#define max(a,b) (a) > (b) ? (a) : (b)\n#define min(a,b) (a) < (b) ? (a) : (b)\n\nvoid car (\n    const float *__restrict img,\n    const float *__restrict kernels,\n    const float *__restrict offsets_h,\n    const float *__restrict offsets_v,\n          float *__restrict output,\n    const params p,\n    const int offset_unit,\n    const int padding,\n    const size_t n)\n{\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const int k_size = (int)sqrtf(float(kernels_size));\n  const int w = img_w - 2 * padding;\n  const int h = img_h - 2 * padding;\n\n  #pragma omp target teams distribute parallel for collapse(4) thread_limit(256)\n  for (int idb = 0; idb < dim_b; idb++)\n  for (int idc = 0; idc < dim_c; idc++)\n  for (int idy = 0; idy < dim_h; idy++)\n  for (int idx = 0; idx < dim_w; idx++) {\n\n    float result = 0;\n    for(int k_y = 0; k_y < k_size; ++k_y)\n    {\n      for(int k_x = 0; k_x < k_size; ++k_x)\n      {\n        const float offset_h = offsets_h(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n        const float offset_v = offsets_v(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n\n        const float p_x = static_cast<float>(idx + 0.5f) / dim_w * w + k_x + offset_h - 0.5f;\n        const float p_y = static_cast<float>(idy + 0.5f) / dim_h * h + k_y + offset_v - 0.5f;\n        const float alpha = p_x - floorf(p_x);\n        const float beta = p_y - floorf(p_y);\n\n        const int xL = max(min(int(floorf(p_x)), w + 2 * padding - 1), 0);\n        const int xR = max(min(xL + 1, w + 2 * padding - 1), 0);\n        const int yT = max(min(int(floorf(p_y)), h + 2 * padding - 1), 0);\n        const int yB = max(min(yT + 1, h + 2 * padding - 1), 0);\n\n        float val = (1.f - alpha) * (1.f - beta) * img(idb,idc,yT,xL);\n        val += alpha * (1.f - beta) * img(idb,idc,yT,xR);\n        val += (1.f - alpha) * beta * img(idb,idc,yB,xL);\n        val += alpha * beta * img(idb,idc,yB,xR);\n        result += val * kernels(idb,k_size * k_y + k_x,idy,idx);\n      }\n    }\n    output(idb,idc,idy,idx) = result;\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  params p = {128, 3, 480, 640, 9, 1024, 1024};\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const int padding = 1;\n\n  size_t image_size = dim_b * dim_c * (img_w + padding) * (img_h + padding);\n  size_t offset_size = dim_b * kernels_size * dim_w * dim_h;\n  size_t kernel_size = dim_b * kernels_size * dim_w * dim_h;\n  size_t output_size = dim_b * dim_c * dim_w * dim_h;\n\n  size_t image_size_byte = sizeof(float) * image_size;\n  size_t offset_size_byte = sizeof(float) * offset_size;\n  size_t kernel_size_byte = sizeof(float) * kernel_size;\n  size_t output_size_byte = sizeof(float) * output_size;\n\n  float *img = (float*) malloc (image_size_byte);\n  float *offsets_h = (float*) malloc (offset_size_byte);\n  float *offsets_v = (float*) malloc (offset_size_byte);\n  float *kernel = (float*) malloc (kernel_size_byte);\n  float *output = (float*) malloc (output_size_byte);\n  float *output_ref = (float*) malloc (output_size_byte);\n\n  unsigned long long seed = 123;\n  for (size_t i = 0; i < image_size; i++) img[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < kernel_size; i++) kernel[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < offset_size; i++) {\n    offsets_h[i] = LCG_random_double(&seed);\n    offsets_v[i] = LCG_random_double(&seed);\n  }\n\n  #pragma omp target data map (to: img[0:image_size],\\\n                                   offsets_h[0:offset_size],\\\n                                   offsets_v[0:offset_size],\\\n                                   kernel[0:kernel_size]) \\\n                          map (from: output[0:output_size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      car(img,\n          kernel,\n          offsets_h,\n          offsets_v,\n          output,\n          p,\n          1, \n\n          padding,\n          output_size);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n  }\n\n  reference (img, kernel, offsets_h, offsets_v, output_ref, p, 1, padding);\n\n  float rmse = 0;\n  for (size_t i = 0; i < output_size; i++)\n    rmse += (output_ref[i] - output[i]) * (output_ref[i] - output[i]);\n  printf(\"RMSE: %f\\n\", sqrtf(rmse/output_size));\n\n  free(img);\n  free(offsets_h);\n  free(offsets_v);\n  free(kernel);\n  free(output);\n  free(output_ref);\n  return 0;\n}\n\n"}}
{"kernel_name": "car", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"utils.h\"\n#include \"reference.h\"\n\n#define max(a,b) (a) > (b) ? (a) : (b)\n#define min(a,b) (a) < (b) ? (a) : (b)\n\nvoid car (\n    const float *__restrict img,\n    const float *__restrict kernels,\n    const float *__restrict offsets_h,\n    const float *__restrict offsets_v,\n          float *__restrict output,\n    const params p,\n    const int offset_unit,\n    const int padding,\n    const size_t n)\n{\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const int k_size = (int)sqrtf(float(kernels_size));\n  const int w = img_w - 2 * padding;\n  const int h = img_h - 2 * padding;\n\n    for (int idb = 0; idb < dim_b; idb++)\n  for (int idc = 0; idc < dim_c; idc++)\n  for (int idy = 0; idy < dim_h; idy++)\n  for (int idx = 0; idx < dim_w; idx++) {\n\n    float result = 0;\n    for(int k_y = 0; k_y < k_size; ++k_y)\n    {\n      for(int k_x = 0; k_x < k_size; ++k_x)\n      {\n        const float offset_h = offsets_h(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n        const float offset_v = offsets_v(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n\n        const float p_x = static_cast<float>(idx + 0.5f) / dim_w * w + k_x + offset_h - 0.5f;\n        const float p_y = static_cast<float>(idy + 0.5f) / dim_h * h + k_y + offset_v - 0.5f;\n        const float alpha = p_x - floorf(p_x);\n        const float beta = p_y - floorf(p_y);\n\n        const int xL = max(min(int(floorf(p_x)), w + 2 * padding - 1), 0);\n        const int xR = max(min(xL + 1, w + 2 * padding - 1), 0);\n        const int yT = max(min(int(floorf(p_y)), h + 2 * padding - 1), 0);\n        const int yB = max(min(yT + 1, h + 2 * padding - 1), 0);\n\n        float val = (1.f - alpha) * (1.f - beta) * img(idb,idc,yT,xL);\n        val += alpha * (1.f - beta) * img(idb,idc,yT,xR);\n        val += (1.f - alpha) * beta * img(idb,idc,yB,xL);\n        val += alpha * beta * img(idb,idc,yB,xR);\n        result += val * kernels(idb,k_size * k_y + k_x,idy,idx);\n      }\n    }\n    output(idb,idc,idy,idx) = result;\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  params p = {128, 3, 480, 640, 9, 1024, 1024};\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const int padding = 1;\n\n  size_t image_size = dim_b * dim_c * (img_w + padding) * (img_h + padding);\n  size_t offset_size = dim_b * kernels_size * dim_w * dim_h;\n  size_t kernel_size = dim_b * kernels_size * dim_w * dim_h;\n  size_t output_size = dim_b * dim_c * dim_w * dim_h;\n\n  size_t image_size_byte = sizeof(float) * image_size;\n  size_t offset_size_byte = sizeof(float) * offset_size;\n  size_t kernel_size_byte = sizeof(float) * kernel_size;\n  size_t output_size_byte = sizeof(float) * output_size;\n\n  float *img = (float*) malloc (image_size_byte);\n  float *offsets_h = (float*) malloc (offset_size_byte);\n  float *offsets_v = (float*) malloc (offset_size_byte);\n  float *kernel = (float*) malloc (kernel_size_byte);\n  float *output = (float*) malloc (output_size_byte);\n  float *output_ref = (float*) malloc (output_size_byte);\n\n  unsigned long long seed = 123;\n  for (size_t i = 0; i < image_size; i++) img[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < kernel_size; i++) kernel[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < offset_size; i++) {\n    offsets_h[i] = LCG_random_double(&seed);\n    offsets_v[i] = LCG_random_double(&seed);\n  }\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      car(img,\n          kernel,\n          offsets_h,\n          offsets_v,\n          output,\n          p,\n          1, \n\n          padding,\n          output_size);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n  }\n\n  reference (img, kernel, offsets_h, offsets_v, output_ref, p, 1, padding);\n\n  float rmse = 0;\n  for (size_t i = 0; i < output_size; i++)\n    rmse += (output_ref[i] - output[i]) * (output_ref[i] - output[i]);\n  printf(\"RMSE: %f\\n\", sqrtf(rmse/output_size));\n\n  free(img);\n  free(offsets_h);\n  free(offsets_v);\n  free(kernel);\n  free(output);\n  free(output_ref);\n  return 0;\n}\n"}}
{"kernel_name": "car", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n#include \"reference.h\"\n\nvoid car (\n  sycl::nd_item<1> &item,\n  const float *__restrict img,\n  const float *__restrict kernels,\n  const float *__restrict offsets_h,\n  const float *__restrict offsets_v,\n        float *__restrict output,\n  const params p,\n  const int offset_unit,\n  const int padding,\n  const size_t n)\n{\n  size_t global_idx = item.get_global_id(0);\n  if(global_idx >= n) return;\n\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const size_t vol_size = (size_t)dim_c * dim_h * dim_w;\n  const size_t img_size = (size_t)dim_h * dim_w;\n\n  const int idb = (global_idx / vol_size) % dim_b;\n  const int idc = (global_idx / img_size) % dim_c;\n  const int idy = (global_idx / dim_w) % dim_h;\n  const int idx = global_idx % dim_w;\n\n  const int k_size = (int)sycl::sqrt(float(kernels_size));\n  const int w = img_w - 2 * padding;\n  const int h = img_h - 2 * padding;\n\n  float result = 0;\n  for(int k_y = 0; k_y < k_size; ++k_y)\n  {\n    for(int k_x = 0; k_x < k_size; ++k_x)\n    {\n      const float offset_h = offsets_h(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n      const float offset_v = offsets_v(idb,k_size * k_y + k_x,idy,idx) * offset_unit;\n\n      const float p_x = static_cast<float>(idx + 0.5f) / dim_w * w + k_x + offset_h - 0.5f;\n      const float p_y = static_cast<float>(idy + 0.5f) / dim_h * h + k_y + offset_v - 0.5f;\n      const float alpha = p_x - sycl::floor(p_x);\n      const float beta = p_y - sycl::floor(p_y);\n\n      const int xL = sycl::max(sycl::min(int(sycl::floor(p_x)), w + 2 * padding - 1), 0);\n      const int xR = sycl::max(sycl::min(xL + 1, w + 2 * padding - 1), 0);\n      const int yT = sycl::max(sycl::min(int(sycl::floor(p_y)), h + 2 * padding - 1), 0);\n      const int yB = sycl::max(sycl::min(yT + 1, h + 2 * padding - 1), 0);\n\n      float val = (1.f - alpha) * (1.f - beta) * img(idb,idc,yT,xL);\n      val += alpha * (1.f - beta) * img(idb,idc,yT,xR);\n      val += (1.f - alpha) * beta * img(idb,idc,yB,xL);\n      val += alpha * beta * img(idb,idc,yB,xR);\n      result += val * kernels(idb,k_size * k_y + k_x,idy,idx);\n    }\n  }\n  output(idb,idc,idy,idx) = result;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  params p = {128, 3, 480, 640, 9, 1024, 1024};\n  const int dim_b = p.output_dim_b;\n  const int dim_c = p.output_dim_c;\n  const int dim_h = p.output_dim_h;\n  const int dim_w = p.output_dim_w;\n  const int kernels_size = p.kernel_size;\n  const int img_w = p.image_w;\n  const int img_h = p.image_h;\n\n  const int padding = 1;\n\n  size_t image_size = (size_t)dim_b * dim_c * (img_w + padding) * (img_h + padding);\n  size_t offset_size = (size_t)dim_b * kernels_size * dim_w * dim_h;\n  size_t kernel_size = (size_t)dim_b * kernels_size * dim_w * dim_h;\n  size_t output_size = (size_t)dim_b * dim_c * dim_w * dim_h;\n\n  size_t image_size_byte = sizeof(float) * image_size;\n  size_t offset_size_byte = sizeof(float) * offset_size;\n  size_t kernel_size_byte = sizeof(float) * kernel_size;\n  size_t output_size_byte = sizeof(float) * output_size;\n\n  float *img = (float*) malloc (image_size_byte);\n  float *offsets_h = (float*) malloc (offset_size_byte);\n  float *offsets_v = (float*) malloc (offset_size_byte);\n  float *kernel = (float*) malloc (kernel_size_byte);\n  float *output = (float*) malloc (output_size_byte);\n  float *output_ref = (float*) malloc (output_size_byte);\n\n  unsigned long long seed = 123;\n  for (size_t i = 0; i < image_size; i++) img[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < kernel_size; i++) kernel[i] = (unsigned char)(256*LCG_random_double(&seed));\n  for (size_t i = 0; i < offset_size; i++) {\n    offsets_h[i] = LCG_random_double(&seed);\n    offsets_v[i] = LCG_random_double(&seed);\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_img = sycl::malloc_device<float>(image_size, q);\n  q.memcpy(d_img, img, image_size_byte);\n\n  float *d_offsets_h = sycl::malloc_device<float>(offset_size, q);\n  q.memcpy(d_offsets_h, offsets_h, offset_size_byte);\n\n  float *d_offsets_v = sycl::malloc_device<float>(offset_size, q);\n  q.memcpy(d_offsets_v, offsets_v, offset_size_byte);\n\n  float *d_kernel = sycl::malloc_device<float>(kernel_size, q);\n  q.memcpy(d_kernel, kernel, kernel_size_byte);\n\n  float *d_output = sycl::malloc_device<float>(output_size, q);\n\n  sycl::range<1> gws ((output_size + 255) / 256 * 256);\n  sycl::range<1> lws (256);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class downsampling>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        car(item,\n            d_img,\n            d_kernel,\n            d_offsets_h,\n            d_offsets_v,\n            d_output,\n            p,\n            1, \n\n            padding,\n            output_size);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n\n  q.memcpy(output, d_output, output_size_byte).wait();\n  reference (img, kernel, offsets_h, offsets_v, output_ref, p, 1, padding);\n\n  float rmse = 0;\n  for (size_t i = 0; i < output_size; i++)\n    rmse += (output_ref[i] - output[i]) * (output_ref[i] - output[i]);\n  printf(\"RMSE: %f\\n\", sqrtf(rmse/output_size));\n\n  sycl::free(d_img, q);\n  sycl::free(d_offsets_h, q);\n  sycl::free(d_offsets_v, q);\n  sycl::free(d_kernel, q);\n  sycl::free(d_output, q);\n\n  free(img);\n  free(offsets_h);\n  free(offsets_v);\n  free(kernel);\n  free(output);\n  free(output_ref);\n  return 0;\n}\n\n"}}
{"kernel_name": "cbsfil", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <cuda.h>\n#include \"kernels.h\"\n\nint PowTwoDivider(int n)\n{\n  if (n == 0) return 0;\n  int divider = 1;\n  while ((n & divider) == 0) divider <<= 1;\n  return divider;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int image_pitch = width * sizeof(float);\n  const int numPix = width * height;\n  const int image_size = numPix * sizeof(float);\n\n  float *image = (float*) malloc (image_size);\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    uint x = rand() % 256;\n    uint y = rand() % 256;\n    uint z = rand() % 256;\n    uint w = rand() % 256;\n    *(uint*)(&image[i]) = (w << 24) | (z << 16) | (y << 8) | x;\n  }\n\n  float *d_image;\n  cudaMalloc((void**)&d_image, image_size);\n\n  int blocks = std::min(PowTwoDivider(height), 64);\n  dim3 dimBlockX (blocks);\n  dim3 dimGridX ((height + blocks - 1) / blocks);\n\n  blocks = std::min(PowTwoDivider(width), 64);\n  dim3 dimBlockY (blocks);\n  dim3 dimGridY ((width  + blocks - 1) / blocks);\n\n  long total_time = 0;\n  for (int i = 0; i < repeat; i++) {\n    cudaMemcpy(d_image, image, image_size, cudaMemcpyHostToDevice);\n    auto start = std::chrono::steady_clock::now();\n\n    toCoef2DX<<<dimGridX, dimBlockX>>>(d_image, image_pitch, width, height);\n    toCoef2DY<<<dimGridY, dimBlockY>>>(d_image, image_pitch, width, height);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n  }\n  printf(\"Average kernel execution time %f (s)\\n\", total_time * 1e-9f / repeat);\n\n  cudaMemcpy(image, d_image, image_size, cudaMemcpyDeviceToHost);\n  cudaFree(d_image);\n\n  float sum = 0.f;\n  for (int i = 0; i < numPix; i++) {\n    const uchar *t = (const uchar*)(&image[i]);\n    sum += (t[0] + t[1] + t[2] + t[3]) / 4;\n  }\n  printf(\"Checksum: %f\\n\", sum / numPix);\n\n  free(image);\n  return 0;\n}\n"}}
{"kernel_name": "cbsfil", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"kernels.h\"\n\nint PowTwoDivider(int n)\n{\n  if (n == 0) return 0;\n  int divider = 1;\n  while ((n & divider) == 0) divider <<= 1;\n  return divider;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int image_pitch = width * sizeof(float);\n  const int numPix = width * height;\n  const int image_size = numPix * sizeof(float);\n\n  float *image = (float*) malloc (image_size);\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    uint x = rand() % 256;\n    uint y = rand() % 256;\n    uint z = rand() % 256;\n    uint w = rand() % 256;\n    *(uint*)(&image[i]) = (w << 24) | (z << 16) | (y << 8) | x;\n  }\n\n  float *d_image;\n  hipMalloc((void**)&d_image, image_size);\n\n  int blocks = std::min(PowTwoDivider(height), 64);\n  dim3 dimBlockX (blocks);\n  dim3 dimGridX ((height + blocks - 1) / blocks);\n\n  blocks = std::min(PowTwoDivider(width), 64);\n  dim3 dimBlockY (blocks);\n  dim3 dimGridY ((width  + blocks - 1) / blocks);\n\n  long total_time = 0;\n  for (int i = 0; i < repeat; i++) {\n    hipMemcpy(d_image, image, image_size, hipMemcpyHostToDevice);\n    auto start = std::chrono::steady_clock::now();\n\n    hipLaunchKernelGGL(toCoef2DX, dimGridX, dimBlockX, 0, 0, d_image, image_pitch, width, height);\n    hipLaunchKernelGGL(toCoef2DY, dimGridY, dimBlockY, 0, 0, d_image, image_pitch, width, height);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n  }\n  printf(\"Average kernel execution time %f (s)\\n\", total_time * 1e-9f / repeat);\n\n  hipMemcpy(image, d_image, image_size, hipMemcpyDeviceToHost);\n  hipFree(d_image);\n\n  float sum = 0.f;\n  for (int i = 0; i < numPix; i++) {\n    const uchar *t = (const uchar*)(&image[i]);\n    sum += (t[0] + t[1] + t[2] + t[3]) / 4;\n  }\n  printf(\"Checksum: %f\\n\", sum / numPix);\n\n  free(image);\n  return 0;\n}\n"}}
{"kernel_name": "cbsfil", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <omp.h>\n#include \"kernels.h\"\n\nint PowTwoDivider(int n)\n{\n  if (n == 0) return 0;\n  int divider = 1;\n  while ((n & divider) == 0) divider <<= 1;\n  return divider;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int image_pitch = width * sizeof(float);\n  const int numPix = width * height;\n  const int image_size = numPix * sizeof(float);\n\n  float *image = (float*) malloc (image_size);\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    uint x = rand() % 256;\n    uint y = rand() % 256;\n    uint z = rand() % 256;\n    uint w = rand() % 256;\n    *(uint*)(&image[i]) = (w << 24) | (z << 16) | (y << 8) | x;\n  }\n\n  long total_time = 0;\n  #pragma omp target data map(from: image[0:numPix])\n  {\n    int numThreadsX = std::min(PowTwoDivider(height), 64);\n    int numThreadsY = std::min(PowTwoDivider(width), 64);\n\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target update to (image[0:numPix])\n\n      auto start = std::chrono::steady_clock::now();\n\n      toCoef2DX(image, numThreadsX, image_pitch, width, height);\n      toCoef2DY(image, numThreadsY, image_pitch, width, height);\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      total_time += time;\n    }\n    printf(\"Average kernel execution time %f (s)\\n\", total_time * 1e-9f / repeat);\n  }\n\n  float sum = 0.f;\n  for (int i = 0; i < numPix; i++) {\n    const uchar *t = (const uchar*)(&image[i]);\n    sum += (t[0] + t[1] + t[2] + t[3]) / 4;\n  }\n  printf(\"Checksum: %f\\n\", sum / numPix);\n\n  free(image);\n  return 0;\n}\n"}}
{"kernel_name": "cbsfil", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include \"kernels.h\"\n\nint PowTwoDivider(int n)\n{\n  if (n == 0) return 0;\n  int divider = 1;\n  while ((n & divider) == 0) divider <<= 1;\n  return divider;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int image_pitch = width * sizeof(float);\n  const int numPix = width * height;\n  const int image_size = numPix * sizeof(float);\n\n  float *image = (float*) malloc (image_size);\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    uint x = rand() % 256;\n    uint y = rand() % 256;\n    uint z = rand() % 256;\n    uint w = rand() % 256;\n    *(uint*)(&image[i]) = (w << 24) | (z << 16) | (y << 8) | x;\n  }\n\n  long total_time = 0;\n    {\n    int numThreadsX = std::min(PowTwoDivider(height), 64);\n    int numThreadsY = std::min(PowTwoDivider(width), 64);\n\n    for (int i = 0; i < repeat; i++) {\n      \n      auto start = std::chrono::steady_clock::now();\n\n      toCoef2DX(image, numThreadsX, image_pitch, width, height);\n      toCoef2DY(image, numThreadsY, image_pitch, width, height);\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      total_time += time;\n    }\n    printf(\"Average kernel execution time %f (s)\\n\", total_time * 1e-9f / repeat);\n  }\n\n  float sum = 0.f;\n  for (int i = 0; i < numPix; i++) {\n    const uchar *t = (const uchar*)(&image[i]);\n    sum += (t[0] + t[1] + t[2] + t[3]) / 4;\n  }\n  printf(\"Checksum: %f\\n\", sum / numPix);\n\n  free(image);\n  return 0;\n}"}}
{"kernel_name": "cbsfil", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n\nint PowTwoDivider(int n)\n{\n  if (n == 0) return 0;\n  int divider = 1;\n  while ((n & divider) == 0) divider <<= 1;\n  return divider;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int image_pitch = width * sizeof(float);\n  const int numPix = width * height;\n  const int image_size = numPix * sizeof(float);\n\n  float *image = (float*) malloc (image_size);\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    uint x = rand() % 256;\n    uint y = rand() % 256;\n    uint z = rand() % 256;\n    uint w = rand() % 256;\n    *(uint*)(&image[i]) = (w << 24) | (z << 16) | (y << 8) | x;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_image = sycl::malloc_device<float>(numPix, q);\n\n  int blocks = std::min(PowTwoDivider(height), 64);\n  sycl::range<1> lwsX (blocks);\n  sycl::range<1> gwsX ((height + blocks-1) / blocks * blocks);\n\n  blocks = std::min(PowTwoDivider(width), 64);\n  sycl::range<1> lwsY (blocks);\n  sycl::range<1> gwsY ((width + blocks-1) / blocks * blocks);\n\n  long total_time = 0;\n  for (int i = 0; i < repeat; i++) {\n    q.memcpy(d_image, image, image_size).wait();\n\n    auto start = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class convertX>(\n        sycl::nd_range<1>(gwsX, lwsX), [=] (sycl::nd_item<1> item) {\n        toCoef2DX(item, d_image, image_pitch, width, height);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class convertY>(\n        sycl::nd_range<1>(gwsY, lwsY), [=] (sycl::nd_item<1> item) {\n        toCoef2DY(item, d_image, image_pitch, width, height);\n      });\n    });\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n  }\n  printf(\"Average kernel execution time %f (s)\\n\", total_time * 1e-9f / repeat);\n\n  q.memcpy(image, d_image, image_size).wait();\n  sycl::free(d_image, q);\n\n  float sum = 0.f;\n  for (int i = 0; i < numPix; i++) {\n    const sycl::uchar *t = (const sycl::uchar*)(&image[i]);\n    sum += (t[0] + t[1] + t[2] + t[3]) / 4;\n  }\n  printf(\"Checksum: %f\\n\", sum / numPix);\n\n  free(image);\n  return 0;\n}\n"}}
{"kernel_name": "colorwheel", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cuda.h>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\n__host__ __device__\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\n__host__ __device__\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sqrtf(fx * fx + fy * fy);\n  float a = atan2f(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\n__global__\nvoid color (uchar* pix, int size, int half_size, float range, float truerange)\n{\n  int y = blockDim.y * blockIdx.y + threadIdx.y;\n  int x = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (y < size && x < size) {\n    float fx = (float)x / (float)half_size * range - range;\n    float fy = (float)y / (float)half_size * range - range;\n    if (x == half_size || y == half_size) return; \n\n    size_t idx = (y * size + x) * 3;\n    computeColor(fx/truerange, fy/truerange, pix+idx);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n  uchar *d_pix;\n  cudaMalloc((void**)&d_pix, imgSize);\n  cudaMemset(d_pix, 0, imgSize);\n\n  dim3 grids ((size+15)/16, (size+15)/16);\n  dim3 blocks (16, 16);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    color <<< grids, blocks >>> (d_pix, size, half_size, range, truerange);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(res, d_pix, imgSize, cudaMemcpyDeviceToHost);\n\n  \n\n  int fail = memcmp(pix, res, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(res[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  cudaFree(d_pix);\n  free(pix);\n  free(res);\n  return 0;\n}\n"}}
{"kernel_name": "colorwheel", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <hip/hip_runtime.h>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\n__host__ __device__\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\n__host__ __device__\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sqrtf(fx * fx + fy * fy);\n  float a = atan2f(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\n__global__\nvoid color (uchar* pix, int size, int half_size, float range, float truerange)\n{\n  int y = blockDim.y * blockIdx.y + threadIdx.y;\n  int x = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (y < size && x < size) {\n    float fx = (float)x / (float)half_size * range - range;\n    float fy = (float)y / (float)half_size * range - range;\n    if (x == half_size || y == half_size) return; \n\n    size_t idx = (y * size + x) * 3;\n    computeColor(fx/truerange, fy/truerange, pix+idx);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n  uchar *d_pix;\n  hipMalloc((void**)&d_pix, imgSize);\n  hipMemset(d_pix, 0, imgSize);\n\n  dim3 grids ((size+15)/16, (size+15)/16);\n  dim3 blocks (16, 16);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    color<<<grids, blocks>>>(d_pix, size, half_size, range, truerange);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(res, d_pix, imgSize, hipMemcpyDeviceToHost);\n\n  \n\n  int fail = memcmp(pix, res, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(res[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  hipFree(d_pix);\n  free(pix);\n  free(res);\n  return 0;\n}\n"}}
{"kernel_name": "colorwheel", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <omp.h>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sqrtf(fx * fx + fy * fy);\n  float a = atan2f(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n  uchar *d_pix = (uchar*) malloc(imgSize);\n  memset(d_pix, 0, imgSize);\n\n  #pragma omp target data map (tofrom: d_pix[0:imgSize])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target teams distribute parallel for collapse(2)\n      for (int y = 0; y < size; y++) {\n        for (int x = 0; x < size; x++) {\n          float fx = (float)x / (float)half_size * range - range;\n          float fy = (float)y / (float)half_size * range - range;\n          if (x != half_size && y != half_size) {\n            size_t idx = (y * size + x) * 3;\n            computeColor(fx/truerange, fy/truerange, d_pix+idx);\n          }\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  \n\n  int fail = memcmp(pix, d_pix, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(d_pix[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  free(d_pix);\n  free(pix);\n  free(res);\n  return 0;\n}\n"}}
{"kernel_name": "colorwheel", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sqrtf(fx * fx + fy * fy);\n  float a = atan2f(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n  uchar *d_pix = (uchar*) malloc(imgSize);\n  memset(d_pix, 0, imgSize);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n            for (int y = 0; y < size; y++) {\n        for (int x = 0; x < size; x++) {\n          float fx = (float)x / (float)half_size * range - range;\n          float fy = (float)y / (float)half_size * range - range;\n          if (x != half_size && y != half_size) {\n            size_t idx = (y * size + x) * 3;\n            computeColor(fx/truerange, fy/truerange, d_pix+idx);\n          }\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  \n\n  int fail = memcmp(pix, d_pix, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(d_pix[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  free(d_pix);\n  free(pix);\n  free(res);\n  return 0;\n}"}}
{"kernel_name": "colorwheel", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <sycl/sycl.hpp>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sycl::sqrt(fx * fx + fy * fy);\n  float a = sycl::atan2(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\nvoid color (sycl::nd_item<2> &item, uchar* pix, int size, int half_size, float range, float truerange)\n{\n  int y = item.get_global_id(0);\n  int x = item.get_global_id(1);\n\n  if (y < size && x < size) {\n    float fx = (float)x / (float)half_size * range - range;\n    float fy = (float)y / (float)half_size * range - range;\n    if (x == half_size || y == half_size) return; \n\n    size_t idx = (y * size + x) * 3;\n    computeColor(fx/truerange, fy/truerange, pix+idx);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  uchar *d_pix = sycl::malloc_device<uchar>(imgSize, q);\n  q.memset(d_pix, 0, imgSize);\n\n  sycl::range<2> gws ((size+15)/16*16, (size+15)/16*16);\n  sycl::range<2> lws (16, 16);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class cw>(sycl::nd_range<2>(gws, lws),\n        [=] (sycl::nd_item<2> item) {\n        color(item, d_pix, size, half_size, range, truerange);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(res, d_pix, imgSize).wait();\n\n  \n\n  int fail = memcmp(pix, res, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(res[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  sycl::free(d_pix, q);\n  free(pix);\n  free(res);\n  return 0;\n}\n"}}
{"kernel_name": "convolution1D", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\n__constant__ T mask [MAX_MASK_WIDTH];\n\ntemplate<typename T>\n__global__\nvoid conv1d(const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  T s = 0;\n  int start = i - mask_width / 2;\n  for (int j = 0; j < mask_width; j++) {\n    if (start + j >= 0 && start + j < input_width) {\n      s += in[start + j] * mask<T>[j];\n    }\n  }\n  out[i] = s;\n}\n\ntemplate<typename T>\n__global__\nvoid conv1d_tiled(const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n  __shared__ T tile[TILE_SIZE + MAX_MASK_WIDTH - 1];\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n  int n = mask_width / 2;  \n\n\n  \n\n  int halo_left = (blockIdx.x - 1) * blockDim.x + threadIdx.x;\n  if (threadIdx.x >= blockDim.x - n)\n     tile[threadIdx.x - (blockDim.x - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n  \n\n  tile[n + threadIdx.x] = in[blockIdx.x * blockDim.x + threadIdx.x];\n\n  \n\n  int halo_right = (blockIdx.x + 1) * blockDim.x + threadIdx.x;\n  if (threadIdx.x < n)\n     tile[threadIdx.x + blockDim.x + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n  __syncthreads();\n\n  T s = 0;\n  for (int j = 0; j < mask_width; j++)\n    s += tile[threadIdx.x + j] * mask<T>[j];\n\n  out[i] = s;\n}\n\ntemplate<typename T>\n__global__\nvoid conv1d_tiled_caching(const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n  __shared__ T tile[TILE_SIZE];\n\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  tile[threadIdx.x] = in[i];\n  __syncthreads();\n\n  int this_tile_start = blockIdx.x * blockDim.x;\n  int next_tile_start = (blockIdx.x + 1) * blockDim.x;\n  int start = i - (mask_width / 2);\n  T s = 0;\n  for (int j = 0; j < mask_width; j++) {\n    int in_index = start + j;\n    if (in_index >= 0 && in_index < input_width) {\n      if (in_index >= this_tile_start && in_index < next_tile_start) {\n        \n\n        \n\n        s += tile[threadIdx.x + j - (mask_width / 2)] * mask<T>[j];\n      } else {\n        s += in[in_index] * mask<T>[j];\n      }\n    }\n  }\n  out[i] = s;\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T h_mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) h_mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n  T *d_a, *d_b;\n  cudaMalloc((void **)&d_a, size_bytes);\n  cudaMalloc((void **)&d_b, size_bytes);\n\n  cudaMemcpy(d_a, a, size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpyToSymbol(mask<T>, h_mask, mask_width * sizeof(T));\n\n  dim3 grids (input_width / BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  cudaDeviceSynchronize();\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  cudaMemcpy(b, d_b, size_bytes, cudaMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d_tiled <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  cudaMemcpy(b, d_b, size_bytes, cudaMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d_tiled_caching <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  cudaMemcpy(b, d_b, size_bytes, cudaMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  free(a);\n  free(b);\n  cudaFree(d_a);\n  cudaFree(d_b);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(input_width, mask_width, repeat);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "convolution1D", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\n__constant__ T mask [MAX_MASK_WIDTH];\n\ntemplate<typename T>\n__global__\nvoid conv1d(const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  T s = 0;\n  int start = i - mask_width / 2;\n  for (int j = 0; j < mask_width; j++) {\n    if (start + j >= 0 && start + j < input_width) {\n      s += in[start + j] * mask<T>[j];\n    }\n  }\n  out[i] = s;\n}\n\ntemplate<typename T>\n__global__\nvoid conv1d_tiled(const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n  __shared__ T tile[TILE_SIZE + MAX_MASK_WIDTH - 1];\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n  int n = mask_width / 2;  \n\n\n  \n\n  int halo_left = (blockIdx.x - 1) * blockDim.x + threadIdx.x;\n  if (threadIdx.x >= blockDim.x - n)\n     tile[threadIdx.x - (blockDim.x - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n  \n\n  tile[n + threadIdx.x] = in[blockIdx.x * blockDim.x + threadIdx.x];\n\n  \n\n  int halo_right = (blockIdx.x + 1) * blockDim.x + threadIdx.x;\n  if (threadIdx.x < n)\n     tile[threadIdx.x + blockDim.x + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n  __syncthreads();\n\n  T s = 0;\n  for (int j = 0; j < mask_width; j++)\n    s += tile[threadIdx.x + j] * mask<T>[j];\n\n  out[i] = s;\n}\n\ntemplate<typename T>\n__global__\nvoid conv1d_tiled_caching(const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n  __shared__ T tile[TILE_SIZE];\n\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  tile[threadIdx.x] = in[i];\n  __syncthreads();\n\n  int this_tile_start = blockIdx.x * blockDim.x;\n  int next_tile_start = (blockIdx.x + 1) * blockDim.x;\n  int start = i - (mask_width / 2);\n  T s = 0;\n  for (int j = 0; j < mask_width; j++) {\n    int in_index = start + j;\n    if (in_index >= 0 && in_index < input_width) {\n      if (in_index >= this_tile_start && in_index < next_tile_start) {\n        \n\n        \n\n        s += tile[threadIdx.x + j - (mask_width / 2)] * mask<T>[j];\n      } else {\n        s += in[in_index] * mask<T>[j];\n      }\n    }\n  }\n  out[i] = s;\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T h_mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) h_mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n  T *d_a, *d_b;\n  hipMalloc((void **)&d_a, size_bytes);\n  hipMalloc((void **)&d_b, size_bytes);\n\n  hipMemcpy(d_a, a, size_bytes, hipMemcpyHostToDevice);\n  hipMemcpyToSymbol(mask<T>, h_mask, mask_width * sizeof(T));\n\n  dim3 grids (input_width / BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  hipDeviceSynchronize();\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  hipMemcpy(b, d_b, size_bytes, hipMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d_tiled <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  hipMemcpy(b, d_b, size_bytes, hipMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    conv1d_tiled_caching <<< grids, blocks >>> (d_a, d_b, input_width, mask_width);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  hipMemcpy(b, d_b, size_bytes, hipMemcpyDeviceToHost);\n  reference(a, b, h_mask, input_width, mask_width);\n\n  free(a);\n  free(b);\n  hipFree(d_a);\n  hipFree(d_b);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(input_width, mask_width, repeat);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "convolution1D", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\nvoid conv1d(const T * __restrict__ mask,\n            const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n  #pragma omp target teams distribute parallel for num_threads(BLOCK_SIZE)\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += in[start + j] * mask[j];\n      }\n    }\n    out[i] = s;\n  }\n}\n\ntemplate<typename T>\nvoid conv1d_tiled(const T *__restrict__ mask,\n                  const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n  #pragma omp target teams num_teams(input_width/BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T tile[TILE_SIZE + MAX_MASK_WIDTH - 1];\n    #pragma omp parallel \n    {\n      int bid = omp_get_team_num();\n      int lid = omp_get_thread_num();\n      int dim = omp_get_num_threads();\n      int i = bid * dim + lid;\n\n      int n = mask_width / 2;  \n\n\n      \n\n      int halo_left = (bid - 1) * dim + lid;\n      if (lid >= dim - n)\n         tile[lid - (dim - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n      \n\n      tile[n + lid] = in[bid * dim + lid];\n\n      \n\n      int halo_right = (bid + 1) * dim + lid;\n      if (lid < n)\n         tile[lid + dim + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n      #pragma omp barrier\n\n      T s = 0;\n      for (int j = 0; j < mask_width; j++)\n        s += tile[lid + j] * mask[j];\n\n      out[i] = s;\n    }\n  }\n}\n\ntemplate<typename T>\nvoid conv1d_tiled_caching(const T *__restrict__ mask,\n                          const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n  #pragma omp target teams num_teams(input_width/BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T tile[TILE_SIZE];\n    #pragma omp parallel \n    {\n      int bid = omp_get_team_num();\n      int lid = omp_get_thread_num();\n      int dim = omp_get_num_threads();\n      int i = bid * dim + lid;\n      tile[lid] = in[i];\n      #pragma omp barrier\n\n      int this_tile_start = bid * dim;\n      int next_tile_start = (bid + 1) * dim;\n      int start = i - (mask_width / 2);\n      T s = 0;\n      for (int j = 0; j < mask_width; j++) {\n        int in_index = start + j;\n        if (in_index >= 0 && in_index < input_width) {\n          if (in_index >= this_tile_start && in_index < next_tile_start) {\n            \n\n            \n\n            s += tile[lid + j - (mask_width / 2)] * mask[j];\n          } else {\n            s += in[in_index] * mask[j];\n          }\n        }\n      }\n      out[i] = s;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n  #pragma omp target data map(to: a[0:input_width], \\\n                                  mask[0:mask_width]) \\\n                          map(alloc: b[0:input_width])\n  {\n    \n\n    auto start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d(mask, a, b, input_width, mask_width);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    #pragma omp target update from (b[0:input_width])\n    reference(a, b, mask, input_width, mask_width);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d_tiled(mask, a, b, input_width, mask_width);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    #pragma omp target update from (b[0:input_width])\n    reference(a, b, mask, input_width, mask_width);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d_tiled_caching(mask, a, b, input_width, mask_width);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n    #pragma omp target update from (b[0:input_width])\n    reference(a, b, mask, input_width, mask_width);\n  }\n\n  free(a);\n  free(b);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(input_width, mask_width, repeat);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "convolution1D", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\nvoid conv1d(const T * __restrict__ mask,\n            const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n    for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += in[start + j] * mask[j];\n      }\n    }\n    out[i] = s;\n  }\n}\n\ntemplate<typename T>\nvoid conv1d_tiled(const T *__restrict__ mask,\n                  const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n    {\n    T tile[TILE_SIZE + MAX_MASK_WIDTH - 1];\n        {\n      int bid = omp_get_team_num();\n      int lid = omp_get_thread_num();\n      int dim = omp_get_num_threads();\n      int i = bid * dim + lid;\n\n      int n = mask_width / 2;  \n\n\n      \n\n      int halo_left = (bid - 1) * dim + lid;\n      if (lid >= dim - n)\n         tile[lid - (dim - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n      \n\n      tile[n + lid] = in[bid * dim + lid];\n\n      \n\n      int halo_right = (bid + 1) * dim + lid;\n      if (lid < n)\n         tile[lid + dim + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n      \n      T s = 0;\n      for (int j = 0; j < mask_width; j++)\n        s += tile[lid + j] * mask[j];\n\n      out[i] = s;\n    }\n  }\n}\n\ntemplate<typename T>\nvoid conv1d_tiled_caching(const T *__restrict__ mask,\n                          const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n    {\n    T tile[TILE_SIZE];\n        {\n      int bid = omp_get_team_num();\n      int lid = omp_get_thread_num();\n      int dim = omp_get_num_threads();\n      int i = bid * dim + lid;\n      tile[lid] = in[i];\n      \n      int this_tile_start = bid * dim;\n      int next_tile_start = (bid + 1) * dim;\n      int start = i - (mask_width / 2);\n      T s = 0;\n      for (int j = 0; j < mask_width; j++) {\n        int in_index = start + j;\n        if (in_index >= 0 && in_index < input_width) {\n          if (in_index >= this_tile_start && in_index < next_tile_start) {\n            \n\n            \n\n            s += tile[lid + j - (mask_width / 2)] * mask[j];\n          } else {\n            s += in[in_index] * mask[j];\n          }\n        }\n      }\n      out[i] = s;\n    }\n  }\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n    {\n    \n\n    auto start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d(mask, a, b, input_width, mask_width);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n        reference(a, b, mask, input_width, mask_width);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d_tiled(mask, a, b, input_width, mask_width);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n        reference(a, b, mask, input_width, mask_width);\n\n    \n\n    start = std::chrono::steady_clock::now();\n    for (int i = 0; i < repeat; i++) {\n      conv1d_tiled_caching(mask, a, b, input_width, mask_width);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n        reference(a, b, mask, input_width, mask_width);\n  }\n\n  free(a);\n  free(b);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(input_width, mask_width, repeat);\n  }\n\n  return 0;\n}"}}
{"kernel_name": "convolution1D", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#ifdef __NVPTX__\n  #include <sycl/ext/oneapi/experimental/cuda/builtins.hpp>\n  using namespace sycl::ext::oneapi::experimental::cuda;\n#else\n  #define ldg(a) (*(a))\n#endif\n\n#define MAX_MASK_WIDTH 10\n#define BLOCK_SIZE 256\n#define TILE_SIZE BLOCK_SIZE\n\ntemplate<typename T>\nclass k1;\n\ntemplate<typename T>\nclass k2;\n\ntemplate<typename T>\nclass k3;\n\ntemplate<typename T>\nvoid conv1d(sycl::nd_item<1> &item,\n            const T * __restrict__ mask,\n            const T * __restrict__ in,\n                  T * __restrict__ out,\n            const int input_width,\n            const int mask_width)\n{\n  int i = item.get_global_id(0);\n  T s = 0;\n  int start = i - mask_width / 2;\n  for (int j = 0; j < mask_width; j++) {\n    if (start + j >= 0 && start + j < input_width) {\n      s += in[start + j] * ldg(&mask[j]);\n    }\n  }\n  out[i] = s;\n}\n\ntemplate<typename T>\nvoid conv1d_tiled(sycl::nd_item<1> &item,\n                  sycl::local_ptr<T> tile,\n                  const T * __restrict__ mask,\n                  const T *__restrict__ in,\n                        T *__restrict__ out,\n                  const int input_width,\n                  const int mask_width)\n{\n  int lid = item.get_local_id(0);\n  int bid = item.get_group(0);\n  int dim = item.get_local_range(0);\n  int i = bid * dim + lid;\n\n  int n = mask_width / 2;  \n\n\n  \n\n  int halo_left = (bid - 1) * dim + lid;\n  if (lid >= dim - n)\n     tile[lid - (dim - n)] = halo_left < 0 ? 0 : in[halo_left];\n\n  \n\n  tile[n + lid] = in[bid * dim + lid];\n\n  \n\n  int halo_right = (bid + 1) * dim + lid;\n  if (lid < n)\n     tile[lid + dim + n] = halo_right >= input_width ? 0 : in[halo_right];\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  T s = 0;\n  for (int j = 0; j < mask_width; j++)\n    s += tile[lid + j] * ldg(&mask[j]);\n\n  out[i] = s;\n}\n\ntemplate<typename T>\nvoid conv1d_tiled_caching(sycl::nd_item<1> &item,\n                          sycl::local_ptr<T> tile,\n                          const T *__restrict__ mask,\n                          const T *__restrict__ in,\n                                T *__restrict__ out,\n                          const int input_width,\n                          const int mask_width)\n{\n  int lid = item.get_local_id(0);\n  int bid = item.get_group(0);\n  int dim = item.get_local_range(0);\n  int i = bid * dim + lid;\n  tile[lid] = in[i];\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  int this_tile_start = bid * dim;\n  int next_tile_start = (bid + 1) * dim;\n  int start = i - (mask_width / 2);\n  T s = 0;\n  for (int j = 0; j < mask_width; j++) {\n    int in_index = start + j;\n    if (in_index >= 0 && in_index < input_width) {\n      if (in_index >= this_tile_start && in_index < next_tile_start) {\n        \n\n        \n\n        s += tile[lid + j - (mask_width / 2)] * ldg(&mask[j]);\n      } else {\n        s += in[in_index] * ldg(&mask[j]);\n      }\n    }\n  }\n  out[i] = s;\n}\n\ntemplate <typename T>\nvoid reference(const T *h_in,\n               const T *d_out,\n               const T *mask,\n               const int input_width,\n               const int mask_width)\n{\n  bool ok = true;\n  for (int i = 0; i < input_width; i++) {\n    T s = 0;\n    int start = i - mask_width / 2;\n    for (int j = 0; j < mask_width; j++) {\n      if (start + j >= 0 && start + j < input_width) {\n        s += h_in[start + j] * mask[j];\n      }\n    }\n    if (fabs(s - d_out[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename T>\nvoid conv1D(sycl::queue &q, const int input_width, const int mask_width, const int repeat)\n{\n  size_t size_bytes = input_width * sizeof(T);\n\n  T *a, *b;\n  a = (T *)malloc(size_bytes); \n\n  b = (T *)malloc(size_bytes); \n\n\n  T h_mask[MAX_MASK_WIDTH];\n\n  for (int i = 0; i < MAX_MASK_WIDTH; i++) h_mask[i] = 1; \n\n  srand(123);\n  for (int i = 0; i < input_width; i++) {\n    a[i] = rand() % 256;\n  }\n\n  T *mask, *d_a, *d_b;\n  mask = sycl::malloc_device<T>(MAX_MASK_WIDTH, q);\n  d_a = sycl::malloc_device<T>(input_width, q);\n  d_b = sycl::malloc_device<T>(input_width, q);\n\n  q.memcpy(d_a, a, size_bytes);\n  q.memcpy(mask, h_mask, mask_width * sizeof(T));\n\n  sycl::range<1> gws (input_width);\n  sycl::range<1> lws (BLOCK_SIZE);\n\n  q.wait();\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k1<T>>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        conv1d(item, mask, d_a, d_b, input_width, mask_width);\n      });\n    });\n  }\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  q.memcpy(b, d_b, size_bytes).wait();\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> tile (sycl::range<1>(TILE_SIZE + MAX_MASK_WIDTH - 1), cgh);\n      cgh.parallel_for<class k2<T>>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        conv1d_tiled(item, tile.get_pointer(), mask, d_a, d_b, input_width, mask_width);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  q.memcpy(b, d_b, size_bytes).wait();\n  reference(a, b, h_mask, input_width, mask_width);\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> tile (sycl::range<1>(TILE_SIZE), cgh);\n      cgh.parallel_for<class k3<T>>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        conv1d_tiled_caching(item, tile.get_pointer(), mask, d_a, d_b, input_width, mask_width);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time of conv1d-tiled-caching kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n  q.memcpy(b, d_b, size_bytes).wait();\n  reference(a, b, h_mask, input_width, mask_width);\n\n  free(a);\n  free(b);\n  sycl::free(mask, q);\n  sycl::free(d_a, q);\n  sycl::free(d_b, q);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <input_width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int input_width = atoi(argv[1]);\n  \n\n  input_width = (input_width + BLOCK_SIZE - 1) / BLOCK_SIZE * BLOCK_SIZE;\n\n  const int repeat = atoi(argv[2]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  for (int mask_width = 3; mask_width < MAX_MASK_WIDTH; mask_width += 2) {\n    printf(\"\\n---------------------\\n\");\n    printf(\"Mask width: %d\\n\", mask_width); \n\n    printf(\"1D convolution (FP64)\\n\");\n    conv1D<double>(q, input_width, mask_width, repeat);\n\n    printf(\"1D convolution (FP32)\\n\");\n    conv1D<float>(q, input_width, mask_width, repeat);\n\n    printf(\"1D convolution (INT16)\\n\");\n    conv1D<int16_t>(q, input_width, mask_width, repeat);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "debayer", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n#include \"util.h\"\n#include \"image.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int input_image_pitch = width;\n  const int output_image_pitch = width * 4;\n  const int numPix = width * height;\n  const int input_image_size = numPix * sizeof(uchar);\n  const int output_image_size = numPix * 4 * sizeof(uchar);\n\n  uchar *input = (uchar*) malloc (input_image_size);\n  uchar *output = (uchar*) malloc (output_image_size);\n\n  \n\n  const int bayer_pattern = RGGB;\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    input[i] = rand() % 256;\n  }\n\n  uchar *d_input;\n  cudaMalloc((void**)&d_input, input_image_size);\n  cudaMemcpy(d_input, input, input_image_size, cudaMemcpyHostToDevice);\n\n  uchar *d_output;\n  cudaMalloc((void**)&d_output, output_image_size);\n\n  dim3 grids ((width + tile_cols - 1) / tile_cols, (height + tile_rows - 1) / tile_rows);\n  dim3 blocks (tile_cols, tile_rows);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    cudaMemset(d_output, 0, output_image_size);\n    malvar_he_cutler_demosaic <<< grids, blocks >>> (\n      height, width, \n      d_input, input_image_pitch,\n      d_output, output_image_pitch,\n      bayer_pattern );\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n\n  cudaMemcpy(output, d_output, output_image_size, cudaMemcpyDeviceToHost);\n\n  long sum = 0;\n  for (int i = 0; i < numPix; i++) sum += output[i];\n  printf(\"Checksum: %ld\\n\", sum);\n\n  free(input);\n  free(output);\n  cudaFree(d_input);\n  cudaFree(d_output);\n  return 0;\n}\n"}}
{"kernel_name": "debayer", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"util.h\"\n#include \"image.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int input_image_pitch = width;\n  const int output_image_pitch = width * 4;\n  const int numPix = width * height;\n  const int input_image_size = numPix * sizeof(uchar);\n  const int output_image_size = numPix * 4 * sizeof(uchar);\n\n  uchar *input = (uchar*) malloc (input_image_size);\n  uchar *output = (uchar*) malloc (output_image_size);\n\n  \n\n  const int bayer_pattern = RGGB;\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    input[i] = rand() % 256;\n  }\n\n  uchar *d_input;\n  hipMalloc((void**)&d_input, input_image_size);\n  hipMemcpy(d_input, input, input_image_size, hipMemcpyHostToDevice);\n\n  uchar *d_output;\n  hipMalloc((void**)&d_output, output_image_size);\n\n  dim3 grids ((width + tile_cols - 1) / tile_cols, (height + tile_rows - 1) / tile_rows);\n  dim3 blocks (tile_cols, tile_rows);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++) \n    hipMemset(d_output, 0, output_image_size);\n    hipLaunchKernelGGL(malvar_he_cutler_demosaic, grids, blocks , 0, 0, \n      height, width, \n      d_input, input_image_pitch,\n      d_output, output_image_pitch,\n      bayer_pattern );\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n\n  hipMemcpy(output, d_output, output_image_size, hipMemcpyDeviceToHost);\n\n  long sum = 0;\n  for (int i = 0; i < numPix; i++) sum += output[i];\n  printf(\"Checksum: %ld\\n\", sum);\n\n  free(input);\n  free(output);\n  hipFree(d_input);\n  hipFree(d_output);\n  return 0;\n}\n"}}
{"kernel_name": "debayer", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n#include \"util.h\"\n#include \"image.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int input_image_pitch = width;\n  const int output_image_pitch = width * 4;\n  const int numPix = width * height;\n  const int input_image_size = numPix * sizeof(uchar);\n  const int output_image_size = numPix * 4 * sizeof(uchar);\n\n  uchar *input = (uchar*) malloc (input_image_size);\n  uchar *output = (uchar*) malloc (output_image_size);\n\n  \n\n  const int bayer_pattern = RGGB;\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    input[i] = rand() % 256;\n  }\n\n  const uint teamX = (width + tile_cols - 1) / tile_cols;\n  const uint teamY = (height + tile_rows - 1) / tile_rows;\n\n  #pragma omp target data map(to: input[0:numPix]) map(from: output[0:numPix])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    \n\n    for (int i = 0; i < repeat; i++) {\n      memset(output, 0, output_image_size);\n      #pragma omp target update to(output[0:numPix])\n      malvar_he_cutler_demosaic (\n        teamX, teamY,\n        height, width, \n        input, input_image_pitch,\n        output, output_image_pitch,\n        bayer_pattern );\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n  }\n\n  long sum = 0;\n  for (int i = 0; i < numPix; i++) sum += output[i];\n  printf(\"Checksum: %ld\\n\", sum);\n\n  free(input);\n  free(output);\n  return 0;\n}\n"}}
{"kernel_name": "debayer", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include \"util.h\"\n#include \"image.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int input_image_pitch = width;\n  const int output_image_pitch = width * 4;\n  const int numPix = width * height;\n  const int input_image_size = numPix * sizeof(uchar);\n  const int output_image_size = numPix * 4 * sizeof(uchar);\n\n  uchar *input = (uchar*) malloc (input_image_size);\n  uchar *output = (uchar*) malloc (output_image_size);\n\n  \n\n  const int bayer_pattern = RGGB;\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    input[i] = rand() % 256;\n  }\n\n  const uint teamX = (width + tile_cols - 1) / tile_cols;\n  const uint teamY = (height + tile_rows - 1) / tile_rows;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    \n\n    for (int i = 0; i < repeat; i++) {\n      memset(output, 0, output_image_size);\n            malvar_he_cutler_demosaic (\n        teamX, teamY,\n        height, width, \n        input, input_image_pitch,\n        output, output_image_pitch,\n        bayer_pattern );\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n  }\n\n  long sum = 0;\n  for (int i = 0; i < numPix; i++) sum += output[i];\n  printf(\"Checksum: %ld\\n\", sum);\n\n  free(input);\n  free(output);\n  return 0;\n}"}}
{"kernel_name": "debayer", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nusing namespace sycl;\n\n#include \"util.h\"\n#include \"image.h\"\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int input_image_pitch = width;\n  const int output_image_pitch = width * 4;\n  const int numPix = width * height;\n  const int input_image_size = numPix * sizeof(uchar);\n  const int output_image_size = numPix * 4 * sizeof(uchar);\n\n  uchar *input = (uchar*) malloc (input_image_size);\n  uchar *output = (uchar*) malloc (output_image_size);\n\n  \n\n  const int bayer_pattern = RGGB;\n\n  \n\n  srand(123);\n  for (int i = 0; i < numPix; i++) {\n    input[i] = rand() % 256;\n  }\n\n#ifdef USE_GPU\n  queue q(gpu_selector_v, property::queue::in_order());\n#else\n  queue q(cpu_selector_v, property::queue::in_order());\n#endif\n\n  uchar *d_input = malloc_device<uchar>(numPix, q);\n  q.memcpy(d_input, input, input_image_size);\n\n  uchar *d_output = malloc_device<uchar>(numPix * 4, q);\n\n  range<2> gws ((height + tile_rows - 1) / tile_rows * tile_rows, \n                      (width + tile_cols - 1) / tile_cols * tile_cols);\n  range<2> lws (tile_rows, tile_cols);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    q.memset(d_output, 0, output_image_size);\n\n    q.submit([&] (handler &cgh) {\n      local_accessor<LDSPixelT, 1> apron(range<1>(apron_rows * apron_cols), cgh);\n      cgh.parallel_for<class debayer>(\n        nd_range<2>(gws, lws), [=] (nd_item<2> item) {\n        malvar_he_cutler_demosaic (\n          item, apron.get_pointer(), height, width, \n          d_input, input_image_pitch,\n          d_output, output_image_pitch,\n          bayer_pattern );\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", time * 1e-9f / repeat);\n\n  q.memcpy(output, d_output, output_image_size);\n\n  long sum = 0;\n  for (int i = 0; i < numPix; i++) sum += output[i];\n  printf(\"Checksum: %ld\\n\", sum);\n\n  free(input);\n  free(output);\n  free(d_input, q);\n  free(d_output, q);\n  return 0;\n}\n"}}
{"kernel_name": "depixel", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"kernels.h\"\n\n#define nthreads 256\n\nint main(int argc, char** argv) {\n\n  if (argc != 4) {\n    printf(\"Usage: %s <image width> <image height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int width = atoi(argv[1]);\n  int height = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int size = width * height;\n  size_t size_output_bytes = size * sizeof(uint);\n  size_t size_image_bytes = size * sizeof(float3);\n\n  std::mt19937 gen(19937);\n  \n\n  std::uniform_real_distribution<float> dis(0.f, 0.4f); \n\n  float3 *h_img = (float3*) malloc(size_image_bytes);\n\n  uint *h_out = (uint*) malloc(size_output_bytes);\n\n  float3 *d_img;\n  cudaMalloc((void**)&d_img, size_image_bytes);\n\n  uint *d_tmp, *d_out;\n  cudaMalloc((void**)&d_tmp, size_output_bytes);\n  cudaMalloc((void**)&d_out, size_output_bytes);\n\n  \n\n  dim3 grids (size / nthreads); \n  dim3 blocks (nthreads);\n\n  float sum = 0;\n  float total_time = 0;\n\n  for (int n = 0; n < repeat; n++) {\n\n    for (int i = 0; i < size; i++) {\n      h_img[i].x = dis(gen);\n      h_img[i].y = dis(gen);\n      h_img[i].z = dis(gen);\n    }\n\n    cudaMemcpy(d_img, h_img, size_image_bytes, cudaMemcpyHostToDevice);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    check_connect<<<grids, blocks>>>(d_img, d_tmp, width, height);\n    eliminate_crosses<<<grids, blocks>>>(d_tmp, d_out, width, height);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    std::chrono::duration<float> time = end - start;\n    total_time += time.count();\n\n    cudaMemcpy(h_out, d_out, size_output_bytes, cudaMemcpyDeviceToHost);\n\n    float lsum = 0;\n    for (int i = 0; i < size; i++)\n      lsum += (h_out[i] & 0xff) / 256.f + \n             ((h_out[i] >> 8) & 0xff) / 256.f + \n             ((h_out[i] >> 16) & 0xff) / 256.f + \n             ((h_out[i] >> 24) & 0xff) / 256.f;\n\n    sum += lsum / size;\n  }\n\n  printf(\"Image size: %d (width) x %d (height)\\ncheckSum: %f\\n\",\n         width, height, sum);\n  printf(\"Average kernel time over %d iterations: %f (s)\\n\",\n         repeat, total_time / repeat);\n\n  cudaFree(d_out);\n  cudaFree(d_img);\n  cudaFree(d_tmp);\n  free(h_out);\n  free(h_img);\n\n  return 0;\n}\n"}}
{"kernel_name": "depixel", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"kernels.h\"\n\n#define nthreads 256\n\nint main(int argc, char** argv) {\n\n  if (argc != 4) {\n    printf(\"Usage: %s <image width> <image height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int width = atoi(argv[1]);\n  int height = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int size = width * height;\n  size_t size_output_bytes = size * sizeof(uint);\n  size_t size_image_bytes = size * sizeof(float3);\n\n  std::mt19937 gen(19937);\n  \n\n  std::uniform_real_distribution<float> dis(0.f, 0.4f); \n\n  float3 *h_img = (float3*) malloc(size_image_bytes);\n\n  uint *h_out = (uint*) malloc(size_output_bytes);\n\n  float3 *d_img;\n  hipMalloc((void**)&d_img, size_image_bytes);\n\n  uint *d_tmp, *d_out;\n  hipMalloc((void**)&d_tmp, size_output_bytes);\n  hipMalloc((void**)&d_out, size_output_bytes);\n\n  \n\n  dim3 grids (size / nthreads); \n  dim3 blocks (nthreads);\n\n  float sum = 0;\n  float total_time = 0;\n\n  for (int n = 0; n < repeat; n++) {\n\n    for (int i = 0; i < size; i++) {\n      h_img[i].x = dis(gen);\n      h_img[i].y = dis(gen);\n      h_img[i].z = dis(gen);\n    }\n\n    hipMemcpy(d_img, h_img, size_image_bytes, hipMemcpyHostToDevice);\n    auto start = std::chrono::steady_clock::now();\n\n    check_connect<<<grids, blocks>>>(d_img, d_tmp, width, height);\n    eliminate_crosses<<<grids, blocks>>>(d_tmp, d_out, width, height);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n\n    hipMemcpy(h_out, d_out, size_output_bytes, hipMemcpyDeviceToHost);\n\n    std::chrono::duration<float> time = end - start;\n    total_time += time.count();\n\n    float lsum = 0;\n    for (int i = 0; i < size; i++)\n      lsum += (h_out[i] & 0xff) / 256.f + \n             ((h_out[i] >> 8) & 0xff) / 256.f + \n             ((h_out[i] >> 16) & 0xff) / 256.f + \n             ((h_out[i] >> 24) & 0xff) / 256.f;\n\n    sum += lsum / size;\n  }\n\n  printf(\"Image size: %d (width) x %d (height)\\ncheckSum: %f\\n\",\n         width, height, sum);\n  printf(\"Average kernel time over %d iterations: %f (s)\\n\",\n         repeat, total_time / repeat);\n\n  hipFree(d_out);\n  hipFree(d_img);\n  hipFree(d_tmp);\n  free(h_out);\n  free(h_img);\n\n  return 0;\n}\n"}}
{"kernel_name": "depixel", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"kernels.h\"\n\nint main(int argc, char** argv) {\n\n  if (argc != 4) {\n    printf(\"Usage: %s <image width> <image height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int width = atoi(argv[1]);\n  int height = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int size = width * height;\n  size_t size_output_bytes = size * sizeof(uint);\n  size_t size_image_bytes = size * sizeof(float3);\n\n  std::mt19937 gen(19937);\n  \n\n  std::uniform_real_distribution<float> dis(0.f, 0.4f); \n\n  float3 *img = (float3*) malloc(size_image_bytes);\n\n  uint *out = (uint*) malloc(size_output_bytes);\n  uint *tmp = (uint*) malloc(size_output_bytes);\n\n  float sum = 0;\n  float total_time = 0;\n\n  #pragma omp target data map (alloc: img[0:size], tmp[0:size]) \\\n                          map (from: out[0:size])\n  {\n    for (int n = 0; n < repeat; n++) {\n\n      for (int i = 0; i < size; i++) {\n        img[i].x = dis(gen);\n        img[i].y = dis(gen);\n        img[i].z = dis(gen);\n      }\n\n      #pragma omp target update to (img[0:size])\n\n      auto start = std::chrono::steady_clock::now();\n\n      check_connect(img, tmp, width, height);\n      eliminate_crosses(tmp, out, width, height);\n\n      auto end = std::chrono::steady_clock::now();\n\n      #pragma omp target update from (out[0:size])\n\n      std::chrono::duration<float> time = end - start;\n      total_time += time.count();\n\n      float lsum = 0;\n      for (int i = 0; i < size; i++)\n        lsum += (out[i] & 0xff) / 256.f + \n               ((out[i] >> 8) & 0xff) / 256.f + \n               ((out[i] >> 16) & 0xff) / 256.f + \n               ((out[i] >> 24) & 0xff) / 256.f;\n\n      sum += lsum / size;\n    }\n  }\n\n  printf(\"Image size: %d (width) x %d (height)\\ncheckSum: %f\\n\",\n         width, height, sum);\n  printf(\"Average kernel time over %d iterations: %f (s)\\n\",\n         repeat, total_time / repeat);\n\n  free(out);\n  free(img);\n  free(tmp);\n\n  return 0;\n}\n"}}
{"kernel_name": "depixel", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"kernels.h\"\n\nint main(int argc, char** argv) {\n\n  if (argc != 4) {\n    printf(\"Usage: %s <image width> <image height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int width = atoi(argv[1]);\n  int height = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int size = width * height;\n  size_t size_output_bytes = size * sizeof(uint);\n  size_t size_image_bytes = size * sizeof(float3);\n\n  std::mt19937 gen(19937);\n  \n\n  std::uniform_real_distribution<float> dis(0.f, 0.4f); \n\n  float3 *img = (float3*) malloc(size_image_bytes);\n\n  uint *out = (uint*) malloc(size_output_bytes);\n  uint *tmp = (uint*) malloc(size_output_bytes);\n\n  float sum = 0;\n  float total_time = 0;\n\n    {\n    for (int n = 0; n < repeat; n++) {\n\n      for (int i = 0; i < size; i++) {\n        img[i].x = dis(gen);\n        img[i].y = dis(gen);\n        img[i].z = dis(gen);\n      }\n\n      \n      auto start = std::chrono::steady_clock::now();\n\n      check_connect(img, tmp, width, height);\n      eliminate_crosses(tmp, out, width, height);\n\n      auto end = std::chrono::steady_clock::now();\n\n      \n      std::chrono::duration<float> time = end - start;\n      total_time += time.count();\n\n      float lsum = 0;\n      for (int i = 0; i < size; i++)\n        lsum += (out[i] & 0xff) / 256.f + \n               ((out[i] >> 8) & 0xff) / 256.f + \n               ((out[i] >> 16) & 0xff) / 256.f + \n               ((out[i] >> 24) & 0xff) / 256.f;\n\n      sum += lsum / size;\n    }\n  }\n\n  printf(\"Image size: %d (width) x %d (height)\\ncheckSum: %f\\n\",\n         width, height, sum);\n  printf(\"Average kernel time over %d iterations: %f (s)\\n\",\n         repeat, total_time / repeat);\n\n  free(out);\n  free(img);\n  free(tmp);\n\n  return 0;\n}"}}
{"kernel_name": "depixel", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n\n#define nthreads 256\n\nint main(int argc, char** argv) {\n\n  if (argc != 4) {\n    printf(\"Usage: %s <image width> <image height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int width = atoi(argv[1]);\n  int height = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int size = width * height;\n  size_t size_output_bytes = size * sizeof(uint);\n  size_t size_image_bytes = size * sizeof(sycl::float3);\n\n  std::mt19937 gen(19937);\n  \n\n  std::uniform_real_distribution<float> dis(0.f, 0.4f); \n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  sycl::float3 *h_img = (sycl::float3*) malloc(size_image_bytes);\n\n  uint *h_out = (uint*) malloc(size_output_bytes);\n\n  sycl::float3 *d_img = sycl::malloc_device<sycl::float3>(size, q);\n\n  uint *d_tmp = sycl::malloc_device<uint>(size, q);\n\n  uint *d_out = sycl::malloc_device<uint>(size, q);\n\n  \n\n  sycl::range<1> gws (size);\n  sycl::range<1> lws (nthreads);\n\n  float sum = 0;\n  float total_time = 0;\n\n  for (int n = 0; n < repeat; n++) {\n\n    for (int i = 0; i < size; i++) {\n      h_img[i].x() = dis(gen);\n      h_img[i].y() = dis(gen);\n      h_img[i].z() = dis(gen);\n    }\n\n    q.memcpy(d_img, h_img, size_image_bytes).wait();\n\n    auto start = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class check>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        check_connect(item, d_img, d_tmp, width, height);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class remove>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        eliminate_crosses(item, d_tmp, d_out, width, height);\n      });\n    });\n  \n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    std::chrono::duration<float> time = end - start;\n    total_time += time.count();\n\n    q.memcpy(h_out, d_out, size_output_bytes).wait();\n\n    float lsum = 0;\n    for (int i = 0; i < size; i++)\n      lsum += (h_out[i] & 0xff) / 256.f + \n             ((h_out[i] >> 8) & 0xff) / 256.f + \n             ((h_out[i] >> 16) & 0xff) / 256.f + \n             ((h_out[i] >> 24) & 0xff) / 256.f;\n\n    sum += lsum / size;\n  }\n\n  printf(\"Image size: %d (width) x %d (height)\\ncheckSum: %f\\n\",\n         width, height, sum);\n  printf(\"Average kernel time over %d iterations: %f (s)\\n\",\n         repeat, total_time / repeat);\n\n  sycl::free(d_out, q);\n  sycl::free(d_img, q);\n  sycl::free(d_tmp, q);\n  free(h_out);\n  free(h_img);\n\n  return 0;\n}\n"}}
{"kernel_name": "doh", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n\ntypedef float IMAGE_T;\ntypedef int INT_T;\n\n\n\n__device__\ninline int _clip(const int x, const int low, const int high)\n{\n  if (x > high)\n    return high;\n  else if (x < low)\n    return low;\n  else\n    return x;\n}\n\n\n\n\n__device__\ninline IMAGE_T _integ(const IMAGE_T * img,\n                      const INT_T img_rows,\n                      const INT_T img_cols,\n                      int r,\n                      int c,\n                      const int rl,\n                      const int cl)\n{\n  r = _clip(r, 0, img_rows - 1);\n  c = _clip(c, 0, img_cols - 1);\n\n  const int r2 = _clip(r + rl, 0, img_rows - 1);\n  const int c2 = _clip(c + cl, 0, img_cols - 1);\n\n  IMAGE_T ans = img[r * img_cols + c] + img[r2 * img_cols + c2] -\n                img[r * img_cols + c2] - img[r2 * img_cols + c];\n\n  return max((IMAGE_T)0, ans);\n}\n\n\n\n\n__global__\nvoid hessian_matrix_det(const IMAGE_T* img,\n                        const INT_T img_rows,\n                        const INT_T img_cols,\n                        const IMAGE_T sigma,\n                        IMAGE_T* out)\n{\n  int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (tid >= img_rows*img_cols) return;\n\n  const int r = tid / img_cols;\n  const int c = tid % img_cols;\n\n  int size = (int)((IMAGE_T)3.0 * sigma);\n\n  const int b = (size - 1) / 2 + 1;\n  const int l = size / 3;\n  const int w = size;\n\n  const IMAGE_T w_i = (IMAGE_T)1.0 / (size * size);\n\n  const IMAGE_T tl = _integ(img, img_rows, img_cols, r - l, c - l, l, l); \n\n  const IMAGE_T br = _integ(img, img_rows, img_cols, r + 1, c + 1, l, l); \n\n  const IMAGE_T bl = _integ(img, img_rows, img_cols, r - l, c + 1, l, l); \n\n  const IMAGE_T tr = _integ(img, img_rows, img_cols, r + 1, c - l, l, l); \n\n\n  IMAGE_T dxy = bl + tr - tl - br;\n  dxy = -dxy * w_i;\n\n  IMAGE_T mid = _integ(img, img_rows, img_cols, r - l + 1, c - l, 2 * l - 1, w);  \n\n  IMAGE_T side = _integ(img, img_rows, img_cols, r - l + 1, c - l / 2, 2 * l - 1, l);  \n\n\n  IMAGE_T dxx = mid - (IMAGE_T)3 * side;\n  dxx = -dxx * w_i;\n\n  mid = _integ(img, img_rows, img_cols, r - l, c - b + 1, w, 2 * b - 1);\n  side = _integ(img, img_rows, img_cols, r - b / 2, c - b + 1, b, 2 * b - 1);\n\n  IMAGE_T dyy = mid - (IMAGE_T)3 * side;\n  dyy = -dyy * w_i;\n\n  out[tid] = (dxx * dyy - (IMAGE_T)0.81 * (dxy * dxy));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <image height> <image width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int h = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int img_size = h * w;\n  size_t img_size_bytes = sizeof(float) * img_size;\n\n  float *input_img = (float*) malloc (img_size_bytes);\n  float *integral_img = (float*) malloc (img_size_bytes);\n  float *output_img = (float*) malloc (img_size_bytes);\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> norm_dist(0.f, 1.f);\n\n  for (int i = 0; i < img_size; i++) {\n    input_img[i] = norm_dist(rng);\n  }\n\n  printf(\"Integrating the input image may take a while...\\n\"); \n  for (int i = 0; i < h; i++) {\n    for (int j = 0; j < w; j++) {\n      IMAGE_T s = 0;\n      for (int y = 0; y <= i; y++)\n        for (int x = 0; x <= j; x++)\n          s += input_img[y * w + x];\n      integral_img[i * w + j] = s;\n    }\n  }\n\n  float *d_input_img;\n  cudaMalloc((void**)&d_input_img, img_size_bytes);\n\n  cudaMemcpy(d_input_img, integral_img, img_size_bytes, cudaMemcpyHostToDevice);\n\n  float *d_output_img;\n  cudaMalloc((void**)&d_output_img, img_size_bytes);\n\n  const IMAGE_T sigma = 4.0;\n\n  dim3 grid ((img_size + 255) / 256);\n  dim3 block (256);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hessian_matrix_det <<< grid, block >>> (\n      d_input_img, h, w, sigma, d_output_img);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  \n  cudaMemcpy(output_img, d_output_img, img_size_bytes, cudaMemcpyDeviceToHost);\n\n  double checksum = 0;\n  for (int i = 0; i < img_size; i++) {\n    checksum += output_img[i];\n  }\n\n  cudaFree(d_input_img);\n  cudaFree(d_output_img);\n  free(input_img);\n  free(integral_img);\n  free(output_img);\n\n  printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3 / repeat);\n  printf(\"Kernel checksum: %lf\\n\", checksum);\n  return 0;\n}\n"}}
{"kernel_name": "doh", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n\ntypedef float IMAGE_T;\ntypedef int INT_T;\n\n\n\n__device__\ninline int _clip(const int x, const int low, const int high)\n{\n  if (x > high)\n    return high;\n  else if (x < low)\n    return low;\n  else\n    return x;\n}\n\n\n\n\n__device__\ninline IMAGE_T _integ(const IMAGE_T * img,\n                      const INT_T img_rows,\n                      const INT_T img_cols,\n                      int r,\n                      int c,\n                      const int rl,\n                      const int cl)\n{\n  r = _clip(r, 0, img_rows - 1);\n  c = _clip(c, 0, img_cols - 1);\n\n  const int r2 = _clip(r + rl, 0, img_rows - 1);\n  const int c2 = _clip(c + cl, 0, img_cols - 1);\n\n  IMAGE_T ans = img[r * img_cols + c] + img[r2 * img_cols + c2] -\n                img[r * img_cols + c2] - img[r2 * img_cols + c];\n\n  return max((IMAGE_T)0, ans);\n}\n\n\n\n\n__global__\nvoid hessian_matrix_det(const IMAGE_T* img,\n                        const INT_T img_rows,\n                        const INT_T img_cols,\n                        const IMAGE_T sigma,\n                        IMAGE_T* out)\n{\n  int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (tid >= img_rows*img_cols) return;\n\n  const int r = tid / img_cols;\n  const int c = tid % img_cols;\n\n  int size = (int)((IMAGE_T)3.0 * sigma);\n\n  const int b = (size - 1) / 2 + 1;\n  const int l = size / 3;\n  const int w = size;\n\n  const IMAGE_T w_i = (IMAGE_T)1.0 / (size * size);\n\n  const IMAGE_T tl = _integ(img, img_rows, img_cols, r - l, c - l, l, l); \n\n  const IMAGE_T br = _integ(img, img_rows, img_cols, r + 1, c + 1, l, l); \n\n  const IMAGE_T bl = _integ(img, img_rows, img_cols, r - l, c + 1, l, l); \n\n  const IMAGE_T tr = _integ(img, img_rows, img_cols, r + 1, c - l, l, l); \n\n\n  IMAGE_T dxy = bl + tr - tl - br;\n  dxy = -dxy * w_i;\n\n  IMAGE_T mid = _integ(img, img_rows, img_cols, r - l + 1, c - l, 2 * l - 1, w);  \n\n  IMAGE_T side = _integ(img, img_rows, img_cols, r - l + 1, c - l / 2, 2 * l - 1, l);  \n\n\n  IMAGE_T dxx = mid - (IMAGE_T)3 * side;\n  dxx = -dxx * w_i;\n\n  mid = _integ(img, img_rows, img_cols, r - l, c - b + 1, w, 2 * b - 1);\n  side = _integ(img, img_rows, img_cols, r - b / 2, c - b + 1, b, 2 * b - 1);\n\n  IMAGE_T dyy = mid - (IMAGE_T)3 * side;\n  dyy = -dyy * w_i;\n\n  out[tid] = (dxx * dyy - (IMAGE_T)0.81 * (dxy * dxy));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int h = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int img_size = h * w;\n  size_t img_size_bytes = sizeof(float) * img_size;\n\n  float *input_img = (float*) malloc (img_size_bytes);\n  float *integral_img = (float*) malloc (img_size_bytes);\n  float *output_img = (float*) malloc (img_size_bytes);\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> norm_dist(0.f, 1.f);\n\n  for (int i = 0; i < img_size; i++) {\n    input_img[i] = norm_dist(rng);\n  }\n\n  printf(\"Integrating the input image may take a while...\\n\"); \n  for (int i = 0; i < h; i++) {\n    for (int j = 0; j < w; j++) {\n      IMAGE_T s = 0;\n      for (int y = 0; y <= i; y++)\n        for (int x = 0; x <= j; x++)\n          s += input_img[y * w + x];\n      integral_img[i * w + j] = s;\n    }\n  }\n\n  float *d_input_img;\n  hipMalloc((void**)&d_input_img, img_size_bytes);\n\n  hipMemcpy(d_input_img, integral_img, img_size_bytes, hipMemcpyHostToDevice);\n\n  float *d_output_img;\n  hipMalloc((void**)&d_output_img, img_size_bytes);\n\n  const IMAGE_T sigma = 4.0;\n\n  dim3 grid ((img_size + 255) / 256);\n  dim3 block (256);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hessian_matrix_det <<< grid, block >>> (\n      d_input_img, h, w, sigma, d_output_img);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  \n  hipMemcpy(output_img, d_output_img, img_size_bytes, hipMemcpyDeviceToHost);\n\n  double checksum = 0;\n  for (int i = 0; i < img_size; i++) {\n    checksum += output_img[i];\n  }\n\n  hipFree(d_input_img);\n  hipFree(d_output_img);\n  free(input_img);\n  free(integral_img);\n  free(output_img);\n\n  printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3 / repeat);\n  printf(\"Kernel checksum: %lf\\n\", checksum);\n  return 0;\n}\n"}}
{"kernel_name": "doh", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n\ntypedef float IMAGE_T;\ntypedef int INT_T;\n\n\n\n\ninline int _clip(const int x, const int low, const int high)\n{\n  if (x > high)\n    return high;\n  else if (x < low)\n    return low;\n  else\n    return x;\n}\n\n\n\n\n\ninline IMAGE_T _integ(const IMAGE_T * img,\n                      const INT_T img_rows,\n                      const INT_T img_cols,\n                      int r,\n                      int c,\n                      const int rl,\n                      const int cl)\n{\n  r = _clip(r, 0, img_rows - 1);\n  c = _clip(c, 0, img_cols - 1);\n\n  const int r2 = _clip(r + rl, 0, img_rows - 1);\n  const int c2 = _clip(c + cl, 0, img_cols - 1);\n\n  IMAGE_T ans = img[r * img_cols + c] + img[r2 * img_cols + c2] -\n                img[r * img_cols + c2] - img[r2 * img_cols + c];\n\n  return fmax((IMAGE_T)0, ans);\n}\n\n\n\n\n\nvoid hessian_matrix_det(const IMAGE_T* img,\n                        const INT_T img_rows,\n                        const INT_T img_cols,\n                        const IMAGE_T sigma,\n                        IMAGE_T* out)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int tid = 0; tid < img_rows*img_cols; tid++) {\n\n    const int r = tid / img_cols;\n    const int c = tid % img_cols;\n\n    int size = (int)((IMAGE_T)3.0 * sigma);\n\n    const int b = (size - 1) / 2 + 1;\n    const int l = size / 3;\n    const int w = size;\n\n    const IMAGE_T w_i = (IMAGE_T)1.0 / (size * size);\n\n    const IMAGE_T tl = _integ(img, img_rows, img_cols, r - l, c - l, l, l); \n\n    const IMAGE_T br = _integ(img, img_rows, img_cols, r + 1, c + 1, l, l); \n\n    const IMAGE_T bl = _integ(img, img_rows, img_cols, r - l, c + 1, l, l); \n\n    const IMAGE_T tr = _integ(img, img_rows, img_cols, r + 1, c - l, l, l); \n\n\n    IMAGE_T dxy = bl + tr - tl - br;\n    dxy = -dxy * w_i;\n\n    IMAGE_T mid = _integ(img, img_rows, img_cols, r - l + 1, c - l, 2 * l - 1, w);  \n\n    IMAGE_T side = _integ(img, img_rows, img_cols, r - l + 1, c - l / 2, 2 * l - 1, l);  \n\n\n    IMAGE_T dxx = mid - (IMAGE_T)3 * side;\n    dxx = -dxx * w_i;\n\n    mid = _integ(img, img_rows, img_cols, r - l, c - b + 1, w, 2 * b - 1);\n    side = _integ(img, img_rows, img_cols, r - b / 2, c - b + 1, b, 2 * b - 1);\n\n    IMAGE_T dyy = mid - (IMAGE_T)3 * side;\n    dyy = -dyy * w_i;\n\n    out[tid] = (dxx * dyy - (IMAGE_T)0.81 * (dxy * dxy));\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int h = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int img_size = h * w;\n  size_t img_size_bytes = sizeof(float) * img_size;\n\n  float *input_img = (float*) malloc (img_size_bytes);\n  float *integral_img = (float*) malloc (img_size_bytes);\n  float *output_img = (float*) malloc (img_size_bytes);\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> norm_dist(0.f, 1.f);\n\n  for (int i = 0; i < img_size; i++) {\n    input_img[i] = norm_dist(rng);\n  }\n\n  printf(\"Integrating the input image may take a while...\\n\"); \n  for (int i = 0; i < h; i++) {\n    for (int j = 0; j < w; j++) {\n      IMAGE_T s = 0;\n      for (int y = 0; y <= i; y++)\n        for (int x = 0; x <= j; x++)\n          s += input_img[y * w + x];\n      integral_img[i * w + j] = s;\n    }\n  }\n\n  long time;\n\n  #pragma omp target data map(to: integral_img[0:img_size]) \\\n                          map(from: output_img[0:img_size])\n  {\n    const IMAGE_T sigma = 4.0;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      hessian_matrix_det(integral_img, h, w, sigma, output_img);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  double checksum = 0;\n  for (int i = 0; i < img_size; i++) {\n    checksum += output_img[i];\n  }\n\n  free(input_img);\n  free(integral_img);\n  free(output_img);\n\n  printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3 / repeat);\n  printf(\"Kernel checksum: %lf\\n\", checksum);\n\n  return 0;\n}\n"}}
{"kernel_name": "doh", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n\ntypedef float IMAGE_T;\ntypedef int INT_T;\n\n\n\n\ninline int _clip(const int x, const int low, const int high)\n{\n  if (x > high)\n    return high;\n  else if (x < low)\n    return low;\n  else\n    return x;\n}\n\n\n\n\n\ninline IMAGE_T _integ(const IMAGE_T * img,\n                      const INT_T img_rows,\n                      const INT_T img_cols,\n                      int r,\n                      int c,\n                      const int rl,\n                      const int cl)\n{\n  r = _clip(r, 0, img_rows - 1);\n  c = _clip(c, 0, img_cols - 1);\n\n  const int r2 = _clip(r + rl, 0, img_rows - 1);\n  const int c2 = _clip(c + cl, 0, img_cols - 1);\n\n  IMAGE_T ans = img[r * img_cols + c] + img[r2 * img_cols + c2] -\n                img[r * img_cols + c2] - img[r2 * img_cols + c];\n\n  return fmax((IMAGE_T)0, ans);\n}\n\n\n\n\n\nvoid hessian_matrix_det(const IMAGE_T* img,\n                        const INT_T img_rows,\n                        const INT_T img_cols,\n                        const IMAGE_T sigma,\n                        IMAGE_T* out)\n{\n    for (int tid = 0; tid < img_rows*img_cols; tid++) {\n\n    const int r = tid / img_cols;\n    const int c = tid % img_cols;\n\n    int size = (int)((IMAGE_T)3.0 * sigma);\n\n    const int b = (size - 1) / 2 + 1;\n    const int l = size / 3;\n    const int w = size;\n\n    const IMAGE_T w_i = (IMAGE_T)1.0 / (size * size);\n\n    const IMAGE_T tl = _integ(img, img_rows, img_cols, r - l, c - l, l, l); \n\n    const IMAGE_T br = _integ(img, img_rows, img_cols, r + 1, c + 1, l, l); \n\n    const IMAGE_T bl = _integ(img, img_rows, img_cols, r - l, c + 1, l, l); \n\n    const IMAGE_T tr = _integ(img, img_rows, img_cols, r + 1, c - l, l, l); \n\n\n    IMAGE_T dxy = bl + tr - tl - br;\n    dxy = -dxy * w_i;\n\n    IMAGE_T mid = _integ(img, img_rows, img_cols, r - l + 1, c - l, 2 * l - 1, w);  \n\n    IMAGE_T side = _integ(img, img_rows, img_cols, r - l + 1, c - l / 2, 2 * l - 1, l);  \n\n\n    IMAGE_T dxx = mid - (IMAGE_T)3 * side;\n    dxx = -dxx * w_i;\n\n    mid = _integ(img, img_rows, img_cols, r - l, c - b + 1, w, 2 * b - 1);\n    side = _integ(img, img_rows, img_cols, r - b / 2, c - b + 1, b, 2 * b - 1);\n\n    IMAGE_T dyy = mid - (IMAGE_T)3 * side;\n    dyy = -dyy * w_i;\n\n    out[tid] = (dxx * dyy - (IMAGE_T)0.81 * (dxy * dxy));\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int h = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int img_size = h * w;\n  size_t img_size_bytes = sizeof(float) * img_size;\n\n  float *input_img = (float*) malloc (img_size_bytes);\n  float *integral_img = (float*) malloc (img_size_bytes);\n  float *output_img = (float*) malloc (img_size_bytes);\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> norm_dist(0.f, 1.f);\n\n  for (int i = 0; i < img_size; i++) {\n    input_img[i] = norm_dist(rng);\n  }\n\n  printf(\"Integrating the input image may take a while...\\n\"); \n  for (int i = 0; i < h; i++) {\n    for (int j = 0; j < w; j++) {\n      IMAGE_T s = 0;\n      for (int y = 0; y <= i; y++)\n        for (int x = 0; x <= j; x++)\n          s += input_img[y * w + x];\n      integral_img[i * w + j] = s;\n    }\n  }\n\n  long time;\n\n    {\n    const IMAGE_T sigma = 4.0;\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      hessian_matrix_det(integral_img, h, w, sigma, output_img);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  double checksum = 0;\n  for (int i = 0; i < img_size; i++) {\n    checksum += output_img[i];\n  }\n\n  free(input_img);\n  free(integral_img);\n  free(output_img);\n\n  printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3 / repeat);\n  printf(\"Kernel checksum: %lf\\n\", checksum);\n\n  return 0;\n}"}}
{"kernel_name": "doh", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n\ntypedef float IMAGE_T;\ntypedef int INT_T;\n\n\n\n\ninline int _clip(const int x, const int low, const int high)\n{\n  if (x > high)\n    return high;\n  else if (x < low)\n    return low;\n  else\n    return x;\n}\n\n\n\n\n\ninline IMAGE_T _integ(const IMAGE_T * img,\n                      const INT_T img_rows,\n                      const INT_T img_cols,\n                      int r,\n                      int c,\n                      const int rl,\n                      const int cl)\n{\n  r = _clip(r, 0, img_rows - 1);\n  c = _clip(c, 0, img_cols - 1);\n\n  const int r2 = _clip(r + rl, 0, img_rows - 1);\n  const int c2 = _clip(c + cl, 0, img_cols - 1);\n\n  IMAGE_T ans = img[r * img_cols + c] + img[r2 * img_cols + c2] -\n                img[r * img_cols + c2] - img[r2 * img_cols + c];\n\n  return sycl::max((IMAGE_T)0, ans);\n}\n\n\n\n\n\nvoid hessian_matrix_det(const IMAGE_T* img,\n                        const INT_T img_rows,\n                        const INT_T img_cols,\n                        const IMAGE_T sigma,\n                        IMAGE_T* out,\n                        sycl::nd_item<1> item)\n{\n  int tid = item.get_global_id(0);\n\n  if (tid >= img_rows*img_cols) return;\n\n  const int r = tid / img_cols;\n  const int c = tid % img_cols;\n\n  int size = (int)((IMAGE_T)3.0 * sigma);\n\n  const int b = (size - 1) / 2 + 1;\n  const int l = size / 3;\n  const int w = size;\n\n  const IMAGE_T w_i = (IMAGE_T)1.0 / (size * size);\n\n  const IMAGE_T tl = _integ(img, img_rows, img_cols, r - l, c - l, l, l); \n\n  const IMAGE_T br = _integ(img, img_rows, img_cols, r + 1, c + 1, l, l); \n\n  const IMAGE_T bl = _integ(img, img_rows, img_cols, r - l, c + 1, l, l); \n\n  const IMAGE_T tr = _integ(img, img_rows, img_cols, r + 1, c - l, l, l); \n\n\n  IMAGE_T dxy = bl + tr - tl - br;\n  dxy = -dxy * w_i;\n\n  IMAGE_T mid = _integ(img, img_rows, img_cols, r - l + 1, c - l, 2 * l - 1, w);  \n\n  IMAGE_T side = _integ(img, img_rows, img_cols, r - l + 1, c - l / 2, 2 * l - 1, l);  \n\n\n  IMAGE_T dxx = mid - (IMAGE_T)3 * side;\n  dxx = -dxx * w_i;\n\n  mid = _integ(img, img_rows, img_cols, r - l, c - b + 1, w, 2 * b - 1);\n  side = _integ(img, img_rows, img_cols, r - b / 2, c - b + 1, b, 2 * b - 1);\n\n  IMAGE_T dyy = mid - (IMAGE_T)3 * side;\n  dyy = -dyy * w_i;\n\n  out[tid] = (dxx * dyy - (IMAGE_T)0.81 * (dxy * dxy));\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  int h = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int repeat = atoi(argv[3]);\n\n  int img_size = h * w;\n  size_t img_size_bytes = sizeof(float) * img_size;\n\n  float *input_img = (float*) malloc (img_size_bytes);\n  float *integral_img = (float*) malloc (img_size_bytes);\n  float *output_img = (float*) malloc (img_size_bytes);\n\n  std::default_random_engine rng (123);\n  std::normal_distribution<float> norm_dist(0.f, 1.f);\n\n  for (int i = 0; i < img_size; i++) {\n    input_img[i] = norm_dist(rng);\n  }\n\n  printf(\"Integrating the input image may take a while...\\n\"); \n  for (int i = 0; i < h; i++) {\n    for (int j = 0; j < w; j++) {\n      IMAGE_T s = 0;\n      for (int y = 0; y <= i; y++)\n        for (int x = 0; x <= j; x++)\n          s += input_img[y * w + x];\n      integral_img[i * w + j] = s;\n    }\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_input_img = sycl::malloc_device<float>(img_size, q);\n\n  q.memcpy(d_input_img, integral_img, img_size_bytes);\n\n  float *d_output_img = sycl::malloc_device<float>(img_size, q);\n\n  const IMAGE_T sigma = 4.0;\n\n  sycl::range<1> gws ((img_size + 255) / 256 * 256);\n  sycl::range<1> lws (256);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(\n        sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        hessian_matrix_det(d_input_img, h, w, sigma, d_output_img, item);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  q.memcpy(output_img, d_output_img, img_size_bytes).wait();\n\n  double checksum = 0;\n  for (int i = 0; i < img_size; i++) {\n    checksum += output_img[i];\n  }\n\n  sycl::free(d_input_img, q);\n  sycl::free(d_output_img, q);\n  free(input_img);\n  free(integral_img);\n  free(output_img);\n\n  printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3 / repeat);\n  printf(\"Kernel checksum: %lf\\n\", checksum);\n  return 0;\n}\n"}}
{"kernel_name": "gabor", "parallel_api": "cuda", "code": {"main.cu": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n#include \"reference.h\"\n\n__global__\nvoid gabor (\n  double *gabor_spatial,\n  const unsigned int height,\n  const unsigned int width,\n  const double center_y,\n  const double center_x,\n  const double ctheta,\n  const double stheta,\n  const double scale,\n  const double sx_2,\n  const double sy_2,\n  const double fx)\n{\n  int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n  double centered_x, centered_y, u, v;\n\n  if (x < width && y < height) {\n    centered_y = (double)y - center_y;\n    centered_x = (double)x - center_x;\n    u = ctheta * centered_x - stheta * centered_y;\n    v = ctheta * centered_y + stheta * centered_x;\n    gabor_spatial[y*width + x] = scale * exp(-0.5*(u*u/sx_2 + v*v/sy_2)) * cos(2.0*M_PI*fx*u);\n  }\n}\n\ndouble* generateGaborKernelDevice(\n  const int repeat,\n  const unsigned int height,\n  const unsigned int width,\n  const unsigned int par_T,\n  const double par_L,\n  const double theta)\n{\n  const double sx = (double)par_T / (2.0*sqrt(2.0*log(2.0)));\n  const double sy = par_L * sx;\n  const double sx_2 = sx*sx;\n  const double sy_2 = sy*sy;\n  const double fx = 1.0 / (double)par_T;\n  const double ctheta = cos(theta);\n  const double stheta = sin(theta);\n  const double center_y = (double)height / 2.0;\n  const double center_x = (double)width / 2.0;\n  const double scale = 1.0/(2.0*M_PI*sx*sy);\n\n  size_t image_size_bytes = height * width * sizeof(double);\n  double *h_gabor_spatial = (double*) malloc (image_size_bytes);\n\n  double *d_gabor_spatial;\n  cudaMalloc((void**)&d_gabor_spatial, image_size_bytes);\n\n  dim3 grids ((width+15)/16, (height+15)/16);\n  dim3 blocks (16, 16);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    gabor<<<grids, blocks>>>(d_gabor_spatial,\n                             height,\n                             width, \n                             center_y,\n                             center_x,\n                             ctheta,\n                             stheta,\n                             scale,\n                             sx_2,\n                             sy_2,\n                             fx);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_gabor_spatial, d_gabor_spatial, image_size_bytes, cudaMemcpyDeviceToHost);\n  cudaFree(d_gabor_spatial);\n  return h_gabor_spatial;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int height = atoi(argv[1]);\n  const int width = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const unsigned int par_T = 13;\n  const double par_L = 2.65;\n  const double theta = 45;\n\n  double *h_filter = generateGaborKernelHost(height, width, par_T, par_L, theta);\n  double *d_filter = generateGaborKernelDevice(repeat, height, width, par_T, par_L, theta);\n  \n  bool ok = true;\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(h_filter[i] - d_filter[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(h_filter);\n  free(d_filter);\n}\n"}}
{"kernel_name": "gabor", "parallel_api": "hip", "code": {"main.cu": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n__global__\nvoid gabor (\n  double *gabor_spatial,\n  const unsigned int height,\n  const unsigned int width,\n  const double center_y,\n  const double center_x,\n  const double ctheta,\n  const double stheta,\n  const double scale,\n  const double sx_2,\n  const double sy_2,\n  const double fx)\n{\n  int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n  double centered_x, centered_y, u, v;\n\n  if (x < width && y < height) {\n    centered_y = (double)y - center_y;\n    centered_x = (double)x - center_x;\n    u = ctheta * centered_x - stheta * centered_y;\n    v = ctheta * centered_y + stheta * centered_x;\n    gabor_spatial[y*width + x] = scale * exp(-0.5*(u*u/sx_2 + v*v/sy_2)) * cos(2.0*M_PI*fx*u);\n  }\n}\n\ndouble* generateGaborKernelDevice(\n  const int repeat,\n  const unsigned int height,\n  const unsigned int width,\n  const unsigned int par_T,\n  const double par_L,\n  const double theta)\n{\n  const double sx = (double)par_T / (2.0*sqrt(2.0*log(2.0)));\n  const double sy = par_L * sx;\n  const double sx_2 = sx*sx;\n  const double sy_2 = sy*sy;\n  const double fx = 1.0 / (double)par_T;\n  const double ctheta = cos(theta);\n  const double stheta = sin(theta);\n  const double center_y = (double)height / 2.0;\n  const double center_x = (double)width / 2.0;\n  const double scale = 1.0/(2.0*M_PI*sx*sy);\n\n  size_t image_size_bytes = height * width * sizeof(double);\n  double *h_gabor_spatial = (double*) malloc (image_size_bytes);\n\n  double *d_gabor_spatial;\n  hipMalloc((void**)&d_gabor_spatial, image_size_bytes);\n\n  dim3 grids ((width+15)/16, (height+15)/16);\n  dim3 blocks (16, 16);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(gabor, grids, blocks, 0, 0, d_gabor_spatial,\n                             height,\n                             width, \n                             center_y,\n                             center_x,\n                             ctheta,\n                             stheta,\n                             scale,\n                             sx_2,\n                             sy_2,\n                             fx);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_gabor_spatial, d_gabor_spatial, image_size_bytes, hipMemcpyDeviceToHost);\n  hipFree(d_gabor_spatial);\n  return h_gabor_spatial;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int height = atoi(argv[1]);\n  const int width = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const unsigned int par_T = 13;\n  const double par_L = 2.65;\n  const double theta = 45;\n\n  double *h_filter = generateGaborKernelHost(height, width, par_T, par_L, theta);\n  double *d_filter = generateGaborKernelDevice(repeat, height, width, par_T, par_L, theta);\n  \n  bool ok = true;\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(h_filter[i] - d_filter[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(h_filter);\n  free(d_filter);\n}\n"}}
{"kernel_name": "gabor", "parallel_api": "omp", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\ndouble* generateGaborKernelDevice(\n  const int repeat,\n  const unsigned int height,\n  const unsigned int width,\n  const unsigned int par_T,\n  const double par_L,\n  const double theta)\n{\n  const double sx = (double)par_T / (2.0*sqrt(2.0*log(2.0)));\n  const double sy = par_L * sx;\n  const double sx_2 = sx*sx;\n  const double sy_2 = sy*sy;\n  const double fx = 1.0 / (double)par_T;\n  const double ctheta = cos(theta);\n  const double stheta = sin(theta);\n  const double center_y = (double)height / 2.0;\n  const double center_x = (double)width / 2.0;\n  const double scale = 1.0/(2.0*M_PI*sx*sy);\n\n  size_t image_size_bytes = height * width * sizeof(double);\n  double *gabor_spatial = (double*) malloc (image_size_bytes);\n\n  #pragma omp target data map (from: gabor_spatial[0:height * width])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n      for (int y = 0; y < height; y++) {\n        for (int x = 0; x < width; x++) {\n          double centered_y = (double)y - center_y;\n          double centered_x = (double)x - center_x;\n          double u = ctheta * centered_x - stheta * centered_y;\n          double v = ctheta * centered_y + stheta * centered_x;\n          gabor_spatial[y*width + x] = scale * exp(-0.5*(u*u/sx_2 + v*v/sy_2)) * cos(2.0*M_PI*fx*u);\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n\n  return gabor_spatial;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int height = atoi(argv[1]);\n  const int width = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const unsigned int par_T = 13;\n  const double par_L = 2.65;\n  const double theta = 45;\n\n  double *h_filter = generateGaborKernelHost(height, width, par_T, par_L, theta);\n  double *d_filter = generateGaborKernelDevice(repeat, height, width, par_T, par_L, theta);\n  \n  bool ok = true;\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(h_filter[i] - d_filter[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(h_filter);\n  free(d_filter);\n}\n"}}
{"kernel_name": "gabor", "parallel_api": "serial", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include \"reference.h\"\n\ndouble* generateGaborKernelDevice(\n  const int repeat,\n  const unsigned int height,\n  const unsigned int width,\n  const unsigned int par_T,\n  const double par_L,\n  const double theta)\n{\n  const double sx = (double)par_T / (2.0*sqrt(2.0*log(2.0)));\n  const double sy = par_L * sx;\n  const double sx_2 = sx*sx;\n  const double sy_2 = sy*sy;\n  const double fx = 1.0 / (double)par_T;\n  const double ctheta = cos(theta);\n  const double stheta = sin(theta);\n  const double center_y = (double)height / 2.0;\n  const double center_x = (double)width / 2.0;\n  const double scale = 1.0/(2.0*M_PI*sx*sy);\n\n  size_t image_size_bytes = height * width * sizeof(double);\n  double *gabor_spatial = (double*) malloc (image_size_bytes);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n            for (int y = 0; y < height; y++) {\n        for (int x = 0; x < width; x++) {\n          double centered_y = (double)y - center_y;\n          double centered_x = (double)x - center_x;\n          double u = ctheta * centered_x - stheta * centered_y;\n          double v = ctheta * centered_y + stheta * centered_x;\n          gabor_spatial[y*width + x] = scale * exp(-0.5*(u*u/sx_2 + v*v/sy_2)) * cos(2.0*M_PI*fx*u);\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n\n  return gabor_spatial;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int height = atoi(argv[1]);\n  const int width = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const unsigned int par_T = 13;\n  const double par_L = 2.65;\n  const double theta = 45;\n\n  double *h_filter = generateGaborKernelHost(height, width, par_T, par_L, theta);\n  double *d_filter = generateGaborKernelDevice(repeat, height, width, par_T, par_L, theta);\n  \n  bool ok = true;\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(h_filter[i] - d_filter[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(h_filter);\n  free(d_filter);\n}"}}
{"kernel_name": "gabor", "parallel_api": "sycl", "code": {"main.cpp": "#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nvoid gabor (\n  sycl::nd_item<2> &item,\n  double *gabor_spatial,\n  const unsigned int height,\n  const unsigned int width,\n  const double center_y,\n  const double center_x,\n  const double ctheta,\n  const double stheta,\n  const double scale,\n  const double sx_2,\n  const double sy_2,\n  const double fx)\n{\n  int x = item.get_global_id(1);\n  int y = item.get_global_id(0);\n\n  double centered_x, centered_y, u, v;\n\n  if (x < width && y < height) {\n    centered_y = (double)y - center_y;\n    centered_x = (double)x - center_x;\n    u = ctheta * centered_x - stheta * centered_y;\n    v = ctheta * centered_y + stheta * centered_x;\n    gabor_spatial[y*width + x] = scale * sycl::exp(-0.5*(u*u/sx_2 + v*v/sy_2)) *\n                                 sycl::cos(2.0*M_PI*fx*u);\n  }\n}\n\ndouble* generateGaborKernelDevice(\n  const int repeat,\n  const unsigned int height,\n  const unsigned int width,\n  const unsigned int par_T,\n  const double par_L,\n  const double theta)\n{\n  const double sx = (double)par_T / (2.0*sqrt(2.0*log(2.0)));\n  const double sy = par_L * sx;\n  const double sx_2 = sx*sx;\n  const double sy_2 = sy*sy;\n  const double fx = 1.0 / (double)par_T;\n  const double ctheta = cos(theta);\n  const double stheta = sin(theta);\n  const double center_y = (double)height / 2.0;\n  const double center_x = (double)width / 2.0;\n  const double scale = 1.0/(2.0*M_PI*sx*sy);\n\n  size_t image_size_bytes = height * width * sizeof(double);\n  double *h_gabor_spatial = (double*) malloc (image_size_bytes);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double *d_gabor_spatial = sycl::malloc_device<double>(height * width, q);\n  q.memcpy(d_gabor_spatial, h_gabor_spatial, image_size_bytes);\n\n  sycl::range<2> gws ((height+15)/16*16, (width+15)/16*16);\n  sycl::range<2> lws (16, 16);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class image_process>(\n         sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n         gabor(item,\n               d_gabor_spatial,\n               height,\n               width, \n               center_y,\n               center_x,\n               ctheta,\n               stheta,\n               scale,\n               sx_2,\n               sy_2,\n               fx);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(h_gabor_spatial, d_gabor_spatial, image_size_bytes).wait();\n  sycl::free(d_gabor_spatial, q);\n\n  return h_gabor_spatial;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <height> <width> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int height = atoi(argv[1]);\n  const int width = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const unsigned int par_T = 13;\n  const double par_L = 2.65;\n  const double theta = 45;\n\n  double *h_filter = generateGaborKernelHost(height, width, par_T, par_L, theta);\n  double *d_filter = generateGaborKernelDevice(repeat, height, width, par_T, par_L, theta);\n  \n  bool ok = true;\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(h_filter[i] - d_filter[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  free(h_filter);\n  free(d_filter);\n}\n"}}
{"kernel_name": "mandelbrot", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n#include \"common.hpp\"\n#include \"mandel.hpp\"\n\nusing namespace std;\n\nvoid Execute() {\n  \n\n  MandelParallel m_par(row_size, col_size, max_iterations);\n  MandelSerial m_ser(row_size, col_size, max_iterations);\n\n  \n\n  m_par.Evaluate();\n\n  double kernel_time = 0;\n\n  \n\n\n  common::MyTimer t_par;\n\n  for (int i = 0; i < repetitions; ++i) \n    kernel_time += m_par.Evaluate();\n\n  common::Duration parallel_time = t_par.elapsed();\n\n  \n\n  m_par.Print();\n\n  \n\n  common::MyTimer t_ser;\n  m_ser.Evaluate();\n  common::Duration serial_time = t_ser.elapsed();\n\n  \n\n  cout << std::setw(20) << \"Serial time: \" << serial_time.count() << \" s\\n\";\n  cout << std::setw(20) << \"Average parallel time: \"\n                        << (parallel_time / repetitions).count() * 1e3 << \" ms\\n\";\n  cout << std::setw(20) << \"Average kernel execution time: \"\n                        << kernel_time / repetitions * 1e3 << \" ms\\n\";\n\n  \n\n  m_par.Verify(m_ser);\n}\n\nvoid Usage(string program_name) {\n  \n\n  cout << \" Incorrect parameters\\n\";\n  cout << \" Usage: \";\n  cout << program_name << \" <repeat>\\n\\n\";\n  exit(-1);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    Usage(argv[0]);\n  }\n\n  try {\n    repetitions = atoi(argv[1]);\n    Execute();\n  } catch (...) {\n    cout << \"Failure\\n\";\n    terminate();\n  }\n  cout << \"Success\\n\";\n  return 0;\n}\n"}}
{"kernel_name": "mandelbrot", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n#include \"common.hpp\"\n#include \"mandel.hpp\"\n\nusing namespace std;\n\nvoid Execute() {\n  \n\n  MandelParallel m_par(row_size, col_size, max_iterations);\n  MandelSerial m_ser(row_size, col_size, max_iterations);\n\n  \n\n  m_par.Evaluate();\n\n  double kernel_time = 0;\n\n  \n\n\n  common::MyTimer t_par;\n\n  for (int i = 0; i < repetitions; ++i) \n    kernel_time += m_par.Evaluate();\n\n  common::Duration parallel_time = t_par.elapsed();\n\n  \n\n  m_par.Print();\n\n  \n\n  common::MyTimer t_ser;\n  m_ser.Evaluate();\n  common::Duration serial_time = t_ser.elapsed();\n\n  \n\n  cout << std::setw(20) << \"Serial time: \" << serial_time.count() << \" s\\n\";\n  cout << std::setw(20) << \"Average parallel time: \"\n                        << (parallel_time / repetitions).count() * 1e3 << \" ms\\n\";\n  cout << std::setw(20) << \"Average kernel execution time: \"\n                        << kernel_time / repetitions * 1e3 << \" ms\\n\";\n\n  \n\n  m_par.Verify(m_ser);\n}\n\nvoid Usage(string program_name) {\n  \n\n  cout << \" Incorrect parameters\\n\";\n  cout << \" Usage: \";\n  cout << program_name << \" <repeat>\\n\\n\";\n  exit(-1);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    Usage(argv[0]);\n  }\n\n  try {\n    repetitions = atoi(argv[1]);\n    Execute();\n  } catch (...) {\n    cout << \"Failure\\n\";\n    terminate();\n  }\n  cout << \"Success\\n\";\n  return 0;\n}\n"}}
{"kernel_name": "mandelbrot", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include \"util.hpp\"\n#include \"mandel.hpp\"\n\nvoid Execute() {\n  \n\n  MandelParallel m_par(row_size, col_size, max_iterations);\n  MandelSerial m_ser(row_size, col_size, max_iterations);\n\n  \n\n  m_par.Evaluate();\n\n  double kernel_time = 0;\n\n  \n\n  common::MyTimer t_par;\n\n  for (int i = 0; i < repetitions; ++i) \n    kernel_time += m_par.Evaluate();\n\n  common::Duration parallel_time = t_par.elapsed();\n\n  \n\n  m_par.Print();\n\n  \n\n  common::MyTimer t_ser;\n  m_ser.Evaluate();\n  common::Duration serial_time = t_ser.elapsed();\n\n  \n\n  std::cout << std::setw(20) << \"serial time: \" << serial_time.count() << \"s\\n\";\n  std::cout << std::setw(20) << \"Average parallel time: \"\n                        << (parallel_time / repetitions).count() * 1e3 << \" ms\\n\";\n  std::cout << std::setw(20) << \"Average kernel execution time: \"\n                        << kernel_time / repetitions * 1e3 << \" ms\\n\";\n\n  \n\n  m_par.Verify(m_ser);\n}\n\nvoid Usage(std::string program_name) {\n  \n\n  std::cout << \" Incorrect parameters\\n\";\n  std::cout << \" Usage: \";\n  std::cout << program_name << \" <repeat>\\n\\n\";\n  exit(-1);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    Usage(argv[0]);\n  }\n\n  try {\n    repetitions = atoi(argv[1]);\n    Execute();\n  } catch (...) {\n    std::cout << \"Failure\\n\";\n    std::terminate();\n  }\n  std::cout << \"Success\\n\";\n  return 0;\n}\n"}}
{"kernel_name": "mandelbrot", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include \"util.hpp\"\n#include \"mandel.hpp\"\n\nvoid Execute() {\n  \n\n  MandelParallel m_par(row_size, col_size, max_iterations);\n  MandelSerial m_ser(row_size, col_size, max_iterations);\n\n  \n\n  m_par.Evaluate();\n\n  double kernel_time = 0;\n\n  \n\n  common::MyTimer t_par;\n\n  for (int i = 0; i < repetitions; ++i) \n    kernel_time += m_par.Evaluate();\n\n  common::Duration parallel_time = t_par.elapsed();\n\n  \n\n  m_par.Print();\n\n  \n\n  common::MyTimer t_ser;\n  m_ser.Evaluate();\n  common::Duration serial_time = t_ser.elapsed();\n\n  \n\n  std::cout << std::setw(20) << \"serial time: \" << serial_time.count() << \"s\\n\";\n  std::cout << std::setw(20) << \"Average parallel time: \"\n                        << (parallel_time / repetitions).count() * 1e3 << \" ms\\n\";\n  std::cout << std::setw(20) << \"Average kernel execution time: \"\n                        << kernel_time / repetitions * 1e3 << \" ms\\n\";\n\n  \n\n  m_par.Verify(m_ser);\n}\n\nvoid Usage(std::string program_name) {\n  \n\n  std::cout << \" Incorrect parameters\\n\";\n  std::cout << \" Usage: \";\n  std::cout << program_name << \" <repeat>\\n\\n\";\n  exit(-1);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    Usage(argv[0]);\n  }\n\n  try {\n    repetitions = atoi(argv[1]);\n    Execute();\n  } catch (...) {\n    std::cout << \"Failure\\n\";\n    std::terminate();\n  }\n  std::cout << \"Success\\n\";\n  return 0;\n}"}}
{"kernel_name": "mandelbrot", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include \"util.hpp\"\n#include \"mandel.hpp\"\n\nvoid Execute(sycl::queue &q) {\n  \n\n  MandelParallel m_par(row_size, col_size, max_iterations);\n  MandelSerial m_ser(row_size, col_size, max_iterations);\n\n  \n\n  m_par.Evaluate(q);\n\n  double kernel_time = 0;\n\n  \n\n  \n\n  common::MyTimer t_par;\n\n  for (int i = 0; i < repetitions; ++i)\n    kernel_time += m_par.Evaluate(q);\n\n  common::Duration parallel_time = t_par.elapsed();\n\n  \n\n  m_par.Print();\n\n  \n\n  common::MyTimer t_ser;\n  m_ser.Evaluate();\n  common::Duration serial_time = t_ser.elapsed();\n\n  \n\n  std::cout << std::setw(20) << \"Serial time: \" << serial_time.count() << \" s\\n\";\n  std::cout << std::setw(20) << \"Average parallel time: \"\n                             << (parallel_time / repetitions).count() * 1e3 << \" ms\\n\";\n  std::cout << std::setw(20) << \"Average kernel execution time: \"\n                             << kernel_time / repetitions * 1e3 << \" ms\\n\";\n\n  \n\n  m_par.Verify(m_ser);\n}\n\nvoid Usage(std::string program_name) {\n  \n\n  std::cout << \" Incorrect parameters\\n\";\n  std::cout << \" Usage: \";\n  std::cout << program_name << \" <repeat>\\n\\n\";\n  exit(-1);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    Usage(argv[0]);\n  }\n\n  try {\n#ifdef USE_GPU\n    sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n    sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n    repetitions = atoi(argv[1]);\n    Execute(q);\n  } catch (...) {\n    std::cout << \"Failure\\n\";\n    std::terminate();\n  }\n  std::cout << \"Success\\n\";\n  return 0;\n}\n"}}
{"kernel_name": "match", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include <cstring>\n#include <cmath>\n#include <iostream>\n#include <vector>\n#include <memory>  \n\n#include <chrono>\n#include <cuda.h>\n\n#define NPTS (2048*8)\n#define NDIM 128\n\n#define M1W  128\n#define M2W   16\n#define M2H   16\n#define M5W   16\n#define M5H   16\n#define M5R    4\n#define M7W   32\n#define M7H   32\n#define M7R    4\n\n\n\nvoid MatchC1(float *h_pts1, float *h_pts2, float *h_score, int *h_index)\n{\n  std::memset(h_score, 0, sizeof(float)*NPTS);\n  for (int p1=0;p1<NPTS;p1++) {\n    for (int p2=0;p2<NPTS;p2++) {\n      float score = 0.0f;\n      for (int d=0;d<NDIM;d++)\n\tscore += h_pts1[p1*NDIM + d]*h_pts2[p2*NDIM + d];\n      if (score>h_score[p1]) {\n\th_score[p1] = score;\n\th_index[p1] = p2;\n      }\n    }\n  }\n}\n\n\n\nvoid CheckMatches(int *h_index, int *h_index2, float *h_score, float *h_score2)\n{\n  int ndiff = 0;\n  for (int i=0;i<NPTS;i++) {\n    ndiff += (h_index[i] != h_index2[i]);\n#ifdef DEBUG\n    if (h_index[i] != h_index2[i])\n      std::cout << \"  \" << i << \" \" << h_index[i] << \" \" << h_index2[i] << \" \" \n                << h_score[i] << \" \" << h_score2[i] << std::endl;\n#endif\n  }\n\n  std::cout << \"Number of incorrect matches: \" << ndiff << std::endl;\n}\n      \n\n__global__ void Match1(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  int p1 = threadIdx.x + M1W*blockIdx.x;\n  float max_score = 0.0f;\n  int index = -1;\n  \n  for (int p2=0;p2<NPTS;p2++) {\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++)\n      score += d_pts1[p1*NDIM + d]*d_pts2[p2*NDIM + d];\n    if (score>max_score) {\n      max_score = score;\n      index = p2;\n    }\n  }\n  \n  d_score[p1] = max_score;\n  d_index[p1] = index;\n}\n\n__global__ void Match2(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float buffer1[M2W*NDIM];  \n  __shared__ float buffer2[M2H*NDIM];  \n  __shared__ float scores[M2W*M2H];    \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*blockIdx.x;\n  if (ty<M2W)\n    for (int d=tx;d<NDIM;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*NDIM + d] = d_pts1[(bp1 + j)*NDIM + d];   \n  __syncthreads();\n  \n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM;d+=M2W)\n      buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d]; \n    __syncthreads();\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++) \n      score += buffer1[tx*NDIM + d]*buffer2[ty*NDIM + d];   \n    scores[idx] = score;\n    __syncthreads();\n    \n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n  \n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\n__global__ void Match3(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float buffer1[M2W*(NDIM + 1)]; \n  __shared__ float buffer2[M2H*NDIM];\n  __shared__ float scores[M2W*M2H];\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*blockIdx.x;\n  if (ty<M2W)\n    for (int d=tx;d<NDIM;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*(NDIM + 1) + d] = d_pts1[(bp1 + j)*NDIM + d]; \n  __syncthreads();\n  \n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM;d+=M2W)\n      buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d];\n    __syncthreads();\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++) \n      score += buffer1[tx*(NDIM + 1) + d]*buffer2[ty*NDIM + d]; \n    scores[idx] = score;\n    __syncthreads();\n    \n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n  \n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\n__global__ void Match4(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M2W*(NDIM/4 + 1)];  \n  __shared__ float4 buffer2[M2H*NDIM/4];        \n  __shared__ float scores[M2W*M2H];\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*blockIdx.x;\n  if (ty<M2W)\n    for (int d=tx;d<NDIM/4;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d]; \n  __syncthreads();\n  \n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM/4;d+=M2W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d]; \n    __syncthreads();\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1 = buffer1[tx*(NDIM/4 + 1) + d]; \n      float4 v2 = buffer2[ty*(NDIM/4) + d];     \n      score += v1.x*v2.x; score += v1.y*v2.y;\n      score += v1.z*v2.z; score += v1.w*v2.w;\n    }\n    scores[idx] = score;\n    __syncthreads();\n    \n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n  \n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match5(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M5W*(NDIM/4 + 1)]; \n  __shared__ float4 buffer2[M5H*NDIM/4];       \n  __shared__ float scores[M5W*M5H];\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M5W*blockIdx.x;\n  if (ty<M5W)\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      for (int j=ty;j<M5W;j+=M5H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n  __syncthreads();\n  \n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n    __syncthreads();\n\n    if (ty<M5H/M5R) {  \n      float score[M5R];                                    \n      for (int dy=0;dy<M5R;dy++)\n\tscore[dy] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n\tfor (int dy=0;dy<M5R;dy++) {\n\t  float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];    \n\t  score[dy] += v1.x*v2.x; score[dy] += v1.y*v2.y;\n\t  score[dy] += v1.z*v2.z; score[dy] += v1.w*v2.w;\n\t}\n      }\n      for (int dy=0;dy<M5R;dy++)\n\tscores[tx + M5W*(M5R*ty + dy)] = score[dy];\n    }\n    __syncthreads();\n    \n    if (ty==0) {\n      for (int i=0;i<M5H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M5W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\n__global__ void Match6(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M5W*(NDIM/4 + 1)]; \n  __shared__ float4 buffer2[M5H*NDIM/4];       \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M5W*blockIdx.x;\n  if (ty<M5W)\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      for (int j=ty;j<M5W;j+=M5H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n  \n  float max_score = 0.0f;\n  int index = -1;    \n  for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n    __syncthreads();\n\n    if (ty<M5H/M5R) {  \n      float score[M5R];                                    \n      for (int dy=0;dy<M5R;dy++)\n\tscore[dy] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n\tfor (int dy=0;dy<M5R;dy++) {\n\t  float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];    \n\t  score[dy] += v1.x*v2.x; score[dy] += v1.y*v2.y;\n\t  score[dy] += v1.z*v2.z; score[dy] += v1.w*v2.w;\n\t}\n      }\n      for (int dy=0;dy<M5R;dy++) {\n\tif (score[dy]>max_score) {   \n\t  max_score = score[dy];     \n\t  index = bp2 + M5R*ty + dy;               \n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M5W*M5H/M5R];\n  if (ty<M5H/M5R) {\n    scores[ty*M5W + tx] = max_score;  \n    indices[ty*M5W + tx] = index;     \n  }\n  __syncthreads();\n  \n  if (ty==0) {\n    max_score = scores[tx];\n    index = indices[tx];\n    for (int y=0;y<M5H/M5R;y++)\n      if (scores[y*M5W + tx]>max_score) {\n\tmax_score = scores[y*M5W + tx]; \n\tindex = indices[y*M5W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match7(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M7W*NDIM/4]; \n  __shared__ float4 buffer2[M7H*NDIM/4];       \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M7W*blockIdx.x;\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)      \n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n  \n  float max_score = 0.0f;\n  int index = -1;    \n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R)       \n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    __syncthreads();\n\n    float score[M7R];                                    \n    for (int dy=0;dy<M7R;dy++)\n      score[dy] = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1 = buffer1[tx*NDIM/4 + (d + tx)%(NDIM/4)];\n      for (int dy=0;dy<M7R;dy++) {\n\tfloat4 v2 = buffer2[(M7R*ty + dy)*(NDIM/4) + d];    \n\tscore[dy] += v1.x*v2.x;\n        score[dy] += v1.y*v2.y;\n\tscore[dy] += v1.z*v2.z;\n        score[dy] += v1.w*v2.w;\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      if (score[dy]>max_score) {   \n\tmax_score = score[dy];     \n\tindex = bp2 + M7R*ty + dy;               \n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  scores[ty*M7W + tx] = max_score;  \n  indices[ty*M7W + tx] = index;     \n  __syncthreads();\n  \n  if (ty==0) {\n    max_score = scores[tx];\n    index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx]; \n\tindex = indices[y*M7W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match8(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M7W*NDIM/4]; \n  __shared__ float4 buffer2[M7H*NDIM/4];       \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M7W*blockIdx.x;\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)     \n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n#define NRX 2\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R)       \n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    __syncthreads();\n\n    if (idx<M7W*M7H/M7R/NRX) {\n      float score[M7R][NRX];                                    \n      for (int dy=0;dy<M7R;dy++)\n\tfor (int i=0;i<NRX;i++)\n\t  score[dy][i] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1[NRX];\n\tfor (int i=0;i<NRX;i++) \n\t  v1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n\tfor (int dy=0;dy<M7R;dy++) {\n\t  float4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];    \n\t  for (int i=0;i<NRX;i++) {\n\t    score[dy][i] += v1[i].x*v2.x;\n\t    score[dy][i] += v1[i].y*v2.y;\n\t    score[dy][i] += v1[i].z*v2.z;\n\t    score[dy][i] += v1[i].w*v2.w;\n\t  }\n\t}\n      }\n      for (int dy=0;dy<M7R;dy++) {\n\tfor (int i=0;i<NRX;i++) {\n\t  if (score[dy][i]>max_score[i]) {\n\t    max_score[i] = score[dy][i];     \n\t    index[i] = bp2 + M7R*iy + dy;\n\t  }\n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  __syncthreads();\n  \n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx]; \n\tindex = indices[y*M7W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match9(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n#define NRX 2\n  __shared__ float4 buffer1[M7W*NDIM/4]; \n  __shared__ float4 buffer2[M7H*NDIM/4];       \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M7W*blockIdx.x;\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R/NRX)     \n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R/NRX)       \n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    __syncthreads();\n\n    float score[M7R][NRX];                                    \n    for (int dy=0;dy<M7R;dy++)\n      for (int i=0;i<NRX;i++)\n\tscore[dy][i] = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1[NRX];\n      for (int i=0;i<NRX;i++) \n\tv1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n      for (int dy=0;dy<M7R;dy++) {\n\tfloat4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];    \n\tfor (int i=0;i<NRX;i++) {\n\t  score[dy][i] += v1[i].x*v2.x;\n\t  score[dy][i] += v1[i].y*v2.y;\n\t  score[dy][i] += v1[i].z*v2.z;\n\t  score[dy][i] += v1[i].w*v2.w;\n\t}\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      for (int i=0;i<NRX;i++) {\n\tif (score[dy][i]>max_score[i]) {\n\t  max_score[i] = score[dy][i];     \n\t  index[i] = bp2 + M7R*iy + dy;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  __syncthreads();\n  \n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx]; \n\tindex = indices[y*M7W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match10(const float *__restrict d_pts1, \n                        const float *__restrict d_pts2,\n                              float *__restrict d_score,\n                                int *__restrict d_index)\n{\n#define NRX 2\n#define NUM (NRX*M7R)                       \n\n  __shared__ float4 buffer1[M7W*NDIM/4];    \n\n  __shared__ float4 buffer2[M7H*NUM];       \n\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M7W*blockIdx.x;\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)     \n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    float score[M7R][NRX];                                    \n    for (int dy=0;dy<M7R;dy++)\n      for (int i=0;i<NRX;i++)\n\tscore[dy][i] = 0.0f;\n\n    int d = (idx%NUM);\n    int j = (idx/NUM);\n    buffer2[j*NUM + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    __syncthreads();\n    for (int dp=0;dp<NDIM/4;dp+=NUM) {\n      float4 temp;\n      if (dp<(NDIM/4-NUM))\n\ttemp = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + dp + d + NUM];\n\n      if (idx<M7W*M7H/M7R/NRX) {\n\tfor (int d=0;d<NUM;d++) {\n\t  float4 v1[NRX];\n#pragma unroll\n\t  for (int i=0;i<NRX;i++) \n\t    v1[i] = buffer1[(((M7W/NRX)*i + ix)<<5) + ((dp + d + (M7W/NRX)*i + ix)&31)];\n\t  \n\n#pragma unroll\n\t  for (int dy=0;dy<M7R;dy++) {\n\t    float4 v2 = buffer2[(M7R*iy + dy)*NUM + d];    \n#pragma unroll\n\t    for (int i=0;i<NRX;i++) {\n\t      score[dy][i] += v1[i].x*v2.x;\n\t      score[dy][i] += v1[i].y*v2.y;\n\t      score[dy][i] += v1[i].z*v2.z;\n\t      score[dy][i] += v1[i].w*v2.w;\n\t    }\n\t  }\n\t}\n      }\n      __syncthreads();\n\n      if (dp<(NDIM/4-NUM)) {\n\tbuffer2[j*NUM + d] = temp;\n\t__syncthreads();\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      for (int i=0;i<NRX;i++) {\n\tif (score[dy][i]>max_score[i]) {\n\t  max_score[i] = score[dy][i];     \n\t  index[i] = bp2 + M7R*iy + dy;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  __syncthreads();\n  \n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx]; \n\tindex = indices[y*M7W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n \n  size_t space = sizeof(float)*NPTS*NDIM*2 + 8;\n  std::vector<float> data(NPTS*NDIM*2 + 8);\n  void *ptr = (void*)&data[0];\n  float *h_pts1 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  ptr = (void*)&data[NPTS*NDIM];\n  float *h_pts2 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  std::vector<int> h_index(NPTS);\n  std::vector<float> h_score(NPTS);\n  std::vector<int> h_index2(NPTS);\n  std::vector<float> h_score2(NPTS);\n  \n  float *d_pts1, *d_pts2, *d_score;\n  int *d_index;\n  std::cout << std::endl;\n  int psize = sizeof(float)*NPTS;\n  std::cout << \"Data size:   \" << 2.0*psize*NDIM/1024/1024 << \" MB\" << std::endl;\n\n  cudaMalloc((void **)&d_pts1, psize*NDIM);\n  cudaMalloc((void **)&d_pts2, psize*NDIM);\n  cudaMalloc((void **)&d_index, psize);\n  cudaMalloc((void **)&d_score, psize);\n\n  for (int i=0;i<NPTS;i++) {\n    float sum1 = 0.0f, sum2 = 0.0f;\n    for (int d=0;d<NDIM;d++) {\n      sum1 += h_pts1[i*NDIM + d] = (float)rand()/RAND_MAX;\n      sum2 += h_pts2[i*NDIM + d] = (float)rand()/RAND_MAX;\n    }\n    sum1 = sqrt(NDIM)/sum1;\n    sum2 = sqrt(NDIM)/sum2;\n    for (int d=0;d<NDIM;d++) {\n      h_pts1[i*NDIM + d] *= sum1;\n      h_pts2[i*NDIM + d] *= sum2;\n    }\n  }\n\n  auto start = std::chrono::high_resolution_clock::now();\n  MatchC1(h_pts1, h_pts2, h_score.data(), h_index.data());\n  auto end = std::chrono::high_resolution_clock::now();\n  auto elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  auto delay = elapsed_seconds.count() * 1000;\n  std::cout << \"MatchCPU1:   \" << elapsed_seconds.count() * 1000 << \" ms  \"\n            << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n\n  cudaMemcpy(d_pts1, h_pts1, psize*NDIM, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_pts2, h_pts2, psize*NDIM, cudaMemcpyHostToDevice);\n  \n  dim3 blocks, threads;\n  blocks = dim3(NPTS/M1W);\n  threads = dim3(M1W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match1<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU1:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M2W);\n  threads = dim3(M2W, M2H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match2<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU2:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M2W);\n  threads = dim3(M2W, M2H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match3<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU3:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n  \n  blocks = dim3(NPTS/M2W);\n  threads = dim3(M2W, M2H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match4<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU4:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n  \n  blocks = dim3(NPTS/M5W);\n  threads = dim3(M5W, M5H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match5<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU5:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n  \n  blocks = dim3(NPTS/M5W);\n  threads = dim3(M5W, M5H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match6<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU6:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M7W);\n  threads = dim3(M7W, M7H/M7R);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match7<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU7:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M7W);\n  threads = dim3(M7W, M7H/M7R);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match8<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU8:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M7W);\n  threads = dim3(M7W, M7H/M7R/2);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match9<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU9:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n\n  blocks = dim3(NPTS/M7W);\n  threads = dim3(M7W, M7H/M7R);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    Match10<<<blocks,threads>>>(d_pts1, d_pts2, d_score, d_index);\n  cudaDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU10:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  cudaMemcpy(h_index2.data(), d_index, psize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(h_score2.data(), d_score, psize, cudaMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  cudaFree(d_pts1);\n  cudaFree(d_pts2);\n  cudaFree(d_index);\n  cudaFree(d_score);\n\n  return 0;\n}\n"}}
{"kernel_name": "match", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include <cstring>\n#include <cmath>\n#include <iostream>\n#include <vector>\n#include <memory>  \n\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define NPTS (2048*8)\n#define NDIM 128\n\n#define M1W  128\n#define M2W   16\n#define M2H   16\n#define M5W   16\n#define M5H   16\n#define M5R    4\n#define M7W   32\n#define M7H   32\n#define M7R    4\n\n\n\nvoid MatchC1(float *h_pts1, float *h_pts2, float *h_score, int *h_index)\n{\n  std::memset(h_score, 0, sizeof(float)*NPTS);\n  for (int p1=0;p1<NPTS;p1++) {\n    for (int p2=0;p2<NPTS;p2++) {\n      float score = 0.0f;\n      for (int d=0;d<NDIM;d++)\n\tscore += h_pts1[p1*NDIM + d]*h_pts2[p2*NDIM + d];\n      if (score>h_score[p1]) {\n\th_score[p1] = score;\n\th_index[p1] = p2;\n      }\n    }\n  }\n}\n\n\n\nvoid CheckMatches(int *h_index, int *h_index2, float *h_score, float *h_score2)\n{\n  int ndiff = 0;\n  for (int i=0;i<NPTS;i++) {\n    ndiff += (h_index[i] != h_index2[i]);\n#ifdef DEBUG\n    if (h_index[i] != h_index2[i])\n      std::cout << \"  \" << i << \" \" << h_index[i] << \" \" << h_index2[i] << \" \" \n                << h_score[i] << \" \" << h_score2[i] << std::endl;\n#endif\n  }\n  std::cout << \"Number of incorrect matches: \" << ndiff << std::endl;\n}\n      \n\n__global__ void Match1(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  int p1 = threadIdx.x + M1W*blockIdx.x;\n  float max_score = 0.0f;\n  int index = -1;\n  \n  for (int p2=0;p2<NPTS;p2++) {\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++)\n      score += d_pts1[p1*NDIM + d]*d_pts2[p2*NDIM + d];\n    if (score>max_score) {\n      max_score = score;\n      index = p2;\n    }\n  }\n  \n  d_score[p1] = max_score;\n  d_index[p1] = index;\n}\n\n__global__ void Match2(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float buffer1[M2W*NDIM];  \n  __shared__ float buffer2[M2H*NDIM];  \n  __shared__ float scores[M2W*M2H];    \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*blockIdx.x;\n  if (ty<M2W)\n    for (int d=tx;d<NDIM;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*NDIM + d] = d_pts1[(bp1 + j)*NDIM + d];   \n  __syncthreads();\n  \n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM;d+=M2W)\n      buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d]; \n    __syncthreads();\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++) \n      score += buffer1[tx*NDIM + d]*buffer2[ty*NDIM + d];   \n    scores[idx] = score;\n    __syncthreads();\n    \n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n  \n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\n__global__ void Match3(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float buffer1[M2W*(NDIM + 1)]; \n  __shared__ float buffer2[M2H*NDIM];\n  __shared__ float scores[M2W*M2H];\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*blockIdx.x;\n  if (ty<M2W)\n    for (int d=tx;d<NDIM;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*(NDIM + 1) + d] = d_pts1[(bp1 + j)*NDIM + d]; \n  __syncthreads();\n  \n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM;d+=M2W)\n      buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d];\n    __syncthreads();\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++) \n      score += buffer1[tx*(NDIM + 1) + d]*buffer2[ty*NDIM + d]; \n    scores[idx] = score;\n    __syncthreads();\n    \n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n  \n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\n__global__ void Match4(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M2W*(NDIM/4 + 1)];  \n  __shared__ float4 buffer2[M2H*NDIM/4];        \n  __shared__ float scores[M2W*M2H];\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*blockIdx.x;\n  if (ty<M2W)\n    for (int d=tx;d<NDIM/4;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d]; \n  __syncthreads();\n  \n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM/4;d+=M2W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d]; \n    __syncthreads();\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1 = buffer1[tx*(NDIM/4 + 1) + d]; \n      float4 v2 = buffer2[ty*(NDIM/4) + d];     \n      score += v1.x*v2.x; score += v1.y*v2.y;\n      score += v1.z*v2.z; score += v1.w*v2.w;\n    }\n    scores[idx] = score;\n    __syncthreads();\n    \n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n  \n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match5(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M5W*(NDIM/4 + 1)]; \n  __shared__ float4 buffer2[M5H*NDIM/4];       \n  __shared__ float scores[M5W*M5H];\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M5W*blockIdx.x;\n  if (ty<M5W)\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      for (int j=ty;j<M5W;j+=M5H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n  __syncthreads();\n  \n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n    __syncthreads();\n\n    if (ty<M5H/M5R) {  \n      float score[M5R];                                    \n      for (int dy=0;dy<M5R;dy++)\n\tscore[dy] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n\tfor (int dy=0;dy<M5R;dy++) {\n\t  float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];    \n\t  score[dy] += v1.x*v2.x; score[dy] += v1.y*v2.y;\n\t  score[dy] += v1.z*v2.z; score[dy] += v1.w*v2.w;\n\t}\n      }\n      for (int dy=0;dy<M5R;dy++)\n\tscores[tx + M5W*(M5R*ty + dy)] = score[dy];\n    }\n    __syncthreads();\n    \n    if (ty==0) {\n      for (int i=0;i<M5H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M5W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\n__global__ void Match6(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M5W*(NDIM/4 + 1)]; \n  __shared__ float4 buffer2[M5H*NDIM/4];       \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M5W*blockIdx.x;\n  if (ty<M5W)\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      for (int j=ty;j<M5W;j+=M5H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n  \n  float max_score = 0.0f;\n  int index = -1;    \n  for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n    __syncthreads();\n\n    if (ty<M5H/M5R) {  \n      float score[M5R];                                    \n      for (int dy=0;dy<M5R;dy++)\n\tscore[dy] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n\tfor (int dy=0;dy<M5R;dy++) {\n\t  float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];    \n\t  score[dy] += v1.x*v2.x; score[dy] += v1.y*v2.y;\n\t  score[dy] += v1.z*v2.z; score[dy] += v1.w*v2.w;\n\t}\n      }\n      for (int dy=0;dy<M5R;dy++) {\n\tif (score[dy]>max_score) {   \n\t  max_score = score[dy];     \n\t  index = bp2 + M5R*ty + dy;               \n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M5W*M5H/M5R];\n  if (ty<M5H/M5R) {\n    scores[ty*M5W + tx] = max_score;  \n    indices[ty*M5W + tx] = index;     \n  }\n  __syncthreads();\n  \n  if (ty==0) {\n    max_score = scores[tx];\n    index = indices[tx];\n    for (int y=0;y<M5H/M5R;y++)\n      if (scores[y*M5W + tx]>max_score) {\n\tmax_score = scores[y*M5W + tx]; \n\tindex = indices[y*M5W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match7(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M7W*NDIM/4]; \n  __shared__ float4 buffer2[M7H*NDIM/4];       \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M7W*blockIdx.x;\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)      \n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n  \n  float max_score = 0.0f;\n  int index = -1;    \n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R)       \n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    __syncthreads();\n\n    float score[M7R];                                    \n    for (int dy=0;dy<M7R;dy++)\n      score[dy] = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1 = buffer1[tx*NDIM/4 + (d + tx)%(NDIM/4)];\n      for (int dy=0;dy<M7R;dy++) {\n\tfloat4 v2 = buffer2[(M7R*ty + dy)*(NDIM/4) + d];    \n\tscore[dy] += v1.x*v2.x;\n        score[dy] += v1.y*v2.y;\n\tscore[dy] += v1.z*v2.z;\n        score[dy] += v1.w*v2.w;\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      if (score[dy]>max_score) {   \n\tmax_score = score[dy];     \n\tindex = bp2 + M7R*ty + dy;               \n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  scores[ty*M7W + tx] = max_score;  \n  indices[ty*M7W + tx] = index;     \n  __syncthreads();\n  \n  if (ty==0) {\n    max_score = scores[tx];\n    index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx]; \n\tindex = indices[y*M7W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match8(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n  __shared__ float4 buffer1[M7W*NDIM/4]; \n  __shared__ float4 buffer2[M7H*NDIM/4];       \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M7W*blockIdx.x;\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)     \n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n#define NRX 2\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R)       \n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    __syncthreads();\n\n    if (idx<M7W*M7H/M7R/NRX) {\n      float score[M7R][NRX];                                    \n      for (int dy=0;dy<M7R;dy++)\n\tfor (int i=0;i<NRX;i++)\n\t  score[dy][i] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1[NRX];\n\tfor (int i=0;i<NRX;i++) \n\t  v1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n\tfor (int dy=0;dy<M7R;dy++) {\n\t  float4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];    \n\t  for (int i=0;i<NRX;i++) {\n\t    score[dy][i] += v1[i].x*v2.x;\n\t    score[dy][i] += v1[i].y*v2.y;\n\t    score[dy][i] += v1[i].z*v2.z;\n\t    score[dy][i] += v1[i].w*v2.w;\n\t  }\n\t}\n      }\n      for (int dy=0;dy<M7R;dy++) {\n\tfor (int i=0;i<NRX;i++) {\n\t  if (score[dy][i]>max_score[i]) {\n\t    max_score[i] = score[dy][i];     \n\t    index[i] = bp2 + M7R*iy + dy;\n\t  }\n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  __syncthreads();\n  \n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx]; \n\tindex = indices[y*M7W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match9(const float *__restrict d_pts1, \n                       const float *__restrict d_pts2,\n                             float *__restrict d_score,\n                               int *__restrict d_index)\n{\n#define NRX 2\n  __shared__ float4 buffer1[M7W*NDIM/4]; \n  __shared__ float4 buffer2[M7H*NDIM/4];       \n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M7W*blockIdx.x;\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R/NRX)     \n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R/NRX)       \n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    __syncthreads();\n\n    float score[M7R][NRX];                                    \n    for (int dy=0;dy<M7R;dy++)\n      for (int i=0;i<NRX;i++)\n\tscore[dy][i] = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1[NRX];\n      for (int i=0;i<NRX;i++) \n\tv1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n      for (int dy=0;dy<M7R;dy++) {\n\tfloat4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];    \n\tfor (int i=0;i<NRX;i++) {\n\t  score[dy][i] += v1[i].x*v2.x;\n\t  score[dy][i] += v1[i].y*v2.y;\n\t  score[dy][i] += v1[i].z*v2.z;\n\t  score[dy][i] += v1[i].w*v2.w;\n\t}\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      for (int i=0;i<NRX;i++) {\n\tif (score[dy][i]>max_score[i]) {\n\t  max_score[i] = score[dy][i];     \n\t  index[i] = bp2 + M7R*iy + dy;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  __syncthreads();\n  \n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx]; \n\tindex = indices[y*M7W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n__global__ void Match10(const float *__restrict d_pts1, \n                        const float *__restrict d_pts2,\n                              float *__restrict d_score,\n                                int *__restrict d_index)\n{\n#define NRX 2\n#define NUM (NRX*M7R)                       \n\n  __shared__ float4 buffer1[M7W*NDIM/4];    \n\n  __shared__ float4 buffer2[M7H*NUM];       \n\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bp1 = M7W*blockIdx.x;\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)     \n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    float score[M7R][NRX];                                    \n    for (int dy=0;dy<M7R;dy++)\n      for (int i=0;i<NRX;i++)\n\tscore[dy][i] = 0.0f;\n\n    int d = (idx%NUM);\n    int j = (idx/NUM);\n    buffer2[j*NUM + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    __syncthreads();\n    for (int dp=0;dp<NDIM/4;dp+=NUM) {\n      float4 temp;\n      if (dp<(NDIM/4-NUM))\n\ttemp = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + dp + d + NUM];\n\n      if (idx<M7W*M7H/M7R/NRX) {\n\tfor (int d=0;d<NUM;d++) {\n\t  float4 v1[NRX];\n#pragma unroll\n\t  for (int i=0;i<NRX;i++) \n\t    v1[i] = buffer1[(((M7W/NRX)*i + ix)<<5) + ((dp + d + (M7W/NRX)*i + ix)&31)];\n\t  \n\n#pragma unroll\n\t  for (int dy=0;dy<M7R;dy++) {\n\t    float4 v2 = buffer2[(M7R*iy + dy)*NUM + d];    \n#pragma unroll\n\t    for (int i=0;i<NRX;i++) {\n\t      score[dy][i] += v1[i].x*v2.x;\n\t      score[dy][i] += v1[i].y*v2.y;\n\t      score[dy][i] += v1[i].z*v2.z;\n\t      score[dy][i] += v1[i].w*v2.w;\n\t    }\n\t  }\n\t}\n      }\n      __syncthreads();\n\n      if (dp<(NDIM/4-NUM)) {\n\tbuffer2[j*NUM + d] = temp;\n\t__syncthreads();\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      for (int i=0;i<NRX;i++) {\n\tif (score[dy][i]>max_score[i]) {\n\t  max_score[i] = score[dy][i];     \n\t  index[i] = bp2 + M7R*iy + dy;\n\t}\n      }\n    }\n    __syncthreads();\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  __syncthreads();\n  \n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx]; \n\tindex = indices[y*M7W + tx];    \n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  size_t space = sizeof(float)*NPTS*NDIM*2 + 8;\n  std::vector<float> data(NPTS*NDIM*2 + 8);\n  void *ptr = (void*)&data[0];\n  float *h_pts1 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  ptr = (void*)&data[NPTS*NDIM];\n  float *h_pts2 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  std::vector<int> h_index(NPTS);\n  std::vector<float> h_score(NPTS);\n  std::vector<int> h_index2(NPTS);\n  std::vector<float> h_score2(NPTS);\n  \n  float *d_pts1, *d_pts2, *d_score;\n  int *d_index;\n  std::cout << std::endl;\n  int psize = sizeof(float)*NPTS;\n  std::cout << \"Data size:   \" << 2.0*psize*NDIM/1024/1024 << \" MB\" << std::endl;\n\n  hipMalloc((void **)&d_pts1, psize*NDIM);\n  hipMalloc((void **)&d_pts2, psize*NDIM);\n  hipMalloc((void **)&d_index, psize);\n  hipMalloc((void **)&d_score, psize);\n\n  for (int i=0;i<NPTS;i++) {\n    float sum1 = 0.0f, sum2 = 0.0f;\n    for (int d=0;d<NDIM;d++) {\n      sum1 += h_pts1[i*NDIM + d] = (float)rand()/RAND_MAX;\n      sum2 += h_pts2[i*NDIM + d] = (float)rand()/RAND_MAX;\n    }\n    sum1 = sqrt(NDIM)/sum1;\n    sum2 = sqrt(NDIM)/sum2;\n    for (int d=0;d<NDIM;d++) {\n      h_pts1[i*NDIM + d] *= sum1;\n      h_pts2[i*NDIM + d] *= sum2;\n    }\n  }\n\n  auto start = std::chrono::high_resolution_clock::now();\n  MatchC1(h_pts1, h_pts2, h_score.data(), h_index.data());\n  auto end = std::chrono::high_resolution_clock::now();\n  auto elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  auto delay = elapsed_seconds.count() * 1000;\n  std::cout << \"MatchCPU1:   \" << delay << \" ms  \"\n            << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n\n  hipMemcpy(d_pts1, h_pts1, psize*NDIM, hipMemcpyHostToDevice);\n  hipMemcpy(d_pts2, h_pts2, psize*NDIM, hipMemcpyHostToDevice);\n  \n  dim3 blocks, threads;\n  blocks = dim3(NPTS/M1W);\n  threads = dim3(M1W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match1, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU1:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M2W);\n  threads = dim3(M2W, M2H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match2, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU2:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M2W);\n  threads = dim3(M2W, M2H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match3, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU3:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n  \n  blocks = dim3(NPTS/M2W);\n  threads = dim3(M2W, M2H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match4, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU4:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n  \n  blocks = dim3(NPTS/M5W);\n  threads = dim3(M5W, M5H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match5, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU5:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n  \n  blocks = dim3(NPTS/M5W);\n  threads = dim3(M5W, M5H);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match6, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU6:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M7W);\n  threads = dim3(M7W, M7H/M7R);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match7, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU7:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M7W);\n  threads = dim3(M7W, M7H/M7R);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match8, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU8:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  blocks = dim3(NPTS/M7W);\n  threads = dim3(M7W, M7H/M7R/2);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match9, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU9:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n\n  blocks = dim3(NPTS/M7W);\n  threads = dim3(M7W, M7H/M7R);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) \n    hipLaunchKernelGGL(Match10, blocks, threads, 0, 0, d_pts1, d_pts2, d_score, d_index);\n  hipDeviceSynchronize();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU10:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  hipMemcpy(h_index2.data(), d_index, psize, hipMemcpyDeviceToHost);\n  hipMemcpy(h_score2.data(), d_score, psize, hipMemcpyDeviceToHost);\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  hipFree(d_pts1);\n  hipFree(d_pts2);\n  hipFree(d_index);\n  hipFree(d_score);\n\n  return 0;\n}\n"}}
{"kernel_name": "match", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include <cstring>\n#include <cmath>\n#include <iostream>\n#include <vector>\n#include <memory>  \n\n#include <chrono>\n#include <omp.h>\n\n#define NPTS (2048*8)\n#define NDIM 128\n\n#define M1W  128\n#define M2W   16\n#define M2H   16\n#define M5W   16\n#define M5H   16\n#define M5R    4\n#define M7W   32\n#define M7H   32\n#define M7R    4\n\n#define NRX 2\n#define NUM (NRX*M7R)                       \n\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z, w;\n} float4;\n\n\n\nvoid MatchC1(float *h_pts1, float *h_pts2, float *h_score, int *h_index)\n{\n  std::memset(h_score, 0, sizeof(float)*NPTS);\n  for (int p1=0;p1<NPTS;p1++) {\n    for (int p2=0;p2<NPTS;p2++) {\n      float score = 0.0f;\n      for (int d=0;d<NDIM;d++)\n\tscore += h_pts1[p1*NDIM + d]*h_pts2[p2*NDIM + d];\n      if (score>h_score[p1]) {\n\th_score[p1] = score;\n\th_index[p1] = p2;\n      }\n    }\n  }\n}\n\n\n\nvoid CheckMatches(int *h_index, int *h_index2, float *h_score, float *h_score2)\n{\n  int ndiff = 0;\n  for (int i=0;i<NPTS;i++) {\n    ndiff += (h_index[i] != h_index2[i]);\n    if (h_index[i] != h_index2[i])\n      std::cout << \"  \" << i << \" \" << h_index[i] << \" \" << h_index2[i] << \" \" << h_score[i] << \" \" << h_score2[i] << std::endl;\n  }\n  std::cout << \"Number of incorrect matches: \" << ndiff << std::endl;\n}\n      \nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  size_t space = sizeof(float)*NPTS*NDIM*2 + 8;\n  std::vector<float> data(NPTS*NDIM*2 + 8);\n  void *ptr = (void*)&data[0];\n  float *h_pts1 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  ptr = (void*)&data[NPTS*NDIM];\n  float *h_pts2 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  std::vector<int> h_index(NPTS);\n  std::vector<float> h_score(NPTS);\n  std::vector<int> h_index2(NPTS);\n  std::vector<float> h_score2(NPTS);\n  \n  std::cout << std::endl;\n  int psize = sizeof(float)*NPTS;\n  std::cout << \"Data size:   \" << 2.0*psize*NDIM/1024/1024 << \" MB\" << std::endl;\n\n  for (int i=0;i<NPTS;i++) {\n    float sum1 = 0.0f, sum2 = 0.0f;\n    for (int d=0;d<NDIM;d++) {\n      sum1 += h_pts1[i*NDIM + d] = (float)rand()/RAND_MAX;\n      sum2 += h_pts2[i*NDIM + d] = (float)rand()/RAND_MAX;\n    }\n    sum1 = sqrt(NDIM)/sum1;\n    sum2 = sqrt(NDIM)/sum2;\n    for (int d=0;d<NDIM;d++) {\n      h_pts1[i*NDIM + d] *= sum1;\n      h_pts2[i*NDIM + d] *= sum2;\n    }\n  }\n\n  float *d_pts1 = h_pts1;\n  float *d_pts2 = h_pts2;\n    int *d_index = h_index2.data();\n  float *d_score = h_score2.data();\n#pragma omp target data map (to: d_pts1[0:NPTS*NDIM], d_pts2[0:NPTS*NDIM]) \\\n                        map (alloc: d_index[0:NPTS], d_score[0:NPTS])\n{\n  auto start = std::chrono::high_resolution_clock::now();\n  MatchC1(h_pts1, h_pts2, h_score.data(), h_index.data());\n  auto end = std::chrono::high_resolution_clock::now();\n  auto elapsed_seconds = end - start;\n  auto delay = elapsed_seconds.count() * 1000;\n  std::cout << \"MatchCPU1:   \" << delay << \" ms  \"\n            << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  \n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams distribute parallel for thread_limit (M1W)\n    for (int p1 = 0; p1 < NPTS; p1++) { \n      float max_score = 0.0f;\n      int index = -1;\n      \n      for (int p2=0;p2<NPTS;p2++) {\n        float score = 0.0f;\n        for (int d=0;d<NDIM;d++)\n          score += d_pts1[p1*NDIM + d]*d_pts2[p2*NDIM + d];\n        if (score>max_score) {\n          max_score = score;\n          index = p2;\n        }\n      }\n      \n      d_score[p1] = max_score;\n      d_index[p1] = index;\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU1:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M2W) thread_limit(M2W*M2H)\n    {\n      float buffer1[M2W*NDIM];  \n      float buffer2[M2H*NDIM];  \n      float scores[M2W*M2H];    \n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M2W;\n        int ty = omp_get_thread_num() / M2W;\n        int idx = tx + M2W*ty;\n        int bp1 = M2W*omp_get_team_num();\n        if (ty<M2W)\n          for (int d=tx;d<NDIM;d+=M2W)\n            for (int j=ty;j<M2W;j+=M2H)\n              buffer1[j*NDIM + d] = d_pts1[(bp1 + j)*NDIM + d];   \n        #pragma omp barrier\n        \n        float max_score = 0.0f;\n        int index = -1;\n        for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n          for (int d=tx;d<NDIM;d+=M2W)\n            buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d]; \n          #pragma omp barrier\n\n          float score = 0.0f;\n          for (int d=0;d<NDIM;d++) \n            score += buffer1[tx*NDIM + d]*buffer2[ty*NDIM + d];   \n          scores[idx] = score;\n          #pragma omp barrier\n          \n          if (ty==0) {\n            for (int i=0;i<M2H;i++) {\n              if (scores[i*M2W + tx]>max_score) {\n                max_score = scores[i*M2W + tx];\n                index = bp2 + i;\n              }\n            }\n          }\n          #pragma omp barrier\n        }\n        \n        if (ty==0) {\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU2:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M2W) thread_limit(M2W*M2H)\n    {\n      float buffer1[M2W*(NDIM + 1)]; \n      float buffer2[M2H*NDIM];\n      float scores[M2W*M2H];\n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M2W;\n        int ty = omp_get_thread_num() / M2W;\n        int idx = tx + M2W*ty;\n        int bp1 = M2W*omp_get_team_num();\n        if (ty<M2W)\n          for (int d=tx;d<NDIM;d+=M2W)\n            for (int j=ty;j<M2W;j+=M2H)\n              buffer1[j*(NDIM + 1) + d] = d_pts1[(bp1 + j)*NDIM + d]; \n        #pragma omp barrier\n        \n        float max_score = 0.0f;\n        int index = -1;\n        for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n          for (int d=tx;d<NDIM;d+=M2W)\n            buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d];\n          #pragma omp barrier\n\n          float score = 0.0f;\n          for (int d=0;d<NDIM;d++) \n            score += buffer1[tx*(NDIM + 1) + d]*buffer2[ty*NDIM + d]; \n          scores[idx] = score;\n          #pragma omp barrier\n          \n          if (ty==0) {\n            for (int i=0;i<M2H;i++) {\n              if (scores[i*M2W + tx]>max_score) {\n                max_score = scores[i*M2W + tx];\n                index = bp2 + i;\n              }\n            }\n          }\n          #pragma omp barrier\n        }\n  \n        if (ty==0) {\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU3:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n  \n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M2W) thread_limit(M2W*M2H)\n    {\n      float4 buffer1[M2W*(NDIM/4 + 1)];  \n      float4 buffer2[M2H*NDIM/4];        \n      float scores[M2W*M2H];\n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M2W;\n        int ty = omp_get_thread_num() / M2W;\n        int idx = tx + M2W*ty;\n        int bp1 = M2W*omp_get_team_num();\n        if (ty<M2W)\n          for (int d=tx;d<NDIM/4;d+=M2W)\n            for (int j=ty;j<M2W;j+=M2H)\n              buffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d]; \n        #pragma omp barrier\n        \n        float max_score = 0.0f;\n        int index = -1;\n        for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n          for (int d=tx;d<NDIM/4;d+=M2W)\n            buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d]; \n          #pragma omp barrier\n\n          float score = 0.0f;\n          for (int d=0;d<NDIM/4;d++) {\n            float4 v1 = buffer1[tx*(NDIM/4 + 1) + d]; \n            float4 v2 = buffer2[ty*(NDIM/4) + d];     \n            score += v1.x*v2.x; score += v1.y*v2.y;\n            score += v1.z*v2.z; score += v1.w*v2.w;\n          }\n          scores[idx] = score;\n          #pragma omp barrier\n          \n          if (ty==0) {\n            for (int i=0;i<M2H;i++) {\n              if (scores[i*M2W + tx]>max_score) {\n                max_score = scores[i*M2W + tx];\n                index = bp2 + i;\n              }\n            }\n          }\n          #pragma omp barrier\n        }\n        \n        if (ty==0) {\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU4:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n  \n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M5W) thread_limit(M5W*M5H)\n    {\n      float4 buffer1[M5W*(NDIM/4 + 1)]; \n      float4 buffer2[M5H*NDIM/4];       \n      float scores[M5W*M5H];\n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M5W;\n        int ty = omp_get_thread_num() / M5W;\n        int bp1 = M5W*omp_get_team_num();\n        if (ty<M5W)\n          for (int d=tx;d<NDIM/4;d+=M5W)\n            for (int j=ty;j<M5W;j+=M5H)\n              buffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n        #pragma omp barrier\n        \n        float max_score = 0.0f;\n        int index = -1;\n        for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n          for (int d=tx;d<NDIM/4;d+=M5W)\n            buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n          #pragma omp barrier\n\n          if (ty<M5H/M5R) {  \n            float score[M5R];                                    \n            for (int dy=0;dy<M5R;dy++)\n              score[dy] = 0.0f;\n            for (int d=0;d<NDIM/4;d++) {\n              float4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n              for (int dy=0;dy<M5R;dy++) {\n                float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];    \n                score[dy] += v1.x*v2.x; score[dy] += v1.y*v2.y;\n                score[dy] += v1.z*v2.z; score[dy] += v1.w*v2.w;\n              }\n            }\n            for (int dy=0;dy<M5R;dy++)\n              scores[tx + M5W*(M5R*ty + dy)] = score[dy];\n          }\n          #pragma omp barrier\n          \n          if (ty==0) {\n            for (int i=0;i<M5H;i++) {\n              if (scores[i*M2W + tx]>max_score) {\n                max_score = scores[i*M5W + tx];\n                index = bp2 + i;\n              }\n            }\n          }\n          #pragma omp barrier\n        }\n\n        if (ty==0) {\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU5:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n  \n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M5W) thread_limit(M5W*M5H)\n    {\n      float4 buffer1[M5W*(NDIM/4 + 1)]; \n      float4 buffer2[M5H*NDIM/4];       \n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M5W;\n        int ty = omp_get_thread_num() / M5W;\n        int bp1 = M5W*omp_get_team_num();\n        if (ty<M5W)\n          for (int d=tx;d<NDIM/4;d+=M5W)\n            for (int j=ty;j<M5W;j+=M5H)\n              buffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n        \n        float max_score = 0.0f;\n        int index = -1;    \n        for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n          for (int d=tx;d<NDIM/4;d+=M5W)\n            buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n          #pragma omp barrier\n\n          if (ty<M5H/M5R) {  \n            float score[M5R];                                    \n            for (int dy=0;dy<M5R;dy++)\n              score[dy] = 0.0f;\n            for (int d=0;d<NDIM/4;d++) {\n              float4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n              for (int dy=0;dy<M5R;dy++) {\n                float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];    \n                score[dy] += v1.x*v2.x; score[dy] += v1.y*v2.y;\n                score[dy] += v1.z*v2.z; score[dy] += v1.w*v2.w;\n              }\n            }\n            for (int dy=0;dy<M5R;dy++) {\n              if (score[dy]>max_score) {   \n                max_score = score[dy];     \n                index = bp2 + M5R*ty + dy;               \n              }\n            }\n          }\n          #pragma omp barrier\n        }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M5W*M5H/M5R];\n        if (ty<M5H/M5R) {\n          scores[ty*M5W + tx] = max_score;  \n          indices[ty*M5W + tx] = index;     \n        }\n        #pragma omp barrier\n        \n        if (ty==0) {\n          max_score = scores[tx];\n          index = indices[tx];\n          for (int y=0;y<M5H/M5R;y++)\n            if (scores[y*M5W + tx]>max_score) {\n              max_score = scores[y*M5W + tx]; \n              index = indices[y*M5W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU6:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M7W) thread_limit(M7W*M7H/M7R)\n    {\n      float4 buffer1[M7W*NDIM/4]; \n      float4 buffer2[M7H*NDIM/4];       \n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M7W;\n        int ty = omp_get_thread_num() / M7W;\n        int bp1 = M7W*omp_get_team_num();\n        for (int d=tx;d<NDIM/4;d+=M7W)\n          for (int j=ty;j<M7W;j+=M7H/M7R)      \n            buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n        \n        float max_score = 0.0f;\n        int index = -1;    \n        for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n          for (int d=tx;d<NDIM/4;d+=M7W)\n            for (int j=ty;j<M7H;j+=M7H/M7R)       \n              buffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n          #pragma omp barrier\n\n          float score[M7R];                                    \n          for (int dy=0;dy<M7R;dy++)\n            score[dy] = 0.0f;\n          for (int d=0;d<NDIM/4;d++) {\n            float4 v1 = buffer1[tx*NDIM/4 + (d + tx)%(NDIM/4)];\n            for (int dy=0;dy<M7R;dy++) {\n              float4 v2 = buffer2[(M7R*ty + dy)*(NDIM/4) + d];    \n              score[dy] += v1.x*v2.x;\n              score[dy] += v1.y*v2.y;\n              score[dy] += v1.z*v2.z;\n              score[dy] += v1.w*v2.w;\n            }\n          }\n          for (int dy=0;dy<M7R;dy++) {\n            if (score[dy]>max_score) {   \n              max_score = score[dy];     \n              index = bp2 + M7R*ty + dy;               \n            }\n          }\n          #pragma omp barrier\n        }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M7W*M7H/M7R];\n        scores[ty*M7W + tx] = max_score;  \n        indices[ty*M7W + tx] = index;     \n        #pragma omp barrier\n        \n        if (ty==0) {\n          max_score = scores[tx];\n          index = indices[tx];\n          for (int y=0;y<M7H/M7R;y++)\n            if (scores[y*M7W + tx]>max_score) {\n              max_score = scores[y*M7W + tx]; \n              index = indices[y*M7W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU7:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M7W) thread_limit(M7W*M7H/M7R)\n    {\n      float4 buffer1[M7W*NDIM/4]; \n      float4 buffer2[M7H*NDIM/4];       \n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M7W;\n        int ty = omp_get_thread_num() / M7W;\n        int bp1 = M7W*omp_get_team_num();\n        for (int d=tx;d<NDIM/4;d+=M7W)\n          for (int j=ty;j<M7W;j+=M7H/M7R)     \n            buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n        float max_score[NRX];\n        int index[NRX];\n        for (int i=0;i<NRX;i++) {\n          max_score[i] = 0.0f;\n          index[i] = -1;\n        }\n        int idx = ty*M7W + tx;\n        int ix = idx%(M7W/NRX);\n        int iy = idx/(M7W/NRX);\n        for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n          for (int d=tx;d<NDIM/4;d+=M7W)\n            for (int j=ty;j<M7H;j+=M7H/M7R)       \n              buffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n          #pragma omp barrier\n\n          if (idx<M7W*M7H/M7R/NRX) {\n            float score[M7R][NRX];                                    \n            for (int dy=0;dy<M7R;dy++)\n              for (int i=0;i<NRX;i++)\n                score[dy][i] = 0.0f;\n            for (int d=0;d<NDIM/4;d++) {\n              float4 v1[NRX];\n              for (int i=0;i<NRX;i++) \n                v1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n              for (int dy=0;dy<M7R;dy++) {\n                float4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];    \n                for (int i=0;i<NRX;i++) {\n                  score[dy][i] += v1[i].x*v2.x;\n                  score[dy][i] += v1[i].y*v2.y;\n                  score[dy][i] += v1[i].z*v2.z;\n                  score[dy][i] += v1[i].w*v2.w;\n                }\n              }\n            }\n            for (int dy=0;dy<M7R;dy++) {\n              for (int i=0;i<NRX;i++) {\n                if (score[dy][i]>max_score[i]) {\n                  max_score[i] = score[dy][i];     \n                  index[i] = bp2 + M7R*iy + dy;\n                }\n              }\n            }\n          }\n          #pragma omp barrier\n        }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M7W*M7H/M7R];\n        if (idx<M7W*M7H/M7R/NRX) {\n          for (int i=0;i<NRX;i++) {\n            scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n            indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n          }\n        }\n        #pragma omp barrier\n        \n        if (ty==0) {\n          float max_score = scores[tx];\n          int index = indices[tx];\n          for (int y=0;y<M7H/M7R;y++)\n            if (scores[y*M7W + tx]>max_score) {\n              max_score = scores[y*M7W + tx]; \n              index = indices[y*M7W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU8:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M7W) thread_limit(M7W*M7H/M7R/2)\n    {\n      float4 buffer1[M7W*NDIM/4]; \n      float4 buffer2[M7H*NDIM/4];       \n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M7W;\n        int ty = omp_get_thread_num() / M7W;\n        int bp1 = M7W*omp_get_team_num();\n        for (int d=tx;d<NDIM/4;d+=M7W)\n          for (int j=ty;j<M7W;j+=M7H/M7R/NRX)     \n            buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n        float max_score[NRX];\n        int index[NRX];\n        for (int i=0;i<NRX;i++) {\n          max_score[i] = 0.0f;\n          index[i] = -1;\n        }\n        int idx = ty*M7W + tx;\n        int ix = idx%(M7W/NRX);\n        int iy = idx/(M7W/NRX);\n        for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n          for (int d=tx;d<NDIM/4;d+=M7W)\n            for (int j=ty;j<M7H;j+=M7H/M7R/NRX)       \n              buffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n          #pragma omp barrier\n\n          float score[M7R][NRX];                                    \n          for (int dy=0;dy<M7R;dy++)\n            for (int i=0;i<NRX;i++)\n              score[dy][i] = 0.0f;\n          for (int d=0;d<NDIM/4;d++) {\n            float4 v1[NRX];\n            for (int i=0;i<NRX;i++) \n              v1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n            for (int dy=0;dy<M7R;dy++) {\n              float4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];    \n              for (int i=0;i<NRX;i++) {\n                score[dy][i] += v1[i].x*v2.x;\n                score[dy][i] += v1[i].y*v2.y;\n                score[dy][i] += v1[i].z*v2.z;\n                score[dy][i] += v1[i].w*v2.w;\n              }\n            }\n          }\n          for (int dy=0;dy<M7R;dy++) {\n            for (int i=0;i<NRX;i++) {\n              if (score[dy][i]>max_score[i]) {\n                max_score[i] = score[dy][i];     \n                index[i] = bp2 + M7R*iy + dy;\n              }\n            }\n          }\n          #pragma omp barrier\n        }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M7W*M7H/M7R];\n        if (idx<M7W*M7H/M7R/NRX) {\n          for (int i=0;i<NRX;i++) {\n            scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n            indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n          }\n        }\n        #pragma omp barrier\n        \n        if (ty==0) {\n          float max_score = scores[tx];\n          int index = indices[tx];\n          for (int y=0;y<M7H/M7R;y++)\n            if (scores[y*M7W + tx]>max_score) {\n              max_score = scores[y*M7W + tx]; \n              index = indices[y*M7W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"Match9:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(NPTS/M7W) thread_limit(M7W*M7H/M7R)\n    {\n      float4 buffer1[M7W*NDIM/4];    \n\n      float4 buffer2[M7H*NUM];       \n\n      #pragma omp parallel \n      {\n        int tx = omp_get_thread_num() % M7W;\n        int ty = omp_get_thread_num() / M7W;\n        int bp1 = M7W*omp_get_team_num();\n        for (int d=tx;d<NDIM/4;d+=M7W)\n          for (int j=ty;j<M7W;j+=M7H/M7R)     \n            buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n        float max_score[NRX];\n        int index[NRX];\n        for (int i=0;i<NRX;i++) {\n          max_score[i] = 0.0f;\n          index[i] = -1;\n        }\n        int idx = ty*M7W + tx;\n        int ix = idx%(M7W/NRX);\n        int iy = idx/(M7W/NRX);\n        for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n          float score[M7R][NRX];                                    \n          for (int dy=0;dy<M7R;dy++)\n            for (int i=0;i<NRX;i++)\n              score[dy][i] = 0.0f;\n\n          int d = (idx%NUM);\n          int j = (idx/NUM);\n          buffer2[j*NUM + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n          #pragma omp barrier\n          for (int dp=0;dp<NDIM/4;dp+=NUM) {\n            float4 temp;\n            if (dp<(NDIM/4-NUM))\n              temp = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + dp + d + NUM];\n\n            if (idx<M7W*M7H/M7R/NRX) {\n              for (int d=0;d<NUM;d++) {\n                float4 v1[NRX];\n                #pragma unroll\n                for (int i=0;i<NRX;i++) \n                  v1[i] = buffer1[(((M7W/NRX)*i + ix)<<5) + ((dp + d + (M7W/NRX)*i + ix)&31)];\n                \n\n                #pragma unroll\n                for (int dy=0;dy<M7R;dy++) {\n                  float4 v2 = buffer2[(M7R*iy + dy)*NUM + d];    \n                   #pragma unroll\n                  for (int i=0;i<NRX;i++) {\n                    score[dy][i] += v1[i].x*v2.x;\n                    score[dy][i] += v1[i].y*v2.y;\n                    score[dy][i] += v1[i].z*v2.z;\n                    score[dy][i] += v1[i].w*v2.w;\n                  }\n                }\n              }\n            }\n            #pragma omp barrier\n\n            if (dp<(NDIM/4-NUM)) {\n              buffer2[j*NUM + d] = temp;\n              #pragma omp barrier\n            }\n          }\n          for (int dy=0;dy<M7R;dy++) {\n            for (int i=0;i<NRX;i++) {\n              if (score[dy][i]>max_score[i]) {\n                max_score[i] = score[dy][i];     \n                index[i] = bp2 + M7R*iy + dy;\n              }\n            }\n          }\n          #pragma omp barrier\n        }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M7W*M7H/M7R];\n        if (idx<M7W*M7H/M7R/NRX) {\n          for (int i=0;i<NRX;i++) {\n            scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n            indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n          }\n        }\n        #pragma omp barrier\n        \n        if (ty==0) {\n          float max_score = scores[tx];\n          int index = indices[tx];\n          for (int y=0;y<M7H/M7R;y++)\n            if (scores[y*M7W + tx]>max_score) {\n              max_score = scores[y*M7W + tx]; \n              index = indices[y*M7W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU10:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  #pragma omp target update from (d_index[0:NPTS])\n  #pragma omp target update from (d_score[0:NPTS])\n  CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n}\n\n  return 0;\n}\n"}}
{"kernel_name": "match", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include <cstring>\n#include <cmath>\n#include <iostream>\n#include <vector>\n#include <memory>  \n\n#include <chrono>\n\n#define NPTS (2048*8)\n#define NDIM 128\n\n#define M1W  128\n#define M2W   16\n#define M2H   16\n#define M5W   16\n#define M5H   16\n#define M5R    4\n#define M7W   32\n#define M7H   32\n#define M7R    4\n\n#define NRX 2\n#define NUM (NRX*M7R)                       \n\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z, w;\n} float4;\n\n\n\nvoid MatchC1(float *h_pts1, float *h_pts2, float *h_score, int *h_index)\n{\n  std::memset(h_score, 0, sizeof(float)*NPTS);\n  for (int p1=0;p1<NPTS;p1++) {\n    for (int p2=0;p2<NPTS;p2++) {\n      float score = 0.0f;\n      for (int d=0;d<NDIM;d++)\n\tscore += h_pts1[p1*NDIM + d]*h_pts2[p2*NDIM + d];\n      if (score>h_score[p1]) {\n\th_score[p1] = score;\n\th_index[p1] = p2;\n      }\n    }\n  }\n}\n\n\n\nvoid CheckMatches(int *h_index, int *h_index2, float *h_score, float *h_score2)\n{\n  int ndiff = 0;\n  for (int i=0;i<NPTS;i++) {\n    ndiff += (h_index[i] != h_index2[i]);\n    if (h_index[i] != h_index2[i])\n      std::cout << \"  \" << i << \" \" << h_index[i] << \" \" << h_index2[i] << \" \" << h_score[i] << \" \" << h_score2[i] << std::endl;\n  }\n  std::cout << \"Number of incorrect matches: \" << ndiff << std::endl;\n}\n      \nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  size_t space = sizeof(float)*NPTS*NDIM*2 + 8;\n  std::vector<float> data(NPTS*NDIM*2 + 8);\n  void *ptr = (void*)&data[0];\n  float *h_pts1 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  ptr = (void*)&data[NPTS*NDIM];\n  float *h_pts2 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  std::vector<int> h_index(NPTS);\n  std::vector<float> h_score(NPTS);\n  std::vector<int> h_index2(NPTS);\n  std::vector<float> h_score2(NPTS);\n  \n  std::cout << std::endl;\n  int psize = sizeof(float)*NPTS;\n  std::cout << \"Data size:   \" << 2.0*psize*NDIM/1024/1024 << \" MB\" << std::endl;\n\n  for (int i=0;i<NPTS;i++) {\n    float sum1 = 0.0f, sum2 = 0.0f;\n    for (int d=0;d<NDIM;d++) {\n      sum1 += h_pts1[i*NDIM + d] = (float)rand()/RAND_MAX;\n      sum2 += h_pts2[i*NDIM + d] = (float)rand()/RAND_MAX;\n    }\n    sum1 = sqrt(NDIM)/sum1;\n    sum2 = sqrt(NDIM)/sum2;\n    for (int d=0;d<NDIM;d++) {\n      h_pts1[i*NDIM + d] *= sum1;\n      h_pts2[i*NDIM + d] *= sum2;\n    }\n  }\n\n  float *d_pts1 = h_pts1;\n  float *d_pts2 = h_pts2;\n    int *d_index = h_index2.data();\n  float *d_score = h_score2.data();\n{\n  auto start = std::chrono::high_resolution_clock::now();\n  MatchC1(h_pts1, h_pts2, h_score.data(), h_index.data());\n  auto end = std::chrono::high_resolution_clock::now();\n  auto elapsed_seconds = end - start;\n  auto delay = elapsed_seconds.count() * 1000;\n  std::cout << \"MatchCPU1:   \" << delay << \" ms  \"\n            << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  \n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        for (int p1 = 0; p1 < NPTS; p1++) { \n      float max_score = 0.0f;\n      int index = -1;\n      \n      for (int p2=0;p2<NPTS;p2++) {\n        float score = 0.0f;\n        for (int d=0;d<NDIM;d++)\n          score += d_pts1[p1*NDIM + d]*d_pts2[p2*NDIM + d];\n        if (score>max_score) {\n          max_score = score;\n          index = p2;\n        }\n      }\n      \n      d_score[p1] = max_score;\n      d_index[p1] = index;\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU1:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float buffer1[M2W*NDIM];  \n      float buffer2[M2H*NDIM];  \n      float scores[M2W*M2H];    \n            {\n        int tx = omp_get_thread_num() % M2W;\n        int ty = omp_get_thread_num() / M2W;\n        int idx = tx + M2W*ty;\n        int bp1 = M2W*omp_get_team_num();\n        if (ty<M2W)\n          for (int d=tx;d<NDIM;d+=M2W)\n            for (int j=ty;j<M2W;j+=M2H)\n              buffer1[j*NDIM + d] = d_pts1[(bp1 + j)*NDIM + d];   \n                \n        float max_score = 0.0f;\n        int index = -1;\n        for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n          for (int d=tx;d<NDIM;d+=M2W)\n            buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d]; \n          \n          float score = 0.0f;\n          for (int d=0;d<NDIM;d++) \n            score += buffer1[tx*NDIM + d]*buffer2[ty*NDIM + d];   \n          scores[idx] = score;\n                    \n          if (ty==0) {\n            for (int i=0;i<M2H;i++) {\n              if (scores[i*M2W + tx]>max_score) {\n                max_score = scores[i*M2W + tx];\n                index = bp2 + i;\n              }\n            }\n          }\n                  }\n        \n        if (ty==0) {\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU2:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float buffer1[M2W*(NDIM + 1)]; \n      float buffer2[M2H*NDIM];\n      float scores[M2W*M2H];\n            {\n        int tx = omp_get_thread_num() % M2W;\n        int ty = omp_get_thread_num() / M2W;\n        int idx = tx + M2W*ty;\n        int bp1 = M2W*omp_get_team_num();\n        if (ty<M2W)\n          for (int d=tx;d<NDIM;d+=M2W)\n            for (int j=ty;j<M2W;j+=M2H)\n              buffer1[j*(NDIM + 1) + d] = d_pts1[(bp1 + j)*NDIM + d]; \n                \n        float max_score = 0.0f;\n        int index = -1;\n        for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n          for (int d=tx;d<NDIM;d+=M2W)\n            buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d];\n          \n          float score = 0.0f;\n          for (int d=0;d<NDIM;d++) \n            score += buffer1[tx*(NDIM + 1) + d]*buffer2[ty*NDIM + d]; \n          scores[idx] = score;\n                    \n          if (ty==0) {\n            for (int i=0;i<M2H;i++) {\n              if (scores[i*M2W + tx]>max_score) {\n                max_score = scores[i*M2W + tx];\n                index = bp2 + i;\n              }\n            }\n          }\n                  }\n  \n        if (ty==0) {\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU3:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n  \n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float4 buffer1[M2W*(NDIM/4 + 1)];  \n      float4 buffer2[M2H*NDIM/4];        \n      float scores[M2W*M2H];\n            {\n        int tx = omp_get_thread_num() % M2W;\n        int ty = omp_get_thread_num() / M2W;\n        int idx = tx + M2W*ty;\n        int bp1 = M2W*omp_get_team_num();\n        if (ty<M2W)\n          for (int d=tx;d<NDIM/4;d+=M2W)\n            for (int j=ty;j<M2W;j+=M2H)\n              buffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d]; \n                \n        float max_score = 0.0f;\n        int index = -1;\n        for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n          for (int d=tx;d<NDIM/4;d+=M2W)\n            buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d]; \n          \n          float score = 0.0f;\n          for (int d=0;d<NDIM/4;d++) {\n            float4 v1 = buffer1[tx*(NDIM/4 + 1) + d]; \n            float4 v2 = buffer2[ty*(NDIM/4) + d];     \n            score += v1.x*v2.x; score += v1.y*v2.y;\n            score += v1.z*v2.z; score += v1.w*v2.w;\n          }\n          scores[idx] = score;\n                    \n          if (ty==0) {\n            for (int i=0;i<M2H;i++) {\n              if (scores[i*M2W + tx]>max_score) {\n                max_score = scores[i*M2W + tx];\n                index = bp2 + i;\n              }\n            }\n          }\n                  }\n        \n        if (ty==0) {\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU4:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n  \n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float4 buffer1[M5W*(NDIM/4 + 1)]; \n      float4 buffer2[M5H*NDIM/4];       \n      float scores[M5W*M5H];\n            {\n        int tx = omp_get_thread_num() % M5W;\n        int ty = omp_get_thread_num() / M5W;\n        int bp1 = M5W*omp_get_team_num();\n        if (ty<M5W)\n          for (int d=tx;d<NDIM/4;d+=M5W)\n            for (int j=ty;j<M5W;j+=M5H)\n              buffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n                \n        float max_score = 0.0f;\n        int index = -1;\n        for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n          for (int d=tx;d<NDIM/4;d+=M5W)\n            buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n          \n          if (ty<M5H/M5R) {  \n            float score[M5R];                                    \n            for (int dy=0;dy<M5R;dy++)\n              score[dy] = 0.0f;\n            for (int d=0;d<NDIM/4;d++) {\n              float4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n              for (int dy=0;dy<M5R;dy++) {\n                float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];    \n                score[dy] += v1.x*v2.x; score[dy] += v1.y*v2.y;\n                score[dy] += v1.z*v2.z; score[dy] += v1.w*v2.w;\n              }\n            }\n            for (int dy=0;dy<M5R;dy++)\n              scores[tx + M5W*(M5R*ty + dy)] = score[dy];\n          }\n                    \n          if (ty==0) {\n            for (int i=0;i<M5H;i++) {\n              if (scores[i*M2W + tx]>max_score) {\n                max_score = scores[i*M5W + tx];\n                index = bp2 + i;\n              }\n            }\n          }\n                  }\n\n        if (ty==0) {\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU5:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n  \n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float4 buffer1[M5W*(NDIM/4 + 1)]; \n      float4 buffer2[M5H*NDIM/4];       \n            {\n        int tx = omp_get_thread_num() % M5W;\n        int ty = omp_get_thread_num() / M5W;\n        int bp1 = M5W*omp_get_team_num();\n        if (ty<M5W)\n          for (int d=tx;d<NDIM/4;d+=M5W)\n            for (int j=ty;j<M5W;j+=M5H)\n              buffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n        \n        float max_score = 0.0f;\n        int index = -1;    \n        for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n          for (int d=tx;d<NDIM/4;d+=M5W)\n            buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n          \n          if (ty<M5H/M5R) {  \n            float score[M5R];                                    \n            for (int dy=0;dy<M5R;dy++)\n              score[dy] = 0.0f;\n            for (int d=0;d<NDIM/4;d++) {\n              float4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n              for (int dy=0;dy<M5R;dy++) {\n                float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];    \n                score[dy] += v1.x*v2.x; score[dy] += v1.y*v2.y;\n                score[dy] += v1.z*v2.z; score[dy] += v1.w*v2.w;\n              }\n            }\n            for (int dy=0;dy<M5R;dy++) {\n              if (score[dy]>max_score) {   \n                max_score = score[dy];     \n                index = bp2 + M5R*ty + dy;               \n              }\n            }\n          }\n                  }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M5W*M5H/M5R];\n        if (ty<M5H/M5R) {\n          scores[ty*M5W + tx] = max_score;  \n          indices[ty*M5W + tx] = index;     \n        }\n                \n        if (ty==0) {\n          max_score = scores[tx];\n          index = indices[tx];\n          for (int y=0;y<M5H/M5R;y++)\n            if (scores[y*M5W + tx]>max_score) {\n              max_score = scores[y*M5W + tx]; \n              index = indices[y*M5W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU6:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float4 buffer1[M7W*NDIM/4]; \n      float4 buffer2[M7H*NDIM/4];       \n            {\n        int tx = omp_get_thread_num() % M7W;\n        int ty = omp_get_thread_num() / M7W;\n        int bp1 = M7W*omp_get_team_num();\n        for (int d=tx;d<NDIM/4;d+=M7W)\n          for (int j=ty;j<M7W;j+=M7H/M7R)      \n            buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n        \n        float max_score = 0.0f;\n        int index = -1;    \n        for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n          for (int d=tx;d<NDIM/4;d+=M7W)\n            for (int j=ty;j<M7H;j+=M7H/M7R)       \n              buffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n          \n          float score[M7R];                                    \n          for (int dy=0;dy<M7R;dy++)\n            score[dy] = 0.0f;\n          for (int d=0;d<NDIM/4;d++) {\n            float4 v1 = buffer1[tx*NDIM/4 + (d + tx)%(NDIM/4)];\n            for (int dy=0;dy<M7R;dy++) {\n              float4 v2 = buffer2[(M7R*ty + dy)*(NDIM/4) + d];    \n              score[dy] += v1.x*v2.x;\n              score[dy] += v1.y*v2.y;\n              score[dy] += v1.z*v2.z;\n              score[dy] += v1.w*v2.w;\n            }\n          }\n          for (int dy=0;dy<M7R;dy++) {\n            if (score[dy]>max_score) {   \n              max_score = score[dy];     \n              index = bp2 + M7R*ty + dy;               \n            }\n          }\n                  }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M7W*M7H/M7R];\n        scores[ty*M7W + tx] = max_score;  \n        indices[ty*M7W + tx] = index;     \n                \n        if (ty==0) {\n          max_score = scores[tx];\n          index = indices[tx];\n          for (int y=0;y<M7H/M7R;y++)\n            if (scores[y*M7W + tx]>max_score) {\n              max_score = scores[y*M7W + tx]; \n              index = indices[y*M7W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU7:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float4 buffer1[M7W*NDIM/4]; \n      float4 buffer2[M7H*NDIM/4];       \n            {\n        int tx = omp_get_thread_num() % M7W;\n        int ty = omp_get_thread_num() / M7W;\n        int bp1 = M7W*omp_get_team_num();\n        for (int d=tx;d<NDIM/4;d+=M7W)\n          for (int j=ty;j<M7W;j+=M7H/M7R)     \n            buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n        float max_score[NRX];\n        int index[NRX];\n        for (int i=0;i<NRX;i++) {\n          max_score[i] = 0.0f;\n          index[i] = -1;\n        }\n        int idx = ty*M7W + tx;\n        int ix = idx%(M7W/NRX);\n        int iy = idx/(M7W/NRX);\n        for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n          for (int d=tx;d<NDIM/4;d+=M7W)\n            for (int j=ty;j<M7H;j+=M7H/M7R)       \n              buffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n          \n          if (idx<M7W*M7H/M7R/NRX) {\n            float score[M7R][NRX];                                    \n            for (int dy=0;dy<M7R;dy++)\n              for (int i=0;i<NRX;i++)\n                score[dy][i] = 0.0f;\n            for (int d=0;d<NDIM/4;d++) {\n              float4 v1[NRX];\n              for (int i=0;i<NRX;i++) \n                v1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n              for (int dy=0;dy<M7R;dy++) {\n                float4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];    \n                for (int i=0;i<NRX;i++) {\n                  score[dy][i] += v1[i].x*v2.x;\n                  score[dy][i] += v1[i].y*v2.y;\n                  score[dy][i] += v1[i].z*v2.z;\n                  score[dy][i] += v1[i].w*v2.w;\n                }\n              }\n            }\n            for (int dy=0;dy<M7R;dy++) {\n              for (int i=0;i<NRX;i++) {\n                if (score[dy][i]>max_score[i]) {\n                  max_score[i] = score[dy][i];     \n                  index[i] = bp2 + M7R*iy + dy;\n                }\n              }\n            }\n          }\n                  }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M7W*M7H/M7R];\n        if (idx<M7W*M7H/M7R/NRX) {\n          for (int i=0;i<NRX;i++) {\n            scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n            indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n          }\n        }\n                \n        if (ty==0) {\n          float max_score = scores[tx];\n          int index = indices[tx];\n          for (int y=0;y<M7H/M7R;y++)\n            if (scores[y*M7W + tx]>max_score) {\n              max_score = scores[y*M7W + tx]; \n              index = indices[y*M7W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU8:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float4 buffer1[M7W*NDIM/4]; \n      float4 buffer2[M7H*NDIM/4];       \n            {\n        int tx = omp_get_thread_num() % M7W;\n        int ty = omp_get_thread_num() / M7W;\n        int bp1 = M7W*omp_get_team_num();\n        for (int d=tx;d<NDIM/4;d+=M7W)\n          for (int j=ty;j<M7W;j+=M7H/M7R/NRX)     \n            buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n        float max_score[NRX];\n        int index[NRX];\n        for (int i=0;i<NRX;i++) {\n          max_score[i] = 0.0f;\n          index[i] = -1;\n        }\n        int idx = ty*M7W + tx;\n        int ix = idx%(M7W/NRX);\n        int iy = idx/(M7W/NRX);\n        for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n          for (int d=tx;d<NDIM/4;d+=M7W)\n            for (int j=ty;j<M7H;j+=M7H/M7R/NRX)       \n              buffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n          \n          float score[M7R][NRX];                                    \n          for (int dy=0;dy<M7R;dy++)\n            for (int i=0;i<NRX;i++)\n              score[dy][i] = 0.0f;\n          for (int d=0;d<NDIM/4;d++) {\n            float4 v1[NRX];\n            for (int i=0;i<NRX;i++) \n              v1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n            for (int dy=0;dy<M7R;dy++) {\n              float4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];    \n              for (int i=0;i<NRX;i++) {\n                score[dy][i] += v1[i].x*v2.x;\n                score[dy][i] += v1[i].y*v2.y;\n                score[dy][i] += v1[i].z*v2.z;\n                score[dy][i] += v1[i].w*v2.w;\n              }\n            }\n          }\n          for (int dy=0;dy<M7R;dy++) {\n            for (int i=0;i<NRX;i++) {\n              if (score[dy][i]>max_score[i]) {\n                max_score[i] = score[dy][i];     \n                index[i] = bp2 + M7R*iy + dy;\n              }\n            }\n          }\n                  }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M7W*M7H/M7R];\n        if (idx<M7W*M7H/M7R/NRX) {\n          for (int i=0;i<NRX;i++) {\n            scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n            indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n          }\n        }\n                \n        if (ty==0) {\n          float max_score = scores[tx];\n          int index = indices[tx];\n          for (int y=0;y<M7H/M7R;y++)\n            if (scores[y*M7W + tx]>max_score) {\n              max_score = scores[y*M7W + tx]; \n              index = indices[y*M7W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"Match9:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n\n\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        {\n      float4 buffer1[M7W*NDIM/4];    \n\n      float4 buffer2[M7H*NUM];       \n\n            {\n        int tx = omp_get_thread_num() % M7W;\n        int ty = omp_get_thread_num() / M7W;\n        int bp1 = M7W*omp_get_team_num();\n        for (int d=tx;d<NDIM/4;d+=M7W)\n          for (int j=ty;j<M7W;j+=M7H/M7R)     \n            buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n        float max_score[NRX];\n        int index[NRX];\n        for (int i=0;i<NRX;i++) {\n          max_score[i] = 0.0f;\n          index[i] = -1;\n        }\n        int idx = ty*M7W + tx;\n        int ix = idx%(M7W/NRX);\n        int iy = idx/(M7W/NRX);\n        for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n          float score[M7R][NRX];                                    \n          for (int dy=0;dy<M7R;dy++)\n            for (int i=0;i<NRX;i++)\n              score[dy][i] = 0.0f;\n\n          int d = (idx%NUM);\n          int j = (idx/NUM);\n          buffer2[j*NUM + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n                    for (int dp=0;dp<NDIM/4;dp+=NUM) {\n            float4 temp;\n            if (dp<(NDIM/4-NUM))\n              temp = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + dp + d + NUM];\n\n            if (idx<M7W*M7H/M7R/NRX) {\n              for (int d=0;d<NUM;d++) {\n                float4 v1[NRX];\n                                for (int i=0;i<NRX;i++) \n                  v1[i] = buffer1[(((M7W/NRX)*i + ix)<<5) + ((dp + d + (M7W/NRX)*i + ix)&31)];\n                \n\n                                for (int dy=0;dy<M7R;dy++) {\n                  float4 v2 = buffer2[(M7R*iy + dy)*NUM + d];    \n                                     for (int i=0;i<NRX;i++) {\n                    score[dy][i] += v1[i].x*v2.x;\n                    score[dy][i] += v1[i].y*v2.y;\n                    score[dy][i] += v1[i].z*v2.z;\n                    score[dy][i] += v1[i].w*v2.w;\n                  }\n                }\n              }\n            }\n            \n            if (dp<(NDIM/4-NUM)) {\n              buffer2[j*NUM + d] = temp;\n                          }\n          }\n          for (int dy=0;dy<M7R;dy++) {\n            for (int i=0;i<NRX;i++) {\n              if (score[dy][i]>max_score[i]) {\n                max_score[i] = score[dy][i];     \n                index[i] = bp2 + M7R*iy + dy;\n              }\n            }\n          }\n                  }\n\n        float *scores = (float*)buffer1;\n        int *indices = (int*)&scores[M7W*M7H/M7R];\n        if (idx<M7W*M7H/M7R/NRX) {\n          for (int i=0;i<NRX;i++) {\n            scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];  \n            indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n          }\n        }\n                \n        if (ty==0) {\n          float max_score = scores[tx];\n          int index = indices[tx];\n          for (int y=0;y<M7H/M7R;y++)\n            if (scores[y*M7W + tx]>max_score) {\n              max_score = scores[y*M7W + tx]; \n              index = indices[y*M7W + tx];    \n            }\n          d_score[bp1 + tx] = max_score;\n          d_index[bp1 + tx] = index;\n        }\n      }\n    }\n  }\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = end - start;\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU10:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n      CheckMatches(h_index.data(), d_index, h_score.data(), d_score);\n}\n\n  return 0;\n}"}}
{"kernel_name": "match", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n#include <cstring>\n#include <cmath>\n#include <iostream>\n#include <vector>\n#include <memory>  \n\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nusing float4 = sycl::float4;\n\n#define NPTS (2048*8)\n#define NDIM 128\n\n#define M1W  128\n#define M2W   16\n#define M2H   16\n#define M5W   16\n#define M5H   16\n#define M5R    4\n#define M7W   32\n#define M7H   32\n#define M7R    4\n\n\n\nvoid MatchC1(float *h_pts1, float *h_pts2, float *h_score, int *h_index)\n{\n  std::memset(h_score, 0, sizeof(float)*NPTS);\n  for (int p1=0;p1<NPTS;p1++) {\n    for (int p2=0;p2<NPTS;p2++) {\n      float score = 0.0f;\n      for (int d=0;d<NDIM;d++)\n\tscore += h_pts1[p1*NDIM + d]*h_pts2[p2*NDIM + d];\n      if (score>h_score[p1]) {\n\th_score[p1] = score;\n\th_index[p1] = p2;\n      }\n    }\n  }\n}\n\n\n\nvoid CheckMatches(int *h_index, int *h_index2, float *h_score, float *h_score2)\n{\n  int ndiff = 0;\n  for (int i=0;i<NPTS;i++) {\n    ndiff += (h_index[i] != h_index2[i]);\n#ifdef DEBUG\n    if (h_index[i] != h_index2[i])\n      std::cout << \"  \" << i << \" \" << h_index[i] << \" \" << h_index2[i] << \" \"\n                << h_score[i] << \" \" << h_score2[i] << std::endl;\n#endif\n  }\n  std::cout << \"Number of incorrect matches: \" << ndiff << std::endl;\n}\n\n\nvoid Match1(sycl::nd_item<1> &item,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int p1 = item.get_global_id(0);\n  float max_score = 0.0f;\n  int index = -1;\n\n  for (int p2=0;p2<NPTS;p2++) {\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++)\n      score += d_pts1[p1*NDIM + d]*d_pts2[p2*NDIM + d];\n    if (score>max_score) {\n      max_score = score;\n      index = p2;\n    }\n  }\n\n  d_score[p1] = max_score;\n  d_index[p1] = index;\n}\n\nvoid Match2(sycl::nd_item<2> &item,\n                  float *__restrict buffer1,\n                  float *__restrict buffer2,\n                  float *__restrict scores,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*item.get_group(1);\n  if (ty<M2W)\n    for (int d=tx;d<NDIM;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*NDIM + d] = d_pts1[(bp1 + j)*NDIM + d];\n  item.barrier(sycl::access::fence_space::local_space);\n\n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM;d+=M2W)\n      buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++)\n      score += buffer1[tx*NDIM + d]*buffer2[ty*NDIM + d];\n    scores[idx] = score;\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\nvoid Match3(sycl::nd_item<2> &item,\n                  float *__restrict buffer1,\n                  float *__restrict buffer2,\n                  float *__restrict scores,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*item.get_group(1);\n  if (ty<M2W)\n    for (int d=tx;d<NDIM;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*(NDIM + 1) + d] = d_pts1[(bp1 + j)*NDIM + d];\n  item.barrier(sycl::access::fence_space::local_space);\n\n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM;d+=M2W)\n      buffer2[ty*NDIM + d] = d_pts2[(bp2 + ty)*NDIM + d];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM;d++)\n      score += buffer1[tx*(NDIM + 1) + d]*buffer2[ty*NDIM + d];\n    scores[idx] = score;\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\nvoid Match4(sycl::nd_item<2> &item,\n                 float4 *__restrict buffer1,\n                 float4 *__restrict buffer2,\n                  float *__restrict scores,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int idx = tx + M2W*ty;\n  int bp1 = M2W*item.get_group(1);\n  if (ty<M2W)\n    for (int d=tx;d<NDIM/4;d+=M2W)\n      for (int j=ty;j<M2W;j+=M2H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n  item.barrier(sycl::access::fence_space::local_space);\n\n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M2H) {\n    for (int d=tx;d<NDIM/4;d+=M2W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    float score = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n      float4 v2 = buffer2[ty*(NDIM/4) + d];\n      score += v1.x()*v2.x(); score += v1.y()*v2.y();\n      score += v1.z()*v2.z(); score += v1.w()*v2.w();\n    }\n    scores[idx] = score;\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if (ty==0) {\n      for (int i=0;i<M2H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M2W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\nvoid Match5(sycl::nd_item<2> &item,\n                 float4 *__restrict buffer1,\n                 float4 *__restrict buffer2,\n                  float *__restrict scores,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int bp1 = M5W*item.get_group(1);\n  if (ty<M5W)\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      for (int j=ty;j<M5W;j+=M5H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n  item.barrier(sycl::access::fence_space::local_space);\n\n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if (ty<M5H/M5R) {\n      float score[M5R];\n      for (int dy=0;dy<M5R;dy++)\n\tscore[dy] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n\tfor (int dy=0;dy<M5R;dy++) {\n\t  float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];\n\t  score[dy] += v1.x()*v2.x(); score[dy] += v1.y()*v2.y();\n\t  score[dy] += v1.z()*v2.z(); score[dy] += v1.w()*v2.w();\n\t}\n      }\n      for (int dy=0;dy<M5R;dy++)\n\tscores[tx + M5W*(M5R*ty + dy)] = score[dy];\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if (ty==0) {\n      for (int i=0;i<M5H;i++) {\n\tif (scores[i*M2W + tx]>max_score) {\n\t  max_score = scores[i*M5W + tx];\n\t  index = bp2 + i;\n\t}\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  if (ty==0) {\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\n\nvoid Match6(sycl::nd_item<2> &item,\n                 float4 *__restrict buffer1,\n                 float4 *__restrict buffer2,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int bp1 = M5W*item.get_group(1);\n  if (ty<M5W)\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      for (int j=ty;j<M5W;j+=M5H)\n\tbuffer1[j*(NDIM/4 + 1) + d] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M5H) {\n    for (int d=tx;d<NDIM/4;d+=M5W)\n      buffer2[ty*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + ty)*(NDIM/4) + d];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if (ty<M5H/M5R) {\n      float score[M5R];\n      for (int dy=0;dy<M5R;dy++)\n\tscore[dy] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1 = buffer1[tx*(NDIM/4 + 1) + d];\n\tfor (int dy=0;dy<M5R;dy++) {\n\t  float4 v2 = buffer2[(M5R*ty + dy)*(NDIM/4) + d];\n\t  score[dy] += v1.x()*v2.x(); score[dy] += v1.y()*v2.y();\n\t  score[dy] += v1.z()*v2.z(); score[dy] += v1.w()*v2.w();\n\t}\n      }\n      for (int dy=0;dy<M5R;dy++) {\n\tif (score[dy]>max_score) {\n\t  max_score = score[dy];\n\t  index = bp2 + M5R*ty + dy;\n\t}\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M5W*M5H/M5R];\n  if (ty<M5H/M5R) {\n    scores[ty*M5W + tx] = max_score;\n    indices[ty*M5W + tx] = index;\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (ty==0) {\n    max_score = scores[tx];\n    index = indices[tx];\n    for (int y=0;y<M5H/M5R;y++)\n      if (scores[y*M5W + tx]>max_score) {\n\tmax_score = scores[y*M5W + tx];\n\tindex = indices[y*M5W + tx];\n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\nvoid Match7(sycl::nd_item<2> &item,\n                 float4 *__restrict buffer1,\n                 float4 *__restrict buffer2,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int bp1 = M7W*item.get_group(1);\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)\n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n  float max_score = 0.0f;\n  int index = -1;\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R)\n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    float score[M7R];\n    for (int dy=0;dy<M7R;dy++)\n      score[dy] = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1 = buffer1[tx*NDIM/4 + (d + tx)%(NDIM/4)];\n      for (int dy=0;dy<M7R;dy++) {\n\tfloat4 v2 = buffer2[(M7R*ty + dy)*(NDIM/4) + d];\n\tscore[dy] += v1.x()*v2.x();\n        score[dy] += v1.y()*v2.y();\n\tscore[dy] += v1.z()*v2.z();\n        score[dy] += v1.w()*v2.w();\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      if (score[dy]>max_score) {\n\tmax_score = score[dy];\n\tindex = bp2 + M7R*ty + dy;\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  scores[ty*M7W + tx] = max_score;\n  indices[ty*M7W + tx] = index;\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (ty==0) {\n    max_score = scores[tx];\n    index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx];\n\tindex = indices[y*M7W + tx];\n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\nvoid Match8(sycl::nd_item<2> &item,\n                 float4 *__restrict buffer1,\n                 float4 *__restrict buffer2,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int bp1 = M7W*item.get_group(1);\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)\n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n#define NRX 2\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R)\n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if (idx<M7W*M7H/M7R/NRX) {\n      float score[M7R][NRX];\n      for (int dy=0;dy<M7R;dy++)\n\tfor (int i=0;i<NRX;i++)\n\t  score[dy][i] = 0.0f;\n      for (int d=0;d<NDIM/4;d++) {\n\tfloat4 v1[NRX];\n\tfor (int i=0;i<NRX;i++)\n\t  v1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n\tfor (int dy=0;dy<M7R;dy++) {\n\t  float4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];\n\t  for (int i=0;i<NRX;i++) {\n\t    score[dy][i] += v1[i].x()*v2.x();\n\t    score[dy][i] += v1[i].y()*v2.y();\n\t    score[dy][i] += v1[i].z()*v2.z();\n\t    score[dy][i] += v1[i].w()*v2.w();\n\t  }\n\t}\n      }\n      for (int dy=0;dy<M7R;dy++) {\n\tfor (int i=0;i<NRX;i++) {\n\t  if (score[dy][i]>max_score[i]) {\n\t    max_score[i] = score[dy][i];\n\t    index[i] = bp2 + M7R*iy + dy;\n\t  }\n\t}\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];\n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx];\n\tindex = indices[y*M7W + tx];\n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\nvoid Match9(sycl::nd_item<2> &item,\n                 float4 *__restrict buffer1,\n                 float4 *__restrict buffer2,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int bp1 = M7W*item.get_group(1);\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R/NRX)\n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    for (int d=tx;d<NDIM/4;d+=M7W)\n      for (int j=ty;j<M7H;j+=M7H/M7R/NRX)\n\tbuffer2[j*NDIM/4 + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    float score[M7R][NRX];\n    for (int dy=0;dy<M7R;dy++)\n      for (int i=0;i<NRX;i++)\n\tscore[dy][i] = 0.0f;\n    for (int d=0;d<NDIM/4;d++) {\n      float4 v1[NRX];\n      for (int i=0;i<NRX;i++)\n\tv1[i] = buffer1[((M7W/NRX)*i + ix)*NDIM/4 + (d + (M7W/NRX)*i + ix)%(NDIM/4)];\n      for (int dy=0;dy<M7R;dy++) {\n\tfloat4 v2 = buffer2[(M7R*iy + dy)*(NDIM/4) + d];\n\tfor (int i=0;i<NRX;i++) {\n\t  score[dy][i] += v1[i].x()*v2.x();\n\t  score[dy][i] += v1[i].y()*v2.y();\n\t  score[dy][i] += v1[i].z()*v2.z();\n\t  score[dy][i] += v1[i].w()*v2.w();\n\t}\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      for (int i=0;i<NRX;i++) {\n\tif (score[dy][i]>max_score[i]) {\n\t  max_score[i] = score[dy][i];\n\t  index[i] = bp2 + M7R*iy + dy;\n\t}\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];\n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx];\n\tindex = indices[y*M7W + tx];\n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\nvoid Match10(sycl::nd_item<2> &item,\n                 float4 *__restrict buffer1,\n                 float4 *__restrict buffer2,\n            const float *__restrict d_pts1,\n            const float *__restrict d_pts2,\n                  float *__restrict d_score,\n                    int *__restrict d_index)\n{\n#define NRX 2\n#define NUM (NRX*M7R)                       \n\n  int tx = item.get_local_id(1);\n  int ty = item.get_local_id(0);\n  int bp1 = M7W*item.get_group(1);\n  for (int d=tx;d<NDIM/4;d+=M7W)\n    for (int j=ty;j<M7W;j+=M7H/M7R)\n      buffer1[j*NDIM/4 + (d + j)%(NDIM/4)] = ((float4*)d_pts1)[(bp1 + j)*(NDIM/4) + d];\n\n  float max_score[NRX];\n  int index[NRX];\n  for (int i=0;i<NRX;i++) {\n    max_score[i] = 0.0f;\n    index[i] = -1;\n  }\n  int idx = ty*M7W + tx;\n  int ix = idx%(M7W/NRX);\n  int iy = idx/(M7W/NRX);\n  for (int bp2=0;bp2<NPTS;bp2+=M7H) {\n    float score[M7R][NRX];\n    for (int dy=0;dy<M7R;dy++)\n      for (int i=0;i<NRX;i++)\n\tscore[dy][i] = 0.0f;\n\n    int d = (idx%NUM);\n    int j = (idx/NUM);\n    buffer2[j*NUM + d] = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + d];\n    item.barrier(sycl::access::fence_space::local_space);\n    for (int dp=0;dp<NDIM/4;dp+=NUM) {\n      float4 temp;\n      if (dp<(NDIM/4-NUM))\n\ttemp = ((float4*)d_pts2)[(bp2 + j)*(NDIM/4) + dp + d + NUM];\n\n      if (idx<M7W*M7H/M7R/NRX) {\n\tfor (int d=0;d<NUM;d++) {\n\t  float4 v1[NRX];\n#pragma unroll\n\t  for (int i=0;i<NRX;i++)\n\t    v1[i] = buffer1[(((M7W/NRX)*i + ix)<<5) + ((dp + d + (M7W/NRX)*i + ix)&31)];\n\t  \n\n#pragma unroll\n\t  for (int dy=0;dy<M7R;dy++) {\n\t    float4 v2 = buffer2[(M7R*iy + dy)*NUM + d];\n#pragma unroll\n\t    for (int i=0;i<NRX;i++) {\n\t      score[dy][i] += v1[i].x()*v2.x();\n\t      score[dy][i] += v1[i].y()*v2.y();\n\t      score[dy][i] += v1[i].z()*v2.z();\n\t      score[dy][i] += v1[i].w()*v2.w();\n\t    }\n\t  }\n\t}\n      }\n      item.barrier(sycl::access::fence_space::local_space);\n\n      if (dp<(NDIM/4-NUM)) {\n\tbuffer2[j*NUM + d] = temp;\n\titem.barrier(sycl::access::fence_space::local_space);\n      }\n    }\n    for (int dy=0;dy<M7R;dy++) {\n      for (int i=0;i<NRX;i++) {\n\tif (score[dy][i]>max_score[i]) {\n\t  max_score[i] = score[dy][i];\n\t  index[i] = bp2 + M7R*iy + dy;\n\t}\n      }\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n  }\n\n  float *scores = (float*)buffer1;\n  int *indices = (int*)&scores[M7W*M7H/M7R];\n  if (idx<M7W*M7H/M7R/NRX) {\n    for (int i=0;i<NRX;i++) {\n      scores[iy*M7W + (M7W/NRX)*i + ix] = max_score[i];\n      indices[iy*M7W + (M7W/NRX)*i + ix] = index[i];\n    }\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (ty==0) {\n    float max_score = scores[tx];\n    int index = indices[tx];\n    for (int y=0;y<M7H/M7R;y++)\n      if (scores[y*M7W + tx]>max_score) {\n\tmax_score = scores[y*M7W + tx];\n\tindex = indices[y*M7W + tx];\n      }\n    d_score[bp1 + tx] = max_score;\n    d_index[bp1 + tx] = index;\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  size_t space = sizeof(float)*NPTS*NDIM*2 + 8;\n  std::vector<float> data(NPTS*NDIM*2 + 8);\n  void *ptr = (void*)&data[0];\n  float *h_pts1 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  ptr = (void*)&data[NPTS*NDIM];\n  float *h_pts2 = (float*)std::align(32, sizeof(float)*NPTS*NDIM, ptr, space);\n  std::vector<int> h_index(NPTS);\n  std::vector<float> h_score(NPTS);\n  std::vector<int> h_index2(NPTS);\n  std::vector<float> h_score2(NPTS);\n\n  std::cout << std::endl;\n  int psize = sizeof(float)*NPTS;\n  std::cout << \"Data size:   \" << 2.0*psize*NDIM/1024/1024 << \" MB\" << std::endl;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_pts1  = sycl::malloc_device<float>(NPTS*NDIM, q);\n  float *d_pts2  = sycl::malloc_device<float>(NPTS*NDIM, q);\n    int *d_index = sycl::malloc_device<  int>(NPTS, q);\n  float *d_score = sycl::malloc_device<float>(NPTS, q);\n\n  for (int i=0;i<NPTS;i++) {\n    float sum1 = 0.0f, sum2 = 0.0f;\n    for (int d=0;d<NDIM;d++) {\n      sum1 += h_pts1[i*NDIM + d] = (float)rand()/RAND_MAX;\n      sum2 += h_pts2[i*NDIM + d] = (float)rand()/RAND_MAX;\n    }\n    sum1 = sqrt(NDIM)/sum1;\n    sum2 = sqrt(NDIM)/sum2;\n    for (int d=0;d<NDIM;d++) {\n      h_pts1[i*NDIM + d] *= sum1;\n      h_pts2[i*NDIM + d] *= sum2;\n    }\n  }\n\n  auto start = std::chrono::high_resolution_clock::now();\n  MatchC1(h_pts1, h_pts2, h_score.data(), h_index.data());\n  auto end = std::chrono::high_resolution_clock::now();\n  auto elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  auto delay = elapsed_seconds.count() * 1000;\n  std::cout << \"MatchCPU1:   \" << delay << \" ms  \"\n            << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n\n  q.memcpy(d_pts1, h_pts1, psize*NDIM);\n  q.memcpy(d_pts2, h_pts2, psize*NDIM);\n  q.wait();\n\n  sycl::range<1> gws1 (NPTS);\n  sycl::range<1> lws1 (M1W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k1>(\n        sycl::nd_range<1>(gws1, lws1), [=] (sycl::nd_item<1> item) {\n        Match1(item, d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU1:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws2 (M2H, NPTS/M2W);\n  sycl::range<2> lws2 (M2H, M2W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> buffer1(sycl::range<1>(M2W*NDIM), cgh);\n      sycl::local_accessor<float, 1> buffer2(sycl::range<1>(M2H*NDIM), cgh);\n      sycl::local_accessor<float, 1> scores(sycl::range<1>(M2H*M2W), cgh);\n      cgh.parallel_for<class k2>(\n        sycl::nd_range<2>(gws2, lws2), [=] (sycl::nd_item<2> item) {\n        Match2(item, buffer1.get_pointer(), buffer2.get_pointer(), scores.get_pointer(),\n               d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU2:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws3 (M2H, NPTS/M2W);\n  sycl::range<2> lws3 (M2H, M2W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> buffer1(sycl::range<1>(M2W*(NDIM+1)), cgh);\n      sycl::local_accessor<float, 1> buffer2(sycl::range<1>(M2H*NDIM), cgh);\n      sycl::local_accessor<float, 1> scores(sycl::range<1>(M2H*M2W), cgh);\n      cgh.parallel_for<class k3>(\n        sycl::nd_range<2>(gws3, lws3), [=] (sycl::nd_item<2> item) {\n        Match3(item, buffer1.get_pointer(), buffer2.get_pointer(), scores.get_pointer(),\n               d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU3:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws4 (M2H, NPTS);\n  sycl::range<2> lws4 (M2H, M2W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float4, 1> buffer1(sycl::range<1>(M2W*(NDIM/4+1)), cgh);\n      sycl::local_accessor<float4, 1> buffer2(sycl::range<1>(M2H*NDIM/4), cgh);\n      sycl::local_accessor<float, 1> scores(sycl::range<1>(M2H*M2W), cgh);\n      cgh.parallel_for<class k4>(\n        sycl::nd_range<2>(gws4, lws4), [=] (sycl::nd_item<2> item) {\n        Match4(item, buffer1.get_pointer(), buffer2.get_pointer(), scores.get_pointer(),\n               d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU4:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws5 (M5H, NPTS);\n  sycl::range<2> lws5 (M5H, M5W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float4, 1> buffer1(sycl::range<1>(M5W*(NDIM/4+1)), cgh);\n      sycl::local_accessor<float4, 1> buffer2(sycl::range<1>(M5H*NDIM/4), cgh);\n      sycl::local_accessor<float, 1> scores(sycl::range<1>(M5H*M5W), cgh);\n      cgh.parallel_for<class k5>(\n        sycl::nd_range<2>(gws5, lws5), [=] (sycl::nd_item<2> item) {\n        Match5(item, buffer1.get_pointer(), buffer2.get_pointer(), scores.get_pointer(),\n               d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU5:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws6 (M5H, NPTS);\n  sycl::range<2> lws6 (M5H, M5W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float4, 1> buffer1(sycl::range<1>(M5W*(NDIM/4+1)), cgh);\n      sycl::local_accessor<float4, 1> buffer2(sycl::range<1>(M5H*NDIM/4), cgh);\n      cgh.parallel_for<class k6>(\n        sycl::nd_range<2>(gws6, lws6), [=] (sycl::nd_item<2> item) {\n        Match6(item, buffer1.get_pointer(), buffer2.get_pointer(),\n               d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU6:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws7 (M7H/M7R, NPTS);\n  sycl::range<2> lws7 (M7H/M7R, M7W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float4, 1> buffer1(sycl::range<1>(M7W*NDIM/4), cgh);\n      sycl::local_accessor<float4, 1> buffer2(sycl::range<1>(M7H*NDIM/4), cgh);\n      cgh.parallel_for<class k7>(\n        sycl::nd_range<2>(gws7, lws7), [=] (sycl::nd_item<2> item) {\n        Match7(item, buffer1.get_pointer(), buffer2.get_pointer(),\n               d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU7:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws8 (M7H/M7R, NPTS);\n  sycl::range<2> lws8 (M7H/M7R, M7W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float4, 1> buffer1(sycl::range<1>(M7W*NDIM/4), cgh);\n      sycl::local_accessor<float4, 1> buffer2(sycl::range<1>(M7H*NDIM/4), cgh);\n      cgh.parallel_for<class k8>(\n        sycl::nd_range<2>(gws8, lws8), [=] (sycl::nd_item<2> item) {\n        Match8(item, buffer1.get_pointer(), buffer2.get_pointer(),\n               d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU8:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws9 (M7H/M7R/2, NPTS);\n  sycl::range<2> lws9 (M7H/M7R/2, M7W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float4, 1> buffer1(sycl::range<1>(M7W*NDIM/4), cgh);\n      sycl::local_accessor<float4, 1> buffer2(sycl::range<1>(M7H*NDIM/4), cgh);\n      cgh.parallel_for<class k9>(\n        sycl::nd_range<2>(gws9, lws9), [=] (sycl::nd_item<2> item) {\n        Match9(item, buffer1.get_pointer(), buffer2.get_pointer(),\n               d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU9:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::range<2> gws10 (M7H/M7R, NPTS);\n  sycl::range<2> lws10 (M7H/M7R, M7W);\n  start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float4, 1> buffer1(sycl::range<1>(M7W*NDIM/4), cgh);\n      sycl::local_accessor<float4, 1> buffer2(sycl::range<1>(M7H*NUM), cgh);\n      cgh.parallel_for<class k10>(sycl::nd_range<2>(gws10, lws10), [=] (sycl::nd_item<2> item) {\n        Match10(item, buffer1.get_pointer(), buffer2.get_pointer(),\n                d_pts1, d_pts2, d_score, d_index);\n      });\n    });\n  q.wait();\n  end = std::chrono::high_resolution_clock::now();\n  elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(end - start);\n  delay = elapsed_seconds.count() * 1000 / repeat;\n  std::cout << \"MatchGPU10:   \" << delay << \" ms  \" << 2.0*NPTS*NPTS*NDIM/delay/1024/1024 << \" Gflops\" << std::endl;\n  q.memcpy(h_index2.data(), d_index, psize);\n  q.memcpy(h_score2.data(), d_score, psize);\n  q.wait();\n  CheckMatches(h_index.data(), h_index2.data(), h_score.data(), h_score2.data());\n\n  sycl::free(d_pts1, q);\n  sycl::free(d_pts2, q);\n  sycl::free(d_index, q);\n  sycl::free(d_score, q);\n  return 0;\n}\n"}}
{"kernel_name": "ne", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n\ninline __device__ float3 operator*(const float3 &a, const float b)\n{\n  return make_float3(a.x * b, a.y * b, a.z * b);\n}\n\ninline __device__ float3 operator-(const float3 &a, const float3 &b)\n{\n  return make_float3(a.x - b.x, a.y - b.y, a.z - b.z);\n}\n\ninline __device__ float dot(const float3 &a, const float3 &b)\n{\n  return a.x * b.x + a.y * b.y + a.z * b.z;\n}\n\ninline __device__ float3 normalize(const float3 &v)\n{\n  float invLen = rsqrtf(dot(v, v));\n  return v * invLen;\n}\n\ninline __device__ float3 cross(const float3 &a, const float3 &b)\n{\n  return make_float3(a.y*b.z - a.z*b.y, a.z*b.x - a.x*b.z, a.x*b.y - a.y*b.x);\n}\n\ninline __device__ float length(const float3 &v)\n{\n  return sqrtf(dot(v, v));\n}\n\ninline __device__\nfloat4 normalEstimate(const float3 *points, int idx, int width, int height) \n{\n  float3 query_pt = points[idx];\n  if (isnan(query_pt.z))\n    return make_float4 (0.f,0.f,0.f,0.f);\n\n  int xIdx = idx % width;\n  int yIdx = idx / width;\n\n  \n\n  bool west_valid  = (xIdx > 1)        && !isnan (points[idx-1].z) &&     fabsf (points[idx-1].z - query_pt.z) < 200.f;\n  bool east_valid  = (xIdx < width-1)  && !isnan (points[idx+1].z) &&     fabsf (points[idx+1].z - query_pt.z) < 200.f;\n  bool north_valid = (yIdx > 1)        && !isnan (points[idx-width].z) && fabsf (points[idx-width].z - query_pt.z) < 200.f;\n  bool south_valid = (yIdx < height-1) && !isnan (points[idx+width].z) && fabsf (points[idx+width].z - query_pt.z) < 200.f;\n\n  float3 horiz, vert;\n  if (west_valid & east_valid)\n    horiz = points[idx+1] - points[idx-1];\n  if (west_valid & !east_valid)\n    horiz = points[idx] - points[idx-1];\n  if (!west_valid & east_valid)\n    horiz = points[idx+1] - points[idx];\n  if (!west_valid & !east_valid)\n    return make_float4 (0.f,0.f,0.f,1.f);\n\n  if (south_valid & north_valid)\n    vert = points[idx-width] - points[idx+width];\n  if (south_valid & !north_valid)\n    vert = points[idx] - points[idx+width];\n  if (!south_valid & north_valid)\n    vert = points[idx-width] - points[idx];\n  if (!south_valid & !north_valid)\n    return make_float4 (0.f,0.f,0.f,1.f);\n\n  float3 normal = cross (horiz, vert);\n\n  float curvature = length (normal);\n  curvature = fabsf(horiz.z) > 0.04f || fabsf(vert.z) > 0.04f ||\n    !west_valid || !east_valid || !north_valid || !south_valid;\n\n  float3 mc = normalize (normal);\n  if ( dot (query_pt, mc) > 0.f )\n    mc = mc * -1.f;\n  return make_float4 (mc.x, mc.y, mc.z, curvature);\n}\n\n__global__ void ne (\n  const float3 *__restrict__ points,\n        float4 *__restrict__ normal_points,\n  const int width,\n  const int height,\n  const int numPts)\n{\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx < numPts) \n    normal_points[idx] = normalEstimate(points, idx, width, height);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int numPts = width * height;\n  const int size = numPts * sizeof(float3);\n  const int normal_size = numPts * sizeof(float4);\n  float3 *points = (float3*) malloc (size);\n  float4 *normal_points = (float4*) malloc (normal_size);\n\n  srand(123);\n  for (int i = 0; i < numPts; i++) {\n    points[i].x = rand() % width;\n    points[i].y = rand() % height;\n    points[i].z = rand() % 256;\n  }\n\n  float3 *d_points;\n  float4 *d_normal_points;\n  cudaMalloc((void**)&d_points, size);\n  cudaMalloc((void**)&d_normal_points, normal_size);\n  cudaMemcpy(d_points, points, size, cudaMemcpyHostToDevice);\n\n  dim3 grids ((numPts + 255)/256);\n  dim3 blocks (256);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    ne <<< grids, blocks >>> (d_points, d_normal_points, width, height, numPts); \n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(normal_points, d_normal_points, normal_size, cudaMemcpyDeviceToHost);\n\n  float sx, sy, sz, sw;\n  sx = sy = sz = sw = 0.f;\n  for (int i = 0; i < numPts; i++) {\n    sx += normal_points[i].x;\n    sy += normal_points[i].y;\n    sz += normal_points[i].z;\n    sw += normal_points[i].w;\n  }\n  printf(\"Checksum: x=%f y=%f z=%f w=%f\\n\", sx, sy, sz, sw);\n\n  cudaFree(d_normal_points);\n  cudaFree(d_points);\n  free(normal_points);\n  free(points);\n  return 0;\n}\n"}}
{"kernel_name": "ne", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\ninline __device__ float3 operator*(const float3 &a, const float b)\n{\n  return make_float3(a.x * b, a.y * b, a.z * b);\n}\n\ninline __device__ float3 operator-(const float3 &a, const float3 &b)\n{\n  return make_float3(a.x - b.x, a.y - b.y, a.z - b.z);\n}\n\ninline __device__ float dot(const float3 &a, const float3 &b)\n{\n  return a.x * b.x + a.y * b.y + a.z * b.z;\n}\n\ninline __device__ float3 normalize(const float3 &v)\n{\n  float invLen = rsqrtf(dot(v, v));\n  return v * invLen;\n}\n\ninline __device__ float3 cross(const float3 &a, const float3 &b)\n{\n  return make_float3(a.y*b.z - a.z*b.y, a.z*b.x - a.x*b.z, a.x*b.y - a.y*b.x);\n}\n\ninline __device__ float length(const float3 &v)\n{\n  return sqrtf(dot(v, v));\n}\n\ninline __device__\nfloat4 normalEstimate(const float3 *points, int idx, int width, int height) \n{\n  float3 query_pt = points[idx];\n  if (isnan(query_pt.z))\n    return make_float4 (0.f,0.f,0.f,0.f);\n\n  int xIdx = idx % width;\n  int yIdx = idx / width;\n\n  \n\n  bool west_valid  = (xIdx > 1)        && !isnan (points[idx-1].z) &&     fabsf (points[idx-1].z - query_pt.z) < 200.f;\n  bool east_valid  = (xIdx < width-1)  && !isnan (points[idx+1].z) &&     fabsf (points[idx+1].z - query_pt.z) < 200.f;\n  bool north_valid = (yIdx > 1)        && !isnan (points[idx-width].z) && fabsf (points[idx-width].z - query_pt.z) < 200.f;\n  bool south_valid = (yIdx < height-1) && !isnan (points[idx+width].z) && fabsf (points[idx+width].z - query_pt.z) < 200.f;\n\n  float3 horiz, vert;\n  if (west_valid & east_valid)\n    horiz = points[idx+1] - points[idx-1];\n  if (west_valid & !east_valid)\n    horiz = points[idx] - points[idx-1];\n  if (!west_valid & east_valid)\n    horiz = points[idx+1] - points[idx];\n  if (!west_valid & !east_valid)\n    return make_float4 (0.f,0.f,0.f,1.f);\n\n  if (south_valid & north_valid)\n    vert = points[idx-width] - points[idx+width];\n  if (south_valid & !north_valid)\n    vert = points[idx] - points[idx+width];\n  if (!south_valid & north_valid)\n    vert = points[idx-width] - points[idx];\n  if (!south_valid & !north_valid)\n    return make_float4 (0.f,0.f,0.f,1.f);\n\n  float3 normal = cross (horiz, vert);\n\n  float curvature = length (normal);\n  curvature = fabsf(horiz.z) > 0.04f || fabsf(vert.z) > 0.04f ||\n    !west_valid || !east_valid || !north_valid || !south_valid;\n\n  float3 mc = normalize (normal);\n  if ( dot (query_pt, mc) > 0.f )\n    mc = mc * -1.f;\n  return make_float4 (mc.x, mc.y, mc.z, curvature);\n}\n\n__global__ void ne (\n  const float3 *__restrict__ points,\n        float4 *__restrict__ normal_points,\n  const int width,\n  const int height,\n  const int numPts)\n{\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx < numPts) \n    normal_points[idx] = normalEstimate(points, idx, width, height);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int numPts = width * height;\n  const int size = numPts * sizeof(float3);\n  const int normal_size = numPts * sizeof(float4);\n  float3 *points = (float3*) malloc (size);\n  float4 *normal_points = (float4*) malloc (normal_size);\n\n  srand(123);\n  for (int i = 0; i < numPts; i++) {\n    points[i].x = rand() % width;\n    points[i].y = rand() % height;\n    points[i].z = rand() % 256;\n  }\n\n  float3 *d_points;\n  float4 *d_normal_points;\n  hipMalloc((void**)&d_points, size);\n  hipMalloc((void**)&d_normal_points, normal_size);\n  hipMemcpy(d_points, points, size, hipMemcpyHostToDevice);\n\n  dim3 grids ((numPts + 255)/256);\n  dim3 blocks (256);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(ne, grids, blocks , 0, 0, d_points, d_normal_points, width, height, numPts); \n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(normal_points, d_normal_points, normal_size, hipMemcpyDeviceToHost);\n\n  float sx, sy, sz, sw;\n  sx = sy = sz = sw = 0.f;\n  for (int i = 0; i < numPts; i++) {\n    sx += normal_points[i].x;\n    sy += normal_points[i].y;\n    sz += normal_points[i].z;\n    sw += normal_points[i].w;\n  }\n  printf(\"Checksum: x=%f y=%f z=%f w=%f\\n\", sx, sy, sz, sw);\n\n  hipFree(d_normal_points);\n  hipFree(d_points);\n  free(normal_points);\n  free(points);\n  return 0;\n}\n"}}
{"kernel_name": "ne", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z;\n}\nfloat3;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z, w;\n}\nfloat4;\n\n#pragma omp declare target\ninline float3 operator*(const float3 &a, const float b)\n{\n  return {a.x * b, a.y * b, a.z * b};\n}\n\ninline float3 operator-(const float3 &a, const float3 &b)\n{\n  return {a.x - b.x, a.y - b.y, a.z - b.z};\n}\n\ninline float dot(const float3 &a, const float3 &b)\n{\n  return a.x * b.x + a.y * b.y + a.z * b.z;\n}\n\ninline float3 normalize(const float3 &v)\n{\n  float invLen = 1.f / sqrtf(dot(v, v));\n  return v * invLen;\n}\n\ninline float3 cross(const float3 &a, const float3 &b)\n{\n  return {a.y*b.z - a.z*b.y, a.z*b.x - a.x*b.z, a.x*b.y - a.y*b.x};\n}\n\ninline float length(const float3 &v)\n{\n  return sqrtf(dot(v, v));\n}\n\ninline float4 normalEstimate(const float3 *points, int idx, int width, int height) \n{\n  float3 query_pt = points[idx];\n  if (isnan(query_pt.z))\n    return {0.f,0.f,0.f,0.f};\n\n  int xIdx = idx % width;\n  int yIdx = idx / width;\n\n  \n\n  bool west_valid  = (xIdx > 1)        && !isnan (points[idx-1].z) &&     fabsf (points[idx-1].z - query_pt.z) < 200.f;\n  bool east_valid  = (xIdx < width-1)  && !isnan (points[idx+1].z) &&     fabsf (points[idx+1].z - query_pt.z) < 200.f;\n  bool north_valid = (yIdx > 1)        && !isnan (points[idx-width].z) && fabsf (points[idx-width].z - query_pt.z) < 200.f;\n  bool south_valid = (yIdx < height-1) && !isnan (points[idx+width].z) && fabsf (points[idx+width].z - query_pt.z) < 200.f;\n\n  float3 horiz, vert;\n  if (west_valid & east_valid)\n    horiz = points[idx+1] - points[idx-1];\n  if (west_valid & !east_valid)\n    horiz = points[idx] - points[idx-1];\n  if (!west_valid & east_valid)\n    horiz = points[idx+1] - points[idx];\n  if (!west_valid & !east_valid)\n    return {0.f,0.f,0.f,1.f};\n\n  if (south_valid & north_valid)\n    vert = points[idx-width] - points[idx+width];\n  if (south_valid & !north_valid)\n    vert = points[idx] - points[idx+width];\n  if (!south_valid & north_valid)\n    vert = points[idx-width] - points[idx];\n  if (!south_valid & !north_valid)\n    return {0.f,0.f,0.f,1.f};\n\n  float3 normal = cross (horiz, vert);\n\n  float curvature = length (normal);\n  curvature = fabsf(horiz.z) > 0.04f || fabsf(vert.z) > 0.04f ||\n              !west_valid || !east_valid || !north_valid || !south_valid;\n\n  float3 mc = normalize (normal);\n  if ( dot (query_pt, mc) > 0.f )\n    mc = mc * -1.f;\n  return {mc.x, mc.y, mc.z, curvature};\n}\n#pragma omp end declare target\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int numPts = width * height;\n  const int size = numPts * sizeof(float3);\n  const int normal_size = numPts * sizeof(float4);\n  float3 *points = (float3*) malloc (size);\n  float4 *normal_points = (float4*) malloc (normal_size);\n\n  srand(123);\n  for (int i = 0; i < numPts; i++) {\n    points[i].x = rand() % width;\n    points[i].y = rand() % height;\n    points[i].z = rand() % 256;\n  }\n\n  #pragma omp target data map (to: points[0:numPts]) \\\n                          map (from: normal_points[0:numPts])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (int idx = 0; idx < numPts; idx++)\n        normal_points[idx] = normalEstimate(points, idx, width, height);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  float sx, sy, sz, sw;\n  sx = sy = sz = sw = 0.f;\n  for (int i = 0; i < numPts; i++) {\n    sx += normal_points[i].x;\n    sy += normal_points[i].y;\n    sz += normal_points[i].z;\n    sw += normal_points[i].w;\n  }\n  printf(\"Checksum: x=%f y=%f z=%f w=%f\\n\", sx, sy, sz, sw);\n\n  free(normal_points);\n  free(points);\n  return 0;\n}\n"}}
{"kernel_name": "ne", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z;\n}\nfloat3;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z, w;\n}\nfloat4;\n\ninline float3 operator*(const float3 &a, const float b)\n{\n  return {a.x * b, a.y * b, a.z * b};\n}\n\ninline float3 operator-(const float3 &a, const float3 &b)\n{\n  return {a.x - b.x, a.y - b.y, a.z - b.z};\n}\n\ninline float dot(const float3 &a, const float3 &b)\n{\n  return a.x * b.x + a.y * b.y + a.z * b.z;\n}\n\ninline float3 normalize(const float3 &v)\n{\n  float invLen = 1.f / sqrtf(dot(v, v));\n  return v * invLen;\n}\n\ninline float3 cross(const float3 &a, const float3 &b)\n{\n  return {a.y*b.z - a.z*b.y, a.z*b.x - a.x*b.z, a.x*b.y - a.y*b.x};\n}\n\ninline float length(const float3 &v)\n{\n  return sqrtf(dot(v, v));\n}\n\ninline float4 normalEstimate(const float3 *points, int idx, int width, int height) \n{\n  float3 query_pt = points[idx];\n  if (isnan(query_pt.z))\n    return {0.f,0.f,0.f,0.f};\n\n  int xIdx = idx % width;\n  int yIdx = idx / width;\n\n  \n\n  bool west_valid  = (xIdx > 1)        && !isnan (points[idx-1].z) &&     fabsf (points[idx-1].z - query_pt.z) < 200.f;\n  bool east_valid  = (xIdx < width-1)  && !isnan (points[idx+1].z) &&     fabsf (points[idx+1].z - query_pt.z) < 200.f;\n  bool north_valid = (yIdx > 1)        && !isnan (points[idx-width].z) && fabsf (points[idx-width].z - query_pt.z) < 200.f;\n  bool south_valid = (yIdx < height-1) && !isnan (points[idx+width].z) && fabsf (points[idx+width].z - query_pt.z) < 200.f;\n\n  float3 horiz, vert;\n  if (west_valid & east_valid)\n    horiz = points[idx+1] - points[idx-1];\n  if (west_valid & !east_valid)\n    horiz = points[idx] - points[idx-1];\n  if (!west_valid & east_valid)\n    horiz = points[idx+1] - points[idx];\n  if (!west_valid & !east_valid)\n    return {0.f,0.f,0.f,1.f};\n\n  if (south_valid & north_valid)\n    vert = points[idx-width] - points[idx+width];\n  if (south_valid & !north_valid)\n    vert = points[idx] - points[idx+width];\n  if (!south_valid & north_valid)\n    vert = points[idx-width] - points[idx];\n  if (!south_valid & !north_valid)\n    return {0.f,0.f,0.f,1.f};\n\n  float3 normal = cross (horiz, vert);\n\n  float curvature = length (normal);\n  curvature = fabsf(horiz.z) > 0.04f || fabsf(vert.z) > 0.04f ||\n              !west_valid || !east_valid || !north_valid || !south_valid;\n\n  float3 mc = normalize (normal);\n  if ( dot (query_pt, mc) > 0.f )\n    mc = mc * -1.f;\n  return {mc.x, mc.y, mc.z, curvature};\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int numPts = width * height;\n  const int size = numPts * sizeof(float3);\n  const int normal_size = numPts * sizeof(float4);\n  float3 *points = (float3*) malloc (size);\n  float4 *normal_points = (float4*) malloc (normal_size);\n\n  srand(123);\n  for (int i = 0; i < numPts; i++) {\n    points[i].x = rand() % width;\n    points[i].y = rand() % height;\n    points[i].z = rand() % 256;\n  }\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n            for (int idx = 0; idx < numPts; idx++)\n        normal_points[idx] = normalEstimate(points, idx, width, height);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  float sx, sy, sz, sw;\n  sx = sy = sz = sw = 0.f;\n  for (int i = 0; i < numPts; i++) {\n    sx += normal_points[i].x;\n    sy += normal_points[i].y;\n    sz += normal_points[i].z;\n    sw += normal_points[i].w;\n  }\n  printf(\"Checksum: x=%f y=%f z=%f w=%f\\n\", sx, sy, sz, sw);\n\n  free(normal_points);\n  free(points);\n  return 0;\n}"}}
{"kernel_name": "ne", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nusing float3 = sycl::float3;\nusing float4 = sycl::float4;\n\n#ifndef SYCL_Geometric\ninline float dot(const float3 &a, const float3 &b)\n{\n  return a.x() * b.x() + a.y() * b.y() + a.z() * b.z();\n}\n\ninline float3 normalize(const float3 &v)\n{\n  float invLen = sycl::rsqrt(dot(v, v));\n  return v * invLen;\n}\n\ninline float3 cross(const float3 &a, const float3 &b)\n{\n  return float3(a.y()*b.z() - a.z()*b.y(), a.z()*b.x() - a.x()*b.z(), a.x()*b.y() - a.y()*b.x());\n}\n\ninline float length(const float3 &v)\n{\n  return sycl::sqrt(dot(v, v));\n}\n#endif\n\ninline float4 normalEstimate(const float3 *points, int idx, int width, int height)\n{\n  float3 query_pt = points[idx];\n  if (sycl::isnan(query_pt.z()))\n    return float4 (0.f,0.f,0.f,0.f);\n\n  int xIdx = idx % width;\n  int yIdx = idx / width;\n\n  \n\n  bool west_valid  = (xIdx > 1)        && !sycl::isnan (points[idx-1].z()) &&\n                     sycl::fabs (points[idx-1].z() - query_pt.z()) < 200.f;\n  bool east_valid  = (xIdx < width-1)  && !sycl::isnan (points[idx+1].z()) &&\n                     sycl::fabs (points[idx+1].z() - query_pt.z()) < 200.f;\n  bool north_valid = (yIdx > 1)        && !sycl::isnan (points[idx-width].z()) &&\n                     sycl::fabs (points[idx-width].z() - query_pt.z()) < 200.f;\n  bool south_valid = (yIdx < height-1) && !sycl::isnan (points[idx+width].z()) &&\n                     sycl::fabs (points[idx+width].z() - query_pt.z()) < 200.f;\n\n  float3 horiz, vert;\n  if (west_valid & east_valid)\n    horiz = points[idx+1] - points[idx-1];\n  if (west_valid & !east_valid)\n    horiz = points[idx] - points[idx-1];\n  if (!west_valid & east_valid)\n    horiz = points[idx+1] - points[idx];\n  if (!west_valid & !east_valid)\n    return float4 (0.f,0.f,0.f,1.f);\n\n  if (south_valid & north_valid)\n    vert = points[idx-width] - points[idx+width];\n  if (south_valid & !north_valid)\n    vert = points[idx] - points[idx+width];\n  if (!south_valid & north_valid)\n    vert = points[idx-width] - points[idx];\n  if (!south_valid & !north_valid)\n    return float4 (0.f,0.f,0.f,1.f);\n\n#ifdef SYCL_Geometric\n  float3 normal = sycl::cross (horiz, vert);\n  float curvature = sycl::length (normal);\n#else\n  float3 normal = cross (horiz, vert);\n  float curvature = length (normal);\n#endif\n\n  curvature = sycl::fabs(horiz.z()) > 0.04f || sycl::fabs(vert.z()) > 0.04f ||\n              !west_valid || !east_valid || !north_valid || !south_valid;\n\n#ifdef SYCL_Geometric\n  float3 mc = sycl::normalize (normal);\n  if ( sycl::dot (query_pt, mc) > 0.f )\n#else\n  float3 mc = normalize (normal);\n  if ( dot (query_pt, mc) > 0.f )\n#endif\n    mc = mc * -1.f;\n  return float4 (mc.x(), mc.y(), mc.z(), curvature);\n}\n\nvoid ne (\n  sycl::nd_item<1> &item,\n  const float3 *__restrict points,\n        float4 *__restrict normal_points,\n  const int width,\n  const int height,\n  const int numPts)\n{\n  int idx = item.get_global_id(0);\n  if (idx < numPts)\n    normal_points[idx] = normalEstimate(points, idx, width, height);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    printf(\"Usage: %s <width> <height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int width = atoi(argv[1]);\n  const int height = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int numPts = width * height;\n  const int size = numPts * sizeof(float3);\n  const int normal_size = numPts * sizeof(float4);\n  float3 *points = (float3*) malloc (size);\n  float4 *normal_points = (float4*) malloc (normal_size);\n\n  srand(123);\n  for (int i = 0; i < numPts; i++) {\n    points[i].x() = rand() % width;\n    points[i].y() = rand() % height;\n    points[i].z() = rand() % 256;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float3 *d_points = sycl::malloc_device<float3>(numPts, q);\n  q.memcpy(d_points, points, size);\n\n  float4 *d_normal_points = sycl::malloc_device<float4>(numPts, q);\n\n  sycl::range<1> gws ((numPts + 255)/256*256);\n  sycl::range<1> lws  (256);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class normal_estimate>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        ne(item, d_points, d_normal_points, width, height, numPts);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(normal_points, d_normal_points, normal_size).wait();\n\n  float sx, sy, sz, sw;\n  sx = sy = sz = sw = 0.f;\n  for (int i = 0; i < numPts; i++) {\n    sx += normal_points[i].x();\n    sy += normal_points[i].y();\n    sz += normal_points[i].z();\n    sw += normal_points[i].w();\n  }\n  printf(\"Checksum: x=%f y=%f z=%f w=%f\\n\", sx, sy, sz, sw);\n\n  sycl::free(d_normal_points, q);\n  sycl::free(d_points, q);\n  free(normal_points);\n  free(points);\n  return 0;\n}\n"}}
{"kernel_name": "resize", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\n__global__\nvoid resize (\n    T *__restrict__ output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict__ input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool round, bool half_pixel_centers)\n{\n    auto in_image_size = in_height * in_width;\n    auto out_image_size = out_height * out_width;\n\n    \n\n    auto num_effective_channels = output_size / out_image_size;\n\n    \n\n    auto num_channel_iters_per_xy = (num_effective_channels / CHANNELS_PER_ITER);\n\n    \n\n    auto iters_required = num_channel_iters_per_xy * out_image_size;\n\n    for (int iter = blockIdx.x * blockDim.x + threadIdx.x;\n             iter < iters_required; iter += blockDim.x * gridDim.x) {\n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_yf = half_pixel_centers ? (y + 0.5f) * o2i_fy : y * o2i_fy;\n        int in_y = round ? lroundf(in_yf) : static_cast<int>(in_yf);\n\n        auto in_xf = half_pixel_centers ? (x + 0.5f) * o2i_fx : x * o2i_fx;\n        int in_x = round ? lroundf(in_xf) : static_cast<int>(in_xf);\n\n        in_x = min(in_x, in_width - 1);\n        in_y = min(in_y, in_height - 1);\n\n        int in_idx = c_start * in_image_size + in_y * in_width + in_x;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        for (int i = 0; i < CHANNELS_PER_ITER; i++) {\n            output[out_idx] = input[in_idx];\n            in_idx += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\n__global__ void resize_bilinear(\n    T *__restrict__ output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict__ input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool half_pixel_centers)\n{\n    auto in_image_size = in_height * in_width;\n    auto out_image_size = out_height * out_width;\n\n    \n\n    auto num_effective_channels = output_size / out_image_size;\n\n    \n\n    auto num_channel_iters_per_xy = (num_effective_channels / CHANNELS_PER_ITER);\n\n    \n\n    auto iters_required = num_channel_iters_per_xy * out_image_size;\n\n    for (int iter = blockIdx.x * blockDim.x + threadIdx.x;\n             iter < iters_required; iter += blockDim.x * gridDim.x) {\n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n        const int c_end = c_start + CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_x = half_pixel_centers ? fmaxf((x + 0.5f) * o2i_fx - 0.5f, 0.0f) : x * o2i_fx;\n        auto in_y = half_pixel_centers ? fmaxf((y + 0.5f) * o2i_fy - 0.5f, 0.0f) : y * o2i_fy;\n\n        auto in_x0 = static_cast<int>(in_x);\n        auto in_x1 = min(in_x0 + 1, in_width - 1);\n\n        auto in_y0 = static_cast<int>(in_y);\n\n        auto in_y1 = min(in_y0, in_height - 1);\n        auto in_y2 = min(in_y0 + 1, in_height - 1);\n\n        int in_offset_r0 = c_start * in_image_size + in_y1 * in_width;\n        int in_offset_r1 = c_start * in_image_size + in_y2 * in_width;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        #pragma unroll 1 \n\n        for (auto c = c_start; c < c_end; c++) {\n            auto v_00 = input[in_offset_r0 + in_x0],\n                 v_01 = input[in_offset_r0 + in_x1],\n                 v_10 = input[in_offset_r1 + in_x0],\n                 v_11 = input[in_offset_r1 + in_x1];\n\n            output[out_idx] =\n                v_00 +\n                T(in_y - in_y0) * T(v_10 - v_00) +\n                T(in_x - in_x0) * T(v_01 - v_00) +\n                T(in_y - in_y0) * T(in_x - in_x0) * T(v_11 - v_01 - v_10 + v_00);\n\n            in_offset_r0 += in_image_size;\n            in_offset_r1 += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T>\nvoid resize_image (\n  const int in_width,\n  const int in_height,\n  const int out_width,\n  const int out_height,\n  const int num_channels,\n  const int repeat,\n  const bool bilinear = false)\n{\n  size_t in_image_size = (size_t)in_height * in_width;\n  size_t in_size = num_channels * in_image_size;\n  size_t in_size_bytes = sizeof(T) * in_size;\n\n  size_t out_image_size = (size_t)out_height * out_width;\n  size_t out_size = num_channels * out_image_size;\n  size_t out_size_bytes = sizeof(T) * out_size;\n\n  T* in_images_h = (T*) malloc (in_size_bytes);\n  T* out_images_h = (T*) malloc (out_size_bytes);\n\n  for(size_t i = 0; i < in_size; i++) in_images_h[i] = static_cast<T>((i+1) % 13);\n\n  T *in_images_d, *out_images_d;\n  cudaMalloc((void**)&in_images_d, in_size_bytes);\n  cudaMemcpy(in_images_d, in_images_h, in_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&out_images_d, out_size_bytes);\n  cudaMemset(out_images_d, 0, out_size_bytes);\n\n  const float fx = in_width / out_width;\n  const float fy = in_height / out_height;\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  if (bilinear) {\n    for (int i = 0; i < repeat; i++) {\n      resize_bilinear<T, 8> <<<29184, 256>>> (\n        out_images_d, out_size, out_height, out_width,\n        in_images_d, in_height, in_width, fx, fy, true);\n    }\n  } else {\n    for (int i = 0; i < repeat; i++) {\n      resize<T, 8> <<<29184, 256>>> (\n        out_images_d, out_size, out_height, out_width,\n        in_images_d, in_height, in_width, fx, fy, true, true);\n    }\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %lf (us)    Perf: %lf (GB/s)\\n\",\n         time * 1e-3 / repeat, (in_size_bytes + out_size_bytes) * repeat * 1.0 / time);\n  \n  cudaMemcpy(out_images_h, out_images_d, out_size_bytes, cudaMemcpyDeviceToHost);\n\n  cudaFree(in_images_d);\n  cudaFree(out_images_d);\n\n  free(in_images_h);\n  free(out_images_h);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 7) {\n    printf(\"Usage: %s <input image width> <input image height>\\n\", argv[0]);\n    printf(\"          <output image width> <output image height>\\n\");\n    printf(\"          <image channels> <repeat>\\n\");\n    return 1;\n  }\n\n  const int in_width = atoi(argv[1]);\n  const int in_height = atoi(argv[2]);\n  const int out_width = atoi(argv[3]);\n  const int out_height = atoi(argv[4]);\n  const int num_channels = atoi(argv[5]);\n  const int repeat = atoi(argv[6]);\n\n  printf(\"Resize %d images from (%d x %d) to (%d x %d)\\n\",\n          num_channels, in_width, in_height, out_width, out_height);\n\n  printf(\"\\nThe size of each pixel is 1 byte\\n\");\n  resize_image<unsigned char>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned char>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 2 bytes\\n\");\n  resize_image<unsigned short>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned short>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 4 bytes\\n\");\n  resize_image<unsigned int>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned int>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  return 0;\n}\n"}}
{"kernel_name": "resize", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\n__global__\nvoid resize (\n    T *__restrict__ output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict__ input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool round, bool half_pixel_centers)\n{\n    auto in_image_size = in_height * in_width;\n    auto out_image_size = out_height * out_width;\n\n    \n\n    auto num_effective_channels = output_size / out_image_size;\n\n    \n\n    auto num_channel_iters_per_xy = (num_effective_channels / CHANNELS_PER_ITER);\n\n    \n\n    auto iters_required = num_channel_iters_per_xy * out_image_size;\n\n    for (int iter = blockIdx.x * blockDim.x + threadIdx.x;\n             iter < iters_required; iter += blockDim.x * gridDim.x) {\n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_yf = half_pixel_centers ? (y + 0.5f) * o2i_fy : y * o2i_fy;\n        int in_y = round ? lroundf(in_yf) : static_cast<int>(in_yf);\n\n        auto in_xf = half_pixel_centers ? (x + 0.5f) * o2i_fx : x * o2i_fx;\n        int in_x = round ? lroundf(in_xf) : static_cast<int>(in_xf);\n\n        in_x = min(in_x, in_width - 1);\n        in_y = min(in_y, in_height - 1);\n\n        int in_idx = c_start * in_image_size + in_y * in_width + in_x;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        for (int i = 0; i < CHANNELS_PER_ITER; i++) {\n            output[out_idx] = input[in_idx];\n            in_idx += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\n__global__ void resize_bilinear(\n    T *__restrict__ output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict__ input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool half_pixel_centers)\n{\n    auto in_image_size = in_height * in_width;\n    auto out_image_size = out_height * out_width;\n\n    \n\n    auto num_effective_channels = output_size / out_image_size;\n\n    \n\n    auto num_channel_iters_per_xy = (num_effective_channels / CHANNELS_PER_ITER);\n\n    \n\n    auto iters_required = num_channel_iters_per_xy * out_image_size;\n\n    for (int iter = blockIdx.x * blockDim.x + threadIdx.x;\n             iter < iters_required; iter += blockDim.x * gridDim.x) {\n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n        const int c_end = c_start + CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_x = half_pixel_centers ? fmaxf((x + 0.5f) * o2i_fx - 0.5f, 0.0f) : x * o2i_fx;\n        auto in_y = half_pixel_centers ? fmaxf((y + 0.5f) * o2i_fy - 0.5f, 0.0f) : y * o2i_fy;\n\n        auto in_x0 = static_cast<int>(in_x);\n        auto in_x1 = min(in_x0 + 1, in_width - 1);\n\n        auto in_y0 = static_cast<int>(in_y);\n\n        auto in_y1 = min(in_y0, in_height - 1);\n        auto in_y2 = min(in_y0 + 1, in_height - 1);\n\n        int in_offset_r0 = c_start * in_image_size + in_y1 * in_width;\n        int in_offset_r1 = c_start * in_image_size + in_y2 * in_width;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        #pragma unroll 1 \n\n        for (auto c = c_start; c < c_end; c++) {\n            auto v_00 = input[in_offset_r0 + in_x0],\n                 v_01 = input[in_offset_r0 + in_x1],\n                 v_10 = input[in_offset_r1 + in_x0],\n                 v_11 = input[in_offset_r1 + in_x1];\n\n            output[out_idx] =\n                v_00 +\n                T(in_y - in_y0) * T(v_10 - v_00) +\n                T(in_x - in_x0) * T(v_01 - v_00) +\n                T(in_y - in_y0) * T(in_x - in_x0) * T(v_11 - v_01 - v_10 + v_00);\n\n            in_offset_r0 += in_image_size;\n            in_offset_r1 += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T>\nvoid resize_image (\n  const int in_width,\n  const int in_height,\n  const int out_width,\n  const int out_height,\n  const int num_channels,\n  const int repeat,\n  const bool bilinear = false)\n{\n  size_t in_image_size = (size_t)in_height * in_width;\n  size_t in_size = num_channels * in_image_size;\n  size_t in_size_bytes = sizeof(T) * in_size;\n\n  size_t out_image_size = (size_t)out_height * out_width;\n  size_t out_size = num_channels * out_image_size;\n  size_t out_size_bytes = sizeof(T) * out_size;\n\n  T* in_images_h = (T*) malloc (in_size_bytes);\n  T* out_images_h = (T*) malloc (out_size_bytes);\n\n  for(size_t i = 0; i < in_size; i++) in_images_h[i] = static_cast<T>((i+1) % 13);\n\n  T *in_images_d, *out_images_d;\n  hipMalloc((void**)&in_images_d, in_size_bytes);\n  hipMemcpy(in_images_d, in_images_h, in_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&out_images_d, out_size_bytes);\n  hipMemset(out_images_d, 0, out_size_bytes);\n\n  const float fx = in_width / out_width;\n  const float fy = in_height / out_height;\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  if (bilinear) {\n    for (int i = 0; i < repeat; i++) {\n      resize_bilinear<T, 8> <<<29184, 256>>> (\n        out_images_d, out_size, out_height, out_width,\n        in_images_d, in_height, in_width, fx, fy, true);\n    }\n  } else {\n    for (int i = 0; i < repeat; i++) {\n      resize<T, 8> <<<29184, 256>>> (\n        out_images_d, out_size, out_height, out_width,\n        in_images_d, in_height, in_width, fx, fy, true, true);\n    }\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %lf (us)    Perf: %lf (GB/s)\\n\",\n         time * 1e-3 / repeat, (in_size_bytes + out_size_bytes) * repeat * 1.0 / time);\n  \n  hipMemcpy(out_images_h, out_images_d, out_size_bytes, hipMemcpyDeviceToHost);\n\n  hipFree(in_images_d);\n  hipFree(out_images_d);\n\n  free(in_images_h);\n  free(out_images_h);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 7) {\n    printf(\"Usage: %s <input image width> <input image height>\\n\", argv[0]);\n    printf(\"          <output image width> <output image height>\\n\");\n    printf(\"          <image channels> <repeat>\\n\");\n    return 1;\n  }\n\n  const int in_width = atoi(argv[1]);\n  const int in_height = atoi(argv[2]);\n  const int out_width = atoi(argv[3]);\n  const int out_height = atoi(argv[4]);\n  const int num_channels = atoi(argv[5]);\n  const int repeat = atoi(argv[6]);\n\n  printf(\"Resize %d images from (%d x %d) to (%d x %d)\\n\",\n          num_channels, in_width, in_height, out_width, out_height);\n\n  printf(\"\\nThe size of each pixel is 1 byte\\n\");\n  resize_image<unsigned char>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned char>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 2 bytes\\n\");\n  resize_image<unsigned short>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned short>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 4 bytes\\n\");\n  resize_image<unsigned int>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned int>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  return 0;\n}\n"}}
{"kernel_name": "resize", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#define min(x, y) ((x) < (y) ? (x) : (y))\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\nvoid resize (\n    T *__restrict output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool round, bool half_pixel_centers)\n{\n    auto iters_required = output_size / CHANNELS_PER_ITER;\n\n    #pragma omp target teams distribute parallel for num_teams(29184) thread_limit(256)\n    for (int iter = 0; iter < iters_required; iter++) {\n\n       auto in_image_size = in_height * in_width;\n       auto out_image_size = out_height * out_width;\n\n       \n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_yf = half_pixel_centers ? (y + 0.5f) * o2i_fy : y * o2i_fy;\n        int in_y = round ? lroundf(in_yf) : static_cast<int>(in_yf);\n\n        auto in_xf = half_pixel_centers ? (x + 0.5f) * o2i_fx : x * o2i_fx;\n        int in_x = round ? lroundf(in_xf) : static_cast<int>(in_xf);\n\n        in_x = min(in_x, in_width - 1);\n        in_y = min(in_y, in_height - 1);\n\n        int in_idx = c_start * in_image_size + in_y * in_width + in_x;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        for (int i = 0; i < CHANNELS_PER_ITER; i++) {\n            output[out_idx] = input[in_idx];\n            in_idx += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\nvoid resize_bilinear(\n    T *__restrict output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool half_pixel_centers)\n{\n    auto iters_required = output_size / CHANNELS_PER_ITER;\n\n    #pragma omp target teams distribute parallel for num_teams(29184) thread_limit(256)\n    for (int iter = 0; iter < iters_required; iter++) {\n\n        auto in_image_size = in_height * in_width;\n        auto out_image_size = out_height * out_width;\n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n        const int c_end = c_start + CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_x = half_pixel_centers ? fmaxf((x + 0.5f) * o2i_fx - 0.5f, 0.0f) : x * o2i_fx;\n        auto in_y = half_pixel_centers ? fmaxf((y + 0.5f) * o2i_fy - 0.5f, 0.0f) : y * o2i_fy;\n\n        auto in_x0 = static_cast<int>(in_x);\n        auto in_x1 = min(in_x0 + 1, in_width - 1);\n\n        auto in_y0 = static_cast<int>(in_y);\n\n        auto in_y1 = min(in_y0, in_height - 1);\n        auto in_y2 = min(in_y0 + 1, in_height - 1);\n\n        int in_offset_r0 = c_start * in_image_size + in_y1 * in_width;\n        int in_offset_r1 = c_start * in_image_size + in_y2 * in_width;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        #pragma unroll 1 \n\n        for (auto c = c_start; c < c_end; c++) {\n            auto v_00 = input[in_offset_r0 + in_x0],\n                 v_01 = input[in_offset_r0 + in_x1],\n                 v_10 = input[in_offset_r1 + in_x0],\n                 v_11 = input[in_offset_r1 + in_x1];\n\n            output[out_idx] =\n                v_00 +\n                T(in_y - in_y0) * T(v_10 - v_00) +\n                T(in_x - in_x0) * T(v_01 - v_00) +\n                T(in_y - in_y0) * T(in_x - in_x0) * T(v_11 - v_01 - v_10 + v_00);\n\n            in_offset_r0 += in_image_size;\n            in_offset_r1 += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T>\nvoid resize_image (\n  const int in_width,\n  const int in_height,\n  const int out_width,\n  const int out_height,\n  const int num_channels,\n  const int repeat,\n  const bool bilinear = false)\n{\n  size_t in_image_size = (size_t)in_height * in_width;\n  size_t in_size = num_channels * in_image_size;\n  size_t in_size_bytes = sizeof(T) * in_size;\n\n  size_t out_image_size = (size_t)out_height * out_width;\n  size_t out_size = num_channels * out_image_size;\n  size_t out_size_bytes = sizeof(T) * out_size;\n\n  T* in_images = (T*) malloc (in_size_bytes);\n  T* out_images = (T*) malloc (out_size_bytes);\n\n  for(size_t i = 0; i < in_size; i++) in_images[i] = static_cast<T>((i+1) % 13);\n\n  const float fx = in_width / out_width;\n  const float fy = in_height / out_height;\n\n  #pragma omp target data map(to: in_images[0:in_size]) map(from: out_images[0:out_size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    \n\n    if (bilinear) {\n      for (int i = 0; i < repeat; i++) {\n        resize_bilinear<T, 8>(\n          out_images, out_size, out_height, out_width,\n          in_images, in_height, in_width, fx, fy, true);\n      }\n    } else {\n      for (int i = 0; i < repeat; i++) {\n        resize<T, 8>(\n          out_images, out_size, out_height, out_width,\n          in_images, in_height, in_width, fx, fy, true, true);\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %lf (us)    Perf: %lf (GB/s)\\n\",\n           time * 1e-3 / repeat, (in_size_bytes + out_size_bytes) * repeat * 1.0 / time);\n  }\n\n  free(in_images);\n  free(out_images);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 7) {\n    printf(\"Usage: %s <input image width> <input image height>\\n\", argv[0]);\n    printf(\"          <output image width> <output image height>\\n\");\n    printf(\"          <image channels> <repeat>\\n\");\n    return 1;\n  }\n\n  const int in_width = atoi(argv[1]);\n  const int in_height = atoi(argv[2]);\n  const int out_width = atoi(argv[3]);\n  const int out_height = atoi(argv[4]);\n  const int num_channels = atoi(argv[5]);\n  const int repeat = atoi(argv[6]);\n\n  printf(\"Resize %d images from (%d x %d) to (%d x %d)\\n\",\n          num_channels, in_width, in_height, out_width, out_height);\n\n  printf(\"\\nThe size of each pixel is 1 byte\\n\");\n  resize_image<unsigned char>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned char>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 2 bytes\\n\");\n  resize_image<unsigned short>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned short>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 4 bytes\\n\");\n  resize_image<unsigned int>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned int>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  return 0;\n}\n"}}
{"kernel_name": "resize", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n\n#define min(x, y) ((x) < (y) ? (x) : (y))\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\nvoid resize (\n    T *__restrict output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool round, bool half_pixel_centers)\n{\n    auto iters_required = output_size / CHANNELS_PER_ITER;\n\n        for (int iter = 0; iter < iters_required; iter++) {\n\n       auto in_image_size = in_height * in_width;\n       auto out_image_size = out_height * out_width;\n\n       \n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_yf = half_pixel_centers ? (y + 0.5f) * o2i_fy : y * o2i_fy;\n        int in_y = round ? lroundf(in_yf) : static_cast<int>(in_yf);\n\n        auto in_xf = half_pixel_centers ? (x + 0.5f) * o2i_fx : x * o2i_fx;\n        int in_x = round ? lroundf(in_xf) : static_cast<int>(in_xf);\n\n        in_x = min(in_x, in_width - 1);\n        in_y = min(in_y, in_height - 1);\n\n        int in_idx = c_start * in_image_size + in_y * in_width + in_x;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        for (int i = 0; i < CHANNELS_PER_ITER; i++) {\n            output[out_idx] = input[in_idx];\n            in_idx += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\nvoid resize_bilinear(\n    T *__restrict output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool half_pixel_centers)\n{\n    auto iters_required = output_size / CHANNELS_PER_ITER;\n\n        for (int iter = 0; iter < iters_required; iter++) {\n\n        auto in_image_size = in_height * in_width;\n        auto out_image_size = out_height * out_width;\n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n        const int c_end = c_start + CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_x = half_pixel_centers ? fmaxf((x + 0.5f) * o2i_fx - 0.5f, 0.0f) : x * o2i_fx;\n        auto in_y = half_pixel_centers ? fmaxf((y + 0.5f) * o2i_fy - 0.5f, 0.0f) : y * o2i_fy;\n\n        auto in_x0 = static_cast<int>(in_x);\n        auto in_x1 = min(in_x0 + 1, in_width - 1);\n\n        auto in_y0 = static_cast<int>(in_y);\n\n        auto in_y1 = min(in_y0, in_height - 1);\n        auto in_y2 = min(in_y0 + 1, in_height - 1);\n\n        int in_offset_r0 = c_start * in_image_size + in_y1 * in_width;\n        int in_offset_r1 = c_start * in_image_size + in_y2 * in_width;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        \n        for (auto c = c_start; c < c_end; c++) {\n            auto v_00 = input[in_offset_r0 + in_x0],\n                 v_01 = input[in_offset_r0 + in_x1],\n                 v_10 = input[in_offset_r1 + in_x0],\n                 v_11 = input[in_offset_r1 + in_x1];\n\n            output[out_idx] =\n                v_00 +\n                T(in_y - in_y0) * T(v_10 - v_00) +\n                T(in_x - in_x0) * T(v_01 - v_00) +\n                T(in_y - in_y0) * T(in_x - in_x0) * T(v_11 - v_01 - v_10 + v_00);\n\n            in_offset_r0 += in_image_size;\n            in_offset_r1 += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T>\nvoid resize_image (\n  const int in_width,\n  const int in_height,\n  const int out_width,\n  const int out_height,\n  const int num_channels,\n  const int repeat,\n  const bool bilinear = false)\n{\n  size_t in_image_size = (size_t)in_height * in_width;\n  size_t in_size = num_channels * in_image_size;\n  size_t in_size_bytes = sizeof(T) * in_size;\n\n  size_t out_image_size = (size_t)out_height * out_width;\n  size_t out_size = num_channels * out_image_size;\n  size_t out_size_bytes = sizeof(T) * out_size;\n\n  T* in_images = (T*) malloc (in_size_bytes);\n  T* out_images = (T*) malloc (out_size_bytes);\n\n  for(size_t i = 0; i < in_size; i++) in_images[i] = static_cast<T>((i+1) % 13);\n\n  const float fx = in_width / out_width;\n  const float fy = in_height / out_height;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    \n\n    if (bilinear) {\n      for (int i = 0; i < repeat; i++) {\n        resize_bilinear<T, 8>(\n          out_images, out_size, out_height, out_width,\n          in_images, in_height, in_width, fx, fy, true);\n      }\n    } else {\n      for (int i = 0; i < repeat; i++) {\n        resize<T, 8>(\n          out_images, out_size, out_height, out_width,\n          in_images, in_height, in_width, fx, fy, true, true);\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %lf (us)    Perf: %lf (GB/s)\\n\",\n           time * 1e-3 / repeat, (in_size_bytes + out_size_bytes) * repeat * 1.0 / time);\n  }\n\n  free(in_images);\n  free(out_images);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 7) {\n    printf(\"Usage: %s <input image width> <input image height>\\n\", argv[0]);\n    printf(\"          <output image width> <output image height>\\n\");\n    printf(\"          <image channels> <repeat>\\n\");\n    return 1;\n  }\n\n  const int in_width = atoi(argv[1]);\n  const int in_height = atoi(argv[2]);\n  const int out_width = atoi(argv[3]);\n  const int out_height = atoi(argv[4]);\n  const int num_channels = atoi(argv[5]);\n  const int repeat = atoi(argv[6]);\n\n  printf(\"Resize %d images from (%d x %d) to (%d x %d)\\n\",\n          num_channels, in_width, in_height, out_width, out_height);\n\n  printf(\"\\nThe size of each pixel is 1 byte\\n\");\n  resize_image<unsigned char>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned char>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 2 bytes\\n\");\n  resize_image<unsigned short>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned short>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 4 bytes\\n\");\n  resize_image<unsigned int>(in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned int>(in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  return 0;\n}"}}
{"kernel_name": "resize", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\n\nvoid resize (\n    T *__restrict output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool round, bool half_pixel_centers,\n    sycl::nd_item<1> &item)\n{\n    auto in_image_size = in_height * in_width;\n    auto out_image_size = out_height * out_width;\n\n    \n\n    auto num_effective_channels = output_size / out_image_size;\n\n    \n\n    auto num_channel_iters_per_xy = (num_effective_channels / CHANNELS_PER_ITER);\n\n    \n\n    auto iters_required = num_channel_iters_per_xy * out_image_size;\n\n    for (int iter = item.get_global_id(0);\n             iter < iters_required;\n             iter += item.get_local_range(0) * item.get_group_range(0)) {\n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_yf = half_pixel_centers ? (y + 0.5f) * o2i_fy : y * o2i_fy;\n        int in_y = round ? sycl::round(in_yf) : static_cast<int>(in_yf);\n\n        auto in_xf = half_pixel_centers ? (x + 0.5f) * o2i_fx : x * o2i_fx;\n        int in_x = round ? sycl::round(in_xf) : static_cast<int>(in_xf);\n\n        in_x = sycl::min(in_x, (int)(in_width - 1));\n        in_y = sycl::min(in_y, (int)(in_height - 1));\n\n        int in_idx = c_start * in_image_size + in_y * in_width + in_x;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        for (int i = 0; i < CHANNELS_PER_ITER; i++) {\n            output[out_idx] = input[in_idx];\n            in_idx += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T, std::size_t CHANNELS_PER_ITER>\nvoid resize_bilinear(\n    T *__restrict output,\n    size_t output_size, int out_height, int out_width,\n    const T *__restrict input, int in_height, int in_width,\n    float o2i_fy, float o2i_fx, bool half_pixel_centers,\n    sycl::nd_item<1> &item)\n{\n    auto in_image_size = in_height * in_width;\n    auto out_image_size = out_height * out_width;\n\n    \n\n    auto num_effective_channels = output_size / out_image_size;\n\n    \n\n    auto num_channel_iters_per_xy = (num_effective_channels / CHANNELS_PER_ITER);\n\n    \n\n    auto iters_required = num_channel_iters_per_xy * out_image_size;\n\n    for (int iter = item.get_global_id(0);\n             iter < iters_required;\n             iter += item.get_local_range(0) * item.get_group_range(0)) {\n\n        const int c_start = (iter / out_image_size) * CHANNELS_PER_ITER;\n        const int c_end = c_start + CHANNELS_PER_ITER;\n\n        \n\n        const int y = (iter % out_image_size) / out_width;\n        const int x = iter % out_width;\n\n        auto in_x = half_pixel_centers\n                        ? sycl::fmax((x + 0.5f) * o2i_fx - 0.5f, 0.0f)\n                        : x * o2i_fx;\n        auto in_y = half_pixel_centers\n                        ? sycl::fmax((y + 0.5f) * o2i_fy - 0.5f, 0.0f)\n                        : y * o2i_fy;\n\n        auto in_x0 = static_cast<int>(in_x);\n        auto in_x1 = sycl::min((int)(in_x0 + 1), (int)(in_width - 1));\n\n        auto in_y0 = static_cast<int>(in_y);\n\n        auto in_y1 = sycl::min(in_y0, (int)(in_height - 1));\n        auto in_y2 = sycl::min((int)(in_y0 + 1), (int)(in_height - 1));\n\n        int in_offset_r0 = c_start * in_image_size + in_y1 * in_width;\n        int in_offset_r1 = c_start * in_image_size + in_y2 * in_width;\n        int out_idx = c_start * out_image_size + y * out_width + x;\n\n        #pragma unroll 1 \n\n        for (auto c = c_start; c < c_end; c++) {\n            auto v_00 = input[in_offset_r0 + in_x0],\n                 v_01 = input[in_offset_r0 + in_x1],\n                 v_10 = input[in_offset_r1 + in_x0],\n                 v_11 = input[in_offset_r1 + in_x1];\n\n            output[out_idx] =\n                v_00 +\n                T(in_y - in_y0) * T(v_10 - v_00) +\n                T(in_x - in_x0) * T(v_01 - v_00) +\n                T(in_y - in_y0) * T(in_x - in_x0) * T(v_11 - v_01 - v_10 + v_00);\n\n            in_offset_r0 += in_image_size;\n            in_offset_r1 += in_image_size;\n            out_idx += out_image_size;\n        }\n    }\n}\n\ntemplate <class T>\nvoid resize_image (\n  sycl::queue &q,\n  const int in_width,\n  const int in_height,\n  const int out_width,\n  const int out_height,\n  const int num_channels,\n  const int repeat,\n  const bool bilinear = false)\n{\n  size_t in_image_size = (size_t)in_height * in_width;\n  size_t in_size = num_channels * in_image_size;\n  size_t in_size_bytes = sizeof(T) * in_size;\n\n  size_t out_image_size = (size_t)out_height * out_width;\n  size_t out_size = num_channels * out_image_size;\n  size_t out_size_bytes = sizeof(T) * out_size;\n\n  T* in_images_h = (T*) malloc (in_size_bytes);\n  T* out_images_h = (T*) malloc (out_size_bytes);\n\n  for(size_t i = 0; i < in_size; i++) in_images_h[i] = static_cast<T>((i+1) % 13);\n\n  T *in_images_d, *out_images_d;\n  in_images_d = (T *)sycl::malloc_device(in_size_bytes, q);\n  q.memcpy(in_images_d, in_images_h, in_size_bytes);\n\n  out_images_d = (T *)sycl::malloc_device(out_size_bytes, q);\n  q.memset(out_images_d, 0, out_size_bytes);\n\n  const float fx = in_width / out_width;\n  const float fy = in_height / out_height;\n\n  q.wait();\n\n  sycl::range<1> gws (29184 * 256);\n  sycl::range<1> lws (256);\n\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  if (bilinear) {\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for(\n          sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n          resize_bilinear<T, 8>(out_images_d, out_size, out_height,\n                                out_width, in_images_d, in_height,\n                                in_width, fx, fy, true,\n                                item);\n        });\n      });\n    }\n  } else {\n    for (int i = 0; i < repeat; i++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for(\n          sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n          resize<T, 8>(out_images_d, out_size, out_height,\n                       out_width, in_images_d, in_height,\n                       in_width, fx, fy, true, true,\n                       item);\n        });\n      });\n    }\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %lf (us)    Perf: %lf (GB/s)\\n\",\n         time * 1e-3 / repeat, (in_size_bytes + out_size_bytes) * repeat * 1.0 / time);\n\n  q.memcpy(out_images_h, out_images_d, out_size_bytes).wait();\n\n  sycl::free(in_images_d, q);\n  sycl::free(out_images_d, q);\n\n  free(in_images_h);\n  free(out_images_h);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 7) {\n    printf(\"Usage: %s <input image width> <input image height>\\n\", argv[0]);\n    printf(\"          <output image width> <output image height>\\n\");\n    printf(\"          <image channels> <repeat>\\n\");\n    return 1;\n  }\n\n  const int in_width = atoi(argv[1]);\n  const int in_height = atoi(argv[2]);\n  const int out_width = atoi(argv[3]);\n  const int out_height = atoi(argv[4]);\n  const int num_channels = atoi(argv[5]);\n  const int repeat = atoi(argv[6]);\n\n  printf(\"Resize %d images from (%d x %d) to (%d x %d)\\n\",\n          num_channels, in_width, in_height, out_width, out_height);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  printf(\"\\nThe size of each pixel is 1 byte\\n\");\n  resize_image<unsigned char>(q, in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned char>(q, in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 2 bytes\\n\");\n  resize_image<unsigned short>(q, in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned short>(q, in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  printf(\"\\nThe size of each pixel is 4 bytes\\n\");\n  resize_image<unsigned int>(q, in_width, in_height, out_width, out_height, num_channels, repeat);\n  printf(\"\\nBilinear resizing\\n\");\n  resize_image<unsigned int>(q, in_width, in_height, out_width, out_height, num_channels, repeat, true);\n\n  return 0;\n}\n"}}
{"kernel_name": "sad", "parallel_api": "cuda", "code": {"main.cu": "#include <iostream>\n#include <chrono>\n#include <cuda.h>\n#include \"bitmap_image.hpp\"\n\n#define check(stmt)                                          \\\n  do {                        \\\n    cudaError_t err = stmt;   \\\n    if (err != cudaSuccess) { \\\n      printf(\"[ERROR] Failed to run stmt %d, error body: %s\\n\", __LINE__, cudaGetErrorString(err));  \\\n      return -1; }            \\\n  } while (0)                 \\\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define FOUND_MIN     5000\n#define min(a, b) ((a) < (b) ? (a) : (b))\n\n__global__ void compute_sad_array(\n                    int*__restrict__ sad_array,\n    const unsigned char*__restrict__ image,\n    const unsigned char*__restrict__ kernel,\n    const int sad_array_size,\n    const int image_width,\n    const int image_height,\n    const int kernel_width,\n    const int kernel_height,\n    const int kernel_size)\n{\n  int col = blockIdx.x * blockDim.x + threadIdx.x;\n  int row = blockIdx.y * blockDim.y + threadIdx.y;\n  int sad_result = 0;\n\n  if (row < image_height && col < image_width) {\n    const int overlap_width = min(image_width - col, kernel_width);\n    const int overlap_height = min(image_height - row, kernel_height);\n    #pragma unroll 4\n    for (int kr = 0; kr < overlap_height; kr++) {\n      #pragma unroll 4\n      for (int kc = 0; kc < overlap_width; kc++) {\n        const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n        const int kernel_addr = (kr * kernel_width + kc) * 3;\n        const int m_r = (int)(image[image_addr + 0]);\n        const int m_g = (int)(image[image_addr + 1]);\n        const int m_b = (int)(image[image_addr + 2]);\n        const int t_r = (int)(kernel[kernel_addr + 0]);\n        const int t_g = (int)(kernel[kernel_addr + 1]);\n        const int t_b = (int)(kernel[kernel_addr + 2]);\n        const int error = abs(m_r - t_r) + abs(m_g - t_g) + abs(m_b - t_b);\n        sad_result += error;\n      }\n    }\n\n    int norm_sad = (int)(sad_result / (float)kernel_size);\n\n    int my_index_in_sad_array = row * image_width + col;\n    if (my_index_in_sad_array < sad_array_size) {\n      sad_array[my_index_in_sad_array] = norm_sad;\n    }\n  }\n}\n\n__global__ void find_min_in_sad_array(\n    const int sad_array_size,\n    const int* __restrict__ sad_array,\n          int* __restrict__ min_sad)\n{\n  unsigned int gid = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int stride = gridDim.x * blockDim.x;\n  unsigned int offset = 0;\n\n  __shared__ int cache[BLOCK_SIZE];\n\n  int temp = FOUND_MIN;\n  while (gid + offset < sad_array_size) {\n    temp = min(temp, sad_array[gid + offset]);\n    offset += stride;\n  }\n\n  cache[threadIdx.x] = temp;\n\n  __syncthreads();\n\n  unsigned int i = blockDim.x / 2;\n  while (i != 0) {\n    if (threadIdx.x < i)\n      cache[threadIdx.x] = min(cache[threadIdx.x], cache[threadIdx.x + i]);\n    __syncthreads();\n    i /= 2;\n  }\n\n  \n\n  if (threadIdx.x == 0)\n    atomicMin(min_sad, cache[0]);\n}\n\n__global__ void get_num_of_occurrences(\n    const int sad_array_size,\n    const int*__restrict__ sad_array,\n    const int*__restrict__ min_sad,\n          int*__restrict__ num_occurrences)\n{\n  unsigned int gid = threadIdx.x + blockIdx.x * blockDim.x;\n\n  __shared__ int s;\n\n  if (gid < sad_array_size) {\n\n    if (threadIdx.x == 0) s = 0;\n\n    __syncthreads();\n\n    if (sad_array[gid] == *min_sad)\n      atomicAdd(&s, 1);\n\n    __syncthreads();\n\n    \n\n    if (threadIdx.x == 0)\n      atomicAdd(num_occurrences, s);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n\n  \n\n  unsigned char* d_main_image;\n  unsigned char* d_template_image;\n  int* d_sad_array;\n  int* d_min_mse;\n  int* d_num_occurances;\n\n  check(cudaMalloc((void **)&d_main_image, 3 * main_size * sizeof(unsigned char)));\n  check(cudaMalloc((void **)&d_template_image, 3 * template_size * sizeof(unsigned char)));\n  check(cudaMalloc((void **)&d_sad_array, sad_array_size * sizeof(int)));\n  check(cudaMalloc((void **)&d_min_mse, sizeof(int)));\n  check(cudaMalloc((void **)&d_num_occurances, sizeof(int)));\n\n  dim3 grids((unsigned int)ceilf((float)main_width / BLOCK_SIZE_X),\n             (unsigned int)ceilf((float)main_height / BLOCK_SIZE_Y));\n  dim3 blocks(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n\n  dim3 grids_2((unsigned int)ceilf((float)sad_array_size / BLOCK_SIZE));\n  dim3 blocks_2(BLOCK_SIZE);\n\n  check(cudaMemcpy(d_main_image, h_main_image,\n                   3 * main_size * sizeof(unsigned char), cudaMemcpyHostToDevice));\n  check(cudaMemcpy(d_template_image, h_template_image,\n                   3 * template_size * sizeof(unsigned char), cudaMemcpyHostToDevice));\n\n  \n\n  double kernel_time = 0.0;\n\n  auto begin = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n\n    h_min_mse = THRESHOLD;\n    check(cudaMemset(d_num_occurances, 0, sizeof(int)));\n    check(cudaMemcpy(d_min_mse, &h_min_mse, sizeof(int), cudaMemcpyHostToDevice));\n\n    cudaDeviceSynchronize();\n    auto kbegin = std::chrono::steady_clock::now();\n\n    compute_sad_array <<< grids, blocks >>> (\n        d_sad_array, d_main_image, d_template_image, sad_array_size, \n        main_width, main_height, template_width, template_height, template_size);\n\n    find_min_in_sad_array <<< grids_2, blocks_2 >>> (\n        sad_array_size, d_sad_array, d_min_mse);\n\n    get_num_of_occurrences <<< grids_2, blocks_2 >>> (\n        sad_array_size, d_sad_array, d_min_mse, d_num_occurances);\n\n    cudaDeviceSynchronize();\n    auto kend = std::chrono::steady_clock::now();\n    kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n    check(cudaMemcpy(&h_min_mse, d_min_mse, sizeof(int), cudaMemcpyDeviceToHost));\n    check(cudaMemcpy(&h_num_occurances, d_num_occurances, sizeof(int), cudaMemcpyDeviceToHost));\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  float elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n  std::cout << \"Parallel Computation Results: \" << std::endl;\n  std::cout << \"Kernel time in msec: \" << kernel_time << std::endl; \n  std::cout << \"Elapsed time in msec: \" << elapsed_time << std::endl; \n  std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n  std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n  std::cout << \"Found Minimum: \" << h_min_mse << std::endl;\n  std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n\n  check(cudaFree(d_main_image));\n  check(cudaFree(d_template_image));\n  check(cudaFree(d_sad_array));\n  check(cudaFree(d_min_mse));\n  check(cudaFree(d_num_occurances));\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}\n"}}
{"kernel_name": "sad", "parallel_api": "hip", "code": {"main.cu": "#include <iostream>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"bitmap_image.hpp\"\n\n#define check(stmt)                                          \\\n  do {                        \\\n    hipError_t err = stmt;   \\\n    if (err != hipSuccess) { \\\n      printf(\"[ERROR] Failed to run stmt %d, error body: %s\\n\", __LINE__, hipGetErrorString(err));  \\\n      return -1; }            \\\n  } while (0)                 \\\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define FOUND_MIN     5000\n#define min(a, b) ((a) < (b) ? (a) : (b))\n\n__global__ void compute_sad_array(\n                    int*__restrict__ sad_array,\n    const unsigned char*__restrict__ image,\n    const unsigned char*__restrict__ kernel,\n    const int sad_array_size,\n    const int image_width,\n    const int image_height,\n    const int kernel_width,\n    const int kernel_height,\n    const int kernel_size)\n{\n  int col = blockIdx.x * blockDim.x + threadIdx.x;\n  int row = blockIdx.y * blockDim.y + threadIdx.y;\n  int sad_result = 0;\n\n  if (row < image_height && col < image_width) {\n    const int overlap_width = min(image_width - col, kernel_width);\n    const int overlap_height = min(image_height - row, kernel_height);\n    #pragma unroll 4\n    for (int kr = 0; kr < overlap_height; kr++) {\n      #pragma unroll 4\n      for (int kc = 0; kc < overlap_width; kc++) {\n        const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n        const int kernel_addr = (kr * kernel_width + kc) * 3;\n        const int m_r = (int)(image[image_addr + 0]);\n        const int m_g = (int)(image[image_addr + 1]);\n        const int m_b = (int)(image[image_addr + 2]);\n        const int t_r = (int)(kernel[kernel_addr + 0]);\n        const int t_g = (int)(kernel[kernel_addr + 1]);\n        const int t_b = (int)(kernel[kernel_addr + 2]);\n        const int error = abs(m_r - t_r) + abs(m_g - t_g) + abs(m_b - t_b);\n        sad_result += error;\n      }\n    }\n\n    int norm_sad = (int)(sad_result / (float)kernel_size);\n\n    int my_index_in_sad_array = row * image_width + col;\n    if (my_index_in_sad_array < sad_array_size) {\n      sad_array[my_index_in_sad_array] = norm_sad;\n    }\n  }\n}\n\n__global__ void find_min_in_sad_array(\n    const int sad_array_size,\n    const int* __restrict__ sad_array,\n          int* __restrict__ min_sad)\n{\n  unsigned int gid = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int stride = gridDim.x * blockDim.x;\n  unsigned int offset = 0;\n\n  __shared__ int cache[BLOCK_SIZE];\n\n  int temp = FOUND_MIN;\n  while (gid + offset < sad_array_size) {\n    temp = min(temp, sad_array[gid + offset]);\n    offset += stride;\n  }\n\n  cache[threadIdx.x] = temp;\n\n  __syncthreads();\n\n  unsigned int i = blockDim.x / 2;\n  while (i != 0) {\n    if (threadIdx.x < i)\n      cache[threadIdx.x] = min(cache[threadIdx.x], cache[threadIdx.x + i]);\n    __syncthreads();\n    i /= 2;\n  }\n\n  \n\n  if (threadIdx.x == 0)\n    atomicMin(min_sad, cache[0]);\n}\n\n__global__ void get_num_of_occurrences(\n    const int sad_array_size,\n    const int*__restrict__ sad_array,\n    const int*__restrict__ min_sad,\n          int*__restrict__ num_occurrences)\n{\n  unsigned int gid = threadIdx.x + blockIdx.x * blockDim.x;\n\n  __shared__ int s;\n\n  if (gid < sad_array_size) {\n\n    if (threadIdx.x == 0) s = 0;\n\n    __syncthreads();\n\n    if (sad_array[gid] == *min_sad)\n      atomicAdd(&s, 1);\n\n    __syncthreads();\n\n    \n\n    if (threadIdx.x == 0)\n      atomicAdd(num_occurrences, s);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n\n  \n\n  unsigned char* d_main_image;\n  unsigned char* d_template_image;\n  int* d_sad_array;\n  int* d_min_mse;\n  int* d_num_occurances;\n\n  check(hipMalloc((void **)&d_main_image, 3 * main_size * sizeof(unsigned char)));\n  check(hipMalloc((void **)&d_template_image, 3 * template_size * sizeof(unsigned char)));\n  check(hipMalloc((void **)&d_sad_array, sad_array_size * sizeof(int)));\n  check(hipMalloc((void **)&d_min_mse, sizeof(int)));\n  check(hipMalloc((void **)&d_num_occurances, sizeof(int)));\n\n  dim3 grids((unsigned int)ceilf((float)main_width / BLOCK_SIZE_X),\n             (unsigned int)ceilf((float)main_height / BLOCK_SIZE_Y));\n  dim3 blocks(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n\n  dim3 grids_2((unsigned int)ceilf((float)sad_array_size / BLOCK_SIZE));\n  dim3 blocks_2(BLOCK_SIZE);\n\n  check(hipMemcpy(d_main_image, h_main_image,\n                   3 * main_size * sizeof(unsigned char), hipMemcpyHostToDevice));\n  check(hipMemcpy(d_template_image, h_template_image,\n                   3 * template_size * sizeof(unsigned char), hipMemcpyHostToDevice));\n\n  \n\n  double kernel_time = 0.0;\n\n  auto begin = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n\n    h_min_mse = THRESHOLD;\n    check(hipMemset(d_num_occurances, 0, sizeof(int)));\n    check(hipMemcpy(d_min_mse, &h_min_mse, sizeof(int), hipMemcpyHostToDevice));\n\n    hipDeviceSynchronize();\n    auto kbegin = std::chrono::steady_clock::now();\n\n    hipLaunchKernelGGL(compute_sad_array, grids, blocks , 0, 0, \n        d_sad_array, d_main_image, d_template_image, sad_array_size, \n        main_width, main_height, template_width, template_height, template_size);\n\n    hipLaunchKernelGGL(find_min_in_sad_array, grids_2, blocks_2 , 0, 0, \n        sad_array_size, d_sad_array, d_min_mse);\n\n    hipLaunchKernelGGL(get_num_of_occurrences, grids_2, blocks_2 , 0, 0, \n        sad_array_size, d_sad_array, d_min_mse, d_num_occurances);\n\n    hipDeviceSynchronize();\n    auto kend = std::chrono::steady_clock::now();\n    kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n    check(hipMemcpy(&h_min_mse, d_min_mse, sizeof(int), hipMemcpyDeviceToHost));\n    check(hipMemcpy(&h_num_occurances, d_num_occurances, sizeof(int), hipMemcpyDeviceToHost));\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  float elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n  std::cout << \"Parallel Computation Results: \" << std::endl;\n  std::cout << \"Kernel time in msec: \" << kernel_time << std::endl; \n  std::cout << \"Elapsed time in msec: \" << elapsed_time << std::endl; \n  std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n  std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n  std::cout << \"Found Minimum: \" << h_min_mse << std::endl;\n  std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n\n  check(hipFree(d_main_image));\n  check(hipFree(d_template_image));\n  check(hipFree(d_sad_array));\n  check(hipFree(d_min_mse));\n  check(hipFree(d_num_occurances));\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}\n"}}
{"kernel_name": "sad", "parallel_api": "omp", "code": {"main.cpp": "#include <iostream>\n#include <chrono>\n#include <omp.h>\n#include \"bitmap_image.hpp\"\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define min(a, b) ((a) < (b) ? (a) : (b))\n\nvoid compute_sad_array(\n                    int*__restrict sad_array,\n    const unsigned char*__restrict image,\n    const unsigned char*__restrict kernel,\n    int sad_array_size,\n    int& min_mse,\n    int& num_occurrences,\n    int image_width, int image_height,\n    int kernel_width, int kernel_height,\n    int kernel_size,\n    double &kernel_time)\n{\n  auto kbegin = std::chrono::steady_clock::now();\n\n  #pragma omp target teams distribute parallel for collapse(2) thread_limit(BLOCK_SIZE)\n  for (int row = 0; row < image_height; row++) {\n    for (int col = 0; col < image_width; col++) {\n      int sad_result = 0;\n      const int overlap_width = min(image_width - col, kernel_width);\n      const int overlap_height = min(image_height - row, kernel_height);\n      #pragma unroll 4\n      for (int kr = 0; kr < overlap_height; kr++) {\n        #pragma unroll 4\n        for (int kc = 0; kc < overlap_width; kc++) {\n          const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n          const int kernel_addr = (kr * kernel_width + kc) * 3;\n          const int m_r = (int)(image[image_addr + 0]);\n          const int m_g = (int)(image[image_addr + 1]);\n          const int m_b = (int)(image[image_addr + 2]);\n          const int t_r = (int)(kernel[kernel_addr + 0]);\n          const int t_g = (int)(kernel[kernel_addr + 1]);\n          const int t_b = (int)(kernel[kernel_addr + 2]);\n          const int error = abs(m_r - t_r) + abs(m_g - t_g) + abs(m_b - t_b);\n          sad_result += error;\n        }\n      }\n\n      int norm_sad = (int)(sad_result / (float)kernel_size);\n\n      int my_index_in_sad_array = row * image_width + col;\n      if (my_index_in_sad_array < sad_array_size) {\n        sad_array[my_index_in_sad_array] = norm_sad;\n      }\n    }\n  }\n\n  int m = THRESHOLD;\n  #pragma omp target teams distribute parallel for thread_limit(256) \\\n    map(tofrom: m) reduction(min: m)\n  for (int i = 0; i < sad_array_size; i++) \n    m = min(m, sad_array[i]);\n\n  int n = 0; \n  #pragma omp target teams distribute parallel for thread_limit(256) \\\n    map(tofrom: n) reduction(+: n)\n  for (int i = 0; i < sad_array_size; i++) {\n    if (sad_array[i] == m) n++;\n  }\n\n  auto kend = std::chrono::steady_clock::now();\n  kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n  min_mse = m;\n  num_occurrences = n;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n  float elapsed_time; \n\n  #pragma omp target data map(to: h_main_image[0:3*main_size],\\\n                                  h_template_image[0:3*template_size]) \\\n                          map(alloc: h_sad_array[0:sad_array_size])\n  {\n    \n\n    double kernel_time = 0.0;\n\n    auto begin = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n\n      compute_sad_array(\n          h_sad_array, h_main_image, h_template_image, sad_array_size, \n          h_min_mse, h_num_occurances,\n          main_width, main_height,\n          template_width, template_height, template_size,\n          kernel_time);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n    std::cout << \"Parallel Computation Results: \" << std::endl;\n    std::cout << \"Kernel time in msec: \" << kernel_time << std::endl; \n    std::cout << \"Elapsed time in msec = \" << elapsed_time << std::endl; \n    std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n    std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n    std::cout << \"Found Minimum:  \" << h_min_mse << std::endl;\n    std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n  }\n\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}\n"}}
{"kernel_name": "sad", "parallel_api": "serial", "code": {"main.cpp": "#include <iostream>\n#include <chrono>\n#include \"bitmap_image.hpp\"\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define min(a, b) ((a) < (b) ? (a) : (b))\n\nvoid compute_sad_array(\n                    int*__restrict sad_array,\n    const unsigned char*__restrict image,\n    const unsigned char*__restrict kernel,\n    int sad_array_size,\n    int& min_mse,\n    int& num_occurrences,\n    int image_width, int image_height,\n    int kernel_width, int kernel_height,\n    int kernel_size,\n    double &kernel_time)\n{\n  auto kbegin = std::chrono::steady_clock::now();\n\n    for (int row = 0; row < image_height; row++) {\n    for (int col = 0; col < image_width; col++) {\n      int sad_result = 0;\n      const int overlap_width = min(image_width - col, kernel_width);\n      const int overlap_height = min(image_height - row, kernel_height);\n            for (int kr = 0; kr < overlap_height; kr++) {\n                for (int kc = 0; kc < overlap_width; kc++) {\n          const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n          const int kernel_addr = (kr * kernel_width + kc) * 3;\n          const int m_r = (int)(image[image_addr + 0]);\n          const int m_g = (int)(image[image_addr + 1]);\n          const int m_b = (int)(image[image_addr + 2]);\n          const int t_r = (int)(kernel[kernel_addr + 0]);\n          const int t_g = (int)(kernel[kernel_addr + 1]);\n          const int t_b = (int)(kernel[kernel_addr + 2]);\n          const int error = abs(m_r - t_r) + abs(m_g - t_g) + abs(m_b - t_b);\n          sad_result += error;\n        }\n      }\n\n      int norm_sad = (int)(sad_result / (float)kernel_size);\n\n      int my_index_in_sad_array = row * image_width + col;\n      if (my_index_in_sad_array < sad_array_size) {\n        sad_array[my_index_in_sad_array] = norm_sad;\n      }\n    }\n  }\n\n  int m = THRESHOLD;\n    for (int i = 0; i < sad_array_size; i++) \n    m = min(m, sad_array[i]);\n\n  int n = 0; \n    for (int i = 0; i < sad_array_size; i++) {\n    if (sad_array[i] == m) n++;\n  }\n\n  auto kend = std::chrono::steady_clock::now();\n  kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n  min_mse = m;\n  num_occurrences = n;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n  float elapsed_time; \n\n    {\n    \n\n    double kernel_time = 0.0;\n\n    auto begin = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n\n      compute_sad_array(\n          h_sad_array, h_main_image, h_template_image, sad_array_size, \n          h_min_mse, h_num_occurances,\n          main_width, main_height,\n          template_width, template_height, template_size,\n          kernel_time);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n    std::cout << \"Parallel Computation Results: \" << std::endl;\n    std::cout << \"Kernel time in msec: \" << kernel_time << std::endl; \n    std::cout << \"Elapsed time in msec = \" << elapsed_time << std::endl; \n    std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n    std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n    std::cout << \"Found Minimum:  \" << h_min_mse << std::endl;\n    std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n  }\n\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}"}}
{"kernel_name": "sad", "parallel_api": "sycl", "code": {"main.cpp": "#include <iostream>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"bitmap_image.hpp\"\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define FOUND_MIN     5000\n#define min(a, b) ((a) < (b) ? (a) : (b))\n#define syncthreads() item.barrier(sycl::access::fence_space::local_space)\n\nvoid compute_sad_array(\n    sycl::nd_item<2> &item,\n                    int*__restrict sad_array,\n    const unsigned char*__restrict image,\n    const unsigned char*__restrict kernel,\n    const int sad_array_size,\n    const int image_width,\n    const int image_height,\n    const int kernel_width,\n    const int kernel_height,\n    const int kernel_size)\n{\n  int col = item.get_global_id(1);\n  int row = item.get_global_id(0);\n  int sad_result = 0;\n\n  if (row < image_height && col < image_width) {\n    const int overlap_width = min(image_width - col, kernel_width);\n    const int overlap_height = min(image_height - row, kernel_height);\n    #pragma unroll 4\n    for (int kr = 0; kr < overlap_height; kr++) {\n      #pragma unroll 4\n      for (int kc = 0; kc < overlap_width; kc++) {\n        const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n        const int kernel_addr = (kr * kernel_width + kc) * 3;\n        const int m_r = (int)(image[image_addr + 0]);\n        const int m_g = (int)(image[image_addr + 1]);\n        const int m_b = (int)(image[image_addr + 2]);\n        const int t_r = (int)(kernel[kernel_addr + 0]);\n        const int t_g = (int)(kernel[kernel_addr + 1]);\n        const int t_b = (int)(kernel[kernel_addr + 2]);\n        const int error = sycl::abs(m_r - t_r) + sycl::abs(m_g - t_g) + sycl::abs(m_b - t_b);\n        sad_result += error;\n      }\n    }\n\n    int norm_sad = (int)(sad_result / (float)kernel_size);\n\n    int my_index_in_sad_array = row * image_width + col;\n    if (my_index_in_sad_array < sad_array_size) {\n      sad_array[my_index_in_sad_array] = norm_sad;\n    }\n  }\n}\n\n\nvoid find_min_in_sad_array(\n    sycl::nd_item<1> &item,\n    const int sad_array_size,\n          int* __restrict cache,\n    const int* __restrict sad_array,\n          int* __restrict min_sad)\n{\n  unsigned int lid = item.get_local_id(0);\n  unsigned int bsz = item.get_local_range(0);\n  unsigned int gid = item.get_group(0) * bsz + lid;\n  unsigned int stride = item.get_group_range(0) * bsz;\n  unsigned int offset = 0;\n\n  int temp = FOUND_MIN;\n  while (gid + offset < sad_array_size) {\n    temp = min(temp, sad_array[gid + offset]);\n    offset += stride;\n  }\n\n  cache[lid] = temp;\n\n  syncthreads();\n\n  unsigned int i = bsz / 2;\n  while (i != 0) {\n    if (lid < i)\n      cache[lid] = min(cache[lid], cache[lid + i]);\n    syncthreads();\n    i /= 2;\n  }\n\n  \n\n  if (lid == 0) {\n    \n\n    auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (min_sad[0]);\n    ao.fetch_min(cache[0]);\n  }\n}\n\nvoid get_num_of_occurrences(\n    sycl::nd_item<1> &item,\n    const int sad_array_size,\n          int &s,\n    const int*__restrict sad_array,\n    const int*__restrict min_sad,\n          int*__restrict num_occurrences)\n{\n  unsigned int gid = item.get_global_id(0);\n\n  if (gid < sad_array_size) {\n    unsigned int lid = item.get_local_id(0);\n\n    if (lid == 0) s = 0;\n\n    syncthreads();\n\n    if (sad_array[gid] == *min_sad) {\n      \n\n      auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (s);\n      ao.fetch_add(1);\n    }\n\n    syncthreads();\n\n    \n\n    if (lid == 0) {\n      \n\n      auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (num_occurrences[0]);\n      ao.fetch_add(s);\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  unsigned char *d_main_image = sycl::malloc_device<unsigned char>(3 * main_size, q);\n  q.memcpy(d_main_image, h_main_image, 3 * main_size * sizeof(unsigned char));\n\n  unsigned char *d_template_image = sycl::malloc_device<unsigned char>(3 * template_size, q);\n  q.memcpy(d_template_image, h_template_image, 3 * template_size * sizeof(unsigned char));\n\n  int *d_sad_array = sycl::malloc_device<int>(sad_array_size, q);\n  int *d_min_mse = sycl::malloc_device<int>(1, q);\n  int *d_num_occurances = sycl::malloc_device<int>(1, q);\n\n  sycl::range<2> gws ((unsigned int)ceilf((float)main_height / BLOCK_SIZE_Y) * BLOCK_SIZE_Y,\n                      (unsigned int)ceilf((float)main_width / BLOCK_SIZE_X) * BLOCK_SIZE_X );\n  sycl::range<2> lws (BLOCK_SIZE_Y, BLOCK_SIZE_X);\n\n  sycl::range<1> gws2 ((unsigned int)ceilf((float)sad_array_size / BLOCK_SIZE) * BLOCK_SIZE);\n  sycl::range<1> lws2 (BLOCK_SIZE);\n\n  \n\n  double kernel_time = 0.0;\n\n  auto begin = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n\n    h_min_mse = THRESHOLD;\n\n    q.memset(d_num_occurances, 0, sizeof(int));\n    q.memcpy(d_min_mse, &h_min_mse, sizeof(int));\n\n    q.wait();\n    auto kbegin = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class sad>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        compute_sad_array (\n          item,\n          d_sad_array,\n          d_main_image,\n          d_template_image,\n          sad_array_size,\n          main_width, main_height,\n          template_width, template_height,\n          template_size);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<int> cache (lws2, cgh);\n      cgh.parallel_for<class find_min>(\n        sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n        find_min_in_sad_array (\n          item,\n          sad_array_size,\n          cache.get_pointer(),\n          d_sad_array,\n          d_min_mse);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<int, 0> sum (cgh);\n      cgh.parallel_for<class count>(\n        sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n        get_num_of_occurrences (\n          item,\n          sad_array_size,\n          sum,\n          d_sad_array,\n          d_min_mse,\n          d_num_occurances);\n      });\n    });\n\n    q.wait();\n    auto kend = std::chrono::steady_clock::now();\n    kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n    q.memcpy(&h_min_mse, d_min_mse, sizeof(int));\n    q.memcpy(&h_num_occurances, d_num_occurances, sizeof(int));\n  }\n  q.wait();\n\n  auto end = std::chrono::steady_clock::now();\n  float elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n  std::cout << \"Parallel Computation Results: \" << std::endl;\n  std::cout << \"Kernel time in msec: \" << kernel_time << std::endl;\n  std::cout << \"Elapsed time in msec = \" << elapsed_time << std::endl;\n  std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n  std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n  std::cout << \"Found Minimum:  \" << h_min_mse << std::endl;\n  std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n\n  sycl::free(d_main_image, q);\n  sycl::free(d_template_image, q);\n  sycl::free(d_sad_array, q);\n  sycl::free(d_min_mse, q);\n  sycl::free(d_num_occurances, q);\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}\n"}}
{"kernel_name": "spm", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <stdbool.h>\n#include <string.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <cuda.h>\n\n#define NUM_THREADS 128\n#define NUM_BLOCKS 256\n\n\n\n\n__host__ __device__ \nfloat interp(const int3 d, const unsigned char f[], float x, float y, float z)\n{\n  int ix, iy, iz;\n  float dx1, dy1, dz1, dx2, dy2, dz2;\n  int k111,k112,k121,k122,k211,k212,k221,k222;\n  float vf;\n  const unsigned char *ff;\n\n  ix = floorf(x); dx1=x-ix; dx2=1.f-dx1;\n  iy = floorf(y); dy1=y-iy; dy2=1.f-dy1;\n  iz = floorf(z); dz1=z-iz; dz2=1.f-dz1;\n\n  ff   = f + ix-1+d.x*(iy-1+d.y*(iz-1));\n  k222 = ff[   0]; k122 = ff[     1];\n  k212 = ff[d.x]; k112 = ff[d.x+1];\n  ff  += d.x*d.y;\n  k221 = ff[   0]; k121 = ff[     1];\n  k211 = ff[d.x]; k111 = ff[d.x+1];\n\n  vf = (((k222*dx2+k122*dx1)*dy2 + (k212*dx2+k112*dx1)*dy1))*dz2 +\n       (((k221*dx2+k121*dx1)*dy2 + (k211*dx2+k111*dx1)*dy1))*dz1;\n\n  return(vf);\n}\n\n__global__ void spm (\n  const float *__restrict__ M, \n  const int data_size,\n  const unsigned char *__restrict__ g_d,\n  const unsigned char *__restrict__ f_d,\n  const int3 dg,\n  const int3 df,\n  unsigned char *__restrict__ ivf_d,\n  unsigned char *__restrict__ ivg_d,\n  bool *__restrict__ data_threshold_d)\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n  \n  const int idx = blockIdx.x * NUM_THREADS + threadIdx.x;\n\n  int x_datasize=(dg.x-2);\n  int y_datasize=(dg.y-2);\n\n  for(int i = idx; i < data_size; i += NUM_THREADS*NUM_BLOCKS)\n  {\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp>=1.f && zp<df.z && yp>=1.f && yp<df.y && xp>=1.f && xp<df.x)\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nvoid spm_reference (\n  const float *M, \n  const int data_size,\n  const unsigned char *g_d,\n  const unsigned char *f_d,\n  const int3 dg,\n  const int3 df,\n  unsigned char *ivf_d,\n  unsigned char *ivg_d,\n  bool *data_threshold_d)\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n  \n  int x_datasize=(dg.x-2);\n  int y_datasize=(dg.y-2);\n\n  for(int i = 0; i < data_size; i++)\n  {\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp>=1.f && zp<df.z && yp>=1.f && yp<df.y && xp>=1.f && xp<df.x)\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int v = atoi(argv[1]);\n  int repeat = atoi(argv[2]);\n\n  int3 g_vol = {v,v,v};\n  int3 f_vol = {v,v,v};\n\n  const int data_size = (g_vol.x+1) * (g_vol.y+1) * (g_vol.z+5);\n  const int vol_size = g_vol.x * g_vol.y * g_vol.z;\n\n  int *hist_d = (int*) malloc (65536*sizeof(int));\n  int *hist_h = (int*) malloc (65536*sizeof(int));\n  memset(hist_d, 0, sizeof(int)*65536); \n  memset(hist_h, 0, sizeof(int)*65536); \n\n  unsigned char *ivf_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n  unsigned char *ivg_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n  bool *data_threshold_h = (bool *)malloc(vol_size*sizeof(bool));\n\n  srand(123);\n\n  float M_h[16];\n  for (int i = 0; i < 16; i++) M_h[i] = (float)rand() / (float)RAND_MAX;\n\n  float *M_d;\n  cudaMalloc((void**)&M_d,16*sizeof(float));\n  cudaMemcpy(M_d,M_h,16*sizeof(float),cudaMemcpyHostToDevice);\n\n  unsigned char* g_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  unsigned char* f_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  for (int i = 0; i < data_size; i++) {\n    g_h[i] = rand() % 256;\n    f_h[i] = rand() % 256;\n  }\n\n  unsigned char *g_d, *f_d;\n  cudaMalloc((void**)&g_d, data_size * sizeof(unsigned char));\n  cudaMalloc((void**)&f_d, data_size * sizeof(unsigned char));\n\n  cudaMemcpy(g_d, g_h, data_size*sizeof(unsigned char), cudaMemcpyHostToDevice);\n  cudaMemcpy(f_d, f_h, data_size*sizeof(unsigned char), cudaMemcpyHostToDevice);\n\n  unsigned char *ivf_d, *ivg_d;\n  cudaMalloc((void**)&ivf_d,vol_size*sizeof(unsigned char));\n  cudaMalloc((void**)&ivg_d,vol_size*sizeof(unsigned char));\n\n  bool *data_threshold_d;\n  cudaMalloc((void**)&data_threshold_d,vol_size*sizeof(bool));\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    spm<<<NUM_BLOCKS,NUM_THREADS>>>(M_d, vol_size, g_d, f_d, g_vol, f_vol,\n                                    ivf_d,ivg_d,data_threshold_d);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(ivf_h,ivf_d,vol_size*sizeof(unsigned char),cudaMemcpyDeviceToHost);\n  cudaMemcpy(ivg_h,ivg_d,vol_size*sizeof(unsigned char),cudaMemcpyDeviceToHost);\n  cudaMemcpy(data_threshold_h,data_threshold_d,vol_size*sizeof(bool),cudaMemcpyDeviceToHost);\n\n  int count = 0;\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_d[ivf_h[i]+ivg_h[i]*256] += 1;    \n      count++;\n    }\n  }\n  printf(\"Device count: %d\\n\", count);\n\n  count = 0;\n  spm_reference(M_h, vol_size, g_h, f_h, g_vol, f_vol, ivf_h, ivg_h, data_threshold_h);\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_h[ivf_h[i]+ivg_h[i]*256] += 1;    \n      count++;\n    }\n  }\n  printf(\"Host count: %d\\n\", count);\n\n  int max_diff = 0;\n  for(int i = 0; i < 65536; i++) {\n    if (hist_h[i] != hist_d[i]) {\n      max_diff = std::max(max_diff, abs(hist_h[i] - hist_d[i]));\n    }\n  }\n  printf(\"Maximum difference %d\\n\", max_diff);\n\n  free(hist_h);\n  free(hist_d);\n  free(ivf_h);\n  free(ivg_h);\n  free(g_h);\n  free(f_h);\n  free(data_threshold_h);\n  cudaFree(M_d);\n  cudaFree(g_d);\n  cudaFree(f_d);\n  cudaFree(ivf_d);\n  cudaFree(ivg_d);\n  cudaFree(data_threshold_d);\n\n  return 0;\n}\n"}}
{"kernel_name": "spm", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <stdbool.h>\n#include <string.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define NUM_THREADS 128\n#define NUM_BLOCKS 256\n\n\n\n\n__host__ __device__ \nfloat interp(const int3 d, const unsigned char f[], float x, float y, float z)\n{\n  int ix, iy, iz;\n  float dx1, dy1, dz1, dx2, dy2, dz2;\n  int k111,k112,k121,k122,k211,k212,k221,k222;\n  float vf;\n  const unsigned char *ff;\n\n  ix = floorf(x); dx1=x-ix; dx2=1.f-dx1;\n  iy = floorf(y); dy1=y-iy; dy2=1.f-dy1;\n  iz = floorf(z); dz1=z-iz; dz2=1.f-dz1;\n\n  ff   = f + ix-1+d.x*(iy-1+d.y*(iz-1));\n  k222 = ff[   0]; k122 = ff[     1];\n  k212 = ff[d.x]; k112 = ff[d.x+1];\n  ff  += d.x*d.y;\n  k221 = ff[   0]; k121 = ff[     1];\n  k211 = ff[d.x]; k111 = ff[d.x+1];\n\n  vf = (((k222*dx2+k122*dx1)*dy2 + (k212*dx2+k112*dx1)*dy1))*dz2 +\n       (((k221*dx2+k121*dx1)*dy2 + (k211*dx2+k111*dx1)*dy1))*dz1;\n\n  return(vf);\n}\n\n__global__ void spm (\n  const float *__restrict__ M, \n  const int data_size,\n  const unsigned char *__restrict__ g_d,\n  const unsigned char *__restrict__ f_d,\n  const int3 dg,\n  const int3 df,\n  unsigned char *__restrict__ ivf_d,\n  unsigned char *__restrict__ ivg_d,\n  bool *__restrict__ data_threshold_d)\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n  \n  const int idx = blockIdx.x * NUM_THREADS + threadIdx.x;\n\n  int x_datasize=(dg.x-2);\n  int y_datasize=(dg.y-2);\n\n  for(int i = idx; i < data_size; i += NUM_THREADS*NUM_BLOCKS)\n  {\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp>=1.f && zp<df.z && yp>=1.f && yp<df.y && xp>=1.f && xp<df.x)\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nvoid spm_reference (\n  const float *M, \n  const int data_size,\n  const unsigned char *g_d,\n  const unsigned char *f_d,\n  const int3 dg,\n  const int3 df,\n  unsigned char *ivf_d,\n  unsigned char *ivg_d,\n  bool *data_threshold_d)\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n  \n  int x_datasize=(dg.x-2);\n  int y_datasize=(dg.y-2);\n\n  for(int i = 0; i < data_size; i++)\n  {\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp>=1.f && zp<df.z && yp>=1.f && yp<df.y && xp>=1.f && xp<df.x)\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int v = atoi(argv[1]);\n  int repeat = atoi(argv[2]);\n\n  int3 g_vol = {v,v,v};\n  int3 f_vol = {v,v,v};\n\n  const int data_size = (g_vol.x+1) * (g_vol.y+1) * (g_vol.z+5);\n  const int vol_size = g_vol.x * g_vol.y * g_vol.z;\n\n  int *hist_d = (int*) malloc (65536*sizeof(int));\n  int *hist_h = (int*) malloc (65536*sizeof(int));\n  memset(hist_d, 0, sizeof(int)*65536); \n  memset(hist_h, 0, sizeof(int)*65536); \n\n  unsigned char *ivf_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n  unsigned char *ivg_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n  bool *data_threshold_h = (bool *)malloc(vol_size*sizeof(bool));\n\n  srand(123);\n\n  float M_h[16];\n  for (int i = 0; i < 16; i++) M_h[i] = (float)rand() / (float)RAND_MAX;\n\n  float *M_d;\n  hipMalloc((void**)&M_d,16*sizeof(float));\n  hipMemcpy(M_d,M_h,16*sizeof(float),hipMemcpyHostToDevice);\n\n  unsigned char* g_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  unsigned char* f_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  for (int i = 0; i < data_size; i++) {\n    g_h[i] = rand() % 256;\n    f_h[i] = rand() % 256;\n  }\n\n  unsigned char *g_d, *f_d;\n  hipMalloc((void**)&g_d, data_size * sizeof(unsigned char));\n  hipMalloc((void**)&f_d, data_size * sizeof(unsigned char));\n\n  hipMemcpy(g_d, g_h, data_size*sizeof(unsigned char), hipMemcpyHostToDevice);\n  hipMemcpy(f_d, f_h, data_size*sizeof(unsigned char), hipMemcpyHostToDevice);\n\n  unsigned char *ivf_d, *ivg_d;\n  hipMalloc((void**)&ivf_d,vol_size*sizeof(unsigned char));\n  hipMalloc((void**)&ivg_d,vol_size*sizeof(unsigned char));\n\n  bool *data_threshold_d;\n  hipMalloc((void**)&data_threshold_d,vol_size*sizeof(bool));\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(spm, NUM_BLOCKS, NUM_THREADS, 0, 0, M_d, vol_size, g_d, f_d, g_vol, f_vol,\n                       ivf_d,ivg_d,data_threshold_d);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(ivf_h,ivf_d,vol_size*sizeof(unsigned char),hipMemcpyDeviceToHost);\n  hipMemcpy(ivg_h,ivg_d,vol_size*sizeof(unsigned char),hipMemcpyDeviceToHost);\n  hipMemcpy(data_threshold_h,data_threshold_d,vol_size*sizeof(bool),hipMemcpyDeviceToHost);\n\n  int count = 0;\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_d[ivf_h[i]+ivg_h[i]*256] += 1;    \n      count++;\n    }\n  }\n  printf(\"Device count: %d\\n\", count);\n\n  count = 0;\n  spm_reference(M_h, vol_size, g_h, f_h, g_vol, f_vol, ivf_h, ivg_h, data_threshold_h);\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_h[ivf_h[i]+ivg_h[i]*256] += 1;    \n      count++;\n    }\n  }\n  printf(\"Host count: %d\\n\", count);\n\n  int max_diff = 0;\n  for(int i = 0; i < 65536; i++) {\n    if (hist_h[i] != hist_d[i]) {\n      max_diff = std::max(max_diff, abs(hist_h[i] - hist_d[i]));\n    }\n  }\n  printf(\"Maximum difference %d\\n\", max_diff);\n\n  free(hist_h);\n  free(hist_d);\n  free(ivf_h);\n  free(ivg_h);\n  free(g_h);\n  free(f_h);\n  free(data_threshold_h);\n  hipFree(M_d);\n  hipFree(g_d);\n  hipFree(f_d);\n  hipFree(ivf_d);\n  hipFree(ivg_d);\n  hipFree(data_threshold_d);\n\n  return 0;\n}\n"}}
{"kernel_name": "spm", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <stdbool.h>\n#include <string.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <omp.h>\n\n#define NUM_THREADS 128\n#define NUM_BLOCKS 256\n#define REPEAT 100\n\ntypedef struct {\n  int x, y, z;\n} int3;\n\n#ifdef OMP_TARGET\n#pragma omp declare target\n#endif\n\n\nfloat interp(const int3 d, const unsigned char f[], float x, float y, float z)\n{\n  int ix, iy, iz;\n  float dx1, dy1, dz1, dx2, dy2, dz2;\n  int k111,k112,k121,k122,k211,k212,k221,k222;\n  float vf;\n  const unsigned char *ff;\n\n  ix = floorf(x); dx1=x-ix; dx2=1.f-dx1;\n  iy = floorf(y); dy1=y-iy; dy2=1.f-dy1;\n  iz = floorf(z); dz1=z-iz; dz2=1.f-dz1;\n\n  ff   = f + ix-1+d.x*(iy-1+d.y*(iz-1));\n  k222 = ff[0]; k122 = ff[1];\n  k212 = ff[d.x]; k112 = ff[d.x+1];\n  ff  += d.x*d.y;\n  k221 = ff[0]; k121 = ff[1];\n  k211 = ff[d.x]; k111 = ff[d.x+1];\n\n  vf = (((k222*dx2+k122*dx1)*dy2 + (k212*dx2+k112*dx1)*dy1))*dz2 +\n       (((k221*dx2+k121*dx1)*dy2 + (k211*dx2+k111*dx1)*dy1))*dz1;\n\n  return(vf);\n}\n#ifdef OMP_TARGET\n#pragma omp end declare target\n#endif\n\nvoid spm (\n  const float *__restrict M, \n  const int data_size,\n  const unsigned char *__restrict g_d,\n  const unsigned char *__restrict f_d,\n  const int3 dg,\n  const int3 df,\n  unsigned char *__restrict ivf_d,\n  unsigned char *__restrict ivg_d,\n  bool *__restrict data_threshold_d)\n\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n  \n#ifdef OMP_TARGET\n  #pragma omp target teams distribute parallel for \\\n  num_teams(NUM_BLOCKS) thread_limit(NUM_THREADS)\n#endif\n  for (int i = 0; i < data_size; i++) {\n    int x_datasize=(dg.x-2);\n    int y_datasize=(dg.y-2);\n\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp>=1.f && zp<df.z && yp>=1.f && yp<df.y && xp>=1.f && xp<df.x)\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nvoid spm_reference (\n  const float *M, \n  const int data_size,\n  const unsigned char *g_d,\n  const unsigned char *f_d,\n  const int3 dg,\n  const int3 df,\n  unsigned char *ivf_d,\n  unsigned char *ivg_d,\n  bool *data_threshold_d)\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n  \n  int x_datasize=(dg.x-2);\n  int y_datasize=(dg.y-2);\n\n  for(int i = 0; i < data_size; i++)\n  {\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp>=1.f && zp<df.z && yp>=1.f && yp<df.y && xp>=1.f && xp<df.x)\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int v = atoi(argv[1]);\n  int repeat = atoi(argv[2]);\n\n  \n\n  int3 g_vol = {v,v,v};\n  int3 f_vol = {v,v,v};\n\n  \n\n  const int data_size = (g_vol.x+1) * (g_vol.y+1) * (g_vol.z+5);\n  \n  \n\n  const int vol_size = g_vol.x * g_vol.y * g_vol.z;\n\n  \n\n  int *hist_d = (int*) malloc (65536*sizeof(int));\n  int *hist_h = (int*) malloc (65536*sizeof(int));\n  memset(hist_d, 0, sizeof(int)*65536); \n  memset(hist_h, 0, sizeof(int)*65536); \n\n  srand(123);\n\n  \n\n  float M_h[16];\n  for (int i = 0; i < 16; i++) M_h[i] = (float)rand() / (float)RAND_MAX;\n\n  \n\n  unsigned char* f_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  unsigned char* g_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  for (int i = 0; i < data_size; i++) {\n    f_h[i] = rand() % 256;\n    g_h[i] = rand() % 256;\n  }\n\n  \n\n  unsigned char *ivf_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n  unsigned char *ivg_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n\n  \n\n  bool *data_threshold_h = (bool *)malloc(vol_size*sizeof(bool));\n\n#ifdef OMP_TARGET\n#pragma omp target data map(to:M_h[0:16], g_h[0:data_size], f_h[0:data_size]) \\\n                        map(from: ivf_h[0:vol_size], ivg_h[0:vol_size],\\\n                                  data_threshold_h[0:vol_size])\n{\n#endif\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    spm(M_h, vol_size, g_h, f_h, g_vol, f_vol, ivf_h, ivg_h, data_threshold_h);\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n#ifdef OMP_TARGET\n}\n#endif\n\n  \n\n  int count = 0;\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_d[ivf_h[i]+ivg_h[i]*256] += 1;    \n      count++;\n    }\n  }\n  printf(\"Device count: %d\\n\", count);\n\n  \n\n  count = 0;\n  spm_reference(M_h, vol_size, g_h, f_h, g_vol, f_vol, ivf_h, ivg_h, data_threshold_h);\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_h[ivf_h[i]+ivg_h[i]*256] += 1;    \n      count++;\n    }\n  }\n  printf(\"Host count: %d\\n\", count);\n\n  int max_diff = 0;\n  for(int i = 0; i < 65536; i++) {\n    if (hist_h[i] != hist_d[i]) {\n      max_diff = std::max(max_diff, abs(hist_h[i] - hist_d[i]));\n    }\n  }\n\n  \n\n  printf(\"Maximum difference %d\\n\", max_diff);\n\n  free(hist_h);\n  free(hist_d);\n  free(ivf_h);\n  free(ivg_h);\n  free(g_h);\n  free(f_h);\n  free(data_threshold_h);\n  return 0;\n}\n"}}
{"kernel_name": "spm", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <stdbool.h>\n#include <string.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n\n#define NUM_THREADS 128\n#define NUM_BLOCKS 256\n#define REPEAT 100\n\ntypedef struct {\n  int x, y, z;\n} int3;\n\n#ifdef OMP_TARGET\n#endif\n\n\nfloat interp(const int3 d, const unsigned char f[], float x, float y, float z)\n{\n  int ix, iy, iz;\n  float dx1, dy1, dz1, dx2, dy2, dz2;\n  int k111,k112,k121,k122,k211,k212,k221,k222;\n  float vf;\n  const unsigned char *ff;\n\n  ix = floorf(x); dx1=x-ix; dx2=1.f-dx1;\n  iy = floorf(y); dy1=y-iy; dy2=1.f-dy1;\n  iz = floorf(z); dz1=z-iz; dz2=1.f-dz1;\n\n  ff   = f + ix-1+d.x*(iy-1+d.y*(iz-1));\n  k222 = ff[0]; k122 = ff[1];\n  k212 = ff[d.x]; k112 = ff[d.x+1];\n  ff  += d.x*d.y;\n  k221 = ff[0]; k121 = ff[1];\n  k211 = ff[d.x]; k111 = ff[d.x+1];\n\n  vf = (((k222*dx2+k122*dx1)*dy2 + (k212*dx2+k112*dx1)*dy1))*dz2 +\n       (((k221*dx2+k121*dx1)*dy2 + (k211*dx2+k111*dx1)*dy1))*dz1;\n\n  return(vf);\n}\n#ifdef OMP_TARGET\n#endif\n\nvoid spm (\n  const float *__restrict M, \n  const int data_size,\n  const unsigned char *__restrict g_d,\n  const unsigned char *__restrict f_d,\n  const int3 dg,\n  const int3 df,\n  unsigned char *__restrict ivf_d,\n  unsigned char *__restrict ivg_d,\n  bool *__restrict data_threshold_d)\n\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n  \n#ifdef OMP_TARGET\n  #endif\n  for (int i = 0; i < data_size; i++) {\n    int x_datasize=(dg.x-2);\n    int y_datasize=(dg.y-2);\n\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp>=1.f && zp<df.z && yp>=1.f && yp<df.y && xp>=1.f && xp<df.x)\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nvoid spm_reference (\n  const float *M, \n  const int data_size,\n  const unsigned char *g_d,\n  const unsigned char *f_d,\n  const int3 dg,\n  const int3 df,\n  unsigned char *ivf_d,\n  unsigned char *ivg_d,\n  bool *data_threshold_d)\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n  \n  int x_datasize=(dg.x-2);\n  int y_datasize=(dg.y-2);\n\n  for(int i = 0; i < data_size; i++)\n  {\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp>=1.f && zp<df.z && yp>=1.f && yp<df.y && xp>=1.f && xp<df.x)\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int v = atoi(argv[1]);\n  int repeat = atoi(argv[2]);\n\n  \n\n  int3 g_vol = {v,v,v};\n  int3 f_vol = {v,v,v};\n\n  \n\n  const int data_size = (g_vol.x+1) * (g_vol.y+1) * (g_vol.z+5);\n  \n  \n\n  const int vol_size = g_vol.x * g_vol.y * g_vol.z;\n\n  \n\n  int *hist_d = (int*) malloc (65536*sizeof(int));\n  int *hist_h = (int*) malloc (65536*sizeof(int));\n  memset(hist_d, 0, sizeof(int)*65536); \n  memset(hist_h, 0, sizeof(int)*65536); \n\n  srand(123);\n\n  \n\n  float M_h[16];\n  for (int i = 0; i < 16; i++) M_h[i] = (float)rand() / (float)RAND_MAX;\n\n  \n\n  unsigned char* f_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  unsigned char* g_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  for (int i = 0; i < data_size; i++) {\n    f_h[i] = rand() % 256;\n    g_h[i] = rand() % 256;\n  }\n\n  \n\n  unsigned char *ivf_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n  unsigned char *ivg_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n\n  \n\n  bool *data_threshold_h = (bool *)malloc(vol_size*sizeof(bool));\n\n#ifdef OMP_TARGET\n{\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    spm(M_h, vol_size, g_h, f_h, g_vol, f_vol, ivf_h, ivg_h, data_threshold_h);\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n#ifdef OMP_TARGET\n}\n#endif\n\n  \n\n  int count = 0;\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_d[ivf_h[i]+ivg_h[i]*256] += 1;    \n      count++;\n    }\n  }\n  printf(\"Device count: %d\\n\", count);\n\n  \n\n  count = 0;\n  spm_reference(M_h, vol_size, g_h, f_h, g_vol, f_vol, ivf_h, ivg_h, data_threshold_h);\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_h[ivf_h[i]+ivg_h[i]*256] += 1;    \n      count++;\n    }\n  }\n  printf(\"Host count: %d\\n\", count);\n\n  int max_diff = 0;\n  for(int i = 0; i < 65536; i++) {\n    if (hist_h[i] != hist_d[i]) {\n      max_diff = std::max(max_diff, abs(hist_h[i] - hist_d[i]));\n    }\n  }\n\n  \n\n  printf(\"Maximum difference %d\\n\", max_diff);\n\n  free(hist_h);\n  free(hist_d);\n  free(ivf_h);\n  free(ivg_h);\n  free(g_h);\n  free(f_h);\n  free(data_threshold_h);\n  return 0;\n}"}}
{"kernel_name": "spm", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <stdbool.h>\n#include <string.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define NUM_THREADS 128\n#define NUM_BLOCKS 256\n\n\n\n\nfloat interp(const sycl::int3 d, const unsigned char f[], float x, float y,\n             float z)\n{\n  int ix, iy, iz;\n  float dx1, dy1, dz1, dx2, dy2, dz2;\n  int k111,k112,k121,k122,k211,k212,k221,k222;\n  float vf;\n  const unsigned char *ff;\n\n  ix = sycl::floor(x); dx1 = x - ix; dx2 = 1.f - dx1;\n  iy = sycl::floor(y); dy1 = y - iy; dy2 = 1.f - dy1;\n  iz = sycl::floor(z); dz1 = z - iz; dz2 = 1.f - dz1;\n\n  ff = f + ix - 1 + d.x() * (iy - 1 + d.y() * (iz - 1));\n  k222 = ff[   0]; k122 = ff[     1];\n  k212 = ff[d.x()]; k112 = ff[d.x() + 1];\n  ff += d.x() * d.y();\n  k221 = ff[   0]; k121 = ff[     1];\n  k211 = ff[d.x()]; k111 = ff[d.x() + 1];\n\n  vf = (((k222*dx2+k122*dx1)*dy2 + (k212*dx2+k112*dx1)*dy1))*dz2 +\n       (((k221*dx2+k121*dx1)*dy2 + (k211*dx2+k111*dx1)*dy1))*dz1;\n\n  return(vf);\n}\n\nvoid spm(const float *__restrict__ M, const int data_size,\n         const unsigned char *__restrict__ g_d,\n         const unsigned char *__restrict__ f_d, const sycl::int3 dg,\n         const sycl::int3 df, unsigned char *__restrict__ ivf_d,\n         unsigned char *__restrict__ ivg_d, bool *__restrict__ data_threshold_d,\n         const sycl::nd_item<1> &item)\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n\n  const int idx = item.get_global_id(0);\n\n  int x_datasize = (dg.x() - 2);\n  int y_datasize = (dg.y() - 2);\n\n  for(int i = idx; i < data_size; i += NUM_THREADS*NUM_BLOCKS)\n  {\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp =\n        ((int)sycl::floor((float)i / x_datasize) % y_datasize) + 1.f;\n    float zz_temp = (sycl::floor((float)i / x_datasize)) / y_datasize + 1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp >= 1.f && zp < df.z() && yp >= 1.f && yp < df.y() && xp >= 1.f &&\n        xp < df.x())\n    {\n      \n\n      ivf_d[i] = sycl::floor(interp(df, f_d, xp, yp, zp) + 0.5f);\n      ivg_d[i] = sycl::floor(interp(dg, g_d, rx, ry, rz) + 0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nvoid spm_reference(const float *M, const int data_size,\n                   const unsigned char *g_d, const unsigned char *f_d,\n                   const sycl::int3 dg, const sycl::int3 df,\n                   unsigned char *ivf_d, unsigned char *ivg_d,\n                   bool *data_threshold_d)\n{\n  \n\n  const float ran[] = {\n    0.656619,0.891183,0.488144,0.992646,0.373326,0.531378,0.181316,0.501944,0.422195,\n    0.660427,0.673653,0.95733,0.191866,0.111216,0.565054,0.969166,0.0237439,0.870216,\n    0.0268766,0.519529,0.192291,0.715689,0.250673,0.933865,0.137189,0.521622,0.895202,\n    0.942387,0.335083,0.437364,0.471156,0.14931,0.135864,0.532498,0.725789,0.398703,\n    0.358419,0.285279,0.868635,0.626413,0.241172,0.978082,0.640501,0.229849,0.681335,\n    0.665823,0.134718,0.0224933,0.262199,0.116515,0.0693182,0.85293,0.180331,0.0324186,\n    0.733926,0.536517,0.27603,0.368458,0.0128863,0.889206,0.866021,0.254247,0.569481,\n    0.159265,0.594364,0.3311,0.658613,0.863634,0.567623,0.980481,0.791832,0.152594,\n    0.833027,0.191863,0.638987,0.669,0.772088,0.379818,0.441585,0.48306,0.608106,\n    0.175996,0.00202556,0.790224,0.513609,0.213229,0.10345,0.157337,0.407515,0.407757,\n    0.0526927,0.941815,0.149972,0.384374,0.311059,0.168534,0.896648};\n\n  int x_datasize = (dg.x() - 2);\n  int y_datasize = (dg.y() - 2);\n\n  for(int i = 0; i < data_size; i++)\n  {\n    float xx_temp = (i%x_datasize)+1.f;\n    float yy_temp = ((int)floorf((float)i/x_datasize)%y_datasize)+1.f;\n    float zz_temp = (floorf((float)i/x_datasize))/y_datasize+1.f;\n\n    \n\n    float rx = xx_temp + ran[i%97];\n    float ry = yy_temp + ran[i%97];\n    float rz = zz_temp + ran[i%97];\n\n    \n\n    float xp = M[0]*rx + M[4]*ry + M[ 8]*rz + M[12];\n    float yp = M[1]*rx + M[5]*ry + M[ 9]*rz+ M[13];\n    float zp = M[2]*rx + M[6]*ry + M[10]*rz+ M[14];\n\n    if (zp >= 1.f && zp < df.z() && yp >= 1.f && yp < df.y() && xp >= 1.f &&\n        xp < df.x())\n    {\n      \n\n      ivf_d[i] = floorf(interp(df, f_d, xp,yp,zp)+0.5f);\n      ivg_d[i] = floorf(interp(dg, g_d, rx,ry,rz)+0.5f);\n      data_threshold_d[i] = true;\n    }\n    else\n    {\n      ivf_d[i] = 0;\n      ivg_d[i] = 0;\n      data_threshold_d[i] = false;\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int v = atoi(argv[1]);\n  int repeat = atoi(argv[2]);\n\n  sycl::int3 g_vol = {v, v, v};\n  sycl::int3 f_vol = {v, v, v};\n\n  const int data_size = (g_vol.x() + 1) * (g_vol.y() + 1) * (g_vol.z() + 5);\n  const int vol_size = g_vol.x() * g_vol.y() * g_vol.z();\n\n  int *hist_d = (int*) malloc (65536*sizeof(int));\n  int *hist_h = (int*) malloc (65536*sizeof(int));\n  memset(hist_d, 0, sizeof(int)*65536);\n  memset(hist_h, 0, sizeof(int)*65536);\n\n  unsigned char *ivf_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n  unsigned char *ivg_h = (unsigned char *)malloc(vol_size*sizeof(unsigned char));\n  bool *data_threshold_h = (bool *)malloc(vol_size*sizeof(bool));\n\n  srand(123);\n\n  float M_h[16];\n  for (int i = 0; i < 16; i++) M_h[i] = (float)rand() / (float)RAND_MAX;\n\n  unsigned char* g_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  unsigned char* f_h = (unsigned char*) malloc (data_size * sizeof(unsigned char));\n  for (int i = 0; i < data_size; i++) {\n    g_h[i] = rand() % 256;\n    f_h[i] = rand() % 256;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *M_d;\n  M_d = sycl::malloc_device<float>(16, q);\n  q.memcpy(M_d, M_h, 16 * sizeof(float));\n\n  unsigned char *g_d, *f_d;\n  g_d = sycl::malloc_device<unsigned char>(data_size, q);\n  f_d = sycl::malloc_device<unsigned char>(data_size, q);\n\n  q.memcpy(g_d, g_h, data_size * sizeof(unsigned char));\n  q.memcpy(f_d, f_h, data_size * sizeof(unsigned char));\n\n  unsigned char *ivf_d, *ivg_d;\n  ivf_d = sycl::malloc_device<unsigned char>(vol_size, q);\n  ivg_d = sycl::malloc_device<unsigned char>(vol_size, q);\n\n  bool *data_threshold_d;\n  data_threshold_d = sycl::malloc_device<bool>(vol_size, q);\n\n  sycl::range<1> gws (NUM_BLOCKS*NUM_THREADS);\n  sycl::range<1> lws (NUM_THREADS);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class kernel>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        spm(M_d, vol_size, g_d, f_d, g_vol, f_vol,\n            ivf_d, ivg_d, data_threshold_d, item);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(ivf_h, ivf_d, vol_size * sizeof(unsigned char));\n  q.memcpy(ivg_h, ivg_d, vol_size * sizeof(unsigned char));\n  q.memcpy(data_threshold_h, data_threshold_d, vol_size * sizeof(bool));\n  q.wait();\n\n  int count = 0;\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_d[ivf_h[i]+ivg_h[i]*256] += 1;\n      count++;\n    }\n  }\n  printf(\"Device count: %d\\n\", count);\n\n  count = 0;\n  spm_reference(M_h, vol_size, g_h, f_h, g_vol, f_vol, ivf_h, ivg_h, data_threshold_h);\n  for(int i = 0; i < vol_size; i++)\n  {\n    if (data_threshold_h[i]) {\n      hist_h[ivf_h[i]+ivg_h[i]*256] += 1;\n      count++;\n    }\n  }\n  printf(\"Host count: %d\\n\", count);\n\n  int max_diff = 0;\n  for(int i = 0; i < 65536; i++) {\n    if (hist_h[i] != hist_d[i]) {\n      max_diff = std::max(max_diff, abs(hist_h[i] - hist_d[i]));\n    }\n  }\n  printf(\"Maximum difference %d\\n\", max_diff);\n\n  free(hist_h);\n  free(hist_d);\n  free(ivf_h);\n  free(ivg_h);\n  free(g_h);\n  free(f_h);\n  free(data_threshold_h);\n  sycl::free(M_d, q);\n  sycl::free(g_d, q);\n  sycl::free(f_d, q);\n  sycl::free(ivf_d, q);\n  sycl::free(ivg_d, q);\n  sycl::free(data_threshold_d, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "stencil1d", "parallel_api": "cuda", "code": {"stencil_1d.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\n__global__\nvoid stencil_1d(const int *__restrict__ in, int *__restrict__ out)\n{\n  __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n  int gindex = threadIdx.x + blockIdx.x * blockDim.x;\n  int lindex = threadIdx.x + RADIUS;\n\n  \n\n  temp[lindex] = in[gindex];\n\n  \n\n  if (threadIdx.x < RADIUS) {\n    temp[lindex - RADIUS] = (gindex < RADIUS) ? 0 : in[gindex - RADIUS];\n    temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n  }\n\n  \n\n  __syncthreads();\n\n  \n\n  int result = 0;\n  for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n    result += temp[lindex + offset];\n\n  \n\n  out[gindex] = result; \n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int size = length * sizeof(int);\n  int pad_size = (length + RADIUS) * sizeof(int);\n\n  int *a, *b;\n  \n\n  a = (int *)malloc(pad_size); \n  b = (int *)malloc(size);\n\n  for (int i = 0; i < length+RADIUS; i++) a[i] = i;\n\n  int *d_a, *d_b;\n  \n\n  cudaMalloc((void **)&d_a, pad_size);\n  cudaMalloc((void **)&d_b, size);\n\n  \n\n  cudaMemcpy(d_a, a, pad_size, cudaMemcpyHostToDevice);\n\n  dim3 grids (length/BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++)\n    stencil_1d <<< grids, blocks >>> (d_a, d_b);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  cudaMemcpy(b, d_b, size, cudaMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b); \n  cudaFree(d_a); \n  cudaFree(d_b); \n  return 0;\n}\n"}}
{"kernel_name": "stencil1d", "parallel_api": "hip", "code": {"stencil_1d.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\n__global__\nvoid stencil_1d(const int *__restrict__ in, int *__restrict__ out)\n{\n  __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n  int gindex = threadIdx.x + blockIdx.x * blockDim.x;\n  int lindex = threadIdx.x + RADIUS;\n\n  \n\n  temp[lindex] = in[gindex];\n\n  \n\n  if (threadIdx.x < RADIUS) {\n    temp[lindex - RADIUS] = (gindex < RADIUS) ? 0 : in[gindex - RADIUS];\n    temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n  }\n\n  \n\n  __syncthreads();\n\n  \n\n  int result = 0;\n  for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n    result += temp[lindex + offset];\n\n  \n\n  out[gindex] = result; \n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int size = length * sizeof(int);\n  int pad_size = (length + RADIUS) * sizeof(int);\n\n  int *a, *b;\n  \n\n  a = (int *)malloc(pad_size); \n  b = (int *)malloc(size);\n\n  for (int i = 0; i < length+RADIUS; i++) a[i] = i;\n\n  int *d_a, *d_b;\n  \n\n  hipMalloc((void **)&d_a, pad_size);\n  hipMalloc((void **)&d_b, size);\n\n  \n\n  hipMemcpy(d_a, a, pad_size, hipMemcpyHostToDevice);\n\n  dim3 grids (length/BLOCK_SIZE);\n  dim3 blocks (BLOCK_SIZE);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(stencil_1d, grids, blocks , 0, 0, d_a, d_b);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  hipMemcpy(b, d_b, size, hipMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b); \n  hipFree(d_a); \n  hipFree(d_b); \n  return 0;\n}\n"}}
{"kernel_name": "stencil1d", "parallel_api": "omp", "code": {"stencil_1d.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <omp.h>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int size = length;\n  int pad_size = (length + RADIUS);\n\n  \n\n  int* a = (int *)malloc(pad_size*sizeof(int)); \n  int* b = (int *)malloc(size*sizeof(int));\n\n  for (int i = 0; i < length+RADIUS; i++) a[i] = i;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target teams distribute map(to: a[0:pad_size]) map(from:b[0:size]) \n    for (int i = 0; i < length; i = i + BLOCK_SIZE) {\n      int temp[BLOCK_SIZE + 2 * RADIUS];\n      #pragma omp parallel for schedule(static,1)\n      for (int j = 0; j < BLOCK_SIZE; j++) {\n        int gindex = i+j;\n        temp[j+RADIUS] = a[gindex]; \n        if (j < RADIUS) {\n          temp[j] = (gindex < RADIUS) ? 0 : a[gindex - RADIUS];\n          temp[j + RADIUS + BLOCK_SIZE] = a[gindex + BLOCK_SIZE];\n        }\n      }\n\n      #pragma omp parallel for schedule(static,1)\n      for (int j = 0; j < BLOCK_SIZE; j++) {\n        int result = 0;\n        for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n          result += temp[j+RADIUS+offset];\n        b[i+j] = result; \n      }\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b); \n  return 0;\n}\n"}}
{"kernel_name": "stencil1d", "parallel_api": "serial", "code": {"stencil_1d.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int size = length;\n  int pad_size = (length + RADIUS);\n\n  \n\n  int* a = (int *)malloc(pad_size*sizeof(int)); \n  int* b = (int *)malloc(size*sizeof(int));\n\n  for (int i = 0; i < length+RADIUS; i++) a[i] = i;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n        for (int i = 0; i < length; i = i + BLOCK_SIZE) {\n      int temp[BLOCK_SIZE + 2 * RADIUS];\n            for (int j = 0; j < BLOCK_SIZE; j++) {\n        int gindex = i+j;\n        temp[j+RADIUS] = a[gindex]; \n        if (j < RADIUS) {\n          temp[j] = (gindex < RADIUS) ? 0 : a[gindex - RADIUS];\n          temp[j + RADIUS + BLOCK_SIZE] = a[gindex + BLOCK_SIZE];\n        }\n      }\n\n            for (int j = 0; j < BLOCK_SIZE; j++) {\n        int result = 0;\n        for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n          result += temp[j+RADIUS+offset];\n        b[i+j] = result; \n      }\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b); \n  return 0;\n}"}}
{"kernel_name": "stencil1d", "parallel_api": "sycl", "code": {"stencil_1d.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define RADIUS 7\n#define BLOCK_SIZE 256\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    printf(\"length is a multiple of %d\\n\", BLOCK_SIZE);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  const int pad_size = (length + RADIUS);\n\n  const size_t input_size_bytes = pad_size * sizeof(int);\n  const size_t output_size_bytes = length * sizeof(int);\n\n  \n\n  int* a = (int *)malloc(input_size_bytes);\n  int* b = (int *)malloc(output_size_bytes);\n\n  for (int i = 0; i < pad_size; i++) a[i] = i;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_in = sycl::malloc_device<int>(pad_size, q);\n  q.memcpy(d_in, a, input_size_bytes);\n\n  int *d_out = sycl::malloc_device<int>(length, q);\n\n  sycl::range<1> gws (length);\n  sycl::range<1> lws (BLOCK_SIZE);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler& cgh) {\n      sycl::local_accessor <int, 1> temp (sycl::range<1>(BLOCK_SIZE + 2 * RADIUS), cgh);\n      cgh.parallel_for<class stencil1D>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int gindex = item.get_global_id(0);\n        int lindex = item.get_local_id(0) + RADIUS;\n\n        \n\n        temp[lindex] = d_in[gindex];\n\n        \n\n        if (item.get_local_id(0) < RADIUS) {\n          temp[lindex - RADIUS] = (gindex < RADIUS) ? 0 : d_in[gindex - RADIUS];\n          temp[lindex + BLOCK_SIZE] = d_in[gindex + BLOCK_SIZE];\n        }\n\n        \n\n        item.barrier(sycl::access::fence_space::local_space);\n\n        \n\n        int result = 0;\n        for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n          result += temp[lindex + offset];\n\n        \n\n        d_out[gindex] = result;\n\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  q.memcpy(b, d_out, output_size_bytes);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < 2*RADIUS; i++) {\n    int s = 0;\n    for (int j = i; j <= i+2*RADIUS; j++)\n      s += j < RADIUS ? 0 : (a[j] - RADIUS);\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n\n  for (int i = 2*RADIUS; i < length; i++) {\n    int s = 0;\n    for (int j = i-RADIUS; j <= i+RADIUS; j++)\n      s += a[j];\n    if (s != b[i]) {\n      printf(\"Error at %d: %d (host) != %d (device)\\n\", i, s, b[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(a);\n  free(b);\n  sycl::free(d_in, q);\n  sycl::free(d_out, q);\n  return 0;\n}\n"}}
{"kernel_name": "stencil3d", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n\n\n\n#define BSIZE 16\n\n\n#define XTILE 20\n\ntypedef double Real;\n\n__global__ void stencil3d(\n    const Real*__restrict__ d_psi, \n          Real*__restrict__ d_npsi, \n    const Real*__restrict__ d_sigmaX, \n    const Real*__restrict__ d_sigmaY, \n    const Real*__restrict__ d_sigmaZ,\n    int nx, int ny, int nz)\n{\n\n  \n\n  __shared__ Real sm_psi[4][BSIZE][BSIZE];\n\n  #define V0(y,z) sm_psi[pii][y][z]\n  #define V1(y,z) sm_psi[cii][y][z]\n  #define V2(y,z) sm_psi[nii][y][z]\n  \n  #define sigmaX(x,y,z,dir) d_sigmaX[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n  #define sigmaY(x,y,z,dir) d_sigmaY[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n  #define sigmaZ(x,y,z,dir) d_sigmaZ[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n  \n  #define psi(x,y,z) d_psi[ z + nz * ( (y) + ny * (x) ) ]\n  #define npsi(x,y,z) d_npsi[ z + nz * ( (y) + ny * (x) ) ]\n\n  const int tjj = threadIdx.y;\n  const int tkk = threadIdx.x;\n\n  \n\n  d_psi = &(psi(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z));\n  d_npsi = &(npsi(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z));\n\n  d_sigmaX = &(sigmaX(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z, 0));\n  d_sigmaY = &(sigmaY(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z, 0));\n  d_sigmaZ = &(sigmaZ(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z, 0));\n\n  int nLast_x=XTILE+1; int nLast_y=(BSIZE-1); int nLast_z=(BSIZE-1);\n  if (blockIdx.x == gridDim.x-1) nLast_x = nx-2 - XTILE * blockIdx.x + 1;\n  if (blockIdx.y == gridDim.y-1) nLast_y = ny-2 - (BSIZE-2) * blockIdx.y + 1;\n  if (blockIdx.z == gridDim.z-1) nLast_z = nz-2 - (BSIZE-2) * blockIdx.z + 1;\n\n  if(tjj>nLast_y || tkk>nLast_z) return;\n\n  \n\n  int pii,cii,nii,tii;\n  pii=0; cii=1; nii=2;\n\n  sm_psi[cii][tjj][tkk] = psi(0,tjj,tkk);\n  sm_psi[nii][tjj][tkk] = psi(1,tjj,tkk);\n  Real xcharge,ycharge,zcharge,dV = 0;\n\n  __syncthreads();\n\n  \n\n  if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n  {\n    Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n    Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n    Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n    dV -= sigmaX(1,tjj,tkk,0) * xd + sigmaX(1,tjj,tkk,1) * yd + sigmaX(1,tjj,tkk,2) * zd ; \n  }\n\n  tii=pii; pii=cii; cii=nii; nii=tii;\n\n  for(int ii=1;ii<nLast_x;ii++)\n  {\n    sm_psi[nii][tjj][tkk] = psi(ii+1,tjj,tkk);\n    __syncthreads();\n\n    \n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj<nLast_y))\n    {\n      Real xd=(-V0(tjj,tkk) - V0(1 + tjj,tkk) + V2(tjj,tkk) + V2(1 + tjj,tkk))/4.;\n      Real yd=-V1(tjj,tkk) + V1(1 + tjj,tkk);\n      Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V1(1 + tjj,-1 + tkk) + V1(1 + tjj,1 + tkk))/4.;\n      ycharge = sigmaY(ii,tjj+1,tkk,0) * xd + sigmaY(ii,tjj+1,tkk,1) * yd + sigmaY(ii,tjj+1,tkk,2) * zd ; \n      dV += ycharge;\n      sm_psi[3][tjj][tkk]=ycharge;\n    }\n    __syncthreads();\n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n      dV -= sm_psi[3][tjj-1][tkk];  \n\n\n    __syncthreads();\n\n    \n\n    if ((tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n    {\n      Real xd=(-V0(tjj,tkk) - V0(tjj,1 + tkk) + V2(tjj,tkk) + V2(tjj,1 + tkk))/4.;\n      Real yd=(-V1(-1 + tjj,tkk) - V1(-1 + tjj,1 + tkk) + V1(1 + tjj,tkk) + V1(1 + tjj,1 + tkk))/4.;\n      Real zd=-V1(tjj,tkk) + V1(tjj,1 + tkk);\n      zcharge = sigmaZ(ii,tjj,tkk+1,0) * xd + sigmaZ(ii,tjj,tkk+1,1) * yd + sigmaZ(ii,tjj,tkk+1,2) * zd ; \n      dV += zcharge;\n      sm_psi[3][tjj][tkk]=zcharge;\n    }\n\n    __syncthreads();\n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n      dV -= sm_psi[3][tjj][tkk-1];\n    __syncthreads();\n\n    \n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n    {\n      Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n      Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n      Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n      xcharge = sigmaX(ii+1,tjj,tkk,0) * xd + sigmaX(ii+1,tjj,tkk,1) * yd + sigmaX(ii+1,tjj,tkk,2) * zd ; \n      dV += xcharge;\n      npsi(ii,tjj,tkk) = dV; \n\n      dV = -xcharge; \n\n    }\n    __syncthreads();\n    tii=pii; pii=cii; cii=nii; nii=tii;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <grid dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n  const int nx = size;\n  const int ny = size;\n  const int nz = size;\n  const int vol = nx * ny * nz;\n  printf(\"Grid dimension: nx=%d ny=%d nz=%d\\n\",nx,ny,nz);\n\n  Real *d_Vm, *d_dVm, *d_sigma;\n\n  \n\n  cudaMalloc((void**)&d_Vm, sizeof(Real)*vol);\n  Real *h_Vm = (Real*) malloc (sizeof(Real)*vol);\n\n#define h_Vm(x,y,z) h_Vm[ z + nz * ( y + ny * ( x  ) ) ]\n\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        h_Vm(ii,jj,kk) = (ii*(ny*nz) + jj * nz + kk) % 19;\n\n  cudaMemcpy(d_Vm, h_Vm, sizeof(Real) * vol , cudaMemcpyHostToDevice);\n\n  \n\n  cudaMalloc((void**)&d_sigma,sizeof(Real)*vol*9);\n  Real *h_sigma = (Real*) malloc(sizeof(Real)*vol*9);\n\n  for (int i = 0; i < vol*9; i++) h_sigma[i] = i % 19;\n\n  cudaMemcpy(d_sigma, h_sigma, sizeof(Real) * vol*9, cudaMemcpyHostToDevice);\n\n  \n\n  cudaMalloc((void**)&d_dVm,sizeof(Real)*vol);\n  cudaMemset(d_dVm, 0, sizeof(Real) * vol);\n\n  \n\n  int bdimz = (nz-2)/(BSIZE-2) + ((nz-2)%(BSIZE-2)==0?0:1);\n  int bdimy = (ny-2)/(BSIZE-2) + ((ny-2)%(BSIZE-2)==0?0:1);\n  int bdimx = (nx-2)/XTILE + ((nx-2)%XTILE==0?0:1);\n\n  dim3 grids (bdimx, bdimy, bdimz);\n  dim3 blocks (BSIZE, BSIZE, 1);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    stencil3d <<< grids, blocks >>> (\n       d_Vm, d_dVm, d_sigma, d_sigma + 3*vol, d_sigma + 6*vol, nx, ny, nz);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  Real *h_dVm = (Real*) malloc (sizeof(Real) * vol);\n  cudaMemcpy(h_dVm, d_dVm, vol*sizeof(Real), cudaMemcpyDeviceToHost);\n\n#ifdef DUMP\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        printf(\"dVm (%d,%d,%d)=%e\\n\",ii,jj,kk,h_dVm[kk+nz*(jj+ny*ii)]);\n#endif\n\n  cudaFree(d_Vm);\n  cudaFree(d_dVm);\n  cudaFree(d_sigma);\n  free(h_sigma);\n  free(h_Vm);\n  free(h_dVm);\n\n  return 0;\n}\n"}}
{"kernel_name": "stencil3d", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n\n\n#define BSIZE 16\n\n\n#define XTILE 20\n\ntypedef double Real;\n\n__global__ void stencil3d(\n    const Real*__restrict__ d_psi, \n          Real*__restrict__ d_npsi, \n    const Real*__restrict__ d_sigmaX, \n    const Real*__restrict__ d_sigmaY, \n    const Real*__restrict__ d_sigmaZ,\n    int nx, int ny, int nz)\n{\n\n  \n\n  __shared__ Real sm_psi[4][BSIZE][BSIZE];\n\n  #define V0(y,z) sm_psi[pii][y][z]\n  #define V1(y,z) sm_psi[cii][y][z]\n  #define V2(y,z) sm_psi[nii][y][z]\n  \n  #define sigmaX(x,y,z,dir) d_sigmaX[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n  #define sigmaY(x,y,z,dir) d_sigmaY[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n  #define sigmaZ(x,y,z,dir) d_sigmaZ[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n  \n  #define psi(x,y,z) d_psi[ z + nz * ( (y) + ny * (x) ) ]\n  #define npsi(x,y,z) d_npsi[ z + nz * ( (y) + ny * (x) ) ]\n\n  const int tjj = threadIdx.y;\n  const int tkk = threadIdx.x;\n\n  \n\n  d_psi = &(psi(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z));\n  d_npsi = &(npsi(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z));\n\n  d_sigmaX = &(sigmaX(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z, 0));\n  d_sigmaY = &(sigmaY(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z, 0));\n  d_sigmaZ = &(sigmaZ(XTILE*blockIdx.x, (BSIZE-2)*blockIdx.y, (BSIZE-2)*blockIdx.z, 0));\n\n  int nLast_x=XTILE+1; int nLast_y=(BSIZE-1); int nLast_z=(BSIZE-1);\n  if (blockIdx.x == gridDim.x-1) nLast_x = nx-2 - XTILE * blockIdx.x + 1;\n  if (blockIdx.y == gridDim.y-1) nLast_y = ny-2 - (BSIZE-2) * blockIdx.y + 1;\n  if (blockIdx.z == gridDim.z-1) nLast_z = nz-2 - (BSIZE-2) * blockIdx.z + 1;\n\n  if(tjj>nLast_y || tkk>nLast_z) return;\n\n  \n\n  int pii,cii,nii,tii;\n  pii=0; cii=1; nii=2;\n\n  sm_psi[cii][tjj][tkk] = psi(0,tjj,tkk);\n  sm_psi[nii][tjj][tkk] = psi(1,tjj,tkk);\n  Real xcharge,ycharge,zcharge,dV = 0;\n\n  __syncthreads();\n\n  \n\n  if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n  {\n    Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n    Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n    Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n    dV -= sigmaX(1,tjj,tkk,0) * xd + sigmaX(1,tjj,tkk,1) * yd + sigmaX(1,tjj,tkk,2) * zd ; \n  }\n\n  tii=pii; pii=cii; cii=nii; nii=tii;\n\n  for(int ii=1;ii<nLast_x;ii++)\n  {\n    sm_psi[nii][tjj][tkk] = psi(ii+1,tjj,tkk);\n    __syncthreads();\n\n    \n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj<nLast_y))\n    {\n      Real xd=(-V0(tjj,tkk) - V0(1 + tjj,tkk) + V2(tjj,tkk) + V2(1 + tjj,tkk))/4.;\n      Real yd=-V1(tjj,tkk) + V1(1 + tjj,tkk);\n      Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V1(1 + tjj,-1 + tkk) + V1(1 + tjj,1 + tkk))/4.;\n      ycharge = sigmaY(ii,tjj+1,tkk,0) * xd + sigmaY(ii,tjj+1,tkk,1) * yd + sigmaY(ii,tjj+1,tkk,2) * zd ; \n      dV += ycharge;\n      sm_psi[3][tjj][tkk]=ycharge;\n    }\n    __syncthreads();\n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n      dV -= sm_psi[3][tjj-1][tkk];  \n\n\n    __syncthreads();\n\n    \n\n    if ((tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n    {\n      Real xd=(-V0(tjj,tkk) - V0(tjj,1 + tkk) + V2(tjj,tkk) + V2(tjj,1 + tkk))/4.;\n      Real yd=(-V1(-1 + tjj,tkk) - V1(-1 + tjj,1 + tkk) + V1(1 + tjj,tkk) + V1(1 + tjj,1 + tkk))/4.;\n      Real zd=-V1(tjj,tkk) + V1(tjj,1 + tkk);\n      zcharge = sigmaZ(ii,tjj,tkk+1,0) * xd + sigmaZ(ii,tjj,tkk+1,1) * yd + sigmaZ(ii,tjj,tkk+1,2) * zd ; \n      dV += zcharge;\n      sm_psi[3][tjj][tkk]=zcharge;\n    }\n\n    __syncthreads();\n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n      dV -= sm_psi[3][tjj][tkk-1];\n    __syncthreads();\n\n    \n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n    {\n      Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n      Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n      Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n      xcharge = sigmaX(ii+1,tjj,tkk,0) * xd + sigmaX(ii+1,tjj,tkk,1) * yd + sigmaX(ii+1,tjj,tkk,2) * zd ; \n      dV += xcharge;\n      npsi(ii,tjj,tkk) = dV; \n\n      dV = -xcharge; \n\n    }\n    __syncthreads();\n    tii=pii; pii=cii; cii=nii; nii=tii;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <grid dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n  const int nx = size;\n  const int ny = size;\n  const int nz = size;\n  const int vol = nx * ny * nz;\n  printf(\"Grid dimension: nx=%d ny=%d nz=%d\\n\",nx,ny,nz);\n\n  Real *d_Vm, *d_dVm, *d_sigma;\n\n  \n\n  hipMalloc((void**)&d_Vm, sizeof(Real)*vol);\n  Real *h_Vm = (Real*) malloc (sizeof(Real)*vol);\n\n#define h_Vm(x,y,z) h_Vm[ z + nz * ( y + ny * ( x  ) ) ]\n\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        h_Vm(ii,jj,kk) = (ii*(ny*nz) + jj * nz + kk) % 19;\n\n  hipMemcpy(d_Vm, h_Vm, sizeof(Real) * vol , hipMemcpyHostToDevice);\n\n  \n\n  hipMalloc((void**)&d_sigma,sizeof(Real)*vol*9);\n  Real *h_sigma = (Real*) malloc(sizeof(Real)*vol*9);\n\n  for (int i = 0; i < vol*9; i++) h_sigma[i] = i % 19;\n\n  hipMemcpy(d_sigma, h_sigma, sizeof(Real) * vol*9, hipMemcpyHostToDevice);\n\n  \n\n  hipMalloc((void**)&d_dVm,sizeof(Real)*vol);\n  hipMemset(d_dVm, 0, sizeof(Real) * vol);\n\n  \n\n  int bdimz = (nz-2)/(BSIZE-2) + ((nz-2)%(BSIZE-2)==0?0:1);\n  int bdimy = (ny-2)/(BSIZE-2) + ((ny-2)%(BSIZE-2)==0?0:1);\n  int bdimx = (nx-2)/XTILE + ((nx-2)%XTILE==0?0:1);\n\n  dim3 grids (bdimx, bdimy, bdimz);\n  dim3 blocks (BSIZE, BSIZE, 1);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    hipLaunchKernelGGL(stencil3d, grids, blocks , 0, 0, \n       d_Vm, d_dVm, d_sigma, d_sigma + 3*vol, d_sigma + 6*vol, nx, ny, nz);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  Real *h_dVm = (Real*) malloc (sizeof(Real) * vol);\n  hipMemcpy(h_dVm, d_dVm, vol*sizeof(Real), hipMemcpyDeviceToHost);\n\n#ifdef DUMP\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        printf(\"dVm (%d,%d,%d)=%e\\n\",ii,jj,kk,h_dVm[kk+nz*(jj+ny*ii)]);\n#endif\n\n  hipFree(d_Vm);\n  hipFree(d_dVm);\n  hipFree(d_sigma);\n  free(h_sigma);\n  free(h_Vm);\n  free(h_dVm);\n\n  return 0;\n}\n"}}
{"kernel_name": "stencil3d", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n\n\n\n#define BSIZE 16\n\n\n#define XTILE 20\n\ntypedef float Real;\n\nvoid stencil3d(\n    const Real*__restrict d_psi, \n          Real*__restrict d_npsi, \n    const Real*__restrict d_sigmaX, \n    const Real*__restrict d_sigmaY, \n    const Real*__restrict d_sigmaZ,\n    int bdimx, int bdimy, int bdimz,\n    int nx, int ny, int nz)\n{\n  #pragma omp target teams num_teams(bdimz*bdimy*bdimx) thread_limit(BSIZE*BSIZE)\n  {\n    Real sm_psi[4][BSIZE][BSIZE];\n    #pragma omp parallel \n    {\n      #define V0(y,z) sm_psi[pii][y][z]\n      #define V1(y,z) sm_psi[cii][y][z]\n      #define V2(y,z) sm_psi[nii][y][z]\n      \n      #define sigmaX(x,y,z,dir) d_sigmaX[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n      #define sigmaY(x,y,z,dir) d_sigmaY[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n      #define sigmaZ(x,y,z,dir) d_sigmaZ[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n      \n      #define psi(x,y,z) d_psi[ z + nz * ( (y) + ny * (x) ) ]\n      #define npsi(x,y,z) d_npsi[ z + nz * ( (y) + ny * (x) ) ]\n\n      const int tjj = omp_get_thread_num() / BSIZE;\n      const int tkk = omp_get_thread_num() % BSIZE;\n      const int blockIdx_x = omp_get_team_num() % bdimx;\n      const int blockIdx_y = omp_get_team_num() / bdimx % bdimy;\n      const int blockIdx_z = omp_get_team_num()  / (bdimx * bdimy);\n      const int gridDim_x = bdimx;\n      const int gridDim_y = bdimy;\n      const int gridDim_z = bdimz;\n\n      \n\n      d_psi = &(psi(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z));\n      d_npsi = &(npsi(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z));\n\n      d_sigmaX = &(sigmaX(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n      d_sigmaY = &(sigmaY(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n      d_sigmaZ = &(sigmaZ(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n\n      int nLast_x=XTILE+1; int nLast_y=(BSIZE-1); int nLast_z=(BSIZE-1);\n      if (blockIdx_x == gridDim_x-1) nLast_x = nx-2 - XTILE * blockIdx_x + 1;\n      if (blockIdx_y == gridDim_y-1) nLast_y = ny-2 - (BSIZE-2) * blockIdx_y + 1;\n      if (blockIdx_z == gridDim_z-1) nLast_z = nz-2 - (BSIZE-2) * blockIdx_z + 1;\n\n      \n\n      int pii,cii,nii,tii;\n      Real xcharge,ycharge,zcharge,dV = 0;\n\n      if(tjj <= nLast_y && tkk <= nLast_z) {\n        pii=0; cii=1; nii=2;\n        sm_psi[cii][tjj][tkk] = psi(0,tjj,tkk);\n        sm_psi[nii][tjj][tkk] = psi(1,tjj,tkk);\n      }\n\n      #pragma omp barrier\n\n      \n\n      if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n      {\n        Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n        Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n        Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n        dV -= sigmaX(1,tjj,tkk,0) * xd + sigmaX(1,tjj,tkk,1) * yd + sigmaX(1,tjj,tkk,2) * zd ; \n      }\n\n      if(tjj <= nLast_y && tkk <= nLast_z) {\n        tii=pii; pii=cii; cii=nii; nii=tii;\n      }\n\n      for(int ii=1;ii<nLast_x;ii++)\n      {\n        if(tjj <= nLast_y && tkk <= nLast_z)\n          sm_psi[nii][tjj][tkk] = psi(ii+1,tjj,tkk);\n        #pragma omp barrier\n\n        \n\n        if ((tkk>0) && (tkk<nLast_z) && (tjj<nLast_y))\n        {\n          Real xd=(-V0(tjj,tkk) - V0(1 + tjj,tkk) + V2(tjj,tkk) + V2(1 + tjj,tkk))/4.;\n          Real yd=-V1(tjj,tkk) + V1(1 + tjj,tkk);\n          Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V1(1 + tjj,-1 + tkk) + V1(1 + tjj,1 + tkk))/4.;\n          ycharge = sigmaY(ii,tjj+1,tkk,0) * xd + sigmaY(ii,tjj+1,tkk,1) * yd + sigmaY(ii,tjj+1,tkk,2) * zd ; \n          dV += ycharge;\n          sm_psi[3][tjj][tkk]=ycharge;\n        }\n        #pragma omp barrier\n\n        if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n          dV -= sm_psi[3][tjj-1][tkk];  \n\n\n        #pragma omp barrier\n\n        \n\n        if ((tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n        {\n          Real xd=(-V0(tjj,tkk) - V0(tjj,1 + tkk) + V2(tjj,tkk) + V2(tjj,1 + tkk))/4.;\n          Real yd=(-V1(-1 + tjj,tkk) - V1(-1 + tjj,1 + tkk) + V1(1 + tjj,tkk) + V1(1 + tjj,1 + tkk))/4.;\n          Real zd=-V1(tjj,tkk) + V1(tjj,1 + tkk);\n          zcharge = sigmaZ(ii,tjj,tkk+1,0) * xd + sigmaZ(ii,tjj,tkk+1,1) * yd + sigmaZ(ii,tjj,tkk+1,2) * zd ; \n          dV += zcharge;\n          sm_psi[3][tjj][tkk]=zcharge;\n        }\n\n        #pragma omp barrier\n\n        if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n          dV -= sm_psi[3][tjj][tkk-1];\n        #pragma omp barrier\n\n        \n\n        if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n        {\n          Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n          Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n          Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n          xcharge = sigmaX(ii+1,tjj,tkk,0) * xd + sigmaX(ii+1,tjj,tkk,1) * yd + sigmaX(ii+1,tjj,tkk,2) * zd ; \n          dV += xcharge;\n          npsi(ii,tjj,tkk) = dV; \n\n          dV = -xcharge; \n\n        }\n        #pragma omp barrier\n        if(tjj <= nLast_y && tkk <= nLast_z) {\n          tii=pii; pii=cii; cii=nii; nii=tii;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <grid dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n  const int nx = size;\n  const int ny = size;\n  const int nz = size;\n  const int vol = nx * ny * nz;\n  printf(\"Grid dimension: nx=%d ny=%d nz=%d\\n\",nx,ny,nz);\n\n  \n\n  Real *h_Vm = (Real*)malloc(sizeof(Real)*vol);\n\n  #define h_Vm(x,y,z) h_Vm[ z + nz * ( y + ny * ( x  ) ) ]\n\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        h_Vm(ii,jj,kk) = (ii*(ny*nz) + jj * nz + kk) % 19;\n\n  \n\n  Real *h_sigma = (Real*) malloc(sizeof(Real)*vol*9);\n  for (int i = 0; i < vol*9; i++) h_sigma[i] = i % 19;\n\n  \n\n  Real *h_dVm = (Real*) malloc (sizeof(Real) * vol);\n  memset(h_dVm, 0, sizeof(Real) * vol);\n\n  \n\n  int bdimz = (nz-2)/(BSIZE-2) + ((nz-2)%(BSIZE-2)==0?0:1);\n  int bdimy = (ny-2)/(BSIZE-2) + ((ny-2)%(BSIZE-2)==0?0:1);\n  int bdimx = (nx-2)/XTILE + ((nx-2)%XTILE==0?0:1);\n\n  #pragma omp target data map(to: h_Vm[0:vol], h_sigma[0:vol*9]) map(tofrom: h_dVm[0:vol])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      stencil3d(h_Vm, h_dVm, h_sigma, h_sigma + 3*vol, h_sigma + 6*vol, \n                bdimx, bdimy, bdimz, nx, ny, nz);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n#ifdef DUMP\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        printf(\"dVm (%d,%d,%d)=%e\\n\",ii,jj,kk,h_dVm[kk+nz*(jj+ny*ii)]);\n#endif\n\n  free(h_sigma);\n  free(h_Vm);\n  free(h_dVm);\n\n  return 0;\n}\n"}}
{"kernel_name": "stencil3d", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n\n\n\n#define BSIZE 16\n\n\n#define XTILE 20\n\ntypedef float Real;\n\nvoid stencil3d(\n    const Real*__restrict d_psi, \n          Real*__restrict d_npsi, \n    const Real*__restrict d_sigmaX, \n    const Real*__restrict d_sigmaY, \n    const Real*__restrict d_sigmaZ,\n    int bdimx, int bdimy, int bdimz,\n    int nx, int ny, int nz)\n{\n    {\n    Real sm_psi[4][BSIZE][BSIZE];\n        {\n      #define V0(y,z) sm_psi[pii][y][z]\n      #define V1(y,z) sm_psi[cii][y][z]\n      #define V2(y,z) sm_psi[nii][y][z]\n      \n      #define sigmaX(x,y,z,dir) d_sigmaX[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n      #define sigmaY(x,y,z,dir) d_sigmaY[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n      #define sigmaZ(x,y,z,dir) d_sigmaZ[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n      \n      #define psi(x,y,z) d_psi[ z + nz * ( (y) + ny * (x) ) ]\n      #define npsi(x,y,z) d_npsi[ z + nz * ( (y) + ny * (x) ) ]\n\n      const int tjj = omp_get_thread_num() / BSIZE;\n      const int tkk = omp_get_thread_num() % BSIZE;\n      const int blockIdx_x = omp_get_team_num() % bdimx;\n      const int blockIdx_y = omp_get_team_num() / bdimx % bdimy;\n      const int blockIdx_z = omp_get_team_num()  / (bdimx * bdimy);\n      const int gridDim_x = bdimx;\n      const int gridDim_y = bdimy;\n      const int gridDim_z = bdimz;\n\n      \n\n      d_psi = &(psi(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z));\n      d_npsi = &(npsi(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z));\n\n      d_sigmaX = &(sigmaX(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n      d_sigmaY = &(sigmaY(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n      d_sigmaZ = &(sigmaZ(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n\n      int nLast_x=XTILE+1; int nLast_y=(BSIZE-1); int nLast_z=(BSIZE-1);\n      if (blockIdx_x == gridDim_x-1) nLast_x = nx-2 - XTILE * blockIdx_x + 1;\n      if (blockIdx_y == gridDim_y-1) nLast_y = ny-2 - (BSIZE-2) * blockIdx_y + 1;\n      if (blockIdx_z == gridDim_z-1) nLast_z = nz-2 - (BSIZE-2) * blockIdx_z + 1;\n\n      \n\n      int pii,cii,nii,tii;\n      Real xcharge,ycharge,zcharge,dV = 0;\n\n      if(tjj <= nLast_y && tkk <= nLast_z) {\n        pii=0; cii=1; nii=2;\n        sm_psi[cii][tjj][tkk] = psi(0,tjj,tkk);\n        sm_psi[nii][tjj][tkk] = psi(1,tjj,tkk);\n      }\n\n      \n      \n\n      if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n      {\n        Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n        Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n        Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n        dV -= sigmaX(1,tjj,tkk,0) * xd + sigmaX(1,tjj,tkk,1) * yd + sigmaX(1,tjj,tkk,2) * zd ; \n      }\n\n      if(tjj <= nLast_y && tkk <= nLast_z) {\n        tii=pii; pii=cii; cii=nii; nii=tii;\n      }\n\n      for(int ii=1;ii<nLast_x;ii++)\n      {\n        if(tjj <= nLast_y && tkk <= nLast_z)\n          sm_psi[nii][tjj][tkk] = psi(ii+1,tjj,tkk);\n        \n        \n\n        if ((tkk>0) && (tkk<nLast_z) && (tjj<nLast_y))\n        {\n          Real xd=(-V0(tjj,tkk) - V0(1 + tjj,tkk) + V2(tjj,tkk) + V2(1 + tjj,tkk))/4.;\n          Real yd=-V1(tjj,tkk) + V1(1 + tjj,tkk);\n          Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V1(1 + tjj,-1 + tkk) + V1(1 + tjj,1 + tkk))/4.;\n          ycharge = sigmaY(ii,tjj+1,tkk,0) * xd + sigmaY(ii,tjj+1,tkk,1) * yd + sigmaY(ii,tjj+1,tkk,2) * zd ; \n          dV += ycharge;\n          sm_psi[3][tjj][tkk]=ycharge;\n        }\n        \n        if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n          dV -= sm_psi[3][tjj-1][tkk];  \n\n\n        \n        \n\n        if ((tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n        {\n          Real xd=(-V0(tjj,tkk) - V0(tjj,1 + tkk) + V2(tjj,tkk) + V2(tjj,1 + tkk))/4.;\n          Real yd=(-V1(-1 + tjj,tkk) - V1(-1 + tjj,1 + tkk) + V1(1 + tjj,tkk) + V1(1 + tjj,1 + tkk))/4.;\n          Real zd=-V1(tjj,tkk) + V1(tjj,1 + tkk);\n          zcharge = sigmaZ(ii,tjj,tkk+1,0) * xd + sigmaZ(ii,tjj,tkk+1,1) * yd + sigmaZ(ii,tjj,tkk+1,2) * zd ; \n          dV += zcharge;\n          sm_psi[3][tjj][tkk]=zcharge;\n        }\n\n        \n        if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n          dV -= sm_psi[3][tjj][tkk-1];\n        \n        \n\n        if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n        {\n          Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n          Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n          Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n          xcharge = sigmaX(ii+1,tjj,tkk,0) * xd + sigmaX(ii+1,tjj,tkk,1) * yd + sigmaX(ii+1,tjj,tkk,2) * zd ; \n          dV += xcharge;\n          npsi(ii,tjj,tkk) = dV; \n\n          dV = -xcharge; \n\n        }\n                if(tjj <= nLast_y && tkk <= nLast_z) {\n          tii=pii; pii=cii; cii=nii; nii=tii;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <grid dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n  const int nx = size;\n  const int ny = size;\n  const int nz = size;\n  const int vol = nx * ny * nz;\n  printf(\"Grid dimension: nx=%d ny=%d nz=%d\\n\",nx,ny,nz);\n\n  \n\n  Real *h_Vm = (Real*)malloc(sizeof(Real)*vol);\n\n  #define h_Vm(x,y,z) h_Vm[ z + nz * ( y + ny * ( x  ) ) ]\n\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        h_Vm(ii,jj,kk) = (ii*(ny*nz) + jj * nz + kk) % 19;\n\n  \n\n  Real *h_sigma = (Real*) malloc(sizeof(Real)*vol*9);\n  for (int i = 0; i < vol*9; i++) h_sigma[i] = i % 19;\n\n  \n\n  Real *h_dVm = (Real*) malloc (sizeof(Real) * vol);\n  memset(h_dVm, 0, sizeof(Real) * vol);\n\n  \n\n  int bdimz = (nz-2)/(BSIZE-2) + ((nz-2)%(BSIZE-2)==0?0:1);\n  int bdimy = (ny-2)/(BSIZE-2) + ((ny-2)%(BSIZE-2)==0?0:1);\n  int bdimx = (nx-2)/XTILE + ((nx-2)%XTILE==0?0:1);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      stencil3d(h_Vm, h_dVm, h_sigma, h_sigma + 3*vol, h_sigma + 6*vol, \n                bdimx, bdimy, bdimz, nx, ny, nz);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n#ifdef DUMP\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        printf(\"dVm (%d,%d,%d)=%e\\n\",ii,jj,kk,h_dVm[kk+nz*(jj+ny*ii)]);\n#endif\n\n  free(h_sigma);\n  free(h_Vm);\n  free(h_dVm);\n\n  return 0;\n}"}}
{"kernel_name": "stencil3d", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n\n\n#define BSIZE 16\n\n\n#define XTILE 20\n\ntypedef double Real;\n\nvoid stencil3d(\n          sycl::nd_item<3> &item,\n          Real*__restrict sm_psi,\n    const Real*__restrict d_psi,\n          Real*__restrict d_npsi,\n    const Real*__restrict d_sigmaX,\n    const Real*__restrict d_sigmaY,\n    const Real*__restrict d_sigmaZ,\n    int nx, int ny, int nz)\n{\n  #define V0(y,z) sm_psi[pii*BSIZE*BSIZE+(y)*BSIZE+(z)]\n  #define V1(y,z) sm_psi[cii*BSIZE*BSIZE+(y)*BSIZE+(z)]\n  #define V2(y,z) sm_psi[nii*BSIZE*BSIZE+(y)*BSIZE+(z)]\n\n  #define sigmaX(x,y,z,dir) d_sigmaX[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n  #define sigmaY(x,y,z,dir) d_sigmaY[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n  #define sigmaZ(x,y,z,dir) d_sigmaZ[ z + nz * ( y + ny * ( x + nx * dir ) ) ]\n\n  #define psi(x,y,z) d_psi[ z + nz * ( (y) + ny * (x) ) ]\n  #define npsi(x,y,z) d_npsi[ z + nz * ( (y) + ny * (x) ) ]\n\n  const int tjj = item.get_local_id(1);\n  const int tkk = item.get_local_id(2);\n  const int blockIdx_x = item.get_group(2);\n  const int blockIdx_y = item.get_group(1);\n  const int blockIdx_z = item.get_group(0);\n  const int gridDim_x = item.get_group_range(2);\n  const int gridDim_y = item.get_group_range(1);\n  const int gridDim_z = item.get_group_range(0);\n\n  \n\n  d_psi = &(psi(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z));\n  d_npsi = &(npsi(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z));\n\n  d_sigmaX = &(sigmaX(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n  d_sigmaY = &(sigmaY(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n  d_sigmaZ = &(sigmaZ(XTILE*blockIdx_x, (BSIZE-2)*blockIdx_y, (BSIZE-2)*blockIdx_z, 0));\n\n  int nLast_x=XTILE+1; int nLast_y=(BSIZE-1); int nLast_z=(BSIZE-1);\n  if (blockIdx_x == gridDim_x-1) nLast_x = nx-2 - XTILE * blockIdx_x + 1;\n  if (blockIdx_y == gridDim_y-1) nLast_y = ny-2 - (BSIZE-2) * blockIdx_y + 1;\n  if (blockIdx_z == gridDim_z-1) nLast_z = nz-2 - (BSIZE-2) * blockIdx_z + 1;\n\n  if(tjj>nLast_y || tkk>nLast_z) return;\n\n  \n\n  int pii,cii,nii,tii;\n  pii=0; cii=1; nii=2;\n\n  sm_psi[cii*BSIZE*BSIZE+tjj*BSIZE+tkk] = psi(0,tjj,tkk);\n  sm_psi[nii*BSIZE*BSIZE+tjj*BSIZE+tkk] = psi(1,tjj,tkk);\n  Real xcharge,ycharge,zcharge,dV = 0;\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n  {\n    Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n    Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n    Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n    dV -= sigmaX(1,tjj,tkk,0) * xd + sigmaX(1,tjj,tkk,1) * yd + sigmaX(1,tjj,tkk,2) * zd ;\n  }\n\n  tii=pii; pii=cii; cii=nii; nii=tii;\n\n  for(int ii=1;ii<nLast_x;ii++)\n  {\n    sm_psi[nii*BSIZE*BSIZE+tjj*BSIZE+tkk] = psi(ii+1,tjj,tkk);\n    item.barrier(sycl::access::fence_space::local_space);\n\n    \n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj<nLast_y))\n    {\n      Real xd=(-V0(tjj,tkk) - V0(1 + tjj,tkk) + V2(tjj,tkk) + V2(1 + tjj,tkk))/4.;\n      Real yd=-V1(tjj,tkk) + V1(1 + tjj,tkk);\n      Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V1(1 + tjj,-1 + tkk) + V1(1 + tjj,1 + tkk))/4.;\n      ycharge = sigmaY(ii,tjj+1,tkk,0) * xd + sigmaY(ii,tjj+1,tkk,1) * yd + sigmaY(ii,tjj+1,tkk,2) * zd ;\n      dV += ycharge;\n      sm_psi[3*BSIZE*BSIZE+tjj*BSIZE+tkk]=ycharge;\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n      dV -= sm_psi[3*BSIZE*BSIZE+(tjj-1)*BSIZE+tkk];  \n\n\n    item.barrier(sycl::access::fence_space::local_space);\n\n    \n\n    if ((tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n    {\n      Real xd=(-V0(tjj,tkk) - V0(tjj,1 + tkk) + V2(tjj,tkk) + V2(tjj,1 + tkk))/4.;\n      Real yd=(-V1(-1 + tjj,tkk) - V1(-1 + tjj,1 + tkk) + V1(1 + tjj,tkk) + V1(1 + tjj,1 + tkk))/4.;\n      Real zd=-V1(tjj,tkk) + V1(tjj,1 + tkk);\n      zcharge = sigmaZ(ii,tjj,tkk+1,0) * xd + sigmaZ(ii,tjj,tkk+1,1) * yd + sigmaZ(ii,tjj,tkk+1,2) * zd ;\n      dV += zcharge;\n      sm_psi[3*BSIZE*BSIZE+tjj*BSIZE+tkk]=zcharge;\n    }\n\n    item.barrier(sycl::access::fence_space::local_space);\n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n      dV -= sm_psi[3*BSIZE*BSIZE+tjj*BSIZE+tkk-1];\n    item.barrier(sycl::access::fence_space::local_space);\n\n    \n\n    if ((tkk>0) && (tkk<nLast_z) && (tjj>0) && (tjj<nLast_y))\n    {\n      Real xd=-V1(tjj,tkk) + V2(tjj,tkk);\n      Real yd=(-V1(-1 + tjj,tkk) + V1(1 + tjj,tkk) - V2(-1 + tjj,tkk) + V2(1 + tjj,tkk))/4.;\n      Real zd=(-V1(tjj,-1 + tkk) + V1(tjj,1 + tkk) - V2(tjj,-1 + tkk) + V2(tjj,1 + tkk))/4.;\n      xcharge = sigmaX(ii+1,tjj,tkk,0) * xd + sigmaX(ii+1,tjj,tkk,1) * yd + sigmaX(ii+1,tjj,tkk,2) * zd ;\n      dV += xcharge;\n      npsi(ii,tjj,tkk) = dV; \n\n      dV = -xcharge; \n\n    }\n    item.barrier(sycl::access::fence_space::local_space);\n    tii=pii; pii=cii; cii=nii; nii=tii;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <grid dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n  const int nx = size;\n  const int ny = size;\n  const int nz = size;\n  const int vol = nx * ny * nz;\n  printf(\"Grid dimension: nx=%d ny=%d nz=%d\\n\",nx,ny,nz);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  Real *h_Vm = (Real*)malloc(sizeof(Real)*vol);\n\n#define h_Vm(x,y,z) h_Vm[ z + nz * ( y + ny * ( x  ) ) ]\n\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        h_Vm(ii,jj,kk) = (ii*(ny*nz) + jj * nz + kk) % 19;\n\n  Real *d_Vm = sycl::malloc_device<Real>(vol, q);\n  q.memcpy(d_Vm, h_Vm, sizeof(Real) * vol);\n\n  \n\n  Real *h_sigma = (Real*) malloc(sizeof(Real)*vol*9);\n\n  for (int i = 0; i < vol*9; i++) h_sigma[i] = i % 19;\n\n  Real *d_sigma = sycl::malloc_device<Real>(vol*9, q);\n  q.memcpy(d_sigma, h_sigma, sizeof(Real) * vol*9);\n\n  \n\n  Real *d_dVm = sycl::malloc_device<Real>(vol, q);\n  q.memset(d_dVm, 0, sizeof(Real) * vol);\n\n  \n\n  int bdimz = (nz-2)/(BSIZE-2) + ((nz-2)%(BSIZE-2)==0?0:1);\n  int bdimy = (ny-2)/(BSIZE-2) + ((ny-2)%(BSIZE-2)==0?0:1);\n  int bdimx = (nx-2)/XTILE + ((nx-2)%XTILE==0?0:1);\n  sycl::range<3> gws (bdimz, bdimy*BSIZE, bdimx*BSIZE);\n  sycl::range<3> lws (1, BSIZE, BSIZE);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<Real, 1> sm_psi (sycl::range<1>(4*BSIZE*BSIZE), cgh);\n      cgh.parallel_for<class diffusion>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        stencil3d(item, sm_psi.get_pointer(), d_Vm, d_dVm,\n                  d_sigma, d_sigma + 3*vol, d_sigma + 6*vol,\n                  nx, ny, nz);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  \n\n  Real *h_dVm = (Real*) malloc (sizeof(Real) * vol);\n  q.memcpy(h_dVm, d_dVm, vol*sizeof(Real)).wait();\n\n#ifdef DUMP\n  for(int ii=0;ii<nx;ii++)\n    for(int jj=0;jj<ny;jj++)\n      for(int kk=0;kk<nz;kk++)\n        printf(\"dVm (%d,%d,%d)=%e\\n\",ii,jj,kk,h_dVm[kk+nz*(jj+ny*ii)]);\n#endif\n\n  sycl::free(d_Vm, q);\n  sycl::free(d_dVm, q);\n  sycl::free(d_sigma, q);\n  free(h_sigma);\n  free(h_Vm);\n  free(h_dVm);\n\n  return 0;\n}\n"}}
{"kernel_name": "surfel", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <cuda.h>\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\ntemplate<typename T>\n__global__ void surfel_render(\n  const T *__restrict__ s,\n  int N,\n  T f,\n  int w,\n  int h,\n  T *__restrict__ d)\n{\n  const int idx = threadIdx.x + blockIdx.x*blockDim.x;\n  const int idy = threadIdx.y + blockIdx.y*blockDim.y;\n\n  if(idx < w && idy < h)\n  {\n    T ray[3];\n    ray[0] = T(idx)-(w-1)*(T)0.5;\n    ray[1] = T(idy)-(h-1)*(T)0.5;\n    ray[2] = f;\n    T pt[3];\n    T n[3];\n    T p[3];\n    T dMin = 1e20;\n    \n    for (int i=0; i<N; ++i) {\n      p[0] = s[i*COL_DIM+COL_P_X];\n      p[1] = s[i*COL_DIM+COL_P_Y];\n      p[2] = s[i*COL_DIM+COL_P_Z];\n      n[0] = s[i*COL_DIM+COL_N_X];\n      n[1] = s[i*COL_DIM+COL_N_Y];\n      n[2] = s[i*COL_DIM+COL_N_Z];\n      T rSqMax = s[i*COL_DIM+COL_RSq];\n      T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n      T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n      T alpha = pDotn / dsDotRay;\n      pt[0] = ray[0]*alpha - p[0];\n      pt[1] = ray[1]*alpha - p[1];\n      pt[2] = ray[2]*alpha - p[2];\n      T t = ray[2]*alpha;\n      T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n      if (rSq < rSqMax && dMin > t) {\n        dMin = t; \n\n      }\n    }\n    d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n  }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *d_src, *d_dst;\n  cudaMalloc((void**)&d_dst, dst_size * sizeof(T));\n  cudaMalloc((void**)&d_src, src_size * sizeof(T));\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n  cudaMemcpy(d_src, h_src, src_size * sizeof(T), cudaMemcpyHostToDevice); \n\n  dim3 threads(16, 16);\n  dim3 blocks((w+15)/16, (h+15)/16);\n\n  for (int f = 0; f < 3; f++) {\n    printf(\"\\nf = %d\\n\", f);\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      surfel_render<T><<<blocks, threads>>>(d_src, n, inverseFocalLength[f], w, h, d_dst);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    cudaMemcpy(h_dst, d_dst, dst_size * sizeof(T), cudaMemcpyDeviceToHost); \n    T *min = std::min_element( h_dst, h_dst + w*h );\n    T *max = std::max_element( h_dst, h_dst + w*h );\n    printf(\"Value range [%e, %e]\\n\", *min, *max);\n  }\n\n  free(h_dst);\n  free(h_src);\n  cudaFree(d_dst);\n  cudaFree(d_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(n, w, h, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "surfel", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\ntemplate<typename T>\n__global__ void surfel_render(\n  const T *__restrict__ s,\n  int N,\n  T f,\n  int w,\n  int h,\n  T *__restrict__ d)\n{\n  const int idx = threadIdx.x + blockIdx.x*blockDim.x;\n  const int idy = threadIdx.y + blockIdx.y*blockDim.y;\n\n  if(idx < w && idy < h)\n  {\n    T ray[3];\n    ray[0] = T(idx)-(w-1)*(T)0.5;\n    ray[1] = T(idy)-(h-1)*(T)0.5;\n    ray[2] = f;\n    T pt[3];\n    T n[3];\n    T p[3];\n    T dMin = 1e20;\n    \n    for (int i=0; i<N; ++i) {\n      p[0] = s[i*COL_DIM+COL_P_X];\n      p[1] = s[i*COL_DIM+COL_P_Y];\n      p[2] = s[i*COL_DIM+COL_P_Z];\n      n[0] = s[i*COL_DIM+COL_N_X];\n      n[1] = s[i*COL_DIM+COL_N_Y];\n      n[2] = s[i*COL_DIM+COL_N_Z];\n      T rSqMax = s[i*COL_DIM+COL_RSq];\n      T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n      T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n      T alpha = pDotn / dsDotRay;\n      pt[0] = ray[0]*alpha - p[0];\n      pt[1] = ray[1]*alpha - p[1];\n      pt[2] = ray[2]*alpha - p[2];\n      T t = ray[2]*alpha;\n      T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n      if (rSq < rSqMax && dMin > t) {\n        dMin = t; \n\n      }\n    }\n    d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n  }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *d_src, *d_dst;\n  hipMalloc((void**)&d_dst, dst_size * sizeof(T));\n  hipMalloc((void**)&d_src, src_size * sizeof(T));\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n  hipMemcpy(d_src, h_src, src_size * sizeof(T), hipMemcpyHostToDevice); \n\n  dim3 threads(16, 16);\n  dim3 blocks((w+15)/16, (h+15)/16);\n\n  for (int f = 0; f < 3; f++) {\n    printf(\"\\nf = %d\\n\", f);\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      hipLaunchKernelGGL(HIP_KERNEL_NAME(surfel_render<T>), blocks, threads, 0, 0, d_src, n, inverseFocalLength[f], w, h, d_dst);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    hipMemcpy(h_dst, d_dst, dst_size * sizeof(T), hipMemcpyDeviceToHost); \n    T *min = std::min_element( h_dst, h_dst + w*h );\n    T *max = std::max_element( h_dst, h_dst + w*h );\n    printf(\"Value range [%e, %e]\\n\", *min, *max);\n  }\n\n  free(h_dst);\n  free(h_src);\n  hipFree(d_dst);\n  hipFree(d_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(n, w, h, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "surfel", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <omp.h>\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\n  template<typename T>\nvoid surfel_render(\n    const T *__restrict s,\n    int N,\n    T f,\n    int w,\n    int h,\n    T *__restrict d)\n{\n  #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n  for (int idy = 0; idy < h; idy++)\n    for (int idx = 0; idx < w; idx++) {\n\n      T ray[3];\n      ray[0] = T(idx)-(w-1)*(T)0.5;\n      ray[1] = T(idy)-(h-1)*(T)0.5;\n      ray[2] = f;\n      T pt[3];\n      T n[3];\n      T p[3];\n      T dMin = 1e20;\n\n      for (int i=0; i<N; ++i) {\n        p[0] = s[i*COL_DIM+COL_P_X];\n        p[1] = s[i*COL_DIM+COL_P_Y];\n        p[2] = s[i*COL_DIM+COL_P_Z];\n        n[0] = s[i*COL_DIM+COL_N_X];\n        n[1] = s[i*COL_DIM+COL_N_Y];\n        n[2] = s[i*COL_DIM+COL_N_Z];\n        T rSqMax = s[i*COL_DIM+COL_RSq];\n        T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n        T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n        T alpha = pDotn / dsDotRay;\n        pt[0] = ray[0]*alpha - p[0];\n        pt[1] = ray[1]*alpha - p[1];\n        pt[2] = ray[2]*alpha - p[2];\n        T t = ray[2]*alpha;\n        T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n        if (rSq < rSqMax && dMin > t) {\n          dMin = t; \n\n        }\n      }\n      d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n    }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n#pragma omp target data map(to: h_src[0:src_size]) \\\n                        map(alloc: h_dst[0:dst_size])\n  {\n    for (int f = 0; f < 3; f++) {\n      printf(\"\\nf = %d\\n\", f);\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++)\n        surfel_render<T>(h_src, n, inverseFocalLength[f], w, h, h_dst);\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n      #pragma omp target update from (h_dst[0:dst_size])\n      T *min = std::min_element( h_dst, h_dst + w*h );\n      T *max = std::max_element( h_dst, h_dst + w*h );\n      printf(\"value range [%e, %e]\\n\", *min, *max);\n    }\n  }\n\n  free(h_dst);\n  free(h_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(n, w, h, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "surfel", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\n  template<typename T>\nvoid surfel_render(\n    const T *__restrict s,\n    int N,\n    T f,\n    int w,\n    int h,\n    T *__restrict d)\n{\n    for (int idy = 0; idy < h; idy++)\n    for (int idx = 0; idx < w; idx++) {\n\n      T ray[3];\n      ray[0] = T(idx)-(w-1)*(T)0.5;\n      ray[1] = T(idy)-(h-1)*(T)0.5;\n      ray[2] = f;\n      T pt[3];\n      T n[3];\n      T p[3];\n      T dMin = 1e20;\n\n      for (int i=0; i<N; ++i) {\n        p[0] = s[i*COL_DIM+COL_P_X];\n        p[1] = s[i*COL_DIM+COL_P_Y];\n        p[2] = s[i*COL_DIM+COL_P_Z];\n        n[0] = s[i*COL_DIM+COL_N_X];\n        n[1] = s[i*COL_DIM+COL_N_Y];\n        n[2] = s[i*COL_DIM+COL_N_Z];\n        T rSqMax = s[i*COL_DIM+COL_RSq];\n        T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n        T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n        T alpha = pDotn / dsDotRay;\n        pt[0] = ray[0]*alpha - p[0];\n        pt[1] = ray[1]*alpha - p[1];\n        pt[2] = ray[2]*alpha - p[2];\n        T t = ray[2]*alpha;\n        T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n        if (rSq < rSqMax && dMin > t) {\n          dMin = t; \n\n        }\n      }\n      d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n    }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n  {\n    for (int f = 0; f < 3; f++) {\n      printf(\"\\nf = %d\\n\", f);\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++)\n        surfel_render<T>(h_src, n, inverseFocalLength[f], w, h, h_dst);\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n            T *min = std::min_element( h_dst, h_dst + w*h );\n      T *max = std::max_element( h_dst, h_dst + w*h );\n      printf(\"value range [%e, %e]\\n\", *min, *max);\n    }\n  }\n\n  free(h_dst);\n  free(h_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(n, w, h, repeat);\n  return 0;\n}"}}
{"kernel_name": "surfel", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include \"common.h\"\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\ntemplate<typename T>\nclass k;\n\n\n\ntemplate<typename T>\nvoid surfel_render(\n  nd_item<2> &item,\n  const T *__restrict s,\n  int N,\n  T f,\n  int w,\n  int h,\n  T *__restrict d)\n{\n  const int idx = item.get_global_id(1);\n  const int idy = item.get_global_id(0);\n\n  if(idx < w && idy < h)\n  {\n    T ray[3];\n    ray[0] = T(idx)-(w-1)*(T)0.5;\n    ray[1] = T(idy)-(h-1)*(T)0.5;\n    ray[2] = f;\n    T pt[3];\n    T n[3];\n    T p[3];\n    T dMin = 1e20;\n    \n    for (int i=0; i<N; ++i) {\n      p[0] = s[i*COL_DIM+COL_P_X];\n      p[1] = s[i*COL_DIM+COL_P_Y];\n      p[2] = s[i*COL_DIM+COL_P_Z];\n      n[0] = s[i*COL_DIM+COL_N_X];\n      n[1] = s[i*COL_DIM+COL_N_Y];\n      n[2] = s[i*COL_DIM+COL_N_Z];\n      T rSqMax = s[i*COL_DIM+COL_RSq];\n      T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n      T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n      T alpha = pDotn / dsDotRay;\n      pt[0] = ray[0]*alpha - p[0];\n      pt[1] = ray[1]*alpha - p[1];\n      pt[2] = ray[2]*alpha - p[2];\n      T t = ray[2]*alpha;\n      T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n      if (rSq < rSqMax && dMin > t) {\n        dMin = t; \n\n      }\n    }\n    d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n  }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(queue &q, int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n  buffer<T, 1> d_src (h_src, src_size);\n  buffer<T, 1> d_dst (dst_size);\n\n  range<2> lws (16, 16);\n  range<2> gws ((h+15)/16*16, (w+15)/16*16);\n  for (int f = 0; f < 3; f++) {\n    printf(\"\\nf = %d\\n\", f);\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      q.submit([&] (handler &cgh) {\n        auto src = d_src.template get_access<sycl_read>(cgh);\n        auto dst = d_dst.template get_access<sycl_discard_write>(cgh);\n        cgh.parallel_for<class k<T>>(nd_range<2>(gws, lws), [=] (nd_item<2> item) {\n          surfel_render<T>(item, src.get_pointer(), n, \n                           inverseFocalLength[f], w, h,\n                           dst.get_pointer());\n        });\n      });\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    q.submit([&] (handler &cgh) {\n      auto acc = d_dst.template get_access<sycl_read>(cgh);\n      cgh.copy(acc, h_dst);\n    }).wait();\n\n    T *min = std::min_element( h_dst, h_dst + w*h );\n    T *max = std::max_element( h_dst, h_dst + w*h );\n    printf(\"value range [%e, %e]\\n\", *min, *max);\n  }\n\n  free(h_dst);\n  free(h_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n#ifdef USE_GPU\n  gpu_selector dev_sel;\n#else\n  cpu_selector dev_sel;\n#endif\n  queue q(dev_sel);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(q, n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(q, n, w, h, repeat);\n  return 0;\n}\n"}}
