{"kernel_name": "adam", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <cuda.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\n__global__\nvoid adam (\n        T* __restrict__ p,\n        T* __restrict__ m,\n        T* __restrict__ v,\n  const G* __restrict__ g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n  const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  const size_t totThreads = gridDim.x*blockDim.x;\n\n  for (size_t j = i; j < vector_size; j += totThreads) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-powf(b1, t));\n      float v_corrected = v[j] / (1.f-powf(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sqrtf(v_corrected + eps);\n      else \n\n        denom = sqrtf(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  float *d_m, *d_v, *d_g, *d_p;\n\n  cudaMalloc((void**)&d_m, size_bytes);\n  cudaMemcpy(d_m, m, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_v, size_bytes);\n  cudaMemcpy(d_v, v, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_g, size_bytes);\n  cudaMemcpy(d_g, g, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_p, size_bytes);\n  cudaMemcpy(d_p, p, size_bytes, cudaMemcpyHostToDevice);\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-8f;\n  const float grad_scale = 256.f;\n\n  const int threadsPerBlock = 256;\n  const dim3 grids ((vector_size+threadsPerBlock-1) / threadsPerBlock);\n  const dim3 blocks (threadsPerBlock);\n\n  adamMode_t mode = ADAM_MODE_0;\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    adam<float, float><<<grids, blocks>>> (\n      d_p, d_m, d_v, d_g,\n      beta1, beta2,\n      eps,\n      grad_scale,\n      step_size,\n      time_step,\n      vector_size,\n      mode,\n      decay);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n\n  cudaMemcpy(p, d_p, size_bytes, cudaMemcpyDeviceToHost); \n\n  cudaFree(d_p);\n  cudaFree(d_m);\n  cudaFree(d_v);\n  cudaFree(d_g);\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "adam", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <hip/hip_runtime.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\n__global__\nvoid adam (\n        T* __restrict__ p,\n        T* __restrict__ m,\n        T* __restrict__ v,\n  const G* __restrict__ g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n  const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  const size_t totThreads = gridDim.x*blockDim.x;\n\n  for (size_t j = i; j < vector_size; j += totThreads) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-powf(b1, t));\n      float v_corrected = v[j] / (1.f-powf(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sqrtf(v_corrected + eps);\n      else \n\n        denom = sqrtf(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  float *d_m, *d_v, *d_g, *d_p;\n\n  hipMalloc((void**)&d_m, size_bytes);\n  hipMemcpy(d_m, m, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_v, size_bytes);\n  hipMemcpy(d_v, v, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_g, size_bytes);\n  hipMemcpy(d_g, g, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_p, size_bytes);\n  hipMemcpy(d_p, p, size_bytes, hipMemcpyHostToDevice);\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-8f;\n  const float grad_scale = 256.f;\n\n  const int threadsPerBlock = 256;\n  const dim3 grids ((vector_size+threadsPerBlock-1) / threadsPerBlock);\n  const dim3 blocks (threadsPerBlock);\n\n  adamMode_t mode = ADAM_MODE_0;\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    adam<float, float><<<grids, blocks>>> (\n      d_p, d_m, d_v, d_g,\n      beta1, beta2,\n      eps,\n      grad_scale,\n      step_size,\n      time_step,\n      vector_size,\n      mode,\n      decay);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n\n  hipMemcpy(p, d_p, size_bytes, hipMemcpyDeviceToHost); \n\n  hipFree(d_p);\n  hipFree(d_m);\n  hipFree(d_v);\n  hipFree(d_g);\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "adam", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <omp.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\ninline void adam (\n        T* __restrict p,\n        T* __restrict m,\n        T* __restrict v,\n  const G* __restrict g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (size_t j = 0; j < vector_size; j++) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-powf(b1, t));\n      float v_corrected = v[j] / (1.f-powf(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sqrtf(v_corrected + eps);\n      else \n\n        denom = sqrtf(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-10f;\n  const float grad_scale = 256.f;\n\n  adamMode_t mode = ADAM_MODE_0;\n\n  #pragma omp target data map (to: m[0:vector_size], v[0:vector_size], g[0:vector_size]) \\\n                          map (tofrom: p[0:vector_size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      adam<float, float>(\n        p, m, v, g,\n        beta1, beta2,\n        eps,\n        grad_scale,\n        step_size,\n        time_step,\n        vector_size,\n        mode,\n        decay);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "adam", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\ninline void adam (\n        T* __restrict p,\n        T* __restrict m,\n        T* __restrict v,\n  const G* __restrict g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n    for (size_t j = 0; j < vector_size; j++) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-powf(b1, t));\n      float v_corrected = v[j] / (1.f-powf(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sqrtf(v_corrected + eps);\n      else \n\n        denom = sqrtf(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-10f;\n  const float grad_scale = 256.f;\n\n  adamMode_t mode = ADAM_MODE_0;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      adam<float, float>(\n        p, m, v, g,\n        beta1, beta2,\n        eps,\n        grad_scale,\n        step_size,\n        time_step,\n        vector_size,\n        mode,\n        decay);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n  }\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}"}}
{"kernel_name": "adam", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <sycl/sycl.hpp>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename T, typename G>\nvoid adam (\n  sycl::nd_item<1> &item,\n        T* __restrict p,\n        T* __restrict m,\n        T* __restrict v,\n  const G* __restrict g,\n  const float b1,\n  const float b2,\n  const float eps,\n  const float grad_scale,\n  const float step_size,\n  const int time_step,\n  const size_t vector_size,\n  adamMode_t mode,\n  const float decay)\n{\n  const int i = item.get_global_id(0);\n  const int totThreads = item.get_group_range(0) * item.get_local_range(0);\n\n  for (size_t j = i; j < vector_size; j += totThreads) {\n    for (int t = 1; t <= time_step; t++) {\n      T scaled_grad = g[j]/grad_scale;\n      m[j] = b1*m[j] + (1.f-b1)*scaled_grad;\n      v[j] = b2*v[j] + (1.f-b2)*scaled_grad*scaled_grad;\n      float m_corrected = m[j] / (1.f-sycl::pown(b1, t));\n      float v_corrected = v[j] / (1.f-sycl::pown(b2, t));\n      float denom;\n      if (mode == ADAM_MODE_0)\n        denom = sycl::sqrt(v_corrected + eps);\n      else \n\n        denom = sycl::sqrt(v_corrected) + eps;\n      float update = (m_corrected/denom) + (decay*p[j]);\n      p[j] -= (step_size*update);\n    }\n  }\n}\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <vector size> <number of time steps> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int vector_size = atoi(argv[1]);\n  const int time_step = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  size_t size_bytes = vector_size * sizeof(float);\n\n  float *m = (float*) malloc (size_bytes);\n  float *v = (float*) malloc (size_bytes);\n  float *g = (float*) malloc (size_bytes);\n  float *p = (float*) malloc (size_bytes);\n  float *r = (float*) malloc (size_bytes);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<float> dist(0, 1);\n  for (int i = 0; i < vector_size; i++) {\n    m[i] = dist(gen);\n    v[i] = dist(gen);\n    g[i] = dist(gen);\n    r[i] = p[i] = dist(gen);\n  }\n\n  float *d_m, *d_v, *d_g, *d_p;\n\n  d_m = sycl::malloc_device<float>(vector_size, q);\n  q.memcpy(d_m, m, size_bytes);\n\n  d_v = sycl::malloc_device<float>(vector_size, q);\n  q.memcpy(d_v, v, size_bytes);\n\n  d_g = sycl::malloc_device<float>(vector_size, q);\n  q.memcpy(d_g, g, size_bytes);\n\n  d_p = sycl::malloc_device<float>(vector_size, q);\n  q.memcpy(d_p, p, size_bytes);\n\n  \n\n  const float step_size = 1e-3f;\n  const float decay = 0.5f;\n  const float beta1 = 0.9f;\n  const float beta2 = 0.999f;\n  const float eps = 1e-10f;\n  const float grad_scale = 256.f;\n\n  const int threadsPerBlock = 256;\n  sycl::range<1> gws ((vector_size+threadsPerBlock-1) / threadsPerBlock * threadsPerBlock);\n  sycl::range<1> lws (threadsPerBlock);\n\n  adamMode_t mode = ADAM_MODE_0;\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class kernel>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        adam<float, float>(\n          item,\n          d_p, d_m, d_v, d_g,\n          beta1, beta2,\n          eps,\n          grad_scale,\n          step_size,\n          time_step,\n          vector_size,\n          mode,\n          decay);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (ms)\\n\", time * 1e-6f / repeat);\n\n  q.memcpy(p, d_p, size_bytes).wait();\n\n  sycl::free(d_p, q);\n  sycl::free(d_m, q);\n  sycl::free(d_v, q);\n  sycl::free(d_g, q);\n\n  \n\n  reference<float, float>(\n    repeat,\n    r, m, v, g,\n    beta1, beta2,\n    eps,\n    grad_scale,\n    step_size,\n    time_step,\n    vector_size,\n    mode,\n    decay);\n\n  bool ok = true; \n  double cr = 0, cp = 0;\n  for (int i = 0; i < vector_size; i++) {\n    if (fabsf(r[i] - p[i]) > 1e-3f) {\n      ok = false;\n      break;\n    }\n    cr += r[i]; cp += p[i];\n  }\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  printf(\"Checksum: %lf %lf\\n\", cr / vector_size, cp / vector_size);\n\n  free(p);\n  free(m);\n  free(v);\n  free(g);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "aop", "parallel_api": "cuda", "code": {"main.cu": "\n\n \n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <algorithm>\n#include <cuda.h>\n\n#ifdef WITH_FULL_W_MATRIX\n#define R_W_MATRICES_SMEM_SLOTS 15\n#else\n#define R_W_MATRICES_SMEM_SLOTS 12\n#endif\n\n#define CHECK_CUDA(call) do { \\\n  cudaError_t status = call; \\\n  if( status != cudaSuccess ) { \\\n    fprintf(stderr, \"CUDA Error at line %d in %s: %s\\n\", __LINE__, __FILE__, cudaGetErrorString(status)); \\\n    exit((int) status); \\\n  } \\\n} while(0)\n\n#define HOST_DEVICE        __host__ __device__\n#define HOST_DEVICE_INLINE __host__ __device__ __forceinline__\n\nHOST_DEVICE_INLINE double3 operator+(const double3 &u, const double3 &v )\n{\n  return make_double3(u.x+v.x, u.y+v.y, u.z+v.z);\n}\n\nHOST_DEVICE_INLINE double4 operator+(const double4 &u, const double4 &v )\n{\n  return make_double4(u.x+v.x, u.y+v.y, u.z+v.z, u.w+v.w);\n}\n\nstruct PayoffCall\n{\n  double m_K;\n  HOST_DEVICE_INLINE PayoffCall(double K) : m_K(K) {}\n  HOST_DEVICE_INLINE double operator()(double S) const { return fmax(S - m_K, 0.0); }\n  HOST_DEVICE_INLINE int is_in_the_money(double S) const { return S > m_K; }\n};\n\nstruct PayoffPut\n{\n  double m_K;\n  HOST_DEVICE_INLINE PayoffPut(double K) : m_K(K) {}\n  HOST_DEVICE_INLINE double operator()(double S) const { return fmax(m_K - S, 0.0); }\n  HOST_DEVICE_INLINE int is_in_the_money(double S) const { return S < m_K; }\n};\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid generate_paths_kernel(int num_timesteps, \n                           int num_paths, \n                           Payoff payoff,\n                           double dt, \n                           double S0, \n                           double r, \n                           double sigma, \n                           const double *__restrict samples, \n                           double *__restrict paths)\n{\n  \n\n  int path = blockIdx.x*NUM_THREADS_PER_BLOCK + threadIdx.x;\n\n  \n\n  if( path >= num_paths ) return;\n  \n  \n\n  const double r_min_half_sigma_sq_dt = (r - 0.5*sigma*sigma)*dt;\n  \n\n  const double sigma_sqrt_dt = sigma*sqrt(dt);\n\n  \n\n  double S = S0;\n\n  \n\n  int offset = path;\n  \n  \n\n  for( int timestep = 0 ; timestep < num_timesteps-1 ; ++timestep, offset += num_paths )\n  {\n    S = S * exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n    paths[offset] = S;\n  }\n\n  \n\n  S = S * exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n\n  \n\n  paths[offset] = payoff(S);\n}\n\nstatic __device__ __forceinline__ void assemble_R(int m, double4 &sums, double *smem_svds)\n{\n  \n\n\n  double x0 = smem_svds[0];\n  double x1 = smem_svds[1];\n  double x2 = smem_svds[2];\n\n  double x0_sq = x0 * x0;\n\n  double sum1 = sums.x - x0;\n  double sum2 = sums.y - x0_sq;\n  double sum3 = sums.z - x0_sq*x0;\n  double sum4 = sums.w - x0_sq*x0_sq;\n\n  double m_as_dbl = (double) m;\n  double sigma = m_as_dbl - 1.0;\n  double mu = sqrt(m_as_dbl);\n  double v0 = -sigma / (1.0 + mu);\n  double v0_sq = v0*v0;\n  double beta = 2.0 * v0_sq / (sigma + v0_sq);\n  \n  double inv_v0 = 1.0 / v0;\n  double one_min_beta = 1.0 - beta;\n  double beta_div_v0  = beta * inv_v0;\n  \n  smem_svds[0] = mu;\n  smem_svds[1] = one_min_beta*x0 - beta_div_v0*sum1;\n  smem_svds[2] = one_min_beta*x0_sq - beta_div_v0*sum2;\n  \n  \n\n  \n  double beta_div_v0_sq = beta_div_v0 * inv_v0;\n  \n  double c1 = beta_div_v0_sq*sum1 + beta_div_v0*x0;\n  double c2 = beta_div_v0_sq*sum2 + beta_div_v0*x0_sq;\n\n  \n\n  \n  double x1_sq = x1*x1;\n\n  sum1 -= x1;\n  sum2 -= x1_sq;\n  sum3 -= x1_sq*x1;\n  sum4 -= x1_sq*x1_sq;\n  \n  x0 = x1-c1;\n  x0_sq = x0*x0;\n  sigma = sum2 - 2.0*c1*sum1 + (m_as_dbl-2.0)*c1*c1;\n  if( abs(sigma) < 1.0e-16 )\n    beta = 0.0;\n  else\n  {\n    mu = sqrt(x0_sq + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  inv_v0 = 1.0 / v0;\n  beta_div_v0 = beta * inv_v0;\n  \n  \n\n  double c3 = (sum3 - c1*sum2 - c2*sum1 + (m_as_dbl-2.0)*c1*c2)*beta_div_v0;\n  double c4 = (x1_sq-c2)*beta_div_v0 + c3*inv_v0;\n  double c5 = c1*c4 - c2;\n  \n  one_min_beta = 1.0 - beta;\n  \n  \n\n  smem_svds[3] = one_min_beta*x0 - beta_div_v0*sigma;\n  smem_svds[4] = one_min_beta*(x1_sq-c2) - c3;\n  \n  \n\n  \n  double x2_sq = x2*x2;\n\n  sum1 -= x2;\n  sum2 -= x2_sq;\n  sum3 -= x2_sq*x2;\n  sum4 -= x2_sq*x2_sq;\n  \n  x0 = x2_sq-c4*x2+c5;\n  sigma = sum4 - 2.0*c4*sum3 + (c4*c4 + 2.0*c5)*sum2 - 2.0*c4*c5*sum1 + (m_as_dbl-3.0)*c5*c5;\n  if( abs(sigma) < 1.0e-12 )\n    beta = 0.0;\n  else\n  {\n    mu = sqrt(x0*x0 + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  \n\n  smem_svds[5] = (1.0-beta)*x0 - (beta/v0)*sigma;\n}\n\nstatic __device__ double off_diag_norm(double A01, double A02, double A12)\n{\n  return sqrt(2.0 * (A01*A01 + A02*A02 + A12*A12));\n}\n\nstatic __device__ __forceinline__ void swap(double &x, double &y)\n{\n  double t = x; x = y; y = t;\n}\n\nstatic __device__ __forceinline__ void svd_3x3(int m, double4 &sums, double *smem_svds)\n{\n  \n\n  assemble_R(m, sums, smem_svds);\n\n  \n\n  double R00 = smem_svds[0];\n  double R01 = smem_svds[1];\n  double R02 = smem_svds[2];\n  double R11 = smem_svds[3];\n  double R12 = smem_svds[4];\n  double R22 = smem_svds[5];\n\n  \n\n  \n  double A00 = R00*R00;\n  double A01 = R00*R01;\n  double A02 = R00*R02;\n  double A11 = R01*R01 + R11*R11;\n  double A12 = R01*R02 + R11*R12;\n  double A22 = R02*R02 + R12*R12 + R22*R22;\n  \n  \n\n  \n  double V00 = 1.0, V01 = 0.0, V02 = 0.0;\n  double V10 = 0.0, V11 = 1.0, V12 = 0.0;\n  double V20 = 0.0, V21 = 0.0, V22 = 1.0;\n  \n  \n\n  \n  const int max_iters = 16;\n  const double tolerance = 1.0e-12;\n  \n  \n\n \n  for( int iter = 0 ; off_diag_norm(A01, A02, A12) >= tolerance && iter < max_iters ; ++iter )\n  {\n    double c, s, B00, B01, B02, B10, B11, B12, B20, B21, B22;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A01 != 0.0 )\n    {\n      double tau = (A11 - A00) / (2.0 * A01);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A01;\n    B01 = s*A00 + c*A01;\n    B10 = c*A01 - s*A11;\n    B11 = s*A01 + c*A11;\n    B02 = A02;\n    \n    A00 = c*B00 - s*B10;\n    A01 = c*B01 - s*B11;\n    A11 = s*B01 + c*B11;\n    A02 = c*B02 - s*A12;\n    A12 = s*B02 + c*A12;\n    \n    B00 = c*V00 - s*V01;\n    V01 = s*V00 + c*V01;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V11;\n    V11 = s*V10 + c*V11;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V21;\n    V21 = s*V20 + c*V21;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A02 != 0.0 )\n    {\n      double tau = (A22 - A00) / (2.0 * A02);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A02;\n    B01 = c*A01 - s*A12;\n    B02 = s*A00 + c*A02;\n    B20 = c*A02 - s*A22;\n    B22 = s*A02 + c*A22;\n    \n    A00 = c*B00 - s*B20;\n    A12 = s*A01 + c*A12;\n    A02 = c*B02 - s*B22;\n    A22 = s*B02 + c*B22;\n    A01 = B01;\n    \n    B00 = c*V00 - s*V02;\n    V02 = s*V00 + c*V02;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V12;\n    V12 = s*V10 + c*V12;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V22;\n    V22 = s*V20 + c*V22;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A12 != 0.0 )\n    {\n      double tau = (A22 - A11) / (2.0 * A12);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B02 = s*A01 + c*A02;\n    B11 = c*A11 - s*A12;\n    B12 = s*A11 + c*A12;\n    B21 = c*A12 - s*A22;\n    B22 = s*A12 + c*A22;\n    \n    A01 = c*A01 - s*A02;\n    A02 = B02;\n    A11 = c*B11 - s*B21;\n    A12 = c*B12 - s*B22;\n    A22 = s*B12 + c*B22;\n    \n    B01 = c*V01 - s*V02;\n    V02 = s*V01 + c*V02;\n    V01 = B01;\n    \n    B11 = c*V11 - s*V12;\n    V12 = s*V11 + c*V12;\n    V11 = B11;\n    \n    B21 = c*V21 - s*V22;\n    V22 = s*V21 + c*V22;\n    V21 = B21;\n  }\n\n  \n\n  if( A00 < A11 )\n  {\n    swap(A00, A11);\n    swap(V00, V01);\n    swap(V10, V11);\n    swap(V20, V21);\n  }\n  if( A00 < A22 )\n  {\n    swap(A00, A22);\n    swap(V00, V02);\n    swap(V10, V12);\n    swap(V20, V22);\n  }\n  if( A11 < A22 )\n  {\n    swap(A11, A22);\n    swap(V01, V02);\n    swap(V11, V12);\n    swap(V21, V22);\n  }\n\n  \n\n  \n  \n\n  \n  double inv_S0 = abs(A00) < 1.0e-12 ? 0.0 : 1.0 / A00;\n  double inv_S1 = abs(A11) < 1.0e-12 ? 0.0 : 1.0 / A11;\n  double inv_S2 = abs(A22) < 1.0e-12 ? 0.0 : 1.0 / A22;\n\n  \n\n  \n  double U00 = V00 * inv_S0; \n  double U01 = V01 * inv_S1; \n  double U02 = V02 * inv_S2;\n  double U10 = V10 * inv_S0; \n  double U11 = V11 * inv_S1; \n  double U12 = V12 * inv_S2;\n  double U20 = V20 * inv_S0; \n  double U21 = V21 * inv_S1; \n  double U22 = V22 * inv_S2;\n  \n  \n\n  \n#ifdef WITH_FULL_W_MATRIX\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B10 = U10*V00 + U11*V01 + U12*V02;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B20 = U20*V00 + U21*V01 + U22*V02;\n  double B21 = U20*V10 + U21*V11 + U22*V12;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] = B10*R00 + B11*R01 + B12*R02;\n  smem_svds[10] =           B11*R11 + B12*R12;\n  smem_svds[11] =                     B12*R22;\n  smem_svds[12] = B20*R00 + B21*R01 + B22*R02;\n  smem_svds[13] =           B21*R11 + B22*R12;\n  smem_svds[14] =                     B22*R22;\n#else\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] =           B11*R11 + B12*R12;\n  smem_svds[10] =                     B12*R22;\n  smem_svds[11] =                     B22*R22;\n#endif\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK, 4)\nvoid prepare_svd_kernel(int num_paths, \n                        int min_in_the_money, \n                        Payoff payoff, \n                        const double *__restrict paths, \n                                 int *__restrict all_out_of_the_money, \n                              double *__restrict svds)\n{\n  \n\n  __shared__ int scan_input[NUM_THREADS_PER_BLOCK];\n  __shared__ int scan_output[1+NUM_THREADS_PER_BLOCK];\n\n  \n\n  __shared__ double4 lsums;\n  __shared__ int lsum;\n\n  \n\n  __shared__ double smem_svds[R_W_MATRICES_SMEM_SLOTS];\n\n  \n\n  const int timestep = blockIdx.x;\n  \n\n  const int offset = timestep * num_paths;\n\n  \n\n  int m = 0;\n  double4 sums = make_double4(0,0,0,0);\n\n  \n\n  if( threadIdx.x < R_W_MATRICES_SMEM_SLOTS )\n    smem_svds[threadIdx.x] = 0.0;\n  __syncthreads();\n\n  \n\n  int found_paths = 0;\n\n  \n\n  for( int path = threadIdx.x ; path < num_paths ; path += NUM_THREADS_PER_BLOCK )\n  {\n    \n\n    double S = paths[offset + path];\n\n    \n\n    const int in_the_money = payoff.is_in_the_money(S);\n\n    \n\n    scan_input[threadIdx.x] = in_the_money;\n    __syncthreads();\n    if (threadIdx.x == 0) {\n      scan_output[0] = 0;\n      for (int i = 1; i <= NUM_THREADS_PER_BLOCK; i++) \n        scan_output[i] = scan_output[i-1]+scan_input[i-1];\n    }\n    __syncthreads();\n    const int partial_sum = scan_output[threadIdx.x];\n    const int total_sum = scan_output[NUM_THREADS_PER_BLOCK];\n\n    if( found_paths < 3 )\n    {\n      if( in_the_money && found_paths + partial_sum < 3 )\n        smem_svds[found_paths + partial_sum] = S;\n      __syncthreads();\n      found_paths += total_sum;\n    }\n\n    \n\n    if (threadIdx.x == 0) lsum = 0;\n    __syncthreads();\n    atomicOr(&lsum, in_the_money);\n    __syncthreads();\n    if (lsum == 0) continue;\n    \n    \n\n    m += in_the_money;\n\n    \n\n    double x = 0.0, x_sq = 0.0;\n    if( in_the_money )\n    {\n      x = S;\n      x_sq = S*S;\n    }\n\n    \n\n    sums.x += x;\n    sums.y += x_sq;\n    sums.z += x_sq*x;\n    sums.w += x_sq*x_sq;\n  }\n\n  \n\n  if (threadIdx.x == 0) lsum = 0;\n  __syncthreads();\n\n  atomicAdd(&lsum, m);\n\n  __syncthreads();\n\n  int not_enough_paths = 0;\n  \n\n  if (threadIdx.x == 0 && lsum < min_in_the_money)\n    not_enough_paths = 1;\n  \n  \n\n  if( not_enough_paths )\n  {\n    if( threadIdx.x == 0 )\n      all_out_of_the_money[blockIdx.x] = 1;\n  } \n  else\n  {\n    \n\n    if (threadIdx.x == 0)\n      lsums = make_double4(0,0,0,0);\n    __syncthreads();\n\n    atomicAdd(&lsums.x, sums.x);\n    atomicAdd(&lsums.y, sums.y);\n    atomicAdd(&lsums.z, sums.z);\n    atomicAdd(&lsums.w, sums.w);\n    \n    __syncthreads();\n    \n    \n\n    if( threadIdx.x == 0 )\n      svd_3x3(lsum, lsums, smem_svds);\n\n    __syncthreads();\n\n    \n\n    if( threadIdx.x < R_W_MATRICES_SMEM_SLOTS )\n      svds[16*blockIdx.x + threadIdx.x] = smem_svds[threadIdx.x];\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK, 8)\nvoid compute_partial_beta_kernel(int num_paths,\n                                 Payoff payoff,\n                                 const double *__restrict svd,\n                                 const double *__restrict paths,\n                                 const double *__restrict cashflows,\n                                 const int *__restrict all_out_of_the_money,\n                                 double *__restrict partial_sums)\n{\n  \n\n  __shared__ double3 lsums;\n  \n  \n\n  __shared__ double shared_svd[R_W_MATRICES_SMEM_SLOTS];\n    \n  \n\n  if( *all_out_of_the_money ) return;\n\n  \n\n  const int NUM_THREADS_PER_GRID = NUM_THREADS_PER_BLOCK * gridDim.x;\n\n  \n\n  if( threadIdx.x < R_W_MATRICES_SMEM_SLOTS )\n    shared_svd[threadIdx.x] = svd[threadIdx.x];\n  __syncthreads();\n\n  \n\n  const double R00 = shared_svd[ 0];\n  const double R01 = shared_svd[ 1];\n  const double R02 = shared_svd[ 2];\n  const double R11 = shared_svd[ 3];\n  const double R12 = shared_svd[ 4];\n  const double R22 = shared_svd[ 5];\n\n  \n\n#ifdef WITH_FULL_W_MATRIX\n  const double W00 = shared_svd[ 6];\n  const double W01 = shared_svd[ 7];\n  const double W02 = shared_svd[ 8];\n  const double W10 = shared_svd[ 9];\n  const double W11 = shared_svd[10];\n  const double W12 = shared_svd[11];\n  const double W20 = shared_svd[12];\n  const double W21 = shared_svd[13];\n  const double W22 = shared_svd[14];\n#else\n  const double W00 = shared_svd[ 6];\n  const double W01 = shared_svd[ 7];\n  const double W02 = shared_svd[ 8];\n  const double W11 = shared_svd[ 9];\n  const double W12 = shared_svd[10];\n  const double W22 = shared_svd[11];\n#endif\n\n  \n\n  const double inv_R00 = R00 != 0.0 ? __drcp_rn(R00) : 0.0;\n  const double inv_R11 = R11 != 0.0 ? __drcp_rn(R11) : 0.0;\n  const double inv_R22 = R22 != 0.0 ? __drcp_rn(R22) : 0.0;\n\n  \n\n  const double inv_R01 = inv_R00*inv_R11*R01;\n  const double inv_R02 = inv_R00*inv_R22*R02;\n  const double inv_R12 =         inv_R22*R12;\n  \n  \n\n#ifdef WITH_FULL_W_MATRIX\n  const double inv_W00 = W00*inv_R00;\n  const double inv_W10 = W10*inv_R00;\n  const double inv_W20 = W20*inv_R00;\n#else\n  const double inv_W00 = W00*inv_R00;\n#endif\n\n  \n\n  double beta0 = 0.0, beta1 = 0.0, beta2 = 0.0;\n\n  \n\n  for( int path = blockIdx.x*NUM_THREADS_PER_BLOCK + threadIdx.x ; path < num_paths ; path += NUM_THREADS_PER_GRID )\n  {\n    \n\n    double S = paths[path];\n\n    \n\n    const int in_the_money = payoff.is_in_the_money(S);\n\n    \n\n    double Q1i = inv_R11*S - inv_R01;\n    double Q2i = inv_R22*S*S - inv_R02 - Q1i*inv_R12;\n\n    \n\n#ifdef WITH_FULL_W_MATRIX\n    const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n    const double WI1 = inv_W10 + W11 * Q1i + W12 * Q2i;\n    const double WI2 = inv_W20 + W21 * Q1i + W22 * Q2i;\n#else\n    const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n    const double WI1 =           W11 * Q1i + W12 * Q2i;\n    const double WI2 =                       W22 * Q2i;\n#endif\n\n    \n\n    double cashflow = in_the_money ? cashflows[path] : 0.0;\n  \n    \n\n    beta0 += WI0*cashflow;\n    beta1 += WI1*cashflow;\n    beta2 += WI2*cashflow;\n  }\n\n  \n\n  if( threadIdx.x == 0 )\n    lsums = make_double3(0,0,0);\n  __syncthreads();\n\n  atomicAdd(&lsums.x, beta0);\n  atomicAdd(&lsums.y, beta1);\n  atomicAdd(&lsums.z, beta2);\n \n  __syncthreads();\n  \n  \n\n  if( threadIdx.x == 0 )\n  {\n    partial_sums[0*NUM_THREADS_PER_BLOCK + blockIdx.x] = lsums.x;\n    partial_sums[1*NUM_THREADS_PER_BLOCK + blockIdx.x] = lsums.y;\n    partial_sums[2*NUM_THREADS_PER_BLOCK + blockIdx.x] = lsums.z;\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid compute_final_beta_kernel(const int *__restrict all_out_of_the_money, double *__restrict beta)\n{\n  \n\n  __shared__ double3 lsums;\n\n  \n\n  if( *all_out_of_the_money )\n  {\n    if( threadIdx.x < 3 )\n      beta[threadIdx.x] = 0.0;\n    return;\n  }\n\n  \n\n  double3 sums;\n  \n  \n\n  sums.x = beta[0*NUM_THREADS_PER_BLOCK + threadIdx.x];\n  sums.y = beta[1*NUM_THREADS_PER_BLOCK + threadIdx.x];\n  sums.z = beta[2*NUM_THREADS_PER_BLOCK + threadIdx.x];\n  \n  \n\n  if( threadIdx.x == 0 )\n    lsums = make_double3(0,0,0);\n  __syncthreads();\n\n  atomicAdd(&lsums.x, sums.x);\n  atomicAdd(&lsums.y, sums.y);\n  atomicAdd(&lsums.z, sums.z);\n \n  __syncthreads();\n  \n  \n\n  if( threadIdx.x == 0 )\n  {\n    \n\n    beta[0] = lsums.x; \n    beta[1] = lsums.y;\n    beta[2] = lsums.z;\n  }\n}\n\n\n\n\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid update_cashflow_kernel(int num_paths,\n                            Payoff payoff_object,\n                            double exp_min_r_dt,\n                            const double *__restrict beta,\n                            const double *__restrict paths,\n                            const int *__restrict all_out_of_the_money,\n                            double *__restrict cashflows)\n{\n  const int NUM_THREADS_PER_GRID = gridDim.x * NUM_THREADS_PER_BLOCK;\n\n  \n\n  const int skip_computations = *all_out_of_the_money;\n\n  \n\n  const double beta0 = beta[0];\n  const double beta1 = beta[1];\n  const double beta2 = beta[2];\n\n  \n\n  int path = blockIdx.x*NUM_THREADS_PER_BLOCK + threadIdx.x;\n  for( ; path < num_paths ; path += NUM_THREADS_PER_GRID )\n  {\n    \n\n    const double old_cashflow = exp_min_r_dt*cashflows[path];\n    if( skip_computations )\n    {\n      cashflows[path] = old_cashflow;\n      continue;\n    }\n  \n    \n\n    double S  = paths[path];\n    double S2 = S*S;\n\n    \n\n    double payoff = payoff_object(S);\n\n    \n\n    double estimated_payoff = beta0 + beta1*S + beta2*S2;\n\n    \n\n    estimated_payoff *= exp_min_r_dt;\n\n    \n\n    if( payoff <= 1.0e-8 || payoff <= estimated_payoff )\n      payoff = old_cashflow;\n    \n    \n\n    cashflows[path] = payoff;\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid compute_partial_sums_kernel(int num_paths, const double *__restrict cashflows, double *__restrict sums)\n{\n  \n\n  __shared__ double lsum;\n\n  \n\n  const int path = blockIdx.x * NUM_THREADS_PER_BLOCK + threadIdx.x;\n\n  \n\n  double sum = 0.0;\n  if( path < num_paths )\n    sum = cashflows[path];\n\n  \n\n  if (threadIdx.x == 0)\n    lsum = 0;\n  __syncthreads();\n  \n  atomicAdd(&lsum, sum);\n  __syncthreads();\n\n  \n\n  if( threadIdx.x == 0 )\n    sums[blockIdx.x] = lsum;\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid compute_final_sum_kernel(int num_paths, int num_blocks, double exp_min_r_dt, double *__restrict sums)\n{\n  \n\n  __shared__ double lsum;\n\n  \n\n  double sum = 0.0;\n  for( int item = threadIdx.x ; item < num_blocks ; item += NUM_THREADS_PER_BLOCK )\n    sum += sums[item];\n\n  \n\n  if (threadIdx.x == 0) lsum = 0;\n  __syncthreads();\n  \n  atomicAdd(&lsum, sum);\n  __syncthreads();\n\n  \n\n  if( threadIdx.x == 0 )\n  {\n    sums[0] = exp_min_r_dt * lsum / (double) num_paths;\n  }\n}\n\ntemplate< typename Payoff >\nstatic inline \nvoid do_run(double *h_samples,\n            int num_timesteps, \n            int num_paths, \n            const Payoff &payoff, \n            double dt,\n            double S0,\n            double r,\n            double sigma,\n            double *d_samples,\n            double *d_paths,\n            double *d_cashflows,\n            double *d_svds,\n            int    *d_all_out_of_the_money,\n            double *d_temp_storage,\n            double *h_price)\n{\n  CHECK_CUDA(cudaMemcpy(d_samples, h_samples, sizeof(double) * num_timesteps*num_paths, cudaMemcpyHostToDevice));\n\n  \n\n  const int NUM_THREADS_PER_BLOCK0 = 256;\n  int grid_dim = (num_paths + NUM_THREADS_PER_BLOCK0-1) / NUM_THREADS_PER_BLOCK0;\n  generate_paths_kernel<NUM_THREADS_PER_BLOCK0><<<grid_dim, NUM_THREADS_PER_BLOCK0>>>(\n    num_timesteps,\n    num_paths,\n    payoff, \n    dt, \n    S0, \n    r, \n    sigma, \n    d_samples,\n    d_paths);\n  CHECK_CUDA(cudaGetLastError());\n\n  \n\n  CHECK_CUDA(cudaMemsetAsync(d_all_out_of_the_money, 0, num_timesteps*sizeof(int)));\n\n  \n\n  const int NUM_THREADS_PER_BLOCK1 = 256;\n  prepare_svd_kernel<NUM_THREADS_PER_BLOCK1><<<num_timesteps-1, NUM_THREADS_PER_BLOCK1>>>(\n    num_paths,\n    4, \n\n    payoff, \n    d_paths, \n    d_all_out_of_the_money,\n    d_svds);\n  CHECK_CUDA(cudaGetLastError());\n\n  \n\n  const double exp_min_r_dt = std::exp(-r*dt);\n\n  \n\n  const int num_threads_per_wave_full_occupancy = 256 * 112;\n\n  \n\n  const int NUM_THREADS_PER_BLOCK2 = 128;\n\n  \n\n  grid_dim = (num_paths + NUM_THREADS_PER_BLOCK2-1) / NUM_THREADS_PER_BLOCK2;\n  double num_waves = grid_dim*NUM_THREADS_PER_BLOCK2 / (double) num_threads_per_wave_full_occupancy;\n\n  int update_cashflow_grid = grid_dim;\n  if( num_waves < 10 && num_waves - (int) num_waves < 0.6 )\n    update_cashflow_grid = std::max(1, (int) num_waves) * num_threads_per_wave_full_occupancy / NUM_THREADS_PER_BLOCK2;\n\n  \n\n  for( int timestep = num_timesteps-2 ; timestep >= 0 ; --timestep )\n  {\n    \n\n    compute_partial_beta_kernel<NUM_THREADS_PER_BLOCK2><<<NUM_THREADS_PER_BLOCK2, NUM_THREADS_PER_BLOCK2>>>(\n      num_paths,\n      payoff,\n      d_svds + 16*timestep,\n      d_paths + timestep*num_paths,\n      d_cashflows,\n      d_all_out_of_the_money + timestep,\n      d_temp_storage);\n    CHECK_CUDA(cudaGetLastError());\n\n    compute_final_beta_kernel<NUM_THREADS_PER_BLOCK2><<<1, NUM_THREADS_PER_BLOCK2>>>(\n      d_all_out_of_the_money + timestep,\n      d_temp_storage);\n    CHECK_CUDA(cudaGetLastError());\n\n    update_cashflow_kernel<NUM_THREADS_PER_BLOCK2><<<update_cashflow_grid, NUM_THREADS_PER_BLOCK2>>>(\n      num_paths,\n      payoff,\n      exp_min_r_dt,\n      d_temp_storage,\n      d_paths + timestep*num_paths,\n      d_all_out_of_the_money + timestep,\n      d_cashflows);\n    CHECK_CUDA(cudaGetLastError());\n  }\n\n  \n\n  const int NUM_THREADS_PER_BLOCK4 = 128;\n  grid_dim = (num_paths + NUM_THREADS_PER_BLOCK4-1) / NUM_THREADS_PER_BLOCK4;\n  \n  compute_partial_sums_kernel<NUM_THREADS_PER_BLOCK4><<<grid_dim, NUM_THREADS_PER_BLOCK4>>>(\n    num_paths,\n    d_cashflows,\n    d_temp_storage);\n  CHECK_CUDA(cudaGetLastError());\n\n  compute_final_sum_kernel<NUM_THREADS_PER_BLOCK4><<<1, NUM_THREADS_PER_BLOCK4>>>(\n    num_paths,\n    grid_dim,\n    exp_min_r_dt,\n    d_temp_storage);\n  CHECK_CUDA(cudaGetLastError());\n\n  \n\n  CHECK_CUDA(cudaMemcpy(h_price, d_temp_storage, sizeof(double), cudaMemcpyDeviceToHost));\n}\n\ntemplate< typename Payoff >\nstatic double binomial_tree(int num_timesteps, const Payoff &payoff, double dt, double S0, double r, double sigma)\n{\n  double *tree = new double[num_timesteps+1];\n\n  double u = std::exp( sigma * std::sqrt(dt));\n  double d = std::exp(-sigma * std::sqrt(dt));\n  double a = std::exp( r     * dt);\n  \n  double p = (a - d) / (u - d);\n  \n  double k = std::pow(d, num_timesteps);\n  for( int t = 0 ; t <= num_timesteps ; ++t )\n  {\n    tree[t] = payoff(S0*k);\n    k *= u*u;\n  }\n\n  for( int t = num_timesteps-1 ; t >= 0 ; --t )\n  {\n    k = std::pow(d, t);\n    for( int i = 0 ; i <= t ; ++i )\n    {\n      double expected = std::exp(-r*dt) * (p*tree[i+1] + (1.0 - p)*tree[i]);\n      double earlyex = payoff(S0*k);\n      tree[i] = std::max(earlyex, expected);\n      k *= u*u;\n    }\n  }\n\n  double f = tree[0];\n  delete[] tree;\n  return f;\n}\n\nstatic double black_scholes_merton_put(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return K*std::exp(-r*T)*normcdf(-d2) - S0*normcdf(-d1);\n}\n\nstatic double black_scholes_merton_call(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return S0*normcdf(d1) - K*std::exp(-r*T)*normcdf(d2);\n}\n\nint main(int argc, char **argv)\n{\n  const int MAX_GRID_SIZE = 2048;\n  \n  \n\n  int num_timesteps = 100;\n  int num_paths     = 32;\n  int num_runs      = 1;\n\n  \n\n  double T     = 1.00;\n  double K     = 4.00;\n  double S0    = 3.60;\n  double r     = 0.06;\n  double sigma = 0.20;\n\n  \n\n  bool price_put = true;\n  \n  \n\n  for( int i = 1 ; i < argc ; ++i )\n  {\n    if( !strcmp(argv[i], \"-timesteps\") )\n      num_timesteps = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-paths\") )\n      num_paths = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-runs\") )\n      num_runs = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-T\") )\n      T = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-S0\") )\n      S0 = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-K\") )\n      K = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-r\") )\n      r = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-sigma\") )\n      sigma = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-call\") )\n      price_put = false;\n    else\n    {\n      fprintf(stderr, \"Unknown option %s. Aborting!!!\\n\", argv[i]);\n      exit(1);\n    }\n  }\n\n  \n\n  printf(\"==============\\n\");\n  printf(\"Num Timesteps         : %d\\n\",  num_timesteps);\n  printf(\"Num Paths             : %dK\\n\", num_paths);\n  printf(\"Num Runs              : %d\\n\",  num_runs);\n  printf(\"T                     : %lf\\n\", T);\n  printf(\"S0                    : %lf\\n\", S0);\n  printf(\"K                     : %lf\\n\", K);\n  printf(\"r                     : %lf\\n\", r);\n  printf(\"sigma                 : %lf\\n\", sigma);\n  printf(\"Option Type           : American %s\\n\",  price_put ? \"Put\" : \"Call\");\n\n  \n\n  num_paths *= 1024;\n\n  \n\n  double dt = T / num_timesteps;\n\n  \n\n  std::default_random_engine rng;\n  std::normal_distribution<double> norm_dist(0.0, 1.0);\n\n  double *h_samples = (double*) malloc (num_timesteps*num_paths*sizeof(double));\n\n  \n\n  double *d_samples = NULL;\n  CHECK_CUDA(cudaMalloc((void**) &d_samples, num_timesteps*num_paths*sizeof(double)));\n\n  \n\n  double *d_paths = NULL;\n  CHECK_CUDA(cudaMalloc((void**) &d_paths, num_timesteps*num_paths*sizeof(double)));\n\n  \n\n  double *d_cashflows = d_paths + (num_timesteps-1)*num_paths;\n\n  \n\n  double *d_svds = NULL;\n  CHECK_CUDA(cudaMalloc((void**) &d_svds, 16*num_timesteps*sizeof(double)));\n\n  \n\n  int *d_all_out_of_the_money = NULL;\n  CHECK_CUDA(cudaMalloc((void**) &d_all_out_of_the_money, num_timesteps*sizeof(int)));\n\n  \n\n  int max_temp_storage = 4*MAX_GRID_SIZE;\n  double *d_temp_storage = NULL;\n  CHECK_CUDA(cudaMalloc((void**) &d_temp_storage, max_temp_storage*sizeof(double)));\n\n  \n\n  double h_price;\n\n  \n\n  float total_elapsed_time = 0;\n\n  for( int run = 0; run < num_runs; ++run )\n  {\n    for (int i = 0; i < num_timesteps*num_paths; ++i)\n      h_samples[i] = norm_dist(rng);\n      \n    auto start = std::chrono::high_resolution_clock::now();\n    if( price_put )\n      do_run(h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffPut(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             d_samples,\n             d_paths,\n             d_cashflows,\n             d_svds,\n             d_all_out_of_the_money,\n             d_temp_storage,\n             &h_price);\n    else\n      do_run(h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffCall(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             d_samples,\n             d_paths,\n             d_cashflows,\n             d_svds,\n             d_all_out_of_the_money,\n             d_temp_storage,\n             &h_price);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    const float elapsed_time =\n       std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n    total_elapsed_time += elapsed_time;\n  }\n\n  printf(\"==============\\n\");\n  printf(\"GPU Longstaff-Schwartz: %.8lf\\n\", h_price);\n  \n  double price = 0.0;\n\n  if( price_put )\n    price = binomial_tree(num_timesteps, PayoffPut(K), dt, S0, r, sigma);\n  else\n    price = binomial_tree(num_timesteps, PayoffCall(K), dt, S0, r, sigma);\n\n  printf(\"Binonmial             : %.8lf\\n\", price);\n  \n  if( price_put )\n    price = black_scholes_merton_put(T, K, S0, r, sigma);\n  else\n    price = black_scholes_merton_call(T, K, S0, r, sigma);\n\n  printf(\"European Price        : %.8lf\\n\", price);\n\n  printf(\"==============\\n\");\n\n  printf(\"elapsed time for each run         : %.3fms\\n\", total_elapsed_time / num_runs);\n  printf(\"==============\\n\");\n\n  \n\n  free(h_samples);\n  CHECK_CUDA(cudaFree(d_temp_storage));\n  CHECK_CUDA(cudaFree(d_all_out_of_the_money));\n  CHECK_CUDA(cudaFree(d_svds));\n  CHECK_CUDA(cudaFree(d_paths));\n  CHECK_CUDA(cudaFree(d_samples));\n\n  return 0;\n}\n"}}
{"kernel_name": "aop", "parallel_api": "hip", "code": {"main.cu": "\n\n \n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <algorithm>\n#include <hip/hip_runtime.h>\n\n#ifdef WITH_FULL_W_MATRIX\n#define R_W_MATRICES_SMEM_SLOTS 15\n#else\n#define R_W_MATRICES_SMEM_SLOTS 12\n#endif\n\n#define CHECK_HIP(call) do { \\\n  hipError_t status = call; \\\n  if( status != hipSuccess ) { \\\n    fprintf(stderr, \"HIP Error at line %d in %s: %s\\n\", __LINE__, __FILE__, hipGetErrorString(status)); \\\n    exit((int) status); \\\n  } \\\n} while(0)\n\n#define HOST_DEVICE        __host__ __device__\n#define HOST_DEVICE_INLINE __host__ __device__ __forceinline__\n\n\nstruct PayoffCall\n{\n  double m_K;\n  HOST_DEVICE_INLINE PayoffCall(double K) : m_K(K) {}\n  HOST_DEVICE_INLINE double operator()(double S) const { return fmax(S - m_K, 0.0); }\n  HOST_DEVICE_INLINE int is_in_the_money(double S) const { return S > m_K; }\n};\n\nstruct PayoffPut\n{\n  double m_K;\n  HOST_DEVICE_INLINE PayoffPut(double K) : m_K(K) {}\n  HOST_DEVICE_INLINE double operator()(double S) const { return fmax(m_K - S, 0.0); }\n  HOST_DEVICE_INLINE int is_in_the_money(double S) const { return S < m_K; }\n};\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid generate_paths_kernel(int num_timesteps, \n                           int num_paths, \n                           Payoff payoff,\n                           double dt, \n                           double S0, \n                           double r, \n                           double sigma, \n                           const double *__restrict samples, \n                           double *__restrict paths)\n{\n  \n\n  int path = blockIdx.x*NUM_THREADS_PER_BLOCK + threadIdx.x;\n\n  \n\n  if( path >= num_paths ) return;\n  \n  \n\n  const double r_min_half_sigma_sq_dt = (r - 0.5*sigma*sigma)*dt;\n  \n\n  const double sigma_sqrt_dt = sigma*sqrt(dt);\n\n  \n\n  double S = S0;\n\n  \n\n  int offset = path;\n  \n  \n\n  for( int timestep = 0 ; timestep < num_timesteps-1 ; ++timestep, offset += num_paths )\n  {\n    S = S * exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n    paths[offset] = S;\n  }\n\n  \n\n  S = S * exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n\n  \n\n  paths[offset] = payoff(S);\n}\n\nstatic __device__ __forceinline__ void assemble_R(int m, double4 &sums, double *smem_svds)\n{\n  \n\n\n  double x0 = smem_svds[0];\n  double x1 = smem_svds[1];\n  double x2 = smem_svds[2];\n\n  double x0_sq = x0 * x0;\n\n  double sum1 = sums.x - x0;\n  double sum2 = sums.y - x0_sq;\n  double sum3 = sums.z - x0_sq*x0;\n  double sum4 = sums.w - x0_sq*x0_sq;\n\n  double m_as_dbl = (double) m;\n  double sigma = m_as_dbl - 1.0;\n  double mu = sqrt(m_as_dbl);\n  double v0 = -sigma / (1.0 + mu);\n  double v0_sq = v0*v0;\n  double beta = 2.0 * v0_sq / (sigma + v0_sq);\n  \n  double inv_v0 = 1.0 / v0;\n  double one_min_beta = 1.0 - beta;\n  double beta_div_v0  = beta * inv_v0;\n  \n  smem_svds[0] = mu;\n  smem_svds[1] = one_min_beta*x0 - beta_div_v0*sum1;\n  smem_svds[2] = one_min_beta*x0_sq - beta_div_v0*sum2;\n  \n  \n\n  \n  double beta_div_v0_sq = beta_div_v0 * inv_v0;\n  \n  double c1 = beta_div_v0_sq*sum1 + beta_div_v0*x0;\n  double c2 = beta_div_v0_sq*sum2 + beta_div_v0*x0_sq;\n\n  \n\n  \n  double x1_sq = x1*x1;\n\n  sum1 -= x1;\n  sum2 -= x1_sq;\n  sum3 -= x1_sq*x1;\n  sum4 -= x1_sq*x1_sq;\n  \n  x0 = x1-c1;\n  x0_sq = x0*x0;\n  sigma = sum2 - 2.0*c1*sum1 + (m_as_dbl-2.0)*c1*c1;\n  if( abs(sigma) < 1.0e-16 )\n    beta = 0.0;\n  else\n  {\n    mu = sqrt(x0_sq + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  inv_v0 = 1.0 / v0;\n  beta_div_v0 = beta * inv_v0;\n  \n  \n\n  double c3 = (sum3 - c1*sum2 - c2*sum1 + (m_as_dbl-2.0)*c1*c2)*beta_div_v0;\n  double c4 = (x1_sq-c2)*beta_div_v0 + c3*inv_v0;\n  double c5 = c1*c4 - c2;\n  \n  one_min_beta = 1.0 - beta;\n  \n  \n\n  smem_svds[3] = one_min_beta*x0 - beta_div_v0*sigma;\n  smem_svds[4] = one_min_beta*(x1_sq-c2) - c3;\n  \n  \n\n  \n  double x2_sq = x2*x2;\n\n  sum1 -= x2;\n  sum2 -= x2_sq;\n  sum3 -= x2_sq*x2;\n  sum4 -= x2_sq*x2_sq;\n  \n  x0 = x2_sq-c4*x2+c5;\n  sigma = sum4 - 2.0*c4*sum3 + (c4*c4 + 2.0*c5)*sum2 - 2.0*c4*c5*sum1 + (m_as_dbl-3.0)*c5*c5;\n  if( abs(sigma) < 1.0e-12 )\n    beta = 0.0;\n  else\n  {\n    mu = sqrt(x0*x0 + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  \n\n  smem_svds[5] = (1.0-beta)*x0 - (beta/v0)*sigma;\n}\n\nstatic __device__ double off_diag_norm(double A01, double A02, double A12)\n{\n  return sqrt(2.0 * (A01*A01 + A02*A02 + A12*A12));\n}\n\nstatic __device__ __forceinline__ void swap(double &x, double &y)\n{\n  double t = x; x = y; y = t;\n}\n\nstatic __device__ __forceinline__ void svd_3x3(int m, double4 &sums, double *smem_svds)\n{\n  \n\n  assemble_R(m, sums, smem_svds);\n\n  \n\n  double R00 = smem_svds[0];\n  double R01 = smem_svds[1];\n  double R02 = smem_svds[2];\n  double R11 = smem_svds[3];\n  double R12 = smem_svds[4];\n  double R22 = smem_svds[5];\n\n  \n\n  \n  double A00 = R00*R00;\n  double A01 = R00*R01;\n  double A02 = R00*R02;\n  double A11 = R01*R01 + R11*R11;\n  double A12 = R01*R02 + R11*R12;\n  double A22 = R02*R02 + R12*R12 + R22*R22;\n  \n  \n\n  \n  double V00 = 1.0, V01 = 0.0, V02 = 0.0;\n  double V10 = 0.0, V11 = 1.0, V12 = 0.0;\n  double V20 = 0.0, V21 = 0.0, V22 = 1.0;\n  \n  \n\n  \n  const int max_iters = 16;\n  const double tolerance = 1.0e-12;\n  \n  \n\n \n  for( int iter = 0 ; off_diag_norm(A01, A02, A12) >= tolerance && iter < max_iters ; ++iter )\n  {\n    double c, s, B00, B01, B02, B10, B11, B12, B20, B21, B22;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A01 != 0.0 )\n    {\n      double tau = (A11 - A00) / (2.0 * A01);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A01;\n    B01 = s*A00 + c*A01;\n    B10 = c*A01 - s*A11;\n    B11 = s*A01 + c*A11;\n    B02 = A02;\n    \n    A00 = c*B00 - s*B10;\n    A01 = c*B01 - s*B11;\n    A11 = s*B01 + c*B11;\n    A02 = c*B02 - s*A12;\n    A12 = s*B02 + c*A12;\n    \n    B00 = c*V00 - s*V01;\n    V01 = s*V00 + c*V01;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V11;\n    V11 = s*V10 + c*V11;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V21;\n    V21 = s*V20 + c*V21;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A02 != 0.0 )\n    {\n      double tau = (A22 - A00) / (2.0 * A02);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A02;\n    B01 = c*A01 - s*A12;\n    B02 = s*A00 + c*A02;\n    B20 = c*A02 - s*A22;\n    B22 = s*A02 + c*A22;\n    \n    A00 = c*B00 - s*B20;\n    A12 = s*A01 + c*A12;\n    A02 = c*B02 - s*B22;\n    A22 = s*B02 + c*B22;\n    A01 = B01;\n    \n    B00 = c*V00 - s*V02;\n    V02 = s*V00 + c*V02;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V12;\n    V12 = s*V10 + c*V12;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V22;\n    V22 = s*V20 + c*V22;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A12 != 0.0 )\n    {\n      double tau = (A22 - A11) / (2.0 * A12);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B02 = s*A01 + c*A02;\n    B11 = c*A11 - s*A12;\n    B12 = s*A11 + c*A12;\n    B21 = c*A12 - s*A22;\n    B22 = s*A12 + c*A22;\n    \n    A01 = c*A01 - s*A02;\n    A02 = B02;\n    A11 = c*B11 - s*B21;\n    A12 = c*B12 - s*B22;\n    A22 = s*B12 + c*B22;\n    \n    B01 = c*V01 - s*V02;\n    V02 = s*V01 + c*V02;\n    V01 = B01;\n    \n    B11 = c*V11 - s*V12;\n    V12 = s*V11 + c*V12;\n    V11 = B11;\n    \n    B21 = c*V21 - s*V22;\n    V22 = s*V21 + c*V22;\n    V21 = B21;\n  }\n\n  \n\n  if( A00 < A11 )\n  {\n    swap(A00, A11);\n    swap(V00, V01);\n    swap(V10, V11);\n    swap(V20, V21);\n  }\n  if( A00 < A22 )\n  {\n    swap(A00, A22);\n    swap(V00, V02);\n    swap(V10, V12);\n    swap(V20, V22);\n  }\n  if( A11 < A22 )\n  {\n    swap(A11, A22);\n    swap(V01, V02);\n    swap(V11, V12);\n    swap(V21, V22);\n  }\n\n  \n\n  \n  \n\n  \n  double inv_S0 = abs(A00) < 1.0e-12 ? 0.0 : 1.0 / A00;\n  double inv_S1 = abs(A11) < 1.0e-12 ? 0.0 : 1.0 / A11;\n  double inv_S2 = abs(A22) < 1.0e-12 ? 0.0 : 1.0 / A22;\n\n  \n\n  \n  double U00 = V00 * inv_S0; \n  double U01 = V01 * inv_S1; \n  double U02 = V02 * inv_S2;\n  double U10 = V10 * inv_S0; \n  double U11 = V11 * inv_S1; \n  double U12 = V12 * inv_S2;\n  double U20 = V20 * inv_S0; \n  double U21 = V21 * inv_S1; \n  double U22 = V22 * inv_S2;\n  \n  \n\n  \n#ifdef WITH_FULL_W_MATRIX\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B10 = U10*V00 + U11*V01 + U12*V02;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B20 = U20*V00 + U21*V01 + U22*V02;\n  double B21 = U20*V10 + U21*V11 + U22*V12;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] = B10*R00 + B11*R01 + B12*R02;\n  smem_svds[10] =           B11*R11 + B12*R12;\n  smem_svds[11] =                     B12*R22;\n  smem_svds[12] = B20*R00 + B21*R01 + B22*R02;\n  smem_svds[13] =           B21*R11 + B22*R12;\n  smem_svds[14] =                     B22*R22;\n#else\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] =           B11*R11 + B12*R12;\n  smem_svds[10] =                     B12*R22;\n  smem_svds[11] =                     B22*R22;\n#endif\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK, 4)\nvoid prepare_svd_kernel(int num_paths, \n                        int min_in_the_money, \n                        Payoff payoff, \n                        const double *__restrict paths, \n                                 int *__restrict all_out_of_the_money, \n                              double *__restrict svds)\n{\n  \n\n  __shared__ int scan_input[NUM_THREADS_PER_BLOCK];\n  __shared__ int scan_output[1+NUM_THREADS_PER_BLOCK];\n\n  \n\n  __shared__ double4 lsums;\n  __shared__ int lsum;\n\n  \n\n  __shared__ double smem_svds[R_W_MATRICES_SMEM_SLOTS];\n\n  \n\n  const int timestep = blockIdx.x;\n  \n\n  const int offset = timestep * num_paths;\n\n  \n\n  int m = 0;\n  double4 sums = make_double4(0,0,0,0);\n\n  \n\n  if( threadIdx.x < R_W_MATRICES_SMEM_SLOTS )\n    smem_svds[threadIdx.x] = 0.0;\n  __syncthreads();\n\n  \n\n  int found_paths = 0;\n\n  \n\n  for( int path = threadIdx.x ; path < num_paths ; path += NUM_THREADS_PER_BLOCK )\n  {\n    \n\n    double S = paths[offset + path];\n\n    \n\n    const int in_the_money = payoff.is_in_the_money(S);\n\n    \n\n    scan_input[threadIdx.x] = in_the_money;\n    __syncthreads();\n    if (threadIdx.x == 0) {\n      scan_output[0] = 0;\n      for (int i = 1; i <= NUM_THREADS_PER_BLOCK; i++) \n        scan_output[i] = scan_output[i-1]+scan_input[i-1];\n    }\n    __syncthreads();\n    const int partial_sum = scan_output[threadIdx.x];\n    const int total_sum = scan_output[NUM_THREADS_PER_BLOCK];\n\n    if( found_paths < 3 )\n    {\n      if( in_the_money && found_paths + partial_sum < 3 )\n        smem_svds[found_paths + partial_sum] = S;\n      __syncthreads();\n      found_paths += total_sum;\n    }\n\n    \n\n    if (threadIdx.x == 0) lsum = 0;\n    __syncthreads();\n    atomicOr(&lsum, in_the_money);\n    __syncthreads();\n    if (lsum == 0) continue;\n    \n    \n\n    m += in_the_money;\n\n    \n\n    double x = 0.0, x_sq = 0.0;\n    if( in_the_money )\n    {\n      x = S;\n      x_sq = S*S;\n    }\n\n    \n\n    sums.x += x;\n    sums.y += x_sq;\n    sums.z += x_sq*x;\n    sums.w += x_sq*x_sq;\n  }\n\n  \n\n  if (threadIdx.x == 0) lsum = 0;\n  __syncthreads();\n\n  atomicAdd(&lsum, m);\n\n  __syncthreads();\n\n  int not_enough_paths = 0;\n  \n\n  if (threadIdx.x == 0 && lsum < min_in_the_money)\n    not_enough_paths = 1;\n  \n  \n\n  if( not_enough_paths )\n  {\n    if( threadIdx.x == 0 )\n      all_out_of_the_money[blockIdx.x] = 1;\n  } \n  else\n  {\n    \n\n\n    if (threadIdx.x == 0)\n      lsums = make_double4(0,0,0,0);\n    __syncthreads();\n\n    atomicAdd(&lsums.x, sums.x);\n    atomicAdd(&lsums.y, sums.y);\n    atomicAdd(&lsums.z, sums.z);\n    atomicAdd(&lsums.w, sums.w);\n    \n    __syncthreads();\n    \n    \n\n    if( threadIdx.x == 0 )\n      svd_3x3(lsum, lsums, smem_svds);\n\n    __syncthreads();\n\n    \n\n    if( threadIdx.x < R_W_MATRICES_SMEM_SLOTS )\n      svds[16*blockIdx.x + threadIdx.x] = smem_svds[threadIdx.x];\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK, 8)\nvoid compute_partial_beta_kernel(int num_paths,\n                                 Payoff payoff,\n                                 const double *__restrict svd,\n                                 const double *__restrict paths,\n                                 const double *__restrict cashflows,\n                                 const int *__restrict all_out_of_the_money,\n                                 double *__restrict partial_sums)\n{\n  \n\n  __shared__ double3 lsums;\n  \n  \n\n  __shared__ double shared_svd[R_W_MATRICES_SMEM_SLOTS];\n    \n  \n\n  if( *all_out_of_the_money ) return;\n\n  \n\n  const int NUM_THREADS_PER_GRID = NUM_THREADS_PER_BLOCK * gridDim.x;\n\n  \n\n  if( threadIdx.x < R_W_MATRICES_SMEM_SLOTS )\n    shared_svd[threadIdx.x] = svd[threadIdx.x];\n  __syncthreads();\n\n  \n\n  const double R00 = shared_svd[ 0];\n  const double R01 = shared_svd[ 1];\n  const double R02 = shared_svd[ 2];\n  const double R11 = shared_svd[ 3];\n  const double R12 = shared_svd[ 4];\n  const double R22 = shared_svd[ 5];\n\n  \n\n#ifdef WITH_FULL_W_MATRIX\n  const double W00 = shared_svd[ 6];\n  const double W01 = shared_svd[ 7];\n  const double W02 = shared_svd[ 8];\n  const double W10 = shared_svd[ 9];\n  const double W11 = shared_svd[10];\n  const double W12 = shared_svd[11];\n  const double W20 = shared_svd[12];\n  const double W21 = shared_svd[13];\n  const double W22 = shared_svd[14];\n#else\n  const double W00 = shared_svd[ 6];\n  const double W01 = shared_svd[ 7];\n  const double W02 = shared_svd[ 8];\n  const double W11 = shared_svd[ 9];\n  const double W12 = shared_svd[10];\n  const double W22 = shared_svd[11];\n#endif\n\n  \n\n  const double inv_R00 = R00 != 0.0 ? __drcp_rn(R00) : 0.0;\n  const double inv_R11 = R11 != 0.0 ? __drcp_rn(R11) : 0.0;\n  const double inv_R22 = R22 != 0.0 ? __drcp_rn(R22) : 0.0;\n\n  \n\n  const double inv_R01 = inv_R00*inv_R11*R01;\n  const double inv_R02 = inv_R00*inv_R22*R02;\n  const double inv_R12 =         inv_R22*R12;\n  \n  \n\n#ifdef WITH_FULL_W_MATRIX\n  const double inv_W00 = W00*inv_R00;\n  const double inv_W10 = W10*inv_R00;\n  const double inv_W20 = W20*inv_R00;\n#else\n  const double inv_W00 = W00*inv_R00;\n#endif\n\n  \n\n  double beta0 = 0.0, beta1 = 0.0, beta2 = 0.0;\n\n  \n\n  for( int path = blockIdx.x*NUM_THREADS_PER_BLOCK + threadIdx.x ; path < num_paths ; path += NUM_THREADS_PER_GRID )\n  {\n    \n\n    double S = paths[path];\n\n    \n\n    const int in_the_money = payoff.is_in_the_money(S);\n\n    \n\n    double Q1i = inv_R11*S - inv_R01;\n    double Q2i = inv_R22*S*S - inv_R02 - Q1i*inv_R12;\n\n    \n\n#ifdef WITH_FULL_W_MATRIX\n    const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n    const double WI1 = inv_W10 + W11 * Q1i + W12 * Q2i;\n    const double WI2 = inv_W20 + W21 * Q1i + W22 * Q2i;\n#else\n    const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n    const double WI1 =           W11 * Q1i + W12 * Q2i;\n    const double WI2 =                       W22 * Q2i;\n#endif\n\n    \n\n    double cashflow = in_the_money ? cashflows[path] : 0.0;\n  \n    \n\n    beta0 += WI0*cashflow;\n    beta1 += WI1*cashflow;\n    beta2 += WI2*cashflow;\n  }\n\n  \n\n  if( threadIdx.x == 0 )\n    lsums = make_double3(0,0,0);\n  __syncthreads();\n\n  atomicAdd(&lsums.x, beta0);\n  atomicAdd(&lsums.y, beta1);\n  atomicAdd(&lsums.z, beta2);\n \n  __syncthreads();\n  \n  \n\n  if( threadIdx.x == 0 )\n  {\n    partial_sums[0*NUM_THREADS_PER_BLOCK + blockIdx.x] = lsums.x;\n    partial_sums[1*NUM_THREADS_PER_BLOCK + blockIdx.x] = lsums.y;\n    partial_sums[2*NUM_THREADS_PER_BLOCK + blockIdx.x] = lsums.z;\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid compute_final_beta_kernel(const int *__restrict all_out_of_the_money, double *__restrict beta)\n{\n  \n\n  __shared__ double3 lsums;\n\n  \n\n  if( *all_out_of_the_money )\n  {\n    if( threadIdx.x < 3 )\n      beta[threadIdx.x] = 0.0;\n    return;\n  }\n\n  \n\n  double3 sums;\n  \n  \n\n  sums.x = beta[0*NUM_THREADS_PER_BLOCK + threadIdx.x];\n  sums.y = beta[1*NUM_THREADS_PER_BLOCK + threadIdx.x];\n  sums.z = beta[2*NUM_THREADS_PER_BLOCK + threadIdx.x];\n  \n  \n\n  if( threadIdx.x == 0 )\n    lsums = make_double3(0,0,0);\n  __syncthreads();\n\n  atomicAdd(&lsums.x, sums.x);\n  atomicAdd(&lsums.y, sums.y);\n  atomicAdd(&lsums.z, sums.z);\n \n  __syncthreads();\n  \n  \n\n  if( threadIdx.x == 0 )\n  {\n    \n\n    beta[0] = lsums.x; \n    beta[1] = lsums.y;\n    beta[2] = lsums.z;\n  }\n}\n\n\n\n\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid update_cashflow_kernel(int num_paths,\n                            Payoff payoff_object,\n                            double exp_min_r_dt,\n                            const double *__restrict beta,\n                            const double *__restrict paths,\n                            const int *__restrict all_out_of_the_money,\n                            double *__restrict cashflows)\n{\n  const int NUM_THREADS_PER_GRID = gridDim.x * NUM_THREADS_PER_BLOCK;\n\n  \n\n  const int skip_computations = *all_out_of_the_money;\n\n  \n\n  const double beta0 = beta[0];\n  const double beta1 = beta[1];\n  const double beta2 = beta[2];\n\n  \n\n  int path = blockIdx.x*NUM_THREADS_PER_BLOCK + threadIdx.x;\n  for( ; path < num_paths ; path += NUM_THREADS_PER_GRID )\n  {\n    \n\n    const double old_cashflow = exp_min_r_dt*cashflows[path];\n    if( skip_computations )\n    {\n      cashflows[path] = old_cashflow;\n      continue;\n    }\n  \n    \n\n    double S  = paths[path];\n    double S2 = S*S;\n\n    \n\n    double payoff = payoff_object(S);\n\n    \n\n    double estimated_payoff = beta0 + beta1*S + beta2*S2;\n\n    \n\n    estimated_payoff *= exp_min_r_dt;\n\n    \n\n    if( payoff <= 1.0e-8 || payoff <= estimated_payoff )\n      payoff = old_cashflow;\n    \n    \n\n    cashflows[path] = payoff;\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid compute_partial_sums_kernel(int num_paths, const double *__restrict cashflows, double *__restrict sums)\n{\n  \n\n  __shared__ double lsum;\n\n  \n\n  const int path = blockIdx.x * NUM_THREADS_PER_BLOCK + threadIdx.x;\n\n  \n\n  double sum = 0.0;\n  if( path < num_paths )\n    sum = cashflows[path];\n\n  \n\n  if (threadIdx.x == 0)\n    lsum = 0;\n  __syncthreads();\n  \n  atomicAdd(&lsum, sum);\n  __syncthreads();\n\n  \n\n  if( threadIdx.x == 0 )\n    sums[blockIdx.x] = lsum;\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK >\n__global__ __launch_bounds__(NUM_THREADS_PER_BLOCK)\nvoid compute_final_sum_kernel(int num_paths, int num_blocks, double exp_min_r_dt, double *__restrict sums)\n{\n  \n\n  __shared__ double lsum;\n\n  \n\n  double sum = 0.0;\n  for( int item = threadIdx.x ; item < num_blocks ; item += NUM_THREADS_PER_BLOCK )\n    sum += sums[item];\n\n  \n\n  if (threadIdx.x == 0) lsum = 0;\n  __syncthreads();\n  \n  atomicAdd(&lsum, sum);\n  __syncthreads();\n\n  \n\n  if( threadIdx.x == 0 )\n  {\n    sums[0] = exp_min_r_dt * lsum / (double) num_paths;\n  }\n}\n\ntemplate< typename Payoff >\nstatic inline \nvoid do_run(double *h_samples,\n            int num_timesteps, \n            int num_paths, \n            const Payoff &payoff, \n            double dt,\n            double S0,\n            double r,\n            double sigma,\n            double *d_samples,\n            double *d_paths,\n            double *d_cashflows,\n            double *d_svds,\n            int    *d_all_out_of_the_money,\n            double *d_temp_storage,\n            double *h_price)\n{\n  CHECK_HIP(hipMemcpy(d_samples, h_samples, sizeof(double) * num_timesteps*num_paths, hipMemcpyHostToDevice));\n\n  \n\n  const int NUM_THREADS_PER_BLOCK0 = 256;\n  int grid_dim = (num_paths + NUM_THREADS_PER_BLOCK0-1) / NUM_THREADS_PER_BLOCK0;\n  hipLaunchKernelGGL(HIP_KERNEL_NAME(generate_paths_kernel<NUM_THREADS_PER_BLOCK0>), dim3(grid_dim), dim3(NUM_THREADS_PER_BLOCK0), 0, 0, \n    num_timesteps,\n    num_paths,\n    payoff, \n    dt, \n    S0, \n    r, \n    sigma, \n    d_samples,\n    d_paths);\n  CHECK_HIP(hipGetLastError());\n\n  \n\n  CHECK_HIP(hipMemsetAsync(d_all_out_of_the_money, 0, num_timesteps*sizeof(int)));\n\n  \n\n  const int NUM_THREADS_PER_BLOCK1 = 256;\n  hipLaunchKernelGGL(HIP_KERNEL_NAME(prepare_svd_kernel<NUM_THREADS_PER_BLOCK1>), dim3(num_timesteps-1), dim3(NUM_THREADS_PER_BLOCK1), 0, 0, \n    num_paths,\n    4, \n\n    payoff, \n    d_paths, \n    d_all_out_of_the_money,\n    d_svds);\n  CHECK_HIP(hipGetLastError());\n\n  \n\n  const double exp_min_r_dt = std::exp(-r*dt);\n\n  \n\n  hipDeviceProp_t properties;\n  int device = 0;\n  CHECK_HIP(hipGetDevice(&device));\n  CHECK_HIP(hipGetDeviceProperties(&properties, device));\n\n  \n\n  const int num_threads_per_wave_full_occupancy = 256 * 112;\n\n  \n\n  const int NUM_THREADS_PER_BLOCK2 = 128;\n\n  \n\n  grid_dim = (num_paths + NUM_THREADS_PER_BLOCK2-1) / NUM_THREADS_PER_BLOCK2;\n  double num_waves = grid_dim*NUM_THREADS_PER_BLOCK2 / (double) num_threads_per_wave_full_occupancy;\n\n  int update_cashflow_grid = grid_dim;\n  if( num_waves < 10 && num_waves - (int) num_waves < 0.6 )\n    update_cashflow_grid = std::max(1, (int) num_waves) * num_threads_per_wave_full_occupancy / NUM_THREADS_PER_BLOCK2;\n\n  \n\n  for( int timestep = num_timesteps-2 ; timestep >= 0 ; --timestep )\n  {\n    \n\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(compute_partial_beta_kernel<NUM_THREADS_PER_BLOCK2>), dim3(NUM_THREADS_PER_BLOCK2), dim3(NUM_THREADS_PER_BLOCK2), 0, 0, \n      num_paths,\n      payoff,\n      d_svds + 16*timestep,\n      d_paths + timestep*num_paths,\n      d_cashflows,\n      d_all_out_of_the_money + timestep,\n      d_temp_storage);\n    CHECK_HIP(hipGetLastError());\n\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(compute_final_beta_kernel<NUM_THREADS_PER_BLOCK2>), dim3(1), dim3(NUM_THREADS_PER_BLOCK2), 0, 0, \n      d_all_out_of_the_money + timestep,\n      d_temp_storage);\n    CHECK_HIP(hipGetLastError());\n\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(update_cashflow_kernel<NUM_THREADS_PER_BLOCK2>), dim3(update_cashflow_grid), dim3(NUM_THREADS_PER_BLOCK2), 0, 0, \n      num_paths,\n      payoff,\n      exp_min_r_dt,\n      d_temp_storage,\n      d_paths + timestep*num_paths,\n      d_all_out_of_the_money + timestep,\n      d_cashflows);\n    CHECK_HIP(hipGetLastError());\n  }\n\n  \n\n  const int NUM_THREADS_PER_BLOCK4 = 128;\n  grid_dim = (num_paths + NUM_THREADS_PER_BLOCK4-1) / NUM_THREADS_PER_BLOCK4;\n  \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(compute_partial_sums_kernel<NUM_THREADS_PER_BLOCK4>), dim3(grid_dim), dim3(NUM_THREADS_PER_BLOCK4), 0, 0, \n    num_paths,\n    d_cashflows,\n    d_temp_storage);\n  CHECK_HIP(hipGetLastError());\n\n  hipLaunchKernelGGL(HIP_KERNEL_NAME(compute_final_sum_kernel<NUM_THREADS_PER_BLOCK4>), dim3(1), dim3(NUM_THREADS_PER_BLOCK4), 0, 0, \n    num_paths,\n    grid_dim,\n    exp_min_r_dt,\n    d_temp_storage);\n  CHECK_HIP(hipGetLastError());\n\n  \n\n  CHECK_HIP(hipMemcpy(h_price, d_temp_storage, sizeof(double), hipMemcpyDeviceToHost));\n}\n\ntemplate< typename Payoff >\nstatic double binomial_tree(int num_timesteps, const Payoff &payoff, double dt, double S0, double r, double sigma)\n{\n  double *tree = new double[num_timesteps+1];\n\n  double u = std::exp( sigma * std::sqrt(dt));\n  double d = std::exp(-sigma * std::sqrt(dt));\n  double a = std::exp( r     * dt);\n  \n  double p = (a - d) / (u - d);\n  \n  double k = std::pow(d, num_timesteps);\n  for( int t = 0 ; t <= num_timesteps ; ++t )\n  {\n    tree[t] = payoff(S0*k);\n    k *= u*u;\n  }\n\n  for( int t = num_timesteps-1 ; t >= 0 ; --t )\n  {\n    k = std::pow(d, t);\n    for( int i = 0 ; i <= t ; ++i )\n    {\n      double expected = std::exp(-r*dt) * (p*tree[i+1] + (1.0 - p)*tree[i]);\n      double earlyex = payoff(S0*k);\n      tree[i] = std::max(earlyex, expected);\n      k *= u*u;\n    }\n  }\n\n  double f = tree[0];\n  delete[] tree;\n  return f;\n}\n\n\n\ninline double normcdf (double x) {\n  return (1.0 + erf(x / sqrt(2.0))) / 2.0;\n}\n\nstatic double black_scholes_merton_put(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return K*std::exp(-r*T)*normcdf(-d2) - S0*normcdf(-d1);\n}\n\nstatic double black_scholes_merton_call(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return S0*normcdf(d1) - K*std::exp(-r*T)*normcdf(d2);\n}\n\nint main(int argc, char **argv)\n{\n  const int MAX_GRID_SIZE = 2048;\n  \n  \n\n  int num_timesteps = 100;\n  int num_paths     = 32;\n  int num_runs      = 1;\n\n  \n\n  double T     = 1.00;\n  double K     = 4.00;\n  double S0    = 3.60;\n  double r     = 0.06;\n  double sigma = 0.20;\n\n  \n\n  bool price_put = true;\n  \n  \n\n  for( int i = 1 ; i < argc ; ++i )\n  {\n    if( !strcmp(argv[i], \"-timesteps\") )\n      num_timesteps = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-paths\") )\n      num_paths = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-runs\") )\n      num_runs = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-T\") )\n      T = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-S0\") )\n      S0 = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-K\") )\n      K = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-r\") )\n      r = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-sigma\") )\n      sigma = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-call\") )\n      price_put = false;\n    else\n    {\n      fprintf(stderr, \"Unknown option %s. Aborting!!!\\n\", argv[i]);\n      exit(1);\n    }\n  }\n\n  \n\n  printf(\"==============\\n\");\n  printf(\"Num Timesteps         : %d\\n\",  num_timesteps);\n  printf(\"Num Paths             : %dK\\n\", num_paths);\n  printf(\"Num Runs              : %d\\n\",  num_runs);\n  printf(\"T                     : %lf\\n\", T);\n  printf(\"S0                    : %lf\\n\", S0);\n  printf(\"K                     : %lf\\n\", K);\n  printf(\"r                     : %lf\\n\", r);\n  printf(\"sigma                 : %lf\\n\", sigma);\n  printf(\"Option Type           : American %s\\n\",  price_put ? \"Put\" : \"Call\");\n\n  \n\n  num_paths *= 1024;\n\n  \n\n  double dt = T / num_timesteps;\n\n  \n\n  std::default_random_engine rng;\n  std::normal_distribution<double> norm_dist(0.0, 1.0);\n\n  double *h_samples = (double*) malloc (num_timesteps*num_paths*sizeof(double));\n\n  \n\n  double *d_samples = NULL;\n  CHECK_HIP(hipMalloc((void**) &d_samples, num_timesteps*num_paths*sizeof(double)));\n\n  \n\n  double *d_paths = NULL;\n  CHECK_HIP(hipMalloc((void**) &d_paths, num_timesteps*num_paths*sizeof(double)));\n\n  \n\n  double *d_cashflows = d_paths + (num_timesteps-1)*num_paths;\n\n  \n\n  double *d_svds = NULL;\n  CHECK_HIP(hipMalloc((void**) &d_svds, 16*num_timesteps*sizeof(double)));\n\n  \n\n  int *d_all_out_of_the_money = NULL;\n  CHECK_HIP(hipMalloc((void**) &d_all_out_of_the_money, num_timesteps*sizeof(int)));\n\n  \n\n  int max_temp_storage = 4*MAX_GRID_SIZE;\n  double *d_temp_storage = NULL;\n  CHECK_HIP(hipMalloc((void**) &d_temp_storage, max_temp_storage*sizeof(double)));\n\n  \n\n  double h_price;\n\n  \n\n  float total_elapsed_time = 0;\n\n  for( int run = 0; run < num_runs; ++run )\n  {\n    for (int i = 0; i < num_timesteps*num_paths; ++i)\n      h_samples[i] = norm_dist(rng);\n      \n    auto start = std::chrono::high_resolution_clock::now();\n    if( price_put )\n      do_run(h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffPut(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             d_samples,\n             d_paths,\n             d_cashflows,\n             d_svds,\n             d_all_out_of_the_money,\n             d_temp_storage,\n             &h_price);\n    else\n      do_run(h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffCall(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             d_samples,\n             d_paths,\n             d_cashflows,\n             d_svds,\n             d_all_out_of_the_money,\n             d_temp_storage,\n             &h_price);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    const float elapsed_time =\n       std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n    total_elapsed_time += elapsed_time;\n  }\n\n  printf(\"==============\\n\");\n  printf(\"GPU Longstaff-Schwartz: %.8lf\\n\", h_price);\n  \n  double price = 0.0;\n\n  if( price_put )\n    price = binomial_tree(num_timesteps, PayoffPut(K), dt, S0, r, sigma);\n  else\n    price = binomial_tree(num_timesteps, PayoffCall(K), dt, S0, r, sigma);\n\n  printf(\"Binonmial             : %.8lf\\n\", price);\n  \n  if( price_put )\n    price = black_scholes_merton_put(T, K, S0, r, sigma);\n  else\n    price = black_scholes_merton_call(T, K, S0, r, sigma);\n\n  printf(\"European Price        : %.8lf\\n\", price);\n\n  printf(\"==============\\n\");\n\n  printf(\"elapsed time for each run         : %.3fms\\n\", total_elapsed_time / num_runs);\n  printf(\"==============\\n\");\n\n  \n\n  free(h_samples);\n  CHECK_HIP(hipFree(d_temp_storage));\n  CHECK_HIP(hipFree(d_all_out_of_the_money));\n  CHECK_HIP(hipFree(d_svds));\n  CHECK_HIP(hipFree(d_paths));\n  CHECK_HIP(hipFree(d_samples));\n\n  return 0;\n}\n"}}
{"kernel_name": "aop", "parallel_api": "omp", "code": {"main.cpp": "\n\n \n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <algorithm>\n#include <omp.h>\n\n#ifdef WITH_FULL_W_MATRIX\n#define R_W_MATRICES_SMEM_SLOTS 15\n#else\n#define R_W_MATRICES_SMEM_SLOTS 12\n#endif\n\n#define HOST_DEVICE        \n#define HOST_DEVICE_INLINE inline\n\ntypedef struct __attribute__((__aligned__(32)))\n{\n  double x, y, z, w;\n}\ndouble4;\n\ntypedef struct __attribute__((__aligned__(32)))\n{\n  double x, y, z;\n}\ndouble3;\n\nHOST_DEVICE_INLINE double3 operator+(const double3 &u, const double3 &v )\n{\n  return {u.x+v.x, u.y+v.y, u.z+v.z};\n}\n\nHOST_DEVICE_INLINE double4 operator+(const double4 &u, const double4 &v )\n{\n  return {u.x+v.x, u.y+v.y, u.z+v.z, u.w+v.w};\n}\n\nstruct PayoffCall\n{\n  double m_K;\n  HOST_DEVICE_INLINE PayoffCall(double K) : m_K(K) {}\n  HOST_DEVICE_INLINE double operator()(double S) const { return fmax(S - m_K, 0.0); }\n  HOST_DEVICE_INLINE int is_in_the_money(double S) const { return S > m_K; }\n};\n\nstruct PayoffPut\n{\n  double m_K;\n  HOST_DEVICE_INLINE PayoffPut(double K) : m_K(K) {}\n  HOST_DEVICE_INLINE double operator()(double S) const { return fmax(m_K - S, 0.0); }\n  HOST_DEVICE_INLINE int is_in_the_money(double S) const { return S < m_K; }\n};\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid generate_paths_kernel(int num_timesteps, \n                           int num_paths, \n                           Payoff payoff,\n                           double dt, \n                           double S0, \n                           double r, \n                           double sigma, \n                           const double *__restrict samples, \n                           double *__restrict paths)\n{\n  \n\n  #pragma omp target teams distribute parallel for thread_limit (NUM_THREADS_PER_BLOCK)\n  for (int path = 0; path < num_paths; path++) {\n\n    \n\n    const double r_min_half_sigma_sq_dt = (r - 0.5*sigma*sigma)*dt;\n    \n\n    const double sigma_sqrt_dt = sigma*sqrt(dt);\n\n    \n\n    double S = S0;\n\n    \n\n    int offset = path;\n    \n    \n\n    for( int timestep = 0 ; timestep < num_timesteps-1 ; ++timestep, offset += num_paths )\n    {\n      S = S * exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n      paths[offset] = S;\n    }\n\n    \n\n    S = S * exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n\n    \n\n    paths[offset] = payoff(S);\n  }\n}\n\n#pragma omp declare target\nstatic inline void assemble_R(int m, double4 &sums, double *smem_svds)\n{\n  \n\n\n  double x0 = smem_svds[0];\n  double x1 = smem_svds[1];\n  double x2 = smem_svds[2];\n\n  double x0_sq = x0 * x0;\n\n  double sum1 = sums.x - x0;\n  double sum2 = sums.y - x0_sq;\n  double sum3 = sums.z - x0_sq*x0;\n  double sum4 = sums.w - x0_sq*x0_sq;\n\n  double m_as_dbl = (double) m;\n  double sigma = m_as_dbl - 1.0;\n  double mu = sqrt(m_as_dbl);\n  double v0 = -sigma / (1.0 + mu);\n  double v0_sq = v0*v0;\n  double beta = 2.0 * v0_sq / (sigma + v0_sq);\n  \n  double inv_v0 = 1.0 / v0;\n  double one_min_beta = 1.0 - beta;\n  double beta_div_v0  = beta * inv_v0;\n  \n  smem_svds[0] = mu;\n  smem_svds[1] = one_min_beta*x0 - beta_div_v0*sum1;\n  smem_svds[2] = one_min_beta*x0_sq - beta_div_v0*sum2;\n  \n  \n\n  \n  double beta_div_v0_sq = beta_div_v0 * inv_v0;\n  \n  double c1 = beta_div_v0_sq*sum1 + beta_div_v0*x0;\n  double c2 = beta_div_v0_sq*sum2 + beta_div_v0*x0_sq;\n\n  \n\n  \n  double x1_sq = x1*x1;\n\n  sum1 -= x1;\n  sum2 -= x1_sq;\n  sum3 -= x1_sq*x1;\n  sum4 -= x1_sq*x1_sq;\n  \n  x0 = x1-c1;\n  x0_sq = x0*x0;\n  sigma = sum2 - 2.0*c1*sum1 + (m_as_dbl-2.0)*c1*c1;\n  if( abs(sigma) < 1.0e-16 )\n    beta = 0.0;\n  else\n  {\n    mu = sqrt(x0_sq + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  inv_v0 = 1.0 / v0;\n  beta_div_v0 = beta * inv_v0;\n  \n  \n\n  double c3 = (sum3 - c1*sum2 - c2*sum1 + (m_as_dbl-2.0)*c1*c2)*beta_div_v0;\n  double c4 = (x1_sq-c2)*beta_div_v0 + c3*inv_v0;\n  double c5 = c1*c4 - c2;\n  \n  one_min_beta = 1.0 - beta;\n  \n  \n\n  smem_svds[3] = one_min_beta*x0 - beta_div_v0*sigma;\n  smem_svds[4] = one_min_beta*(x1_sq-c2) - c3;\n  \n  \n\n  \n  double x2_sq = x2*x2;\n\n  sum1 -= x2;\n  sum2 -= x2_sq;\n  sum3 -= x2_sq*x2;\n  sum4 -= x2_sq*x2_sq;\n  \n  x0 = x2_sq-c4*x2+c5;\n  sigma = sum4 - 2.0*c4*sum3 + (c4*c4 + 2.0*c5)*sum2 - 2.0*c4*c5*sum1 + (m_as_dbl-3.0)*c5*c5;\n  if( abs(sigma) < 1.0e-12 )\n    beta = 0.0;\n  else\n  {\n    mu = sqrt(x0*x0 + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  \n\n  smem_svds[5] = (1.0-beta)*x0 - (beta/v0)*sigma;\n}\n\nstatic double off_diag_norm(double A01, double A02, double A12)\n{\n  return sqrt(2.0 * (A01*A01 + A02*A02 + A12*A12));\n}\n\nstatic inline void swap(double &x, double &y)\n{\n  double t = x; x = y; y = t;\n}\n\nstatic inline void svd_3x3(int m, double4 &sums, double *smem_svds)\n{\n  \n\n  assemble_R(m, sums, smem_svds);\n\n  \n\n  double R00 = smem_svds[0];\n  double R01 = smem_svds[1];\n  double R02 = smem_svds[2];\n  double R11 = smem_svds[3];\n  double R12 = smem_svds[4];\n  double R22 = smem_svds[5];\n\n  \n\n  \n  double A00 = R00*R00;\n  double A01 = R00*R01;\n  double A02 = R00*R02;\n  double A11 = R01*R01 + R11*R11;\n  double A12 = R01*R02 + R11*R12;\n  double A22 = R02*R02 + R12*R12 + R22*R22;\n  \n  \n\n  \n  double V00 = 1.0, V01 = 0.0, V02 = 0.0;\n  double V10 = 0.0, V11 = 1.0, V12 = 0.0;\n  double V20 = 0.0, V21 = 0.0, V22 = 1.0;\n  \n  \n\n  \n  const int max_iters = 16;\n  const double tolerance = 1.0e-12;\n  \n  \n\n \n  for( int iter = 0 ; off_diag_norm(A01, A02, A12) >= tolerance && iter < max_iters ; ++iter )\n  {\n    double c, s, B00, B01, B02, B10, B11, B12, B20, B21, B22;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A01 != 0.0 )\n    {\n      double tau = (A11 - A00) / (2.0 * A01);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A01;\n    B01 = s*A00 + c*A01;\n    B10 = c*A01 - s*A11;\n    B11 = s*A01 + c*A11;\n    B02 = A02;\n    \n    A00 = c*B00 - s*B10;\n    A01 = c*B01 - s*B11;\n    A11 = s*B01 + c*B11;\n    A02 = c*B02 - s*A12;\n    A12 = s*B02 + c*A12;\n    \n    B00 = c*V00 - s*V01;\n    V01 = s*V00 + c*V01;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V11;\n    V11 = s*V10 + c*V11;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V21;\n    V21 = s*V20 + c*V21;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A02 != 0.0 )\n    {\n      double tau = (A22 - A00) / (2.0 * A02);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A02;\n    B01 = c*A01 - s*A12;\n    B02 = s*A00 + c*A02;\n    B20 = c*A02 - s*A22;\n    B22 = s*A02 + c*A22;\n    \n    A00 = c*B00 - s*B20;\n    A12 = s*A01 + c*A12;\n    A02 = c*B02 - s*B22;\n    A22 = s*B02 + c*B22;\n    A01 = B01;\n    \n    B00 = c*V00 - s*V02;\n    V02 = s*V00 + c*V02;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V12;\n    V12 = s*V10 + c*V12;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V22;\n    V22 = s*V20 + c*V22;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A12 != 0.0 )\n    {\n      double tau = (A22 - A11) / (2.0 * A12);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B02 = s*A01 + c*A02;\n    B11 = c*A11 - s*A12;\n    B12 = s*A11 + c*A12;\n    B21 = c*A12 - s*A22;\n    B22 = s*A12 + c*A22;\n    \n    A01 = c*A01 - s*A02;\n    A02 = B02;\n    A11 = c*B11 - s*B21;\n    A12 = c*B12 - s*B22;\n    A22 = s*B12 + c*B22;\n    \n    B01 = c*V01 - s*V02;\n    V02 = s*V01 + c*V02;\n    V01 = B01;\n    \n    B11 = c*V11 - s*V12;\n    V12 = s*V11 + c*V12;\n    V11 = B11;\n    \n    B21 = c*V21 - s*V22;\n    V22 = s*V21 + c*V22;\n    V21 = B21;\n  }\n\n  \n\n  if( A00 < A11 )\n  {\n    swap(A00, A11);\n    swap(V00, V01);\n    swap(V10, V11);\n    swap(V20, V21);\n  }\n  if( A00 < A22 )\n  {\n    swap(A00, A22);\n    swap(V00, V02);\n    swap(V10, V12);\n    swap(V20, V22);\n  }\n  if( A11 < A22 )\n  {\n    swap(A11, A22);\n    swap(V01, V02);\n    swap(V11, V12);\n    swap(V21, V22);\n  }\n\n  \n\n  \n  \n\n  \n  double inv_S0 = abs(A00) < 1.0e-12 ? 0.0 : 1.0 / A00;\n  double inv_S1 = abs(A11) < 1.0e-12 ? 0.0 : 1.0 / A11;\n  double inv_S2 = abs(A22) < 1.0e-12 ? 0.0 : 1.0 / A22;\n\n  \n\n  \n  double U00 = V00 * inv_S0; \n  double U01 = V01 * inv_S1; \n  double U02 = V02 * inv_S2;\n  double U10 = V10 * inv_S0; \n  double U11 = V11 * inv_S1; \n  double U12 = V12 * inv_S2;\n  double U20 = V20 * inv_S0; \n  double U21 = V21 * inv_S1; \n  double U22 = V22 * inv_S2;\n  \n  \n\n  \n#ifdef WITH_FULL_W_MATRIX\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B10 = U10*V00 + U11*V01 + U12*V02;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B20 = U20*V00 + U21*V01 + U22*V02;\n  double B21 = U20*V10 + U21*V11 + U22*V12;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] = B10*R00 + B11*R01 + B12*R02;\n  smem_svds[10] =           B11*R11 + B12*R12;\n  smem_svds[11] =                     B12*R22;\n  smem_svds[12] = B20*R00 + B21*R01 + B22*R02;\n  smem_svds[13] =           B21*R11 + B22*R12;\n  smem_svds[14] =                     B22*R22;\n#else\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] =           B11*R11 + B12*R12;\n  smem_svds[10] =                     B12*R22;\n  smem_svds[11] =                     B22*R22;\n#endif\n}\n#pragma omp end declare target\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid prepare_svd_kernel(const int numTeams,\n                        int num_paths, \n                        int min_in_the_money, \n                        Payoff payoff, \n                        const double *__restrict paths, \n                                 int *__restrict all_out_of_the_money, \n                              double *__restrict svds)\n{\n  #pragma omp target teams num_teams(numTeams) thread_limit(NUM_THREADS_PER_BLOCK)\n  {\n    \n\n    int scan_input[NUM_THREADS_PER_BLOCK];\n    int scan_output[1+NUM_THREADS_PER_BLOCK];\n\n    \n\n    double4 lsums;\n    int lsum;\n\n    \n\n    double smem_svds[R_W_MATRICES_SMEM_SLOTS];\n    #pragma omp parallel \n    {\n      int lid = omp_get_thread_num();\n      int bid = omp_get_team_num();\n\n      \n\n      const int timestep = bid;\n      \n\n      const int offset = timestep * num_paths;\n\n      \n\n      int m = 0;\n      double4 sums = { 0.0, 0.0, 0.0, 0.0 };\n\n      \n\n      if( lid < R_W_MATRICES_SMEM_SLOTS )\n        smem_svds[lid] = 0.0;\n      #pragma omp barrier\n\n      \n\n      int found_paths = 0;\n\n      \n\n      for( int path = lid ; path < num_paths ; path += NUM_THREADS_PER_BLOCK )\n      {\n        \n\n        double S = paths[offset + path];\n\n        \n\n        const int in_the_money = payoff.is_in_the_money(S);\n\n        \n\n        scan_input[lid] = in_the_money;\n        #pragma omp barrier\n        if (lid == 0) {\n          scan_output[0] = 0;\n          for (int i = 1; i <= NUM_THREADS_PER_BLOCK; i++) \n            scan_output[i] = scan_output[i-1]+scan_input[i-1];\n        }\n        #pragma omp barrier\n        const int partial_sum = scan_output[lid];\n        const int total_sum = scan_output[NUM_THREADS_PER_BLOCK];\n\n        if( found_paths < 3 )\n        {\n          if( in_the_money && found_paths + partial_sum < 3 )\n            smem_svds[found_paths + partial_sum] = S;\n          #pragma omp barrier\n          found_paths += total_sum;\n        }\n\n        \n\n        if (lid == 0) lsum = 0;\n        #pragma omp barrier\n\n        #pragma omp atomic update\n        lsum |= in_the_money;\n\n        #pragma omp barrier\n        if (lsum == 0) continue;\n        \n        \n\n        m += in_the_money;\n\n        \n\n        double x = 0.0, x_sq = 0.0;\n        if( in_the_money )\n        {\n          x = S;\n          x_sq = S*S;\n        }\n\n        \n\n        sums.x += x;\n        sums.y += x_sq;\n        sums.z += x_sq*x;\n        sums.w += x_sq*x_sq;\n      }\n\n      \n\n      if (lid == 0) lsum = 0;\n      #pragma omp barrier\n\n      #pragma omp atomic update\n      lsum += m;\n\n      #pragma omp barrier\n\n      int not_enough_paths = 0;\n      \n\n      if (lid == 0 && lsum < min_in_the_money)\n        not_enough_paths = 1;\n      \n      \n\n      if( not_enough_paths )\n      {\n        if( lid == 0 )\n          all_out_of_the_money[bid] = 1;\n      } \n      else\n      {\n        \n\n\n        if (lid == 0) lsums = {0.0, 0.0, 0.0, 0.0};\n        #pragma omp barrier\n\n        #pragma omp atomic update\n        lsums.x += sums.x;\n\n        #pragma omp atomic update\n        lsums.y += sums.y;\n\n        #pragma omp atomic update\n        lsums.z += sums.z;\n        \n        #pragma omp barrier\n        \n        \n\n        if( lid == 0 )\n          svd_3x3(lsum, lsums, smem_svds);\n\n        #pragma omp barrier\n\n        \n\n        if( lid < R_W_MATRICES_SMEM_SLOTS )\n          svds[16*bid + lid] = smem_svds[lid];\n      }\n    }\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid compute_beta_kernel(int num_paths,\n                         Payoff payoff,\n                         const double *__restrict svd,\n                         const double *__restrict paths,\n                         const double *__restrict cashflows,\n                         const int *__restrict all_out_of_the_money,\n                         double *__restrict beta)\n{\n  \n\n  if( *all_out_of_the_money == 0) {\n\n    \n\n    \n\n    #pragma omp target teams distribute parallel for thread_limit(NUM_THREADS_PER_BLOCK) \\\n                                                       reduction(+:beta[:3]) shared(svd)\n    for( int path = 0; path < num_paths ; path++)\n    {\n      \n\n      const double R00 = svd[ 0];\n      const double R01 = svd[ 1];\n      const double R02 = svd[ 2];\n      const double R11 = svd[ 3];\n      const double R12 = svd[ 4];\n      const double R22 = svd[ 5];\n\n    \n\n    #ifdef WITH_FULL_W_MATRIX\n      const double W00 = svd[ 6];\n      const double W01 = svd[ 7];\n      const double W02 = svd[ 8];\n      const double W10 = svd[ 9];\n      const double W11 = svd[10];\n      const double W12 = svd[11];\n      const double W20 = svd[12];\n      const double W21 = svd[13];\n      const double W22 = svd[14];\n    #else\n      const double W00 = svd[ 6];\n      const double W01 = svd[ 7];\n      const double W02 = svd[ 8];\n      const double W11 = svd[ 9];\n      const double W12 = svd[10];\n      const double W22 = svd[11];\n    #endif\n\n      \n\n      const double inv_R00 = R00 != 0.0 ? 1.0 / R00 : 0.0;\n      const double inv_R11 = R11 != 0.0 ? 1.0 / R11 : 0.0;\n      const double inv_R22 = R22 != 0.0 ? 1.0 / R22 : 0.0;\n\n      \n\n      const double inv_R01 = inv_R00*inv_R11*R01;\n      const double inv_R02 = inv_R00*inv_R22*R02;\n      const double inv_R12 =         inv_R22*R12;\n      \n      \n\n    #ifdef WITH_FULL_W_MATRIX\n      const double inv_W00 = W00*inv_R00;\n      const double inv_W10 = W10*inv_R00;\n      const double inv_W20 = W20*inv_R00;\n    #else\n      const double inv_W00 = W00*inv_R00;\n    #endif\n      \n\n      double S = paths[path];\n\n      \n\n      const int in_the_money = payoff.is_in_the_money(S);\n\n      \n\n      double Q1i = inv_R11*S - inv_R01;\n      double Q2i = inv_R22*S*S - inv_R02 - Q1i*inv_R12;\n\n      \n\n  #ifdef WITH_FULL_W_MATRIX\n      const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n      const double WI1 = inv_W10 + W11 * Q1i + W12 * Q2i;\n      const double WI2 = inv_W20 + W21 * Q1i + W22 * Q2i;\n  #else\n      const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n      const double WI1 =           W11 * Q1i + W12 * Q2i;\n      const double WI2 =                       W22 * Q2i;\n  #endif\n\n      \n\n      double cashflow = in_the_money ? cashflows[path] : 0.0;\n    \n      \n\n      beta[0] += WI0*cashflow;\n      beta[1] += WI1*cashflow;\n      beta[2] += WI2*cashflow;\n    }\n  }\n}\n\n\n\n\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid update_cashflow_kernel(int numTeams, \n                            int num_paths,\n                            Payoff payoff_object,\n                            double exp_min_r_dt,\n                            const double *__restrict beta,\n                            const double *__restrict paths,\n                            const int *__restrict all_out_of_the_money,\n                            double *__restrict cashflows)\n{\n  \n\n  #pragma omp target teams distribute parallel for num_teams(numTeams) thread_limit(NUM_THREADS_PER_BLOCK)\n  for (int path = 0; path < num_paths ; path ++) \n  {\n    \n\n    const int skip_computations = *all_out_of_the_money;\n\n    \n\n    const double beta0 = beta[0];\n    const double beta1 = beta[1];\n    const double beta2 = beta[2];\n\n    \n\n    const double old_cashflow = exp_min_r_dt*cashflows[path];\n    if( skip_computations )\n    {\n      cashflows[path] = old_cashflow;\n      continue;\n    }\n  \n    \n\n    double S  = paths[path];\n    double S2 = S*S;\n\n    \n\n    double payoff = payoff_object(S);\n\n    \n\n    double estimated_payoff = beta0 + beta1*S + beta2*S2;\n\n    \n\n    estimated_payoff *= exp_min_r_dt;\n\n    \n\n    if( payoff <= 1.0e-8 || payoff <= estimated_payoff )\n      payoff = old_cashflow;\n    \n    \n\n    cashflows[path] = payoff;\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK >\nvoid compute_sums_kernel(int num_paths, \n                         const double *__restrict cashflows,\n                         double exp_min_r_dt, \n                         double &price)\n{\n  double sum = 0.0;\n  \n\n  #pragma omp target teams distribute parallel for thread_limit(NUM_THREADS_PER_BLOCK) \\\n                                                     map(tofrom: sum) reduction(+:sum)\n  for (int path = 0; path < num_paths; path++)\n  {\n    sum += cashflows[path];\n  }\n  price = exp_min_r_dt * sum / (double) num_paths;\n}\n\n\ntemplate< typename Payoff >\nstatic inline \nvoid do_run(double *h_samples,\n            int num_timesteps, \n            int num_paths, \n            const Payoff &payoff, \n            double dt,\n            double S0,\n            double r,\n            double sigma,\n            double *d_paths,\n            double *d_cashflows,\n            double *d_svds,\n            int    *d_all_out_of_the_money,\n            double *d_temp_storage,\n            double &h_price)\n{\n  #pragma omp target update to (h_samples[0:num_timesteps*num_paths])\n\n  \n\n  const int NUM_THREADS_PER_BLOCK0 = 256;\n  generate_paths_kernel<NUM_THREADS_PER_BLOCK0>(\n    num_timesteps,\n    num_paths,\n    payoff, \n    dt, \n    S0, \n    r, \n    sigma, \n    h_samples,\n    d_paths);\n\n  \n\n  #pragma omp target teams distribute parallel for thread_limit(256) \n  for (int i = 0; i < num_timesteps; i++)\n    d_all_out_of_the_money[i] = 0;\n\n  \n\n  const int NUM_THREADS_PER_BLOCK1 = 256;\n  prepare_svd_kernel<NUM_THREADS_PER_BLOCK1>(\n    num_timesteps-1,  \n\n    num_paths,\n    4, \n\n    payoff, \n    d_paths, \n    d_all_out_of_the_money,\n    d_svds);\n\n#ifdef DEBUG\n   #pragma omp target update from (d_svds[0:num_timesteps*16])\n   for (int i = 0; i < num_timesteps*16; i++)\n     printf(\"svd%d: %lf\\n\", i, d_svds[i]);\n#endif\n\n  \n\n  const double exp_min_r_dt = std::exp(-r*dt);\n\n  \n\n  const int num_threads_per_wave_full_occupancy = 256 * 112;\n\n  \n\n  const int NUM_THREADS_PER_BLOCK2 = 128;\n\n  \n\n  const int grid_dim = (num_paths + NUM_THREADS_PER_BLOCK2-1) / NUM_THREADS_PER_BLOCK2;\n  double num_waves = grid_dim*NUM_THREADS_PER_BLOCK2 / (double) num_threads_per_wave_full_occupancy;\n\n  int update_cashflow_grid = grid_dim;\n  if( num_waves < 10 && num_waves - (int) num_waves < 0.6 )\n    update_cashflow_grid = std::max(1, (int) num_waves) * num_threads_per_wave_full_occupancy / NUM_THREADS_PER_BLOCK2;\n\n  \n\n  for( int timestep = num_timesteps-2 ; timestep >= 0 ; --timestep )\n  {\n    \n\n    compute_beta_kernel<NUM_THREADS_PER_BLOCK2>(\n      num_paths,\n      payoff,\n      d_svds + 16*timestep,\n      d_paths + timestep*num_paths,\n      d_cashflows,\n      d_all_out_of_the_money + timestep,\n      d_temp_storage);\n\n#ifdef DEBUG\n   #pragma omp target update from (d_temp_storage[0:4*2048])\n   printf(\"timestep: %d beta: %lf %lf %lf\\n\", timestep, d_temp_storage[0], d_temp_storage[1], d_temp_storage[2]);\n#endif\n\n    update_cashflow_kernel<NUM_THREADS_PER_BLOCK2>(\n      update_cashflow_grid,\n      num_paths,\n      payoff,\n      exp_min_r_dt,\n      d_temp_storage,\n      d_paths + timestep*num_paths,\n      d_all_out_of_the_money + timestep,\n      d_cashflows);\n  }\n\n  \n\n  const int NUM_THREADS_PER_BLOCK4 = 128;\n  compute_sums_kernel<NUM_THREADS_PER_BLOCK4>(\n    num_paths,\n    d_cashflows,\n    exp_min_r_dt,\n    h_price);\n}\n\ntemplate< typename Payoff >\nstatic double binomial_tree(int num_timesteps, const Payoff &payoff, double dt, double S0, double r, double sigma)\n{\n  double *tree = new double[num_timesteps+1];\n\n  double u = std::exp( sigma * std::sqrt(dt));\n  double d = std::exp(-sigma * std::sqrt(dt));\n  double a = std::exp( r     * dt);\n  \n  double p = (a - d) / (u - d);\n  \n  double k = std::pow(d, num_timesteps);\n  for( int t = 0 ; t <= num_timesteps ; ++t )\n  {\n    tree[t] = payoff(S0*k);\n    k *= u*u;\n  }\n\n  for( int t = num_timesteps-1 ; t >= 0 ; --t )\n  {\n    k = std::pow(d, t);\n    for( int i = 0 ; i <= t ; ++i )\n    {\n      double expected = std::exp(-r*dt) * (p*tree[i+1] + (1.0 - p)*tree[i]);\n      double earlyex = payoff(S0*k);\n      tree[i] = std::max(earlyex, expected);\n      k *= u*u;\n    }\n  }\n\n  double f = tree[0];\n  delete[] tree;\n  return f;\n}\n\n\n\ninline double my_normcdf (double x) {\n  return (1.0 + erf(x / sqrt(2.0))) / 2.0;\n}\n\nstatic double black_scholes_merton_put(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return K*std::exp(-r*T)*my_normcdf(-d2) - S0*my_normcdf(-d1);\n}\n\nstatic double black_scholes_merton_call(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return S0*my_normcdf(d1) - K*std::exp(-r*T)*my_normcdf(d2);\n}\n\nint main(int argc, char **argv)\n{\n  const int MAX_GRID_SIZE = 2048;\n  \n  \n\n  int num_timesteps = 100;\n  int num_paths     = 32;\n  int num_runs      = 1;\n\n  \n\n  double T     = 1.00;\n  double K     = 4.00;\n  double S0    = 3.60;\n  double r     = 0.06;\n  double sigma = 0.20;\n\n  \n\n  bool price_put = true;\n  \n  \n\n  for( int i = 1 ; i < argc ; ++i )\n  {\n    if( !strcmp(argv[i], \"-timesteps\") )\n      num_timesteps = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-paths\") )\n      num_paths = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-runs\") )\n      num_runs = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-T\") )\n      T = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-S0\") )\n      S0 = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-K\") )\n      K = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-r\") )\n      r = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-sigma\") )\n      sigma = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-call\") )\n      price_put = false;\n    else\n    {\n      fprintf(stderr, \"Unknown option %s. Aborting!!!\\n\", argv[i]);\n      exit(1);\n    }\n  }\n\n  \n\n  printf(\"==============\\n\");\n  printf(\"Num Timesteps         : %d\\n\",  num_timesteps);\n  printf(\"Num Paths             : %dK\\n\", num_paths);\n  printf(\"Num Runs              : %d\\n\",  num_runs);\n  printf(\"T                     : %lf\\n\", T);\n  printf(\"S0                    : %lf\\n\", S0);\n  printf(\"K                     : %lf\\n\", K);\n  printf(\"r                     : %lf\\n\", r);\n  printf(\"sigma                 : %lf\\n\", sigma);\n  printf(\"Option Type           : American %s\\n\",  price_put ? \"Put\" : \"Call\");\n\n  \n\n  num_paths *= 1024;\n\n  \n\n  double dt = T / num_timesteps;\n\n  \n\n  std::default_random_engine rng;\n  std::normal_distribution<double> norm_dist(0.0, 1.0);\n\n  \n\n  double *h_samples = (double*) malloc (num_timesteps*num_paths*sizeof(double));\n\n  \n\n  double *h_paths = (double*) malloc (num_timesteps*num_paths*sizeof(double));\n\n  \n\n  double *h_svds = (double*) malloc (16*num_timesteps*sizeof(double));\n\n  \n\n  int *h_all_out_of_the_money = (int*) malloc (num_timesteps*sizeof(int));\n\n  \n\n  int max_temp_storage = 4*MAX_GRID_SIZE;\n  double *h_temp_storage = (double*) malloc (max_temp_storage*sizeof(double));\n\n  \n\n  \n\n\n#pragma omp target data map(alloc: h_samples[0:num_timesteps*num_paths], \\\n                                   h_paths[0:num_timesteps*num_paths], \\\n                                   h_svds[0:num_timesteps*16], \\\n                                   h_all_out_of_the_money[0:num_timesteps],\\\n                                   h_temp_storage[0:max_temp_storage])\n{\n  \n\n  double h_price;\n\n  \n\n  float total_elapsed_time = 0;\n\n  for( int run = 0; run < num_runs; ++run )\n  {\n    for (int i = 0; i < num_timesteps*num_paths; ++i)\n      h_samples[i] = norm_dist(rng);\n      \n    auto start = std::chrono::high_resolution_clock::now();\n    if( price_put )\n      do_run(h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffPut(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             h_paths,\n             h_paths + (num_timesteps-1)*num_paths, \n\n             h_svds,\n             h_all_out_of_the_money,\n             h_temp_storage,\n             h_price);\n    else\n      do_run(h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffCall(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             h_paths,\n             h_paths + (num_timesteps-1)*num_paths, \n\n             h_svds,\n             h_all_out_of_the_money,\n             h_temp_storage,\n             h_price);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    const float elapsed_time =\n       std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n    total_elapsed_time += elapsed_time;\n  }\n\n  printf(\"==============\\n\");\n  printf(\"GPU Longstaff-Schwartz: %.8lf\\n\", h_price);\n  \n  double price = 0.0;\n\n  if( price_put )\n    price = binomial_tree(num_timesteps, PayoffPut(K), dt, S0, r, sigma);\n  else\n    price = binomial_tree(num_timesteps, PayoffCall(K), dt, S0, r, sigma);\n\n  printf(\"Binonmial             : %.8lf\\n\", price);\n  \n  if( price_put )\n    price = black_scholes_merton_put(T, K, S0, r, sigma);\n  else\n    price = black_scholes_merton_call(T, K, S0, r, sigma);\n\n  printf(\"European Price        : %.8lf\\n\", price);\n\n  printf(\"==============\\n\");\n\n  printf(\"elapsed time for each run         : %.3fms\\n\", total_elapsed_time / num_runs);\n  printf(\"==============\\n\");\n\n  \n\n  free(h_samples);\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "aop", "parallel_api": "serial", "code": {"main.cpp": "\n\n \n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <algorithm>\n\n#ifdef WITH_FULL_W_MATRIX\n#define R_W_MATRICES_SMEM_SLOTS 15\n#else\n#define R_W_MATRICES_SMEM_SLOTS 12\n#endif\n\n#define HOST_DEVICE        \n#define HOST_DEVICE_INLINE inline\n\ntypedef struct __attribute__((__aligned__(32)))\n{\n  double x, y, z, w;\n}\ndouble4;\n\ntypedef struct __attribute__((__aligned__(32)))\n{\n  double x, y, z;\n}\ndouble3;\n\nHOST_DEVICE_INLINE double3 operator+(const double3 &u, const double3 &v )\n{\n  return {u.x+v.x, u.y+v.y, u.z+v.z};\n}\n\nHOST_DEVICE_INLINE double4 operator+(const double4 &u, const double4 &v )\n{\n  return {u.x+v.x, u.y+v.y, u.z+v.z, u.w+v.w};\n}\n\nstruct PayoffCall\n{\n  double m_K;\n  HOST_DEVICE_INLINE PayoffCall(double K) : m_K(K) {}\n  HOST_DEVICE_INLINE double operator()(double S) const { return fmax(S - m_K, 0.0); }\n  HOST_DEVICE_INLINE int is_in_the_money(double S) const { return S > m_K; }\n};\n\nstruct PayoffPut\n{\n  double m_K;\n  HOST_DEVICE_INLINE PayoffPut(double K) : m_K(K) {}\n  HOST_DEVICE_INLINE double operator()(double S) const { return fmax(m_K - S, 0.0); }\n  HOST_DEVICE_INLINE int is_in_the_money(double S) const { return S < m_K; }\n};\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid generate_paths_kernel(int num_timesteps, \n                           int num_paths, \n                           Payoff payoff,\n                           double dt, \n                           double S0, \n                           double r, \n                           double sigma, \n                           const double *__restrict samples, \n                           double *__restrict paths)\n{\n  \n\n    for (int path = 0; path < num_paths; path++) {\n\n    \n\n    const double r_min_half_sigma_sq_dt = (r - 0.5*sigma*sigma)*dt;\n    \n\n    const double sigma_sqrt_dt = sigma*sqrt(dt);\n\n    \n\n    double S = S0;\n\n    \n\n    int offset = path;\n    \n    \n\n    for( int timestep = 0 ; timestep < num_timesteps-1 ; ++timestep, offset += num_paths )\n    {\n      S = S * exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n      paths[offset] = S;\n    }\n\n    \n\n    S = S * exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n\n    \n\n    paths[offset] = payoff(S);\n  }\n}\n\nstatic inline void assemble_R(int m, double4 &sums, double *smem_svds)\n{\n  \n\n\n  double x0 = smem_svds[0];\n  double x1 = smem_svds[1];\n  double x2 = smem_svds[2];\n\n  double x0_sq = x0 * x0;\n\n  double sum1 = sums.x - x0;\n  double sum2 = sums.y - x0_sq;\n  double sum3 = sums.z - x0_sq*x0;\n  double sum4 = sums.w - x0_sq*x0_sq;\n\n  double m_as_dbl = (double) m;\n  double sigma = m_as_dbl - 1.0;\n  double mu = sqrt(m_as_dbl);\n  double v0 = -sigma / (1.0 + mu);\n  double v0_sq = v0*v0;\n  double beta = 2.0 * v0_sq / (sigma + v0_sq);\n  \n  double inv_v0 = 1.0 / v0;\n  double one_min_beta = 1.0 - beta;\n  double beta_div_v0  = beta * inv_v0;\n  \n  smem_svds[0] = mu;\n  smem_svds[1] = one_min_beta*x0 - beta_div_v0*sum1;\n  smem_svds[2] = one_min_beta*x0_sq - beta_div_v0*sum2;\n  \n  \n\n  \n  double beta_div_v0_sq = beta_div_v0 * inv_v0;\n  \n  double c1 = beta_div_v0_sq*sum1 + beta_div_v0*x0;\n  double c2 = beta_div_v0_sq*sum2 + beta_div_v0*x0_sq;\n\n  \n\n  \n  double x1_sq = x1*x1;\n\n  sum1 -= x1;\n  sum2 -= x1_sq;\n  sum3 -= x1_sq*x1;\n  sum4 -= x1_sq*x1_sq;\n  \n  x0 = x1-c1;\n  x0_sq = x0*x0;\n  sigma = sum2 - 2.0*c1*sum1 + (m_as_dbl-2.0)*c1*c1;\n  if( abs(sigma) < 1.0e-16 )\n    beta = 0.0;\n  else\n  {\n    mu = sqrt(x0_sq + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  inv_v0 = 1.0 / v0;\n  beta_div_v0 = beta * inv_v0;\n  \n  \n\n  double c3 = (sum3 - c1*sum2 - c2*sum1 + (m_as_dbl-2.0)*c1*c2)*beta_div_v0;\n  double c4 = (x1_sq-c2)*beta_div_v0 + c3*inv_v0;\n  double c5 = c1*c4 - c2;\n  \n  one_min_beta = 1.0 - beta;\n  \n  \n\n  smem_svds[3] = one_min_beta*x0 - beta_div_v0*sigma;\n  smem_svds[4] = one_min_beta*(x1_sq-c2) - c3;\n  \n  \n\n  \n  double x2_sq = x2*x2;\n\n  sum1 -= x2;\n  sum2 -= x2_sq;\n  sum3 -= x2_sq*x2;\n  sum4 -= x2_sq*x2_sq;\n  \n  x0 = x2_sq-c4*x2+c5;\n  sigma = sum4 - 2.0*c4*sum3 + (c4*c4 + 2.0*c5)*sum2 - 2.0*c4*c5*sum1 + (m_as_dbl-3.0)*c5*c5;\n  if( abs(sigma) < 1.0e-12 )\n    beta = 0.0;\n  else\n  {\n    mu = sqrt(x0*x0 + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  \n\n  smem_svds[5] = (1.0-beta)*x0 - (beta/v0)*sigma;\n}\n\nstatic double off_diag_norm(double A01, double A02, double A12)\n{\n  return sqrt(2.0 * (A01*A01 + A02*A02 + A12*A12));\n}\n\nstatic inline void swap(double &x, double &y)\n{\n  double t = x; x = y; y = t;\n}\n\nstatic inline void svd_3x3(int m, double4 &sums, double *smem_svds)\n{\n  \n\n  assemble_R(m, sums, smem_svds);\n\n  \n\n  double R00 = smem_svds[0];\n  double R01 = smem_svds[1];\n  double R02 = smem_svds[2];\n  double R11 = smem_svds[3];\n  double R12 = smem_svds[4];\n  double R22 = smem_svds[5];\n\n  \n\n  \n  double A00 = R00*R00;\n  double A01 = R00*R01;\n  double A02 = R00*R02;\n  double A11 = R01*R01 + R11*R11;\n  double A12 = R01*R02 + R11*R12;\n  double A22 = R02*R02 + R12*R12 + R22*R22;\n  \n  \n\n  \n  double V00 = 1.0, V01 = 0.0, V02 = 0.0;\n  double V10 = 0.0, V11 = 1.0, V12 = 0.0;\n  double V20 = 0.0, V21 = 0.0, V22 = 1.0;\n  \n  \n\n  \n  const int max_iters = 16;\n  const double tolerance = 1.0e-12;\n  \n  \n\n \n  for( int iter = 0 ; off_diag_norm(A01, A02, A12) >= tolerance && iter < max_iters ; ++iter )\n  {\n    double c, s, B00, B01, B02, B10, B11, B12, B20, B21, B22;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A01 != 0.0 )\n    {\n      double tau = (A11 - A00) / (2.0 * A01);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A01;\n    B01 = s*A00 + c*A01;\n    B10 = c*A01 - s*A11;\n    B11 = s*A01 + c*A11;\n    B02 = A02;\n    \n    A00 = c*B00 - s*B10;\n    A01 = c*B01 - s*B11;\n    A11 = s*B01 + c*B11;\n    A02 = c*B02 - s*A12;\n    A12 = s*B02 + c*A12;\n    \n    B00 = c*V00 - s*V01;\n    V01 = s*V00 + c*V01;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V11;\n    V11 = s*V10 + c*V11;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V21;\n    V21 = s*V20 + c*V21;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A02 != 0.0 )\n    {\n      double tau = (A22 - A00) / (2.0 * A02);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A02;\n    B01 = c*A01 - s*A12;\n    B02 = s*A00 + c*A02;\n    B20 = c*A02 - s*A22;\n    B22 = s*A02 + c*A22;\n    \n    A00 = c*B00 - s*B20;\n    A12 = s*A01 + c*A12;\n    A02 = c*B02 - s*B22;\n    A22 = s*B02 + c*B22;\n    A01 = B01;\n    \n    B00 = c*V00 - s*V02;\n    V02 = s*V00 + c*V02;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V12;\n    V12 = s*V10 + c*V12;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V22;\n    V22 = s*V20 + c*V22;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A12 != 0.0 )\n    {\n      double tau = (A22 - A11) / (2.0 * A12);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B02 = s*A01 + c*A02;\n    B11 = c*A11 - s*A12;\n    B12 = s*A11 + c*A12;\n    B21 = c*A12 - s*A22;\n    B22 = s*A12 + c*A22;\n    \n    A01 = c*A01 - s*A02;\n    A02 = B02;\n    A11 = c*B11 - s*B21;\n    A12 = c*B12 - s*B22;\n    A22 = s*B12 + c*B22;\n    \n    B01 = c*V01 - s*V02;\n    V02 = s*V01 + c*V02;\n    V01 = B01;\n    \n    B11 = c*V11 - s*V12;\n    V12 = s*V11 + c*V12;\n    V11 = B11;\n    \n    B21 = c*V21 - s*V22;\n    V22 = s*V21 + c*V22;\n    V21 = B21;\n  }\n\n  \n\n  if( A00 < A11 )\n  {\n    swap(A00, A11);\n    swap(V00, V01);\n    swap(V10, V11);\n    swap(V20, V21);\n  }\n  if( A00 < A22 )\n  {\n    swap(A00, A22);\n    swap(V00, V02);\n    swap(V10, V12);\n    swap(V20, V22);\n  }\n  if( A11 < A22 )\n  {\n    swap(A11, A22);\n    swap(V01, V02);\n    swap(V11, V12);\n    swap(V21, V22);\n  }\n\n  \n\n  \n  \n\n  \n  double inv_S0 = abs(A00) < 1.0e-12 ? 0.0 : 1.0 / A00;\n  double inv_S1 = abs(A11) < 1.0e-12 ? 0.0 : 1.0 / A11;\n  double inv_S2 = abs(A22) < 1.0e-12 ? 0.0 : 1.0 / A22;\n\n  \n\n  \n  double U00 = V00 * inv_S0; \n  double U01 = V01 * inv_S1; \n  double U02 = V02 * inv_S2;\n  double U10 = V10 * inv_S0; \n  double U11 = V11 * inv_S1; \n  double U12 = V12 * inv_S2;\n  double U20 = V20 * inv_S0; \n  double U21 = V21 * inv_S1; \n  double U22 = V22 * inv_S2;\n  \n  \n\n  \n#ifdef WITH_FULL_W_MATRIX\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B10 = U10*V00 + U11*V01 + U12*V02;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B20 = U20*V00 + U21*V01 + U22*V02;\n  double B21 = U20*V10 + U21*V11 + U22*V12;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] = B10*R00 + B11*R01 + B12*R02;\n  smem_svds[10] =           B11*R11 + B12*R12;\n  smem_svds[11] =                     B12*R22;\n  smem_svds[12] = B20*R00 + B21*R01 + B22*R02;\n  smem_svds[13] =           B21*R11 + B22*R12;\n  smem_svds[14] =                     B22*R22;\n#else\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] =           B11*R11 + B12*R12;\n  smem_svds[10] =                     B12*R22;\n  smem_svds[11] =                     B22*R22;\n#endif\n}\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid prepare_svd_kernel(const int numTeams,\n                        int num_paths, \n                        int min_in_the_money, \n                        Payoff payoff, \n                        const double *__restrict paths, \n                                 int *__restrict all_out_of_the_money, \n                              double *__restrict svds)\n{\n    {\n    \n\n    int scan_input[NUM_THREADS_PER_BLOCK];\n    int scan_output[1+NUM_THREADS_PER_BLOCK];\n\n    \n\n    double4 lsums;\n    int lsum;\n\n    \n\n    double smem_svds[R_W_MATRICES_SMEM_SLOTS];\n        {\n      int lid = omp_get_thread_num();\n      int bid = omp_get_team_num();\n\n      \n\n      const int timestep = bid;\n      \n\n      const int offset = timestep * num_paths;\n\n      \n\n      int m = 0;\n      double4 sums = { 0.0, 0.0, 0.0, 0.0 };\n\n      \n\n      if( lid < R_W_MATRICES_SMEM_SLOTS )\n        smem_svds[lid] = 0.0;\n      \n      \n\n      int found_paths = 0;\n\n      \n\n      for( int path = lid ; path < num_paths ; path += NUM_THREADS_PER_BLOCK )\n      {\n        \n\n        double S = paths[offset + path];\n\n        \n\n        const int in_the_money = payoff.is_in_the_money(S);\n\n        \n\n        scan_input[lid] = in_the_money;\n                if (lid == 0) {\n          scan_output[0] = 0;\n          for (int i = 1; i <= NUM_THREADS_PER_BLOCK; i++) \n            scan_output[i] = scan_output[i-1]+scan_input[i-1];\n        }\n                const int partial_sum = scan_output[lid];\n        const int total_sum = scan_output[NUM_THREADS_PER_BLOCK];\n\n        if( found_paths < 3 )\n        {\n          if( in_the_money && found_paths + partial_sum < 3 )\n            smem_svds[found_paths + partial_sum] = S;\n                    found_paths += total_sum;\n        }\n\n        \n\n        if (lid == 0) lsum = 0;\n        \n                lsum |= in_the_money;\n\n                if (lsum == 0) continue;\n        \n        \n\n        m += in_the_money;\n\n        \n\n        double x = 0.0, x_sq = 0.0;\n        if( in_the_money )\n        {\n          x = S;\n          x_sq = S*S;\n        }\n\n        \n\n        sums.x += x;\n        sums.y += x_sq;\n        sums.z += x_sq*x;\n        sums.w += x_sq*x_sq;\n      }\n\n      \n\n      if (lid == 0) lsum = 0;\n      \n            lsum += m;\n\n      \n      int not_enough_paths = 0;\n      \n\n      if (lid == 0 && lsum < min_in_the_money)\n        not_enough_paths = 1;\n      \n      \n\n      if( not_enough_paths )\n      {\n        if( lid == 0 )\n          all_out_of_the_money[bid] = 1;\n      } \n      else\n      {\n        \n\n\n        if (lid == 0) lsums = {0.0, 0.0, 0.0, 0.0};\n        \n                lsums.x += sums.x;\n\n                lsums.y += sums.y;\n\n                lsums.z += sums.z;\n        \n                \n        \n\n        if( lid == 0 )\n          svd_3x3(lsum, lsums, smem_svds);\n\n        \n        \n\n        if( lid < R_W_MATRICES_SMEM_SLOTS )\n          svds[16*bid + lid] = smem_svds[lid];\n      }\n    }\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid compute_beta_kernel(int num_paths,\n                         Payoff payoff,\n                         const double *__restrict svd,\n                         const double *__restrict paths,\n                         const double *__restrict cashflows,\n                         const int *__restrict all_out_of_the_money,\n                         double *__restrict beta)\n{\n  \n\n  if( *all_out_of_the_money == 0) {\n\n    \n\n    \n\n        for( int path = 0; path < num_paths ; path++)\n    {\n      \n\n      const double R00 = svd[ 0];\n      const double R01 = svd[ 1];\n      const double R02 = svd[ 2];\n      const double R11 = svd[ 3];\n      const double R12 = svd[ 4];\n      const double R22 = svd[ 5];\n\n    \n\n    #ifdef WITH_FULL_W_MATRIX\n      const double W00 = svd[ 6];\n      const double W01 = svd[ 7];\n      const double W02 = svd[ 8];\n      const double W10 = svd[ 9];\n      const double W11 = svd[10];\n      const double W12 = svd[11];\n      const double W20 = svd[12];\n      const double W21 = svd[13];\n      const double W22 = svd[14];\n    #else\n      const double W00 = svd[ 6];\n      const double W01 = svd[ 7];\n      const double W02 = svd[ 8];\n      const double W11 = svd[ 9];\n      const double W12 = svd[10];\n      const double W22 = svd[11];\n    #endif\n\n      \n\n      const double inv_R00 = R00 != 0.0 ? 1.0 / R00 : 0.0;\n      const double inv_R11 = R11 != 0.0 ? 1.0 / R11 : 0.0;\n      const double inv_R22 = R22 != 0.0 ? 1.0 / R22 : 0.0;\n\n      \n\n      const double inv_R01 = inv_R00*inv_R11*R01;\n      const double inv_R02 = inv_R00*inv_R22*R02;\n      const double inv_R12 =         inv_R22*R12;\n      \n      \n\n    #ifdef WITH_FULL_W_MATRIX\n      const double inv_W00 = W00*inv_R00;\n      const double inv_W10 = W10*inv_R00;\n      const double inv_W20 = W20*inv_R00;\n    #else\n      const double inv_W00 = W00*inv_R00;\n    #endif\n      \n\n      double S = paths[path];\n\n      \n\n      const int in_the_money = payoff.is_in_the_money(S);\n\n      \n\n      double Q1i = inv_R11*S - inv_R01;\n      double Q2i = inv_R22*S*S - inv_R02 - Q1i*inv_R12;\n\n      \n\n  #ifdef WITH_FULL_W_MATRIX\n      const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n      const double WI1 = inv_W10 + W11 * Q1i + W12 * Q2i;\n      const double WI2 = inv_W20 + W21 * Q1i + W22 * Q2i;\n  #else\n      const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n      const double WI1 =           W11 * Q1i + W12 * Q2i;\n      const double WI2 =                       W22 * Q2i;\n  #endif\n\n      \n\n      double cashflow = in_the_money ? cashflows[path] : 0.0;\n    \n      \n\n      beta[0] += WI0*cashflow;\n      beta[1] += WI1*cashflow;\n      beta[2] += WI2*cashflow;\n    }\n  }\n}\n\n\n\n\n\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid update_cashflow_kernel(int numTeams, \n                            int num_paths,\n                            Payoff payoff_object,\n                            double exp_min_r_dt,\n                            const double *__restrict beta,\n                            const double *__restrict paths,\n                            const int *__restrict all_out_of_the_money,\n                            double *__restrict cashflows)\n{\n  \n\n    for (int path = 0; path < num_paths ; path ++) \n  {\n    \n\n    const int skip_computations = *all_out_of_the_money;\n\n    \n\n    const double beta0 = beta[0];\n    const double beta1 = beta[1];\n    const double beta2 = beta[2];\n\n    \n\n    const double old_cashflow = exp_min_r_dt*cashflows[path];\n    if( skip_computations )\n    {\n      cashflows[path] = old_cashflow;\n      continue;\n    }\n  \n    \n\n    double S  = paths[path];\n    double S2 = S*S;\n\n    \n\n    double payoff = payoff_object(S);\n\n    \n\n    double estimated_payoff = beta0 + beta1*S + beta2*S2;\n\n    \n\n    estimated_payoff *= exp_min_r_dt;\n\n    \n\n    if( payoff <= 1.0e-8 || payoff <= estimated_payoff )\n      payoff = old_cashflow;\n    \n    \n\n    cashflows[path] = payoff;\n  }\n}\n\ntemplate< int NUM_THREADS_PER_BLOCK >\nvoid compute_sums_kernel(int num_paths, \n                         const double *__restrict cashflows,\n                         double exp_min_r_dt, \n                         double &price)\n{\n  double sum = 0.0;\n  \n\n    for (int path = 0; path < num_paths; path++)\n  {\n    sum += cashflows[path];\n  }\n  price = exp_min_r_dt * sum / (double) num_paths;\n}\n\n\ntemplate< typename Payoff >\nstatic inline \nvoid do_run(double *h_samples,\n            int num_timesteps, \n            int num_paths, \n            const Payoff &payoff, \n            double dt,\n            double S0,\n            double r,\n            double sigma,\n            double *d_paths,\n            double *d_cashflows,\n            double *d_svds,\n            int    *d_all_out_of_the_money,\n            double *d_temp_storage,\n            double &h_price)\n{\n  \n  \n\n  const int NUM_THREADS_PER_BLOCK0 = 256;\n  generate_paths_kernel<NUM_THREADS_PER_BLOCK0>(\n    num_timesteps,\n    num_paths,\n    payoff, \n    dt, \n    S0, \n    r, \n    sigma, \n    h_samples,\n    d_paths);\n\n  \n\n    for (int i = 0; i < num_timesteps; i++)\n    d_all_out_of_the_money[i] = 0;\n\n  \n\n  const int NUM_THREADS_PER_BLOCK1 = 256;\n  prepare_svd_kernel<NUM_THREADS_PER_BLOCK1>(\n    num_timesteps-1,  \n\n    num_paths,\n    4, \n\n    payoff, \n    d_paths, \n    d_all_out_of_the_money,\n    d_svds);\n\n#ifdef DEBUG\n      for (int i = 0; i < num_timesteps*16; i++)\n     printf(\"svd%d: %lf\\n\", i, d_svds[i]);\n#endif\n\n  \n\n  const double exp_min_r_dt = std::exp(-r*dt);\n\n  \n\n  const int num_threads_per_wave_full_occupancy = 256 * 112;\n\n  \n\n  const int NUM_THREADS_PER_BLOCK2 = 128;\n\n  \n\n  const int grid_dim = (num_paths + NUM_THREADS_PER_BLOCK2-1) / NUM_THREADS_PER_BLOCK2;\n  double num_waves = grid_dim*NUM_THREADS_PER_BLOCK2 / (double) num_threads_per_wave_full_occupancy;\n\n  int update_cashflow_grid = grid_dim;\n  if( num_waves < 10 && num_waves - (int) num_waves < 0.6 )\n    update_cashflow_grid = std::max(1, (int) num_waves) * num_threads_per_wave_full_occupancy / NUM_THREADS_PER_BLOCK2;\n\n  \n\n  for( int timestep = num_timesteps-2 ; timestep >= 0 ; --timestep )\n  {\n    \n\n    compute_beta_kernel<NUM_THREADS_PER_BLOCK2>(\n      num_paths,\n      payoff,\n      d_svds + 16*timestep,\n      d_paths + timestep*num_paths,\n      d_cashflows,\n      d_all_out_of_the_money + timestep,\n      d_temp_storage);\n\n#ifdef DEBUG\n      printf(\"timestep: %d beta: %lf %lf %lf\\n\", timestep, d_temp_storage[0], d_temp_storage[1], d_temp_storage[2]);\n#endif\n\n    update_cashflow_kernel<NUM_THREADS_PER_BLOCK2>(\n      update_cashflow_grid,\n      num_paths,\n      payoff,\n      exp_min_r_dt,\n      d_temp_storage,\n      d_paths + timestep*num_paths,\n      d_all_out_of_the_money + timestep,\n      d_cashflows);\n  }\n\n  \n\n  const int NUM_THREADS_PER_BLOCK4 = 128;\n  compute_sums_kernel<NUM_THREADS_PER_BLOCK4>(\n    num_paths,\n    d_cashflows,\n    exp_min_r_dt,\n    h_price);\n}\n\ntemplate< typename Payoff >\nstatic double binomial_tree(int num_timesteps, const Payoff &payoff, double dt, double S0, double r, double sigma)\n{\n  double *tree = new double[num_timesteps+1];\n\n  double u = std::exp( sigma * std::sqrt(dt));\n  double d = std::exp(-sigma * std::sqrt(dt));\n  double a = std::exp( r     * dt);\n  \n  double p = (a - d) / (u - d);\n  \n  double k = std::pow(d, num_timesteps);\n  for( int t = 0 ; t <= num_timesteps ; ++t )\n  {\n    tree[t] = payoff(S0*k);\n    k *= u*u;\n  }\n\n  for( int t = num_timesteps-1 ; t >= 0 ; --t )\n  {\n    k = std::pow(d, t);\n    for( int i = 0 ; i <= t ; ++i )\n    {\n      double expected = std::exp(-r*dt) * (p*tree[i+1] + (1.0 - p)*tree[i]);\n      double earlyex = payoff(S0*k);\n      tree[i] = std::max(earlyex, expected);\n      k *= u*u;\n    }\n  }\n\n  double f = tree[0];\n  delete[] tree;\n  return f;\n}\n\n\n\ninline double my_normcdf (double x) {\n  return (1.0 + erf(x / sqrt(2.0))) / 2.0;\n}\n\nstatic double black_scholes_merton_put(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return K*std::exp(-r*T)*my_normcdf(-d2) - S0*my_normcdf(-d1);\n}\n\nstatic double black_scholes_merton_call(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return S0*my_normcdf(d1) - K*std::exp(-r*T)*my_normcdf(d2);\n}\n\nint main(int argc, char **argv)\n{\n  const int MAX_GRID_SIZE = 2048;\n  \n  \n\n  int num_timesteps = 100;\n  int num_paths     = 32;\n  int num_runs      = 1;\n\n  \n\n  double T     = 1.00;\n  double K     = 4.00;\n  double S0    = 3.60;\n  double r     = 0.06;\n  double sigma = 0.20;\n\n  \n\n  bool price_put = true;\n  \n  \n\n  for( int i = 1 ; i < argc ; ++i )\n  {\n    if( !strcmp(argv[i], \"-timesteps\") )\n      num_timesteps = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-paths\") )\n      num_paths = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-runs\") )\n      num_runs = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-T\") )\n      T = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-S0\") )\n      S0 = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-K\") )\n      K = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-r\") )\n      r = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-sigma\") )\n      sigma = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-call\") )\n      price_put = false;\n    else\n    {\n      fprintf(stderr, \"Unknown option %s. Aborting!!!\\n\", argv[i]);\n      exit(1);\n    }\n  }\n\n  \n\n  printf(\"==============\\n\");\n  printf(\"Num Timesteps         : %d\\n\",  num_timesteps);\n  printf(\"Num Paths             : %dK\\n\", num_paths);\n  printf(\"Num Runs              : %d\\n\",  num_runs);\n  printf(\"T                     : %lf\\n\", T);\n  printf(\"S0                    : %lf\\n\", S0);\n  printf(\"K                     : %lf\\n\", K);\n  printf(\"r                     : %lf\\n\", r);\n  printf(\"sigma                 : %lf\\n\", sigma);\n  printf(\"Option Type           : American %s\\n\",  price_put ? \"Put\" : \"Call\");\n\n  \n\n  num_paths *= 1024;\n\n  \n\n  double dt = T / num_timesteps;\n\n  \n\n  std::default_random_engine rng;\n  std::normal_distribution<double> norm_dist(0.0, 1.0);\n\n  \n\n  double *h_samples = (double*) malloc (num_timesteps*num_paths*sizeof(double));\n\n  \n\n  double *h_paths = (double*) malloc (num_timesteps*num_paths*sizeof(double));\n\n  \n\n  double *h_svds = (double*) malloc (16*num_timesteps*sizeof(double));\n\n  \n\n  int *h_all_out_of_the_money = (int*) malloc (num_timesteps*sizeof(int));\n\n  \n\n  int max_temp_storage = 4*MAX_GRID_SIZE;\n  double *h_temp_storage = (double*) malloc (max_temp_storage*sizeof(double));\n\n  \n\n  \n\n\n{\n  \n\n  double h_price;\n\n  \n\n  float total_elapsed_time = 0;\n\n  for( int run = 0; run < num_runs; ++run )\n  {\n    for (int i = 0; i < num_timesteps*num_paths; ++i)\n      h_samples[i] = norm_dist(rng);\n      \n    auto start = std::chrono::high_resolution_clock::now();\n    if( price_put )\n      do_run(h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffPut(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             h_paths,\n             h_paths + (num_timesteps-1)*num_paths, \n\n             h_svds,\n             h_all_out_of_the_money,\n             h_temp_storage,\n             h_price);\n    else\n      do_run(h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffCall(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             h_paths,\n             h_paths + (num_timesteps-1)*num_paths, \n\n             h_svds,\n             h_all_out_of_the_money,\n             h_temp_storage,\n             h_price);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    const float elapsed_time =\n       std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n    total_elapsed_time += elapsed_time;\n  }\n\n  printf(\"==============\\n\");\n  printf(\"GPU Longstaff-Schwartz: %.8lf\\n\", h_price);\n  \n  double price = 0.0;\n\n  if( price_put )\n    price = binomial_tree(num_timesteps, PayoffPut(K), dt, S0, r, sigma);\n  else\n    price = binomial_tree(num_timesteps, PayoffCall(K), dt, S0, r, sigma);\n\n  printf(\"Binonmial             : %.8lf\\n\", price);\n  \n  if( price_put )\n    price = black_scholes_merton_put(T, K, S0, r, sigma);\n  else\n    price = black_scholes_merton_call(T, K, S0, r, sigma);\n\n  printf(\"European Price        : %.8lf\\n\", price);\n\n  printf(\"==============\\n\");\n\n  printf(\"elapsed time for each run         : %.3fms\\n\", total_elapsed_time / num_runs);\n  printf(\"==============\\n\");\n\n  \n\n  free(h_samples);\n  }\n\n  return 0;\n}"}}
{"kernel_name": "aop", "parallel_api": "sycl", "code": {"main.cpp": "\n\n \n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cmath>\n#include <random>\n#include <chrono>\n#include <algorithm>\n#include <sycl/sycl.hpp>\n\n#ifdef WITH_FULL_W_MATRIX\n#define R_W_MATRICES_SMEM_SLOTS 15\n#else\n#define R_W_MATRICES_SMEM_SLOTS 12\n#endif\n\n#define syncthreads() item.barrier(sycl::access::fence_space::local_space)\n\n\nstruct PayoffCall\n{\n  double m_K;\n  inline PayoffCall(double K) : m_K(K) {}\n  inline double operator()(double S) const { return sycl::fmax(S - m_K, 0.0); }\n  inline int is_in_the_money(double S) const { return S > m_K; }\n};\n\nstruct PayoffPut\n{\n  double m_K;\n  inline PayoffPut(double K) : m_K(K) {}\n  inline double operator()(double S) const { return sycl::fmax(m_K - S, 0.0); }\n  inline int is_in_the_money(double S) const { return S < m_K; }\n};\n\n\ntemplate< typename Payoff >\nclass generate_paths;\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid generate_paths_kernel(sycl::nd_item<1> &item,\n                           int num_timesteps, \n                           int num_paths, \n                           Payoff payoff,\n                           double dt, \n                           double S0, \n                           double r, \n                           double sigma, \n                           const double *__restrict samples, \n                           double *__restrict paths)\n{\n  \n\n  int path = item.get_global_id(0);\n\n  \n\n  if( path >= num_paths ) return;\n  \n  \n\n  const double r_min_half_sigma_sq_dt = (r - 0.5*sigma*sigma)*dt;\n  \n\n  const double sigma_sqrt_dt = sigma * sycl::sqrt(dt);\n\n  \n\n  double S = S0;\n\n  \n\n  int offset = path;\n  \n  \n\n  for( int timestep = 0 ; timestep < num_timesteps-1 ; ++timestep, offset += num_paths )\n  {\n    S = S * sycl::exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n    paths[offset] = S;\n  }\n\n  \n\n  S = S * sycl::exp(r_min_half_sigma_sq_dt + sigma_sqrt_dt*samples[offset]);\n\n  \n\n  paths[offset] = payoff(S);\n}\n\nstatic inline void assemble_R(int m, sycl::double4 &sums, double *smem_svds)\n{\n  \n\n\n  double x0 = smem_svds[0];\n  double x1 = smem_svds[1];\n  double x2 = smem_svds[2];\n\n  double x0_sq = x0 * x0;\n\n  double sum1 = sums.x() - x0;\n  double sum2 = sums.y() - x0_sq;\n  double sum3 = sums.z() - x0_sq*x0;\n  double sum4 = sums.w() - x0_sq*x0_sq;\n\n  double m_as_dbl = (double) m;\n  double sigma = m_as_dbl - 1.0;\n  double mu = sycl::sqrt(m_as_dbl);\n  double v0 = -sigma / (1.0 + mu);\n  double v0_sq = v0*v0;\n  double beta = 2.0 * v0_sq / (sigma + v0_sq);\n  \n  double inv_v0 = 1.0 / v0;\n  double one_min_beta = 1.0 - beta;\n  double beta_div_v0  = beta * inv_v0;\n  \n  smem_svds[0] = mu;\n  smem_svds[1] = one_min_beta*x0 - beta_div_v0*sum1;\n  smem_svds[2] = one_min_beta*x0_sq - beta_div_v0*sum2;\n  \n  \n\n  \n  double beta_div_v0_sq = beta_div_v0 * inv_v0;\n  \n  double c1 = beta_div_v0_sq*sum1 + beta_div_v0*x0;\n  double c2 = beta_div_v0_sq*sum2 + beta_div_v0*x0_sq;\n\n  \n\n  \n  double x1_sq = x1*x1;\n\n  sum1 -= x1;\n  sum2 -= x1_sq;\n  sum3 -= x1_sq*x1;\n  sum4 -= x1_sq*x1_sq;\n  \n  x0 = x1-c1;\n  x0_sq = x0*x0;\n  sigma = sum2 - 2.0*c1*sum1 + (m_as_dbl-2.0)*c1*c1;\n  if( sycl::abs(sigma) < 1.0e-16 )\n    beta = 0.0;\n  else\n  {\n    mu = sycl::sqrt(x0_sq + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  inv_v0 = 1.0 / v0;\n  beta_div_v0 = beta * inv_v0;\n  \n  \n\n  double c3 = (sum3 - c1*sum2 - c2*sum1 + (m_as_dbl-2.0)*c1*c2)*beta_div_v0;\n  double c4 = (x1_sq-c2)*beta_div_v0 + c3*inv_v0;\n  double c5 = c1*c4 - c2;\n  \n  one_min_beta = 1.0 - beta;\n  \n  \n\n  smem_svds[3] = one_min_beta*x0 - beta_div_v0*sigma;\n  smem_svds[4] = one_min_beta*(x1_sq-c2) - c3;\n  \n  \n\n  \n  double x2_sq = x2*x2;\n\n  sum1 -= x2;\n  sum2 -= x2_sq;\n  sum3 -= x2_sq*x2;\n  sum4 -= x2_sq*x2_sq;\n  \n  x0 = x2_sq-c4*x2+c5;\n  sigma = sum4 - 2.0*c4*sum3 + (c4*c4 + 2.0*c5)*sum2 - 2.0*c4*c5*sum1 + (m_as_dbl-3.0)*c5*c5;\n  if( sycl::abs(sigma) < 1.0e-12 )\n    beta = 0.0;\n  else\n  {\n    mu = sycl::sqrt(x0*x0 + sigma);\n    if( x0 <= 0.0 )\n      v0 = x0 - mu;\n    else\n      v0 = -sigma / (x0 + mu);\n    v0_sq = v0*v0;\n    beta = 2.0*v0_sq / (sigma + v0_sq);\n  }\n  \n  \n\n  smem_svds[5] = (1.0-beta)*x0 - (beta/v0)*sigma;\n}\n\nstatic double off_diag_norm(double A01, double A02, double A12)\n{\n  return sycl::sqrt(2.0 * (A01*A01 + A02*A02 + A12*A12));\n}\n\nstatic inline void swap(double &x, double &y)\n{\n  double t = x; x = y; y = t;\n}\n\nstatic inline void svd_3x3(int m, sycl::double4 &sums, double *smem_svds)\n{\n  \n\n  assemble_R(m, sums, smem_svds);\n\n  \n\n  double R00 = smem_svds[0];\n  double R01 = smem_svds[1];\n  double R02 = smem_svds[2];\n  double R11 = smem_svds[3];\n  double R12 = smem_svds[4];\n  double R22 = smem_svds[5];\n\n  \n\n  \n  double A00 = R00*R00;\n  double A01 = R00*R01;\n  double A02 = R00*R02;\n  double A11 = R01*R01 + R11*R11;\n  double A12 = R01*R02 + R11*R12;\n  double A22 = R02*R02 + R12*R12 + R22*R22;\n  \n  \n\n  \n  double V00 = 1.0, V01 = 0.0, V02 = 0.0;\n  double V10 = 0.0, V11 = 1.0, V12 = 0.0;\n  double V20 = 0.0, V21 = 0.0, V22 = 1.0;\n  \n  \n\n  \n  const int max_iters = 16;\n  const double tolerance = 1.0e-12;\n  \n  \n\n \n  for( int iter = 0 ; off_diag_norm(A01, A02, A12) >= tolerance && iter < max_iters ; ++iter )\n  {\n    double c, s, B00, B01, B02, B10, B11, B12, B20, B21, B22;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A01 != 0.0 )\n    {\n      double tau = (A11 - A00) / (2.0 * A01);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sycl::sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sycl::sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A01;\n    B01 = s*A00 + c*A01;\n    B10 = c*A01 - s*A11;\n    B11 = s*A01 + c*A11;\n    B02 = A02;\n    \n    A00 = c*B00 - s*B10;\n    A01 = c*B01 - s*B11;\n    A11 = s*B01 + c*B11;\n    A02 = c*B02 - s*A12;\n    A12 = s*B02 + c*A12;\n    \n    B00 = c*V00 - s*V01;\n    V01 = s*V00 + c*V01;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V11;\n    V11 = s*V10 + c*V11;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V21;\n    V21 = s*V20 + c*V21;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A02 != 0.0 )\n    {\n      double tau = (A22 - A00) / (2.0 * A02);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sycl::sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sycl::sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B00 = c*A00 - s*A02;\n    B01 = c*A01 - s*A12;\n    B02 = s*A00 + c*A02;\n    B20 = c*A02 - s*A22;\n    B22 = s*A02 + c*A22;\n    \n    A00 = c*B00 - s*B20;\n    A12 = s*A01 + c*A12;\n    A02 = c*B02 - s*B22;\n    A22 = s*B02 + c*B22;\n    A01 = B01;\n    \n    B00 = c*V00 - s*V02;\n    V02 = s*V00 + c*V02;\n    V00 = B00;\n    \n    B10 = c*V10 - s*V12;\n    V12 = s*V10 + c*V12;\n    V10 = B10;\n    \n    B20 = c*V20 - s*V22;\n    V22 = s*V20 + c*V22;\n    V20 = B20;\n    \n    \n\n    \n    c = 1.0, s = 0.0;\n    if( A12 != 0.0 )\n    {\n      double tau = (A22 - A11) / (2.0 * A12);\n      double sgn = tau < 0.0 ? -1.0 : 1.0;\n      double t   = sgn / (sgn*tau + sycl::sqrt(1.0 + tau*tau));\n      \n      c = 1.0 / sycl::sqrt(1.0 + t*t);\n      s = t*c;\n    }\n    \n    \n\n    \n    B02 = s*A01 + c*A02;\n    B11 = c*A11 - s*A12;\n    B12 = s*A11 + c*A12;\n    B21 = c*A12 - s*A22;\n    B22 = s*A12 + c*A22;\n    \n    A01 = c*A01 - s*A02;\n    A02 = B02;\n    A11 = c*B11 - s*B21;\n    A12 = c*B12 - s*B22;\n    A22 = s*B12 + c*B22;\n    \n    B01 = c*V01 - s*V02;\n    V02 = s*V01 + c*V02;\n    V01 = B01;\n    \n    B11 = c*V11 - s*V12;\n    V12 = s*V11 + c*V12;\n    V11 = B11;\n    \n    B21 = c*V21 - s*V22;\n    V22 = s*V21 + c*V22;\n    V21 = B21;\n  }\n\n  \n\n  if( A00 < A11 )\n  {\n    swap(A00, A11);\n    swap(V00, V01);\n    swap(V10, V11);\n    swap(V20, V21);\n  }\n  if( A00 < A22 )\n  {\n    swap(A00, A22);\n    swap(V00, V02);\n    swap(V10, V12);\n    swap(V20, V22);\n  }\n  if( A11 < A22 )\n  {\n    swap(A11, A22);\n    swap(V01, V02);\n    swap(V11, V12);\n    swap(V21, V22);\n  }\n\n  \n\n  \n  \n\n  \n  double inv_S0 = sycl::abs(A00) < 1.0e-12 ? 0.0 : 1.0 / A00;\n  double inv_S1 = sycl::abs(A11) < 1.0e-12 ? 0.0 : 1.0 / A11;\n  double inv_S2 = sycl::abs(A22) < 1.0e-12 ? 0.0 : 1.0 / A22;\n\n  \n\n  \n  double U00 = V00 * inv_S0; \n  double U01 = V01 * inv_S1; \n  double U02 = V02 * inv_S2;\n  double U10 = V10 * inv_S0; \n  double U11 = V11 * inv_S1; \n  double U12 = V12 * inv_S2;\n  double U20 = V20 * inv_S0; \n  double U21 = V21 * inv_S1; \n  double U22 = V22 * inv_S2;\n  \n  \n\n  \n#ifdef WITH_FULL_W_MATRIX\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B10 = U10*V00 + U11*V01 + U12*V02;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B20 = U20*V00 + U21*V01 + U22*V02;\n  double B21 = U20*V10 + U21*V11 + U22*V12;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] = B10*R00 + B11*R01 + B12*R02;\n  smem_svds[10] =           B11*R11 + B12*R12;\n  smem_svds[11] =                     B12*R22;\n  smem_svds[12] = B20*R00 + B21*R01 + B22*R02;\n  smem_svds[13] =           B21*R11 + B22*R12;\n  smem_svds[14] =                     B22*R22;\n#else\n  double B00 = U00*V00 + U01*V01 + U02*V02;\n  double B01 = U00*V10 + U01*V11 + U02*V12;\n  double B02 = U00*V20 + U01*V21 + U02*V22;\n  double B11 = U10*V10 + U11*V11 + U12*V12;\n  double B12 = U10*V20 + U11*V21 + U12*V22;\n  double B22 = U20*V20 + U21*V21 + U22*V22;\n  \n  smem_svds[ 6] = B00*R00 + B01*R01 + B02*R02;\n  smem_svds[ 7] =           B01*R11 + B02*R12;\n  smem_svds[ 8] =                     B02*R22;\n  smem_svds[ 9] =           B11*R11 + B12*R12;\n  smem_svds[10] =                     B12*R22;\n  smem_svds[11] =                     B22*R22;\n#endif\n}\n\ntemplate< typename Payoff >\nclass prepare_svd;\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid prepare_svd_kernel(sycl::nd_item<1> &item,\n                        int num_paths, \n                        int min_in_the_money, \n                        Payoff payoff, \n                        int *__restrict scan_input,\n                        int *__restrict scan_output,\n                        sycl::double4& lsums,\n                        int& lsum,\n                        double *__restrict smem_svds,\n                        const double *__restrict paths, \n                                 int *__restrict all_out_of_the_money, \n                              double *__restrict svds)\n{\n  \n\n  int bid = item.get_group(0);\n  int lid = item.get_local_id(0);\n\n  \n\n  const int timestep = bid;\n\n  \n\n  const int offset = timestep * num_paths;\n\n  \n\n  int m = 0; \n  sycl::double4 sums = sycl::double4(0.0);\n\n  \n\n  if( lid < R_W_MATRICES_SMEM_SLOTS )\n    smem_svds[lid] = 0.0;\n  syncthreads();\n\n  \n\n  int found_paths = 0;\n\n  \n\n  for( int path = lid ; path < num_paths ; path += NUM_THREADS_PER_BLOCK )\n  {\n    \n\n    double S = paths[offset + path];\n\n    \n\n    \n\n    int in_the_money = payoff.is_in_the_money(S);\n\n    \n\n    scan_input[lid] = in_the_money;\n    syncthreads();\n    if (lid == 0) {\n      scan_output[0] = 0;\n      for (int i = 1; i <= NUM_THREADS_PER_BLOCK; i++) \n        scan_output[i] = scan_output[i-1]+scan_input[i-1];\n    }\n    syncthreads();\n    const int partial_sum = scan_output[lid];\n    const int total_sum = scan_output[NUM_THREADS_PER_BLOCK];\n\n    if( found_paths < 3 )\n    {\n      if( in_the_money && found_paths + partial_sum < 3 )\n        smem_svds[found_paths + partial_sum] = S;\n      syncthreads();\n      found_paths += total_sum;\n    }\n\n    \n\n    if (lid == 0) lsum = 0;\n    syncthreads();\n    \n\n    auto any_obj = sycl::atomic_ref<int, \n                   sycl::memory_order::relaxed,\n                   sycl::memory_scope::work_group,\n                   sycl::access::address_space::local_space> (lsum);\n\n    any_obj.fetch_or(in_the_money);\n    syncthreads();\n    if (lsum == 0) continue;\n    \n    \n\n    m += in_the_money;\n\n    \n\n    double x = 0.0, x_sq = 0.0;\n    if( in_the_money )\n    {\n      x = S;\n      x_sq = S*S;\n    }\n\n    \n\n    sums.x() += x;\n    sums.y() += x_sq;\n    sums.z() += x_sq*x;\n    sums.w() += x_sq*x_sq;\n  }\n\n  \n\n  if (lid == 0) lsum = 0;\n  syncthreads();\n\n  auto sum_obj = sycl::atomic_ref<int, \n                 sycl::memory_order::relaxed,\n                 sycl::memory_scope::work_group,\n                 sycl::access::address_space::local_space> (lsum);\n\n  sum_obj.fetch_add(m);\n\n  syncthreads();\n\n  int not_enough_paths = 0;\n  \n\n  if (lid == 0 && lsum < min_in_the_money)\n    not_enough_paths = 1;\n  \n  \n\n  if( not_enough_paths )\n  {\n    if( lid == 0 )\n      all_out_of_the_money[bid] = 1;\n  } \n  else\n  {\n    \n\n\n    if (lid == 0)\n      lsums = sycl::double4(0.0);\n    syncthreads();\n\n    auto sumx_obj = sycl::atomic_ref<double, \n                    sycl::memory_order::relaxed,\n                    sycl::memory_scope::work_group,\n                    sycl::access::address_space::local_space> (lsums.x());\n    sumx_obj.fetch_add(sums.x());\n    \n    auto sumy_obj = sycl::atomic_ref<double, \n                    sycl::memory_order::relaxed,\n                    sycl::memory_scope::work_group,\n                    sycl::access::address_space::local_space> (lsums.y());\n    sumy_obj.fetch_add(sums.y());\n\n    auto sumz_obj = sycl::atomic_ref<double, \n                    sycl::memory_order::relaxed,\n                    sycl::memory_scope::work_group,\n                    sycl::access::address_space::local_space> (lsums.z());\n    sumz_obj.fetch_add(sums.z());\n\n    auto sumw_obj = sycl::atomic_ref<double, \n                    sycl::memory_order::relaxed,\n                    sycl::memory_scope::work_group,\n                    sycl::access::address_space::local_space> (lsums.w());\n    sumw_obj.fetch_add(sums.w());\n\n    syncthreads();\n    \n    \n\n    if( lid == 0 )\n      svd_3x3(lsum, lsums, smem_svds);\n\n    syncthreads();\n\n    \n\n    if( lid < R_W_MATRICES_SMEM_SLOTS )\n      svds[16*bid + lid] = smem_svds[lid];\n  }\n}\n\ntemplate< typename Payoff >\nclass partial_beta;\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid compute_partial_beta_kernel(sycl::nd_item<1> &item,\n                                 int num_paths,\n                                 Payoff payoff,\n                                       sycl::double3 &lsums,\n                                       double *__restrict shared_svd,\n                                 const double *__restrict svd,\n                                 const double *__restrict paths,\n                                 const double *__restrict cashflows,\n                                 const int *__restrict all_out_of_the_money,\n                                 double *__restrict partial_sums)\n{\n    \n  \n\n  if( *all_out_of_the_money ) return;\n\n  \n\n  const int NUM_THREADS_PER_GRID = NUM_THREADS_PER_BLOCK * item.get_group_range(0);\n\n  int lid = item.get_local_id(0);\n  int bid = item.get_group(0);\n\n  \n\n  if( lid < R_W_MATRICES_SMEM_SLOTS )\n    shared_svd[lid] = svd[lid];\n  syncthreads();\n\n  \n\n  const double R00 = shared_svd[ 0];\n  const double R01 = shared_svd[ 1];\n  const double R02 = shared_svd[ 2];\n  const double R11 = shared_svd[ 3];\n  const double R12 = shared_svd[ 4];\n  const double R22 = shared_svd[ 5];\n\n  \n\n#ifdef WITH_FULL_W_MATRIX\n  const double W00 = shared_svd[ 6];\n  const double W01 = shared_svd[ 7];\n  const double W02 = shared_svd[ 8];\n  const double W10 = shared_svd[ 9];\n  const double W11 = shared_svd[10];\n  const double W12 = shared_svd[11];\n  const double W20 = shared_svd[12];\n  const double W21 = shared_svd[13];\n  const double W22 = shared_svd[14];\n#else\n  const double W00 = shared_svd[ 6];\n  const double W01 = shared_svd[ 7];\n  const double W02 = shared_svd[ 8];\n  const double W11 = shared_svd[ 9];\n  const double W12 = shared_svd[10];\n  const double W22 = shared_svd[11];\n#endif\n\n  \n\n  const double inv_R00 = R00 != 0.0 ? 1.0 / R00 : 0.0;\n  const double inv_R11 = R11 != 0.0 ? 1.0 / R11 : 0.0;\n  const double inv_R22 = R22 != 0.0 ? 1.0 / R22 : 0.0;\n\n  \n\n  const double inv_R01 = inv_R00*inv_R11*R01;\n  const double inv_R02 = inv_R00*inv_R22*R02;\n  const double inv_R12 =         inv_R22*R12;\n  \n  \n\n#ifdef WITH_FULL_W_MATRIX\n  const double inv_W00 = W00*inv_R00;\n  const double inv_W10 = W10*inv_R00;\n  const double inv_W20 = W20*inv_R00;\n#else\n  const double inv_W00 = W00*inv_R00;\n#endif\n\n  \n\n  double beta0 = 0.0, beta1 = 0.0, beta2 = 0.0;\n\n  \n\n  for( int path = bid * NUM_THREADS_PER_BLOCK + lid ; path < num_paths ; path += NUM_THREADS_PER_GRID )\n  {\n    \n\n    double S = paths[path];\n\n    \n\n    const int in_the_money = payoff.is_in_the_money(S);\n\n    \n\n    double Q1i = inv_R11*S - inv_R01;\n    double Q2i = inv_R22*S*S - inv_R02 - Q1i*inv_R12;\n\n    \n\n#ifdef WITH_FULL_W_MATRIX\n    const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n    const double WI1 = inv_W10 + W11 * Q1i + W12 * Q2i;\n    const double WI2 = inv_W20 + W21 * Q1i + W22 * Q2i;\n#else\n    const double WI0 = inv_W00 + W01 * Q1i + W02 * Q2i;\n    const double WI1 =           W11 * Q1i + W12 * Q2i;\n    const double WI2 =                       W22 * Q2i;\n#endif\n\n    \n\n    double cashflow = in_the_money ? cashflows[path] : 0.0;\n  \n    \n\n    beta0 += WI0*cashflow;\n    beta1 += WI1*cashflow;\n    beta2 += WI2*cashflow;\n  }\n\n  \n\n  if( lid == 0 )\n    lsums = sycl::double3(0);\n  syncthreads();\n\n  auto sumx_obj = sycl::atomic_ref<double, \n                  sycl::memory_order::relaxed,\n                  sycl::memory_scope::work_group,\n                  sycl::access::address_space::local_space> (lsums.x());\n  sumx_obj.fetch_add(beta0);\n  \n  auto sumy_obj = sycl::atomic_ref<double, \n                  sycl::memory_order::relaxed,\n                  sycl::memory_scope::work_group,\n                  sycl::access::address_space::local_space> (lsums.y());\n  sumy_obj.fetch_add(beta1);\n\n  auto sumz_obj = sycl::atomic_ref<double, \n                  sycl::memory_order::relaxed,\n                  sycl::memory_scope::work_group,\n                  sycl::access::address_space::local_space> (lsums.z());\n  sumz_obj.fetch_add(beta2);\n\n  syncthreads();\n  \n  \n\n  if( lid == 0 )\n  {\n    partial_sums[0*NUM_THREADS_PER_BLOCK + bid] = lsums.x();\n    partial_sums[1*NUM_THREADS_PER_BLOCK + bid] = lsums.y();\n    partial_sums[2*NUM_THREADS_PER_BLOCK + bid] = lsums.z();\n  }\n}\n\ntemplate< typename PayOff >\nclass final_beta;\n\ntemplate< int NUM_THREADS_PER_BLOCK >\nvoid compute_final_beta_kernel(\n  sycl::nd_item<1> &item,\n  sycl::double3& lsums,\n  const int *__restrict all_out_of_the_money,\n  double *__restrict beta)\n{\n  int lid = item.get_local_id(0);\n\n  \n\n  if( *all_out_of_the_money )\n  {\n    if( lid < 3 )\n      beta[lid] = 0.0;\n    return;\n  }\n\n  \n\n  sycl::double3 sums;\n  \n  \n\n  sums.x() = beta[0*NUM_THREADS_PER_BLOCK + lid];\n  sums.y() = beta[1*NUM_THREADS_PER_BLOCK + lid];\n  sums.z() = beta[2*NUM_THREADS_PER_BLOCK + lid];\n  \n  \n\n  if( lid == 0 )\n    lsums = sycl::double3(0);\n  syncthreads();\n\n  auto sumx_obj = sycl::atomic_ref<double, \n                  sycl::memory_order::relaxed,\n                  sycl::memory_scope::work_group,\n                  sycl::access::address_space::local_space> (lsums.x());\n  sumx_obj.fetch_add(sums.x());\n  \n  auto sumy_obj = sycl::atomic_ref<double, \n                  sycl::memory_order::relaxed,\n                  sycl::memory_scope::work_group,\n                  sycl::access::address_space::local_space> (lsums.y());\n  sumy_obj.fetch_add(sums.y());\n\n  auto sumz_obj = sycl::atomic_ref<double, \n                  sycl::memory_order::relaxed,\n                  sycl::memory_scope::work_group,\n                  sycl::access::address_space::local_space> (lsums.z());\n  sumz_obj.fetch_add(sums.z());\n \n  syncthreads();\n  \n  \n\n  if( lid == 0 )\n  {\n    beta[0] = lsums.x(); \n    beta[1] = lsums.y();\n    beta[2] = lsums.z();\n  }\n}\n\n\n\n\n\ntemplate< typename Payoff >\nclass update_cashflow;\n\ntemplate< int NUM_THREADS_PER_BLOCK, typename Payoff >\nvoid update_cashflow_kernel(sycl::nd_item<1> &item,\n                            int num_paths,\n                            Payoff payoff_object,\n                            double exp_min_r_dt,\n                            const double *__restrict beta,\n                            const double *__restrict paths,\n                            const int *__restrict all_out_of_the_money,\n                            double *__restrict cashflows)\n{\n  const int NUM_THREADS_PER_GRID = item.get_group_range(0) * NUM_THREADS_PER_BLOCK;\n\n  \n\n  const int skip_computations = *all_out_of_the_money;\n\n  \n\n  const double beta0 = beta[0];\n  const double beta1 = beta[1];\n  const double beta2 = beta[2];\n\n  \n\n  int path = item.get_global_id(0);\n  for( ; path < num_paths ; path += NUM_THREADS_PER_GRID )\n  {\n    \n\n    const double old_cashflow = exp_min_r_dt*cashflows[path];\n    if( skip_computations )\n    {\n      cashflows[path] = old_cashflow;\n      continue;\n    }\n  \n    \n\n    double S  = paths[path];\n    double S2 = S*S;\n\n    \n\n    double payoff = payoff_object(S);\n\n    \n\n    double estimated_payoff = beta0 + beta1*S + beta2*S2;\n\n    \n\n    estimated_payoff *= exp_min_r_dt;\n\n    \n\n    if( payoff <= 1.0e-8 || payoff <= estimated_payoff )\n      payoff = old_cashflow;\n    \n    \n\n    cashflows[path] = payoff;\n  }\n}\n\ntemplate< typename Payoff >\nclass partial_sums;\n\ntemplate< int NUM_THREADS_PER_BLOCK >\nvoid compute_partial_sums_kernel(sycl::nd_item<1> &item,\n                                 int num_paths, \n                                 double& lsum,\n                                 const double *__restrict cashflows,\n                                 double *__restrict sums)\n{\n  int lid = item.get_local_id(0);\n  int bid = item.get_group(0);\n\n  \n\n  const int path = bid * NUM_THREADS_PER_BLOCK + lid;\n\n  \n\n  double sum = 0.0;\n  if( path < num_paths )\n    sum = cashflows[path];\n\n  \n\n  if (lid == 0) lsum = 0;\n  syncthreads();\n  \n  \n\n  auto sum_obj = sycl::atomic_ref<double, \n                 sycl::memory_order::relaxed,\n                 sycl::memory_scope::work_group,\n                 sycl::access::address_space::local_space> (lsum);\n  sum_obj.fetch_add(sum);\n \n  syncthreads();\n\n  \n\n  if( lid == 0 )\n    sums[bid] = lsum;\n}\n\ntemplate< typename Payoff >\nclass final_sums;\n\ntemplate< int NUM_THREADS_PER_BLOCK >\nvoid compute_final_sum_kernel(\n  sycl::nd_item<1> &item,\n  int num_paths, \n  int num_blocks,\n  double exp_min_r_dt,\n  double& lsum,\n  double *__restrict sums)\n{\n  int lid = item.get_local_id(0);\n\n  \n\n  double sum = 0.0;\n  for( int item = lid ; item < num_blocks ; item += NUM_THREADS_PER_BLOCK )\n    sum += sums[item];\n\n  \n\n  if (lid == 0) lsum = 0;\n  syncthreads();\n  \n  \n\n  auto sum_obj = sycl::atomic_ref<double, \n                 sycl::memory_order::relaxed,\n                 sycl::memory_scope::work_group,\n                 sycl::access::address_space::local_space> (lsum);\n  sum_obj.fetch_add(sum);\n\n  syncthreads();\n\n  \n\n  if( lid == 0 )\n  {\n    sums[0] = exp_min_r_dt * lsum / (double) num_paths;\n  }\n}\n\ntemplate< typename Payoff >\nstatic inline \nvoid do_run(sycl::queue &q,\n            double *h_samples,\n            int num_timesteps, \n            int num_paths, \n            const Payoff &payoff, \n            double dt,\n            double S0,\n            double r,\n            double sigma,\n            double *d_samples,\n            double *d_paths,\n            double *d_cashflows,\n            double *d_svds,\n            int    *d_all_out_of_the_money,\n            double *d_temp_storage,\n            double *h_price)\n{\n  q.memcpy(d_samples, h_samples, sizeof(double) * num_timesteps * num_paths);\n\n  \n\n  const int NUM_THREADS_PER_BLOCK0 = 256;\n  int grid_dim = (num_paths + NUM_THREADS_PER_BLOCK0-1) / NUM_THREADS_PER_BLOCK0;\n  sycl::range<1> gws_gen_paths (grid_dim * NUM_THREADS_PER_BLOCK0);\n  sycl::range<1> lws_gen_paths (NUM_THREADS_PER_BLOCK0);\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class generate_paths<Payoff>>(\n      sycl::nd_range<1>(gws_gen_paths, lws_gen_paths), [=] (sycl::nd_item<1> item) {\n      generate_paths_kernel<NUM_THREADS_PER_BLOCK0>(\n        item,\n        num_timesteps,\n        num_paths,\n        payoff,\n        dt,\n        S0,\n        r,\n        sigma,\n        d_samples,\n        d_paths);\n    });\n  });\n\n  \n\n  q.memset(d_all_out_of_the_money, 0, num_timesteps*sizeof(int));\n\n  \n\n  const int NUM_THREADS_PER_BLOCK1 = 256;\n  sycl::range<1> gws_prepare_svd ((num_timesteps-1) * NUM_THREADS_PER_BLOCK1);\n  sycl::range<1> lws_prepare_svd (NUM_THREADS_PER_BLOCK1);\n\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<int, 1> scan_input(sycl::range<1>(NUM_THREADS_PER_BLOCK1), cgh);\n    sycl::local_accessor<int, 1> scan_output(sycl::range<1>(1+NUM_THREADS_PER_BLOCK1), cgh);\n    sycl::local_accessor<sycl::double4, 0> lsums (cgh);\n    sycl::local_accessor<int, 0> lsum (cgh);\n    sycl::local_accessor<double, 1> smem_svds (sycl::range<1>(R_W_MATRICES_SMEM_SLOTS), cgh);\n    cgh.parallel_for<class prepare_svd<Payoff>>(sycl::nd_range<1>(gws_prepare_svd, lws_prepare_svd), [=] (sycl::nd_item<1> item) {\n      prepare_svd_kernel<NUM_THREADS_PER_BLOCK1>(\n          item,\n          num_paths,\n          4, \n\n          payoff, \n          scan_input.get_pointer(),\n          scan_output.get_pointer(),\n          lsums,\n          lsum,\n          smem_svds.get_pointer(),\n          d_paths,\n          d_all_out_of_the_money,\n          d_svds);\n    });\n  });\n\n  \n\n  const double exp_min_r_dt = std::exp(-r*dt);\n\n  \n\n  const int num_threads_per_wave_full_occupancy = 256 * 112;\n\n  \n\n  const int NUM_THREADS_PER_BLOCK2 = 128;\n\n  \n\n  grid_dim = (num_paths + NUM_THREADS_PER_BLOCK2-1) / NUM_THREADS_PER_BLOCK2;\n  double num_waves = grid_dim*NUM_THREADS_PER_BLOCK2 / (double) num_threads_per_wave_full_occupancy;\n\n  int update_cashflow_grid = grid_dim;\n  if( num_waves < 10 && num_waves - (int) num_waves < 0.6 )\n    update_cashflow_grid = std::max(1, (int) num_waves) * num_threads_per_wave_full_occupancy / NUM_THREADS_PER_BLOCK2;\n\n  \n\n  for( int timestep = num_timesteps-2 ; timestep >= 0 ; --timestep )\n  {\n    \n\n    sycl::range<1> gws_partial_beta (NUM_THREADS_PER_BLOCK2 * NUM_THREADS_PER_BLOCK2);\n    sycl::range<1> lws_partial_beta (NUM_THREADS_PER_BLOCK2);\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<sycl::double3, 0> lsums (cgh);\n      sycl::local_accessor<double, 1> shared_svds (sycl::range<1>(R_W_MATRICES_SMEM_SLOTS), cgh);\n      cgh.parallel_for<class partial_beta<Payoff>>(\n        sycl::nd_range<1>(gws_partial_beta, lws_partial_beta), [=] (sycl::nd_item<1> item) {\n        compute_partial_beta_kernel<NUM_THREADS_PER_BLOCK2>(\n          item,\n          num_paths,\n          payoff,\n          lsums,\n          shared_svds.get_pointer(),\n          d_svds + 16*timestep,\n          d_paths + timestep*num_paths,\n          d_cashflows,\n          d_all_out_of_the_money + timestep,\n          d_temp_storage);\n      });\n    });\n\n    \n\n    sycl::range<1> gws_final_beta (NUM_THREADS_PER_BLOCK2);\n    sycl::range<1> lws_final_beta (NUM_THREADS_PER_BLOCK2);\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<sycl::double3, 0> lsums (cgh);\n      cgh.parallel_for<class final_beta<Payoff>>(\n        sycl::nd_range<1>(gws_final_beta, lws_final_beta), [=] (sycl::nd_item<1> item) {\n        compute_final_beta_kernel<NUM_THREADS_PER_BLOCK2>(\n          item,\n          lsums,\n          d_all_out_of_the_money + timestep,\n          d_temp_storage);\n      });\n    });\n\n    sycl::range<1> gws_cashflow (update_cashflow_grid * NUM_THREADS_PER_BLOCK2);\n    sycl::range<1> lws_cashflow (NUM_THREADS_PER_BLOCK2);\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class update_cashflow<Payoff>>(\n        sycl::nd_range<1>(gws_cashflow, lws_cashflow), [=] (sycl::nd_item<1> item) {\n        update_cashflow_kernel<NUM_THREADS_PER_BLOCK2>(\n          item,\n          num_paths,\n          payoff,\n          exp_min_r_dt,\n          d_temp_storage,\n          d_paths + timestep*num_paths,\n          d_all_out_of_the_money + timestep,\n          d_cashflows);\n      });\n    });\n  }\n\n  \n\n  const int NUM_THREADS_PER_BLOCK4 = 128;\n  grid_dim = (num_paths + NUM_THREADS_PER_BLOCK4-1) / NUM_THREADS_PER_BLOCK4;\n\n  sycl::range<1> gws_partial_sum (grid_dim * NUM_THREADS_PER_BLOCK4);\n  sycl::range<1> lws_partial_sum (NUM_THREADS_PER_BLOCK4);\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<double, 0> lsum (cgh);\n    cgh.parallel_for<class partial_sums<Payoff>>(\n      sycl::nd_range<1>(gws_partial_sum, lws_partial_sum), [=] (sycl::nd_item<1> item) {\n      compute_partial_sums_kernel<NUM_THREADS_PER_BLOCK4>(\n        item,\n        num_paths,\n        lsum,\n        d_cashflows,\n        d_temp_storage);\n    });\n  });\n\n  sycl::range<1> gws_final_sum (NUM_THREADS_PER_BLOCK4);\n  sycl::range<1> lws_final_sum (NUM_THREADS_PER_BLOCK4);\n  q.submit([&] (sycl::handler &cgh) {\n    sycl::local_accessor<double, 0> lsum (cgh);\n    cgh.parallel_for<class final_sums<Payoff>>(\n      sycl::nd_range<1>(gws_final_sum, lws_final_sum), [=] (sycl::nd_item<1> item) {\n      compute_final_sum_kernel<NUM_THREADS_PER_BLOCK4>(\n        item,\n        num_paths,\n        grid_dim,\n        exp_min_r_dt,\n        lsum,\n        d_temp_storage);\n    });\n  });\n\n  \n\n  q.memcpy(h_price, d_temp_storage, sizeof(double)).wait();\n}\n\ntemplate< typename Payoff >\nstatic double binomial_tree(int num_timesteps, const Payoff &payoff, double dt, double S0, double r, double sigma)\n{\n  double *tree = new double[num_timesteps+1];\n\n  double u = std::exp( sigma * std::sqrt(dt));\n  double d = std::exp(-sigma * std::sqrt(dt));\n  double a = std::exp( r     * dt);\n  \n  double p = (a - d) / (u - d);\n  \n  double k = std::pow(d, num_timesteps);\n  for( int t = 0 ; t <= num_timesteps ; ++t )\n  {\n    tree[t] = payoff(S0*k);\n    k *= u*u;\n  }\n\n  for( int t = num_timesteps-1 ; t >= 0 ; --t )\n  {\n    k = std::pow(d, t);\n    for( int i = 0 ; i <= t ; ++i )\n    {\n      double expected = std::exp(-r*dt) * (p*tree[i+1] + (1.0 - p)*tree[i]);\n      double earlyex = payoff(S0*k);\n      tree[i] = std::max(earlyex, expected);\n      k *= u*u;\n    }\n  }\n\n  double f = tree[0];\n  delete[] tree;\n  return f;\n}\n\n\n\ninline double normcdf (double x) {\n  return (1.0 + sycl::erf(x / sycl::sqrt(2.0))) / 2.0;\n}\n\nstatic double black_scholes_merton_put(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return K*std::exp(-r*T)*normcdf(-d2) - S0*normcdf(-d1);\n}\n\nstatic double black_scholes_merton_call(double T, double K, double S0, double r, double sigma)\n{\n  double d1 = (std::log(S0 / K) + (r + 0.5*sigma*sigma)*T) / (sigma*std::sqrt(T));\n  double d2 = d1 - sigma*std::sqrt(T);\n  \n  return S0*normcdf(d1) - K*std::exp(-r*T)*normcdf(d2);\n}\n\nint main(int argc, char **argv)\n{\n  const int MAX_GRID_SIZE = 2048;\n  \n  \n\n  int num_timesteps = 100;\n  int num_paths     = 32;\n  int num_runs      = 1;\n\n  \n\n  double T     = 1.00;\n  double K     = 4.00;\n  double S0    = 3.60;\n  double r     = 0.06;\n  double sigma = 0.20;\n\n  \n\n  bool price_put = true;\n  \n  \n\n  for( int i = 1 ; i < argc ; ++i )\n  {\n    if( !strcmp(argv[i], \"-timesteps\") )\n      num_timesteps = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-paths\") )\n      num_paths = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-runs\") )\n      num_runs = strtol(argv[++i], NULL, 10);\n    else if( !strcmp(argv[i], \"-T\") )\n      T = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-S0\") )\n      S0 = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-K\") )\n      K = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-r\") )\n      r = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-sigma\") )\n      sigma = strtod(argv[++i], NULL);\n    else if( !strcmp(argv[i], \"-call\") )\n      price_put = false;\n    else\n    {\n      fprintf(stderr, \"Unknown option %s. Aborting!!!\\n\", argv[i]);\n      exit(1);\n    }\n  }\n\n  \n\n  printf(\"==============\\n\");\n  printf(\"Num Timesteps         : %d\\n\",  num_timesteps);\n  printf(\"Num Paths             : %dK\\n\", num_paths);\n  printf(\"Num Runs              : %d\\n\",  num_runs);\n  printf(\"T                     : %lf\\n\", T);\n  printf(\"S0                    : %lf\\n\", S0);\n  printf(\"K                     : %lf\\n\", K);\n  printf(\"r                     : %lf\\n\", r);\n  printf(\"sigma                 : %lf\\n\", sigma);\n  printf(\"Option Type           : American %s\\n\",  price_put ? \"Put\" : \"Call\");\n\n  \n\n  num_paths *= 1024;\n\n  \n\n  double dt = T / num_timesteps;\n\n  \n\n  std::default_random_engine rng;\n  std::normal_distribution<double> norm_dist(0.0, 1.0);\n\n  double *h_samples = (double*) malloc (num_timesteps*num_paths*sizeof(double));\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  double *d_samples = sycl::malloc_device<double>(num_timesteps*num_paths, q);\n\n  \n\n  double *d_paths = sycl::malloc_device<double>(num_timesteps*num_paths, q);\n\n  \n\n  double *d_cashflows = d_paths + (num_timesteps-1)*num_paths;\n\n  \n\n  double *d_svds = sycl::malloc_device<double>(16*num_timesteps, q);\n\n  \n\n  int *d_all_out_of_the_money = sycl::malloc_device<int>(num_timesteps, q);\n\n  \n\n  int max_temp_storage = 4*MAX_GRID_SIZE;\n  double *d_temp_storage = sycl::malloc_device<double>(max_temp_storage, q);\n\n  \n\n  double h_price;\n\n  \n\n  float total_elapsed_time = 0;\n\n  for( int run = 0; run < num_runs; ++run )\n  {\n    for (int i = 0; i < num_timesteps*num_paths; ++i)\n      h_samples[i] = norm_dist(rng);\n      \n    auto start = std::chrono::high_resolution_clock::now();\n    if( price_put )\n      do_run(q,\n             h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffPut(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             d_samples,\n             d_paths,\n             d_cashflows,\n             d_svds,\n             d_all_out_of_the_money,\n             d_temp_storage,\n             &h_price);\n    else\n      do_run(q,\n             h_samples,\n             num_timesteps, \n             num_paths, \n             PayoffCall(K), \n             dt,\n             S0,\n             r,\n             sigma,\n             d_samples,\n             d_paths,\n             d_cashflows,\n             d_svds,\n             d_all_out_of_the_money,\n             d_temp_storage,\n             &h_price);\n\n    auto end = std::chrono::high_resolution_clock::now();\n    const float elapsed_time =\n       std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n    total_elapsed_time += elapsed_time;\n  }\n\n  printf(\"==============\\n\");\n  printf(\"GPU Longstaff-Schwartz: %.8lf\\n\", h_price);\n  \n  double price = 0.0;\n\n  if( price_put )\n    price = binomial_tree(num_timesteps, PayoffPut(K), dt, S0, r, sigma);\n  else\n    price = binomial_tree(num_timesteps, PayoffCall(K), dt, S0, r, sigma);\n\n  printf(\"Binonmial             : %.8lf\\n\", price);\n  \n  if( price_put )\n    price = black_scholes_merton_put(T, K, S0, r, sigma);\n  else\n    price = black_scholes_merton_call(T, K, S0, r, sigma);\n\n  printf(\"European Price        : %.8lf\\n\", price);\n\n  printf(\"==============\\n\");\n\n  printf(\"elapsed time for each run         : %.3fms\\n\", total_elapsed_time / num_runs);\n  printf(\"==============\\n\");\n\n  \n\n  free(h_samples);\n  sycl::free(d_temp_storage, q);\n  sycl::free(d_all_out_of_the_money, q);\n  sycl::free(d_svds, q);\n  sycl::free(d_paths, q);\n  sycl::free(d_samples, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "assert", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <assert.h>\n#include <cuda.h>\n#include <chrono>\n\n\n\n\n\n__global__ void testKernel(int N)\n{\n  int gid = blockIdx.x*blockDim.x + threadIdx.x ;\n  assert(gid < N) ;\n}\n\n\n\n__global__ void perfKernel()\n{\n  int gid = blockIdx.x*blockDim.x + threadIdx.x ;\n  assert(gid <= blockDim.x * gridDim.x) ;\n  int s = 0;\n  for (int n = 1; n <= gid; n++) {\n    s++; assert(s <= gid);\n  }\n}\n\n__global__ void perfKernel2()\n{\n  int gid = blockIdx.x*blockDim.x + threadIdx.x ;\n  int s = 0;\n  for (int n = 1; n <= gid; n++) {\n    s++; assert(s <= gid);\n  }\n}\n\n\n\nbool runPerf(int argc, char **argv);\nbool runTest(int argc, char **argv);\n\nint main(int argc, char **argv)\n{\n  \n\n  runPerf(argc, argv);\n\n  \n\n  bool testResult = runTest(argc, argv);\n\n  printf(\"Test assert completed, returned %s\\n\",\n         testResult ? \"OK\" : \"ERROR!\");\n\n  if (!testResult) return EXIT_FAILURE;\n\n  exit(EXIT_SUCCESS);\n}\n\nbool runTest(int argc, char **argv)\n{\n  int Nblocks = 2;\n  int Nthreads = 32;\n  cudaError_t error ;\n\n  \n\n  \n\n  dim3 dimGrid(Nblocks);\n  dim3 dimBlock(Nthreads);\n\n  printf(\"\\nLaunch kernel to generate assertion failures\\n\");\n  testKernel<<<dimGrid, dimBlock>>>(60);\n\n  \n\n  printf(\"\\n-- Begin assert output\\n\\n\");\n  error = cudaDeviceSynchronize();\n  printf(\"\\n-- End assert output\\n\\n\");\n\n  \n\n  if (error == cudaErrorAssert)\n  {\n    printf(\"Device assert failed as expected, \"\n           \"CUDA error message is: %s\\n\\n\",\n           cudaGetErrorString(error));\n  }\n\n  return (error == cudaErrorAssert);\n}\n\nbool runPerf(int argc, char **argv)\n{\n  int Nblocks = 1000;\n  int Nthreads = 256;\n\n  dim3 dimGrid(Nblocks);\n  dim3 dimBlock(Nthreads);\n\n  printf(\"\\nLaunch kernel to evaluate the impact of assertion on performance \\n\");\n\n  printf(\"Each thread in the kernel executes threadID + 1 assertions\\n\");\n  auto start = std::chrono::steady_clock::now();\n  perfKernel<<<dimGrid, dimBlock>>>();\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  std::chrono::duration<float> time = end - start;\n  printf(\"Kernel time : %f\\n\", time.count());\n\n  printf(\"Each thread in the kernel executes threadID assertions\\n\");\n  start = std::chrono::steady_clock::now();\n  perfKernel2<<<dimGrid, dimBlock>>>();\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = end - start;\n  printf(\"Kernel time : %f\\n\", time.count());\n\n  return true;\n}\n"}}
{"kernel_name": "assert", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <assert.h>\n#include <hip/hip_runtime.h>\n#include <chrono>\n\n\n\n\n\n__global__ void testKernel(int N)\n{\n  int gid = blockIdx.x*blockDim.x + threadIdx.x ;\n  assert(gid < N) ;\n}\n\n\n\n__global__ void perfKernel()\n{\n  int gid = blockIdx.x*blockDim.x + threadIdx.x ;\n  assert(gid <= blockDim.x * gridDim.x) ;\n  int s = 0;\n  for (int n = 1; n <= gid; n++) {\n    s++; assert(s <= gid);\n  }\n}\n\n__global__ void perfKernel2()\n{\n  int gid = blockIdx.x*blockDim.x + threadIdx.x ;\n  int s = 0;\n  for (int n = 1; n <= gid; n++) {\n    s++; assert(s <= gid);\n  }\n}\n\n\n\nbool runPerf(int argc, char **argv);\nbool runTest(int argc, char **argv);\n\nint main(int argc, char **argv)\n{\n  \n\n  runPerf(argc, argv);\n\n  \n\n  bool testResult = runTest(argc, argv);\n\n  printf(\"Test assert completed, returned %s\\n\",\n         testResult ? \"OK\" : \"ERROR!\");\n\n  if (!testResult) return EXIT_FAILURE;\n\n  exit(EXIT_SUCCESS);\n}\n\nbool runTest(int argc, char **argv)\n{\n  int Nblocks = 2;\n  int Nthreads = 32;\n  hipError_t error ;\n\n  \n\n  \n\n  dim3 dimGrid(Nblocks);\n  dim3 dimBlock(Nthreads);\n\n  printf(\"\\nLaunch kernel to generate assertion failures\\n\");\n  hipLaunchKernelGGL(testKernel, dimGrid, dimBlock, 0, 0, 60);\n\n  \n\n  printf(\"\\n-- Begin assert output\\n\\n\");\n  error = hipDeviceSynchronize();\n  printf(\"\\n-- End assert output\\n\\n\");\n\n  \n\n  if (error == hipErrorAssert)\n  {\n    printf(\"Device assert failed as expected, \"\n           \"HIP error message is: %s\\n\\n\",\n           hipGetErrorString(error));\n  }\n\n  return (error == hipErrorAssert);\n}\n\nbool runPerf(int argc, char **argv)\n{\n  int Nblocks = 1000;\n  int Nthreads = 256;\n\n  dim3 dimGrid(Nblocks);\n  dim3 dimBlock(Nthreads);\n\n  printf(\"\\nLaunch kernel to evaluate the impact of assertion on performance \\n\");\n\n  printf(\"Each thread in the kernel executes threadID + 1 assertions\\n\");\n  auto start = std::chrono::steady_clock::now();\n  hipLaunchKernelGGL(perfKernel, dimGrid, dimBlock, 0, 0);\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  std::chrono::duration<float> time = end - start;\n  printf(\"Kernel time : %f\\n\", time.count());\n\n  printf(\"Each thread in the kernel executes threadID assertions\\n\");\n  start = std::chrono::steady_clock::now();\n  hipLaunchKernelGGL(perfKernel2, dimGrid, dimBlock, 0, 0);\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = end - start;\n  printf(\"Kernel time : %f\\n\", time.count());\n\n  return true;\n}\n"}}
{"kernel_name": "assert", "parallel_api": "sycl", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <assert.h>\n#include <iostream>\n#include <chrono>\n#include <exception>\n#include <sycl/sycl.hpp>\n\nauto report_error = [] (sycl::exception_list elist) {\n  for (auto &e : elist) {\n    try { std::rethrow_exception(e); }\n    catch (sycl::exception& e) {\n      std::cerr << \"Error:\\n\" << e.what() << std::endl;\n    }\n  }\n};\n\n\n\n\n\nvoid testKernel(int N, sycl::nd_item<1> &item)\n{\n  int gid = item.get_global_id(0);\n  assert(gid < N) ;\n}\n\n\n\nvoid perfKernel(sycl::nd_item<1> &item)\n{\n  int gid = item.get_global_id(0);\n  assert(gid <= item.get_local_range(0) * item.get_group_range(0));\n  int s = 0;\n  for (int n = 1; n <= gid; n++) {\n    s++; assert(s <= gid);\n  }\n}\n\nvoid perfKernel2(sycl::nd_item<1> &item)\n{\n  int gid = item.get_global_id(0);\n  int s = 0;\n  for (int n = 1; n <= gid; n++) {\n    s++; assert(s <= gid);\n  }\n}\n\n\n\nbool runPerf(sycl::queue &q, int argc, char **argv);\nbool runTest(sycl::queue &q, int argc, char **argv);\n\nint main(int argc, char **argv)\n{\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, report_error, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, report_error, sycl::property::queue::in_order());\n#endif\n\n  \n\n  runPerf(q, argc, argv);\n\n  \n\n  bool testResult = runTest(q, argc, argv);\n\n  printf(\"Test assert completed, returned %s\\n\",\n         testResult ? \"OK\" : \"ERROR!\");\n\n  if (!testResult) return EXIT_FAILURE;\n\n  exit(EXIT_SUCCESS);\n}\n\nbool runTest(sycl::queue &q, int argc, char **argv) {\n  int Nblocks = 2;\n  int Nthreads = 32;\n\n  \n\n  \n\n  sycl::range<1> gws (Nblocks * Nthreads);\n  sycl::range<1> lws (Nthreads);\n\n  printf(\"\\nLaunch kernel to generate assertion failures\\n\");\n\n  try {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        testKernel(60, item);\n      });\n    });\n\n    \n\n    printf(\"\\n-- Begin assert output\\n\\n\");\n    q.wait_and_throw();\n    printf(\"\\n-- End assert output\\n\\n\");\n  }\n  catch (...) {}\n  return true;\n}\n\nbool runPerf(sycl::queue &q, int argc, char **argv)\n{\n  int Nblocks = 1000;\n  int Nthreads = 256;\n\n  sycl::range<1> gws (Nblocks * Nthreads);\n  sycl::range<1> lws (Nthreads);\n\n  printf(\"\\nLaunch kernel to evaluate the impact of assertion on performance \\n\");\n\n  printf(\"Each thread in the kernel executes threadID + 1 assertions\\n\");\n  auto start = std::chrono::steady_clock::now();\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      perfKernel(item);\n    });\n  }).wait();\n  auto end = std::chrono::steady_clock::now();\n  std::chrono::duration<float> time = end - start;\n  printf(\"Kernel time : %f\\n\", time.count());\n\n  printf(\"Each thread in the kernel executes threadID assertions\\n\");\n  start = std::chrono::steady_clock::now();\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      perfKernel2(item);\n    });\n  }).wait();\n  end = std::chrono::steady_clock::now();\n  time = end - start;\n  printf(\"Kernel time : %f\\n\", time.count());\n\n  return true;\n}\n"}}
{"kernel_name": "atomicPerf", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n\nstatic void CheckError( cudaError_t err, const char *file, int line ) {\n  if (err != cudaSuccess) {\n    printf( \"%s in %s at line %d\\n\", cudaGetErrorString( err ), file, line );\n  }\n}\n#define CHECK_ERROR( err ) (CheckError( err, __FILE__, __LINE__ ))\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\n__global__ void BlockRangeAtomicOnGlobalMem(T* data, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+threadIdx.x, (T)1);  \n\n  }\n}\n\ntemplate <typename T>\n__global__ void WarpRangeAtomicOnGlobalMem(T* data, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+(i & 0x1F), (T)1); \n\n  }\n}\n\ntemplate <typename T>\n__global__ void SingleRangeAtomicOnGlobalMem(T* data, int offset, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+offset, (T)1);    \n\n  }\n}\n\ntemplate <typename T>\n__global__ void BlockRangeAtomicOnSharedMem(T* data, int n)\n{\n  __shared__ T smem_data[BLOCK_SIZE];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data+threadIdx.x, (T)1);\n  }\n  if (blockIdx.x == gridDim.x)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\n__global__ void WarpRangeAtomicOnSharedMem(T* data, int n)\n{\n  __shared__ T smem_data[32];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data+(i & 0x1F), (T)1);\n  }\n  if (blockIdx.x == gridDim.x && threadIdx.x < 0x1F)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\n__global__ void SingleRangeAtomicOnSharedMem(T* data, int offset, int n)\n{\n  __shared__ T smem_data[BLOCK_SIZE];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data + offset, (T)1);\n  }\n  if (blockIdx.x == gridDim.x && threadIdx.x == 0)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) {\n    data[i] = i%1024+1;\n  }\n\n  T* d_data;\n  CHECK_ERROR( cudaMalloc((void **)&d_data, data_size) );\n\n  dim3 block (BLOCK_SIZE);\n  dim3 grid (n / BLOCK_SIZE);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    BlockRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    WarpRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    SingleRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, i % BLOCK_SIZE, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    BlockRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    WarpRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( cudaMemcpy(d_data, data, data_size, cudaMemcpyHostToDevice) );\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    SingleRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, i % BLOCK_SIZE, n);\n  }\n  CHECK_ERROR( cudaDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  free(data);\n  cudaFree(d_data); \n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}\n"}}
{"kernel_name": "atomicPerf", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\nstatic void CheckError( hipError_t err, const char *file, int line ) {\n  if (err != hipSuccess) {\n    printf( \"%s in %s at line %d\\n\", hipGetErrorString( err ), file, line );\n  }\n}\n#define CHECK_ERROR( err ) (CheckError( err, __FILE__, __LINE__ ))\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\n__global__ void BlockRangeAtomicOnGlobalMem(T* data, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+threadIdx.x, (T)1);  \n\n  }\n}\n\ntemplate <typename T>\n__global__ void WarpRangeAtomicOnGlobalMem(T* data, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+(i & 0x1F), (T)1); \n\n  }\n}\n\ntemplate <typename T>\n__global__ void SingleRangeAtomicOnGlobalMem(T* data, int offset, int n)\n{\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(data+offset, (T)1);    \n\n  }\n}\n\ntemplate <typename T>\n__global__ void BlockRangeAtomicOnSharedMem(T* data, int n)\n{\n  __shared__ T smem_data[BLOCK_SIZE];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data+threadIdx.x, (T)1);\n  }\n  if (blockIdx.x == gridDim.x)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\n__global__ void WarpRangeAtomicOnSharedMem(T* data, int n)\n{\n  __shared__ T smem_data[32];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data+(i & 0x1F), (T)1);\n  }\n  if (blockIdx.x == gridDim.x && threadIdx.x < 0x1F)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\n__global__ void SingleRangeAtomicOnSharedMem(T* data, int offset, int n)\n{\n  __shared__ T smem_data[BLOCK_SIZE];\n  unsigned int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n  for ( unsigned int i = tid; i < n; i += blockDim.x*gridDim.x){\n    atomicAdd(smem_data + offset, (T)1);\n  }\n  if (blockIdx.x == gridDim.x && threadIdx.x == 0)\n    data[threadIdx.x] = smem_data[threadIdx.x];\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) {\n    data[i] = i%1024+1;\n  }\n\n  T* d_data;\n  CHECK_ERROR( hipMalloc((void **)&d_data, data_size) );\n\n  dim3 block (BLOCK_SIZE);\n  dim3 grid (n / BLOCK_SIZE);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    BlockRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    WarpRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    SingleRangeAtomicOnGlobalMem<T><<<grid, block>>>(d_data, i % BLOCK_SIZE, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    BlockRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    WarpRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  CHECK_ERROR( hipMemcpy(d_data, data, data_size, hipMemcpyHostToDevice) );\n  CHECK_ERROR( hipDeviceSynchronize() );\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    SingleRangeAtomicOnSharedMem<T><<<grid, block>>>(d_data, i % BLOCK_SIZE, n);\n  }\n  CHECK_ERROR( hipDeviceSynchronize() );\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  free(data);\n  hipFree(d_data); \n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}\n"}}
{"kernel_name": "atomicPerf", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <omp.h>\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnGlobalMem(T* data, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for ( unsigned int i = 0; i < n; i++) {\n    #pragma omp atomic update\n    data[i % BLOCK_SIZE]++;  \n\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnGlobalMem(T* data, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for ( unsigned int i = 0; i < n; i++) {\n    #pragma omp atomic update\n    data[i & 0x1F]++; \n\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnGlobalMem(T* data, int offset, int n)\n{\n  #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n  for ( unsigned int i = 0; i < n; i++) {\n    #pragma omp atomic update\n    data[0]++;    \n\n  }\n}\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnSharedMem(T* data, int n)\n{\n  #pragma omp target teams num_teams(n / BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T smem_data[BLOCK_SIZE];\n    #pragma omp parallel \n    {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[threadIdx_x]++;\n      }\n      if (blockIdx_x == gridDim_x)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnSharedMem(T* data, int n)\n{\n  #pragma omp target teams num_teams(n / BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T smem_data[32];\n    #pragma omp parallel \n    {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[i & 0x1F]++;\n      }\n      if (blockIdx_x == gridDim_x && threadIdx_x < 0x1F)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnSharedMem(T* data, int offset, int n)\n{\n  #pragma omp target teams num_teams(n / BLOCK_SIZE) thread_limit(BLOCK_SIZE)\n  {\n    T smem_data[BLOCK_SIZE];\n    #pragma omp parallel \n    {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[offset]++;\n      }\n      if (blockIdx_x == gridDim_x && threadIdx_x == 0)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) data[i] = i%1024+1;\n\n  #pragma omp target data map(alloc: data[0:t])\n  {\n    #pragma omp target update to (data[0:t])\n    auto start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      BlockRangeAtomicOnGlobalMem<T>(data, n);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      WarpRangeAtomicOnGlobalMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      SingleRangeAtomicOnGlobalMem<T>(data, i % BLOCK_SIZE, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      BlockRangeAtomicOnSharedMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      WarpRangeAtomicOnSharedMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n    #pragma omp target update to (data[0:t])\n    start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      SingleRangeAtomicOnSharedMem<T>(data, i % BLOCK_SIZE, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n  }\n  free(data);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}\n"}}
{"kernel_name": "atomicPerf", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnGlobalMem(T* data, int n)\n{\n    for ( unsigned int i = 0; i < n; i++) {\n        data[i % BLOCK_SIZE]++;  \n\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnGlobalMem(T* data, int n)\n{\n    for ( unsigned int i = 0; i < n; i++) {\n        data[i & 0x1F]++; \n\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnGlobalMem(T* data, int offset, int n)\n{\n    for ( unsigned int i = 0; i < n; i++) {\n        data[0]++;    \n\n  }\n}\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnSharedMem(T* data, int n)\n{\n    {\n    T smem_data[BLOCK_SIZE];\n        {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[threadIdx_x]++;\n      }\n      if (blockIdx_x == gridDim_x)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnSharedMem(T* data, int n)\n{\n    {\n    T smem_data[32];\n        {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[i & 0x1F]++;\n      }\n      if (blockIdx_x == gridDim_x && threadIdx_x < 0x1F)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnSharedMem(T* data, int offset, int n)\n{\n    {\n    T smem_data[BLOCK_SIZE];\n        {\n      unsigned int blockIdx_x = omp_get_team_num();\n      unsigned int gridDim_x = omp_get_num_teams();\n      unsigned int blockDim_x = omp_get_num_threads();\n      unsigned int threadIdx_x = omp_get_thread_num();\n      unsigned int tid = (blockIdx_x * blockDim_x) + threadIdx_x;\n      for ( unsigned int i = tid; i < n; i += blockDim_x*gridDim_x){\n        smem_data[offset]++;\n      }\n      if (blockIdx_x == gridDim_x && threadIdx_x == 0)\n        data[threadIdx_x] = smem_data[threadIdx_x];\n    }\n  }\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) data[i] = i%1024+1;\n\n    {\n        auto start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      BlockRangeAtomicOnGlobalMem<T>(data, n);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      WarpRangeAtomicOnGlobalMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      SingleRangeAtomicOnGlobalMem<T>(data, i % BLOCK_SIZE, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      BlockRangeAtomicOnSharedMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      WarpRangeAtomicOnSharedMem<T>(data, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n    for(int i=0; i<t; i++) data[i] = i%1024+1;\n        start = std::chrono::steady_clock::now();\n    for(int i=0; i<repeat; i++)\n    {\n      SingleRangeAtomicOnSharedMem<T>(data, i % BLOCK_SIZE, n);\n    }\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n            time * 1e-3f / repeat);\n\n  }\n  free(data);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}"}}
{"kernel_name": "atomicPerf", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnGlobalMem(T* data, int n, sycl::nd_item<1> &item)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (data[item.get_local_id(0)]);\n    ao.fetch_add((T)1); \n\n  }\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnGlobalMem(T* data, int n, sycl::nd_item<1> &item)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (data[i & 0x1F]);\n    ao.fetch_add((T)1); \n\n  }\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnGlobalMem(T* data, int offset, int n, sycl::nd_item<1> &item)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (data[offset]);\n    ao.fetch_add((T)1); \n\n  }\n}\n\ntemplate <typename T>\nvoid BlockRangeAtomicOnSharedMem(T* data, int n, sycl::nd_item<1> item,\n                                 T *smem_data)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (smem_data[item.get_local_id(0)]);\n    ao.fetch_add((T)1); \n\n  }\n  if (item.get_group(0) == item.get_group_range(0))\n    data[item.get_local_id(0)] = smem_data[item.get_local_id(0)];\n}\n\ntemplate <typename T>\nvoid WarpRangeAtomicOnSharedMem(T* data, int n, sycl::nd_item<1> item,\n                                T *smem_data)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (smem_data[i & 0x1F]);\n    ao.fetch_add((T)1); \n\n  }\n  if (item.get_group(0) == item.get_group_range(0) &&\n      item.get_local_id(0) < 0x1F)\n    data[item.get_local_id(0)] = smem_data[item.get_local_id(0)];\n}\n\ntemplate <typename T>\nvoid SingleRangeAtomicOnSharedMem(T* data, int offset, int n, sycl::nd_item<1> item,\n                                  T *smem_data)\n{\n  unsigned int tid = item.get_global_id(0);\n  for (unsigned int i = tid; i < n;\n       i += item.get_local_range(0) * item.get_group_range(0)) {\n    auto ao = sycl::atomic_ref<T, \n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (smem_data[offset]);\n    ao.fetch_add((T)1); \n\n  }\n  if (item.get_group(0) == item.get_group_range(0) &&\n      item.get_local_id(0) == 0)\n    data[item.get_local_id(0)] = smem_data[item.get_local_id(0)];\n}\n\ntemplate <typename T>\nvoid atomicPerf (int n, int t, int repeat)\n{\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n  \n  size_t data_size = sizeof(T) * t;\n\n  T* data = (T*) malloc (data_size);\n\n  for(int i=0; i<t; i++) {\n    data[i] = i%1024+1;\n  }\n\n  T* d_data = (T *)sycl::malloc_device(data_size, q);\n\n  sycl::range<1> lws (BLOCK_SIZE);\n  sycl::range<1> gws (n);\n\n  q.memcpy(d_data, data, data_size).wait();\n  auto start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        BlockRangeAtomicOnGlobalMem<T>(d_data, n, item);\n      });\n    });\n  }\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        WarpRangeAtomicOnGlobalMem<T>(d_data, n, item);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        SingleRangeAtomicOnGlobalMem<T>(d_data, i % BLOCK_SIZE, n, item);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnGlobalMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> smem (sycl::range<1>(BLOCK_SIZE), cgh);\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        BlockRangeAtomicOnSharedMem<T>(d_data, n, item, smem.get_pointer());\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of BlockRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> smem (sycl::range<1>(32), cgh);\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        WarpRangeAtomicOnSharedMem<T>(d_data, n, item, smem.get_pointer());\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of WarpRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  q.memcpy(d_data, data, data_size).wait();\n  start = std::chrono::steady_clock::now();\n  for(int i=0; i<repeat; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<T, 1> smem (sycl::range<1>(BLOCK_SIZE), cgh);\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        SingleRangeAtomicOnSharedMem<T>(d_data, i % BLOCK_SIZE,\n                                        n, item, smem.get_pointer());\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SingleRangeAtomicOnSharedMem: %f (us)\\n\",\n          time * 1e-3f / repeat);\n\n  free(data);\n  sycl::free(d_data, q);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int n = 3*4*7*8*9*256; \n\n  const int len = 1024; \n\n  \n  printf(\"\\nFP64 atomic add\\n\");\n  atomicPerf<double>(n, len, repeat); \n\n  printf(\"\\nINT32 atomic add\\n\");\n  atomicPerf<int>(n, len, repeat); \n\n  printf(\"\\nFP32 atomic add\\n\");\n  atomicPerf<float>(n, len, repeat); \n\n  return 0;\n}\n"}}
{"kernel_name": "attentionMultiHead", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cuda.h>\n\n#define FINAL_MASK 0xffffffff\n\n__inline__ __device__\nfloat warpReduceSum(float val)\n{\n  for(int mask = 16; mask > 0; mask >>= 1)\n    val += __shfl_xor_sync(FINAL_MASK, val, mask, 32);\n  return val;\n}\n\n\n\n__inline__ __device__\nfloat blockReduceSum(float val)\n{\n  static __shared__ float shared[32]; \n  int lane = threadIdx.x & 0x1f; \n  int wid = threadIdx.x >> 5;  \n\n  val = warpReduceSum(val);\n\n  if(lane == 0)\n    shared[wid] = val;\n\n  __syncthreads();\n\n\n  val = (threadIdx.x < (blockDim.x >> 5 )) ? shared[lane] : 0;\n  val = warpReduceSum(val);\n\n  return val;\n}\n\n__inline__ __device__\nfloat warpReduceMax(float val)\n{\n  for(int mask = 16; mask > 0; mask >>= 1)\n    val = max(val, __shfl_xor_sync(FINAL_MASK, val, mask, 32));\n  return val;\n}\n\n\n\n__inline__ __device__\nfloat blockReduceMax(float val)\n{\n  static __shared__ float shared[32]; \n  int lane = threadIdx.x & 0x1f; \n\n  int wid = threadIdx.x >> 5;  \n\n\n  val = warpReduceMax(val); \n\n\n  if(lane == 0) \n\n    shared[wid] = val;\n\n  __syncthreads();\n\n  val = (threadIdx.x < (blockDim.x >> 5)) ? shared[lane] : 0;\n  val = warpReduceMax(val);\n\n  return val;\n}\n\n\n__global__\nvoid mha (\n   const float *__restrict__ q, \n   const float *__restrict__ k, \n   const float *__restrict__ v, \n   const int beam_size, \n   const int n_steps, \n   const int qk_col, \n   const int v_col, \n   const int nhead, \n   const float scale,\n   const int THRESHOLD,\n   float *__restrict__ dst)\n{\n  \n\n  int dim_per_head = qk_col / nhead;\n  int candidate_id = blockIdx.x / nhead;\n  int head_id = blockIdx.x % nhead;\n\n  \n\n  extern __shared__ float buffer[];\n  float *sq = buffer;\n  \n\n  float *logits = buffer + dim_per_head;\n\n\n  \n\n  int pos = candidate_id * qk_col + head_id * dim_per_head + threadIdx.x;\n  if(threadIdx.x < dim_per_head) sq[threadIdx.x] = q[pos];\n  __syncthreads();\n\n  \n\n\n  float summ = 0.f;\n  if(threadIdx.x < n_steps)\n  {   \n    const float *k2 = k + candidate_id * qk_col * n_steps + head_id * dim_per_head + threadIdx.x * qk_col;\n    for (int i = 0; i < dim_per_head; i++)\n      summ += sq[i] * k2[i];\n    summ *= scale;\n  }   \n\n  \n\n\n  __shared__ float s_max_val;\n  __shared__ float s_sum;\n\n  float local_i = threadIdx.x < n_steps ? summ : -1e-20f;\n  float local_o;\n\n  float max_val = blockReduceMax(local_i);\n\n  if(threadIdx.x == 0)\n    s_max_val = max_val;\n  __syncthreads();\n\n  local_i -= s_max_val;\n\n  if(local_i < -THRESHOLD) local_i = -THRESHOLD;\n\n  local_o = expf(local_i);\n\n  float val = (threadIdx.x < n_steps) ? local_o : 0.f;\n  val = blockReduceSum(val);\n  if(threadIdx.x == 0) s_sum = val;\n  __syncthreads();\n\n  if(threadIdx.x < n_steps) logits[threadIdx.x] = local_o / s_sum;\n  __syncthreads();\n\n  \n\n  summ = 0.f;\n  if(threadIdx.x < dim_per_head)\n  {\n    int tid = candidate_id * v_col * n_steps + head_id * dim_per_head + threadIdx.x;\n    for(int i = 0; i < n_steps; ++i)\n      summ += logits[i] * v[tid + i * v_col];\n    dst[candidate_id * v_col + head_id * dim_per_head + threadIdx.x] = summ;\n  }\n}\n\n\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  \n\n  const int beamsize = 4;\n  const int nhead = 16;\n  const int dim_feature = nhead * 256;\n  const int n_steps = 9;\n\n  \n\n  const float scaler = sqrtf(nhead * 1.f / dim_feature);\n\n  \n\n  const int qk_col = dim_feature;\n  const int v_col = dim_feature;\n  const int THRESHOLD = 64;\n\n  const int q_size = beamsize * dim_feature;\n  const int q_size_bytes = sizeof(float) * q_size;\n\n  const int k_size = beamsize * dim_feature * n_steps;\n  const int k_size_bytes = sizeof(float) * k_size;\n\n  const int v_size = beamsize * dim_feature * n_steps;\n  const int v_size_bytes = sizeof(float) * v_size;\n\n  float *dq, *dk, *dv, *dst;\n  cudaMalloc((void**)&dq, q_size_bytes);\n  cudaMalloc((void**)&dk, k_size_bytes);\n  cudaMalloc((void**)&dv, v_size_bytes);\n  cudaMalloc((void**)&dst, q_size_bytes);\n\n  float *hq = (float*)malloc(q_size_bytes);\n  float *hk = (float*)malloc(k_size_bytes);\n  float *hv = (float*)malloc(v_size_bytes);\n  float *h_dst = (float*)malloc(q_size_bytes);\n\n  \n\n  for(int i = 0; i < q_size; ++i)\n    hq[i] = rand() / (float)RAND_MAX;\n\n  for(int i = 0; i < k_size; ++i)\n    hk[i] = rand() / (float)RAND_MAX;\n\n  for(int i = 0; i < v_size; ++i)\n    hv[i] = rand() / (float)RAND_MAX;\n\n  cudaMemcpy(dq, hq, q_size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(dk, hk, k_size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(dv, hv, v_size_bytes, cudaMemcpyHostToDevice);\n\n  dim3 grid(nhead * beamsize);\n  dim3 block(qk_col / nhead);\n\n  const int shared_size = sizeof(float) * ((qk_col / nhead) + n_steps);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    mha <<<grid, block, shared_size, 0 >>> (dq, dk, dv,\n      beamsize, n_steps, qk_col, v_col, nhead, scaler, THRESHOLD, dst);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(h_dst, dst, q_size_bytes, cudaMemcpyDeviceToHost);\n\n  cudaFree(dq);\n  cudaFree(dk);\n  cudaFree(dv);\n  cudaFree(dst);\n\n  \n\n  for (int i = 0; i < beamsize - 1; i++) {\n    float sum = 0.f;\n    for (int j = 0; j < dim_feature; j++) {\n       float d = h_dst[i * dim_feature + j] -\n                 h_dst[(i + 1) * dim_feature + j];\n       sum += d * d;\n    }\n    printf(\"Distance between beams %d and %d: %f\\n\", i, i+1, sqrtf(sum));\n  }\n\n  free(hq);\n  free(hk);\n  free(hv);\n  free(h_dst);\n\n  return 0;\n}\n"}}
{"kernel_name": "attentionMultiHead", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <hip/hip_runtime.h>\n\n__inline__ __device__\nfloat warpReduceSum(float val)\n{\n  for(int mask = 16; mask > 0; mask >>= 1)\n    val += __shfl_xor(val, mask, 32);\n  return val;\n}\n\n\n\n__inline__ __device__\nfloat blockReduceSum(float val)\n{\n  static __shared__ float shared[32]; \n  int lane = threadIdx.x & 0x1f; \n  int wid = threadIdx.x >> 5;  \n\n  val = warpReduceSum(val);\n\n  if(lane == 0)\n    shared[wid] = val;\n\n  __syncthreads();\n\n\n  val = (threadIdx.x < (blockDim.x >> 5 )) ? shared[lane] : 0;\n  val = warpReduceSum(val);\n\n  return val;\n}\n\n__inline__ __device__\nfloat warpReduceMax(float val)\n{\n  for(int mask = 16; mask > 0; mask >>= 1)\n    val = max(val, __shfl_xor(val, mask, 32));\n  return val;\n}\n\n\n\n__inline__ __device__\nfloat blockReduceMax(float val)\n{\n  static __shared__ float shared[32]; \n  int lane = threadIdx.x & 0x1f; \n\n  int wid = threadIdx.x >> 5;  \n\n\n  val = warpReduceMax(val); \n\n\n  if(lane == 0) \n\n    shared[wid] = val;\n\n  __syncthreads();\n\n  val = (threadIdx.x < (blockDim.x >> 5)) ? shared[lane] : 0;\n  val = warpReduceMax(val);\n\n  return val;\n}\n\n\n__global__\nvoid mha (\n   const float *__restrict__ q, \n   const float *__restrict__ k, \n   const float *__restrict__ v, \n   const int beam_size, \n   const int n_steps, \n   const int qk_col, \n   const int v_col, \n   const int nhead, \n   const float scale,\n   const int THRESHOLD,\n   float *__restrict__ dst)\n{\n  \n\n  int dim_per_head = qk_col / nhead;\n  int candidate_id = blockIdx.x / nhead;\n  int head_id = blockIdx.x % nhead;\n\n  \n\n  extern __shared__ float buffer[];\n  float *sq = buffer;\n  float *logits = buffer + dim_per_head;\n\n\n  \n\n  int pos = candidate_id * qk_col + head_id * dim_per_head + threadIdx.x;\n  if(threadIdx.x < dim_per_head) sq[threadIdx.x] = q[pos];\n  __syncthreads();\n\n  \n\n\n  float summ = 0.f;\n  if(threadIdx.x < n_steps)\n  {   \n    const float *k2 = k + candidate_id * qk_col * n_steps + head_id * dim_per_head + threadIdx.x * qk_col;\n    for (int i = 0; i < dim_per_head; i++)\n      summ += sq[i] * k2[i];\n    summ *= scale;\n  }   \n\n  \n\n\n  __shared__ float s_max_val;\n  __shared__ float s_sum;\n\n  float local_i = threadIdx.x < n_steps ? summ : -1e-20f;\n  float local_o;\n\n  float max_val = blockReduceMax(local_i);\n\n  if(threadIdx.x == 0)\n    s_max_val = max_val;\n  __syncthreads();\n\n  local_i -= s_max_val;\n\n  if(local_i < -THRESHOLD) local_i = -THRESHOLD;\n\n  local_o = expf(local_i);\n\n  float val = (threadIdx.x < n_steps) ? local_o : 0.f;\n  val = blockReduceSum(val);\n  if(threadIdx.x == 0) s_sum = val;\n  __syncthreads();\n\n  if(threadIdx.x < n_steps) logits[threadIdx.x] = local_o / s_sum;\n  __syncthreads();\n\n  \n\n  summ = 0.f;\n  if(threadIdx.x < dim_per_head)\n  {\n    int tid = candidate_id * v_col * n_steps + head_id * dim_per_head + threadIdx.x;\n    for(int i = 0; i < n_steps; ++i)\n      summ += logits[i] * v[tid + i * v_col];\n    dst[candidate_id * v_col + head_id * dim_per_head + threadIdx.x] = summ;\n  }\n}\n\n\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  \n\n  const int beamsize = 4;\n  const int nhead = 16;\n  const int dim_feature = nhead * 256;\n  const int n_steps = 9;\n\n  \n\n  const float scaler = sqrtf(nhead * 1.f / dim_feature);\n\n  \n\n  const int qk_col = dim_feature;\n  const int v_col = dim_feature;\n  const int THRESHOLD = 64;\n\n  const int q_size = beamsize * dim_feature;\n  const int q_size_bytes = sizeof(float) * q_size;\n\n  const int k_size = beamsize * dim_feature * n_steps;\n  const int k_size_bytes = sizeof(float) * k_size;\n\n  const int v_size = beamsize * dim_feature * n_steps;\n  const int v_size_bytes = sizeof(float) * v_size;\n\n  float *dq, *dk, *dv, *dst;\n  hipMalloc((void**)&dq, q_size_bytes);\n  hipMalloc((void**)&dk, k_size_bytes);\n  hipMalloc((void**)&dv, v_size_bytes);\n  hipMalloc((void**)&dst, q_size_bytes);\n\n  float *hq = (float*)malloc(q_size_bytes);\n  float *hk = (float*)malloc(k_size_bytes);\n  float *hv = (float*)malloc(v_size_bytes);\n  float *h_dst = (float*)malloc(q_size_bytes);\n\n  \n\n  for(int i = 0; i < q_size; ++i)\n    hq[i] = rand() / (float)RAND_MAX;\n\n  for(int i = 0; i < k_size; ++i)\n    hk[i] = rand() / (float)RAND_MAX;\n\n  for(int i = 0; i < v_size; ++i)\n    hv[i] = rand() / (float)RAND_MAX;\n\n  hipMemcpy(dq, hq, q_size_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(dk, hk, k_size_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(dv, hv, v_size_bytes, hipMemcpyHostToDevice);\n\n  dim3 grid(nhead * beamsize);\n  dim3 block(qk_col / nhead);\n\n  const int shared_size = sizeof(float) * ((qk_col / nhead) + n_steps);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(mha, grid, block, shared_size, 0 , dq, dk, dv,\n      beamsize, n_steps, qk_col, v_col, nhead, scaler, THRESHOLD, dst);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(h_dst, dst, q_size_bytes, hipMemcpyDeviceToHost);\n\n  hipFree(dq);\n  hipFree(dk);\n  hipFree(dv);\n  hipFree(dst);\n\n  \n\n  for (int i = 0; i < beamsize - 1; i++) {\n    float sum = 0.f;\n    for (int j = 0; j < dim_feature; j++) {\n       float d = h_dst[i * dim_feature + j] -\n                 h_dst[(i + 1) * dim_feature + j];\n       sum += d * d;\n    }\n    printf(\"Distance between beams %d and %d: %f\\n\", i, i+1, sqrtf(sum));\n  }\n\n  free(hq);\n  free(hk);\n  free(hv);\n  free(h_dst);\n\n  return 0;\n}\n"}}
{"kernel_name": "attentionMultiHead", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cstdio>\n#include <cstdlib>\n#include <cmath>\n#include <sycl/sycl.hpp>\n\ninline\nfloat warpReduceSum(float val, sycl::nd_item<1> &item)\n{\n  auto sg = item.get_sub_group();\n  for(int mask = 16; mask > 0; mask >>= 1)\n    val += sg.shuffle_xor(val, mask);\n  return val;\n}\n\n\n\ninline\nfloat blockReduceSum(float val, sycl::nd_item<1> &item, float *shared)\n{\n  int lid = item.get_local_id(0);\n  int lane = lid & 0x1f;\n  int wid = lid >> 5;\n\n  val = warpReduceSum(val, item);\n\n  if(lane == 0)\n    shared[wid] = val;\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  val = (lid < (item.get_local_range(0) >> 5)) ? shared[lane] : 0;\n  val = warpReduceSum(val, item);\n\n  return val;\n}\n\ninline\nfloat warpReduceMax(float val, sycl::nd_item<1> &item)\n{\n  auto sg = item.get_sub_group();\n  for(int mask = 16; mask > 0; mask >>= 1)\n    val = sycl::max(val, sg.shuffle_xor(val, mask));\n  return val;\n}\n\n\n\ninline\nfloat blockReduceMax(float val, sycl::nd_item<1> &item, float *shared)\n{\n  int lid = item.get_local_id(0);\n  int lane = lid & 0x1f; \n\n  int wid = lid >> 5;    \n\n\n  val = warpReduceMax(val, item); \n\n\n  if(lane == 0) \n\n    shared[wid] = val;\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  val = (lid < (item.get_local_range(0) >> 5)) ? shared[lane] : 0;\n  val = warpReduceMax(val, item);\n\n  return val;\n}\n\nvoid mha (\n   const float *__restrict q, \n   const float *__restrict k, \n   const float *__restrict v, \n   const int beam_size, \n   const int n_steps, \n   const int qk_col, \n   const int v_col, \n   const int nhead, \n   const float scale,\n   const int THRESHOLD,\n   float *__restrict dst,\n   sycl::nd_item<1> &item,\n   float *shared,\n   float &s_max_val,\n   float &s_sum)\n{\n  \n\n  int gid = item.get_group(0);\n  int lid = item.get_local_id(0);\n  int dim_per_head = qk_col / nhead;\n  int candidate_id = gid / nhead;\n  int head_id = gid % nhead;\n\n  \n\n  float *sq = shared;\n  float *logits = shared + dim_per_head;\n\n  \n\n  int pos = candidate_id * qk_col + head_id * dim_per_head + lid;\n  if (lid < dim_per_head) sq[lid] = q[pos];\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n\n  float summ = 0.f;\n  if (lid < n_steps)\n  {\n    const float* k2 = k + candidate_id * qk_col * n_steps + head_id * dim_per_head + lid * qk_col;\n    for (int i = 0; i < dim_per_head; i++)\n      summ += sq[i] * k2[i];\n    summ *= scale;\n  }   \n\n  \n\n\n  float local_i = lid < n_steps ? summ : -1e-20f;\n  float local_o;\n\n  float max_val = blockReduceMax(local_i, item, shared);\n\n  if (lid == 0)\n    s_max_val = max_val;\n  item.barrier(sycl::access::fence_space::local_space);\n\n  local_i -= s_max_val;\n\n  if(local_i < -THRESHOLD) local_i = -THRESHOLD;\n\n  local_o = sycl::exp(local_i);\n\n  float val = (lid < n_steps) ? local_o : 0.f;\n  val = blockReduceSum(val, item, shared);\n  if (lid == 0) s_sum = val;\n  item.barrier(sycl::access::fence_space::local_space);\n\n  if (lid < n_steps) logits[lid] = local_o / s_sum;\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  summ = 0.f;\n  if (lid < dim_per_head)\n  {\n    int tid = candidate_id * v_col * n_steps + head_id * dim_per_head + lid;\n    for(int i = 0; i < n_steps; ++i)\n      summ += logits[i] * v[tid + i * v_col];\n    dst[candidate_id * v_col + head_id * dim_per_head + lid] = summ;\n  }\n}\n\n\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  \n\n  const int beamsize = 4;\n  const int nhead = 16;\n  const int dim_feature = nhead * 256;\n  const int n_steps = 9;\n\n  \n\n  const float scaler = sqrtf(nhead * 1.f / dim_feature);\n\n  \n\n  const int qk_col = dim_feature;\n  const int v_col = dim_feature;\n  const int THRESHOLD = 64;\n\n  const int q_size = beamsize * dim_feature;\n  const int q_size_bytes = sizeof(float) * q_size;\n\n  const int k_size = beamsize * dim_feature * n_steps;\n  const int k_size_bytes = sizeof(float) * k_size;\n\n  const int v_size = beamsize * dim_feature * n_steps;\n  const int v_size_bytes = sizeof(float) * v_size;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *dq = (float *)sycl::malloc_device(q_size_bytes, q);\n  float *dk = (float *)sycl::malloc_device(k_size_bytes, q);\n  float *dv = (float *)sycl::malloc_device(v_size_bytes, q);\n  float *dst = (float *)sycl::malloc_device(q_size_bytes, q);\n\n  float *hq = (float*)malloc(q_size_bytes);\n  float *hk = (float*)malloc(k_size_bytes);\n  float *hv = (float*)malloc(v_size_bytes);\n  float *h_dst = (float*)malloc(q_size_bytes);\n\n  \n\n  for(int i = 0; i < q_size; ++i)\n    hq[i] = rand() / (float)RAND_MAX;\n\n  for(int i = 0; i < k_size; ++i)\n    hk[i] = rand() / (float)RAND_MAX;\n\n  for(int i = 0; i < v_size; ++i)\n    hv[i] = rand() / (float)RAND_MAX;\n\n  q.memcpy(dq, hq, q_size_bytes);\n  q.memcpy(dk, hk, k_size_bytes);\n  q.memcpy(dv, hv, v_size_bytes);\n\n  sycl::range<1> lws (qk_col / nhead);\n  sycl::range<1> gws (nhead * beamsize * qk_col / nhead);\n\n  const int shared_size = ((qk_col / nhead) + n_steps);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      sycl::local_accessor<float, 1> shared(sycl::range<1>(shared_size), cgh);\n      sycl::local_accessor<float, 0> s_max_val(cgh);\n      sycl::local_accessor<float, 0> s_sum(cgh);\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n        [[sycl::reqd_sub_group_size(32)]] {\n        mha(dq, dk, dv, beamsize, n_steps, qk_col, v_col, nhead, scaler,\n            THRESHOLD, dst, item, shared.get_pointer(), s_max_val, s_sum);\n        });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(h_dst, dst, q_size_bytes).wait();\n\n  sycl::free(dq, q);\n  sycl::free(dk, q);\n  sycl::free(dv, q);\n  sycl::free(dst, q);\n\n  \n\n  for (int i = 0; i < beamsize - 1; i++) {\n    float sum = 0.f;\n    for (int j = 0; j < dim_feature; j++) {\n       float d = h_dst[i * dim_feature + j] -\n                 h_dst[(i + 1) * dim_feature + j];\n       sum += d * d;\n    }\n    printf(\"Distance between beams %d and %d: %f\\n\", i, i+1, sqrtf(sum));\n  }\n\n  free(hq);\n  free(hk);\n  free(hv);\n  free(h_dst);\n\n  return 0;\n}\n"}}
{"kernel_name": "b+tree", "parallel_api": "omp", "code": {"main.c": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <stdio.h>                  \n\n#include <limits.h>                  \n\n#include <math.h>                  \n\n#include <string.h>                  \n\n\n\n\n\n\n\n\n\n#include \"./common.h\"                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include \"./util/timer/timer.h\"            \n\n#include \"./util/num/num.h\"              \n\n\n\n\n\n\n\n\n\n#include \"./kernel/kernel_wrapper.h\"    \n\n#include \"./kernel/kernel2_wrapper.h\"    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nknode *knodes;\nrecord *krecords;\nchar *mem;\nlong freeptr;\nlong malloc_size;\nlong size;\nlong maxheight;\n\n\n\nint order = DEFAULT_ORDER;\n\n\n\nnode *tree_queue = NULL;\n\n\n\nbool verbose_output = false;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  void \nlist_init(  list_t *l,\n    int32_t (*compare)(const void *key, \n      const void *with),\n    void (*datum_delete)(void *))\n{\n  l->head = l->tail = NULL;\n  l->length = 0;\n  l->compare = compare;\n  l->datum_delete = datum_delete;\n}\n\n  void \nlist_delete(list_t *l)\n{\n\n  list_item_t *li, *del;\n\n  for (li = l->head; li;) {\n\n    del = li;\n    li = li->next;\n    list_item_delete(del, l->datum_delete);\n  }\n\n  l->head = l->tail = NULL;\n  l->length = 0;\n}\n\n  void \nlist_reset(list_t *l)\n{\n  list_delete(l);\n}\n\n  void \nlist_insert_item_head(  list_t *l, \n    list_item_t *i)\n{\n  if (l->head) {\n    i->next = l->head;\n    l->head->pred = i;\n    l->head = i;\n    l->head->pred = NULL;\n  } else {\n    l->head = l->tail = i;\n    i->next = i->pred = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_item_tail(  list_t *l, \n    list_item_t *i)\n{\n  if (l->head) {\n    l->tail->next = i;\n    i->pred = l->tail;\n    i->next = NULL;\n    l->tail = i;\n  } else {\n    l->head = l->tail = i;\n    i->next = i->pred = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_item_before(list_t *l, \n    list_item_t *next, \n    list_item_t *i)\n{\n  \n\n  \n\n  if (l->head == next) {\n    i->next = next;\n    i->pred = NULL;\n    l->head = i;\n    next->pred = i;\n  } else {\n    i->next = next;\n    i->pred = next->pred;\n    next->pred->next = i;\n    next->pred = i;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_item_after(  list_t *l, \n    list_item_t *pred, \n    list_item_t *i)\n{\n  \n\n  \n\n  if (l->tail == pred) {\n    i->pred = pred;\n    i->next = NULL;\n    l->tail = i;\n    pred->next = i;\n  } else {\n    i->pred = pred;\n    i->next = pred->next;\n    pred->next->pred = i;\n    pred->next = i;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_item_sorted(list_t *l, \n    list_item_t *i)\n{\n  list_item_t *itr;\n\n  if (l->head) {\n    for (itr = l->head; itr && l->compare(list_item_get_datum(i),\n          list_item_get_datum(itr)) < 0;\n        itr = itr->next)\n      ;\n    if (itr) {\n      i->next = itr;\n      i->pred = itr->pred;\n      itr->pred = i;\n      i->pred->next = i;\n    } else {\n      l->tail->next = i;\n      i->pred = l->tail;\n      i->next = NULL;\n      l->tail = i;\n    }\n  } else {\n    l->head = l->tail = i;\n    i->pred = i->next = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_head(  list_t *l, \n    void *v)\n{\n  list_item_t *i;\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n  if (l->head) {\n    i->next = l->head;\n    l->head->pred = i;\n    l->head = i;\n    l->head->pred = NULL;\n  } else {\n    l->head = l->tail = i;\n    i->next = i->pred = NULL;\n  }\n  l->length++;\n\n}\n\n  void \nlist_insert_tail(  list_t *l, \n    void *v)\n{\n  list_item_t *i;\n\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n  if (l->head) {\n    l->tail->next = i;\n    i->pred = l->tail;\n    i->next = NULL;\n    l->tail = i;\n  } else {\n    l->head = l->tail = i;\n    i->next = i->pred = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_before(  list_t *l, \n    list_item_t *next, \n    void *v)\n{\n  list_item_t *i;\n\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n\n  \n\n  \n\n  if (l->head == next) {\n    i->next = next;\n    i->pred = NULL;\n    l->head = i;\n    next->pred = i;\n  } else {\n    i->next = next;\n    i->pred = next->pred;\n    next->pred->next = i;\n    next->pred = i;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_after(  list_t *l, \n    list_item_t *pred, \n    void *v)\n{\n  list_item_t *i;\n\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n\n  \n\n  \n\n  if (l->tail == pred) {\n    i->pred = pred;\n    i->next = NULL;\n    l->tail = i;\n    pred->next = i;\n  } else {\n    i->pred = pred;\n    i->next = pred->next;\n    pred->next->pred = i;\n    pred->next = i;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_sorted(  list_t *l, \n    void *v)\n{\n  list_item_t *itr;\n  list_item_t *i;\n\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n\n\n  if (l->head) {\n    for (itr = l->head; itr && l->compare(list_item_get_datum(i),\n          list_item_get_datum(itr)) < 0;\n        itr = itr->next)\n      ;\n    if (itr) {\n      i->next = itr;\n      i->pred = itr->pred;\n      itr->pred = i;\n      i->pred->next = i;\n    } else {\n      l->tail->next = i;\n      i->pred = l->tail;\n      i->next = NULL;\n      l->tail = i;\n    }\n  } else {\n    l->head = l->tail = i;\n    i->pred = i->next = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_remove_item(  list_t *l, \n    list_item_t *i)\n{\n  if (i == l->head) {\n    l->head = l->head->next;\n    if (l->head)\n      l->head->pred = NULL;\n    else\n      l->tail = NULL;\n  } else if (i == l->tail) {\n    l->tail = l->tail->pred;\n    l->tail->next = NULL;\n  } else {\n    i->pred->next = i->next;\n    i->next->pred = i->pred;\n  }\n  l->length--;\n  list_item_delete(i, l->datum_delete);\n}\n\n  void \nlist_remove_head(list_t *l)\n{\n  list_remove_item(l, l->head);\n}\n\n  void \nlist_remove_tail(list_t *l)\n{\n  list_remove_item(l, l->tail);\n}\n\n  list_item_t* \nlist_find_item(  list_t *l, \n    void *datum)\n{\n  list_item_t *li;\n\n  for (li = l->head; li && l->compare(datum, list_item_get_datum(li));\n      li = li->next)\n    ;\n\n  return li;\n}\n\n  list_item_t* \nlist_get_head_item(list_t *l)\n{\n  return l->head;\n}\n\n  list_item_t* \nlist_get_tail_item(list_t *l)\n{\n  return l->tail;\n}\n\n  void* \nlist_find(  list_t *l, \n    void *datum)\n{\n  list_item_t *li;\n\n  for (li = l->head; li && l->compare(datum, list_item_get_datum(li));\n      li = li->next)\n    ;\n\n  return li ? li->datum : NULL;\n}\n\n  void* \nlist_get_head(list_t *l)\n{\n  return l->head ? l->head->datum : NULL;\n}\n\n  void* \nlist_get_tail(list_t *l)\n{\n  return l->tail ? l->tail->datum : NULL;\n}\n\n  uint32_t \nlist_get_length(list_t *l)\n{\n  return l->length;\n}\n\n  bool \nlist_is_empty(list_t *l)\n{\n  return (l->length == 0);\n}\n\n  bool \nlist_not_empty(list_t *l)\n{\n  return (l->length != 0);\n}\n\n  void \nlist_visit_items(  list_t *l, \n    void (*visitor)(void *v))\n{\n  list_item_t *li;\n\n  for (li = l->head; li; li = li->next)\n    visitor(list_item_get_datum(li));\n}\n\n  void \nlist_item_init(  list_item_t *li, \n    void *datum)\n{\n  li->pred = li->next = NULL;\n  li->datum = datum;\n}\n\n  void \nlist_item_delete(  list_item_t *li, \n    void (*datum_delete)(void *datum))\n{\n  if (datum_delete) {\n    datum_delete(li->datum);\n  }\n\n  free(li);\n}\n\n  void *\nlist_item_get_datum(list_item_t *li)\n{\n  return li->datum;\n}\n\n  void \nlist_iterator_init(  list_t *l, \n    list_iterator_t *li)\n{\n  *li = l ? l->head : NULL;\n}\n\n  void \nlist_iterator_delete(list_iterator_t *li)\n{\n  *li = NULL;\n}\n\n  void \nlist_iterator_next(list_iterator_t *li)\n{\n  if (*li)\n    *li = (*li)->next;\n}\n\n  void \nlist_iterator_prev(list_iterator_t *li)\n{\n  if (*li)\n    *li = (*li)->pred;\n}\n\n  void *\nlist_iterator_get_datum(list_iterator_t *li)\n{\n  return *li ? (*li)->datum : NULL;\n}\n\n  bool \nlist_iterator_is_valid(list_iterator_t *li)\n{\n  return (*li != NULL);\n}\n\n  void \nlist_reverse_iterator_init(  list_t *l, \n    list_reverse_iterator_t *li)\n{\n  *li = l ? l->tail : NULL;\n}\n\n  void \nlist_reverse_iterator_delete(list_reverse_iterator_t *li)\n{\n  *li = NULL;\n}\n\n  void \nlist_reverse_iterator_next(list_reverse_iterator_t *li)\n{\n  if (*li)\n    *li = (*li)->pred;\n}\n\n  void \nlist_reverse_iterator_prev(list_reverse_iterator_t *li)\n{\n  if (*li)\n    *li = (*li)->next;\n}\n\n  void *\nlist_reverse_iterator_get_datum(list_reverse_iterator_t *li)\n{\n  return *li ? (*li)->datum : NULL;\n}\n\n  bool \nlist_reverse_iterator_is_valid(list_reverse_iterator_t *li)\n{\n  return (li != NULL);\n}\n\n\n\n\n\n\n\n\n\n\n  void *\nkmalloc(int size)\n{\n\n  \n\n  void * r = (void *)freeptr;\n  freeptr+=size;\n  if(freeptr > malloc_size+(long)mem){\n    printf(\"Memory Overflow\\n\");\n    exit(1);\n  }\n  return r;\n}\n\n\n\n  long \ntransform_to_cuda(  node * root, \n    bool verbose)\n{\n\n  struct timeval one,two;\n  double time;\n  gettimeofday (&one, NULL);\n  long max_nodes = (long)(pow(order,log(size)/log(order/2.0)-1) + 1);\n  malloc_size = size*sizeof(record) + max_nodes*sizeof(knode); \n  mem = (char*)malloc(malloc_size);\n  if(mem==NULL){\n    printf(\"Initial malloc error\\n\");\n    exit(1);\n  }\n  freeptr = (long)mem;\n\n  krecords = (record * )kmalloc(size*sizeof(record));\n  \n\n  knodes = (knode *)kmalloc(max_nodes*sizeof(knode));\n  \n\n\n  tree_queue = NULL;\n  enqueue(root);\n  node * n;\n  knode * k;\n  int i;\n  long nodeindex = 0;\n  long recordindex = 0;\n  long queueindex = 0;\n  knodes[0].location = nodeindex++;\n\n  while( tree_queue != NULL ) {\n    n = dequeue();\n    k = &knodes[queueindex];\n    k->location = queueindex++;\n    k->is_leaf = n->is_leaf;\n    k->num_keys = n->num_keys+2;\n    \n\n    k->keys[0]=INT_MIN; \n    k->keys[k->num_keys-1]=INT_MAX;\n    for(i=k->num_keys; i < order; i++)k->keys[i]=INT_MAX;\n    if(!k->is_leaf){\n      k->indices[0]=nodeindex++;\n      \n\n      \n\n      \n\n      for(i=1;i<k->num_keys-1;i++){\n        k->keys[i] = n->keys[i-1];\n        enqueue((node * )n->pointers[i-1]);\n        k->indices[i] = nodeindex++;\n        \n\n        \n\n        \n\n        \n\n      }\n      \n\n      enqueue((node * )n->pointers[i-1]);\n    }\n    else{\n      k->indices[0]=0;\n      for(i=1;i<k->num_keys-1;i++){\n        k->keys[i] = n->keys[i-1];\n        krecords[recordindex].value=((record *)n->pointers[i-1])->value;\n        k->indices[i] = recordindex++;\n        \n\n        \n\n        \n\n      }\n    }\n\n    k->indices[k->num_keys-1]=queueindex;\n    \n\n    \n\n    \n\n\n    if(verbose){\n      printf(\"Successfully created knode with index %d\\n\", k->location);\n      printf(\"Is Leaf: %d, Num Keys: %d\\n\", k->is_leaf, k->num_keys);\n      printf(\"Pointers: \");\n      for(i=0;i<k->num_keys;i++)\n        printf(\"%d | \", k->indices[i]);\n      printf(\"\\nKeys: \");\n      for(i=0;i<k->num_keys;i++)\n        printf(\"%d | \", k->keys[i]);\n      printf(\"\\n\\n\");\n    }\n  }\n  long mem_used = size*sizeof(record)+(nodeindex)*sizeof(knode);\n  if(verbose){\n    for(i = 0; i < size; i++)\n      printf(\"%d \", krecords[i].value);\n    printf(\"\\nNumber of records = %ld, sizeof(record)=%lu, total=%lu\\n\",size,sizeof(record),size*sizeof(record));\n    printf(\"Number of knodes = %ld, sizeof(knode)=%lu, total=%lu\\n\",nodeindex,sizeof(knode),(nodeindex)*sizeof(knode));\n    printf(\"\\nDone Transformation. Mem used: %ld\\n\", mem_used);\n  }\n  gettimeofday (&two, NULL);\n  double oneD = one.tv_sec + (double)one.tv_usec * .000001;\n  double twoD = two.tv_sec + (double)two.tv_usec * .000001;\n  time = twoD-oneD;\n  printf(\"Tree transformation took %f\\n\", time);\n\n  return mem_used;\n\n}\n\n\n\n  list_t *\nfindRange(  node * root, \n    int start, \n    int end) \n{\n\n  int i;\n  node * c = find_leaf( root, start, false );\n\n  if (c == NULL) return NULL;\n\n  list_t * retList = (list_t *)malloc(sizeof(list_t));\n  list_init(retList,NULL,NULL);\n\n  int counter = 0;\n  bool cont = true;\n  while(cont && c!=0){\n    cont = false;\n    for(i = 0;i  < c->num_keys;i++){\n      if(c->keys[i] >= start && c->keys[i] <= end){\n        \n\n        counter++;\n        cont = true;\n      }else{\n        cont = false;\n        break;\n      }\n    }\n    c = (node *)c->pointers[order-1];\n  }\n  return retList;\n}\n\n\n\n  void \nusage_1( void ) \n{\n\n  printf(\"B+ Tree of Order %d.\\n\", order);\n  printf(\"\\tAmittai Aviram -- amittai.aviram@yale.edu  Version %s\\n\", Version);\n  printf(\"\\tfollowing Silberschatz, Korth, Sidarshan, Database Concepts, 5th ed.\\n\\n\");\n  printf(\"To build a B+ tree of a different order, start again and enter the order\\n\");\n  printf(\"as an integer argument:  bpt <order>.  \");\n  printf(\"3 <= order <=20\\n\");\n  printf(\"To start with input from a file of newline-delimited integers, start again and enter\\n\");\n  printf(\"the order followed by the filename:  bpt <order> <inputfile>.\\n\");\n\n}\n\n\n\n  void \nusage_2( void ) \n{\n\n  printf(\"Enter any of the following commands after the prompt > :\\n\");\n  printf(\"\\ti <k>  -- Insert <k> (an integer) as both key and value).\\n\");\n  printf(\"\\tf <k>  -- Find the value under key <k>.\\n\");\n  printf(\"\\tp <k> -- Print the path from the root to key k and its associated value.\\n\");\n  printf(\"\\td <k>  -- Delete key <k> and its associated value.\\n\");\n  printf(\"\\tx -- Destroy the whole tree.  Start again with an empty tree of the same order.\\n\");\n  printf(\"\\tt -- Print the B+ tree.\\n\");\n  printf(\"\\tl -- Print the keys of the leaves (bottom row of the tree).\\n\");\n  printf(\"\\tv -- Toggle output of pointer addresses (\\\"verbose\\\") in tree and leaves.\\n\");\n  printf(\"\\tq -- Quit. (Or use Ctl-D.)\\n\");\n  printf(\"\\t? -- Print this help message.\\n\");\n}\n\n\n\n  void \nenqueue( node* new_node ) \n{\n  node * c;\n  if (tree_queue == NULL) {\n    tree_queue = new_node;\n    tree_queue->next = NULL;\n  }\n  else {\n    c = tree_queue;\n    while(c->next != NULL) {\n      c = c->next;\n    }\n    c->next = new_node;\n    new_node->next = NULL;\n  }\n}\n\n\n\n  node *\ndequeue( void ) \n{\n  node * n = tree_queue;\n  tree_queue = tree_queue->next;\n  n->next = NULL;\n  return n;\n}\n\n\n\n  void \nprint_leaves( node* root ) \n{\n  int i;\n  node * c = root;\n  if (root == NULL) {\n    printf(\"Empty tree.\\n\");\n    return;\n  }\n  while (!c->is_leaf)\n    c = (node *) c->pointers[0];\n  while (true) {\n    for (i = 0; i < c->num_keys; i++) {\n      if (verbose_output)\n        \n\n        printf(\"%d \", c->keys[i]);\n    }\n    if (verbose_output)\n      \n\n      if (c->pointers[order - 1] != NULL) {\n        printf(\" | \");\n        c = (node *) c->pointers[order - 1];\n      }\n      else\n        break;\n  }\n  printf(\"\\n\");\n}\n\n\n\n  int \nheight( node* root ) \n{\n  int h = 0;\n  node * c = root;\n  while (!c->is_leaf) {\n    c = (node *) c->pointers[0];\n    h++;\n  }\n  return h;\n}\n\n\n\n  int \npath_to_root( node* root, node* child ) \n{\n  int length = 0;\n  node * c = child;\n  while (c != root) {\n    c = c->parent;\n    length++;\n  }\n  return length;\n}\n\n\n\n  void \nprint_tree( node* root ) \n{\n\n  node * n = NULL;\n  int i = 0;\n  int rank = 0;\n  int new_rank = 0;\n\n  if (root == NULL) {\n    printf(\"Empty tree.\\n\");\n    return;\n  }\n  tree_queue = NULL;\n  enqueue(root);\n  while( tree_queue != NULL ) {\n    n = dequeue();\n    if (n->parent != NULL && n == n->parent->pointers[0]) {\n      new_rank = path_to_root( root, n );\n      if (new_rank != rank) {\n        rank = new_rank;\n        printf(\"\\n\");\n      }\n    }\n    if (verbose_output) \n      printf(\"(%x)\", n);\n    for (i = 0; i < n->num_keys; i++) {\n      if (verbose_output)\n        printf(\"%x \", n->pointers[i]);\n      printf(\"%d \", n->keys[i]);\n    }\n    if (!n->is_leaf)\n      for (i = 0; i <= n->num_keys; i++)\n        enqueue((node *) n->pointers[i]);\n    if (verbose_output) {\n      if (n->is_leaf) \n        printf(\"%x \", n->pointers[order - 1]);\n      else\n        printf(\"%x \", n->pointers[n->num_keys]);\n    }\n    printf(\"| \");\n  }\n  printf(\"\\n\");\n}\n\n\n\n  node *\nfind_leaf( node* root, int key, bool verbose ) \n{\n\n  int i = 0;\n  node * c = root;\n  if (c == NULL) {\n    if (verbose) \n      printf(\"Empty tree.\\n\");\n    return c;\n  }\n  while (!c->is_leaf) {\n    if (verbose) {\n      printf(\"[\");\n      for (i = 0; i < c->num_keys - 1; i++)\n        printf(\"%d \", c->keys[i]);\n      printf(\"%d] \", c->keys[i]);\n    }\n    i = 0;\n    while (i < c->num_keys) {\n      if (key >= c->keys[i]) \n        i++;\n      else \n        break;\n    }\n    if (verbose)\n      printf(\"%d ->\\n\", i);\n    c = (node *)c->pointers[i];\n  }\n  if (verbose) {\n    printf(\"Leaf [\");\n    for (i = 0; i < c->num_keys - 1; i++)\n      printf(\"%d \", c->keys[i]);\n    printf(\"%d] ->\\n\", c->keys[i]);\n  }\n  return c;\n\n}\n\n\n\n  record *\nfind( node* root, int key, bool verbose ) \n{\n\n  int i = 0;\n  node * c = find_leaf( root, key, verbose );\n  if (c == NULL) \n    return NULL;\n  for (i = 0; i < c->num_keys; i++)\n    if (c->keys[i] == key) \n      break;\n  if (i == c->num_keys) \n    return NULL;\n  else\n    return (record *)c->pointers[i];\n\n}\n\n\n\n  int \ncut( int length ) \n{\n  if (length % 2 == 0)\n    return length/2;\n  else\n    return length/2 + 1;\n}\n\n\n\n\n\n\n\n\n\n\n  record *\nmake_record(int value) \n{\n  record * new_record = (record *)malloc(sizeof(record));\n  if (new_record == NULL) {\n    perror(\"Record creation.\");\n    exit(EXIT_FAILURE);\n  }\n  else {\n    new_record->value = value;\n  }\n  return new_record;\n}\n\n\n\n  node *\nmake_node( void ) \n{\n  node * new_node;\n  new_node = (node *) malloc(sizeof(node));\n  if (new_node == NULL) {\n    perror(\"Node creation.\");\n    exit(EXIT_FAILURE);\n  }\n  new_node->keys = (int *) malloc( (order - 1) * sizeof(int) );\n  if (new_node->keys == NULL) {\n    perror(\"New node keys array.\");\n    exit(EXIT_FAILURE);\n  }\n  new_node->pointers = (void **) malloc( order * sizeof(void *) );\n  if (new_node->pointers == NULL) {\n    perror(\"New node pointers array.\");\n    exit(EXIT_FAILURE);\n  }\n  new_node->is_leaf = false;\n  new_node->num_keys = 0;\n  new_node->parent = NULL;\n  new_node->next = NULL;\n  return new_node;\n}\n\n\n\n  node *\nmake_leaf( void ) \n{\n  node* leaf = make_node();\n  leaf->is_leaf = true;\n  return leaf;\n}\n\n\n\n  int \nget_left_index(node* parent, node* left) \n{\n\n  int left_index = 0;\n  while (left_index <= parent->num_keys && \n      parent->pointers[left_index] != left)\n    left_index++;\n  return left_index;\n}\n\n\n\n  node *\ninsert_into_leaf( node* leaf, int key, record* pointer ) \n{\n\n  int i, insertion_point;\n\n  insertion_point = 0;\n  while (insertion_point < leaf->num_keys && leaf->keys[insertion_point] < key)\n    insertion_point++;\n\n  for (i = leaf->num_keys; i > insertion_point; i--) {\n    leaf->keys[i] = leaf->keys[i - 1];\n    leaf->pointers[i] = leaf->pointers[i - 1];\n  }\n  leaf->keys[insertion_point] = key;\n  leaf->pointers[insertion_point] = pointer;\n  leaf->num_keys++;\n  return leaf;\n}\n\n\n\n  node *\ninsert_into_leaf_after_splitting(  node* root, \n    node* leaf, \n    int key, \n    record* pointer) \n{\n\n  node * new_leaf;\n  int * temp_keys;\n  void ** temp_pointers;\n  int insertion_index, split, new_key, i, j;\n\n  new_leaf = make_leaf();\n\n  temp_keys = (int *) malloc( order * sizeof(int) );\n  if (temp_keys == NULL) {\n    perror(\"Temporary keys array.\");\n    exit(EXIT_FAILURE);\n  }\n\n  temp_pointers = (void **) malloc( order * sizeof(void *) );\n  if (temp_pointers == NULL) {\n    perror(\"Temporary pointers array.\");\n    exit(EXIT_FAILURE);\n  }\n\n  insertion_index = 0;\n  while (leaf->keys[insertion_index] < key && insertion_index < order - 1)\n    insertion_index++;\n\n  for (i = 0, j = 0; i < leaf->num_keys; i++, j++) {\n    if (j == insertion_index) j++;\n    temp_keys[j] = leaf->keys[i];\n    temp_pointers[j] = leaf->pointers[i];\n  }\n\n  temp_keys[insertion_index] = key;\n  temp_pointers[insertion_index] = pointer;\n\n  leaf->num_keys = 0;\n\n  split = cut(order - 1);\n\n  for (i = 0; i < split; i++) {\n    leaf->pointers[i] = temp_pointers[i];\n    leaf->keys[i] = temp_keys[i];\n    leaf->num_keys++;\n  }\n\n  for (i = split, j = 0; i < order; i++, j++) {\n    new_leaf->pointers[j] = temp_pointers[i];\n    new_leaf->keys[j] = temp_keys[i];\n    new_leaf->num_keys++;\n  }\n\n  free(temp_pointers);\n  free(temp_keys);\n\n  new_leaf->pointers[order - 1] = leaf->pointers[order - 1];\n  leaf->pointers[order - 1] = new_leaf;\n\n  for (i = leaf->num_keys; i < order - 1; i++)\n    leaf->pointers[i] = NULL;\n  for (i = new_leaf->num_keys; i < order - 1; i++)\n    new_leaf->pointers[i] = NULL;\n\n  new_leaf->parent = leaf->parent;\n  new_key = new_leaf->keys[0];\n\n  return insert_into_parent(root, leaf, new_key, new_leaf);\n}\n\n\n\n  node *\ninsert_into_node(  node* root, \n    node* n, \n    int left_index, \n    int key, \n    node* right) \n{\n\n  int i;\n\n  for (i = n->num_keys; i > left_index; i--) {\n    n->pointers[i + 1] = n->pointers[i];\n    n->keys[i] = n->keys[i - 1];\n  }\n  n->pointers[left_index + 1] = right;\n  n->keys[left_index] = key;\n  n->num_keys++;\n  return root;\n}\n\n\n\n  node *\ninsert_into_node_after_splitting(  node* root, \n    node* old_node, \n    int left_index, \n    int key, \n    node * right) \n{\n\n  int i, j, split, k_prime;\n  node * new_node, * child;\n  int * temp_keys;\n  node ** temp_pointers;\n\n  \n\n\n  temp_pointers = (node **) malloc( (order + 1) * sizeof(node *) );\n  if (temp_pointers == NULL) {\n    perror(\"Temporary pointers array for splitting nodes.\");\n    exit(EXIT_FAILURE);\n  }\n  temp_keys = (int *) malloc( order * sizeof(int) );\n  if (temp_keys == NULL) {\n    perror(\"Temporary keys array for splitting nodes.\");\n    exit(EXIT_FAILURE);\n  }\n\n  for (i = 0, j = 0; i < old_node->num_keys + 1; i++, j++) {\n    if (j == left_index + 1) j++;\n    temp_pointers[j] = (node *) old_node->pointers[i];\n  }\n\n  for (i = 0, j = 0; i < old_node->num_keys; i++, j++) {\n    if (j == left_index) j++;\n    temp_keys[j] = old_node->keys[i];\n  }\n\n  temp_pointers[left_index + 1] = right;\n  temp_keys[left_index] = key;\n\n  \n  \n  split = cut(order);\n  new_node = make_node();\n  old_node->num_keys = 0;\n  for (i = 0; i < split - 1; i++) {\n    old_node->pointers[i] = temp_pointers[i];\n    old_node->keys[i] = temp_keys[i];\n    old_node->num_keys++;\n  }\n  old_node->pointers[i] = temp_pointers[i];\n  k_prime = temp_keys[split - 1];\n  for (++i, j = 0; i < order; i++, j++) {\n    new_node->pointers[j] = temp_pointers[i];\n    new_node->keys[j] = temp_keys[i];\n    new_node->num_keys++;\n  }\n  new_node->pointers[j] = temp_pointers[i];\n  free(temp_pointers);\n  free(temp_keys);\n  new_node->parent = old_node->parent;\n  for (i = 0; i <= new_node->num_keys; i++) {\n    child = (node *) new_node->pointers[i];\n    child->parent = new_node;\n  }\n\n  \n\n\n  return insert_into_parent(root, old_node, k_prime, new_node);\n}\n\n\n\n  node *\ninsert_into_parent(  node* root, \n    node* left, \n    int key, \n    node* right) \n{\n\n  int left_index;\n  node * parent;\n\n  parent = left->parent;\n\n  \n\n\n  if (parent == NULL)\n    return insert_into_new_root(left, key, right);\n\n  \n\n\n  \n\n\n  left_index = get_left_index(parent, left);\n\n\n  \n\n\n  if (parent->num_keys < order - 1)\n    return insert_into_node(root, parent, left_index, key, right);\n\n  \n\n\n  return insert_into_node_after_splitting(root, parent, left_index, key, right);\n}\n\n\n\n  node *\ninsert_into_new_root(  node* left, \n    int key, \n    node* right) \n{\n\n  node * root = make_node();\n  root->keys[0] = key;\n  root->pointers[0] = left;\n  root->pointers[1] = right;\n  root->num_keys++;\n  root->parent = NULL;\n  left->parent = root;\n  right->parent = root;\n  return root;\n}\n\n\n\n  node *\nstart_new_tree(  int key, \n    record* pointer) \n{\n\n  node * root = make_leaf();\n  root->keys[0] = key;\n  root->pointers[0] = pointer;\n  root->pointers[order - 1] = NULL;\n  root->parent = NULL;\n  root->num_keys++;\n  return root;\n}\n\n\n\n  node *\ninsert(  node* root, \n    int key, \n    int value ) \n{\n\n  record* pointer;\n  node* leaf;\n\n  \n\n  if (find(root, key, false) != NULL)\n    return root;\n\n  \n\n  pointer = make_record(value);\n\n  \n\n  if (root == NULL) \n    return start_new_tree(key, pointer);\n\n  \n\n  leaf = find_leaf(root, key, false);\n\n  \n\n  if (leaf->num_keys < order - 1) {\n    leaf = insert_into_leaf(leaf, key, pointer);\n    return root;\n  }\n\n  \n\n  return insert_into_leaf_after_splitting(root, leaf, key, pointer);\n}\n\n\n\n\n\n\n\n\n\n\n  int \nget_neighbor_index( node* n ) \n{\n\n  int i;\n\n  \n\n  for (i = 0; i <= n->parent->num_keys; i++)\n    if (n->parent->pointers[i] == n)\n      return i - 1;\n\n  \n\n  printf(\"Search for nonexistent pointer to node in parent.\\n\");\n  \n\n  exit(EXIT_FAILURE);\n}\n\n\n\n  node* \nremove_entry_from_node(  node* n, \n    int key, \n    node * pointer) \n{\n\n  int i, num_pointers;\n\n  \n\n  i = 0;\n  while (n->keys[i] != key)\n    i++;\n  for (++i; i < n->num_keys; i++)\n    n->keys[i - 1] = n->keys[i];\n\n  \n\n  \n\n  num_pointers = n->is_leaf ? n->num_keys : n->num_keys + 1;\n  i = 0;\n  while (n->pointers[i] != pointer)\n    i++;\n  for (++i; i < num_pointers; i++)\n    n->pointers[i - 1] = n->pointers[i];\n\n\n  \n\n  n->num_keys--;\n\n  \n\n  \n\n  if (n->is_leaf)\n    for (i = n->num_keys; i < order - 1; i++)\n      n->pointers[i] = NULL;\n  else\n    for (i = n->num_keys + 1; i < order; i++)\n      n->pointers[i] = NULL;\n\n  return n;\n}\n\n\n\n  node* \nadjust_root(node* root) \n{\n\n  node * new_root;\n\n  \n\n\n  if (root->num_keys > 0)\n    return root;\n\n  \n\n\n  \n\n  \n\n  \n\n\n  if (!root->is_leaf) {\n    new_root = (node *) root->pointers[0];\n    new_root->parent = NULL;\n  }\n\n  \n\n  \n\n\n  else\n    new_root = NULL;\n\n  free(root->keys);\n  free(root->pointers);\n  free(root);\n\n  return new_root;\n}\n\n\n\n  node* \ncoalesce_nodes(  node* root, \n    node* n, \n    node* neighbor, \n    int neighbor_index, \n    int k_prime) \n{\n\n  int i, j, neighbor_insertion_index, n_start, n_end, new_k_prime;\n  node * tmp;\n  bool split;\n\n  \n\n\n  if (neighbor_index == -1) {\n    tmp = n;\n    n = neighbor;\n    neighbor = tmp;\n  }\n\n  \n\n\n  neighbor_insertion_index = neighbor->num_keys;\n\n  \n\n\n  split = false;\n\n  \n\n\n  if (!n->is_leaf) {\n\n    \n\n\n    neighbor->keys[neighbor_insertion_index] = k_prime;\n    neighbor->num_keys++;\n\n\n    \n\n\n    n_end = n->num_keys;\n\n    \n\n    n_start = 0; \n\n    if (n->num_keys + neighbor->num_keys >= order) {\n      split = true;\n      n_end = cut(order) - 2;\n    }\n\n    for (i = neighbor_insertion_index + 1, j = 0; j < n_end; i++, j++) {\n      neighbor->keys[i] = n->keys[j];\n      neighbor->pointers[i] = n->pointers[j];\n      neighbor->num_keys++;\n      n->num_keys--;\n      n_start++;\n    }\n\n    \n\n\n    neighbor->pointers[i] = n->pointers[j];\n\n    \n\n    if (split) {\n      new_k_prime = n->keys[n_start];\n      for (i = 0, j = n_start + 1; i < n->num_keys; i++, j++) {\n        n->keys[i] = n->keys[j];\n        n->pointers[i] = n->pointers[j];\n      }\n      n->pointers[i] = n->pointers[j];\n      n->num_keys--;\n    }\n\n    \n\n\n    for (i = 0; i < neighbor->num_keys + 1; i++) {\n      tmp = (node *)neighbor->pointers[i];\n      tmp->parent = neighbor;\n    }\n  }\n\n  \n\n\n  else {\n    for (i = neighbor_insertion_index, j = 0; j < n->num_keys; i++, j++) {\n      neighbor->keys[i] = n->keys[j];\n      neighbor->pointers[i] = n->pointers[j];\n      neighbor->num_keys++;\n    }\n    neighbor->pointers[order - 1] = n->pointers[order - 1];\n  }\n\n  if (!split) {\n    root = delete_entry(root, n->parent, k_prime, n);\n    free(n->keys);\n    free(n->pointers);\n    free(n); \n  }\n  else\n    for (i = 0; i < n->parent->num_keys; i++)\n      if (n->parent->pointers[i + 1] == n) {\n        n->parent->keys[i] = new_k_prime;\n        break;\n      }\n\n  return root;\n\n}\n\n\n\n  node* \nredistribute_nodes(  node* root, \n    node* n, \n    node* neighbor, \n    int neighbor_index, \n    int k_prime_index, \n    int k_prime) \n{  \n\n  int i;\n  node * tmp;\n\n  \n\n\n  if (neighbor_index != -1) {\n    if (!n->is_leaf)\n      n->pointers[n->num_keys + 1] = n->pointers[n->num_keys];\n    for (i = n->num_keys; i > 0; i--) {\n      n->keys[i] = n->keys[i - 1];\n      n->pointers[i] = n->pointers[i - 1];\n    }\n    if (!n->is_leaf) {\n      n->pointers[0] = neighbor->pointers[neighbor->num_keys];\n      tmp = (node *)n->pointers[0];\n      tmp->parent = n;\n      neighbor->pointers[neighbor->num_keys] = NULL;\n      n->keys[0] = k_prime;\n      n->parent->keys[k_prime_index] = neighbor->keys[neighbor->num_keys - 1];\n    }\n    else {\n      n->pointers[0] = neighbor->pointers[neighbor->num_keys - 1];\n      neighbor->pointers[neighbor->num_keys - 1] = NULL;\n      n->keys[0] = neighbor->keys[neighbor->num_keys - 1];\n      n->parent->keys[k_prime_index] = n->keys[0];\n    }\n  }\n\n  \n\n\n  else {  \n    if (n->is_leaf) {\n      n->keys[n->num_keys] = neighbor->keys[0];\n      n->pointers[n->num_keys] = neighbor->pointers[0];\n      n->parent->keys[k_prime_index] = neighbor->keys[1];\n    }\n    else {\n      n->keys[n->num_keys] = k_prime;\n      n->pointers[n->num_keys + 1] = neighbor->pointers[0];\n      tmp = (node *)n->pointers[n->num_keys + 1];\n      tmp->parent = n;\n      n->parent->keys[k_prime_index] = neighbor->keys[0];\n    }\n    for (i = 0; i < neighbor->num_keys; i++) {\n      neighbor->keys[i] = neighbor->keys[i + 1];\n      neighbor->pointers[i] = neighbor->pointers[i + 1];\n    }\n    if (!n->is_leaf)\n      neighbor->pointers[i] = neighbor->pointers[i + 1];\n  }\n\n  \n\n\n  n->num_keys++;\n  neighbor->num_keys--;\n\n  return root;\n}\n\n\n\n  node* \ndelete_entry(  node* root, \n    node* n, \n    int key, \n    void* pointer ) \n{\n\n  int min_keys;\n  node * neighbor;\n  int neighbor_index;\n  int k_prime_index, k_prime;\n  int capacity;\n\n  \n\n\n  n = remove_entry_from_node(n, key, (node *) pointer);\n\n  \n\n\n  if (n == root) \n    return adjust_root(root);\n\n\n  \n\n\n  \n\n\n  min_keys = n->is_leaf ? cut(order - 1) : cut(order) - 1;\n\n  \n\n\n  if (n->num_keys >= min_keys)\n    return root;\n\n  \n\n\n  \n\n\n  neighbor_index = get_neighbor_index( n );\n  k_prime_index = neighbor_index == -1 ? 0 : neighbor_index;\n  k_prime = n->parent->keys[k_prime_index];\n  neighbor = neighbor_index == -1 ? (node *) n->parent->pointers[1] : \n    (node *)n->parent->pointers[neighbor_index];\n\n  capacity = n->is_leaf ? order : order - 1;\n\n  \n\n\n  if (neighbor->num_keys + n->num_keys < capacity)\n    return coalesce_nodes(root, n, neighbor, neighbor_index, k_prime);\n\n  \n\n\n  else\n    return redistribute_nodes(root, n, neighbor, neighbor_index, k_prime_index, k_prime);\n}\n\n\n\n  node* \ndeleteVal(  node* root, \n    int key) \n{\n\n  node * key_leaf;\n  record * key_record;\n\n  key_record = find(root, key, false);\n  key_leaf = find_leaf(root, key, false);\n  if (key_record != NULL && key_leaf != NULL) {\n    free(key_record);\n    root = delete_entry(root, key_leaf, key, key_record);\n  }\n  return root;\n}\n\n\n\n  void \ndestroy_tree_nodes(node* root) \n{\n  int i;\n  if (root->is_leaf)\n    for (i = 0; i < root->num_keys; i++)\n      free(root->pointers[i]);\n  else\n    for (i = 0; i < root->num_keys + 1; i++)\n      destroy_tree_nodes((node *) root->pointers[i]);\n  free(root->pointers);\n  free(root->keys);\n  free(root);\n}\n\n\n\n  node* \ndestroy_tree(node* root) \n{\n  destroy_tree_nodes(root);\n  return NULL;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  int \nmain( int argc, char** argv )\n{\n\n  printf(\"WG size of kernel 1 = %d WG size of kernel 2 = %d \\n\", DEFAULT_ORDER, DEFAULT_ORDER_2);\n  \n\n  \n\n  \n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  \n\n  \n\n  \n\n\n  \n\n  int cur_arg;\n  int arch_arg;\n  arch_arg = 0;\n  int cores_arg;\n  cores_arg = 1;\n  char *input_file = NULL;\n  char *command_file = NULL;\n  const char *output=\"output.txt\";\n  FILE * pFile;\n\n  \n\n  for(cur_arg=1; cur_arg<argc; cur_arg++){\n    \n\n    if(strcmp(argv[cur_arg], \"file\")==0){\n      \n\n      if(argc>=cur_arg+1){\n        input_file = argv[cur_arg+1];\n        cur_arg = cur_arg+1;\n        \n\n      }\n      \n\n      else{\n        printf(\"ERROR: Missing value to -file parameter\\n\");\n        return -1;\n      }\n    }\n    else if(strcmp(argv[cur_arg], \"command\")==0){\n      \n\n      if(argc>=cur_arg+1){\n        command_file = argv[cur_arg+1];\n        cur_arg = cur_arg+1;\n        \n\n      }\n      \n\n      else{\n        printf(\"ERROR: Missing value to command parameter\\n\");\n        return -1;\n      }\n    }\n  }\n  \n\n  if((input_file==NULL)||(command_file==NULL))\n    printf(\"Usage: ./b+tree file input_file command command_list\\n\");\n\n  \n\n  printf(\"Input File: %s \\n\", input_file);\n  printf(\"Command File: %s \\n\", command_file);\n\n\n  FILE * commandFile;\n  long lSize;\n  char * commandBuffer;\n  size_t result;\n\n  commandFile = fopen ( command_file, \"rb\" );\n  if (commandFile==NULL) {fputs (\"Command File error\",stderr); exit (1);}\n\n  \n\n  fseek (commandFile , 0 , SEEK_END);\n  lSize = ftell (commandFile);\n  rewind (commandFile);\n\n  \n\n  commandBuffer = (char*) malloc (sizeof(char)*lSize);\n  if (commandBuffer == NULL) {fputs (\"Command Buffer memory error\",stderr); exit (2);}\n\n  \n\n  result = fread (commandBuffer,1,lSize,commandFile);\n  if (result != lSize) {fputs (\"Command file reading error\",stderr); exit (3);}\n\n  \n\n\n  \n\n  fclose (commandFile);\n\n  \n\n  \n\n  printf(\"Command Buffer: \\n\");\n  printf(\"%s\",commandBuffer);\n  \n\n\n\n  pFile = fopen (output,\"w+\");\n  if (pFile==NULL) \n    printf (\"Fail to open %s !\\n\",output);\n  fprintf(pFile,\"******starting******\\n\");\n  fclose(pFile);\n\n  \n\n  \n\n  \n\n\n  FILE *file_pointer;\n  node *root;\n  root = NULL;\n  record *r;\n  int input;\n  char instruction;\n  order = DEFAULT_ORDER_2;\n  verbose_output = false;\n\n  \n\n  \n\n\n  \n\n  \n\n  \n\n\n  if (input_file != NULL) {\n\n    printf(\"Getting input from file %s...\\n\", argv[1]);\n\n    \n\n    file_pointer = fopen(input_file, \"r\");\n    if (file_pointer == NULL) {\n      perror(\"Failure to open input file.\");\n      exit(EXIT_FAILURE);\n    }\n\n    \n\n    fscanf(file_pointer, \"%d\\n\", &input);\n    size = input;\n\n    \n\n    while (!feof(file_pointer)) {\n      fscanf(file_pointer, \"%d\\n\", &input);\n      root = insert(root, input, input);\n    }\n\n    \n\n    fclose(file_pointer);\n    \n\n    \n\n\n  }\n  else{\n    printf(\"ERROR: Argument -file missing\\n\");\n    return 0;\n  }\n\n  \n\n  \n\n  \n\n\n  printf(\"Transforming data to a GPU suitable structure...\\n\");\n  long mem_used = transform_to_cuda(root,0);\n  maxheight = height(root);\n  long rootLoc = (long)knodes - (long)mem;\n\n  \n\n  \n\n  \n\n  char *commandPointer=commandBuffer;\n  printf(\"Waiting for command\\n\");\n  printf(\"> \");\n  while (sscanf(commandPointer, \"%c\", &instruction) != EOF) {\n    commandPointer++;\n    switch (instruction) {\n      \n\n      \n\n      \n\n\n      case 'i':\n        {\n          scanf(\"%d\", &input);\n          while (getchar() != (int)'\\n');\n          root = insert(root, input, input);\n          print_tree(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'f':\n        {\n        }\n\n        \n\n        \n\n        \n\n\n      case 'p':\n        {\n          scanf(\"%d\", &input);\n          while (getchar() != (int)'\\n');\n          r = find(root, input, instruction == 'p');\n          if (r == NULL)\n            printf(\"Record not found under key %d.\\n\", input);\n          else \n            printf(\"Record found: %d\\n\",r->value);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'd':\n        {\n          scanf(\"%d\", &input);\n          while (getchar() != (int)'\\n');\n          root = (node *) deleteVal(root, input);\n          print_tree(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'x':\n        {\n          while (getchar() != (int)'\\n');\n          root = destroy_tree(root);\n          print_tree(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'l':\n        {\n          while (getchar() != (int)'\\n');\n          print_leaves(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 't':\n        {\n          while (getchar() != (int)'\\n');\n          print_tree(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'v':\n        {\n          while (getchar() != (int)'\\n');\n          verbose_output = !verbose_output;\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'q':\n        {\n          while (getchar() != (int)'\\n');\n          return EXIT_SUCCESS;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'k':\n        {\n\n          \n\n          int count;\n          sscanf(commandPointer, \"%d\", &count);\n          while(*commandPointer!=32 && *commandPointer!='\\n')\n            commandPointer++;\n\n          printf(\"\\n ******command: k count=%d \\n\",count);\n          if(count > 65535){\n            printf(\"ERROR: Number of requested querries should be 65,535 at most. (limited by # of teams)\\n\");\n            exit(0);\n          }\n\n          \n\n          record *records = (record *)mem;\n          long records_elem = (long)rootLoc / sizeof(record);\n          long records_mem = (long)rootLoc;\n          printf(\"records_elem=%d, records_unit_mem=%d, records_mem=%d\\n\", (int)records_elem, (int)sizeof(record), (int)records_mem);\n\n          \n\n          knode *knodes = (knode *)((long)mem + (long)rootLoc);\n          long knodes_elem = ((long)(mem_used) - (long)rootLoc) / sizeof(knode);\n          long knodes_mem = (long)(mem_used) - (long)rootLoc;\n          printf(\"knodes_elem=%d, knodes_unit_mem=%d, knodes_mem=%d\\n\", (int)knodes_elem, (int)sizeof(knode), (int)knodes_mem);\n\n          \n\n          long *currKnode;\n          currKnode = (long *)malloc(count*sizeof(long));\n          \n\n          memset(currKnode, 0, count*sizeof(long));\n\n          \n\n          long *offset;\n          offset = (long *)malloc(count*sizeof(long));\n          \n\n          memset(offset, 0, count*sizeof(long));\n\n          \n\n          int *keys;\n          keys = (int *)malloc(count*sizeof(int));\n          \n\n          srand(123);\n          int i;\n          for(i = 0; i < count; i++){\n            keys[i] = (rand()/(float)RAND_MAX)*size;\n          }\n\n          \n\n          record *ans = (record *)malloc(sizeof(record)*count);\n          \n\n          for(i = 0; i < count; i++){\n            ans[i].value = -1;\n          }\n\n          \n\n          kernel_wrapper(  records,\n              records_elem, \n\n              knodes,\n              knodes_elem,\n              knodes_elem,\n\n\n              order,\n              maxheight,\n              count,\n\n              currKnode,\n              offset,\n              keys,\n              ans);\n\n          pFile = fopen (output,\"aw+\");\n          if (pFile==NULL)\n          {\n            printf (\"Fail to open %s !\\n\",output);\n          }\n\n          fprintf(pFile,\"\\n ******command: k count=%d \\n\",count);\n          for(i = 0; i < count; i++){\n            fprintf(pFile, \"%d    %d\\n\",i, ans[i].value);\n          }\n          fprintf(pFile, \" \\n\");\n          fclose(pFile);\n\n\n          \n\n          free(currKnode);\n          free(offset);\n          free(keys);\n          free(ans);\n\n          \n\n          break;\n\n        }\n\n        \n\n        \n\n        \n\n\n      case 'r':\n        {\n          int start, end;\n          scanf(\"%d\", &start);\n          scanf(\"%d\", &end);\n          if(start > end){\n            input = start;\n            start = end;\n            end = input;\n          }\n          printf(\"For range %d to %d, \",start,end);\n          list_t * ansList;\n          ansList = findRange(root, start, end);\n          printf(\"%d records found\\n\", list_get_length(ansList));\n          \n\n          free(ansList);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'j':\n        {\n\n          \n\n          int count;\n          sscanf(commandPointer, \"%d\", &count);\n          while(*commandPointer!=32 && *commandPointer!='\\n')\n            commandPointer++;\n\n          int rSize;\n          sscanf(commandPointer, \"%d\", &rSize);\n          while(*commandPointer!=32 && *commandPointer!='\\n')\n            commandPointer++;\n\n          printf(\"\\n******command: j count=%d, rSize=%d \\n\",count, rSize);\n\n          if(rSize > size || rSize < 0) {\n            printf(\"Search range size is larger than data set size %d.\\n\", (int)size);\n            exit(0);\n          }\n\n          \n\n          knode *knodes = (knode *)((long)mem + (long)rootLoc);\n          long knodes_elem = ((long)(mem_used) - (long)rootLoc) / sizeof(knode);\n          long knodes_mem = (long)(mem_used) - (long)rootLoc;\n          printf(\"knodes_elem=%d, knodes_unit_mem=%d, knodes_mem=%d\\n\", (int)knodes_elem, (int)sizeof(knode), (int)knodes_mem);\n\n          \n\n          long *currKnode;\n          currKnode = (long *)malloc(count*sizeof(long));\n          \n\n          memset (currKnode, 0, count*sizeof(long));\n\n          \n\n          long *offset;\n          offset = (long *)malloc(count*sizeof(long));\n          \n\n          memset (offset, 0, count*sizeof(long));\n\n          \n\n          long *lastKnode;\n          lastKnode = (long *)malloc(count*sizeof(long));\n          \n\n          memset (lastKnode, 0, count*sizeof(long));\n\n          \n\n          long *offset_2;\n          offset_2 = (long *)malloc(count*sizeof(long));\n          \n\n          memset (offset_2, 0, count*sizeof(long));\n\n          \n\n          int *start;\n          start = (int *)malloc(count*sizeof(int));\n          int *end;\n          end = (int *)malloc(count*sizeof(int));\n          \n\n          srand(123);\n          int i;\n          for(i = 0; i < count; i++){\n            start[i] = (rand()/(float)RAND_MAX)*size;\n            end[i] = start[i]+rSize;\n            if(end[i] >= size){ \n              start[i] = start[i] - (end[i] - size);\n              end[i]= size-1;\n            }\n          }\n\n          \n\n          int *recstart;\n          recstart = (int *)malloc(count*sizeof(int));\n          int *reclength;\n          reclength = (int *)malloc(count*sizeof(int));\n          \n\n          for(i = 0; i < count; i++){\n            recstart[i] = 0;\n            reclength[i] = 0;\n          }\n\n          kernel2_wrapper(knodes,\n              knodes_elem,\n              knodes_elem, \n\n\n              order,\n              maxheight,\n              count,\n\n              currKnode,\n              offset,\n              lastKnode,\n              offset_2,\n              start,\n              end,\n              recstart,\n              reclength);\n\n\n          pFile = fopen (output,\"aw+\");\n          if (pFile==NULL)\n          {\n            printf (\"Fail to open %s !\\n\",output);\n          }\n\n          fprintf(pFile,\"\\n******command: j count=%d, rSize=%d \\n\",count, rSize);        \n          for(i = 0; i < count; i++){\n            fprintf(pFile, \"%d    %d    %d\\n\",i, recstart[i],reclength[i]);\n          }\n          fprintf(pFile, \" \\n\");\n          fclose(pFile);\n\n          \n\n          free(currKnode);\n          free(offset);\n          free(lastKnode);\n          free(offset_2);\n          free(start);\n          free(end);\n          free(recstart);\n          free(reclength);\n\n          \n\n          break;\n\n        }\n\n        \n\n        \n\n        \n\n\n      default:\n        {\n\n          \n\n          break;\n\n        }\n\n    }\n    printf(\"> \");\n\n  }\n  printf(\"\\n\");\n\n  \n\n  \n\n  \n\n\n  free(mem);\n  return EXIT_SUCCESS;\n\n}\n\n\n\n\n\n\n\n\n", "kernel2_wrapper.c": "#include <stdio.h>\n#include <string.h>\n#include <omp.h>\n#include \"../common.h\"                \n\n#include \"../util/timer/timer.h\"          \n\n#include \"./kernel2_wrapper.h\"      \n\n\n\n\n\n\n\n\n\nvoid \nkernel2_wrapper(\n    knode *knodes,\n    long knodes_elem,\n    long knodes_mem,  \n\n\n    int order,\n    long maxheight,\n    int count,\n\n    long *currKnode,\n    long *offset,\n    long *lastKnode,\n    long *offset_2,\n    int *start,\n    int *end,\n    int *recstart,\n    int *reclength)\n{\n\n  \n\n  \n\n  \n\n\n  \n\n\n  size_t threads;\n  threads = order < 256 ? order : 256;\n\n#pragma omp target data map(to: knodes[0: knodes_mem],\\\n                                start[0: count],\\\n                                end[0: count],\\\n                                currKnode[0: count],\\\n                                offset[0: count],\\\n                                lastKnode[0: count],\\\n                                offset_2[0: count])\\\n                        map(tofrom: recstart[0: count])\\\n                        map(from: reclength[0: count])\n  {\n    long long kernel_start = get_time();\n\n    #pragma omp target teams num_teams(count) thread_limit(threads)\n    {\n      #pragma omp parallel\n      {\n        \n\n        int thid = omp_get_thread_num();\n        int bid = omp_get_team_num();\n\n        int i;\n        for(i = 0; i < maxheight; i++){\n\n          if((knodes[currKnode[bid]].keys[thid] <= start[bid]) && (knodes[currKnode[bid]].keys[thid+1] > start[bid])){\n            \n\n            \n\n            \n\n            if(knodes[currKnode[bid]].indices[thid] < knodes_elem) {\n              offset[bid] = knodes[currKnode[bid]].indices[thid];\n            }\n          }\n          if((knodes[lastKnode[bid]].keys[thid] <= end[bid]) && (knodes[lastKnode[bid]].keys[thid+1] > end[bid])){\n            \n\n            \n\n            \n\n            if(knodes[lastKnode[bid]].indices[thid] < knodes_elem) {\n              offset_2[bid] = knodes[lastKnode[bid]].indices[thid];\n            }\n          }\n          #pragma omp barrier\n          \n\n          if(thid==0){\n            currKnode[bid] = offset[bid];\n            lastKnode[bid] = offset_2[bid];\n          }\n          #pragma omp barrier\n        }\n\n        \n\n        if(knodes[currKnode[bid]].keys[thid] == start[bid]){\n          recstart[bid] = knodes[currKnode[bid]].indices[thid];\n        }\n        #pragma omp barrier\n\n        \n\n        if(knodes[lastKnode[bid]].keys[thid] == end[bid]){\n          reclength[bid] = knodes[lastKnode[bid]].indices[thid] - recstart[bid]+1;\n        }\n      }\n    }\n    long long kernel_end = get_time();\n    printf(\"Kernel execution time: %f (us)\\n\", (float)(kernel_end-kernel_start));\n  }\n\n#ifdef DEBUG\n  for (int i = 0; i < count; i++)\n\t  printf(\"recstart[%d] = %d\\n\", i, recstart[i]);\n  for (int i = 0; i < count; i++)\n\t  printf(\"reclength[%d] = %d\\n\", i, reclength[i]);\n#endif\n\n}\n\n", "kernel_wrapper.c": "#include <stdio.h>\n#include <string.h>\n#include <omp.h>\n#include \"../common.h\"                \n\n#include \"../util/timer/timer.h\"          \n\n#include \"./kernel_wrapper.h\"      \n\n\n\nvoid \nkernel_wrapper(  record *records,\n    long records_mem, \n\n    knode *knodes,\n    long knodes_elem,\n    long knodes_mem,  \n\n\n    int order,\n    long maxheight,\n    int count,\n\n    long *currKnode,\n    long *offset,\n    int *keys,\n    record *ans)\n{\n\n  \n\n  \n\n  \n\n\n  \n\n\n  int threads = order < 256 ? order : 256;\n\n  #pragma omp target data map(to: knodes[0: knodes_mem],\\\n                                  records[0: records_mem],\\\n                                  keys[0: count], \\\n                                  currKnode[0: count],\\\n                                  offset[0: count])\\\n                          map(from: ans[0: count])\n  {\n    long long kernel_start = get_time();\n\n    #pragma omp target teams num_teams(count) thread_limit(threads)\n    {\n      #pragma omp parallel\n      {\n        \n\n        int thid = omp_get_thread_num();\n        int bid = omp_get_team_num();\n\n        \n\n        for(int i = 0; i < maxheight; i++){\n\n          \n\n          if((knodes[currKnode[bid]].keys[thid]) <= keys[bid] && (knodes[currKnode[bid]].keys[thid+1] > keys[bid])){\n            \n\n            \n\n            \n\n            if(knodes[offset[bid]].indices[thid] < knodes_elem){\n              offset[bid] = knodes[offset[bid]].indices[thid];\n            }\n          }\n          #pragma omp barrier\n          \n\n          if(thid==0){\n            currKnode[bid] = offset[bid];\n          }\n          #pragma omp barrier\n        }\n\n        \n\n        \n\n        if(knodes[currKnode[bid]].keys[thid] == keys[bid]){\n          ans[bid].value = records[knodes[currKnode[bid]].indices[thid]].value;\n        }\n      }\n    }\n    long long kernel_end = get_time();\n    printf(\"Kernel execution time: %f (us)\\n\", (float)(kernel_end-kernel_start));\n  } \n\n#ifdef DEBUG\n  for (int i = 0; i < count; i++)\n    printf(\"ans[%d] = %d\\n\", i, ans[i].value);\n  printf(\"\\n\");\n#endif\n\n}\n\n"}}
{"kernel_name": "b+tree", "parallel_api": "serial", "code": {"main.c": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <stdio.h>                  \n\n#include <limits.h>                  \n\n#include <math.h>                  \n\n#include <string.h>                  \n\n\n\n\n\n\n\n\n\n#include \"./common.h\"                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include \"./util/timer/timer.h\"            \n\n#include \"./util/num/num.h\"              \n\n\n\n\n\n\n\n\n\n#include \"./kernel/kernel_wrapper.h\"    \n\n#include \"./kernel/kernel2_wrapper.h\"    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nknode *knodes;\nrecord *krecords;\nchar *mem;\nlong freeptr;\nlong malloc_size;\nlong size;\nlong maxheight;\n\n\n\nint order = DEFAULT_ORDER;\n\n\n\nnode *tree_queue = NULL;\n\n\n\nbool verbose_output = false;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  void \nlist_init(  list_t *l,\n    int32_t (*compare)(const void *key, \n      const void *with),\n    void (*datum_delete)(void *))\n{\n  l->head = l->tail = NULL;\n  l->length = 0;\n  l->compare = compare;\n  l->datum_delete = datum_delete;\n}\n\n  void \nlist_delete(list_t *l)\n{\n\n  list_item_t *li, *del;\n\n  for (li = l->head; li;) {\n\n    del = li;\n    li = li->next;\n    list_item_delete(del, l->datum_delete);\n  }\n\n  l->head = l->tail = NULL;\n  l->length = 0;\n}\n\n  void \nlist_reset(list_t *l)\n{\n  list_delete(l);\n}\n\n  void \nlist_insert_item_head(  list_t *l, \n    list_item_t *i)\n{\n  if (l->head) {\n    i->next = l->head;\n    l->head->pred = i;\n    l->head = i;\n    l->head->pred = NULL;\n  } else {\n    l->head = l->tail = i;\n    i->next = i->pred = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_item_tail(  list_t *l, \n    list_item_t *i)\n{\n  if (l->head) {\n    l->tail->next = i;\n    i->pred = l->tail;\n    i->next = NULL;\n    l->tail = i;\n  } else {\n    l->head = l->tail = i;\n    i->next = i->pred = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_item_before(list_t *l, \n    list_item_t *next, \n    list_item_t *i)\n{\n  \n\n  \n\n  if (l->head == next) {\n    i->next = next;\n    i->pred = NULL;\n    l->head = i;\n    next->pred = i;\n  } else {\n    i->next = next;\n    i->pred = next->pred;\n    next->pred->next = i;\n    next->pred = i;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_item_after(  list_t *l, \n    list_item_t *pred, \n    list_item_t *i)\n{\n  \n\n  \n\n  if (l->tail == pred) {\n    i->pred = pred;\n    i->next = NULL;\n    l->tail = i;\n    pred->next = i;\n  } else {\n    i->pred = pred;\n    i->next = pred->next;\n    pred->next->pred = i;\n    pred->next = i;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_item_sorted(list_t *l, \n    list_item_t *i)\n{\n  list_item_t *itr;\n\n  if (l->head) {\n    for (itr = l->head; itr && l->compare(list_item_get_datum(i),\n          list_item_get_datum(itr)) < 0;\n        itr = itr->next)\n      ;\n    if (itr) {\n      i->next = itr;\n      i->pred = itr->pred;\n      itr->pred = i;\n      i->pred->next = i;\n    } else {\n      l->tail->next = i;\n      i->pred = l->tail;\n      i->next = NULL;\n      l->tail = i;\n    }\n  } else {\n    l->head = l->tail = i;\n    i->pred = i->next = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_head(  list_t *l, \n    void *v)\n{\n  list_item_t *i;\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n  if (l->head) {\n    i->next = l->head;\n    l->head->pred = i;\n    l->head = i;\n    l->head->pred = NULL;\n  } else {\n    l->head = l->tail = i;\n    i->next = i->pred = NULL;\n  }\n  l->length++;\n\n}\n\n  void \nlist_insert_tail(  list_t *l, \n    void *v)\n{\n  list_item_t *i;\n\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n  if (l->head) {\n    l->tail->next = i;\n    i->pred = l->tail;\n    i->next = NULL;\n    l->tail = i;\n  } else {\n    l->head = l->tail = i;\n    i->next = i->pred = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_before(  list_t *l, \n    list_item_t *next, \n    void *v)\n{\n  list_item_t *i;\n\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n\n  \n\n  \n\n  if (l->head == next) {\n    i->next = next;\n    i->pred = NULL;\n    l->head = i;\n    next->pred = i;\n  } else {\n    i->next = next;\n    i->pred = next->pred;\n    next->pred->next = i;\n    next->pred = i;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_after(  list_t *l, \n    list_item_t *pred, \n    void *v)\n{\n  list_item_t *i;\n\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n\n  \n\n  \n\n  if (l->tail == pred) {\n    i->pred = pred;\n    i->next = NULL;\n    l->tail = i;\n    pred->next = i;\n  } else {\n    i->pred = pred;\n    i->next = pred->next;\n    pred->next->pred = i;\n    pred->next = i;\n  }\n  l->length++;\n}\n\n  void \nlist_insert_sorted(  list_t *l, \n    void *v)\n{\n  list_item_t *itr;\n  list_item_t *i;\n\n  i = (list_item_t *)malloc(sizeof (*i));\n  list_item_init(i, v);\n\n\n  if (l->head) {\n    for (itr = l->head; itr && l->compare(list_item_get_datum(i),\n          list_item_get_datum(itr)) < 0;\n        itr = itr->next)\n      ;\n    if (itr) {\n      i->next = itr;\n      i->pred = itr->pred;\n      itr->pred = i;\n      i->pred->next = i;\n    } else {\n      l->tail->next = i;\n      i->pred = l->tail;\n      i->next = NULL;\n      l->tail = i;\n    }\n  } else {\n    l->head = l->tail = i;\n    i->pred = i->next = NULL;\n  }\n  l->length++;\n}\n\n  void \nlist_remove_item(  list_t *l, \n    list_item_t *i)\n{\n  if (i == l->head) {\n    l->head = l->head->next;\n    if (l->head)\n      l->head->pred = NULL;\n    else\n      l->tail = NULL;\n  } else if (i == l->tail) {\n    l->tail = l->tail->pred;\n    l->tail->next = NULL;\n  } else {\n    i->pred->next = i->next;\n    i->next->pred = i->pred;\n  }\n  l->length--;\n  list_item_delete(i, l->datum_delete);\n}\n\n  void \nlist_remove_head(list_t *l)\n{\n  list_remove_item(l, l->head);\n}\n\n  void \nlist_remove_tail(list_t *l)\n{\n  list_remove_item(l, l->tail);\n}\n\n  list_item_t* \nlist_find_item(  list_t *l, \n    void *datum)\n{\n  list_item_t *li;\n\n  for (li = l->head; li && l->compare(datum, list_item_get_datum(li));\n      li = li->next)\n    ;\n\n  return li;\n}\n\n  list_item_t* \nlist_get_head_item(list_t *l)\n{\n  return l->head;\n}\n\n  list_item_t* \nlist_get_tail_item(list_t *l)\n{\n  return l->tail;\n}\n\n  void* \nlist_find(  list_t *l, \n    void *datum)\n{\n  list_item_t *li;\n\n  for (li = l->head; li && l->compare(datum, list_item_get_datum(li));\n      li = li->next)\n    ;\n\n  return li ? li->datum : NULL;\n}\n\n  void* \nlist_get_head(list_t *l)\n{\n  return l->head ? l->head->datum : NULL;\n}\n\n  void* \nlist_get_tail(list_t *l)\n{\n  return l->tail ? l->tail->datum : NULL;\n}\n\n  uint32_t \nlist_get_length(list_t *l)\n{\n  return l->length;\n}\n\n  bool \nlist_is_empty(list_t *l)\n{\n  return (l->length == 0);\n}\n\n  bool \nlist_not_empty(list_t *l)\n{\n  return (l->length != 0);\n}\n\n  void \nlist_visit_items(  list_t *l, \n    void (*visitor)(void *v))\n{\n  list_item_t *li;\n\n  for (li = l->head; li; li = li->next)\n    visitor(list_item_get_datum(li));\n}\n\n  void \nlist_item_init(  list_item_t *li, \n    void *datum)\n{\n  li->pred = li->next = NULL;\n  li->datum = datum;\n}\n\n  void \nlist_item_delete(  list_item_t *li, \n    void (*datum_delete)(void *datum))\n{\n  if (datum_delete) {\n    datum_delete(li->datum);\n  }\n\n  free(li);\n}\n\n  void *\nlist_item_get_datum(list_item_t *li)\n{\n  return li->datum;\n}\n\n  void \nlist_iterator_init(  list_t *l, \n    list_iterator_t *li)\n{\n  *li = l ? l->head : NULL;\n}\n\n  void \nlist_iterator_delete(list_iterator_t *li)\n{\n  *li = NULL;\n}\n\n  void \nlist_iterator_next(list_iterator_t *li)\n{\n  if (*li)\n    *li = (*li)->next;\n}\n\n  void \nlist_iterator_prev(list_iterator_t *li)\n{\n  if (*li)\n    *li = (*li)->pred;\n}\n\n  void *\nlist_iterator_get_datum(list_iterator_t *li)\n{\n  return *li ? (*li)->datum : NULL;\n}\n\n  bool \nlist_iterator_is_valid(list_iterator_t *li)\n{\n  return (*li != NULL);\n}\n\n  void \nlist_reverse_iterator_init(  list_t *l, \n    list_reverse_iterator_t *li)\n{\n  *li = l ? l->tail : NULL;\n}\n\n  void \nlist_reverse_iterator_delete(list_reverse_iterator_t *li)\n{\n  *li = NULL;\n}\n\n  void \nlist_reverse_iterator_next(list_reverse_iterator_t *li)\n{\n  if (*li)\n    *li = (*li)->pred;\n}\n\n  void \nlist_reverse_iterator_prev(list_reverse_iterator_t *li)\n{\n  if (*li)\n    *li = (*li)->next;\n}\n\n  void *\nlist_reverse_iterator_get_datum(list_reverse_iterator_t *li)\n{\n  return *li ? (*li)->datum : NULL;\n}\n\n  bool \nlist_reverse_iterator_is_valid(list_reverse_iterator_t *li)\n{\n  return (li != NULL);\n}\n\n\n\n\n\n\n\n\n\n\n  void *\nkmalloc(int size)\n{\n\n  \n\n  void * r = (void *)freeptr;\n  freeptr+=size;\n  if(freeptr > malloc_size+(long)mem){\n    printf(\"Memory Overflow\\n\");\n    exit(1);\n  }\n  return r;\n}\n\n\n\n  long \ntransform_to_cuda(  node * root, \n    bool verbose)\n{\n\n  struct timeval one,two;\n  double time;\n  gettimeofday (&one, NULL);\n  long max_nodes = (long)(pow(order,log(size)/log(order/2.0)-1) + 1);\n  malloc_size = size*sizeof(record) + max_nodes*sizeof(knode); \n  mem = (char*)malloc(malloc_size);\n  if(mem==NULL){\n    printf(\"Initial malloc error\\n\");\n    exit(1);\n  }\n  freeptr = (long)mem;\n\n  krecords = (record * )kmalloc(size*sizeof(record));\n  \n\n  knodes = (knode *)kmalloc(max_nodes*sizeof(knode));\n  \n\n\n  tree_queue = NULL;\n  enqueue(root);\n  node * n;\n  knode * k;\n  int i;\n  long nodeindex = 0;\n  long recordindex = 0;\n  long queueindex = 0;\n  knodes[0].location = nodeindex++;\n\n  while( tree_queue != NULL ) {\n    n = dequeue();\n    k = &knodes[queueindex];\n    k->location = queueindex++;\n    k->is_leaf = n->is_leaf;\n    k->num_keys = n->num_keys+2;\n    \n\n    k->keys[0]=INT_MIN; \n    k->keys[k->num_keys-1]=INT_MAX;\n    for(i=k->num_keys; i < order; i++)k->keys[i]=INT_MAX;\n    if(!k->is_leaf){\n      k->indices[0]=nodeindex++;\n      \n\n      \n\n      \n\n      for(i=1;i<k->num_keys-1;i++){\n        k->keys[i] = n->keys[i-1];\n        enqueue((node * )n->pointers[i-1]);\n        k->indices[i] = nodeindex++;\n        \n\n        \n\n        \n\n        \n\n      }\n      \n\n      enqueue((node * )n->pointers[i-1]);\n    }\n    else{\n      k->indices[0]=0;\n      for(i=1;i<k->num_keys-1;i++){\n        k->keys[i] = n->keys[i-1];\n        krecords[recordindex].value=((record *)n->pointers[i-1])->value;\n        k->indices[i] = recordindex++;\n        \n\n        \n\n        \n\n      }\n    }\n\n    k->indices[k->num_keys-1]=queueindex;\n    \n\n    \n\n    \n\n\n    if(verbose){\n      printf(\"Successfully created knode with index %d\\n\", k->location);\n      printf(\"Is Leaf: %d, Num Keys: %d\\n\", k->is_leaf, k->num_keys);\n      printf(\"Pointers: \");\n      for(i=0;i<k->num_keys;i++)\n        printf(\"%d | \", k->indices[i]);\n      printf(\"\\nKeys: \");\n      for(i=0;i<k->num_keys;i++)\n        printf(\"%d | \", k->keys[i]);\n      printf(\"\\n\\n\");\n    }\n  }\n  long mem_used = size*sizeof(record)+(nodeindex)*sizeof(knode);\n  if(verbose){\n    for(i = 0; i < size; i++)\n      printf(\"%d \", krecords[i].value);\n    printf(\"\\nNumber of records = %ld, sizeof(record)=%lu, total=%lu\\n\",size,sizeof(record),size*sizeof(record));\n    printf(\"Number of knodes = %ld, sizeof(knode)=%lu, total=%lu\\n\",nodeindex,sizeof(knode),(nodeindex)*sizeof(knode));\n    printf(\"\\nDone Transformation. Mem used: %ld\\n\", mem_used);\n  }\n  gettimeofday (&two, NULL);\n  double oneD = one.tv_sec + (double)one.tv_usec * .000001;\n  double twoD = two.tv_sec + (double)two.tv_usec * .000001;\n  time = twoD-oneD;\n  printf(\"Tree transformation took %f\\n\", time);\n\n  return mem_used;\n\n}\n\n\n\n  list_t *\nfindRange(  node * root, \n    int start, \n    int end) \n{\n\n  int i;\n  node * c = find_leaf( root, start, false );\n\n  if (c == NULL) return NULL;\n\n  list_t * retList = (list_t *)malloc(sizeof(list_t));\n  list_init(retList,NULL,NULL);\n\n  int counter = 0;\n  bool cont = true;\n  while(cont && c!=0){\n    cont = false;\n    for(i = 0;i  < c->num_keys;i++){\n      if(c->keys[i] >= start && c->keys[i] <= end){\n        \n\n        counter++;\n        cont = true;\n      }else{\n        cont = false;\n        break;\n      }\n    }\n    c = (node *)c->pointers[order-1];\n  }\n  return retList;\n}\n\n\n\n  void \nusage_1( void ) \n{\n\n  printf(\"B+ Tree of Order %d.\\n\", order);\n  printf(\"\\tAmittai Aviram -- amittai.aviram@yale.edu  Version %s\\n\", Version);\n  printf(\"\\tfollowing Silberschatz, Korth, Sidarshan, Database Concepts, 5th ed.\\n\\n\");\n  printf(\"To build a B+ tree of a different order, start again and enter the order\\n\");\n  printf(\"as an integer argument:  bpt <order>.  \");\n  printf(\"3 <= order <=20\\n\");\n  printf(\"To start with input from a file of newline-delimited integers, start again and enter\\n\");\n  printf(\"the order followed by the filename:  bpt <order> <inputfile>.\\n\");\n\n}\n\n\n\n  void \nusage_2( void ) \n{\n\n  printf(\"Enter any of the following commands after the prompt > :\\n\");\n  printf(\"\\ti <k>  -- Insert <k> (an integer) as both key and value).\\n\");\n  printf(\"\\tf <k>  -- Find the value under key <k>.\\n\");\n  printf(\"\\tp <k> -- Print the path from the root to key k and its associated value.\\n\");\n  printf(\"\\td <k>  -- Delete key <k> and its associated value.\\n\");\n  printf(\"\\tx -- Destroy the whole tree.  Start again with an empty tree of the same order.\\n\");\n  printf(\"\\tt -- Print the B+ tree.\\n\");\n  printf(\"\\tl -- Print the keys of the leaves (bottom row of the tree).\\n\");\n  printf(\"\\tv -- Toggle output of pointer addresses (\\\"verbose\\\") in tree and leaves.\\n\");\n  printf(\"\\tq -- Quit. (Or use Ctl-D.)\\n\");\n  printf(\"\\t? -- Print this help message.\\n\");\n}\n\n\n\n  void \nenqueue( node* new_node ) \n{\n  node * c;\n  if (tree_queue == NULL) {\n    tree_queue = new_node;\n    tree_queue->next = NULL;\n  }\n  else {\n    c = tree_queue;\n    while(c->next != NULL) {\n      c = c->next;\n    }\n    c->next = new_node;\n    new_node->next = NULL;\n  }\n}\n\n\n\n  node *\ndequeue( void ) \n{\n  node * n = tree_queue;\n  tree_queue = tree_queue->next;\n  n->next = NULL;\n  return n;\n}\n\n\n\n  void \nprint_leaves( node* root ) \n{\n  int i;\n  node * c = root;\n  if (root == NULL) {\n    printf(\"Empty tree.\\n\");\n    return;\n  }\n  while (!c->is_leaf)\n    c = (node *) c->pointers[0];\n  while (true) {\n    for (i = 0; i < c->num_keys; i++) {\n      if (verbose_output)\n        \n\n        printf(\"%d \", c->keys[i]);\n    }\n    if (verbose_output)\n      \n\n      if (c->pointers[order - 1] != NULL) {\n        printf(\" | \");\n        c = (node *) c->pointers[order - 1];\n      }\n      else\n        break;\n  }\n  printf(\"\\n\");\n}\n\n\n\n  int \nheight( node* root ) \n{\n  int h = 0;\n  node * c = root;\n  while (!c->is_leaf) {\n    c = (node *) c->pointers[0];\n    h++;\n  }\n  return h;\n}\n\n\n\n  int \npath_to_root( node* root, node* child ) \n{\n  int length = 0;\n  node * c = child;\n  while (c != root) {\n    c = c->parent;\n    length++;\n  }\n  return length;\n}\n\n\n\n  void \nprint_tree( node* root ) \n{\n\n  node * n = NULL;\n  int i = 0;\n  int rank = 0;\n  int new_rank = 0;\n\n  if (root == NULL) {\n    printf(\"Empty tree.\\n\");\n    return;\n  }\n  tree_queue = NULL;\n  enqueue(root);\n  while( tree_queue != NULL ) {\n    n = dequeue();\n    if (n->parent != NULL && n == n->parent->pointers[0]) {\n      new_rank = path_to_root( root, n );\n      if (new_rank != rank) {\n        rank = new_rank;\n        printf(\"\\n\");\n      }\n    }\n    if (verbose_output) \n      printf(\"(%x)\", n);\n    for (i = 0; i < n->num_keys; i++) {\n      if (verbose_output)\n        printf(\"%x \", n->pointers[i]);\n      printf(\"%d \", n->keys[i]);\n    }\n    if (!n->is_leaf)\n      for (i = 0; i <= n->num_keys; i++)\n        enqueue((node *) n->pointers[i]);\n    if (verbose_output) {\n      if (n->is_leaf) \n        printf(\"%x \", n->pointers[order - 1]);\n      else\n        printf(\"%x \", n->pointers[n->num_keys]);\n    }\n    printf(\"| \");\n  }\n  printf(\"\\n\");\n}\n\n\n\n  node *\nfind_leaf( node* root, int key, bool verbose ) \n{\n\n  int i = 0;\n  node * c = root;\n  if (c == NULL) {\n    if (verbose) \n      printf(\"Empty tree.\\n\");\n    return c;\n  }\n  while (!c->is_leaf) {\n    if (verbose) {\n      printf(\"[\");\n      for (i = 0; i < c->num_keys - 1; i++)\n        printf(\"%d \", c->keys[i]);\n      printf(\"%d] \", c->keys[i]);\n    }\n    i = 0;\n    while (i < c->num_keys) {\n      if (key >= c->keys[i]) \n        i++;\n      else \n        break;\n    }\n    if (verbose)\n      printf(\"%d ->\\n\", i);\n    c = (node *)c->pointers[i];\n  }\n  if (verbose) {\n    printf(\"Leaf [\");\n    for (i = 0; i < c->num_keys - 1; i++)\n      printf(\"%d \", c->keys[i]);\n    printf(\"%d] ->\\n\", c->keys[i]);\n  }\n  return c;\n\n}\n\n\n\n  record *\nfind( node* root, int key, bool verbose ) \n{\n\n  int i = 0;\n  node * c = find_leaf( root, key, verbose );\n  if (c == NULL) \n    return NULL;\n  for (i = 0; i < c->num_keys; i++)\n    if (c->keys[i] == key) \n      break;\n  if (i == c->num_keys) \n    return NULL;\n  else\n    return (record *)c->pointers[i];\n\n}\n\n\n\n  int \ncut( int length ) \n{\n  if (length % 2 == 0)\n    return length/2;\n  else\n    return length/2 + 1;\n}\n\n\n\n\n\n\n\n\n\n\n  record *\nmake_record(int value) \n{\n  record * new_record = (record *)malloc(sizeof(record));\n  if (new_record == NULL) {\n    perror(\"Record creation.\");\n    exit(EXIT_FAILURE);\n  }\n  else {\n    new_record->value = value;\n  }\n  return new_record;\n}\n\n\n\n  node *\nmake_node( void ) \n{\n  node * new_node;\n  new_node = (node *) malloc(sizeof(node));\n  if (new_node == NULL) {\n    perror(\"Node creation.\");\n    exit(EXIT_FAILURE);\n  }\n  new_node->keys = (int *) malloc( (order - 1) * sizeof(int) );\n  if (new_node->keys == NULL) {\n    perror(\"New node keys array.\");\n    exit(EXIT_FAILURE);\n  }\n  new_node->pointers = (void **) malloc( order * sizeof(void *) );\n  if (new_node->pointers == NULL) {\n    perror(\"New node pointers array.\");\n    exit(EXIT_FAILURE);\n  }\n  new_node->is_leaf = false;\n  new_node->num_keys = 0;\n  new_node->parent = NULL;\n  new_node->next = NULL;\n  return new_node;\n}\n\n\n\n  node *\nmake_leaf( void ) \n{\n  node* leaf = make_node();\n  leaf->is_leaf = true;\n  return leaf;\n}\n\n\n\n  int \nget_left_index(node* parent, node* left) \n{\n\n  int left_index = 0;\n  while (left_index <= parent->num_keys && \n      parent->pointers[left_index] != left)\n    left_index++;\n  return left_index;\n}\n\n\n\n  node *\ninsert_into_leaf( node* leaf, int key, record* pointer ) \n{\n\n  int i, insertion_point;\n\n  insertion_point = 0;\n  while (insertion_point < leaf->num_keys && leaf->keys[insertion_point] < key)\n    insertion_point++;\n\n  for (i = leaf->num_keys; i > insertion_point; i--) {\n    leaf->keys[i] = leaf->keys[i - 1];\n    leaf->pointers[i] = leaf->pointers[i - 1];\n  }\n  leaf->keys[insertion_point] = key;\n  leaf->pointers[insertion_point] = pointer;\n  leaf->num_keys++;\n  return leaf;\n}\n\n\n\n  node *\ninsert_into_leaf_after_splitting(  node* root, \n    node* leaf, \n    int key, \n    record* pointer) \n{\n\n  node * new_leaf;\n  int * temp_keys;\n  void ** temp_pointers;\n  int insertion_index, split, new_key, i, j;\n\n  new_leaf = make_leaf();\n\n  temp_keys = (int *) malloc( order * sizeof(int) );\n  if (temp_keys == NULL) {\n    perror(\"Temporary keys array.\");\n    exit(EXIT_FAILURE);\n  }\n\n  temp_pointers = (void **) malloc( order * sizeof(void *) );\n  if (temp_pointers == NULL) {\n    perror(\"Temporary pointers array.\");\n    exit(EXIT_FAILURE);\n  }\n\n  insertion_index = 0;\n  while (leaf->keys[insertion_index] < key && insertion_index < order - 1)\n    insertion_index++;\n\n  for (i = 0, j = 0; i < leaf->num_keys; i++, j++) {\n    if (j == insertion_index) j++;\n    temp_keys[j] = leaf->keys[i];\n    temp_pointers[j] = leaf->pointers[i];\n  }\n\n  temp_keys[insertion_index] = key;\n  temp_pointers[insertion_index] = pointer;\n\n  leaf->num_keys = 0;\n\n  split = cut(order - 1);\n\n  for (i = 0; i < split; i++) {\n    leaf->pointers[i] = temp_pointers[i];\n    leaf->keys[i] = temp_keys[i];\n    leaf->num_keys++;\n  }\n\n  for (i = split, j = 0; i < order; i++, j++) {\n    new_leaf->pointers[j] = temp_pointers[i];\n    new_leaf->keys[j] = temp_keys[i];\n    new_leaf->num_keys++;\n  }\n\n  free(temp_pointers);\n  free(temp_keys);\n\n  new_leaf->pointers[order - 1] = leaf->pointers[order - 1];\n  leaf->pointers[order - 1] = new_leaf;\n\n  for (i = leaf->num_keys; i < order - 1; i++)\n    leaf->pointers[i] = NULL;\n  for (i = new_leaf->num_keys; i < order - 1; i++)\n    new_leaf->pointers[i] = NULL;\n\n  new_leaf->parent = leaf->parent;\n  new_key = new_leaf->keys[0];\n\n  return insert_into_parent(root, leaf, new_key, new_leaf);\n}\n\n\n\n  node *\ninsert_into_node(  node* root, \n    node* n, \n    int left_index, \n    int key, \n    node* right) \n{\n\n  int i;\n\n  for (i = n->num_keys; i > left_index; i--) {\n    n->pointers[i + 1] = n->pointers[i];\n    n->keys[i] = n->keys[i - 1];\n  }\n  n->pointers[left_index + 1] = right;\n  n->keys[left_index] = key;\n  n->num_keys++;\n  return root;\n}\n\n\n\n  node *\ninsert_into_node_after_splitting(  node* root, \n    node* old_node, \n    int left_index, \n    int key, \n    node * right) \n{\n\n  int i, j, split, k_prime;\n  node * new_node, * child;\n  int * temp_keys;\n  node ** temp_pointers;\n\n  \n\n\n  temp_pointers = (node **) malloc( (order + 1) * sizeof(node *) );\n  if (temp_pointers == NULL) {\n    perror(\"Temporary pointers array for splitting nodes.\");\n    exit(EXIT_FAILURE);\n  }\n  temp_keys = (int *) malloc( order * sizeof(int) );\n  if (temp_keys == NULL) {\n    perror(\"Temporary keys array for splitting nodes.\");\n    exit(EXIT_FAILURE);\n  }\n\n  for (i = 0, j = 0; i < old_node->num_keys + 1; i++, j++) {\n    if (j == left_index + 1) j++;\n    temp_pointers[j] = (node *) old_node->pointers[i];\n  }\n\n  for (i = 0, j = 0; i < old_node->num_keys; i++, j++) {\n    if (j == left_index) j++;\n    temp_keys[j] = old_node->keys[i];\n  }\n\n  temp_pointers[left_index + 1] = right;\n  temp_keys[left_index] = key;\n\n  \n  \n  split = cut(order);\n  new_node = make_node();\n  old_node->num_keys = 0;\n  for (i = 0; i < split - 1; i++) {\n    old_node->pointers[i] = temp_pointers[i];\n    old_node->keys[i] = temp_keys[i];\n    old_node->num_keys++;\n  }\n  old_node->pointers[i] = temp_pointers[i];\n  k_prime = temp_keys[split - 1];\n  for (++i, j = 0; i < order; i++, j++) {\n    new_node->pointers[j] = temp_pointers[i];\n    new_node->keys[j] = temp_keys[i];\n    new_node->num_keys++;\n  }\n  new_node->pointers[j] = temp_pointers[i];\n  free(temp_pointers);\n  free(temp_keys);\n  new_node->parent = old_node->parent;\n  for (i = 0; i <= new_node->num_keys; i++) {\n    child = (node *) new_node->pointers[i];\n    child->parent = new_node;\n  }\n\n  \n\n\n  return insert_into_parent(root, old_node, k_prime, new_node);\n}\n\n\n\n  node *\ninsert_into_parent(  node* root, \n    node* left, \n    int key, \n    node* right) \n{\n\n  int left_index;\n  node * parent;\n\n  parent = left->parent;\n\n  \n\n\n  if (parent == NULL)\n    return insert_into_new_root(left, key, right);\n\n  \n\n\n  \n\n\n  left_index = get_left_index(parent, left);\n\n\n  \n\n\n  if (parent->num_keys < order - 1)\n    return insert_into_node(root, parent, left_index, key, right);\n\n  \n\n\n  return insert_into_node_after_splitting(root, parent, left_index, key, right);\n}\n\n\n\n  node *\ninsert_into_new_root(  node* left, \n    int key, \n    node* right) \n{\n\n  node * root = make_node();\n  root->keys[0] = key;\n  root->pointers[0] = left;\n  root->pointers[1] = right;\n  root->num_keys++;\n  root->parent = NULL;\n  left->parent = root;\n  right->parent = root;\n  return root;\n}\n\n\n\n  node *\nstart_new_tree(  int key, \n    record* pointer) \n{\n\n  node * root = make_leaf();\n  root->keys[0] = key;\n  root->pointers[0] = pointer;\n  root->pointers[order - 1] = NULL;\n  root->parent = NULL;\n  root->num_keys++;\n  return root;\n}\n\n\n\n  node *\ninsert(  node* root, \n    int key, \n    int value ) \n{\n\n  record* pointer;\n  node* leaf;\n\n  \n\n  if (find(root, key, false) != NULL)\n    return root;\n\n  \n\n  pointer = make_record(value);\n\n  \n\n  if (root == NULL) \n    return start_new_tree(key, pointer);\n\n  \n\n  leaf = find_leaf(root, key, false);\n\n  \n\n  if (leaf->num_keys < order - 1) {\n    leaf = insert_into_leaf(leaf, key, pointer);\n    return root;\n  }\n\n  \n\n  return insert_into_leaf_after_splitting(root, leaf, key, pointer);\n}\n\n\n\n\n\n\n\n\n\n\n  int \nget_neighbor_index( node* n ) \n{\n\n  int i;\n\n  \n\n  for (i = 0; i <= n->parent->num_keys; i++)\n    if (n->parent->pointers[i] == n)\n      return i - 1;\n\n  \n\n  printf(\"Search for nonexistent pointer to node in parent.\\n\");\n  \n\n  exit(EXIT_FAILURE);\n}\n\n\n\n  node* \nremove_entry_from_node(  node* n, \n    int key, \n    node * pointer) \n{\n\n  int i, num_pointers;\n\n  \n\n  i = 0;\n  while (n->keys[i] != key)\n    i++;\n  for (++i; i < n->num_keys; i++)\n    n->keys[i - 1] = n->keys[i];\n\n  \n\n  \n\n  num_pointers = n->is_leaf ? n->num_keys : n->num_keys + 1;\n  i = 0;\n  while (n->pointers[i] != pointer)\n    i++;\n  for (++i; i < num_pointers; i++)\n    n->pointers[i - 1] = n->pointers[i];\n\n\n  \n\n  n->num_keys--;\n\n  \n\n  \n\n  if (n->is_leaf)\n    for (i = n->num_keys; i < order - 1; i++)\n      n->pointers[i] = NULL;\n  else\n    for (i = n->num_keys + 1; i < order; i++)\n      n->pointers[i] = NULL;\n\n  return n;\n}\n\n\n\n  node* \nadjust_root(node* root) \n{\n\n  node * new_root;\n\n  \n\n\n  if (root->num_keys > 0)\n    return root;\n\n  \n\n\n  \n\n  \n\n  \n\n\n  if (!root->is_leaf) {\n    new_root = (node *) root->pointers[0];\n    new_root->parent = NULL;\n  }\n\n  \n\n  \n\n\n  else\n    new_root = NULL;\n\n  free(root->keys);\n  free(root->pointers);\n  free(root);\n\n  return new_root;\n}\n\n\n\n  node* \ncoalesce_nodes(  node* root, \n    node* n, \n    node* neighbor, \n    int neighbor_index, \n    int k_prime) \n{\n\n  int i, j, neighbor_insertion_index, n_start, n_end, new_k_prime;\n  node * tmp;\n  bool split;\n\n  \n\n\n  if (neighbor_index == -1) {\n    tmp = n;\n    n = neighbor;\n    neighbor = tmp;\n  }\n\n  \n\n\n  neighbor_insertion_index = neighbor->num_keys;\n\n  \n\n\n  split = false;\n\n  \n\n\n  if (!n->is_leaf) {\n\n    \n\n\n    neighbor->keys[neighbor_insertion_index] = k_prime;\n    neighbor->num_keys++;\n\n\n    \n\n\n    n_end = n->num_keys;\n\n    \n\n    n_start = 0; \n\n    if (n->num_keys + neighbor->num_keys >= order) {\n      split = true;\n      n_end = cut(order) - 2;\n    }\n\n    for (i = neighbor_insertion_index + 1, j = 0; j < n_end; i++, j++) {\n      neighbor->keys[i] = n->keys[j];\n      neighbor->pointers[i] = n->pointers[j];\n      neighbor->num_keys++;\n      n->num_keys--;\n      n_start++;\n    }\n\n    \n\n\n    neighbor->pointers[i] = n->pointers[j];\n\n    \n\n    if (split) {\n      new_k_prime = n->keys[n_start];\n      for (i = 0, j = n_start + 1; i < n->num_keys; i++, j++) {\n        n->keys[i] = n->keys[j];\n        n->pointers[i] = n->pointers[j];\n      }\n      n->pointers[i] = n->pointers[j];\n      n->num_keys--;\n    }\n\n    \n\n\n    for (i = 0; i < neighbor->num_keys + 1; i++) {\n      tmp = (node *)neighbor->pointers[i];\n      tmp->parent = neighbor;\n    }\n  }\n\n  \n\n\n  else {\n    for (i = neighbor_insertion_index, j = 0; j < n->num_keys; i++, j++) {\n      neighbor->keys[i] = n->keys[j];\n      neighbor->pointers[i] = n->pointers[j];\n      neighbor->num_keys++;\n    }\n    neighbor->pointers[order - 1] = n->pointers[order - 1];\n  }\n\n  if (!split) {\n    root = delete_entry(root, n->parent, k_prime, n);\n    free(n->keys);\n    free(n->pointers);\n    free(n); \n  }\n  else\n    for (i = 0; i < n->parent->num_keys; i++)\n      if (n->parent->pointers[i + 1] == n) {\n        n->parent->keys[i] = new_k_prime;\n        break;\n      }\n\n  return root;\n\n}\n\n\n\n  node* \nredistribute_nodes(  node* root, \n    node* n, \n    node* neighbor, \n    int neighbor_index, \n    int k_prime_index, \n    int k_prime) \n{  \n\n  int i;\n  node * tmp;\n\n  \n\n\n  if (neighbor_index != -1) {\n    if (!n->is_leaf)\n      n->pointers[n->num_keys + 1] = n->pointers[n->num_keys];\n    for (i = n->num_keys; i > 0; i--) {\n      n->keys[i] = n->keys[i - 1];\n      n->pointers[i] = n->pointers[i - 1];\n    }\n    if (!n->is_leaf) {\n      n->pointers[0] = neighbor->pointers[neighbor->num_keys];\n      tmp = (node *)n->pointers[0];\n      tmp->parent = n;\n      neighbor->pointers[neighbor->num_keys] = NULL;\n      n->keys[0] = k_prime;\n      n->parent->keys[k_prime_index] = neighbor->keys[neighbor->num_keys - 1];\n    }\n    else {\n      n->pointers[0] = neighbor->pointers[neighbor->num_keys - 1];\n      neighbor->pointers[neighbor->num_keys - 1] = NULL;\n      n->keys[0] = neighbor->keys[neighbor->num_keys - 1];\n      n->parent->keys[k_prime_index] = n->keys[0];\n    }\n  }\n\n  \n\n\n  else {  \n    if (n->is_leaf) {\n      n->keys[n->num_keys] = neighbor->keys[0];\n      n->pointers[n->num_keys] = neighbor->pointers[0];\n      n->parent->keys[k_prime_index] = neighbor->keys[1];\n    }\n    else {\n      n->keys[n->num_keys] = k_prime;\n      n->pointers[n->num_keys + 1] = neighbor->pointers[0];\n      tmp = (node *)n->pointers[n->num_keys + 1];\n      tmp->parent = n;\n      n->parent->keys[k_prime_index] = neighbor->keys[0];\n    }\n    for (i = 0; i < neighbor->num_keys; i++) {\n      neighbor->keys[i] = neighbor->keys[i + 1];\n      neighbor->pointers[i] = neighbor->pointers[i + 1];\n    }\n    if (!n->is_leaf)\n      neighbor->pointers[i] = neighbor->pointers[i + 1];\n  }\n\n  \n\n\n  n->num_keys++;\n  neighbor->num_keys--;\n\n  return root;\n}\n\n\n\n  node* \ndelete_entry(  node* root, \n    node* n, \n    int key, \n    void* pointer ) \n{\n\n  int min_keys;\n  node * neighbor;\n  int neighbor_index;\n  int k_prime_index, k_prime;\n  int capacity;\n\n  \n\n\n  n = remove_entry_from_node(n, key, (node *) pointer);\n\n  \n\n\n  if (n == root) \n    return adjust_root(root);\n\n\n  \n\n\n  \n\n\n  min_keys = n->is_leaf ? cut(order - 1) : cut(order) - 1;\n\n  \n\n\n  if (n->num_keys >= min_keys)\n    return root;\n\n  \n\n\n  \n\n\n  neighbor_index = get_neighbor_index( n );\n  k_prime_index = neighbor_index == -1 ? 0 : neighbor_index;\n  k_prime = n->parent->keys[k_prime_index];\n  neighbor = neighbor_index == -1 ? (node *) n->parent->pointers[1] : \n    (node *)n->parent->pointers[neighbor_index];\n\n  capacity = n->is_leaf ? order : order - 1;\n\n  \n\n\n  if (neighbor->num_keys + n->num_keys < capacity)\n    return coalesce_nodes(root, n, neighbor, neighbor_index, k_prime);\n\n  \n\n\n  else\n    return redistribute_nodes(root, n, neighbor, neighbor_index, k_prime_index, k_prime);\n}\n\n\n\n  node* \ndeleteVal(  node* root, \n    int key) \n{\n\n  node * key_leaf;\n  record * key_record;\n\n  key_record = find(root, key, false);\n  key_leaf = find_leaf(root, key, false);\n  if (key_record != NULL && key_leaf != NULL) {\n    free(key_record);\n    root = delete_entry(root, key_leaf, key, key_record);\n  }\n  return root;\n}\n\n\n\n  void \ndestroy_tree_nodes(node* root) \n{\n  int i;\n  if (root->is_leaf)\n    for (i = 0; i < root->num_keys; i++)\n      free(root->pointers[i]);\n  else\n    for (i = 0; i < root->num_keys + 1; i++)\n      destroy_tree_nodes((node *) root->pointers[i]);\n  free(root->pointers);\n  free(root->keys);\n  free(root);\n}\n\n\n\n  node* \ndestroy_tree(node* root) \n{\n  destroy_tree_nodes(root);\n  return NULL;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  int \nmain( int argc, char** argv )\n{\n\n  printf(\"WG size of kernel 1 = %d WG size of kernel 2 = %d \\n\", DEFAULT_ORDER, DEFAULT_ORDER_2);\n  \n\n  \n\n  \n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  \n\n  \n\n  \n\n\n  \n\n  int cur_arg;\n  int arch_arg;\n  arch_arg = 0;\n  int cores_arg;\n  cores_arg = 1;\n  char *input_file = NULL;\n  char *command_file = NULL;\n  const char *output=\"output.txt\";\n  FILE * pFile;\n\n  \n\n  for(cur_arg=1; cur_arg<argc; cur_arg++){\n    \n\n    if(strcmp(argv[cur_arg], \"file\")==0){\n      \n\n      if(argc>=cur_arg+1){\n        input_file = argv[cur_arg+1];\n        cur_arg = cur_arg+1;\n        \n\n      }\n      \n\n      else{\n        printf(\"ERROR: Missing value to -file parameter\\n\");\n        return -1;\n      }\n    }\n    else if(strcmp(argv[cur_arg], \"command\")==0){\n      \n\n      if(argc>=cur_arg+1){\n        command_file = argv[cur_arg+1];\n        cur_arg = cur_arg+1;\n        \n\n      }\n      \n\n      else{\n        printf(\"ERROR: Missing value to command parameter\\n\");\n        return -1;\n      }\n    }\n  }\n  \n\n  if((input_file==NULL)||(command_file==NULL))\n    printf(\"Usage: ./b+tree file input_file command command_list\\n\");\n\n  \n\n  printf(\"Input File: %s \\n\", input_file);\n  printf(\"Command File: %s \\n\", command_file);\n\n\n  FILE * commandFile;\n  long lSize;\n  char * commandBuffer;\n  size_t result;\n\n  commandFile = fopen ( command_file, \"rb\" );\n  if (commandFile==NULL) {fputs (\"Command File error\",stderr); exit (1);}\n\n  \n\n  fseek (commandFile , 0 , SEEK_END);\n  lSize = ftell (commandFile);\n  rewind (commandFile);\n\n  \n\n  commandBuffer = (char*) malloc (sizeof(char)*lSize);\n  if (commandBuffer == NULL) {fputs (\"Command Buffer memory error\",stderr); exit (2);}\n\n  \n\n  result = fread (commandBuffer,1,lSize,commandFile);\n  if (result != lSize) {fputs (\"Command file reading error\",stderr); exit (3);}\n\n  \n\n\n  \n\n  fclose (commandFile);\n\n  \n\n  \n\n  printf(\"Command Buffer: \\n\");\n  printf(\"%s\",commandBuffer);\n  \n\n\n\n  pFile = fopen (output,\"w+\");\n  if (pFile==NULL) \n    printf (\"Fail to open %s !\\n\",output);\n  fprintf(pFile,\"******starting******\\n\");\n  fclose(pFile);\n\n  \n\n  \n\n  \n\n\n  FILE *file_pointer;\n  node *root;\n  root = NULL;\n  record *r;\n  int input;\n  char instruction;\n  order = DEFAULT_ORDER_2;\n  verbose_output = false;\n\n  \n\n  \n\n\n  \n\n  \n\n  \n\n\n  if (input_file != NULL) {\n\n    printf(\"Getting input from file %s...\\n\", argv[1]);\n\n    \n\n    file_pointer = fopen(input_file, \"r\");\n    if (file_pointer == NULL) {\n      perror(\"Failure to open input file.\");\n      exit(EXIT_FAILURE);\n    }\n\n    \n\n    fscanf(file_pointer, \"%d\\n\", &input);\n    size = input;\n\n    \n\n    while (!feof(file_pointer)) {\n      fscanf(file_pointer, \"%d\\n\", &input);\n      root = insert(root, input, input);\n    }\n\n    \n\n    fclose(file_pointer);\n    \n\n    \n\n\n  }\n  else{\n    printf(\"ERROR: Argument -file missing\\n\");\n    return 0;\n  }\n\n  \n\n  \n\n  \n\n\n  printf(\"Transforming data to a GPU suitable structure...\\n\");\n  long mem_used = transform_to_cuda(root,0);\n  maxheight = height(root);\n  long rootLoc = (long)knodes - (long)mem;\n\n  \n\n  \n\n  \n\n  char *commandPointer=commandBuffer;\n  printf(\"Waiting for command\\n\");\n  printf(\"> \");\n  while (sscanf(commandPointer, \"%c\", &instruction) != EOF) {\n    commandPointer++;\n    switch (instruction) {\n      \n\n      \n\n      \n\n\n      case 'i':\n        {\n          scanf(\"%d\", &input);\n          while (getchar() != (int)'\\n');\n          root = insert(root, input, input);\n          print_tree(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'f':\n        {\n        }\n\n        \n\n        \n\n        \n\n\n      case 'p':\n        {\n          scanf(\"%d\", &input);\n          while (getchar() != (int)'\\n');\n          r = find(root, input, instruction == 'p');\n          if (r == NULL)\n            printf(\"Record not found under key %d.\\n\", input);\n          else \n            printf(\"Record found: %d\\n\",r->value);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'd':\n        {\n          scanf(\"%d\", &input);\n          while (getchar() != (int)'\\n');\n          root = (node *) deleteVal(root, input);\n          print_tree(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'x':\n        {\n          while (getchar() != (int)'\\n');\n          root = destroy_tree(root);\n          print_tree(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'l':\n        {\n          while (getchar() != (int)'\\n');\n          print_leaves(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 't':\n        {\n          while (getchar() != (int)'\\n');\n          print_tree(root);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'v':\n        {\n          while (getchar() != (int)'\\n');\n          verbose_output = !verbose_output;\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'q':\n        {\n          while (getchar() != (int)'\\n');\n          return EXIT_SUCCESS;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'k':\n        {\n\n          \n\n          int count;\n          sscanf(commandPointer, \"%d\", &count);\n          while(*commandPointer!=32 && *commandPointer!='\\n')\n            commandPointer++;\n\n          printf(\"\\n ******command: k count=%d \\n\",count);\n          if(count > 65535){\n            printf(\"ERROR: Number of requested querries should be 65,535 at most. (limited by # of teams)\\n\");\n            exit(0);\n          }\n\n          \n\n          record *records = (record *)mem;\n          long records_elem = (long)rootLoc / sizeof(record);\n          long records_mem = (long)rootLoc;\n          printf(\"records_elem=%d, records_unit_mem=%d, records_mem=%d\\n\", (int)records_elem, (int)sizeof(record), (int)records_mem);\n\n          \n\n          knode *knodes = (knode *)((long)mem + (long)rootLoc);\n          long knodes_elem = ((long)(mem_used) - (long)rootLoc) / sizeof(knode);\n          long knodes_mem = (long)(mem_used) - (long)rootLoc;\n          printf(\"knodes_elem=%d, knodes_unit_mem=%d, knodes_mem=%d\\n\", (int)knodes_elem, (int)sizeof(knode), (int)knodes_mem);\n\n          \n\n          long *currKnode;\n          currKnode = (long *)malloc(count*sizeof(long));\n          \n\n          memset(currKnode, 0, count*sizeof(long));\n\n          \n\n          long *offset;\n          offset = (long *)malloc(count*sizeof(long));\n          \n\n          memset(offset, 0, count*sizeof(long));\n\n          \n\n          int *keys;\n          keys = (int *)malloc(count*sizeof(int));\n          \n\n          srand(123);\n          int i;\n          for(i = 0; i < count; i++){\n            keys[i] = (rand()/(float)RAND_MAX)*size;\n          }\n\n          \n\n          record *ans = (record *)malloc(sizeof(record)*count);\n          \n\n          for(i = 0; i < count; i++){\n            ans[i].value = -1;\n          }\n\n          \n\n          kernel_wrapper(  records,\n              records_elem, \n\n              knodes,\n              knodes_elem,\n              knodes_elem,\n\n\n              order,\n              maxheight,\n              count,\n\n              currKnode,\n              offset,\n              keys,\n              ans);\n\n          pFile = fopen (output,\"aw+\");\n          if (pFile==NULL)\n          {\n            printf (\"Fail to open %s !\\n\",output);\n          }\n\n          fprintf(pFile,\"\\n ******command: k count=%d \\n\",count);\n          for(i = 0; i < count; i++){\n            fprintf(pFile, \"%d    %d\\n\",i, ans[i].value);\n          }\n          fprintf(pFile, \" \\n\");\n          fclose(pFile);\n\n\n          \n\n          free(currKnode);\n          free(offset);\n          free(keys);\n          free(ans);\n\n          \n\n          break;\n\n        }\n\n        \n\n        \n\n        \n\n\n      case 'r':\n        {\n          int start, end;\n          scanf(\"%d\", &start);\n          scanf(\"%d\", &end);\n          if(start > end){\n            input = start;\n            start = end;\n            end = input;\n          }\n          printf(\"For range %d to %d, \",start,end);\n          list_t * ansList;\n          ansList = findRange(root, start, end);\n          printf(\"%d records found\\n\", list_get_length(ansList));\n          \n\n          free(ansList);\n          break;\n        }\n\n        \n\n        \n\n        \n\n\n      case 'j':\n        {\n\n          \n\n          int count;\n          sscanf(commandPointer, \"%d\", &count);\n          while(*commandPointer!=32 && *commandPointer!='\\n')\n            commandPointer++;\n\n          int rSize;\n          sscanf(commandPointer, \"%d\", &rSize);\n          while(*commandPointer!=32 && *commandPointer!='\\n')\n            commandPointer++;\n\n          printf(\"\\n******command: j count=%d, rSize=%d \\n\",count, rSize);\n\n          if(rSize > size || rSize < 0) {\n            printf(\"Search range size is larger than data set size %d.\\n\", (int)size);\n            exit(0);\n          }\n\n          \n\n          knode *knodes = (knode *)((long)mem + (long)rootLoc);\n          long knodes_elem = ((long)(mem_used) - (long)rootLoc) / sizeof(knode);\n          long knodes_mem = (long)(mem_used) - (long)rootLoc;\n          printf(\"knodes_elem=%d, knodes_unit_mem=%d, knodes_mem=%d\\n\", (int)knodes_elem, (int)sizeof(knode), (int)knodes_mem);\n\n          \n\n          long *currKnode;\n          currKnode = (long *)malloc(count*sizeof(long));\n          \n\n          memset (currKnode, 0, count*sizeof(long));\n\n          \n\n          long *offset;\n          offset = (long *)malloc(count*sizeof(long));\n          \n\n          memset (offset, 0, count*sizeof(long));\n\n          \n\n          long *lastKnode;\n          lastKnode = (long *)malloc(count*sizeof(long));\n          \n\n          memset (lastKnode, 0, count*sizeof(long));\n\n          \n\n          long *offset_2;\n          offset_2 = (long *)malloc(count*sizeof(long));\n          \n\n          memset (offset_2, 0, count*sizeof(long));\n\n          \n\n          int *start;\n          start = (int *)malloc(count*sizeof(int));\n          int *end;\n          end = (int *)malloc(count*sizeof(int));\n          \n\n          srand(123);\n          int i;\n          for(i = 0; i < count; i++){\n            start[i] = (rand()/(float)RAND_MAX)*size;\n            end[i] = start[i]+rSize;\n            if(end[i] >= size){ \n              start[i] = start[i] - (end[i] - size);\n              end[i]= size-1;\n            }\n          }\n\n          \n\n          int *recstart;\n          recstart = (int *)malloc(count*sizeof(int));\n          int *reclength;\n          reclength = (int *)malloc(count*sizeof(int));\n          \n\n          for(i = 0; i < count; i++){\n            recstart[i] = 0;\n            reclength[i] = 0;\n          }\n\n          kernel2_wrapper(knodes,\n              knodes_elem,\n              knodes_elem, \n\n\n              order,\n              maxheight,\n              count,\n\n              currKnode,\n              offset,\n              lastKnode,\n              offset_2,\n              start,\n              end,\n              recstart,\n              reclength);\n\n\n          pFile = fopen (output,\"aw+\");\n          if (pFile==NULL)\n          {\n            printf (\"Fail to open %s !\\n\",output);\n          }\n\n          fprintf(pFile,\"\\n******command: j count=%d, rSize=%d \\n\",count, rSize);        \n          for(i = 0; i < count; i++){\n            fprintf(pFile, \"%d    %d    %d\\n\",i, recstart[i],reclength[i]);\n          }\n          fprintf(pFile, \" \\n\");\n          fclose(pFile);\n\n          \n\n          free(currKnode);\n          free(offset);\n          free(lastKnode);\n          free(offset_2);\n          free(start);\n          free(end);\n          free(recstart);\n          free(reclength);\n\n          \n\n          break;\n\n        }\n\n        \n\n        \n\n        \n\n\n      default:\n        {\n\n          \n\n          break;\n\n        }\n\n    }\n    printf(\"> \");\n\n  }\n  printf(\"\\n\");\n\n  \n\n  \n\n  \n\n\n  free(mem);\n  return EXIT_SUCCESS;\n\n}\n\n\n\n\n\n\n\n", "kernel2_wrapper.c": "#include <stdio.h>\n#include <string.h>\n#include \"../common.h\"                \n\n#include \"../util/timer/timer.h\"          \n\n#include \"./kernel2_wrapper.h\"      \n\n\n\n\n\n\n\n\n\nvoid \nkernel2_wrapper(\n    knode *knodes,\n    long knodes_elem,\n    long knodes_mem,  \n\n\n    int order,\n    long maxheight,\n    int count,\n\n    long *currKnode,\n    long *offset,\n    long *lastKnode,\n    long *offset_2,\n    int *start,\n    int *end,\n    int *recstart,\n    int *reclength)\n{\n\n  \n\n  \n\n  \n\n\n  \n\n\n  size_t threads;\n  threads = order < 256 ? order : 256;\n\n  {\n    long long kernel_start = get_time();\n\n        {\n            {\n        \n\n        int thid = omp_get_thread_num();\n        int bid = omp_get_team_num();\n\n        int i;\n        for(i = 0; i < maxheight; i++){\n\n          if((knodes[currKnode[bid]].keys[thid] <= start[bid]) && (knodes[currKnode[bid]].keys[thid+1] > start[bid])){\n            \n\n            \n\n            \n\n            if(knodes[currKnode[bid]].indices[thid] < knodes_elem) {\n              offset[bid] = knodes[currKnode[bid]].indices[thid];\n            }\n          }\n          if((knodes[lastKnode[bid]].keys[thid] <= end[bid]) && (knodes[lastKnode[bid]].keys[thid+1] > end[bid])){\n            \n\n            \n\n            \n\n            if(knodes[lastKnode[bid]].indices[thid] < knodes_elem) {\n              offset_2[bid] = knodes[lastKnode[bid]].indices[thid];\n            }\n          }\n                    \n\n          if(thid==0){\n            currKnode[bid] = offset[bid];\n            lastKnode[bid] = offset_2[bid];\n          }\n                  }\n\n        \n\n        if(knodes[currKnode[bid]].keys[thid] == start[bid]){\n          recstart[bid] = knodes[currKnode[bid]].indices[thid];\n        }\n        \n        \n\n        if(knodes[lastKnode[bid]].keys[thid] == end[bid]){\n          reclength[bid] = knodes[lastKnode[bid]].indices[thid] - recstart[bid]+1;\n        }\n      }\n    }\n    long long kernel_end = get_time();\n    printf(\"Kernel execution time: %f (us)\\n\", (float)(kernel_end-kernel_start));\n  }\n\n#ifdef DEBUG\n  for (int i = 0; i < count; i++)\n\t  printf(\"recstart[%d] = %d\\n\", i, recstart[i]);\n  for (int i = 0; i < count; i++)\n\t  printf(\"reclength[%d] = %d\\n\", i, reclength[i]);\n#endif\n\n}\n", "kernel_wrapper.c": "#include <stdio.h>\n#include <string.h>\n#include \"../common.h\"                \n\n#include \"../util/timer/timer.h\"          \n\n#include \"./kernel_wrapper.h\"      \n\n\n\nvoid \nkernel_wrapper(  record *records,\n    long records_mem, \n\n    knode *knodes,\n    long knodes_elem,\n    long knodes_mem,  \n\n\n    int order,\n    long maxheight,\n    int count,\n\n    long *currKnode,\n    long *offset,\n    int *keys,\n    record *ans)\n{\n\n  \n\n  \n\n  \n\n\n  \n\n\n  int threads = order < 256 ? order : 256;\n\n    {\n    long long kernel_start = get_time();\n\n        {\n            {\n        \n\n        int thid = omp_get_thread_num();\n        int bid = omp_get_team_num();\n\n        \n\n        for(int i = 0; i < maxheight; i++){\n\n          \n\n          if((knodes[currKnode[bid]].keys[thid]) <= keys[bid] && (knodes[currKnode[bid]].keys[thid+1] > keys[bid])){\n            \n\n            \n\n            \n\n            if(knodes[offset[bid]].indices[thid] < knodes_elem){\n              offset[bid] = knodes[offset[bid]].indices[thid];\n            }\n          }\n                    \n\n          if(thid==0){\n            currKnode[bid] = offset[bid];\n          }\n                  }\n\n        \n\n        \n\n        if(knodes[currKnode[bid]].keys[thid] == keys[bid]){\n          ans[bid].value = records[knodes[currKnode[bid]].indices[thid]].value;\n        }\n      }\n    }\n    long long kernel_end = get_time();\n    printf(\"Kernel execution time: %f (us)\\n\", (float)(kernel_end-kernel_start));\n  } \n\n#ifdef DEBUG\n  for (int i = 0; i < count; i++)\n    printf(\"ans[%d] = %d\\n\", i, ans[i].value);\n  printf(\"\\n\");\n#endif\n\n}\n"}}
{"kernel_name": "bezier-surface", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n#include <cuda.h>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\n__host__ __device__\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n    blend *= pow(mu, (FLOAT)k);\n  if(n - k > 0)\n    blend *= pow(1 - mu, (FLOAT)(n - k));\n  return (blend);\n}\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\n__global__\nvoid BezierGPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n\n  i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i > RESOLUTIONI) return;\n\n  mui = i / (FLOAT)(RESOLUTIONI - 1);\n  for(j = 0; j < RESOLUTIONJ; j++) {\n    muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n    XYZ out = {0, 0, 0};\n    \n\n    for(ki = 0; ki <= NI; ki++) {\n      bi = BezierBlend(ki, mui, NI);\n      \n\n      for(kj = 0; kj <= NJ; kj++) {\n        bj = BezierBlend(kj, muj, NJ);\n        out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n        out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n        out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n      }\n    }\n    outp[i * RESOLUTIONJ + j] = out;\n  }\n\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n  \n\n\n  XYZ *d_in;\n  XYZ *d_out;\n  int in_size   = (in_size_i + 1) * (in_size_j + 1) * sizeof(XYZ);\n  int out_size  = out_size_i * out_size_j * sizeof(XYZ);\n\n  cudaMalloc((void**)&d_in, in_size);\n  cudaMalloc((void**)&d_out, out_size);\n\n  cudaMemcpy(d_in, in, in_size, cudaMemcpyHostToDevice);\n\n  dim3 block(p.work_group_size);\n  dim3 grid((out_size_i + p.work_group_size - 1) / p.work_group_size);\n\n  cudaDeviceSynchronize();\n  auto kstart = std::chrono::steady_clock::now();\n\n  BezierGPU <<< grid, block >>> (d_in, d_out, in_size_i, in_size_j, out_size_i, out_size_j);\n\n  cudaDeviceSynchronize();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n  std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n\n  cudaMemcpy(gpu_out, d_out, out_size, cudaMemcpyDeviceToHost);\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n  cudaFree(d_in);\n  cudaFree(d_out);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}\n"}}
{"kernel_name": "bezier-surface", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n#include <hip/hip_runtime.h>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\n__host__ __device__\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n    blend *= pow(mu, (FLOAT)k);\n  if(n - k > 0)\n    blend *= pow(1 - mu, (FLOAT)(n - k));\n  return (blend);\n}\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\n__global__\nvoid BezierGPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n\n  i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i > RESOLUTIONI) return;\n\n  mui = i / (FLOAT)(RESOLUTIONI - 1);\n  for(j = 0; j < RESOLUTIONJ; j++) {\n    muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n    XYZ out = {0, 0, 0};\n    \n\n    for(ki = 0; ki <= NI; ki++) {\n      bi = BezierBlend(ki, mui, NI);\n      \n\n      for(kj = 0; kj <= NJ; kj++) {\n        bj = BezierBlend(kj, muj, NJ);\n        out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n        out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n        out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n      }\n    }\n    outp[i * RESOLUTIONJ + j] = out;\n  }\n\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n  \n\n\n  XYZ *d_in;\n  XYZ *d_out;\n  int in_size   = (in_size_i + 1) * (in_size_j + 1) * sizeof(XYZ);\n  int out_size  = out_size_i * out_size_j * sizeof(XYZ);\n\n  hipMalloc((void**)&d_in, in_size);\n  hipMalloc((void**)&d_out, out_size);\n\n  hipMemcpy(d_in, in, in_size, hipMemcpyHostToDevice);\n\n  dim3 block(p.work_group_size);\n  dim3 grid((out_size_i + p.work_group_size - 1) / p.work_group_size);\n\n  hipDeviceSynchronize();\n  auto kstart = std::chrono::steady_clock::now();\n\n  hipLaunchKernelGGL(BezierGPU, grid, block , 0, 0, d_in, d_out, in_size_i, in_size_j, out_size_i, out_size_j);\n\n  hipDeviceSynchronize();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n  std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n\n  hipMemcpy(gpu_out, d_out, out_size, hipMemcpyDeviceToHost);\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n  hipFree(d_in);\n  hipFree(d_out);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}\n"}}
{"kernel_name": "bezier-surface", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\n#pragma omp declare target\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n#if DOUBLE_PRECISION\n    blend *= pow(mu, (FLOAT)k);\n#else\n  blend *= powf(mu, (FLOAT)k);\n#endif\n  if(n - k > 0)\n#if DOUBLE_PRECISION\n    blend *= pow(1 - mu, (FLOAT)(n - k));\n#else\n  blend *= powf(1 - mu, (FLOAT)(n - k));\n#endif\n  return (blend);\n}\n#pragma omp end declare target\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n  #pragma omp target data map(to: in[0:(in_size_i+1)*(in_size_j+1)]) \\\n                          map(from: gpu_out [0:out_size_i*out_size_j])\n  {\n    auto kstart = std::chrono::steady_clock::now();\n\n    #pragma omp target teams distribute parallel for simd thread_limit(256)\n    for (int i = 0; i < out_size_i; i++) {\n      FLOAT   mui = i / (FLOAT)(out_size_i - 1);\n      for(int j = 0; j < out_size_j; j++) {\n        FLOAT muj     = j / (FLOAT)(out_size_j - 1);\n        XYZ out = {0, 0, 0};\n        \n\n        for(int ki = 0; ki <= in_size_i; ki++) {\n          FLOAT bi = BezierBlend(ki, mui, in_size_i);\n          \n\n          for(int kj = 0; kj <= in_size_j; kj++) {\n            FLOAT bj = BezierBlend(kj, muj, in_size_j);\n            out.x += (in[ki * (in_size_j + 1) + kj].x * bi * bj);\n            out.y += (in[ki * (in_size_j + 1) + kj].y * bi * bj);\n            out.z += (in[ki * (in_size_j + 1) + kj].z * bi * bj);\n          }\n        }\n        gpu_out[i * out_size_j + j] = out;\n      }\n    }\n\n    auto kend = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n    std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n  }\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}\n"}}
{"kernel_name": "bezier-surface", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n#if DOUBLE_PRECISION\n    blend *= pow(mu, (FLOAT)k);\n#else\n  blend *= powf(mu, (FLOAT)k);\n#endif\n  if(n - k > 0)\n#if DOUBLE_PRECISION\n    blend *= pow(1 - mu, (FLOAT)(n - k));\n#else\n  blend *= powf(1 - mu, (FLOAT)(n - k));\n#endif\n  return (blend);\n}\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n    {\n    auto kstart = std::chrono::steady_clock::now();\n\n        for (int i = 0; i < out_size_i; i++) {\n      FLOAT   mui = i / (FLOAT)(out_size_i - 1);\n      for(int j = 0; j < out_size_j; j++) {\n        FLOAT muj     = j / (FLOAT)(out_size_j - 1);\n        XYZ out = {0, 0, 0};\n        \n\n        for(int ki = 0; ki <= in_size_i; ki++) {\n          FLOAT bi = BezierBlend(ki, mui, in_size_i);\n          \n\n          for(int kj = 0; kj <= in_size_j; kj++) {\n            FLOAT bj = BezierBlend(kj, muj, in_size_j);\n            out.x += (in[ki * (in_size_j + 1) + kj].x * bi * bj);\n            out.y += (in[ki * (in_size_j + 1) + kj].y * bi * bj);\n            out.z += (in[ki * (in_size_j + 1) + kj].z * bi * bj);\n          }\n        }\n        gpu_out[i * out_size_j + j] = out;\n      }\n    }\n\n    auto kend = std::chrono::steady_clock::now();\n    auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n    std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n  }\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}"}}
{"kernel_name": "bezier-surface", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <math.h>\n#include <stdio.h>\n#include <assert.h>\n#include <unistd.h>\n#include <chrono>\n#include <iostream>\n#include <sycl/sycl.hpp>\n\n\n#if DOUBLE_PRECISION\n#define FLOAT double\n#else\n#define FLOAT float\n#endif\n\ntypedef struct {\n  FLOAT x;\n  FLOAT y;\n  FLOAT z;\n} XYZ;\n\n#define divceil(n, m) (((n)-1) / (m) + 1)\n\n\n\nstruct Params {\n\n  int         work_group_size;\n  const char *file_name;\n  int         in_size_i;\n  int         in_size_j;\n  int         out_size_i;\n  int         out_size_j;\n\n  Params(int argc, char **argv) {\n    work_group_size = 256;\n    file_name     = \"input/control.txt\";\n    in_size_i = in_size_j = 3;\n    out_size_i = out_size_j = 300;\n    int opt;\n    while((opt = getopt(argc, argv, \"hp:d:i:g:t:w:r:a:f:m:n:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'g': work_group_size = atoi(optarg); break;\n        case 'f': file_name = optarg; break;\n        case 'm': in_size_i = in_size_j = atoi(optarg); break;\n        case 'n': out_size_i = out_size_j = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -g <G>    # device work-group size (default=256)\"\n        \"\\n\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -f <F>    name of input file with control points (default=input/control.txt)\"\n        \"\\n    -m <N>    input size in both dimensions (default=3)\"\n        \"\\n    -n <R>    output resolution in both dimensions (default=300)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(XYZ *in, const Params &p) {\n\n  \n\n  FILE *f = NULL;\n  f       = fopen(p.file_name, \"r\");\n  if(f == NULL) {\n    puts(\"Error opening file\");\n    exit(-1);\n  } else {\n    printf(\"Read data from file %s\\n\", p.file_name);\n  } \n\n\n  \n\n  int k = 0, ic = 0;\n  XYZ v[10000];\n#if DOUBLE_PRECISION\n  while(fscanf(f, \"%lf,%lf,%lf\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#else\n    while(fscanf(f, \"%f,%f,%f\", &v[ic].x, &v[ic].y, &v[ic].z) == 3)\n#endif\n    {\n      ic++;\n    }\n  for(int i = 0; i <= p.in_size_i; i++) {\n    for(int j = 0; j <= p.in_size_j; j++) {\n      in[i * (p.in_size_j + 1) + j].x = v[k].x;\n      in[i * (p.in_size_j + 1) + j].y = v[k].y;\n      in[i * (p.in_size_j + 1) + j].z = v[k].z;\n      \n\n      k = (k + 1) % 16;\n    }\n  }\n}\n\ninline int compare_output(XYZ *outp, XYZ *outpCPU, int NI, int NJ, int RESOLUTIONI, int RESOLUTIONJ) {\n  double sum_delta2, sum_ref2, L1norm2;\n  sum_delta2 = 0;\n  sum_ref2   = 0;\n  L1norm2    = 0;\n  for(int i = 0; i < RESOLUTIONI; i++) {\n    for(int j = 0; j < RESOLUTIONJ; j++) {\n      sum_delta2 += std::fabs(outp[i * RESOLUTIONJ + j].x - outpCPU[i * RESOLUTIONJ + j].x);\n      sum_ref2 += std::fabs(outpCPU[i * RESOLUTIONJ + j].x);\n      sum_delta2 += std::fabs(outp[i * RESOLUTIONJ + j].y - outpCPU[i * RESOLUTIONJ + j].y);\n      sum_ref2 += std::fabs(outpCPU[i * RESOLUTIONJ + j].y);\n      sum_delta2 += std::fabs(outp[i * RESOLUTIONJ + j].z - outpCPU[i * RESOLUTIONJ + j].z);\n      sum_ref2 += std::fabs(outpCPU[i * RESOLUTIONJ + j].z);\n    }\n  }\n  L1norm2 = (double)(sum_delta2 / sum_ref2);\n  if(L1norm2 >= 1e-6){\n    printf(\"Test failed\\n\");\n    return 1;\n  }\n  return 0;\n}\n\n\n\ninline FLOAT BezierBlend(int k, FLOAT mu, int n) {\n  int nn, kn, nkn;\n  FLOAT   blend = 1;\n  nn        = n;\n  kn        = k;\n  nkn       = n - k;\n  while(nn >= 1) {\n    blend *= nn;\n    nn--;\n    if(kn > 1) {\n      blend /= (FLOAT)kn;\n      kn--;\n    }\n    if(nkn > 1) {\n      blend /= (FLOAT)nkn;\n      nkn--;\n    }\n  }\n  if(k > 0)\n    blend *= sycl::pow(mu, (FLOAT)k);\n  if(n - k > 0)\n    blend *= sycl::pow(1 - mu, (FLOAT)(n - k));\n  return (blend);\n}\n\n\n\nvoid BezierCPU(const XYZ *inp, XYZ *outp, const int NI, const int NJ, const int RESOLUTIONI, const int RESOLUTIONJ) {\n  int i, j, ki, kj;\n  FLOAT   mui, muj, bi, bj;\n  for(i = 0; i < RESOLUTIONI; i++) {\n    mui = i / (FLOAT)(RESOLUTIONI - 1);\n    for(j = 0; j < RESOLUTIONJ; j++) {\n      muj     = j / (FLOAT)(RESOLUTIONJ - 1);\n      XYZ out = {0, 0, 0};\n      for(ki = 0; ki <= NI; ki++) {\n        bi = BezierBlend(ki, mui, NI);\n        for(kj = 0; kj <= NJ; kj++) {\n          bj = BezierBlend(kj, muj, NJ);\n          out.x += (inp[ki * (NJ + 1) + kj].x * bi * bj);\n          out.y += (inp[ki * (NJ + 1) + kj].y * bi * bj);\n          out.z += (inp[ki * (NJ + 1) + kj].z * bi * bj);\n        }\n      }\n      outp[i * RESOLUTIONJ + j] = out;\n    }\n  }\n}\n\nvoid run(XYZ *in, int in_size_i, int in_size_j, int out_size_i, int out_size_j, const Params &p) {\n\n  XYZ *cpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n  XYZ *gpu_out = (XYZ *)malloc(out_size_i * out_size_j * sizeof(XYZ));\n\n  \n\n  auto start = std::chrono::steady_clock::now();\n  BezierCPU(in, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n  std::cout << \"host execution time: \" << time << \" ms\" << std::endl;\n\n  \n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int in_size   = (in_size_i + 1) * (in_size_j + 1);\n  int out_size  = out_size_i * out_size_j;\n\n  XYZ *d_in = sycl::malloc_device<XYZ>(in_size, q);\n  q.memcpy(d_in, in, sizeof(XYZ) * in_size);\n\n  XYZ *d_out = sycl::malloc_device<XYZ>(out_size, q);\n\n  size_t lws = p.work_group_size;\n  size_t gws = (out_size_i + p.work_group_size - 1) / p.work_group_size * p.work_group_size;\n\n  q.wait();\n  auto kstart = std::chrono::steady_clock::now();\n\n  q.submit([&](sycl::handler& cgh) {\n    cgh.parallel_for<class bs>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      int i, j, ki, kj;\n      FLOAT   mui, muj, bi, bj;\n\n      i = item.get_global_id(0);\n      if (i >= out_size_i) return;\n\n      mui = i / (FLOAT)(out_size_i - 1);\n      for(j = 0; j < out_size_j; j++) {\n        muj     = j / (FLOAT)(out_size_j - 1);\n        XYZ out = {0, 0, 0};\n\n        \n\n        for(ki = 0; ki <= in_size_i; ki++) {\n          bi = BezierBlend(ki, mui, in_size_i);\n          \n\n          for(kj = 0; kj <= in_size_j; kj++) {\n            bj = BezierBlend(kj, muj, in_size_j);\n            out.x += (d_in[ki * (in_size_j + 1) + kj].x * bi * bj);\n            out.y += (d_in[ki * (in_size_j + 1) + kj].y * bi * bj);\n            out.z += (d_in[ki * (in_size_j + 1) + kj].z * bi * bj);\n          }\n        }\n        d_out[i * out_size_j + j] = out;\n      }\n    });\n  });\n\n  q.wait();\n  auto kend = std::chrono::steady_clock::now();\n  auto ktime = std::chrono::duration_cast<std::chrono::milliseconds>(kend - kstart).count();\n  std::cout << \"kernel execution time: \" << ktime << \" ms\" << std::endl;\n\n  q.memcpy(gpu_out, d_out, sizeof(XYZ) * out_size).wait();\n\n  \n\n  int status = compare_output(gpu_out, cpu_out, in_size_i, in_size_j, out_size_i, out_size_j);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  free(cpu_out);\n  free(gpu_out);\n  sycl::free(d_in, q);\n  sycl::free(d_out, q);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int in_size   = (p.in_size_i + 1) * (p.in_size_j + 1) * sizeof(XYZ);\n  \n\n\n  \n\n  XYZ* h_in = (XYZ *)malloc(in_size);\n  read_input(h_in, p);\n\n  \n\n  run(h_in, p.in_size_i, p.in_size_j, p.out_size_i, p.out_size_j, p);\n\n  free(h_in);\n  return 0;\n}\n"}}
{"kernel_name": "bilateral", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <cuda.h>\n#include <chrono>\n#include \"reference.h\"\n\ntemplate<int R>\n__global__ void bilateralFilter(\n    const float *__restrict__ in,\n    float *__restrict__ out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n  const int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  const int idy = blockIdx.y*blockDim.y + threadIdx.y;\n\n  if(idx >= w || idy >= h) return;\n\n  int id = idy*w + idx;\n  float I = in[id];\n  float res = 0;\n  float normalization = 0;\n\n  \n\n#ifdef LOOP_UNROLL\n  #pragma unroll\n#endif\n  for(int i = -R; i <= R; i++) {\n#ifdef LOOP_UNROLL\n    #pragma unroll\n#endif\n    for(int j = -R; j <= R; j++) {\n\n      int idk = idx+i;\n      int idl = idy+j;\n\n      \n\n      if( idk < 0) idk = -idk;\n      if( idl < 0) idl = -idl;\n      if( idk > w - 1) idk = w - 1 - i;\n      if( idl > h - 1) idl = h - 1 - j;\n\n      int id_w = idl*w + idk;\n      float I_w = in[id_w];\n\n      \n\n      float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n      \n\n      float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n                      (2.f * variance_spatial);\n\n      \n\n      \n\n      float weight = a_square * expf(spatial + range);\n\n      normalization += weight;\n      res += (I_w * weight);\n    }\n  }\n  out[id] = res/normalization;\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n   \n\n   \n\n   \n\n   \n\n  float variance_I = atof(argv[3]);\n\n   \n\n  float variance_spatial = atof(argv[4]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  int repeat = atoi(argv[5]);\n\n  float *d_src, *d_dst;\n  cudaMalloc((void**)&d_dst, img_size * sizeof(float));\n  cudaMalloc((void**)&d_src, img_size * sizeof(float));\n\n  float *h_src = (float*) malloc (img_size * sizeof(float));\n  \n\n  float *h_dst = (float*) malloc (img_size * sizeof(float));\n  float *r_dst = (float*) malloc (img_size * sizeof(float));\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n  cudaMemcpy(d_src, h_src, img_size * sizeof(float), cudaMemcpyHostToDevice); \n\n  dim3 threads (16, 16);\n  dim3 blocks ((w+15)/16, (h+15)/16);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<3><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(h_dst, d_dst, img_size * sizeof(float), cudaMemcpyDeviceToHost); \n\n  \n\n  bool ok = true;\n  reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<6><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(h_dst, d_dst, img_size * sizeof(float), cudaMemcpyDeviceToHost); \n\n  reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<9><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(h_dst, d_dst, img_size * sizeof(float), cudaMemcpyDeviceToHost); \n\n  reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  cudaFree(d_dst);\n  cudaFree(d_src);\n  return 0;\n}\n"}}
{"kernel_name": "bilateral", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <hip/hip_runtime.h>\n#include <chrono>\n#include \"reference.h\"\n\ntemplate<int R>\n__global__ void bilateralFilter(\n    const float *__restrict__ in,\n    float *__restrict__ out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n  const int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  const int idy = blockIdx.y*blockDim.y + threadIdx.y;\n\n  if(idx >= w || idy >= h) return;\n\n  int id = idy*w + idx;\n  float I = in[id];\n  float res = 0;\n  float normalization = 0;\n\n  \n\n#ifdef LOOP_UNROLL\n  #pragma unroll\n#endif\n  for(int i = -R; i <= R; i++) {\n#ifdef LOOP_UNROLL\n    #pragma unroll\n#endif\n    for(int j = -R; j <= R; j++) {\n\n      int idk = idx+i;\n      int idl = idy+j;\n\n      \n\n      if( idk < 0) idk = -idk;\n      if( idl < 0) idl = -idl;\n      if( idk > w - 1) idk = w - 1 - i;\n      if( idl > h - 1) idl = h - 1 - j;\n\n      int id_w = idl*w + idk;\n      float I_w = in[id_w];\n\n      \n\n      float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n      \n\n      float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n                      (2.f * variance_spatial);\n\n      \n\n      \n\n      float weight = a_square * expf(spatial + range);\n\n      normalization += weight;\n      res += (I_w * weight);\n    }\n  }\n  out[id] = res/normalization;\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n   \n\n   \n\n   \n\n   \n\n  float variance_I = atof(argv[3]);\n\n   \n\n  float variance_spatial = atof(argv[4]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  int repeat = atoi(argv[5]);\n\n  float *d_src, *d_dst;\n  hipMalloc((void**)&d_dst, img_size * sizeof(float));\n  hipMalloc((void**)&d_src, img_size * sizeof(float));\n\n  float *h_src = (float*) malloc (img_size * sizeof(float));\n  \n\n  float *h_dst = (float*) malloc (img_size * sizeof(float));\n  float *r_dst = (float*) malloc (img_size * sizeof(float));\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n  hipMemcpy(d_src, h_src, img_size * sizeof(float), hipMemcpyHostToDevice); \n\n  dim3 threads (16, 16);\n  dim3 blocks ((w+15)/16, (h+15)/16);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<3><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(h_dst, d_dst, img_size * sizeof(float), hipMemcpyDeviceToHost); \n\n  \n\n  bool ok = true;\n  reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<6><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(h_dst, d_dst, img_size * sizeof(float), hipMemcpyDeviceToHost); \n\n  reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    bilateralFilter<9><<<blocks, threads>>>(\n        d_src, d_dst, w, h, a_square, variance_I, variance_spatial);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(h_dst, d_dst, img_size * sizeof(float), hipMemcpyDeviceToHost); \n\n  reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  hipFree(d_dst);\n  hipFree(d_src);\n  return 0;\n}\n"}}
{"kernel_name": "bilateral", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n#include \"reference.h\"\n\ntemplate<int R>\nvoid bilateralFilter(\n    const float *__restrict in,\n    float *__restrict out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n  #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n  for (int idy = 0; idy < h; idy++)\n    for (int idx = 0; idx < w; idx++) {\n\n      int id = idy*w + idx;\n      float I = in[id];\n      float res = 0;\n      float normalization = 0;\n\n      \n\n      #ifdef LOOP_UNROLL\n      #pragma unroll\n      #endif\n      for(int i = -R; i <= R; i++) {\n      #ifdef LOOP_UNROLL\n      #pragma unroll\n      #endif\n        for(int j = -R; j <= R; j++) {\n\n          int idk = idx+i;\n          int idl = idy+j;\n\n          \n\n          if( idk < 0) idk = -idk;\n          if( idl < 0) idl = -idl;\n          if( idk > w - 1) idk = w - 1 - i;\n          if( idl > h - 1) idl = h - 1 - j;\n\n          int id_w = idl*w + idk;\n          float I_w = in[id_w];\n\n          \n\n          float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n          \n\n          float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n            (2.f * variance_spatial);\n\n          \n\n          \n\n          float weight = a_square * expf(spatial + range);\n\n          normalization += weight;\n          res += (I_w * weight);\n        }\n      }\n      out[id] = res/normalization;\n    }\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n  \n\n  \n\n  \n\n  \n\n  float variance_I = atof(argv[3]);\n\n  \n\n  float variance_spatial = atof(argv[4]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  int repeat = atoi(argv[5]);\n\n  float *h_src = (float*) malloc (img_size * sizeof(float));\n  \n\n  float *h_dst = (float*) malloc (img_size * sizeof(float));\n  float *r_dst = (float*) malloc (img_size * sizeof(float));\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n  #pragma omp target data map(to: h_src[0:img_size]) \\\n                          map(alloc: h_dst[0:img_size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<3>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    #pragma omp target update from (h_dst[0:img_size])\n\n    \n\n    bool ok = true;\n    reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<6>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    #pragma omp target update from (h_dst[0:img_size])\n\n    reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<9>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    #pragma omp target update from (h_dst[0:img_size])\n\n    reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  return 0;\n}\n"}}
{"kernel_name": "bilateral", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include \"reference.h\"\n\ntemplate<int R>\nvoid bilateralFilter(\n    const float *__restrict in,\n    float *__restrict out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n    for (int idy = 0; idy < h; idy++)\n    for (int idx = 0; idx < w; idx++) {\n\n      int id = idy*w + idx;\n      float I = in[id];\n      float res = 0;\n      float normalization = 0;\n\n      \n\n      #ifdef LOOP_UNROLL\n            #endif\n      for(int i = -R; i <= R; i++) {\n      #ifdef LOOP_UNROLL\n            #endif\n        for(int j = -R; j <= R; j++) {\n\n          int idk = idx+i;\n          int idl = idy+j;\n\n          \n\n          if( idk < 0) idk = -idk;\n          if( idl < 0) idl = -idl;\n          if( idk > w - 1) idk = w - 1 - i;\n          if( idl > h - 1) idl = h - 1 - j;\n\n          int id_w = idl*w + idk;\n          float I_w = in[id_w];\n\n          \n\n          float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n          \n\n          float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n            (2.f * variance_spatial);\n\n          \n\n          \n\n          float weight = a_square * expf(spatial + range);\n\n          normalization += weight;\n          res += (I_w * weight);\n        }\n      }\n      out[id] = res/normalization;\n    }\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n  \n\n  \n\n  \n\n  \n\n  float variance_I = atof(argv[3]);\n\n  \n\n  float variance_spatial = atof(argv[4]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  int repeat = atoi(argv[5]);\n\n  float *h_src = (float*) malloc (img_size * sizeof(float));\n  \n\n  float *h_dst = (float*) malloc (img_size * sizeof(float));\n  float *r_dst = (float*) malloc (img_size * sizeof(float));\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<3>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    \n    \n\n    bool ok = true;\n    reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<6>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    \n    reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      bilateralFilter<9>(h_src, h_dst, w, h, a_square, variance_I, variance_spatial);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    \n    reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n    for (int i = 0; i < w*h; i++) {\n      if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n        ok = false;\n        break;\n      }\n    }\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  return 0;\n}"}}
{"kernel_name": "bilateral", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\ntemplate<int R>\nvoid bilateralFilter(\n    sycl::nd_item<2> &item,\n    const float *__restrict in,\n    float *__restrict out,\n    int w, \n    int h, \n    float a_square,\n    float variance_I,\n    float variance_spatial)\n{\n  const int idx = item.get_global_id(1);\n  const int idy = item.get_global_id(0);\n\n  if(idx >= w || idy >= h) return;\n\n  int id = idy*w + idx;\n  float I = in[id];\n  float res = 0;\n  float normalization = 0;\n\n  \n\n#ifdef LOOP_UNROLL\n  #pragma unroll\n#endif\n  for(int i = -R; i <= R; i++) {\n#ifdef LOOP_UNROLL\n    #pragma unroll\n#endif\n    for(int j = -R; j <= R; j++) {\n\n      int idk = idx+i;\n      int idl = idy+j;\n\n      \n\n      if( idk < 0) idk = -idk;\n      if( idl < 0) idl = -idl;\n      if( idk > w - 1) idk = w - 1 - i;\n      if( idl > h - 1) idl = h - 1 - j;\n\n      int id_w = idl*w + idk;\n      float I_w = in[id_w];\n\n      \n\n      float range = -(I-I_w) * (I-I_w) / (2.f * variance_I);\n\n      \n\n      float spatial = -((idk-idx)*(idk-idx) + (idl-idy)*(idl-idy)) /\n                      (2.f * variance_spatial);\n\n      \n\n      \n\n      float weight = a_square * sycl::exp(spatial + range);\n\n      normalization += weight;\n      res += (I_w * weight);\n    }\n  }\n  out[id] = res/normalization;\n}\n\n\n\n\n\n\n\nint main(int argc, char *argv[]) {\n\n  if (argc != 6) {\n    printf(\"Usage: %s <image width> <image height> <intensity> <spatial> <repeat>\\n\",\n            argv[0]);\n    return 1;\n  }\n\n  \n\n  int w = atoi(argv[1]);\n  int h = atoi(argv[2]);\n  const int img_size = w*h;\n\n   \n\n   \n\n   \n\n   \n\n  float variance_I = atof(argv[3]);\n\n   \n\n  float variance_spatial = atof(argv[4]);\n\n  int repeat = atoi(argv[5]);\n\n  \n\n  float a_square = 0.5f / (variance_I * (float)M_PI);\n\n  const size_t img_size_bytes = img_size * sizeof(float);\n\n  float *h_src = (float*) malloc (img_size_bytes);\n  \n\n  float *h_dst = (float*) malloc (img_size_bytes);\n  float *r_dst = (float*) malloc (img_size_bytes);\n\n  srand(123);\n  for (int i = 0; i < img_size; i++)\n    h_src[i] = rand() % 256;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_src = sycl::malloc_device<float>(img_size, q);\n  q.memcpy(d_src, h_src, img_size_bytes);\n\n  float *d_dst = sycl::malloc_device<float>(img_size, q);\n\n  sycl::range<2> lws (16, 16);\n  sycl::range<2> gws ((h+15)/16*16, (w+15)/16*16);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class radius3x3>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        bilateralFilter<3>(item, d_src, d_dst,\n                           w, h, a_square, variance_I, variance_spatial);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (3x3) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(h_dst, d_dst, img_size_bytes).wait();\n\n  \n\n  bool ok = true;\n  reference<3>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class radius6x6>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        bilateralFilter<6>(item, d_src, d_dst,\n                           w, h, a_square, variance_I, variance_spatial);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (6x6) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(h_dst, d_dst, img_size_bytes).wait();\n\n  reference<6>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class radius9x9>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        bilateralFilter<9>(item, d_src, d_dst,\n                           w, h, a_square, variance_I, variance_spatial);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (9x9) %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(h_dst, d_dst, img_size_bytes).wait();\n\n  reference<9>(h_src, r_dst, w, h, a_square, variance_I, variance_spatial);\n  for (int i = 0; i < w*h; i++) {\n    if (fabsf(r_dst[i] - h_dst[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_dst);\n  free(r_dst);\n  free(h_src);\n  sycl::free(d_dst, q);\n  sycl::free(d_src, q);\n  return 0;\n}\n"}}
{"kernel_name": "binomial", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n\n\nextern \"C\" void BlackScholesCall(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\n\n\nextern \"C\" void binomialOptionsCPU(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    );\n\n\n\n\n\nreal randData(real low, real high)\n{\n  real t = (real)rand() / (real)RAND_MAX;\n  return ((real)1.0 - t) * low + t * high;\n}\n\nint main(int argc, char **argv)\n{\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  const int OPT_N = MAX_OPTIONS;\n\n  TOptionData optionData[MAX_OPTIONS];\n  real\n    callValueBS[MAX_OPTIONS],\n    callValueGPU[MAX_OPTIONS],\n    callValueCPU[MAX_OPTIONS];\n\n  real\n    sumDelta, sumRef, gpuTime, errorVal;\n\n  int i;\n\n  printf(\"Generating input data...\\n\");\n  srand(123);\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    optionData[i].S = randData(5.0f, 30.0f);\n    optionData[i].X = randData(1.0f, 100.0f);\n    optionData[i].T = randData(0.25f, 10.0f);\n    optionData[i].R = 0.06f;\n    optionData[i].V = 0.10f;\n    BlackScholesCall(callValueBS[i], optionData[i]);\n  }\n\n  printf(\"Running GPU binomial tree...\\n\");\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  binomialOptionsGPU(callValueGPU, optionData, OPT_N, NUM_ITERATIONS);\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<real> elapsed_seconds = end - start;\n  gpuTime = (real)elapsed_seconds.count();\n\n  printf(\"Options count            : %i     \\n\", OPT_N);\n  printf(\"Time steps               : %i     \\n\", NUM_STEPS);\n  printf(\"Total binomialOptionsGPU() time: %f msec\\n\", gpuTime * 1000);\n  printf(\"Options per second       : %f     \\n\", OPT_N / (gpuTime));\n\n  printf(\"Running CPU binomial tree...\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    binomialOptionsCPU(callValueCPU[i], optionData[i]);\n  }\n\n  printf(\"Comparing the results...\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n  printf(\"GPU binomial vs. Black-Scholes\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i] - callValueGPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", (double)(sumDelta / sumRef));\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. Black-Scholes\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i]- callValueCPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", sumDelta / sumRef);\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. GPU binomial\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueGPU[i] - callValueCPU[i]);\n    sumRef += callValueCPU[i];\n  }\n\n  printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  printf(\"L1 norm: %E\\n\", errorVal = sumDelta / sumRef);\n\n  if (errorVal > 5e-4)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}\n", "kernel.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n\n\n\ntypedef struct\n{\n  real S;\n  real X;\n  real vDt;\n  real puByDf;\n  real pdByDf;\n} __TOptionData;\n\n\n\n\n#ifndef DOUBLE_PRECISION\n__device__ inline float expiryCallValue(float S, float X, float vDt, int i)\n{\n  float d = S * __expf(vDt * (2.0f * i - NUM_STEPS)) - X;\n  return (d > 0.0F) ? d : 0.0F;\n}\n#else\n__device__ inline double expiryCallValue(double S, double X, double vDt, int i)\n{\n  double d = S * exp(vDt * (2.0 * i - NUM_STEPS)) - X;\n  return (d > 0.0) ? d : 0.0;\n}\n#endif\n\n\n\n\n#define THREADBLOCK_SIZE 128\n#define ELEMS_PER_THREAD (NUM_STEPS/THREADBLOCK_SIZE)\n#if NUM_STEPS % THREADBLOCK_SIZE\n#error Bad constants\n#endif\n\n__global__ void binomialOptionsKernel(const __TOptionData *__restrict d_OptionData,\n                                      real *__restrict d_CallValue)\n{\n  __shared__ real call_exchange[THREADBLOCK_SIZE + 1];\n\n  const int     tid = threadIdx.x;\n  const real      S = d_OptionData[blockIdx.x].S;\n  const real      X = d_OptionData[blockIdx.x].X;\n  const real    vDt = d_OptionData[blockIdx.x].vDt;\n  const real puByDf = d_OptionData[blockIdx.x].puByDf;\n  const real pdByDf = d_OptionData[blockIdx.x].pdByDf;\n\n  real call[ELEMS_PER_THREAD + 1];\n#pragma unroll\n  for(int i = 0; i < ELEMS_PER_THREAD; ++i)\n    call[i] = expiryCallValue(S, X, vDt, tid * ELEMS_PER_THREAD + i);\n\n  if (tid == 0)\n    call_exchange[THREADBLOCK_SIZE] = expiryCallValue(S, X, vDt, NUM_STEPS);\n\n  int final_it = max(0, tid * ELEMS_PER_THREAD - 1);\n\n#pragma unroll 16\n  for(int i = NUM_STEPS; i > 0; --i)\n  {\n    call_exchange[tid] = call[0];\n    __syncthreads();\n    call[ELEMS_PER_THREAD] = call_exchange[tid + 1];\n    __syncthreads();\n\n    if (i > final_it)\n    {\n#pragma unroll\n      for(int j = 0; j < ELEMS_PER_THREAD; ++j)\n        call[j] = puByDf * call[j + 1] + pdByDf * call[j];\n    }\n  }\n\n  if (tid == 0)\n  {\n    d_CallValue[blockIdx.x] = call[0];\n  }\n}\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    )\n{\n  __TOptionData h_OptionData[MAX_OPTIONS];\n\n  for (int i = 0; i < optN; i++)\n  {\n    const real      T = optionData[i].T;\n    const real      R = optionData[i].R;\n    const real      V = optionData[i].V;\n\n    const real     dt = T / (real)NUM_STEPS;\n    const real    vDt = V * sqrt(dt);\n    const real    rDt = R * dt;\n    \n\n    const real     If = exp(rDt);\n    const real     Df = exp(-rDt);\n    \n\n    const real      u = exp(vDt);\n    const real      d = exp(-vDt);\n    const real     pu = (If - d) / (u - d);\n    const real     pd = (real)1.0 - pu;\n    const real puByDf = pu * Df;\n    const real pdByDf = pd * Df;\n\n    h_OptionData[i].S      = (real)optionData[i].S;\n    h_OptionData[i].X      = (real)optionData[i].X;\n    h_OptionData[i].vDt    = (real)vDt;\n    h_OptionData[i].puByDf = (real)puByDf;\n    h_OptionData[i].pdByDf = (real)pdByDf;\n  }\n\n  __TOptionData *d_OptionData;\n  cudaMalloc ((void**)&d_OptionData, sizeof(__TOptionData) * MAX_OPTIONS);\n  cudaMemcpy(d_OptionData, h_OptionData, optN * sizeof(__TOptionData), cudaMemcpyHostToDevice);\n\n  real *d_CallValue;\n  cudaMalloc ((void**)&d_CallValue, sizeof(real) * MAX_OPTIONS);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < numIterations; i++)\n    binomialOptionsKernel<<<optN, THREADBLOCK_SIZE>>>(d_OptionData, d_CallValue);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3f / numIterations);\n\n  cudaMemcpy(callValue, d_CallValue, optN *sizeof(real), cudaMemcpyDeviceToHost);\n  cudaFree(d_OptionData);\n  cudaFree(d_CallValue);\n}\n"}}
{"kernel_name": "binomial", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n\n\nextern \"C\" void BlackScholesCall(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\n\n\nextern \"C\" void binomialOptionsCPU(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    );\n\n\n\n\n\nreal randData(real low, real high)\n{\n  real t = (real)rand() / (real)RAND_MAX;\n  return ((real)1.0 - t) * low + t * high;\n}\n\nint main(int argc, char **argv)\n{\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  const int OPT_N = MAX_OPTIONS;\n\n  TOptionData optionData[MAX_OPTIONS];\n  real\n    callValueBS[MAX_OPTIONS],\n    callValueGPU[MAX_OPTIONS],\n    callValueCPU[MAX_OPTIONS];\n\n  real\n    sumDelta, sumRef, gpuTime, errorVal;\n\n  int i;\n\n  printf(\"Generating input data...\\n\");\n  srand(123);\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    optionData[i].S = randData(5.0f, 30.0f);\n    optionData[i].X = randData(1.0f, 100.0f);\n    optionData[i].T = randData(0.25f, 10.0f);\n    optionData[i].R = 0.06f;\n    optionData[i].V = 0.10f;\n    BlackScholesCall(callValueBS[i], optionData[i]);\n  }\n\n  printf(\"Running GPU binomial tree...\\n\");\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  binomialOptionsGPU(callValueGPU, optionData, OPT_N, NUM_ITERATIONS);\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<real> elapsed_seconds = end - start;\n  gpuTime = (real)elapsed_seconds.count();\n\n  printf(\"Options count            : %i     \\n\", OPT_N);\n  printf(\"Time steps               : %i     \\n\", NUM_STEPS);\n  printf(\"Total binomialOptionsGPU() time: %f msec\\n\", gpuTime * 1000);\n  printf(\"Options per second       : %f     \\n\", OPT_N / (gpuTime));\n\n  printf(\"Running CPU binomial tree...\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    binomialOptionsCPU(callValueCPU[i], optionData[i]);\n  }\n\n  printf(\"Comparing the results...\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n  printf(\"GPU binomial vs. Black-Scholes\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i] - callValueGPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", (double)(sumDelta / sumRef));\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. Black-Scholes\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i]- callValueCPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", sumDelta / sumRef);\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. GPU binomial\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueGPU[i] - callValueCPU[i]);\n    sumRef += callValueCPU[i];\n  }\n\n  printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  printf(\"L1 norm: %E\\n\", errorVal = sumDelta / sumRef);\n\n  if (errorVal > 5e-4)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}\n", "kernel.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n\n\n\ntypedef struct\n{\n  real S;\n  real X;\n  real vDt;\n  real puByDf;\n  real pdByDf;\n} __TOptionData;\n\n\n\n\n#ifndef DOUBLE_PRECISION\n__device__ inline float expiryCallValue(float S, float X, float vDt, int i)\n{\n  float d = S * __expf(vDt * (2.0f * i - NUM_STEPS)) - X;\n  return (d > 0.0F) ? d : 0.0F;\n}\n#else\n__device__ inline double expiryCallValue(double S, double X, double vDt, int i)\n{\n  double d = S * exp(vDt * (2.0 * i - NUM_STEPS)) - X;\n  return (d > 0.0) ? d : 0.0;\n}\n#endif\n\n\n\n\n#define THREADBLOCK_SIZE 128\n#define ELEMS_PER_THREAD (NUM_STEPS/THREADBLOCK_SIZE)\n#if NUM_STEPS % THREADBLOCK_SIZE\n#error Bad constants\n#endif\n\n__global__ void binomialOptionsKernel(const __TOptionData *__restrict d_OptionData,\n                                      real *__restrict d_CallValue)\n{\n  __shared__ real call_exchange[THREADBLOCK_SIZE + 1];\n\n  const int     tid = threadIdx.x;\n  const real      S = d_OptionData[blockIdx.x].S;\n  const real      X = d_OptionData[blockIdx.x].X;\n  const real    vDt = d_OptionData[blockIdx.x].vDt;\n  const real puByDf = d_OptionData[blockIdx.x].puByDf;\n  const real pdByDf = d_OptionData[blockIdx.x].pdByDf;\n\n  real call[ELEMS_PER_THREAD + 1];\n#pragma unroll\n  for(int i = 0; i < ELEMS_PER_THREAD; ++i)\n    call[i] = expiryCallValue(S, X, vDt, tid * ELEMS_PER_THREAD + i);\n\n  if (tid == 0)\n    call_exchange[THREADBLOCK_SIZE] = expiryCallValue(S, X, vDt, NUM_STEPS);\n\n  int final_it = max(0, tid * ELEMS_PER_THREAD - 1);\n\n#pragma unroll 16\n  for(int i = NUM_STEPS; i > 0; --i)\n  {\n    call_exchange[tid] = call[0];\n    __syncthreads();\n    call[ELEMS_PER_THREAD] = call_exchange[tid + 1];\n    __syncthreads();\n\n    if (i > final_it)\n    {\n#pragma unroll\n      for(int j = 0; j < ELEMS_PER_THREAD; ++j)\n        call[j] = puByDf * call[j + 1] + pdByDf * call[j];\n    }\n  }\n\n  if (tid == 0)\n  {\n    d_CallValue[blockIdx.x] = call[0];\n  }\n}\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    )\n{\n  __TOptionData h_OptionData[MAX_OPTIONS];\n\n  for (int i = 0; i < optN; i++)\n  {\n    const real      T = optionData[i].T;\n    const real      R = optionData[i].R;\n    const real      V = optionData[i].V;\n\n    const real     dt = T / (real)NUM_STEPS;\n    const real    vDt = V * sqrt(dt);\n    const real    rDt = R * dt;\n    \n\n    const real     If = exp(rDt);\n    const real     Df = exp(-rDt);\n    \n\n    const real      u = exp(vDt);\n    const real      d = exp(-vDt);\n    const real     pu = (If - d) / (u - d);\n    const real     pd = (real)1.0 - pu;\n    const real puByDf = pu * Df;\n    const real pdByDf = pd * Df;\n\n    h_OptionData[i].S      = (real)optionData[i].S;\n    h_OptionData[i].X      = (real)optionData[i].X;\n    h_OptionData[i].vDt    = (real)vDt;\n    h_OptionData[i].puByDf = (real)puByDf;\n    h_OptionData[i].pdByDf = (real)pdByDf;\n  }\n\n  __TOptionData *d_OptionData;\n  hipMalloc ((void**)&d_OptionData, sizeof(__TOptionData) * MAX_OPTIONS);\n  hipMemcpy(d_OptionData, h_OptionData, optN * sizeof(__TOptionData), hipMemcpyHostToDevice);\n\n  real *d_CallValue;\n  hipMalloc ((void**)&d_CallValue, sizeof(real) * MAX_OPTIONS);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < numIterations; i++)\n    hipLaunchKernelGGL(binomialOptionsKernel, dim3(optN), dim3(THREADBLOCK_SIZE), 0, 0, d_OptionData, d_CallValue);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3f / numIterations);\n\n  hipMemcpy(callValue, d_CallValue, optN *sizeof(real), hipMemcpyDeviceToHost);\n  hipFree(d_OptionData);\n  hipFree(d_CallValue);\n}\n"}}
{"kernel_name": "binomial", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n\n\nextern \"C\" void BlackScholesCall(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\n\n\nextern \"C\" void binomialOptionsCPU(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    );\n\n\n\n\n\nreal randData(real low, real high)\n{\n  real t = (real)rand() / (real)RAND_MAX;\n  return ((real)1.0 - t) * low + t * high;\n}\n\nint main(int argc, char **argv)\n{\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  const int OPT_N = MAX_OPTIONS;\n\n  TOptionData optionData[MAX_OPTIONS];\n  real\n    callValueBS[MAX_OPTIONS],\n    callValueGPU[MAX_OPTIONS],\n    callValueCPU[MAX_OPTIONS];\n\n  real\n    sumDelta, sumRef, gpuTime, errorVal;\n\n  int i;\n\n  printf(\"Generating input data...\\n\");\n  srand(123);\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    optionData[i].S = randData(5.0f, 30.0f);\n    optionData[i].X = randData(1.0f, 100.0f);\n    optionData[i].T = randData(0.25f, 10.0f);\n    optionData[i].R = 0.06f;\n    optionData[i].V = 0.10f;\n    BlackScholesCall(callValueBS[i], optionData[i]);\n  }\n\n  printf(\"Running GPU binomial tree...\\n\");\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  binomialOptionsGPU(callValueGPU, optionData, OPT_N, NUM_ITERATIONS);\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<real> elapsed_seconds = end - start;\n  gpuTime = (real)elapsed_seconds.count();\n\n  printf(\"Options count            : %i     \\n\", OPT_N);\n  printf(\"Time steps               : %i     \\n\", NUM_STEPS);\n  printf(\"Total binomialOptionsGPU() time: %f msec\\n\", gpuTime * 1000);\n  printf(\"Options per second       : %f     \\n\", OPT_N / (gpuTime));\n\n  printf(\"Running CPU binomial tree...\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    binomialOptionsCPU(callValueCPU[i], optionData[i]);\n  }\n\n  printf(\"Comparing the results...\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n  printf(\"GPU binomial vs. Black-Scholes\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i] - callValueGPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", (double)(sumDelta / sumRef));\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. Black-Scholes\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i]- callValueCPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", sumDelta / sumRef);\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. GPU binomial\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueGPU[i] - callValueCPU[i]);\n    sumRef += callValueCPU[i];\n  }\n\n  printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  printf(\"L1 norm: %E\\n\", errorVal = sumDelta / sumRef);\n\n  if (errorVal > 5e-4)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}\n", "kernel.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n#define max(a, b) ((a) < (b) ? (b) : (a))\n\n\n\ntypedef struct\n{\n  real S;\n  real X;\n  real vDt;\n  real puByDf;\n  real pdByDf;\n} __TOptionData;\n\n\n\n\n#ifndef DOUBLE_PRECISION\ninline float expiryCallValue(float S, float X, float vDt, int i)\n{\n  float d = S * expf(vDt * (2.0f * i - NUM_STEPS)) - X;\n  return (d > 0.0F) ? d : 0.0F;\n}\n#else\ninline double expiryCallValue(double S, double X, double vDt, int i)\n{\n  double d = S * exp(vDt * (2.0 * i - NUM_STEPS)) - X;\n  return (d > 0.0) ? d : 0.0;\n}\n#endif\n\n\n\n\n#define THREADBLOCK_SIZE 128\n#define ELEMS_PER_THREAD (NUM_STEPS/THREADBLOCK_SIZE)\n#if NUM_STEPS % THREADBLOCK_SIZE\n#error Bad constants\n#endif\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    )\n{\n  __TOptionData d_OptionData[MAX_OPTIONS];\n\n  for (int i = 0; i < optN; i++)\n  {\n    const real      T = optionData[i].T;\n    const real      R = optionData[i].R;\n    const real      V = optionData[i].V;\n\n    const real     dt = T / (real)NUM_STEPS;\n    const real    vDt = V * sqrt(dt);\n    const real    rDt = R * dt;\n    \n\n    const real     If = exp(rDt);\n    const real     Df = exp(-rDt);\n    \n\n    const real      u = exp(vDt);\n    const real      d = exp(-vDt);\n    const real     pu = (If - d) / (u - d);\n    const real     pd = (real)1.0 - pu;\n    const real puByDf = pu * Df;\n    const real pdByDf = pd * Df;\n\n    d_OptionData[i].S      = (real)optionData[i].S;\n    d_OptionData[i].X      = (real)optionData[i].X;\n    d_OptionData[i].vDt    = (real)vDt;\n    d_OptionData[i].puByDf = (real)puByDf;\n    d_OptionData[i].pdByDf = (real)pdByDf;\n  }\n\n  #pragma omp target data map(to: d_OptionData[0:MAX_OPTIONS]) \\\n                          map(from: callValue[0:MAX_OPTIONS])\n  {\n    auto start = std::chrono::steady_clock::now();\n  \n    for (int i = 0; i < numIterations; i++) {\n      #pragma omp target teams num_teams(optN) thread_limit(THREADBLOCK_SIZE)\n      {\n        real call_exchange[THREADBLOCK_SIZE + 1];\n        #pragma omp parallel \n        {\n          const int     tid = omp_get_thread_num();\n          const int     bid = omp_get_team_num();\n          const real      S = d_OptionData[bid].S;\n          const real      X = d_OptionData[bid].X;\n          const real    vDt = d_OptionData[bid].vDt;\n          const real puByDf = d_OptionData[bid].puByDf;\n          const real pdByDf = d_OptionData[bid].pdByDf;\n  \n          real call[ELEMS_PER_THREAD + 1];\n          #pragma unroll\n          for(int i = 0; i < ELEMS_PER_THREAD; ++i)\n            call[i] = expiryCallValue(S, X, vDt, tid * ELEMS_PER_THREAD + i);\n  \n          if (tid == 0)\n            call_exchange[THREADBLOCK_SIZE] = expiryCallValue(S, X, vDt, NUM_STEPS);\n  \n          int final_it = max(0, tid * ELEMS_PER_THREAD - 1);\n  \n          #pragma unroll 16\n          for(int i = NUM_STEPS; i > 0; --i)\n          {\n            call_exchange[tid] = call[0];\n            #pragma omp barrier\n            call[ELEMS_PER_THREAD] = call_exchange[tid + 1];\n            #pragma omp barrier\n  \n            if (i > final_it)\n            {\n              #pragma unroll\n              for(int j = 0; j < ELEMS_PER_THREAD; ++j)\n                call[j] = puByDf * call[j + 1] + pdByDf * call[j];\n            }\n          }\n  \n          if (tid == 0)\n          {\n            callValue[bid] = call[0];\n          }\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3f / numIterations);\n  }\n}\n"}}
{"kernel_name": "binomial", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n\n\nextern \"C\" void BlackScholesCall(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\n\n\nextern \"C\" void binomialOptionsCPU(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    );\n\n\n\n\n\nreal randData(real low, real high)\n{\n  real t = (real)rand() / (real)RAND_MAX;\n  return ((real)1.0 - t) * low + t * high;\n}\n\nint main(int argc, char **argv)\n{\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  const int OPT_N = MAX_OPTIONS;\n\n  TOptionData optionData[MAX_OPTIONS];\n  real\n    callValueBS[MAX_OPTIONS],\n    callValueGPU[MAX_OPTIONS],\n    callValueCPU[MAX_OPTIONS];\n\n  real\n    sumDelta, sumRef, gpuTime, errorVal;\n\n  int i;\n\n  printf(\"Generating input data...\\n\");\n  srand(123);\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    optionData[i].S = randData(5.0f, 30.0f);\n    optionData[i].X = randData(1.0f, 100.0f);\n    optionData[i].T = randData(0.25f, 10.0f);\n    optionData[i].R = 0.06f;\n    optionData[i].V = 0.10f;\n    BlackScholesCall(callValueBS[i], optionData[i]);\n  }\n\n  printf(\"Running GPU binomial tree...\\n\");\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  binomialOptionsGPU(callValueGPU, optionData, OPT_N, NUM_ITERATIONS);\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<real> elapsed_seconds = end - start;\n  gpuTime = (real)elapsed_seconds.count();\n\n  printf(\"Options count            : %i     \\n\", OPT_N);\n  printf(\"Time steps               : %i     \\n\", NUM_STEPS);\n  printf(\"Total binomialOptionsGPU() time: %f msec\\n\", gpuTime * 1000);\n  printf(\"Options per second       : %f     \\n\", OPT_N / (gpuTime));\n\n  printf(\"Running CPU binomial tree...\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    binomialOptionsCPU(callValueCPU[i], optionData[i]);\n  }\n\n  printf(\"Comparing the results...\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n  printf(\"GPU binomial vs. Black-Scholes\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i] - callValueGPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", (double)(sumDelta / sumRef));\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. Black-Scholes\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i]- callValueCPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", sumDelta / sumRef);\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. GPU binomial\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueGPU[i] - callValueCPU[i]);\n    sumRef += callValueCPU[i];\n  }\n\n  printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  printf(\"L1 norm: %E\\n\", errorVal = sumDelta / sumRef);\n\n  if (errorVal > 5e-4)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}", "kernel.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n#define max(a, b) ((a) < (b) ? (b) : (a))\n\n\n\ntypedef struct\n{\n  real S;\n  real X;\n  real vDt;\n  real puByDf;\n  real pdByDf;\n} __TOptionData;\n\n\n\n\n#ifndef DOUBLE_PRECISION\ninline float expiryCallValue(float S, float X, float vDt, int i)\n{\n  float d = S * expf(vDt * (2.0f * i - NUM_STEPS)) - X;\n  return (d > 0.0F) ? d : 0.0F;\n}\n#else\ninline double expiryCallValue(double S, double X, double vDt, int i)\n{\n  double d = S * exp(vDt * (2.0 * i - NUM_STEPS)) - X;\n  return (d > 0.0) ? d : 0.0;\n}\n#endif\n\n\n\n\n#define THREADBLOCK_SIZE 128\n#define ELEMS_PER_THREAD (NUM_STEPS/THREADBLOCK_SIZE)\n#if NUM_STEPS % THREADBLOCK_SIZE\n#endif\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    )\n{\n  __TOptionData d_OptionData[MAX_OPTIONS];\n\n  for (int i = 0; i < optN; i++)\n  {\n    const real      T = optionData[i].T;\n    const real      R = optionData[i].R;\n    const real      V = optionData[i].V;\n\n    const real     dt = T / (real)NUM_STEPS;\n    const real    vDt = V * sqrt(dt);\n    const real    rDt = R * dt;\n    \n\n    const real     If = exp(rDt);\n    const real     Df = exp(-rDt);\n    \n\n    const real      u = exp(vDt);\n    const real      d = exp(-vDt);\n    const real     pu = (If - d) / (u - d);\n    const real     pd = (real)1.0 - pu;\n    const real puByDf = pu * Df;\n    const real pdByDf = pd * Df;\n\n    d_OptionData[i].S      = (real)optionData[i].S;\n    d_OptionData[i].X      = (real)optionData[i].X;\n    d_OptionData[i].vDt    = (real)vDt;\n    d_OptionData[i].puByDf = (real)puByDf;\n    d_OptionData[i].pdByDf = (real)pdByDf;\n  }\n\n    {\n    auto start = std::chrono::steady_clock::now();\n  \n    for (int i = 0; i < numIterations; i++) {\n            {\n        real call_exchange[THREADBLOCK_SIZE + 1];\n                {\n          const int     tid = omp_get_thread_num();\n          const int     bid = omp_get_team_num();\n          const real      S = d_OptionData[bid].S;\n          const real      X = d_OptionData[bid].X;\n          const real    vDt = d_OptionData[bid].vDt;\n          const real puByDf = d_OptionData[bid].puByDf;\n          const real pdByDf = d_OptionData[bid].pdByDf;\n  \n          real call[ELEMS_PER_THREAD + 1];\n                    for(int i = 0; i < ELEMS_PER_THREAD; ++i)\n            call[i] = expiryCallValue(S, X, vDt, tid * ELEMS_PER_THREAD + i);\n  \n          if (tid == 0)\n            call_exchange[THREADBLOCK_SIZE] = expiryCallValue(S, X, vDt, NUM_STEPS);\n  \n          int final_it = max(0, tid * ELEMS_PER_THREAD - 1);\n  \n                    for(int i = NUM_STEPS; i > 0; --i)\n          {\n            call_exchange[tid] = call[0];\n                        call[ELEMS_PER_THREAD] = call_exchange[tid + 1];\n              \n            if (i > final_it)\n            {\n                            for(int j = 0; j < ELEMS_PER_THREAD; ++j)\n                call[j] = puByDf * call[j + 1] + pdByDf * call[j];\n            }\n          }\n  \n          if (tid == 0)\n          {\n            callValue[bid] = call[0];\n          }\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3f / numIterations);\n  }\n}"}}
{"kernel_name": "binomial", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <chrono>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n\n\nextern \"C\" void BlackScholesCall(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\n\n\nextern \"C\" void binomialOptionsCPU(\n    real &callResult,\n    TOptionData optionData\n    );\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    );\n\n\n\n\n\nreal randData(real low, real high)\n{\n  real t = (real)rand() / (real)RAND_MAX;\n  return ((real)1.0 - t) * low + t * high;\n}\n\nint main(int argc, char **argv)\n{\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  const int OPT_N = MAX_OPTIONS;\n\n  TOptionData optionData[MAX_OPTIONS];\n  real\n    callValueBS[MAX_OPTIONS],\n    callValueGPU[MAX_OPTIONS],\n    callValueCPU[MAX_OPTIONS];\n\n  real\n    sumDelta, sumRef, gpuTime, errorVal;\n\n  int i;\n\n  printf(\"Generating input data...\\n\");\n  srand(123);\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    optionData[i].S = randData(5.0f, 30.0f);\n    optionData[i].X = randData(1.0f, 100.0f);\n    optionData[i].T = randData(0.25f, 10.0f);\n    optionData[i].R = 0.06f;\n    optionData[i].V = 0.10f;\n    BlackScholesCall(callValueBS[i], optionData[i]);\n  }\n\n  printf(\"Running GPU binomial tree...\\n\");\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  binomialOptionsGPU(callValueGPU, optionData, OPT_N, NUM_ITERATIONS);\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<real> elapsed_seconds = end - start;\n  gpuTime = (real)elapsed_seconds.count();\n\n  printf(\"Options count            : %i     \\n\", OPT_N);\n  printf(\"Time steps               : %i     \\n\", NUM_STEPS);\n  printf(\"Total binomialOptionsGPU() time: %f msec\\n\", gpuTime * 1000);\n  printf(\"Options per second       : %f     \\n\", OPT_N / (gpuTime));\n\n  printf(\"Running CPU binomial tree...\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    binomialOptionsCPU(callValueCPU[i], optionData[i]);\n  }\n\n  printf(\"Comparing the results...\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n  printf(\"GPU binomial vs. Black-Scholes\\n\");\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i] - callValueGPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", (double)(sumDelta / sumRef));\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. Black-Scholes\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueBS[i]- callValueCPU[i]);\n    sumRef += fabs(callValueBS[i]);\n  }\n\n  if (sumRef >1E-5)\n  {\n    printf(\"L1 norm: %E\\n\", sumDelta / sumRef);\n  }\n  else\n  {\n    printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  }\n\n  printf(\"CPU binomial vs. GPU binomial\\n\");\n  sumDelta = 0;\n  sumRef   = 0;\n\n  for (i = 0; i < OPT_N; i++)\n  {\n    sumDelta += fabs(callValueGPU[i] - callValueCPU[i]);\n    sumRef += callValueCPU[i];\n  }\n\n  printf(\"Avg. diff: %E\\n\", (double)(sumDelta / (real)OPT_N));\n  printf(\"L1 norm: %E\\n\", errorVal = sumDelta / sumRef);\n\n  if (errorVal > 5e-4)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}\n", "kernel.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#include \"binomialOptions.h\"\n#include \"realtype.h\"\n\n\n\n\ntypedef struct\n{\n  real S;\n  real X;\n  real vDt;\n  real puByDf;\n  real pdByDf;\n} __TOptionData;\n\n\n\n\n#ifndef DOUBLE_PRECISION\ninline float expiryCallValue(float S, float X, float vDt, int i)\n{\n  float d = S * sycl::exp(vDt * (2.0f * i - NUM_STEPS)) - X;\n  return (d > 0.0F) ? d : 0.0F;\n}\n#else\ninline double expiryCallValue(double S, double X, double vDt, int i)\n{\n  double d = S * sycl::exp(vDt * (2.0 * i - NUM_STEPS)) - X;\n  return (d > 0.0) ? d : 0.0;\n}\n#endif\n\n\n\n\n#define THREADBLOCK_SIZE 128\n#define ELEMS_PER_THREAD (NUM_STEPS/THREADBLOCK_SIZE)\n#if NUM_STEPS % THREADBLOCK_SIZE\n#error Bad constants\n#endif\n\n\n\nextern \"C\" void binomialOptionsGPU(\n    real *callValue,\n    TOptionData  *optionData,\n    int optN,\n    int numIterations\n    )\n{\n  __TOptionData h_OptionData[MAX_OPTIONS];\n\n  for (int i = 0; i < optN; i++)\n  {\n    const real      T = optionData[i].T;\n    const real      R = optionData[i].R;\n    const real      V = optionData[i].V;\n\n    const real     dt = T / (real)NUM_STEPS;\n    const real    vDt = V * sqrt(dt);\n    const real    rDt = R * dt;\n    \n\n    const real     If = exp(rDt);\n    const real     Df = exp(-rDt);\n    \n\n    const real      u = exp(vDt);\n    const real      d = exp(-vDt);\n    const real     pu = (If - d) / (u - d);\n    const real     pd = (real)1.0 - pu;\n    const real puByDf = pu * Df;\n    const real pdByDf = pd * Df;\n\n    h_OptionData[i].S      = (real)optionData[i].S;\n    h_OptionData[i].X      = (real)optionData[i].X;\n    h_OptionData[i].vDt    = (real)vDt;\n    h_OptionData[i].puByDf = (real)puByDf;\n    h_OptionData[i].pdByDf = (real)pdByDf;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  __TOptionData *d_optionData = sycl::malloc_device<__TOptionData>(MAX_OPTIONS, q);\n  q.memcpy(d_optionData, h_OptionData, sizeof(__TOptionData) * MAX_OPTIONS);\n\n  real *d_callValue = sycl::malloc_device<real>(MAX_OPTIONS, q);\n\n  sycl::range<1> gws (optN * THREADBLOCK_SIZE);\n  sycl::range<1> lws (THREADBLOCK_SIZE);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < numIterations; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<real, 1> call_exchange(sycl::range<1>(THREADBLOCK_SIZE + 1), cgh);\n      cgh.parallel_for<class kernel>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        const int     tid = item.get_local_id(0);\n        const int     bid = item.get_group(0);\n        const real      S = d_optionData[bid].S;\n        const real      X = d_optionData[bid].X;\n        const real    vDt = d_optionData[bid].vDt;\n        const real puByDf = d_optionData[bid].puByDf;\n        const real pdByDf = d_optionData[bid].pdByDf;\n\n        real call[ELEMS_PER_THREAD + 1];\n        #pragma unroll\n        for(int i = 0; i < ELEMS_PER_THREAD; ++i)\n          call[i] = expiryCallValue(S, X, vDt, tid * ELEMS_PER_THREAD + i);\n\n        if (tid == 0)\n          call_exchange[THREADBLOCK_SIZE] = expiryCallValue(S, X, vDt, NUM_STEPS);\n\n        int final_it = sycl::max(0, tid * ELEMS_PER_THREAD - 1);\n\n        #pragma unroll 16\n        for(int i = NUM_STEPS; i > 0; --i)\n        {\n          call_exchange[tid] = call[0];\n          item.barrier(sycl::access::fence_space::local_space);\n          call[ELEMS_PER_THREAD] = call_exchange[tid + 1];\n          item.barrier(sycl::access::fence_space::local_space);\n\n          if (i > final_it)\n          {\n            #pragma unroll\n            for(int j = 0; j < ELEMS_PER_THREAD; ++j)\n              call[j] = puByDf * call[j + 1] + pdByDf * call[j];\n          }\n        }\n\n        if (tid == 0)\n        {\n          d_callValue[bid] = call[0];\n        }\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (us)\\n\", time * 1e-3f / numIterations);\n\n  q.memcpy(callValue, d_callValue, optN *sizeof(real)).wait();\n  sycl::free(d_optionData, q);\n  sycl::free(d_callValue, q);\n}\n"}}
{"kernel_name": "blas-gemmStridedBatched", "parallel_api": "cuda", "code": {"main.cu": "#include <assert.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <chrono>\n#include <cmath>\n#include <iostream>\n#include <type_traits> \n\n#include <cuda_fp16.h>\n#include <cuda_runtime.h>\n#include <cublas_v2.h>\n#include \"reference.h\"\n\nusing namespace std;\n\ntemplate <typename T>\nvoid gemmBatched(\n  int lower,\n  int upper,\n  int num,\n  int reps,\n  int verbose) \n{\n  if(verbose) cout << \"initializing inputs\" << endl;\n  size_t matrices_size = upper * upper * num * sizeof(T);\n  size_t vectors_size = upper * num * sizeof(T);\n\n  T *matrices = (T*)malloc(matrices_size);\n  assert(matrices);\n\n  T *vectors = (T*)malloc(vectors_size);\n  assert(vectors);\n\n  T *result = (T*)malloc(vectors_size);\n  assert(result);\n\n  T *result_ref = (T*)malloc(vectors_size);\n  assert(result_ref);\n\n  srand48(48);\n  for(int i = 0; i < num * upper * upper; i++)\n    matrices[i] = static_cast<T>(drand48());\n\n  for(int i = 0; i < num * upper; i++)\n    vectors[i] = static_cast<T>(drand48());\n\n  cudaError_t cudaStat;\n  cublasStatus_t stat;\n  cublasHandle_t handle;\n\n  stat = cublasCreate(&handle);\n  if(stat != CUBLAS_STATUS_SUCCESS){\n    cerr << \"cublas init failed\" << endl;\n    exit(1);\n  }\n\n  if(verbose) cout << \"allocating device variables\" << endl;\n\n  \n\n  T *devMatrices;\n  cudaStat = cudaMalloc((void**)&devMatrices, matrices_size);\n  assert(!cudaStat);\n\n  T *devVectors;\n  cudaStat = cudaMalloc((void**)&devVectors, vectors_size);\n  assert(!cudaStat);\n\n  \n\n  T *devResult;\n  cudaStat = cudaMalloc((void**)&devResult, vectors_size);\n\n  assert(!cudaStat);\n\n  if(verbose) cout << \"copying data to device\" << endl;\n  \n\n  cudaStat = \n    cudaMemcpy(devMatrices, matrices, matrices_size, cudaMemcpyHostToDevice);\n\n  assert(!cudaStat);\n  \n  cudaStat = \n    cudaMemcpy(devVectors, vectors, vectors_size, cudaMemcpyHostToDevice);\n\n  assert(!cudaStat);\n\n  int lda = upper, \n\n      ldb = upper, \n\n      ldc = upper; \n\n\n  const T alpha = 1.0f, beta = 0.0f;\n\n  \n\n#define GEMM_BATCHED_PARAMETERS handle,              \\\n                                CUBLAS_OP_N,         \\\n                                CUBLAS_OP_N,         \\\n                                m, n, k,             \\\n                                &alpha,              \\\n                                devMatrices,         \\\n                                lda,                 \\\n                                upper * upper,       \\\n                                devVectors,          \\\n                                ldb,                 \\\n                                upper,               \\\n                                &beta,               \\\n                                devResult,           \\\n                                ldc,                 \\\n                                upper,               \\\n                                num\n\n  for(int size = lower; size <= upper; size++){\n    if(verbose) cout << \"running with <size x size> x <size x 1> \" << size << endl;\n    double sum = 0.0;\n    const int m = size, n = 1, k = size;\n    for(int rep = 0; rep <= reps; rep++){\n      auto start = std::chrono::steady_clock::now();\n\n      if constexpr (std::is_same_v<T, double>)\n        stat = cublasDgemmStridedBatched(GEMM_BATCHED_PARAMETERS);\n      else if constexpr (std::is_same_v<T, float>)\n        stat = cublasSgemmStridedBatched(GEMM_BATCHED_PARAMETERS);\n      else if constexpr (std::is_same_v<T, __half>)\n        stat = cublasHgemmStridedBatched(GEMM_BATCHED_PARAMETERS);\n\n      cudaDeviceSynchronize();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      auto elapsed = time * 1e-3;\n\n      if(stat != CUBLAS_STATUS_SUCCESS){\n        cerr << \"cublasXgemmStridedBatched failed\" << endl;\n        break;\n      }\n\n      if (rep != 0) sum += elapsed;\n      \n      if(verbose)\n\tcout << \"size \" << size << \": \" << elapsed << \" us; \" \n\t     << elapsed / num << \" us per operation\" << endl;\n    }\n    cout << \"size \" << size << \" average execution time: \" << sum/reps << \" us; \"\n\t << sum / reps / num << \" us per operation; \"\n         << \"floating-point operations per second: \";\n    performance(m, n, k, 1e3 * (sum / reps / num));\n\n    \n\n    if constexpr (std::is_same_v<T, double>) {\n      cudaMemcpy(result, devResult, vectors_size, cudaMemcpyDeviceToHost);\n      gemmBatched_ref (num, upper, upper, 1, m, k, n, alpha, beta,\n                       matrices, lda, vectors, ldb, result_ref, ldc);\n\n      for (int i = 0; i < num; i++) {\n      for (int j = 0; j < m; j++) {\n        if (abs(result[i*upper+j] - result_ref[i*upper+j]) > 1e-6) {\n          cout << \"Mismatch at batch index \" << i << \": \" << result[i*upper+j] << \"!=\"\n               << result_ref[i*upper+j] << endl;\n          break;\n        }\n      }}\n    }\n  }\n\n  cudaFree(devMatrices);\n  cudaFree(devVectors);\n  cudaFree(devResult);\n  cublasDestroy(handle);\n\n  free(matrices);\n  free(vectors);\n  free(result);\n  free(result_ref);\n}\n\nint main(int argc, char ** argv){\n\n  int status;\n  int lower = 2;    \n\n  int upper = 100;  \n\n  int num = 25000;  \n\n  int reps = 10;\n  int verbose = 0;\n  \n  while((status = getopt(argc, argv, \"l:u:n:r:v\")) != -1){\n    switch(status){\n    case 'l':\n      lower = strtoul(optarg, 0, 0);\n      break;\n    case 'u':\n      upper = strtoul(optarg, 0, 0);\n      break;\n    case 'n':\n      num = strtoul(optarg, 0, 0);  \n\n      break;\n    case 'r':\n      reps = strtoul(optarg, 0, 0);\n      break;\n    case 'v':\n      verbose = 1;\n      break;\n    default:\n      cerr << \"invalid argument: \" << status << endl;\n      exit(1);\n    }\n  }\n\n  cout << \"running with\" << \" lower: \" << lower << \" upper: \" << upper\n       << \" num: \" << num << \" reps: \" << reps << endl;\n\n  cout << \">>>>>>>>>>>>>>> Half precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<__half>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Single precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<float>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Double precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<double>(lower, upper, num, reps, verbose);\n      \n  return 0;\n}\n"}}
{"kernel_name": "blas-gemmStridedBatched", "parallel_api": "hip", "code": {"main.cu": "#include <assert.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <chrono>\n#include <cmath>\n#include <iostream>\n#include <type_traits> \n\n#include <hip/hip_fp16.h>\n#include <hip/hip_runtime.h>\n#include <hipblas/hipblas.h>\n#include \"reference.h\"\n\nusing namespace std;\n\ntemplate <typename T>\nvoid gemmBatched(\n  int lower,\n  int upper,\n  int num,\n  int reps,\n  int verbose) \n{\n  if(verbose) cout << \"initializing inputs\" << endl;\n  size_t matrices_size = upper * upper * num * sizeof(T);\n  size_t vectors_size = upper * num * sizeof(T);\n\n  T *matrices = (T*)malloc(matrices_size);\n  assert(matrices);\n\n  T *vectors = (T*)malloc(vectors_size);\n  assert(vectors);\n\n  T *result = (T*)malloc(vectors_size);\n  assert(result);\n\n  T *result_ref = (T*)malloc(vectors_size);\n  assert(result_ref);\n\n  srand48(48);\n  for(int i = 0; i < num * upper * upper; i++)\n    matrices[i] = static_cast<T>(drand48());\n\n  for(int i = 0; i < num * upper; i++)\n    vectors[i] = static_cast<T>(drand48());\n\n  hipError_t cudaStat;\n  hipblasStatus_t stat;\n  hipblasHandle_t handle;\n\n  stat = hipblasCreate(&handle);\n  if(stat != HIPBLAS_STATUS_SUCCESS){\n    cerr << \"hipblas init failed\" << endl;\n    exit(1);\n  }\n\n  if(verbose) cout << \"allocating device variables\" << endl;\n\n  \n\n  T *devMatrices;\n  cudaStat = hipMalloc((void**)&devMatrices, matrices_size);\n  assert(!cudaStat);\n\n  T *devVectors;\n  cudaStat = hipMalloc((void**)&devVectors, vectors_size);\n  assert(!cudaStat);\n\n  \n\n  T *devResult;\n  cudaStat = hipMalloc((void**)&devResult, vectors_size);\n\n  assert(!cudaStat);\n\n  if(verbose) cout << \"copying data to device\" << endl;\n  \n\n  cudaStat = \n    hipMemcpy(devMatrices, matrices, matrices_size, hipMemcpyHostToDevice);\n\n  assert(!cudaStat);\n  \n  cudaStat = \n    hipMemcpy(devVectors, vectors, vectors_size, hipMemcpyHostToDevice);\n\n  assert(!cudaStat);\n\n  int lda = upper, \n\n      ldb = upper, \n\n      ldc = upper; \n\n\n  const T alpha = 1.0f, beta = 0.0f;\n\n  \n\n#define GEMM_BATCHED_PARAMETERS handle,              \\\n                                HIPBLAS_OP_N,        \\\n                                HIPBLAS_OP_N,        \\\n                                m, n, k,             \\\n                                &alpha,              \\\n                                devMatrices,         \\\n                                lda,                 \\\n                                upper * upper,       \\\n                                devVectors,          \\\n                                ldb,                 \\\n                                upper,               \\\n                                &beta,               \\\n                                devResult,           \\\n                                ldc,                 \\\n                                upper,               \\\n                                num\n\n  for(int size = lower; size <= upper; size++){\n    if(verbose) cout << \"running with <size x size> x <size x 1> \" << size << endl;\n    double sum = 0.0;\n    const int m = size, n = 1, k = size;\n    for(int rep = 0; rep <= reps; rep++){\n      auto start = std::chrono::steady_clock::now();\n\n      if constexpr (std::is_same_v<T, double>)\n        stat = hipblasDgemmStridedBatched(GEMM_BATCHED_PARAMETERS);\n      else if constexpr (std::is_same_v<T, float>)\n        stat = hipblasSgemmStridedBatched(GEMM_BATCHED_PARAMETERS);\n      else if constexpr (std::is_same_v<T, __half>)\n        stat = hipblasHgemmStridedBatched(GEMM_BATCHED_PARAMETERS);\n\n      hipDeviceSynchronize();\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      auto elapsed = time * 1e-3;\n\n      if(stat != HIPBLAS_STATUS_SUCCESS){\n        cerr << \"hipblasXgemmStridedBatched failed\" << endl;\n        break;\n      }\n\n      if (rep != 0) sum += elapsed;\n      \n      if(verbose)\n\tcout << \"size \" << size << \": \" << elapsed << \" us; \" \n\t     << elapsed / num << \" us per operation\" << endl;\n    }\n    cout << \"size \" << size << \" average execution time: \" << sum/reps << \" us; \"\n\t << sum / reps / num << \" us per operation; \"\n         << \"floating-point operations per second: \";\n    performance(m, n, k, 1e3 * (sum / reps / num));\n\n    \n\n    if constexpr (std::is_same_v<T, double>) {\n      hipMemcpy(result, devResult, vectors_size, hipMemcpyDeviceToHost);\n      gemmBatched_ref (num, upper, upper, 1, m, k, n, alpha, beta,\n                       matrices, lda, vectors, ldb, result_ref, ldc);\n\n      for (int i = 0; i < num; i++) {\n      for (int j = 0; j < m; j++) {\n        if (abs(result[i*upper+j] - result_ref[i*upper+j]) > 1e-6) {\n          cout << \"Mismatch at batch index \" << i << \": \" << result[i*upper+j] << \"!=\"\n               << result_ref[i*upper+j] << endl;\n          break;\n        }\n      }}\n    }\n  }\n\n  hipFree(devMatrices);\n  hipFree(devVectors);\n  hipFree(devResult);\n  hipblasDestroy(handle);\n\n  free(matrices);\n  free(vectors);\n  free(result);\n  free(result_ref);\n}\n\nint main(int argc, char ** argv){\n\n  int status;\n  int lower = 2;    \n\n  int upper = 100;  \n\n  int num = 25000;  \n\n  int reps = 10;\n  int verbose = 0;\n  \n  while((status = getopt(argc, argv, \"l:u:n:r:v\")) != -1){\n    switch(status){\n    case 'l':\n      lower = strtoul(optarg, 0, 0);\n      break;\n    case 'u':\n      upper = strtoul(optarg, 0, 0);\n      break;\n    case 'n':\n      num = strtoul(optarg, 0, 0);  \n\n      break;\n    case 'r':\n      reps = strtoul(optarg, 0, 0);\n      break;\n    case 'v':\n      verbose = 1;\n      break;\n    default:\n      cerr << \"invalid argument: \" << status << endl;\n      exit(1);\n    }\n  }\n\n  cout << \"running with\" << \" lower: \" << lower << \" upper: \" << upper\n       << \" num: \" << num << \" reps: \" << reps << endl;\n\n  cout << \">>>>>>>>>>>>>>> Half precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<__half>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Single precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<float>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Double precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<double>(lower, upper, num, reps, verbose);\n      \n  return 0;\n}\n"}}
{"kernel_name": "blas-gemmStridedBatched", "parallel_api": "sycl", "code": {"main.cpp": "#include <assert.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <chrono>\n#include <cmath>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include <oneapi/mkl.hpp>\n#include \"reference.h\"\n\nusing namespace std;\n\ntemplate <typename T>\nvoid gemmBatched(\n  int lower,\n  int upper,\n  int num,\n  int reps,\n  int verbose) try \n{\n  if(verbose) cout << \"initializing inputs\" << endl;\n  size_t matrices_size = upper * upper * num * sizeof(T);\n  size_t vectors_size = upper * num * sizeof(T);\n\n  T *matrices = (T*)malloc(matrices_size);\n  assert(matrices);\n\n  T *vectors = (T*)malloc(vectors_size);\n  assert(vectors);\n\n  T *result = (T*)malloc(vectors_size);\n  assert(result);\n\n  T *result_ref = (T*)malloc(vectors_size);\n  assert(result_ref);\n\n  srand48(48);\n  for(int i = 0; i < num * upper * upper; i++)\n    matrices[i] = static_cast<T>(drand48());\n\n  for(int i = 0; i < num * upper; i++)\n    vectors[i] = static_cast<T>(drand48());\n\n  if(verbose) cout << \"allocating device variables\" << endl;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  T *devMatrices = (T *)sycl::malloc_device(matrices_size, q);\n  assert(devMatrices != nullptr);\n\n  T *devVectors = (T *)sycl::malloc_device(vectors_size, q);\n  assert(devVectors != nullptr);\n\n  \n\n  T *devResult = (T *)sycl::malloc_device(vectors_size, q);\n  assert(devResult != nullptr);\n\n  if(verbose) cout << \"copying data to device\" << endl;\n  \n\n  q.memcpy(devMatrices, matrices, matrices_size).wait();\n  q.memcpy(devVectors, vectors, vectors_size).wait();\n\n  int lda = upper, \n\n      ldb = upper, \n\n      ldc = upper; \n\n\n  const T alpha = 1.0f, beta = 0.0f;\n\n  \n\n  struct param_t {\n    oneapi::mkl::transpose transpose_info[2];\n    T value_info[2];\n    std::int64_t size_info[3];\n    std::int64_t ld_info[3];\n    std::int64_t stride_info[3];\n  };\n\n  param_t *p = (param_t *)std::malloc(sizeof(param_t));\n  p->transpose_info[0] = oneapi::mkl::transpose::nontrans;\n  p->transpose_info[1] = oneapi::mkl::transpose::nontrans;\n  p->value_info[0] = alpha;\n  p->value_info[1] = beta;\n  p->ld_info[0] = lda;\n  p->ld_info[1] = ldb;\n  p->ld_info[2] = ldc;\n  p->stride_info[0] = upper*upper;\n  p->stride_info[1] = upper;\n  p->stride_info[2] = upper;\n\n  for(int size = lower; size <= upper; size++){\n    if(verbose) cout << \"running with <size x size> x <size x 1> \" << size << endl;\n    double sum = 0.0;\n    const int m = size, n = 1, k = size;\n    p->size_info[0] = m;\n    p->size_info[1] = n;\n    p->size_info[2] = k;\n    for(int rep = 0; rep <= reps; rep++){\n      auto start = std::chrono::steady_clock::now();\n\n      oneapi::mkl::blas::column_major::gemm_batch(\n        q, p->transpose_info[0], p->transpose_info[1],\n        p->size_info[0], p->size_info[1], p->size_info[2],\n        p->value_info[0],\n        devMatrices, p->ld_info[0], p->stride_info[0],\n        devVectors, p->ld_info[1], p->stride_info[1],\n        p->value_info[1],\n        devResult, p->ld_info[2], p->stride_info[2],\n        num).wait();\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      auto elapsed = time * 1e-3;\n\n      if (rep != 0) sum += elapsed;\n      \n      if(verbose)\n\tcout << \"size \" << size << \": \" << elapsed << \" us; \" \n\t     << elapsed / num << \" us per operation\" << endl;\n    }\n    cout << \"size \" << size << \" average execution time: \" << sum/reps << \" us; \"\n\t << sum / reps / num << \" us per operation; \"\n         << \"floating-point operations per second: \";\n    performance(m, n, k, 1e3 * (sum / reps / num));\n\n    \n\n    if constexpr (std::is_same_v<T, double>) {\n      q.memcpy(result, devResult, vectors_size).wait();\n      gemmBatched_ref (num, upper, upper, 1, m, k, n, alpha, beta,\n                       matrices, lda, vectors, ldb, result_ref, ldc);\n\n      for (int i = 0; i < num; i++) {\n      for (int j = 0; j < m; j++) {\n        if (abs(result[i*upper+j] - result_ref[i*upper+j]) > 1e-6) {\n          cout << \"Mismatch at batch index \" << i << \": \" << result[i*upper+j] << \"!=\"\n               << result_ref[i*upper+j] << endl;\n          break;\n        }\n      }}\n    }\n  }\n\n  sycl::free(devMatrices, q);\n  sycl::free(devVectors, q);\n  sycl::free(devResult, q);\n\n  free(p);\n  free(matrices);\n  free(vectors);\n  free(result);\n  free(result_ref);\n}\ncatch (sycl::exception const &exc) {\n  std::cerr << exc.what() << \"Exception caught at file:\" << __FILE__\n            << \", line:\" << __LINE__ << std::endl;\n  std::exit(1);\n}\n\nint main(int argc, char **argv) {\n\n  int status;\n  int lower = 2;    \n\n  int upper = 100;  \n\n  int num = 25000;  \n\n  int reps = 10;\n  int verbose = 0;\n  \n  while((status = getopt(argc, argv, \"l:u:n:r:v\")) != -1){\n    switch(status){\n    case 'l':\n      lower = strtoul(optarg, 0, 0);\n      break;\n    case 'u':\n      upper = strtoul(optarg, 0, 0);\n      break;\n    case 'n':\n      num = strtoul(optarg, 0, 0);\n      break;\n    case 'r':\n      reps = strtoul(optarg, 0, 0);\n      break;\n    case 'v':\n      verbose = 1;\n      break;\n    default:\n      cerr << \"invalid argument: \" << status << endl;\n      exit(1);\n    }\n  }\n\n  cout << \"running with\" << \" lower: \" << lower << \" upper: \" << upper\n       << \" num: \" << num << \" reps: \" << reps << endl;\n\n  cout << \">>>>>>>>>>>>>>> Half precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<sycl::half>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Single precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<float>(lower, upper, num, reps, verbose);\n  cout << \">>>>>>>>>>>>>>> Double precision gemmBatched >>>>>>>>>>>>>>> \" << endl;\n  gemmBatched<double>(lower, upper, num, reps, verbose);\n      \n  return 0;\n}\n"}}
{"kernel_name": "blockAccess", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <random>\n#include <cuda.h>\n#include \"block_load.h\"\n#include \"block_store.h\"\n\n#define NUM 4\n\n__global__ void reference (const float * __restrict__ A,\n                           unsigned char *out, const unsigned int n)\n{\n  for (unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n       idx < n; idx += gridDim.x * blockDim.x) {\n    out[idx] = int(A[idx]);\n  }\n}\n\ntemplate<int TH, int NUM_BLOCK>\n__global__ void kernel (const float * __restrict__ A,\n                        unsigned char *out, const unsigned int n)\n{\n  const int bid = blockIdx.x;\n  const int base_idx = (bid * NUM_BLOCK);\n\n  float vals[NUM];\n  unsigned char qvals[NUM];\n\n  typedef BlockLoad<float, TH, NUM> LoadFloat;\n  typedef BlockStore<unsigned char, TH, NUM> StoreChar;\n\n  __shared__ typename LoadFloat::TempStorage loadf;\n  __shared__ typename StoreChar::TempStorage storec;\n\n  for (unsigned int i = base_idx; i < n; i += gridDim.x*NUM_BLOCK)\n  {\n      unsigned int valid_items = n - i > NUM_BLOCK ? NUM_BLOCK : n - i;\n\n      LoadFloat(loadf).Load(&(A[i]), vals, valid_items);\n\n      #pragma unroll\n      for(int j = 0; j < NUM; j++)\n          qvals[j] = int(vals[j]);\n\n      StoreChar(storec).Store(&(out[i]), qvals, valid_items);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <number of columns> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const unsigned int n = nrows * ncols;\n  const size_t A_size = n * sizeof(float);\n  const size_t out_size = n * sizeof(unsigned char);\n\n  float *A = (float*) malloc (A_size);\n  unsigned char *out = (unsigned char*) malloc (out_size);\n\n  std::mt19937 gen{19937};\n \n  std::normal_distribution<float> d{128.0, 127.0};\n\n  for (unsigned int i = 0; i < n; i++) {\n    A[i] = d(gen); \n  }\n\n  float *d_A;\n  cudaMalloc((void**)&d_A, A_size);\n  cudaMemcpy(d_A, A, A_size, cudaMemcpyHostToDevice);\n\n  unsigned char *d_out;\n  cudaMalloc((void**)&d_out, out_size);\n  \n  const int block_size = 256;\n\n  cudaDeviceProp prop;\n  cudaGetDeviceProperties(&prop, 0);\n  dim3 grid (16 * prop.multiProcessorCount);\n  dim3 block (block_size);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    reference<<<grid, block>>>(d_A, d_out, n);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the reference kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    kernel<block_size, block_size*NUM><<<grid, block>>>(d_A, d_out, n);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the blockAccess kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n  \n  cudaMemcpy(out, d_out, out_size, cudaMemcpyDeviceToHost);\n\n  bool error = false;\n  for (unsigned int i = 0; i < n; i++) {\n    unsigned char t = int(A[i]);\n    if (out[i] != t) {\n      printf(\"@%u: %u != %u\\n\", i, out[i], t);\n      error = true;\n      break;\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  cudaFree(d_A);\n  cudaFree(d_out);\n  free(A);\n  free(out);\n  return 0;\n}\n"}}
{"kernel_name": "blockAccess", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"block_load.h\"\n#include \"block_store.h\"\n\n#define NUM 4\n\n__global__ void reference (const float * __restrict__ A,\n                           unsigned char *out, const unsigned int n)\n{\n  for (unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n       idx < n; idx += gridDim.x * blockDim.x) {\n    out[idx] = int(A[idx]);\n  }\n}\n\ntemplate<int TH, int NUM_BLOCK>\n__global__ void kernel (const float * __restrict__ A,\n                        unsigned char *out, const unsigned int n)\n{\n  const int bid = blockIdx.x;\n  const int base_idx = (bid * NUM_BLOCK);\n\n  float vals[NUM];\n  unsigned char qvals[NUM];\n\n  typedef BlockLoad<float, TH, NUM> LoadFloat;\n  typedef BlockStore<unsigned char, TH, NUM> StoreChar;\n\n  __shared__ typename LoadFloat::TempStorage loadf;\n  __shared__ typename StoreChar::TempStorage storec;\n\n  for (unsigned int i = base_idx; i < n; i += gridDim.x*NUM_BLOCK)\n  {\n      unsigned int valid_items = n - i > NUM_BLOCK ? NUM_BLOCK : n - i;\n\n      LoadFloat(loadf).Load(&(A[i]), vals, valid_items);\n\n      #pragma unroll\n      for(int j = 0; j < NUM; j++)\n          qvals[j] = int(vals[j]);\n\n      StoreChar(storec).Store(&(out[i]), qvals, valid_items);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <number of columns> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const unsigned int n = nrows * ncols;\n  const size_t A_size = n * sizeof(float);\n  const size_t out_size = n * sizeof(unsigned char);\n\n  float *A = (float*) malloc (A_size);\n  unsigned char *out = (unsigned char*) malloc (out_size);\n\n  std::mt19937 gen{19937};\n \n  std::normal_distribution<float> d{128.0, 127.0};\n\n  for (unsigned int i = 0; i < n; i++) {\n    A[i] = d(gen); \n  }\n\n  float *d_A;\n  hipMalloc((void**)&d_A, A_size);\n  hipMemcpy(d_A, A, A_size, hipMemcpyHostToDevice);\n\n  unsigned char *d_out;\n  hipMalloc((void**)&d_out, out_size);\n  \n  const int block_size = 256;\n\n  hipDeviceProp_t prop;\n  hipGetDeviceProperties(&prop, 0);\n  dim3 grid (16 * prop.multiProcessorCount);\n  dim3 block (block_size);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    reference<<<grid, block>>>(d_A, d_out, n);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the reference kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    kernel<block_size, block_size*NUM><<<grid, block>>>(d_A, d_out, n);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the blockAccess kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n  \n  hipMemcpy(out, d_out, out_size, hipMemcpyDeviceToHost);\n\n  bool error = false;\n  for (unsigned int i = 0; i < n; i++) {\n    unsigned char t = int(A[i]);\n    if (out[i] != t) {\n      printf(\"@%u: %u != %u\\n\", i, out[i], t);\n      error = true;\n      break;\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  hipFree(d_A);\n  hipFree(d_out);\n  free(A);\n  free(out);\n  return 0;\n}\n"}}
{"kernel_name": "blockAccess", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n#include \"block_load.h\"\n#include \"block_store.h\"\n\n#define NUM 4\n\nvoid reference (const float * __restrict__ A,\n                unsigned char *out, const unsigned int n,\n                const sycl::nd_item<3> &item)\n{\n  for (unsigned int idx = item.get_global_id(2);\n       idx < n; idx += item.get_local_range(2) * item.get_group_range(2)) {\n    out[idx] = int(A[idx]);\n  }\n}\n\ntemplate<int TH, int NUM_BLOCK>\nvoid kernel(const float * __restrict__ A,\n            unsigned char *out, const int n,\n            const sycl::nd_item<3> &item)\n{\n  const int bid = item.get_group(2);\n  const int base_idx = (bid * NUM_BLOCK);\n\n  float vals[NUM];\n  unsigned char qvals[NUM];\n\n  typedef BlockLoad<float, TH, NUM> LoadFloat;\n  typedef BlockStore<unsigned char, TH, NUM> StoreChar;\n\n  sycl::multi_ptr<typename LoadFloat::TempStorage[1], sycl::access::address_space::local_space> p1 =\n      sycl::ext::oneapi::group_local_memory_for_overwrite<typename LoadFloat::TempStorage[1]>(item.get_group());\n  typename LoadFloat::TempStorage *loadf = *p1;\n\n  sycl::multi_ptr<typename StoreChar::TempStorage[1], sycl::access::address_space::local_space> p2 =\n      sycl::ext::oneapi::group_local_memory_for_overwrite<typename StoreChar::TempStorage[1]>(item.get_group());\n  typename StoreChar::TempStorage *storec = *p2;\n\n  for (unsigned int i = base_idx; i < n; i += item.get_group_range(2)*NUM_BLOCK)\n  {\n      unsigned int valid_items = n - i > NUM_BLOCK ? NUM_BLOCK : n - i;\n\n      LoadFloat(*loadf, item).Load(&(A[i]), vals, valid_items);\n\n      #pragma unroll\n      for(int j = 0; j < NUM; j++)\n          qvals[j] = (int)vals[j];\n\n      StoreChar(*storec, item).Store(&(out[i]), qvals, valid_items);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <number of columns> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const size_t n = (size_t)nrows * ncols;\n  const size_t A_size = n * sizeof(float);\n  const size_t out_size = n * sizeof(unsigned char);\n\n  float *A = (float*) malloc (A_size);\n  unsigned char *out = (unsigned char*) malloc (out_size);\n\n  std::mt19937 gen{19937};\n \n  std::normal_distribution<float> d{128.0, 127.0};\n\n  for (size_t i = 0; i < n; i++) {\n    A[i] = d(gen); \n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_A;\n  d_A = (float *)sycl::malloc_device(A_size, q);\n  q.memcpy(d_A, A, A_size).wait();\n\n  unsigned char *d_out;\n  d_out = (unsigned char *)sycl::malloc_device(out_size, q);\n\n  const int block_size = 256;\n\n  int cu = q.get_device().get_info<sycl::info::device::max_compute_units>();\n  sycl::range<3> gws (1, 1, 16 * cu * block_size);\n  sycl::range<3> lws (1, 1, block_size);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(\n          sycl::nd_range<3>(gws, lws),\n          [=](sycl::nd_item<3> item) {\n            reference(d_A, d_out, n, item);\n          });\n    });\n  }\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the reference kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(\n          sycl::nd_range<3>(gws, lws),\n          [=](sycl::nd_item<3> item) {\n            kernel<block_size, block_size * NUM>(\n                d_A, d_out, n, item);\n          });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the blockAccess kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(out, d_out, out_size).wait();\n\n  bool error = false;\n  for (unsigned int i = 0; i < n; i++) {\n    unsigned char t = int(A[i]);\n    if (out[i] != t) {\n      printf(\"@%u: %u != %u\\n\", i, out[i], t);\n      error = true;\n      break;\n    }\n  }\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n  \n  sycl::free(d_A, q);\n  sycl::free(d_out, q);\n  free(A);\n  free(out);\n  return 0;\n}\n"}}
{"kernel_name": "blockexchange", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cuda.h>\n#include \"utils.h\"\n#include \"block_load.h\"\n#include \"block_store.h\"\n#include \"block_exchange.h\"\n\nconstexpr int items_per_thread = 4;\n\ntemplate <int BLOCK_SIZE, int NUM_BLOCK>\n__global__ void k(const int *d, int *o, const int n)\n{\n  const int bid = blockIdx.x;\n  const int dim = gridDim.x;\n  constexpr int block_threads = BLOCK_SIZE;\n\n  typedef BlockExchange<int, block_threads, items_per_thread> BlockExchangeT;\n  typedef BlockLoad<int, block_threads, items_per_thread> LoadInteger;\n  typedef BlockStore<int, block_threads, items_per_thread> StoreInteger;\n\n  \n\n  __shared__ typename BlockExchangeT::TempStorage temp_storage;\n  __shared__ typename LoadInteger::TempStorage loadi;\n  __shared__ typename StoreInteger::TempStorage storei;\n\n  \n\n  int thread_data[items_per_thread];\n\n  const int n_full = (NUM_BLOCK*(n/NUM_BLOCK)) + (n % NUM_BLOCK == 0 ? 0 : NUM_BLOCK);\n  const int base_idx = (bid * NUM_BLOCK);\n  for (unsigned int i = base_idx; i < n_full; i += dim*NUM_BLOCK) {\n    unsigned int valid_items = n - i > NUM_BLOCK ? NUM_BLOCK : n - i;\n    LoadInteger(loadi).Load(&(d[i]), thread_data, valid_items);\n\n    \n\n    BlockExchangeT(temp_storage).BlockedToStriped(thread_data, thread_data);\n\n    StoreInteger(storei).Store(&(o[i]), thread_data, valid_items);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <number of columns> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const size_t n = (size_t)nrows * ncols;\n  const size_t A_size = n * sizeof(int);\n  const size_t out_size = n * sizeof(int);\n\n  int *A = (int*) malloc (A_size);\n  int *out = (int*) malloc (out_size);\n\n  for (size_t i = 0; i < n; i++) {\n    A[i] = i;\n  }\n\n  int *d_A;\n  cudaMalloc((void**)&d_A, A_size);\n  cudaMemcpy(d_A, A, A_size, cudaMemcpyHostToDevice);\n\n  int *d_out;\n  cudaMalloc((void**)&d_out, out_size);\n\n  const int block_size = 256;\n\n  dim3 grid ((n+block_size-1)/block_size);\n  dim3 block (block_size);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    k<block_size, block_size*items_per_thread><<<grid, block>>>(d_A, d_out, n);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(out, d_out, out_size, cudaMemcpyDeviceToHost);\n\n#ifdef DEBUG\n  for (size_t i = 0; i < n; i++) {\n    printf(\"%zu: %d %d\\n\", i, A[i], out[i]);\n  }\n#endif\n\n  \n\n  \n\n\n  \n\n  \n\n  const int items_per_block = items_per_thread * block_size;\n  if (n % items_per_block == 0) {\n    size_t k;\n    bool ok = true;\n    for (k = 0; k < n; k += items_per_block) {\n      size_t i = k;\n      for (int j = 0; j < items_per_thread; j++) {\n        for (int m = 0; m < block_size-1; m++) {\n          if (i + (m+1)*items_per_thread < n) {\n            if (out[i + (m+1)*items_per_thread] - out[i + m*items_per_thread] != 1) {\n              printf(\"Error at index %zu\\n\", i + (m+1)*items_per_thread);\n              ok = false;\n              goto stop;\n            }\n          }\n        }\n        i++;\n      }\n    }\n    stop:\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  cudaFree(d_A);\n  cudaFree(d_out);\n  free(A);\n  free(out);\n  return 0;\n}\n"}}
{"kernel_name": "blockexchange", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <hip/hip_runtime.h>\n#include \"utils.h\"\n#include \"block_load.h\"\n#include \"block_store.h\"\n#include \"block_exchange.h\"\n\nconstexpr int items_per_thread = 4;\n\ntemplate <int BLOCK_SIZE, int NUM_BLOCK>\n__global__ void k(const int *d, int *o, const int n)\n{\n  const int bid = blockIdx.x;\n  const int dim = gridDim.x;\n  constexpr int block_threads = BLOCK_SIZE;\n\n  typedef BlockExchange<int, block_threads, items_per_thread> BlockExchangeT;\n  typedef BlockLoad<int, block_threads, items_per_thread> LoadInteger;\n  typedef BlockStore<int, block_threads, items_per_thread> StoreInteger;\n\n  \n\n  __shared__ typename BlockExchangeT::TempStorage temp_storage;\n  __shared__ typename LoadInteger::TempStorage loadi;\n  __shared__ typename StoreInteger::TempStorage storei;\n\n  \n\n  int thread_data[items_per_thread];\n\n  const int n_full = (NUM_BLOCK*(n/NUM_BLOCK)) + (n % NUM_BLOCK == 0 ? 0 : NUM_BLOCK);\n  const int base_idx = (bid * NUM_BLOCK);\n  for (unsigned int i = base_idx; i < n_full; i += dim*NUM_BLOCK) {\n    unsigned int valid_items = n - i > NUM_BLOCK ? NUM_BLOCK : n - i;\n    LoadInteger(loadi).Load(&(d[i]), thread_data, valid_items);\n\n    \n\n    BlockExchangeT(temp_storage).BlockedToStriped(thread_data, thread_data);\n\n    StoreInteger(storei).Store(&(o[i]), thread_data, valid_items);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <number of columns> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const size_t n = (size_t)nrows * ncols;\n  const size_t A_size = n * sizeof(int);\n  const size_t out_size = n * sizeof(int);\n\n  int *A = (int*) malloc (A_size);\n  int *out = (int*) malloc (out_size);\n\n  for (size_t i = 0; i < n; i++) {\n    A[i] = i;\n  }\n\n  int *d_A;\n  hipMalloc((void**)&d_A, A_size);\n  hipMemcpy(d_A, A, A_size, hipMemcpyHostToDevice);\n\n  int *d_out;\n  hipMalloc((void**)&d_out, out_size);\n\n  const int block_size = 256;\n\n  dim3 grid ((n+block_size-1)/block_size);\n  dim3 block (block_size);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    k<block_size, block_size*items_per_thread><<<grid, block>>>(d_A, d_out, n);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(out, d_out, out_size, hipMemcpyDeviceToHost);\n\n#ifdef DEBUG\n  for (size_t i = 0; i < n; i++) {\n    printf(\"%zu: %d %d\\n\", i, A[i], out[i]);\n  }\n#endif\n\n  \n\n  \n\n\n  \n\n  \n\n  const int items_per_block = items_per_thread * block_size;\n  if (n % items_per_block == 0) {\n    size_t k;\n    bool ok = true;\n    for (k = 0; k < n; k += items_per_block) {\n      size_t i = k;\n      for (int j = 0; j < items_per_thread; j++) {\n        for (int m = 0; m < block_size-1; m++) {\n          if (i + (m+1)*items_per_thread < n) {\n            if (out[i + (m+1)*items_per_thread] - out[i + m*items_per_thread] != 1) {\n              printf(\"Error at index %zu\\n\", i + (m+1)*items_per_thread);\n              ok = false;\n              goto stop;\n            }\n          }\n        }\n        i++;\n      }\n    }\n    stop:\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  hipFree(d_A);\n  hipFree(d_out);\n  free(A);\n  free(out);\n  return 0;\n}\n"}}
{"kernel_name": "blockexchange", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n#include \"block_load.h\"\n#include \"block_store.h\"\n#include \"block_exchange.h\"\n\nconstexpr int items_per_thread = 4;\n\ntemplate <int BLOCK_SIZE, int NUM_BLOCK>\nvoid k(const int *d, int *o, const int n, const sycl::nd_item<3> &item)\n{\n  const int bid = item.get_group(2);\n  const int dim = item.get_group_range(2);\n  constexpr int block_threads = BLOCK_SIZE;\n\n  typedef BlockExchange<int, block_threads, items_per_thread> BlockExchangeT;\n  typedef BlockLoad<int, block_threads, items_per_thread> LoadInteger;\n  typedef BlockStore<int, block_threads, items_per_thread> StoreInteger;\n\n  \n\n  sycl::multi_ptr<typename BlockExchangeT::TempStorage[1], sycl::access::address_space::local_space> p1 =\n      sycl::ext::oneapi::group_local_memory_for_overwrite<typename BlockExchangeT::TempStorage[1]>(item.get_group());\n  typename BlockExchangeT::TempStorage *temp_storage = *p1;\n\n  sycl::multi_ptr<typename LoadInteger::TempStorage[1], sycl::access::address_space::local_space> p2 =\n      sycl::ext::oneapi::group_local_memory_for_overwrite<typename LoadInteger::TempStorage[1]>(item.get_group());\n  typename LoadInteger::TempStorage *loadi = *p2;\n\n  sycl::multi_ptr<typename StoreInteger::TempStorage[1], sycl::access::address_space::local_space> p3 =\n      sycl::ext::oneapi::group_local_memory_for_overwrite<typename StoreInteger::TempStorage[1]>(item.get_group());\n  typename StoreInteger::TempStorage *storei = *p3;\n\n  \n\n  int thread_data[items_per_thread];\n\n  const int n_full = (NUM_BLOCK*(n/NUM_BLOCK)) + (n % NUM_BLOCK == 0 ? 0 : NUM_BLOCK);\n  const int base_idx = (bid * NUM_BLOCK);\n  for (unsigned int i = base_idx; i < n_full; i += dim*NUM_BLOCK) {\n    unsigned int valid_items = n - i > NUM_BLOCK ? NUM_BLOCK : n - i;\n    LoadInteger(*loadi, item).Load(&(d[i]), thread_data, valid_items);\n\n    \n\n    BlockExchangeT(*temp_storage, item).BlockedToStriped(thread_data, thread_data);\n\n    StoreInteger(*storei, item).Store(&(o[i]), thread_data, valid_items);\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of rows> <number of columns> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nrows = atoi(argv[1]);\n  const int ncols = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const size_t n = (size_t)nrows * ncols;\n  const size_t A_size = n * sizeof(int);\n  const size_t out_size = n * sizeof(int);\n\n  int *A = (int*) malloc (A_size);\n  int *out = (int*) malloc (out_size);\n\n  for (size_t i = 0; i < n; i++) {\n    A[i] = i;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_A;\n  d_A = (int *)sycl::malloc_device(A_size, q);\n  q.memcpy(d_A, A, A_size);\n\n  int *d_out;\n  d_out = (int *)sycl::malloc_device(out_size, q);\n\n  const int block_size = 256;\n\n  sycl::range<3> grid(1, 1, (n + block_size - 1) / block_size);\n  sycl::range<3> block(1, 1, block_size);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(\n          sycl::nd_range<3>(grid * block, block),\n          [=](sycl::nd_item<3> item) {\n            k<block_size, block_size * items_per_thread>(\n                d_A, d_out, n, item);\n          });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(out, d_out, out_size).wait();\n\n#ifdef DEBUG\n  for (size_t i = 0; i < n; i++) {\n    printf(\"%zu: %d %d\\n\", i, A[i], out[i]);\n  }\n#endif\n\n  \n\n  \n\n\n  \n\n  \n\n  const int items_per_block = items_per_thread * block_size;\n  if (n % items_per_block == 0) {\n    size_t k;\n    bool ok = true;\n    for (k = 0; k < n; k += items_per_block) {\n      size_t i = k;\n      for (int j = 0; j < items_per_thread; j++) {\n        for (int m = 0; m < block_size-1; m++) {\n          if (i + (m+1)*items_per_thread < n) {\n            if (out[i + (m+1)*items_per_thread] - out[i + m*items_per_thread] != 1) {\n              printf(\"Error at index %zu\\n\", i + (m+1)*items_per_thread);\n              ok = false;\n              goto stop;\n            }\n          }\n        }\n        i++;\n      }\n    }\n    stop:\n    printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  }\n\n  sycl::free(d_A, q);\n  sycl::free(d_out, q);\n  free(A);\n  free(out);\n  return 0;\n}\n"}}
{"kernel_name": "bsearch", "parallel_api": "cuda", "code": {"main.cu": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n#include <cuda.h>\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\ntemplate <typename T>\n__global__ void\nkernel_BS (const T* __restrict__ acc_a,\n           const T* __restrict__ acc_z,\n            size_t* __restrict__ acc_r,\n           const size_t n)\n{ \n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  T z = acc_z[i];\n  size_t low = 0;\n  size_t high = n;\n  while (high - low > 1) {\n    size_t mid = low + (high - low)/2;\n    if (z < acc_a[mid])\n      high = mid;\n    else\n      low = mid;\n  }\n  acc_r[i] = low;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS2 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  unsigned  nbits = 0;\n  while (n >> nbits) nbits++;\n  size_t k = 1ULL << (nbits - 1);\n  T z = acc_z[i];\n  size_t idx = (acc_a[k] <= z) ? k : 0;\n  while (k >>= 1) {\n    size_t r = idx | k;\n    if (r < n && z >= acc_a[r]) { \n      idx = r;\n    }\n  }\n  acc_r[i] = idx;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS3 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  unsigned nbits = 0;\n  while (n >> nbits) nbits++;\n  size_t k = 1ULL << (nbits - 1);\n  T z = acc_z[i];\n  size_t idx = (acc_a[k] <= z) ? k : 0;\n  while (k >>= 1) {\n    size_t r = idx | k;\n    size_t w = r < n ? r : n; \n    if (z >= acc_a[w]) { \n      idx = r;\n    }\n  }\n  acc_r[i] = idx;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS4 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  __shared__  size_t k;\n\n  size_t gid = blockIdx.x*blockDim.x+threadIdx.x;\n  size_t lid = threadIdx.x; \n\n  if (lid == 0) {\n    unsigned nbits = 0;\n    while (n >> nbits) nbits++;\n    k = 1ULL << (nbits - 1);\n  }\n  __syncthreads();\n\n  size_t p = k;\n  T z = acc_z[gid];\n  size_t idx = (acc_a[p] <= z) ? p : 0;\n  while (p >>= 1) {\n    size_t r = idx | p;\n    size_t w = r < n ? r : n;\n    if (z >= acc_a[w]) { \n      idx = r;\n    }\n  }\n  acc_r[gid] = idx;\n}\n\ntemplate <typename T>\nvoid bs ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs1) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs2 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS2<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs2) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs3 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS3<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs3) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs4 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS4<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs4) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n  for (size_t i = 0; i < zSize; ++i)\n  {\n    \n\n    if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n    {\n      std::cout << msg << \": incorrect result:\" << std::endl;\n      std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n      std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n      break;\n    }\n    \n\n    r[i] = 0xFFFFFFFF;\n  }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) z[i] = rand() % N;\n\n  Real_t* d_a;\n  Real_t* d_z;\n  size_t *d_r;\n  cudaMalloc((void**)&d_a, sizeof(Real_t)*aSize);\n  cudaMalloc((void**)&d_z, sizeof(Real_t)*zSize);\n  cudaMalloc((void**)&d_r, sizeof(size_t)*zSize);\n  cudaMemcpy(d_a, a, sizeof(Real_t)*aSize, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_z, z, sizeof(Real_t)*zSize, cudaMemcpyHostToDevice);\n\n  bs(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(r, d_r, sizeof(size_t)*zSize, cudaMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs\");\n#endif\n\n  bs2(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(r, d_r, sizeof(size_t)*zSize, cudaMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs2\");\n#endif\n\n  bs3(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(r, d_r, sizeof(size_t)*zSize, cudaMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs3\");\n#endif\n\n  bs4(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  cudaMemcpy(r, d_r, sizeof(size_t)*zSize, cudaMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs4\");\n#endif\n\n  cudaFree(d_a);\n  cudaFree(d_z);\n  cudaFree(d_r);\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "bsearch", "parallel_api": "hip", "code": {"main.cu": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n#include <hip/hip_runtime.h>\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\ntemplate <typename T>\n__global__ void\nkernel_BS (const T* __restrict__ acc_a,\n           const T* __restrict__ acc_z,\n            size_t* __restrict__ acc_r,\n           const size_t n)\n{ \n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  T z = acc_z[i];\n  size_t low = 0;\n  size_t high = n;\n  while (high - low > 1) {\n    size_t mid = low + (high - low)/2;\n    if (z < acc_a[mid])\n      high = mid;\n    else\n      low = mid;\n  }\n  acc_r[i] = low;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS2 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  unsigned  nbits = 0;\n  while (n >> nbits) nbits++;\n  size_t k = 1ULL << (nbits - 1);\n  T z = acc_z[i];\n  size_t idx = (acc_a[k] <= z) ? k : 0;\n  while (k >>= 1) {\n    size_t r = idx | k;\n    if (r < n && z >= acc_a[r]) { \n      idx = r;\n    }\n  }\n  acc_r[i] = idx;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS3 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  size_t i = blockIdx.x*blockDim.x+threadIdx.x;\n  unsigned nbits = 0;\n  while (n >> nbits) nbits++;\n  size_t k = 1ULL << (nbits - 1);\n  T z = acc_z[i];\n  size_t idx = (acc_a[k] <= z) ? k : 0;\n  while (k >>= 1) {\n    size_t r = idx | k;\n    size_t w = r < n ? r : n; \n    if (z >= acc_a[w]) { \n      idx = r;\n    }\n  }\n  acc_r[i] = idx;\n}\n\ntemplate <typename T>\n__global__ void\nkernel_BS4 (const T* __restrict__ acc_a,\n            const T* __restrict__ acc_z,\n             size_t* __restrict__ acc_r,\n            const size_t n)\n{\n  __shared__  size_t k;\n\n  size_t gid = blockIdx.x*blockDim.x+threadIdx.x;\n  size_t lid = threadIdx.x; \n\n  if (lid == 0) {\n    unsigned nbits = 0;\n    while (n >> nbits) nbits++;\n    k = 1ULL << (nbits - 1);\n  }\n  __syncthreads();\n\n  size_t p = k;\n  T z = acc_z[gid];\n  size_t idx = (acc_a[p] <= z) ? p : 0;\n  while (p >>= 1) {\n    size_t r = idx | p;\n    size_t w = r < n ? r : n;\n    if (z >= acc_a[w]) { \n      idx = r;\n    }\n  }\n  acc_r[gid] = idx;\n}\n\ntemplate <typename T>\nvoid bs ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs1) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs2 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS2<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs2) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs3 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS3<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs3) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs4 ( const size_t aSize,\n    const size_t zSize,\n    const T *d_a,  \n\n    const T *d_z,  \n\n    size_t *d_r,   \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++)\n    kernel_BS4<<<zSize/256, 256>>>(d_a, d_z, d_r, n);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (bs4) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n  for (size_t i = 0; i < zSize; ++i)\n  {\n    \n\n    if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n    {\n      std::cout << msg << \": incorrect result:\" << std::endl;\n      std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n      std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n      break;\n    }\n    \n\n    r[i] = 0xFFFFFFFF;\n  }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) z[i] = rand() % N;\n\n  Real_t* d_a;\n  Real_t* d_z;\n  size_t *d_r;\n  hipMalloc((void**)&d_a, sizeof(Real_t)*aSize);\n  hipMalloc((void**)&d_z, sizeof(Real_t)*zSize);\n  hipMalloc((void**)&d_r, sizeof(size_t)*zSize);\n  hipMemcpy(d_a, a, sizeof(Real_t)*aSize, hipMemcpyHostToDevice);\n  hipMemcpy(d_z, z, sizeof(Real_t)*zSize, hipMemcpyHostToDevice);\n\n  bs(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  hipMemcpy(r, d_r, sizeof(size_t)*zSize, hipMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs\");\n#endif\n\n  bs2(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  hipMemcpy(r, d_r, sizeof(size_t)*zSize, hipMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs2\");\n#endif\n\n  bs3(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  hipMemcpy(r, d_r, sizeof(size_t)*zSize, hipMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs3\");\n#endif\n\n  bs4(aSize, zSize, d_a, d_z, d_r, N, repeat);\n\n#ifdef DEBUG\n  hipMemcpy(r, d_r, sizeof(size_t)*zSize, hipMemcpyDeviceToHost);\n  verify(a, z, r, aSize, zSize, \"bs4\");\n#endif\n\n  hipFree(d_a);\n  hipFree(d_z);\n  hipFree(d_r);\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "bsearch", "parallel_api": "omp", "code": {"main.cpp": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n#include <omp.h>\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\ntemplate <typename T>\nvoid bs ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < zSize; i++) { \n      T z = acc_z[i];\n      size_t low = 0;\n      size_t high = n;\n      while (high - low > 1) {\n        size_t mid = low + (high - low)/2;\n        if (z < acc_a[mid])\n          high = mid;\n        else\n          low = mid;\n      }\n      acc_r[i] = low;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs1) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs2 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < zSize; i++) { \n      unsigned  nbits = 0;\n      while (n >> nbits) nbits++;\n      size_t k = 1ULL << (nbits - 1);\n      T z = acc_z[i];\n      size_t idx = (acc_a[k] <= z) ? k : 0;\n      while (k >>= 1) {\n        size_t r = idx | k;\n        if (r < n && z >= acc_a[r]) { \n          idx = r;\n        }\n      }\n      acc_r[i] = idx;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs2) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs3 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int i = 0; i < zSize; i++) { \n      unsigned nbits = 0;\n      while (n >> nbits) nbits++;\n      size_t k = 1ULL << (nbits - 1);\n      T z = acc_z[i];\n      size_t idx = (acc_a[k] <= z) ? k : 0;\n      while (k >>= 1) {\n        size_t r = idx | k;\n        size_t w = r < n ? r : n; \n        if (z >= acc_a[w]) { \n          idx = r;\n        }\n      }\n      acc_r[i] = idx;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs3) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs4 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n    #pragma omp target teams num_teams(zSize/256)  thread_limit(256)\n    {\n      size_t k;\n      #pragma omp parallel\n      {\n        size_t lid = omp_get_thread_num();\n        size_t gid = omp_get_team_num()*omp_get_num_threads()+lid;\n        if (lid == 0) {\n          unsigned nbits = 0;\n          while (n >> nbits) nbits++;\n          k = 1ULL << (nbits - 1);\n        }\n        #pragma omp barrier\n\n        size_t p = k;\n        T z = acc_z[gid];\n        size_t idx = (acc_a[p] <= z) ? p : 0;\n        while (p >>= 1) {\n          size_t r = idx | p;\n          size_t w = r < n ? r : n;\n          if (z >= acc_a[w]) { \n            idx = r;\n          }\n        }\n        acc_r[gid] = idx;\n      }\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs4) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n  for (size_t i = 0; i < zSize; ++i)\n  {\n    \n\n    if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n    {\n      std::cout << msg << \": incorrect result:\" << std::endl;\n      std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n      std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n      break;\n    }\n    \n\n    r[i] = 0xFFFFFFFF;\n  }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) { \n    z[i] = rand() % N;\n  }\n\n  #pragma omp target data map(to: a[0:aSize], z[0:zSize]) \\\n                          map(from: r[0:zSize])\n  {\n    bs(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n    #pragma omp target update from (r[0:zSize])\n    verify(a, z, r, aSize, zSize, \"bs1\");\n  #endif\n  \n    bs2(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n    #pragma omp target update from (r[0:zSize])\n    verify(a, z, r, aSize, zSize, \"bs2\");\n  #endif\n  \n    bs3(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n    #pragma omp target update from (r[0:zSize])\n    verify(a, z, r, aSize, zSize, \"bs3\");\n  #endif\n  \n    bs4(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n    #pragma omp target update from (r[0:zSize])\n    verify(a, z, r, aSize, zSize, \"bs4\");\n  #endif\n  }\n\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "bsearch", "parallel_api": "serial", "code": {"main.cpp": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\ntemplate <typename T>\nvoid bs ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n        for (int i = 0; i < zSize; i++) { \n      T z = acc_z[i];\n      size_t low = 0;\n      size_t high = n;\n      while (high - low > 1) {\n        size_t mid = low + (high - low)/2;\n        if (z < acc_a[mid])\n          high = mid;\n        else\n          low = mid;\n      }\n      acc_r[i] = low;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs1) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs2 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n        for (int i = 0; i < zSize; i++) { \n      unsigned  nbits = 0;\n      while (n >> nbits) nbits++;\n      size_t k = 1ULL << (nbits - 1);\n      T z = acc_z[i];\n      size_t idx = (acc_a[k] <= z) ? k : 0;\n      while (k >>= 1) {\n        size_t r = idx | k;\n        if (r < n && z >= acc_a[r]) { \n          idx = r;\n        }\n      }\n      acc_r[i] = idx;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs2) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs3 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n        for (int i = 0; i < zSize; i++) { \n      unsigned nbits = 0;\n      while (n >> nbits) nbits++;\n      size_t k = 1ULL << (nbits - 1);\n      T z = acc_z[i];\n      size_t idx = (acc_a[k] <= z) ? k : 0;\n      while (k >>= 1) {\n        size_t r = idx | k;\n        size_t w = r < n ? r : n; \n        if (z >= acc_a[w]) { \n          idx = r;\n        }\n      }\n      acc_r[i] = idx;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs3) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\ntemplate <typename T>\nvoid bs4 ( const size_t aSize,\n    const size_t zSize,\n    const T *acc_a,  \n\n    const T *acc_z,  \n\n    size_t *acc_r,  \n\n    const size_t n,\n    const int repeat )\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int i= 0; i < repeat; i++) {\n        {\n      size_t k;\n            {\n        size_t lid = omp_get_thread_num();\n        size_t gid = omp_get_team_num()*omp_get_num_threads()+lid;\n        if (lid == 0) {\n          unsigned nbits = 0;\n          while (n >> nbits) nbits++;\n          k = 1ULL << (nbits - 1);\n        }\n        \n        size_t p = k;\n        T z = acc_z[gid];\n        size_t idx = (acc_a[p] <= z) ? p : 0;\n        while (p >>= 1) {\n          size_t r = idx | p;\n          size_t w = r < n ? r : n;\n          if (z >= acc_a[w]) { \n            idx = r;\n          }\n        }\n        acc_r[gid] = idx;\n      }\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average device execution time (bs4) \" << (time * 1e-9f) / repeat << \" (s)\\n\";\n}\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n  for (size_t i = 0; i < zSize; ++i)\n  {\n    \n\n    if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n    {\n      std::cout << msg << \": incorrect result:\" << std::endl;\n      std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n      std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n      break;\n    }\n    \n\n    r[i] = 0xFFFFFFFF;\n  }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) { \n    z[i] = rand() % N;\n  }\n\n    {\n    bs(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n        verify(a, z, r, aSize, zSize, \"bs1\");\n  #endif\n  \n    bs2(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n        verify(a, z, r, aSize, zSize, \"bs2\");\n  #endif\n  \n    bs3(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n        verify(a, z, r, aSize, zSize, \"bs3\");\n  #endif\n  \n    bs4(aSize, zSize, a, z, r, N, repeat);\n  \n  #ifdef DEBUG\n        verify(a, z, r, aSize, zSize, \"bs4\");\n  #endif\n  }\n\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}"}}
{"kernel_name": "bsearch", "parallel_api": "sycl", "code": {"main.cpp": "#include <cstdlib>\n#include <chrono>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include \"bs.h\"\n#include \"bs2.h\"\n#include \"bs3.h\"\n#include \"bs4.h\"\n\n#ifndef Real_t \n#define Real_t float\n#endif\n\n#ifdef DEBUG\nvoid verify(Real_t *a, Real_t *z, size_t *r, size_t aSize, size_t zSize, std::string msg)\n{\n    for (size_t i = 0; i < zSize; ++i)\n    {\n        \n\n        if (!(r[i]+1 < aSize && a[r[i]] <= z[i] && z[i] < a[r[i] + 1]))\n        {\n          std::cout << msg << \": incorrect result:\" << std::endl;\n          std::cout << \"index = \" << i << \" r[index] = \" << r[i] << std::endl;\n          std::cout << a[r[i]] << \" <= \" << z[i] << \" < \" << a[r[i] + 1] << std::endl;\n          break;\n        }\n        \n\n        r[i] = 0xFFFFFFFF;\n    }\n}\n#endif\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    std::cout << \"Usage ./main <number of elements> <repeat>\\n\";\n    return 1;\n  }\n\n  size_t numElem = atol(argv[1]);\n  uint repeat = atoi(argv[2]);\n\n  srand(2);\n  size_t aSize = numElem;\n  size_t zSize = 2*aSize;\n  Real_t *a = NULL;\n  Real_t *z = NULL;\n  size_t *r = NULL;\n  posix_memalign((void**)&a, 1024, aSize * sizeof(Real_t));\n  posix_memalign((void**)&z, 1024, zSize * sizeof(Real_t));\n  posix_memalign((void**)&r, 1024, zSize * sizeof(size_t));\n\n  size_t N = aSize-1;\n\n  \n\n  for (size_t i = 0; i < aSize; i++) a[i] = i;\n\n  \n\n  for (size_t i = 0; i < zSize; i++) z[i] = rand() % N;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  Real_t *d_a = sycl::malloc_device<Real_t>(aSize, q);\n  q.memcpy(d_a, a, aSize * sizeof(Real_t));\n\n  Real_t *d_z = sycl::malloc_device<Real_t>(zSize, q);\n  q.memcpy(d_z, z, zSize * sizeof(Real_t));\n\n  size_t *d_r = sycl::malloc_device<size_t>(zSize, q);\n\n  bs(q, aSize, zSize, d_a, d_z, d_r, N, repeat);  \n\n#ifdef DEBUG\n  q.memcpy(r, d_r, zSize * sizeof(size_t)).wait();\n  verify(a, z, r, aSize, zSize, \"bs\");\n#endif\n\n  bs2(q, aSize, zSize, d_a, d_z, d_r, N, repeat);  \n\n#ifdef DEBUG\n  q.memcpy(r, d_r, zSize * sizeof(size_t)).wait();\n  verify(a, z, r, aSize, zSize, \"bs2\");\n#endif\n\n  bs3(q, aSize, zSize, d_a, d_z, d_r, N, repeat);  \n\n#ifdef DEBUG\n  q.memcpy(r, d_r, zSize * sizeof(size_t)).wait();\n  verify(a, z, r, aSize, zSize, \"bs3\");\n#endif\n\n  bs4(q, aSize, zSize, d_a, d_z, d_r, N, repeat);  \n\n#ifdef DEBUG\n  q.memcpy(r, d_r, zSize * sizeof(size_t)).wait();\n  verify(a, z, r, aSize, zSize, \"bs4\");\n#endif\n\n  sycl::free(d_a, q);\n  sycl::free(d_z, q);\n  sycl::free(d_r, q);\n  free(a);\n  free(z);\n  free(r);\n  return 0;\n}\n"}}
{"kernel_name": "colorwheel", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <cuda.h>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\n__host__ __device__\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\n__host__ __device__\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sqrtf(fx * fx + fy * fy);\n  float a = atan2f(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\n__global__\nvoid color (uchar* pix, int size, int half_size, float range, float truerange)\n{\n  int y = blockDim.y * blockIdx.y + threadIdx.y;\n  int x = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (y < size && x < size) {\n    float fx = (float)x / (float)half_size * range - range;\n    float fy = (float)y / (float)half_size * range - range;\n    if (x == half_size || y == half_size) return; \n\n    size_t idx = (y * size + x) * 3;\n    computeColor(fx/truerange, fy/truerange, pix+idx);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n  uchar *d_pix;\n  cudaMalloc((void**)&d_pix, imgSize);\n  cudaMemset(d_pix, 0, imgSize);\n\n  dim3 grids ((size+15)/16, (size+15)/16);\n  dim3 blocks (16, 16);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    color <<< grids, blocks >>> (d_pix, size, half_size, range, truerange);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(res, d_pix, imgSize, cudaMemcpyDeviceToHost);\n\n  \n\n  int fail = memcmp(pix, res, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(res[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  cudaFree(d_pix);\n  free(pix);\n  free(res);\n  return 0;\n}\n"}}
{"kernel_name": "colorwheel", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <hip/hip_runtime.h>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\n__host__ __device__\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\n__host__ __device__\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sqrtf(fx * fx + fy * fy);\n  float a = atan2f(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\n__global__\nvoid color (uchar* pix, int size, int half_size, float range, float truerange)\n{\n  int y = blockDim.y * blockIdx.y + threadIdx.y;\n  int x = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (y < size && x < size) {\n    float fx = (float)x / (float)half_size * range - range;\n    float fy = (float)y / (float)half_size * range - range;\n    if (x == half_size || y == half_size) return; \n\n    size_t idx = (y * size + x) * 3;\n    computeColor(fx/truerange, fy/truerange, pix+idx);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n  uchar *d_pix;\n  hipMalloc((void**)&d_pix, imgSize);\n  hipMemset(d_pix, 0, imgSize);\n\n  dim3 grids ((size+15)/16, (size+15)/16);\n  dim3 blocks (16, 16);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    color<<<grids, blocks>>>(d_pix, size, half_size, range, truerange);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(res, d_pix, imgSize, hipMemcpyDeviceToHost);\n\n  \n\n  int fail = memcmp(pix, res, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(res[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  hipFree(d_pix);\n  free(pix);\n  free(res);\n  return 0;\n}\n"}}
{"kernel_name": "colorwheel", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <omp.h>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sqrtf(fx * fx + fy * fy);\n  float a = atan2f(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n  uchar *d_pix = (uchar*) malloc(imgSize);\n  memset(d_pix, 0, imgSize);\n\n  #pragma omp target data map (tofrom: d_pix[0:imgSize])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      #pragma omp target teams distribute parallel for collapse(2)\n      for (int y = 0; y < size; y++) {\n        for (int x = 0; x < size; x++) {\n          float fx = (float)x / (float)half_size * range - range;\n          float fy = (float)y / (float)half_size * range - range;\n          if (x != half_size && y != half_size) {\n            size_t idx = (y * size + x) * 3;\n            computeColor(fx/truerange, fy/truerange, d_pix+idx);\n          }\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  \n\n  int fail = memcmp(pix, d_pix, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(d_pix[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  free(d_pix);\n  free(pix);\n  free(res);\n  return 0;\n}\n"}}
{"kernel_name": "colorwheel", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sqrtf(fx * fx + fy * fy);\n  float a = atan2f(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n  uchar *d_pix = (uchar*) malloc(imgSize);\n  memset(d_pix, 0, imgSize);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n            for (int y = 0; y < size; y++) {\n        for (int x = 0; x < size; x++) {\n          float fx = (float)x / (float)half_size * range - range;\n          float fy = (float)y / (float)half_size * range - range;\n          if (x != half_size && y != half_size) {\n            size_t idx = (y * size + x) * 3;\n            computeColor(fx/truerange, fy/truerange, d_pix+idx);\n          }\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  \n\n  int fail = memcmp(pix, d_pix, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(d_pix[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  free(d_pix);\n  free(pix);\n  free(res);\n  return 0;\n}"}}
{"kernel_name": "colorwheel", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <sycl/sycl.hpp>\n\n\n\n\n\n\n\n\n\n\n\n\n#define RY  15\n#define YG  6\n#define GC  4\n#define CB  11\n#define BM  13\n#define MR  6\n#define MAXCOLS  (RY + YG + GC + CB + BM + MR)\ntypedef unsigned char uchar;\n\nvoid setcols(int cw[MAXCOLS][3], int r, int g, int b, int k)\n{\n  cw[k][0] = r;\n  cw[k][1] = g;\n  cw[k][2] = b;\n}\n\nvoid computeColor(float fx, float fy, uchar *pix)\n{\n  int cw[MAXCOLS][3];  \n\n\n  \n\n  \n\n  \n\n  \n\n  int i;\n  int k = 0;\n  for (i = 0; i < RY; i++) setcols(cw, 255,     255*i/RY,   0,       k++);\n  for (i = 0; i < YG; i++) setcols(cw, 255-255*i/YG, 255,     0,     k++);\n  for (i = 0; i < GC; i++) setcols(cw, 0,       255,     255*i/GC,   k++);\n  for (i = 0; i < CB; i++) setcols(cw, 0,       255-255*i/CB, 255,   k++);\n  for (i = 0; i < BM; i++) setcols(cw, 255*i/BM,     0,     255,     k++);\n  for (i = 0; i < MR; i++) setcols(cw, 255,     0,     255-255*i/MR, k++);\n\n  float rad = sycl::sqrt(fx * fx + fy * fy);\n  float a = sycl::atan2(-fy, -fx) / (float)M_PI;\n  float fk = (a + 1.f) / 2.f * (MAXCOLS-1);\n  int k0 = (int)fk;\n  int k1 = (k0 + 1) % MAXCOLS;\n  float f = fk - k0;\n  for (int b = 0; b < 3; b++) {\n    float col0 = cw[k0][b] / 255.f;\n    float col1 = cw[k1][b] / 255.f;\n    float col = (1.f - f) * col0 + f * col1;\n    if (rad <= 1)\n      col = 1.f - rad * (1.f - col); \n\n    else\n      col *= .75f; \n\n    pix[2 - b] = (int)(255.f * col);\n  }\n}\n\nvoid color (sycl::nd_item<2> &item, uchar* pix, int size, int half_size, float range, float truerange)\n{\n  int y = item.get_global_id(0);\n  int x = item.get_global_id(1);\n\n  if (y < size && x < size) {\n    float fx = (float)x / (float)half_size * range - range;\n    float fy = (float)y / (float)half_size * range - range;\n    if (x == half_size || y == half_size) return; \n\n    size_t idx = (y * size + x) * 3;\n    computeColor(fx/truerange, fy/truerange, pix+idx);\n  }\n}\n\nint main(int argc, char **argv)\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <range> <size> <repeat>\\n\", argv[0]);\n    exit(1);\n  }\n  const float truerange = atof(argv[1]);\n  const int size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  \n\n  float range = 1.04f * truerange;\n\n  const int half_size = size/2;\n\n  \n\n  size_t imgSize = size * size * 3;\n  uchar* pix = (uchar*) malloc (imgSize);\n  uchar* res = (uchar*) malloc (imgSize);\n\n  memset(pix, 0, imgSize);\n\n  for (int y = 0; y < size; y++) {\n    for (int x = 0; x < size; x++) {\n      float fx = (float)x / (float)half_size * range - range;\n      float fy = (float)y / (float)half_size * range - range;\n      if (x == half_size || y == half_size) continue; \n\n      size_t idx = (y * size + x) * 3;\n      computeColor(fx/truerange, fy/truerange, pix+idx);\n    }\n  }\n\n  printf(\"Start execution on a device\\n\");\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  uchar *d_pix = sycl::malloc_device<uchar>(imgSize, q);\n  q.memset(d_pix, 0, imgSize);\n\n  sycl::range<2> gws ((size+15)/16*16, (size+15)/16*16);\n  sycl::range<2> lws (16, 16);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class cw>(sycl::nd_range<2>(gws, lws),\n        [=] (sycl::nd_item<2> item) {\n        color(item, d_pix, size, half_size, range, truerange);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time : %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(res, d_pix, imgSize).wait();\n\n  \n\n  int fail = memcmp(pix, res, imgSize);\n  if (fail) {\n    int max_error = 0;\n    for (size_t i = 0; i < imgSize; i++) {\n       int e = abs(res[i] - pix[i]);\n       if (e > max_error) max_error = e;\n    }\n    printf(\"Maximum error between host and device results: %d\\n\", max_error);\n  }\n  else {\n    printf(\"%s\\n\", \"PASS\");\n  }\n  \n  sycl::free(d_pix, q);\n  free(pix);\n  free(res);\n  return 0;\n}\n"}}
{"kernel_name": "coordinates", "parallel_api": "cuda", "code": {"main.cu": "#include <algorithm>\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <thrust/transform.h>\n#include <thrust/host_vector.h>\n#include <thrust/device_vector.h>\n#include \"utils.hpp\"\n\ntemplate <typename T>\nvoid coordinates_transform(const int num_coords, const int repeat)\n{\n  thrust::host_vector<lonlat_2d<T>> h_input (num_coords);\n  thrust::host_vector<cartesian_2d<T>> h_output (num_coords);\n  thrust::host_vector<cartesian_2d<T>> h_ref_output (num_coords);\n\n  lonlat_2d<T> h_origin;\n  h_origin.x = (T)90; \n\n  h_origin.y = (T)45;\n\n  \n\n  for (int i = 0; i < num_coords; i++) {\n    h_input[i].x = (T)(rand() % 360 - 180);\n    h_input[i].y = (T)(rand() % 180 - 90);\n  }\n\n  thrust::device_vector<lonlat_2d<T>> d_input = h_input;\n  thrust::device_vector<cartesian_2d<T>> d_output (num_coords);\n \n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    thrust::transform(d_input.cbegin(), d_input.cend(),\n                      d_output.begin(), to_cartesian_functor<T>(h_origin));\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of device transform: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  h_output = d_output;  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < 10; i++) {\n    std::transform(h_input.cbegin(), h_input.cend(),\n                   h_ref_output.begin(), to_cartesian_functor<T>(h_origin));\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of host transform: %f (us)\\n\", (time * 1e-3f) / 10);\n\n  bool ok = true;\n  for (int i = 0; i < num_coords; i++) {\n    if (!(h_output[i] == h_ref_output[i])) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of coordinates> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_coords = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  srand(123);\n\n  printf(\"\\nDouble-precision coordinates transform\\n\");\n  coordinates_transform<double>(num_coords, repeat);\n\n  printf(\"\\nSingle-precision coordinates transform\\n\");\n  coordinates_transform<float>(num_coords, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "coordinates", "parallel_api": "hip", "code": {"main.cu": "#include <algorithm>\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <thrust/transform.h>\n#include <thrust/host_vector.h>\n#include <thrust/device_vector.h>\n#include \"utils.hpp\"\n\ntemplate <typename T>\nvoid coordinates_transform(const int num_coords, const int repeat)\n{\n  thrust::host_vector<lonlat_2d<T>> h_input (num_coords);\n  thrust::host_vector<cartesian_2d<T>> h_output (num_coords);\n  thrust::host_vector<cartesian_2d<T>> h_ref_output (num_coords);\n\n  lonlat_2d<T> h_origin;\n  h_origin.x = (T)90; \n\n  h_origin.y = (T)45;\n\n  \n\n  for (int i = 0; i < num_coords; i++) {\n    h_input[i].x = (T)(rand() % 360 - 180);\n    h_input[i].y = (T)(rand() % 180 - 90);\n  }\n\n  thrust::device_vector<lonlat_2d<T>> d_input = h_input;\n  thrust::device_vector<cartesian_2d<T>> d_output (num_coords);\n \n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    thrust::transform(d_input.cbegin(), d_input.cend(),\n                      d_output.begin(), to_cartesian_functor<T>(h_origin));\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of device transform: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  h_output = d_output;  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < 10; i++) {\n    std::transform(h_input.cbegin(), h_input.cend(),\n                   h_ref_output.begin(), to_cartesian_functor<T>(h_origin));\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of host transform: %f (us)\\n\", (time * 1e-3f) / 10);\n\n  bool ok = true;\n  for (int i = 0; i < num_coords; i++) {\n    if (!(h_output[i] == h_ref_output[i])) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of coordinates> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_coords = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  srand(123);\n\n  printf(\"\\nDouble-precision coordinates transform\\n\");\n  coordinates_transform<double>(num_coords, repeat);\n\n  printf(\"\\nSingle-precision coordinates transform\\n\");\n  coordinates_transform<float>(num_coords, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "coordinates", "parallel_api": "sycl", "code": {"main.cpp": "#include <oneapi/dpl/algorithm>\n#include <oneapi/dpl/execution>\n#include <sycl/sycl.hpp>\n#include <algorithm>\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <vector>\n#include \"utils.hpp\"\n\ntemplate <typename T>\nvoid coordinates_transform(sycl::queue &q, const int num_coords, const int repeat)\n{\n  std::vector<lonlat_2d<T>> h_input (num_coords);\n  std::vector<cartesian_2d<T>> h_output (num_coords);\n  std::vector<cartesian_2d<T>> h_ref_output (num_coords);\n\n  lonlat_2d<T> h_origin;\n  h_origin.x = (T)90; \n\n  h_origin.y = (T)45;\n\n  \n\n  for (int i = 0; i < num_coords; i++) {\n    h_input[i].x = (T)(rand() % 360 - 180);\n    h_input[i].y = (T)(rand() % 180 - 90);\n  }\n\n  sycl::buffer<lonlat_2d<T>, 1> d_input (h_input.data(), num_coords);\n  sycl::buffer<cartesian_2d<T>, 1> d_output (num_coords);\n \n  auto policy = oneapi::dpl::execution::make_device_policy(q);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    std::transform(policy,\n      oneapi::dpl::begin(d_input),\n      oneapi::dpl::end(d_input),\n      oneapi::dpl::begin(d_output),\n      to_cartesian_functor<T>(h_origin));\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of device transform: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  q.submit([&] (sycl::handler &cgh) {\n    auto acc = d_output.template get_access<sycl::access::mode::read>(cgh);\n    cgh.copy(acc, h_output.data());\n  }).wait(); \n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < 10; i++) {\n    std::transform(h_input.cbegin(), h_input.cend(),\n                   h_ref_output.begin(), to_cartesian_functor<T>(h_origin));\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of host transform: %f (us)\\n\", (time * 1e-3f) / 10);\n\n  bool ok = true;\n  for (int i = 0; i < num_coords; i++) {\n    if (!(h_output[i] == h_ref_output[i])) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of coordinates> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_coords = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  srand(123);\n\n#ifdef USE_GPU\n  sycl::gpu_selector dev_sel;\n#else\n  sycl::cpu_selector dev_sel;\n#endif\n  sycl::queue q(dev_sel);\n\n  printf(\"\\nDouble-precision coordinates transform\\n\");\n  coordinates_transform<double>(q, num_coords, repeat);\n\n  printf(\"\\nSingle-precision coordinates transform\\n\");\n  coordinates_transform<float>(q, num_coords, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "dispatch", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <algorithm>\n#include <array>\n#include <chrono>\n#include <iostream>\n#include <cuda.h>\n\n#define NUM_GROUPS 1\n#define GROUP_SIZE 1\n#define WARMUP_RUN_COUNT 100\n#define TIMING_RUN_COUNT 1000\n#define TOTAL_RUN_COUNT WARMUP_RUN_COUNT + TIMING_RUN_COUNT\n#define BATCH_SIZE 1000\n\n__global__\nvoid EmptyKernel() { }\n\nvoid print_timing(std::string test, const std::array<float, TOTAL_RUN_COUNT> &results, int batch = 1)\n{\n  float total_us = 0.0f, mean_us = 0.0f, stddev_us = 0.0f;\n\n  \n\n  auto start_iter = std::next(results.begin(), WARMUP_RUN_COUNT);\n  auto end_iter = results.end();\n\n  \n\n  std::for_each(start_iter, end_iter, [&](const float &run_ms) {\n    total_us += (run_ms * 1000) / batch;\n  });\n  mean_us = total_us  / TIMING_RUN_COUNT;\n\n  \n\n  total_us = 0;\n  std::for_each(start_iter, end_iter, [&](const float &run_ms) {\n    float dev_us = ((run_ms * 1000) / batch) - mean_us;\n    total_us += dev_us * dev_us;\n  });\n  stddev_us = sqrt(total_us / TIMING_RUN_COUNT);\n\n  \n\n  printf(\"\\n %s: mean = %.1f us, stddev = %.1f us\\n\", test.c_str(), mean_us, stddev_us);\n}\n\nint main() {\n  std::array<float, TOTAL_RUN_COUNT> results;\n\n  \n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    EmptyKernel<<<dim3(NUM_GROUPS), dim3(GROUP_SIZE)>>>();\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Enqueue rate\", results);\n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    EmptyKernel<<<dim3(NUM_GROUPS), dim3(GROUP_SIZE)>>>();\n    cudaDeviceSynchronize();\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Single dispatch latency\", results);\n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    for (int j = 0; j < BATCH_SIZE; j++) {\n      EmptyKernel<<<dim3(NUM_GROUPS), dim3(GROUP_SIZE)>>>();\n    }\n    cudaDeviceSynchronize();\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Batch dispatch latency\", results, BATCH_SIZE);\n\n  return 0;\n}\n"}}
{"kernel_name": "dispatch", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <algorithm>\n#include <array>\n#include <chrono>\n#include <iostream>\n#include <hip/hip_runtime.h>\n\n#define NUM_GROUPS 1\n#define GROUP_SIZE 1\n#define WARMUP_RUN_COUNT 100\n#define TIMING_RUN_COUNT 1000\n#define TOTAL_RUN_COUNT WARMUP_RUN_COUNT + TIMING_RUN_COUNT\n#define BATCH_SIZE 1000\n\n__global__\nvoid EmptyKernel() { }\n\nvoid print_timing(std::string test, const std::array<float, TOTAL_RUN_COUNT> &results, int batch = 1)\n{\n  float total_us = 0.0f, mean_us = 0.0f, stddev_us = 0.0f;\n\n  \n\n  auto start_iter = std::next(results.begin(), WARMUP_RUN_COUNT);\n  auto end_iter = results.end();\n\n  \n\n  std::for_each(start_iter, end_iter, [&](const float &run_ms) {\n    total_us += (run_ms * 1000) / batch;\n  });\n  mean_us = total_us  / TIMING_RUN_COUNT;\n\n  \n\n  total_us = 0;\n  std::for_each(start_iter, end_iter, [&](const float &run_ms) {\n    float dev_us = ((run_ms * 1000) / batch) - mean_us;\n    total_us += dev_us * dev_us;\n  });\n  stddev_us = sqrt(total_us / TIMING_RUN_COUNT);\n\n  \n\n  printf(\"\\n %s: mean = %.1f us, stddev = %.1f us\\n\", test.c_str(), mean_us, stddev_us);\n}\n\nint main() {\n  std::array<float, TOTAL_RUN_COUNT> results;\n\n  \n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    hipLaunchKernelGGL((EmptyKernel), dim3(NUM_GROUPS), dim3(GROUP_SIZE), 0, 0);\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Enqueue rate\", results);\n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    hipLaunchKernelGGL((EmptyKernel), dim3(NUM_GROUPS), dim3(GROUP_SIZE), 0, 0);\n    hipDeviceSynchronize();\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Single dispatch latency\", results);\n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    for (int j = 0; j < BATCH_SIZE; j++) {\n      hipLaunchKernelGGL((EmptyKernel), dim3(NUM_GROUPS), dim3(GROUP_SIZE), 0, 0);\n    }\n    hipDeviceSynchronize();\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Batch dispatch latency\", results, BATCH_SIZE);\n\n  return 0;\n}\n"}}
{"kernel_name": "dispatch", "parallel_api": "sycl", "code": {"main.cpp": "\n\n#include <algorithm>\n#include <array>\n#include <chrono>\n#include <cmath>\n#include <iostream>\n#include <sycl/sycl.hpp>\n\n#define NUM_GROUPS 1\n#define GROUP_SIZE 1\n#define WARMUP_RUN_COUNT 100\n#define TIMING_RUN_COUNT 1000\n#define TOTAL_RUN_COUNT WARMUP_RUN_COUNT + TIMING_RUN_COUNT\n#define BATCH_SIZE 1000\n\n\nvoid print_timing(std::string test, const std::array<float, TOTAL_RUN_COUNT> &results, int batch = 1)\n{\n  float total_us = 0.0f, mean_us = 0.0f, stddev_us = 0.0f;\n\n  \n\n  auto start_iter = std::next(results.begin(), WARMUP_RUN_COUNT);\n  auto end_iter = results.end();\n\n  \n\n  std::for_each(start_iter, end_iter, [&](const float &run_ms) {\n    total_us += (run_ms * 1000) / batch;\n  });\n  mean_us = total_us  / TIMING_RUN_COUNT;\n\n  \n\n  total_us = 0;\n  std::for_each(start_iter, end_iter, [&](const float &run_ms) {\n    float dev_us = ((run_ms * 1000) / batch) - mean_us;\n    total_us += dev_us * dev_us;\n  });\n  stddev_us = sqrt(total_us / TIMING_RUN_COUNT);\n\n  \n\n  printf(\"\\n %s: mean = %.1f us, stddev = %.1f us\\n\", test.c_str(), mean_us, stddev_us);\n}\n\nint main() {\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  std::array<float, TOTAL_RUN_COUNT> results;\n\n  sycl::range<1> gws (NUM_GROUPS * GROUP_SIZE);\n  sycl::range<1> lws (GROUP_SIZE);\n\n  \n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      });\n    });\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Enqueue rate\", results);\n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      });\n    }).wait();\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Single dispatch latency\", results);\n\n  \n\n  \n\n  \n\n  for (auto i = 0; i < TOTAL_RUN_COUNT; ++i) {\n    auto start = std::chrono::high_resolution_clock::now();\n    for (int j = 0; j < BATCH_SIZE; j++) {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        });\n      });\n    }\n    q.wait();\n    auto stop = std::chrono::high_resolution_clock::now();\n    results[i] = std::chrono::duration<float, std::milli>(stop - start).count();\n  }\n  print_timing(\"Batch dispatch latency\", results, BATCH_SIZE);\n\n  return 0;\n}\n"}}
{"kernel_name": "eikonal", "parallel_api": "hip", "code": {"StructuredEikonal.cu": "#include \"StructuredEikonal.h\"\n\nStructuredEikonal::StructuredEikonal(bool verbose) \n:verbose_(verbose), isGpuMemCreated_(false),\nwidth_(256), height_(256), depth_(256),\nitersPerBlock_(10), solverType_(0) {}\n\nStructuredEikonal::~StructuredEikonal() {}\n\nvoid StructuredEikonal::writeNRRD(std::string filename) {\n  std::fstream out(filename.c_str(), std::ios::out | std::ios::binary);\n  out << \"NRRD0001\\n\";\n  out << \"# Complete NRRD file format specification at:\\n\";\n  out << \"# http:\n\n  out << \"type: double\\n\";\n  out << \"dimension: 3\\n\";\n  out << \"sizes: \" << this->width_ << \" \" << this->height_ << \" \" << this->depth_ << \"\\n\";\n  out << \"endian: little\\n\";\n  out << \"encoding: raw\\n\\n\";\n  double checksum = 0.0;\n  for(size_t k = 0; k < this->depth_; k++) {\n    for(size_t j = 0; j < this->height_; j++) {\n      for(size_t i = 0; i < this->width_; i++) {\n        double d = this->answer_[i][j][k];\n        checksum += d;\n        out.write(reinterpret_cast<const char*>(&d),sizeof(double));\n      }\n    }\n  }\n  out.close();\n  printf(\"Checksum = %lf\\n\", checksum / (this->depth_ * this->height_ * this->width_));\n}\n\nvoid StructuredEikonal::setDims(size_t x, size_t y, size_t z) {\n  this->width_ = x;\n  this->height_ = y;\n  this->depth_ = z;\n}\n\nvoid StructuredEikonal::error(char* msg) {\n  printf(\"%s\\n\",msg);\n  assert(false);\n  exit(0);\n}\n\nvoid StructuredEikonal::init_device_mem() {\n  assert(this->width_ > 0 && this->height_ > 0 && this->depth_ > 0);\n  if(this->width_ <= 0 || this->height_ <= 0 || this->depth_ <= 0){ \n    printf(\"Volume dimension cannot be zero\");\n    exit(1);\n  }\n\n  \n\n  size_t nx, ny, nz;\n\n  nx = this->width_ + (BLOCK_LENGTH-this->width_%BLOCK_LENGTH)%BLOCK_LENGTH;\n  ny = this->height_ + (BLOCK_LENGTH-this->height_%BLOCK_LENGTH)%BLOCK_LENGTH;\n  nz = this->depth_ + (BLOCK_LENGTH-this->depth_%BLOCK_LENGTH)%BLOCK_LENGTH;\n  if (this->verbose_) {\n    printf(\"%zu %zu %zu\\n\",nx,ny,nz);\n  }\n\n  auto volSize = nx*ny*nz;\n  auto blkSize = BLOCK_LENGTH*BLOCK_LENGTH*BLOCK_LENGTH;\n\n  auto nBlkX = nx / BLOCK_LENGTH;\n  auto nBlkY = ny / BLOCK_LENGTH;\n  auto nBlkZ = nz / BLOCK_LENGTH;\n  auto blockNum = nBlkX*nBlkY*nBlkZ;\n\n  this->memoryStruct_.xdim = static_cast<int>(nx);\n  this->memoryStruct_.ydim = static_cast<int>(ny);\n  this->memoryStruct_.zdim = static_cast<int>(nz);\n  this->memoryStruct_.volsize = static_cast<uint>(volSize);\n  this->memoryStruct_.blksize = static_cast<uint>(blkSize);\n  this->memoryStruct_.blklength = BLOCK_LENGTH;\n  this->memoryStruct_.blknum = static_cast<uint>(blockNum);\n  this->memoryStruct_.nIter = static_cast<int>(this->itersPerBlock_); \n\n\n  if(this->isGpuMemCreated_) \n\n  {\n    free((DOUBLE*)this->memoryStruct_.h_sol);\n    free((uint*)this->memoryStruct_.h_list);\n    free((bool*)this->memoryStruct_.h_listed);\n    free((bool*)this->memoryStruct_.h_listVol);\n    free((int*)this->memoryStruct_.blockOrder);\n    hipFree(this->memoryStruct_.d_spd);\n    hipFree(this->memoryStruct_.d_sol);\n    hipFree(this->memoryStruct_.t_sol);  \n\n    hipFree(this->memoryStruct_.d_con);  \n\n    hipFree(this->memoryStruct_.d_list);\n    hipFree(this->memoryStruct_.d_listVol);\n    hipFree(this->memoryStruct_.d_mask);\n  }\n  this->isGpuMemCreated_ = true;\n\n  this->memoryStruct_.h_sol = (DOUBLE*) malloc(volSize*sizeof(DOUBLE)); \n\n  this->memoryStruct_.h_list = (uint*) malloc(blockNum*sizeof(uint)); \n\n  this->memoryStruct_.h_listed = (bool*) malloc(blockNum*sizeof(bool));  \n\n  this->memoryStruct_.h_listVol = (bool*) malloc(blockNum*sizeof(bool)); \n\n  this->memoryStruct_.blockOrder = (int*) malloc(blockNum*sizeof(int));\n\n  \n\n  \n\n  \n\n  hipMalloc((void**)&(this->memoryStruct_.d_spd), volSize*sizeof(double));\n\n  hipMalloc((void**)&(this->memoryStruct_.d_sol), volSize*sizeof(DOUBLE));\n\n  hipMalloc((void**)&(this->memoryStruct_.t_sol), volSize*sizeof(DOUBLE));  \n\n\n  hipMalloc((void**)&(this->memoryStruct_.d_con), volSize*sizeof(bool));  \n\n\n  hipMalloc((void**)&(this->memoryStruct_.d_list), blockNum*sizeof(uint));\n\n  hipMalloc((void**)&(this->memoryStruct_.d_listVol), blockNum*sizeof(bool));\n\n  hipMalloc((void**)&(this->memoryStruct_.d_mask), volSize*sizeof(bool));\n}\n\nvoid StructuredEikonal::set_attribute_mask() {\n  uint volSize = this->memoryStruct_.volsize;\n\n  int nx, ny, nz, blklength;\n\n  nx = memoryStruct_.xdim;\n  ny = memoryStruct_.ydim;\n  nz = memoryStruct_.zdim;\n  blklength = memoryStruct_.blklength;\n\n  \n\n  double *h_spd  = new double[volSize]; \n\n  bool  *h_mask = new bool[volSize];\n\n  \n\n  \n\n  uint idx = 0;\n  for(int zStr = 0; zStr < nz; zStr += blklength) {\n    for(int yStr = 0; yStr < ny; yStr += blklength) {\n      for(int xStr = 0; xStr < nx; xStr += blklength) {\n        \n\n        for(int z=zStr; z<zStr+blklength; z++) {\n          for(int y=yStr; y<yStr+blklength; y++) {\n            for(int x=xStr; x<xStr+blklength; x++) {\n              h_spd[idx] = this->speeds_[x][y][z];\n              h_mask[idx] = true;\n              idx++;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  \n\n  hipMemcpy(memoryStruct_.d_spd, h_spd, volSize*sizeof(double), hipMemcpyHostToDevice);\n  hipMemcpy(memoryStruct_.d_mask, h_mask, volSize*sizeof(bool), hipMemcpyHostToDevice);\n\n  delete[] h_spd;\n  delete[] h_mask;\n}\n\nvoid StructuredEikonal::initialization() {\n  this->init_device_mem();\n  this->set_attribute_mask();\n}\n\nvoid StructuredEikonal::map_generator() {\n  double pi = 3.141592653589793238462643383;\n  this->speeds_ = std::vector<std::vector<std::vector<double> > >(\n    this->width_, std::vector<std::vector<double> >(\n    this->height_, std::vector<double>(this->depth_,1.)));\n  switch(this->solverType_){\n  case 0 :\n    \n\n    break;\n  case 1 :\n    \n\n    for (size_t k = 0 ; k < this->depth_ ; ++k) {\n      for (size_t j = 0 ; j < this->height_; ++j) {\n        for ( size_t i = 0 ; i < this->width_ ; ++i) {\n          this->speeds_[i][j][k] =\n            (6 + 5*(sin((i*pi)/this->width_ *2))*\n            sin((j*pi)/this->height_*2)*\n            sin((k*pi)/this->depth_*2));\n        }\n      }\n    }\n    break;\n  }\n}\n\nvoid StructuredEikonal::setSeeds(std::vector<std::array<size_t, 3> > seeds) {\n  this->seeds_ = seeds;\n}\n\nvoid StructuredEikonal::useSeeds() {\n  if (this->verbose_) {\n    std::cout << \"Loading seed volume...\" << std::endl;\n  }\n  uint volSize, blockNum;\n  int nx, ny, nz, blklength;\n\n  nx = this->memoryStruct_.xdim;\n  ny = this->memoryStruct_.ydim;\n  nz = this->memoryStruct_.zdim;\n  volSize = this->memoryStruct_.volsize;\n  blklength = this->memoryStruct_.blklength;\n  blockNum = this->memoryStruct_.blknum;\n\n  \n\n  \n\n  uint idx = 0;\n  uint blk_idx = 0;\n  uint list_idx = 0;\n  uint nActiveBlock = 0;\n\n  for(int zStr = 0; zStr < nz; zStr += blklength) {\n    for(int yStr = 0; yStr < ny; yStr += blklength) {\n      for(int xStr = 0; xStr < nx; xStr += blklength) {\n        \n\n        bool isSeedBlock = false;\n\n        for(int z=zStr; z<zStr+blklength; z++) {\n          for(int y=yStr; y<yStr+blklength; y++) {\n            for(int x=xStr; x<xStr+blklength; x++) {\n              this->memoryStruct_.h_sol[idx] = INF;\n              if (this->seeds_.empty()) {\n                if (x == nx/2 && y == ny/2 && z == nz/2) {\n                  this->memoryStruct_.h_sol[idx] = 0;\n                  isSeedBlock = true;\n                  if (this->verbose_) {\n                    printf(\"%d is Selected bt source \\n\",idx);\n                  }\n                }\n              } else {\n                for(size_t i = 0; i < this->seeds_.size(); i++) {\n                  if (this->seeds_[i][0] == (size_t)x && \n                      this->seeds_[i][1] == (size_t)y && \n                      this->seeds_[i][2] == (size_t)z) {\n                    this->memoryStruct_.h_sol[idx] = 0;\n                    isSeedBlock = true;\n                    if (this->verbose_) {\n                      printf(\"%d is Selected bt source \\n\",idx);\n                    }\n                  }\n                }\n              }\n              idx++;\n            }\n          }\n        }\n        \n\n        if(isSeedBlock) {\n          if (this->verbose_) {\n            printf(\"%d,%d,%d is Seed Block \\n\",zStr,yStr,xStr);\n          }\n          this->memoryStruct_.h_listVol[blk_idx] = true;\n          this->memoryStruct_.h_listed[blk_idx] = true;\n          this->memoryStruct_.h_list[list_idx] = blk_idx;\n          list_idx++;\n          nActiveBlock++;\n        } else {\n          this->memoryStruct_.h_listVol[blk_idx] = false;\n          this->memoryStruct_.h_listed[blk_idx] = false;\n        }\n        blk_idx++;\n      }\n    }\n  }\n  this->memoryStruct_.nActiveBlock = nActiveBlock;\n  \n\n  hipMemcpy(this->memoryStruct_.d_sol, this->memoryStruct_.h_sol, volSize*sizeof(DOUBLE), hipMemcpyHostToDevice);\n  hipMemcpy(this->memoryStruct_.t_sol, this->memoryStruct_.h_sol, volSize*sizeof(DOUBLE), hipMemcpyHostToDevice);\n  hipMemcpy(this->memoryStruct_.d_list, this->memoryStruct_.h_list, nActiveBlock*sizeof(uint), hipMemcpyHostToDevice);\n  hipMemcpy(this->memoryStruct_.d_listVol, this->memoryStruct_.h_listVol, blockNum*sizeof(bool), hipMemcpyHostToDevice);\n  \n\n  hipMemset(this->memoryStruct_.d_con, 1, volSize*sizeof(bool));\n}\n\nvoid StructuredEikonal::setMapType(size_t t) {\n    this->solverType_ = t;\n  }\n\nvoid StructuredEikonal::solveEikonal() {\n  if (this->speeds_.empty()) {\n    this->map_generator();\n  }\n  this->isGpuMemCreated_ = false;\n  this->initialization();\n  this->useSeeds();\n  runEikonalSolverSimple(this->memoryStruct_);\n  this->get_solution();\n}\n\nstd::vector< std::vector< std::vector<double> > > \n  StructuredEikonal::getFinalResult() {\n    return this->answer_;\n  }\n\nvoid StructuredEikonal::get_solution() {\n  \n\n  hipMemcpy(this->memoryStruct_.h_sol,\n    this->memoryStruct_.d_sol, this->memoryStruct_.volsize*sizeof(DOUBLE), \n    hipMemcpyDeviceToHost);\n  \n\n  this->answer_ = std::vector<std::vector<std::vector<double> > >(\n    this->width_, std::vector<std::vector<double> >( \n    this->height_, std::vector<double>(this->depth_,0)));\n  for(size_t blockID = 0; blockID < this->memoryStruct_.blknum; blockID++) {\n    size_t baseAddr = blockID * this->memoryStruct_.blksize;\n\t\tsize_t xgridlength = this->memoryStruct_.xdim/BLOCK_LENGTH;\n\t\tsize_t ygridlength = this->memoryStruct_.ydim/BLOCK_LENGTH;\n\t\t\n\n\t\tsize_t bx = blockID%xgridlength;\n\t\tsize_t tmpIdx = (blockID - bx)/xgridlength;\n\t\tsize_t by = tmpIdx%ygridlength;\n\t\tsize_t bz = (tmpIdx-by)/ygridlength;\n    \n\n    for(int k = 0; k < BLOCK_LENGTH; k++) {\n      for(int j = 0; j < BLOCK_LENGTH; j++) {\n        for(int i = 0; i < BLOCK_LENGTH; i++) {\n          double d = this->memoryStruct_.h_sol[baseAddr + \n            k * BLOCK_LENGTH * BLOCK_LENGTH + \n            j * BLOCK_LENGTH + i];\n          if ((i + bx * BLOCK_LENGTH) < this->width_ && \n            (j + by * BLOCK_LENGTH) < this->height_ &&\n            (k + bz * BLOCK_LENGTH) < this->depth_) {\n            this->answer_[(i + bx * BLOCK_LENGTH)][(j +\n              by * BLOCK_LENGTH)][k + bz * BLOCK_LENGTH] = d;\n          }\n        }\n      }\n    }\n  }\n}\n\nvoid StructuredEikonal::setItersPerBlock(size_t t) {\n  this->itersPerBlock_ = t;\n}\n", "fim.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <cstdio>\n#include <string>\n#include <cmath>\n#include <float.h>\n#include <vector>\n#include <iostream>\n#include \"kernel.h\"\n#include \"fim.h\"\n\nvoid runEikonalSolverSimple(GPUMEMSTRUCT &cmem)\n{\n  int xdim, ydim, zdim;\n  xdim = cmem.xdim;\n  ydim = cmem.ydim;\n  zdim = cmem.zdim;\n\n  \n\n  uint volSize = cmem.volsize;\n  uint blockNum = cmem.blknum;\n\n  printf(\"# of total voxels : %d\\n\", volSize);\n  printf(\"# of total blocks : %d\\n\", blockNum);\n\n  \n\n\n  \n\n  int nIter = cmem.nIter;\n  uint nActiveBlock = cmem.nActiveBlock; \n\n\n  double *d_spd = cmem.d_spd;\n  DOUBLE *d_sol = cmem.d_sol;\n  DOUBLE *t_sol = cmem.t_sol;\n\n  uint *d_list = cmem.d_list;\n  bool *d_listVol = cmem.d_listVol;\n\n  bool *d_con = cmem.d_con;\n  bool *d_mask = cmem.d_mask;\n\n  \n\n  uint *h_list = (uint*) malloc(blockNum*sizeof(uint));\n  bool *h_listed = (bool*) malloc(blockNum*sizeof(bool));\n  bool *h_listVol = (bool*) malloc(blockNum*sizeof(bool));\n\n  \n\n  memcpy(h_list, cmem.h_list, blockNum*sizeof(uint));\n  memcpy(h_listed, cmem.h_listed, blockNum*sizeof(bool));\n  memcpy(h_listVol, cmem.h_listVol, blockNum*sizeof(bool));\n\n  hipMemcpy(cmem.d_list, cmem.h_list, nActiveBlock*sizeof(uint), hipMemcpyHostToDevice);\n  hipMemcpy(cmem.d_listVol, cmem.h_listVol, blockNum*sizeof(bool), hipMemcpyHostToDevice);\n  hipMemcpy(cmem.d_sol, cmem.h_sol, volSize*sizeof(DOUBLE), hipMemcpyHostToDevice);\n  hipMemcpy(cmem.t_sol, cmem.h_sol, volSize*sizeof(DOUBLE), hipMemcpyHostToDevice);\n  hipMemset(cmem.d_con, 1, volSize*sizeof(bool));\n\n  \n\n  dim3 dimBlock(BLOCK_LENGTH,BLOCK_LENGTH,BLOCK_LENGTH);\n  dim3 dimGrid(nActiveBlock);\n\n  int nTotalIter = 0;\n  \n\n\n  std::vector<int> sourceList;\n  sourceList.push_back((zdim/2)*ydim*xdim + (ydim/2)*xdim + (xdim/2));\n\n#ifdef TIMER\n  \n\n  StopWatchInterface *timer_total, *timer_solver, *timer_reduction, *timer_list, *timer_list2, *timer_coarse;\n  timer_total = timer_solver = timer_reduction = timer_list = timer_list2 = timer_coarse = NULL;\n\n  sdkCreateTimer(&timer_total);\n  sdkCreateTimer(&timer_solver);\n  sdkCreateTimer(&timer_reduction);\n  sdkCreateTimer(&timer_list);\n  sdkCreateTimer(&timer_list2);\n  sdkCreateTimer(&timer_coarse);\n  sdkStartTimer(&timer_total);\n#endif\n\n  uint nTotalBlockProcessed = 0;\n\n  \n\n  while(nActiveBlock > 0)\n  {\n    assert(nActiveBlock < 4294967295);\n\n    nTotalBlockProcessed += nActiveBlock;\n\n    nTotalIter++;\n\n    \n\n    \n\n    \n\n\n#ifdef DEBUG\n      printf(\"# of active tiles : %u\\n\", nActiveBlock);\n#endif\n\n    \n\n    \n\n\n#ifdef TIMER\n    sdkStartTimer(&timer_solver);\n#endif\n\n    dimGrid.y = (unsigned int)floor(((double)nActiveBlock-1)/65535)+1;\n    dimGrid.x = (unsigned int)ceil ((double)nActiveBlock/(double)dimGrid.y);\n\n#ifdef DEBUG\n      printf(\"Grid size : %d x %d\\n\", dimGrid.x, dimGrid.y);\n#endif\n\n    hipMemcpy(d_list, h_list, nActiveBlock*sizeof(uint), hipMemcpyHostToDevice);\n\n    hipLaunchKernelGGL(run_solver, dimGrid, dimBlock , 0, 0, d_spd, d_mask, d_sol, t_sol, d_con, d_list, xdim, ydim, zdim, nIter, nActiveBlock);\n\n#ifdef TIMER\n    hipDeviceSynchronize();\n    sdkStopTimer(&timer_solver);\n#endif\n\n    \n\n    \n\n\n#ifdef TIMER\n    sdkStartTimer(&timer_reduction);\n#endif\n\n    hipLaunchKernelGGL(run_reduction, dimGrid, dim3(BLOCK_LENGTH,BLOCK_LENGTH,BLOCK_LENGTH/2), 0, 0, d_con, d_listVol, d_list, nActiveBlock);\n\n#ifdef TIMER\n    hipDeviceSynchronize();\n    sdkStopTimer(&timer_reduction);\n#endif\n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n#ifdef TIMER\n    sdkStartTimer(&timer_list);\n#endif\n\n    hipMemcpy(h_listVol, d_listVol, blockNum*sizeof(bool), hipMemcpyDeviceToHost);\n\n    uint nOldActiveBlock = nActiveBlock;\n    uint nBlkX = xdim/BLOCK_LENGTH;\n    uint nBlkY = ydim/BLOCK_LENGTH;\n\n    for(uint i=0; i<nOldActiveBlock; i++)\n    {\n      \n\n      uint currBlkIdx = h_list[i];\n\n      if(!h_listVol[currBlkIdx]) \n\n      {\n        uint nb[6];\n        nb[0] = (currBlkIdx < nBlkX*nBlkY) ? currBlkIdx : (currBlkIdx - nBlkX*nBlkY);  \n\n        nb[1] = ((currBlkIdx + nBlkX*nBlkY) >= blockNum) ? currBlkIdx : (currBlkIdx + nBlkX*nBlkY); \n\n        nb[2] = (currBlkIdx < nBlkX) ? currBlkIdx : (currBlkIdx - nBlkX); \n\n        nb[3] = ((currBlkIdx + nBlkX) >= blockNum) ? currBlkIdx : (currBlkIdx + nBlkX); \n\n        nb[4] = (currBlkIdx%nBlkX == 0) ? currBlkIdx : currBlkIdx-1; \n\n        nb[5] = ((currBlkIdx+1)%nBlkX == 0) ? currBlkIdx : currBlkIdx+1; \n\n\n        for(int nbIdx = 0; nbIdx < 6; nbIdx++)\n        {\n          uint currIdx = nb[nbIdx];\n\n          \n\n\n          if(!h_listed[currIdx])\n          {\n            h_listed[currIdx] = true;\n            h_list[nActiveBlock++] = currIdx;\n          }\n        }\n      }\n    }\n\n#ifdef TIMER\n    hipDeviceSynchronize();\n    sdkStopTimer(&timer_list);\n#endif\n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n#ifdef TIMER\n    sdkStartTimer(&timer_solver);\n#endif\n\n    \n\n    dimGrid.y = (unsigned int)floor(((double)nActiveBlock-1)/65535)+1;\n    dimGrid.x = (unsigned int)ceil((double)nActiveBlock/(double)dimGrid.y);\n\n#ifdef DEBUG\n      printf(\"Grid size : %d x %d\\n\", dimGrid.x, dimGrid.y);\n#endif\n\n    hipMemcpy(d_list, h_list, nActiveBlock*sizeof(uint), hipMemcpyHostToDevice);\n\n    hipLaunchKernelGGL(run_check_neighbor, dimGrid, dimBlock , 0, 0, d_spd, d_mask, t_sol, d_sol, d_con, d_list, xdim, ydim, zdim, nOldActiveBlock, nActiveBlock);\n\n#ifdef TIMER\n    hipDeviceSynchronize();\n    sdkStopTimer(&timer_solver);\n#endif\n\n    \n\n    \n\n\n#ifdef TIMER\n    sdkStartTimer(&timer_reduction);\n#endif\n\n    hipLaunchKernelGGL(run_reduction, dimGrid, dim3(BLOCK_LENGTH,BLOCK_LENGTH,BLOCK_LENGTH/2), 0, 0, d_con, d_listVol, d_list, nActiveBlock);\n\n#ifdef TIMER\n    hipDeviceSynchronize();\n    sdkStopTimer(&timer_reduction);\n#endif\n\n    \n\n    \n\n    \n\n    \n\n\n#ifdef TIMER\n    sdkStartTimer(&timer_list2);\n#endif\n\n    nActiveBlock = 0;\n    hipMemcpy(h_listVol, d_listVol, blockNum*sizeof(bool), hipMemcpyDeviceToHost);\n\n    for(uint i=0; i<blockNum; i++)\n    {\n      if(h_listVol[i]) \n\n      {\n        h_listed[i] = true;\n        h_list[nActiveBlock++] = i;\n        \n\n      }\n      else h_listed[i] = false;\n    }\n\n#ifdef TIMER\n    hipDeviceSynchronize();\n    sdkStopTimer(&timer_list2);\n#endif\n\n#ifdef DEBUG\n      printf(\"Iteration : %d\\n\", nTotalIter);\n#endif\n  }\n\n#ifdef TIMER\n  sdkStopTimer(&timer_total);\n#endif\n\n  printf(\"Eikonal solver converged after %d iterations\\n\", nTotalIter);\n\n#ifdef TIMER\n  printf(\"Total Running Time: %f (sec)\\n\", sdkGetTimerValue(&timer_total) / 1000);\n  printf(\"Time for solver : %f (sec)\\n\", sdkGetTimerValue(&timer_solver) / 1000);\n  printf(\"Time for reduction : %f (sec)\\n\", sdkGetTimerValue(&timer_reduction) / 1000);\n  printf(\"Time for list update-1 (CPU) : %f (sec)\\n\", sdkGetTimerValue(&timer_list) / 1000);\n  printf(\"Time for list update-2 (CPU) : %f (sec)\\n\", sdkGetTimerValue(&timer_list2) / 1000);\n#endif\n\n  printf(\"Total # of blocks processed : %d\\n\", nTotalBlockProcessed);\n\n\n  \n\n  free(h_list);\n  free(h_listed);\n  free(h_listVol);\n}\n", "kernel.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include \"kernel.h\"\n\n__device__ DOUBLE get_time_eikonal(DOUBLE a, DOUBLE b, DOUBLE c, DOUBLE s)\n{\n  DOUBLE ret, tmp;\n\n  \n\n  if(a < b) { tmp = a; a = b; b = tmp; }\n  if(b < c) { tmp = b; b = c; c = tmp; }\n  if(a < b) { tmp = a; a = b; b = tmp; }\n\n  ret = INF;\n\n  if(c < INF)\n  {\n    ret = c + s;\n\n    if(ret > b) \n    {  \n      tmp = ((b+c) + sqrtf(2.0f*s*s-(b-c)*(b-c)))*0.5f;\n\n      if(tmp > b) ret = tmp; \n\n      if(ret > a)  {      \n        tmp = (a+b+c)/3.0f + sqrtf(2.0f*(a*(b-a)+b*(c-b)+c*(a-c))+3.0f*s*s)/3.0f; \n\n        if(tmp > a) ret = tmp;\n      }\n    }\n  }\n\n  return ret;\n}\n\n__global__ void run_solver(\n  const double*__restrict__ spd,\n  const bool*__restrict__ mask,\n  const DOUBLE *__restrict__ sol_in,\n  DOUBLE *__restrict__ sol_out,\n  bool *__restrict__ con,\n  const uint*__restrict__ list,\n  int xdim, int ydim, int zdim,\n  int nIter, uint nActiveBlock)\n{\n  uint list_idx = blockIdx.y*gridDim.x + blockIdx.x;\n\n  if(list_idx < nActiveBlock)\n  {\n    \n\n    uint block_idx = list[list_idx];\n\n    double F;\n    bool isValid;\n    uint blocksize = BLOCK_LENGTH*BLOCK_LENGTH*BLOCK_LENGTH;\n    uint base_addr = block_idx*blocksize;\n\n    uint xgridlength = xdim/BLOCK_LENGTH;\n    uint ygridlength = ydim/BLOCK_LENGTH;\n    uint zgridlength = zdim/BLOCK_LENGTH;\n\n    \n\n    uint bx = block_idx%xgridlength;\n    uint tmpIdx = (block_idx - bx)/xgridlength;\n    uint by = tmpIdx%ygridlength;\n    uint bz = (tmpIdx-by)/ygridlength;\n\n    uint tx = threadIdx.x;\n    uint ty = threadIdx.y;\n    uint tz = threadIdx.z;\n    uint tIdx = tz*BLOCK_LENGTH*BLOCK_LENGTH + ty*BLOCK_LENGTH + tx;\n\n    __shared__ DOUBLE _sol[BLOCK_LENGTH+2][BLOCK_LENGTH+2][BLOCK_LENGTH+2];\n\n    \n\n    dim3 idx(tx+1,ty+1,tz+1);\n\n    SOL(idx.x,idx.y,idx.z) = sol_in[base_addr + tIdx];\n    F = spd[base_addr + tIdx];\n    if(F > 0) F = 1.0/F; \n\n    isValid = mask[base_addr + tIdx];\n\n    uint new_base_addr, new_tIdx;\n\n    \n\n    if(tx == 0) \n    {\n      if(bx == 0) \n\n      {  \n        new_tIdx = tIdx;\n        new_base_addr = base_addr;\n      }\n      else\n      {\n        new_tIdx = tIdx + BLOCK_LENGTH-1;\n        new_base_addr = (block_idx - 1)*blocksize;  \n      }\n\n      SOL(tx,idx.y,idx.z) = sol_in[new_base_addr + new_tIdx];  \n    }\n\n    if(tx == BLOCK_LENGTH-1)\n    {\n      if(bx == xgridlength-1) \n\n      {\n        new_tIdx = tIdx;\n        new_base_addr = base_addr;\n      }\n      else\n      {\n        new_tIdx = tIdx - (BLOCK_LENGTH-1);\n        new_base_addr = (block_idx + 1)*blocksize;  \n      }\n      SOL(tx+2,idx.y,idx.z) = sol_in[new_base_addr + new_tIdx];  \n    }\n\n    if(ty == 0)\n    {\n      if(by == 0)\n      {\n        new_tIdx = tIdx;\n        new_base_addr = base_addr;\n      }\n      else\n      {\n        new_tIdx = tIdx + (BLOCK_LENGTH-1)*BLOCK_LENGTH;\n        new_base_addr = (block_idx - xgridlength)*blocksize;\n      }\n\n      SOL(idx.x,ty,idx.z) = sol_in[new_base_addr + new_tIdx];\n    }\n\n    if(ty == BLOCK_LENGTH-1)\n    {\n      if(by == ygridlength-1) \n      {\n        new_tIdx = tIdx;\n        new_base_addr = base_addr;\n      }\n      else\n      {\n        new_tIdx = tIdx - (BLOCK_LENGTH-1)*BLOCK_LENGTH;\n        new_base_addr = (block_idx + xgridlength)*blocksize;\n      }\n\n      SOL(idx.x,ty+2,idx.z) = sol_in[new_base_addr + new_tIdx];\n    }\n\n    if(tz == 0)\n    {\n      if(bz == 0)\n      {\n        new_tIdx = tIdx;\n        new_base_addr = base_addr;\n      }\n      else\n      {\n        new_tIdx = tIdx + (BLOCK_LENGTH-1)*BLOCK_LENGTH*BLOCK_LENGTH;\n        new_base_addr = (block_idx - xgridlength*ygridlength)*blocksize;\n      }\n\n      SOL(idx.x,idx.y,tz) = sol_in[new_base_addr + new_tIdx];\n    }\n\n    if(tz == BLOCK_LENGTH-1)\n    {\n      if(bz == zgridlength-1) \n      {\n        new_tIdx = tIdx;\n        new_base_addr = base_addr;\n      }\n      else\n      {\n        new_tIdx = tIdx - (BLOCK_LENGTH-1)*BLOCK_LENGTH*BLOCK_LENGTH;\n        new_base_addr = (block_idx + xgridlength*ygridlength)*blocksize;\n      }\n\n      SOL(idx.x,idx.y,tz+2) = sol_in[new_base_addr + new_tIdx];\n    }\n\n    __syncthreads();\n\n    DOUBLE a,b,c,oldT,newT;\n\n    for(int iter=0; iter<nIter; iter++)  \n    {\n      \n\n      \n\n      \n\n      oldT = newT = SOL(idx.x,idx.y,idx.z);\n\n      if(isValid)\n      {\n        a = min(SOL(tx,idx.y,idx.z),SOL(tx+2,idx.y,idx.z));\n        b = min(SOL(idx.x,ty,idx.z),SOL(idx.x,ty+2,idx.z));\n        c = min(SOL(idx.x,idx.y,tz),SOL(idx.x,idx.y,tz+2));\n\n        DOUBLE tmp = (DOUBLE) get_time_eikonal(a, b, c, F);\n\n        newT = min(tmp,oldT);\n      }\n      __syncthreads();  \n\n      if(isValid) SOL(idx.x,idx.y,idx.z) = newT;\n\n      __syncthreads(); \n\n    }\n\n    DOUBLE residue = oldT - newT;\n\n    \n\n    con[base_addr + tIdx] = (residue < EPS) ? true : false;\n    sol_out[base_addr + tIdx] = newT;    \n  }\n}\n\n__global__ void run_reduction(\n  const bool *__restrict__ con,\n  bool *__restrict__ listVol,\n  const uint *__restrict__ list,\n  uint nActiveBlock)\n{\n  uint list_idx = blockIdx.y*gridDim.x + blockIdx.x;\n\n  if(list_idx < nActiveBlock)\n  {\n    uint block_idx = list[list_idx];\n\n    __shared__ bool conv[BLOCK_LENGTH*BLOCK_LENGTH*BLOCK_LENGTH];\n\n    uint blocksize = BLOCK_LENGTH*BLOCK_LENGTH*BLOCK_LENGTH/2;\n    uint base_addr = block_idx*blocksize*2;\n    uint tx = threadIdx.x;\n    uint ty = threadIdx.y;\n    uint tz = threadIdx.z;\n    uint tIdx = tz*BLOCK_LENGTH*BLOCK_LENGTH + ty*BLOCK_LENGTH + tx;\n\n    conv[tIdx] = con[base_addr + tIdx];\n    conv[tIdx + blocksize] = con[base_addr + tIdx + blocksize];\n\n    __syncthreads();\n\n    for(uint i=blocksize; i>0; i/=2)\n    {\n      if(tIdx < i)\n      {\n        bool b1, b2;\n        b1 = conv[tIdx];\n        b2 = conv[tIdx+i];\n        conv[tIdx] = (b1 && b2) ? true : false ;\n      }\n      __syncthreads();\n    }\n\n    if(tIdx == 0) \n    {    \n      listVol[block_idx] = !conv[0]; \n\n    }\n  }\n}\n\n__global__ void run_check_neighbor(\n  const double*__restrict__ spd,\n  const bool*__restrict__ mask,\n  const DOUBLE *__restrict__ sol_in,\n  DOUBLE *__restrict__ sol_out,\n  bool *__restrict__ con,\n  const uint*__restrict__ list,\n  int xdim, int ydim, int zdim,\n  uint nActiveBlock, uint nTotalBlock)\n{\n\n  uint list_idx = blockIdx.y*gridDim.x + blockIdx.x;\n\n  if(list_idx < nTotalBlock)\n  {\n    double F;\n    bool isValid;\n    __shared__ DOUBLE _sol[BLOCK_LENGTH+2][BLOCK_LENGTH+2][BLOCK_LENGTH+2];\n\n    uint block_idx = list[list_idx];\n    uint blocksize = BLOCK_LENGTH*BLOCK_LENGTH*BLOCK_LENGTH;\n    uint base_addr = block_idx*blocksize;\n\n    uint tx = threadIdx.x;\n    uint ty = threadIdx.y;\n    uint tz = threadIdx.z;\n    uint tIdx = tz*BLOCK_LENGTH*BLOCK_LENGTH + ty*BLOCK_LENGTH + tx;\n\n    if(list_idx < nActiveBlock) \n\n    {\n      sol_out[base_addr + tIdx] = sol_in[base_addr + tIdx];\n    } \n    else\n    {\n      uint xgridlength = xdim/BLOCK_LENGTH;\n      uint ygridlength = ydim/BLOCK_LENGTH;\n      uint zgridlength = zdim/BLOCK_LENGTH;\n\n      \n\n      uint bx = block_idx%xgridlength;\n      uint tmpIdx = (block_idx - bx)/xgridlength;\n      uint by = tmpIdx%ygridlength;\n      uint bz = (tmpIdx-by)/ygridlength;\n\n      \n\n      dim3 idx(tx+1,ty+1,tz+1);\n      _sol[idx.x][idx.y][idx.z] = sol_in[base_addr + tIdx];\n      F = spd[base_addr + tIdx];\n      if(F > 0) F = 1.0/F;\n      isValid = mask[base_addr + tIdx];\n\n      uint new_base_addr, new_tIdx;\n\n      \n\n      if(tx == 0) \n      {\n        if(bx == 0) \n\n        {  \n          new_tIdx = tIdx;\n          new_base_addr = base_addr;\n        }\n        else\n        {\n          new_tIdx = tIdx + BLOCK_LENGTH-1;\n          new_base_addr = (block_idx - 1)*blocksize;  \n        }\n        _sol[tx][idx.y][idx.z] = sol_in[new_base_addr + new_tIdx];  \n      }\n\n      if(tx == BLOCK_LENGTH-1)\n      {\n        if(bx == xgridlength-1) \n\n        {\n          new_tIdx = tIdx;\n          new_base_addr = base_addr;\n        }\n        else\n        {\n          new_tIdx = tIdx - (BLOCK_LENGTH-1);\n          new_base_addr = (block_idx + 1)*blocksize;  \n        }\n        _sol[tx+2][idx.y][idx.z] = sol_in[new_base_addr + new_tIdx];  \n      }\n\n      if(ty == 0)\n      {\n        if(by == 0)\n        {\n          new_tIdx = tIdx;\n          new_base_addr = base_addr;\n        }\n        else\n        {\n          new_tIdx = tIdx + (BLOCK_LENGTH-1)*BLOCK_LENGTH;\n          new_base_addr = (block_idx - xgridlength)*blocksize;\n        }\n        _sol[idx.x][ty][idx.z] = sol_in[new_base_addr + new_tIdx];\n      }\n\n      if(ty == BLOCK_LENGTH-1)\n      {\n        if(by == ygridlength-1) \n        {\n          new_tIdx = tIdx;\n          new_base_addr = base_addr;\n        }\n        else\n        {\n          new_tIdx = tIdx - (BLOCK_LENGTH-1)*BLOCK_LENGTH;\n          new_base_addr = (block_idx + xgridlength)*blocksize;\n        }\n        _sol[idx.x][ty+2][idx.z] = sol_in[new_base_addr + new_tIdx];\n      }\n\n      if(tz == 0)\n      {\n        if(bz == 0)\n        {\n          new_tIdx = tIdx;\n          new_base_addr = base_addr;\n        }\n        else\n        {\n          new_tIdx = tIdx + (BLOCK_LENGTH-1)*BLOCK_LENGTH*BLOCK_LENGTH;\n          new_base_addr = (block_idx - xgridlength*ygridlength)*blocksize;\n        }\n        _sol[idx.x][idx.y][tz] = sol_in[new_base_addr + new_tIdx];\n      }\n\n      if(tz == BLOCK_LENGTH-1)\n      {\n        if(bz == zgridlength-1) \n        {\n          new_tIdx = tIdx;\n          new_base_addr = base_addr;\n        }\n        else\n        {\n          new_tIdx = tIdx - (BLOCK_LENGTH-1)*BLOCK_LENGTH*BLOCK_LENGTH;\n          new_base_addr = (block_idx + xgridlength*ygridlength)*blocksize;\n        }\n        _sol[idx.x][idx.y][tz+2] = sol_in[new_base_addr + new_tIdx];\n      }\n\n      __syncthreads();\n\n\n      DOUBLE a,b,c,oldT,newT;\n\n      \n\n      \n\n      \n\n      oldT = newT = _sol[idx.x][idx.y][idx.z];\n\n      if(isValid)\n      {\n        a = min(_sol[tx][idx.y][idx.z],_sol[tx+2][idx.y][idx.z]);\n        b = min(_sol[idx.x][ty][idx.z],_sol[idx.x][ty+2][idx.z]);\n        c = min(_sol[idx.x][idx.y][tz],_sol[idx.x][idx.y][tz+2]);\n\n        DOUBLE tmp = (DOUBLE) get_time_eikonal(a, b, c, F);\n        newT = min(tmp,oldT);\n\n        sol_out[base_addr + tIdx] = newT;\n      }\n      \n\n      DOUBLE residue = oldT - newT;\n      con[base_addr + tIdx] = (residue < EPS) ? true : false;  \n    }\n  }\n}\n"}}
{"kernel_name": "filter", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <cuda.h>\n#include <cooperative_groups.h>\n\n__global__ \nvoid filter (int *__restrict__ dst,\n             int *__restrict__ nres,\n             const int*__restrict__ src,\n             int n)\n{\n  __shared__ int l_n;\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  \n\n  if (threadIdx.x == 0)\n    l_n = 0;\n  __syncthreads();\n\n  \n\n  \n\n  int d, pos;\n\n  if(i < n) {\n    d = src[i];\n    if(d > 0)\n      pos = atomicAdd(&l_n, 1);\n  }\n  __syncthreads();\n\n  \n\n  if(threadIdx.x == 0)\n    l_n = atomicAdd(nres, l_n);\n  __syncthreads();\n\n  \n\n  if(i < n && d > 0) {\n    pos += l_n; \n\n    dst[pos] = d;\n  }\n  __syncthreads();\n}\n\n\n__device__ int atomicAggInc(int *ctr) {\n  auto g = cooperative_groups::coalesced_threads();\n  int warp_res = 0;\n  if(g.thread_rank() == 0)\n    warp_res = atomicAdd(ctr, g.size());\n  return g.shfl(warp_res, 0) + g.thread_rank();\n}\n\n__global__\nvoid filter2 (int *__restrict__ dst,\n              int *__restrict__ nres,\n              const int*__restrict__ src,\n              int n)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if(i < n && src[i] > 0)\n    dst[atomicAggInc(nres)] = src[i];\n}\n\n\n\n\nbool check(int *d_nres, int *d_output, int h_nres, std::vector<int> &h_output) {\n  int nres;\n  cudaMemcpy(&nres, d_nres, sizeof(int), cudaMemcpyDeviceToHost);\n\n  std::vector<int> output (nres);\n\n  cudaMemcpy(output.data(), d_output, sizeof(int) * nres, cudaMemcpyDeviceToHost);\n\n  \n\n  cudaMemset(d_output, 0, sizeof(int) * nres);\n\n  std::sort(output.begin(), output.end());\n\n  bool equal = (h_nres == nres) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_nres, output.begin());\n  return equal;\n}\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  \n\n  std::vector<int> h_output (num_elems);\n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n\n  \n\n  int *d_input, *d_output, *d_nres;\n\n  cudaMalloc(&d_input, sizeof(int) * num_elems);\n  cudaMalloc(&d_output, sizeof(int) * num_elems);\n  cudaMalloc(&d_nres, sizeof(int));\n\n  cudaMemcpy(d_input, input.data(),\n             sizeof(int) * num_elems, cudaMemcpyHostToDevice);\n\n  dim3 dimBlock (block_size);\n  dim3 dimGrid ((num_elems + block_size - 1) / block_size);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    cudaMemset(d_nres, 0, sizeof(int));\n    filter<<<dimGrid, dimBlock>>>(d_output, d_nres, d_input, num_elems);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (shared memory) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  bool match = check(d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    cudaMemset(d_nres, 0, sizeof(int));\n    filter2<<<dimGrid, dimBlock>>>(d_output, d_nres, d_input, num_elems);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (global aggregate) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  match = check(d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_input);\n  cudaFree(d_output);\n  cudaFree(d_nres);\n\n  return 0;\n}\n"}}
{"kernel_name": "filter", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <hip/hip_runtime.h>\n#include <hip/hip_cooperative_groups.h>\n\n__global__ \nvoid filter (int *__restrict__ dst,\n             int *__restrict__ nres,\n             const int*__restrict__ src,\n             int n)\n{\n  __shared__ int l_n;\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  \n\n  if (threadIdx.x == 0)\n    l_n = 0;\n  __syncthreads();\n\n  \n\n  \n\n  int d, pos;\n\n  if(i < n) {\n    d = src[i];\n    if(d > 0)\n      pos = atomicAdd(&l_n, 1);\n  }\n  __syncthreads();\n\n  \n\n  if(threadIdx.x == 0)\n    l_n = atomicAdd(nres, l_n);\n  __syncthreads();\n\n  \n\n  if(i < n && d > 0) {\n    pos += l_n; \n\n    dst[pos] = d;\n  }\n  __syncthreads();\n}\n\n__device__ int atomicAggInc(int *ctr) {\n  auto g = cooperative_groups::coalesced_threads();\n  int warp_res = 0;\n  if(g.thread_rank() == 0)\n    warp_res = atomicAdd(ctr, g.size());\n  return g.shfl(warp_res, 0) + g.thread_rank();\n}\n\n__global__\nvoid filter2 (int *__restrict__ dst,\n              int *__restrict__ nres,\n              const int*__restrict__ src,\n              int n)\n{\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if(i < n && src[i] > 0)\n    dst[atomicAggInc(nres)] = src[i];\n}\n\n\n\n\nbool check(int *d_nres, int *d_output, int h_nres, std::vector<int> &h_output) {\n  int nres;\n  hipMemcpy(&nres, d_nres, sizeof(int), hipMemcpyDeviceToHost);\n\n  std::vector<int> output (nres);\n\n  hipMemcpy(output.data(), d_output, sizeof(int) * nres, hipMemcpyDeviceToHost);\n\n  \n\n  hipMemset(d_output, 0, sizeof(int) * nres);\n\n  std::sort(output.begin(), output.end());\n\n  bool equal = (h_nres == nres) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_nres, output.begin());\n  return equal;\n}\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  \n\n  std::vector<int> h_output (num_elems);\n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n\n  \n\n  int *d_input, *d_output, *d_nres;\n\n  hipMalloc(&d_input, sizeof(int) * num_elems);\n  hipMalloc(&d_output, sizeof(int) * num_elems);\n  hipMalloc(&d_nres, sizeof(int));\n\n  hipMemcpy(d_input, input.data(),\n             sizeof(int) * num_elems, hipMemcpyHostToDevice);\n\n  dim3 dimBlock (block_size);\n  dim3 dimGrid ((num_elems + block_size - 1) / block_size);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipMemset(d_nres, 0, sizeof(int));\n    filter<<<dimGrid, dimBlock>>>(d_output, d_nres, d_input, num_elems);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (shared memory) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  bool match = check(d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipMemset(d_nres, 0, sizeof(int));\n    filter2<<<dimGrid, dimBlock>>>(d_output, d_nres, d_input, num_elems);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (global aggregate) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  match = check(d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_input);\n  hipFree(d_output);\n  hipFree(d_nres);\n\n  return 0;\n}\n"}}
{"kernel_name": "filter", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <omp.h>\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n  std::vector<int> output (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  int *data_to_filter = input.data();\n  int *filtered_data = output.data();\n  int nres[1];\n\n  #pragma omp target data map(to: data_to_filter[0:num_elems]) \\\n                          map(from: nres[0:1]) \\\n                          map(from: filtered_data[0:num_elems])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      nres[0] = 0;\n      #pragma omp target update to (nres[0:1]) \n\n\n      #pragma omp target teams num_teams((num_elems+block_size-1)/block_size) \\\n      thread_limit(block_size) \n      {\n        int l_n;\n        #pragma omp parallel \n        {\n          int i = omp_get_team_num() * omp_get_num_threads() + omp_get_thread_num() ;\n          if (omp_get_thread_num() == 0)\n            l_n = 0;\n          #pragma omp barrier\n          int d, pos;\n        \n          if(i < num_elems) {\n            d = data_to_filter[i];\n            if(d > 0) {\n              #pragma omp atomic capture\n              pos = l_n++;\n            }\n          }\n          #pragma omp barrier\n  \n          \n\n          if (omp_get_thread_num() == 0) {\n            \n\n             int old;\n             #pragma omp atomic capture\n             {\n                old = nres[0];\n                nres[0] += l_n; \n             }\n             l_n = old;\n          }\n          #pragma omp barrier\n        \n          \n\n          if(i < num_elems && d > 0) {\n            pos += l_n; \n\n            filtered_data[pos] = d;\n          }\n          #pragma omp barrier\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %lf (ms)\\n\", (time * 1e-6) / repeat);\n  }\n\n  std::vector<int> h_output (num_elems);\n\n  \n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n  std::sort(output.begin(), output.begin() + nres[0]);\n\n  bool equal = (h_flt_count == nres[0]) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_flt_count, output.begin());\n\n  printf(\"\\nFilter using shared memory %s \\n\",\n         equal ? \"PASS\" : \"FAIL\");\n\n  return 0;\n}\n"}}
{"kernel_name": "filter", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n  std::vector<int> output (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  int *data_to_filter = input.data();\n  int *filtered_data = output.data();\n  int nres[1];\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      nres[0] = 0;\n      \n\n            {\n        int l_n;\n                {\n          int i = omp_get_team_num() * omp_get_num_threads() + omp_get_thread_num() ;\n          if (omp_get_thread_num() == 0)\n            l_n = 0;\n                    int d, pos;\n        \n          if(i < num_elems) {\n            d = data_to_filter[i];\n            if(d > 0) {\n                            pos = l_n++;\n            }\n          }\n            \n          \n\n          if (omp_get_thread_num() == 0) {\n            \n\n             int old;\n                          {\n                old = nres[0];\n                nres[0] += l_n; \n             }\n             l_n = old;\n          }\n                  \n          \n\n          if(i < num_elems && d > 0) {\n            pos += l_n; \n\n            filtered_data[pos] = d;\n          }\n                  }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time %lf (ms)\\n\", (time * 1e-6) / repeat);\n  }\n\n  std::vector<int> h_output (num_elems);\n\n  \n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n  std::sort(output.begin(), output.begin() + nres[0]);\n\n  bool equal = (h_flt_count == nres[0]) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_flt_count, output.begin());\n\n  printf(\"\\nFilter using shared memory %s \\n\",\n         equal ? \"PASS\" : \"FAIL\");\n\n  return 0;\n}"}}
{"kernel_name": "filter", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <vector>\n#include <sycl/sycl.hpp>\n\n\n\nbool check(sycl::queue &q, int *d_nres, int *d_output, int h_nres, std::vector<int> &h_output) {\n  int nres;\n  q.memcpy(&nres, d_nres, sizeof(int)).wait();\n\n  std::vector<int> output (nres);\n\n  q.memcpy(output.data(), d_output, sizeof(int) * nres).wait();\n\n  \n\n  q.memset(d_output, 0, sizeof(int) * nres);\n\n  std::sort(output.begin(), output.end());\n\n  bool equal = (h_nres == nres) && \n               std::equal(h_output.begin(),\n                          h_output.begin() + h_nres, output.begin());\n  return equal;\n}\n\nvoid filter(int *__restrict d_output,\n            int *__restrict d_nres,\n            const int*__restrict__ d_input,\n            const int num_elems,\n            int &l_n,\n            sycl::nd_item<1> &item)\n{\n  int i = item.get_global_id(0);\n\n  \n\n  if (item.get_local_id(0) == 0) l_n = 0;\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  \n\n  int d, pos;\n\n  if(i < num_elems) {\n    d = d_input[i];\n    if(d > 0) {\n      auto ao = sycl::atomic_ref<int,\n                sycl::memory_order::relaxed,\n                sycl::memory_scope::work_group,\n                sycl::access::address_space::local_space> (l_n);\n      pos = ao.fetch_add(1);\n    }\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  if(item.get_local_id(0) == 0) {\n    auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (d_nres[0]);\n    l_n = ao.fetch_add(l_n);\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  if(i < num_elems && d > 0) {\n    pos += l_n; \n\n    d_output[pos] = d;\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n}\n\nint atomicAggInc(int *ctr) {\n  auto g = sycl::ext::oneapi::experimental::this_kernel::get_opportunistic_group();\n  int warp_res = 0;\n  if (g.leader()) {\n    auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (ctr[0]);\n    warp_res = ao.fetch_add(g.get_local_linear_range());\n  }\n  return sycl::group_broadcast(g, warp_res) + g.get_local_linear_id();\n}\n\n\nvoid filter2 (int *__restrict__ dst,\n              int *__restrict__ nres,\n              const int*__restrict__ src,\n              int n,\n              const sycl::nd_item<1> &item)\n{\n  int i = item.get_global_id(0);\n  if (i < n && src[i] > 0)\n    dst[atomicAggInc(nres)] = src[i];\n}\n\n\nint main(int argc, char **argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of elements> <block size> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int num_elems = atoi(argv[1]);\n  const int block_size = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n    \n  std::vector<int> input (num_elems);\n\n  \n\n  for (int i = 0; i < num_elems; i++) {\n    input[i] = i - num_elems / 2;\n  }\n\n  std::mt19937 g;\n  g.seed(19937);\n  std::shuffle(input.begin(), input.end(), g);\n\n  \n\n  std::vector<int> h_output (num_elems);\n\n  int h_flt_count = 0;\n  for (int i = 0; i < num_elems; i++) {\n    if (input[i] > 0) {\n      h_output[h_flt_count++] = input[i];\n    }\n  }\n  \n\n  std::sort(h_output.begin(), h_output.begin() + h_flt_count);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_input, *d_output, *d_nres;\n\n  d_input = sycl::malloc_device<int>(num_elems, q);\n  d_output = sycl::malloc_device<int>(num_elems, q);\n  d_nres = sycl::malloc_device<int>(1, q);\n\n  q.memcpy(d_input, input.data(), sizeof(int) * num_elems);\n\n  sycl::range<1> lws (block_size);\n  sycl::range<1> gws ((num_elems + block_size - 1) / block_size * block_size);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.memset(d_nres, 0, sizeof(int));\n    q.submit([&](sycl::handler &h) {\n      sycl::local_accessor <int, 0> l_n (h);\n      h.parallel_for<class filter_sharedMem>(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        filter(d_output, d_nres, d_input, num_elems, l_n, item);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (shared memory) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  bool match = check(q, d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.memset(d_nres, 0, sizeof(int));\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class filter_atomicAggInc>(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        filter2(d_output, d_nres, d_input, num_elems, item);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of filter (global aggregate) %lf (ms)\\n\",\n         (time * 1e-6) / repeat);\n\n  match = check(q, d_nres, d_output, h_flt_count, h_output);\n  printf(\"%s\\n\", match ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_input, q);\n  sycl::free(d_output, q);\n  sycl::free(d_nres, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "flip", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include <cuda.h>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\n__global__ void flip_kernel(\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims)\n{\n  int64_t linear_index = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (linear_index >= n) return;\n\n  int64_t cur_indices = linear_index;\n  int64_t rem = 0;\n  int64_t dst_offset = 0;\n\n  for (int64_t i = 0; i < total_dims; i++) {\n    int64_t temp = cur_indices;\n    cur_indices = cur_indices / strides_contiguous[i];\n    rem = temp - cur_indices * strides_contiguous[i];\n    for (int64_t j = 0; j < flip_dims_size; j++) {\n      \n\n      if (i == flip_dims[j]) {\n        cur_indices = shape[i] - 1 - cur_indices;\n      }\n    }\n    dst_offset += cur_indices * strides[i];\n    cur_indices = rem;\n  }\n  out_tensor[linear_index] = in_tensor[dst_offset];\n}\n\n\n\nvoid property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  property(\"shape\", shape);\n  property(\"flip_dims\", flip);\n  property(\"stride\", stride);\n\n  int64_t dims_bytes = num_dims * sizeof(int64_t);\n  int64_t flip_dims_bytes = num_flip_dims * sizeof(int64_t);\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n  scalar_t *d_input, *d_output;\n  cudaMalloc((void**)&d_input, input_size_bytes);\n  cudaMemcpy(d_input, input, input_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_output, output_size_bytes);\n\n  int64_t *d_flip_dims, *d_shape, *d_strides, *d_strides_contiguous;\n\n  cudaMalloc((void**)&d_flip_dims, flip_dims_bytes);\n  cudaMemcpy(d_flip_dims, flip.data(), flip_dims_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_shape, dims_bytes);\n  cudaMemcpy(d_shape, shape.data(), dims_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_strides, dims_bytes);\n  cudaMemcpy(d_strides, stride.data(), dims_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_strides_contiguous, dims_bytes);\n  cudaMemcpy(d_strides_contiguous, stride.data(), dims_bytes, cudaMemcpyHostToDevice);\n\n  const int threadsPerBlock = 256;\n  dim3 grid ((n + threadsPerBlock - 1) / threadsPerBlock);\n  dim3 block (threadsPerBlock);\n\n  \n\n  flip_kernel<scalar_t><<<grid, block>>> (\n    d_input, d_output, n, d_flip_dims, num_flip_dims,\n    d_strides, d_strides_contiguous, d_shape, num_dims);\n\n  flip_kernel_cpu<scalar_t>(\n    input, output_ref, n, flip.data(), num_flip_dims,\n    stride.data(), stride.data(), shape.data(), num_dims);\n\n  cudaMemcpy(output, d_output, output_size_bytes, cudaMemcpyDeviceToHost);\n  int error = memcmp(output, output_ref, output_size_bytes);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n#ifdef EXAMPLE\n  for (int i = 0; i < n; i++) {\n    printf(\"%f \", output[i]);\n  }\n  printf(\"\\n\");\n#endif\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    flip_kernel<scalar_t><<<grid, block>>> (\n      d_input,\n      d_output,\n      n,\n      d_flip_dims,\n      num_flip_dims,\n      d_strides,\n      d_strides_contiguous,\n      d_shape,\n      num_dims);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(input);\n  free(output);\n  free(output_ref);\n  cudaFree(d_input);\n  cudaFree(d_output);\n  cudaFree(d_flip_dims);\n  cudaFree(d_shape);\n  cudaFree(d_strides);\n  cudaFree(d_strides_contiguous);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "flip", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\n__global__ void flip_kernel(\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims)\n{\n  int64_t linear_index = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (linear_index >= n) return;\n\n  int64_t cur_indices = linear_index;\n  int64_t rem = 0;\n  int64_t dst_offset = 0;\n\n  for (int64_t i = 0; i < total_dims; i++) {\n    int64_t temp = cur_indices;\n    cur_indices = cur_indices / strides_contiguous[i];\n    rem = temp - cur_indices * strides_contiguous[i];\n    for (int64_t j = 0; j < flip_dims_size; j++) {\n      \n\n      if (i == flip_dims[j]) {\n        cur_indices = shape[i] - 1 - cur_indices;\n      }\n    }\n    dst_offset += cur_indices * strides[i];\n    cur_indices = rem;\n  }\n  out_tensor[linear_index] = in_tensor[dst_offset];\n}\n\n\n\nvoid property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  property(\"shape\", shape);\n  property(\"flip_dims\", flip);\n  property(\"stride\", stride);\n\n  int64_t dims_bytes = num_dims * sizeof(int64_t);\n  int64_t flip_dims_bytes = num_flip_dims * sizeof(int64_t);\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n  scalar_t *d_input, *d_output;\n  hipMalloc((void**)&d_input, input_size_bytes);\n  hipMemcpy(d_input, input, input_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_output, output_size_bytes);\n\n  int64_t *d_flip_dims, *d_shape, *d_strides, *d_strides_contiguous;\n\n  hipMalloc((void**)&d_flip_dims, flip_dims_bytes);\n  hipMemcpy(d_flip_dims, flip.data(), flip_dims_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_shape, dims_bytes);\n  hipMemcpy(d_shape, shape.data(), dims_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_strides, dims_bytes);\n  hipMemcpy(d_strides, stride.data(), dims_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_strides_contiguous, dims_bytes);\n  hipMemcpy(d_strides_contiguous, stride.data(), dims_bytes, hipMemcpyHostToDevice);\n\n  const int threadsPerBlock = 256;\n  dim3 grid ((n + threadsPerBlock - 1) / threadsPerBlock);\n  dim3 block (threadsPerBlock);\n\n  \n\n  flip_kernel<scalar_t><<<grid, block>>> (\n    d_input, d_output, n, d_flip_dims, num_flip_dims,\n    d_strides, d_strides_contiguous, d_shape, num_dims);\n\n  flip_kernel_cpu<scalar_t>(\n    input, output_ref, n, flip.data(), num_flip_dims,\n    stride.data(), stride.data(), shape.data(), num_dims);\n\n  hipMemcpy(output, d_output, output_size_bytes, hipMemcpyDeviceToHost);\n  int error = memcmp(output, output_ref, output_size_bytes);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n#ifdef EXAMPLE\n  for (int i = 0; i < n; i++) {\n    printf(\"%f \", output[i]);\n  }\n  printf(\"\\n\");\n#endif\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    flip_kernel<scalar_t><<<grid, block>>> (\n      d_input,\n      d_output,\n      n,\n      d_flip_dims,\n      num_flip_dims,\n      d_strides,\n      d_strides_contiguous,\n      d_shape,\n      num_dims);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(input);\n  free(output);\n  free(output_ref);\n  hipFree(d_input);\n  hipFree(d_output);\n  hipFree(d_flip_dims);\n  hipFree(d_shape);\n  hipFree(d_strides);\n  hipFree(d_strides_contiguous);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "flip", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include <omp.h>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\nvoid flip_kernel(\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims) \n{\n  #pragma omp target teams distribute parallel for num_threads(256)\n  for (int64_t linear_index = 0; linear_index < n; linear_index++) {\n\n    int64_t cur_indices = linear_index;\n    int64_t rem = 0;\n    int64_t dst_offset = 0;\n\n    for (int64_t i = 0; i < total_dims; i++) {\n      int64_t temp = cur_indices;\n      cur_indices = cur_indices / strides_contiguous[i];\n      rem = temp - cur_indices * strides_contiguous[i];\n      for (int64_t j = 0; j < flip_dims_size; j++) {\n        \n\n        if (i == flip_dims[j]) {\n          cur_indices = shape[i] - 1 - cur_indices;\n        }\n      }\n      dst_offset += cur_indices * strides[i];\n      cur_indices = rem;\n    }\n    out_tensor[linear_index] = in_tensor[dst_offset];\n  }\n}\n\n\n\nvoid property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  property(\"shape\", shape);\n  property(\"flip_dims\", flip);\n  property(\"stride\", stride);\n\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n  scalar_t *d_input = input; \n  scalar_t *d_output = output; \n  int64_t *d_shape = shape.data();\n  int64_t *d_flip_dims = flip.data();\n  int64_t *d_strides = stride.data();\n  int64_t *d_strides_contiguous = stride.data();\n\n  #pragma omp target data map(to: d_input[0:n], \\\n                                  d_shape[0:num_dims], \\\n                                  d_flip_dims[0:num_dims], \\\n                                  d_strides[0:num_dims], \\\n                                  d_strides_contiguous[0:num_dims]) \\\n                          map(alloc: d_output[0:n])\n  {\n    \n\n    flip_kernel<scalar_t>(\n      d_input, d_output, n, d_flip_dims, num_flip_dims,\n      d_strides, d_strides_contiguous, d_shape, num_dims);\n\n    flip_kernel_cpu<scalar_t>(\n      input, output_ref, n, flip.data(), num_flip_dims,\n      stride.data(), stride.data(), shape.data(), num_dims);\n\n    #pragma omp target update from (d_output[0:n])\n    int error = memcmp(output, output_ref, output_size_bytes);\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n    #ifdef EXAMPLE\n      for (int i = 0; i < n; i++) {\n        printf(\"%f \", output[i]);\n      }\n      printf(\"\\n\");\n    #endif\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      flip_kernel<scalar_t>(\n        d_input,\n        d_output,\n        n,\n        d_flip_dims,\n        num_flip_dims,\n        d_strides,\n        d_strides_contiguous,\n        d_shape,\n        num_dims);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  free(input);\n  free(output);\n  free(output_ref);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "flip", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\nvoid flip_kernel(\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims) \n{\n    for (int64_t linear_index = 0; linear_index < n; linear_index++) {\n\n    int64_t cur_indices = linear_index;\n    int64_t rem = 0;\n    int64_t dst_offset = 0;\n\n    for (int64_t i = 0; i < total_dims; i++) {\n      int64_t temp = cur_indices;\n      cur_indices = cur_indices / strides_contiguous[i];\n      rem = temp - cur_indices * strides_contiguous[i];\n      for (int64_t j = 0; j < flip_dims_size; j++) {\n        \n\n        if (i == flip_dims[j]) {\n          cur_indices = shape[i] - 1 - cur_indices;\n        }\n      }\n      dst_offset += cur_indices * strides[i];\n      cur_indices = rem;\n    }\n    out_tensor[linear_index] = in_tensor[dst_offset];\n  }\n}\n\n\n\nvoid property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  property(\"shape\", shape);\n  property(\"flip_dims\", flip);\n  property(\"stride\", stride);\n\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n  scalar_t *d_input = input; \n  scalar_t *d_output = output; \n  int64_t *d_shape = shape.data();\n  int64_t *d_flip_dims = flip.data();\n  int64_t *d_strides = stride.data();\n  int64_t *d_strides_contiguous = stride.data();\n\n    {\n    \n\n    flip_kernel<scalar_t>(\n      d_input, d_output, n, d_flip_dims, num_flip_dims,\n      d_strides, d_strides_contiguous, d_shape, num_dims);\n\n    flip_kernel_cpu<scalar_t>(\n      input, output_ref, n, flip.data(), num_flip_dims,\n      stride.data(), stride.data(), shape.data(), num_dims);\n\n        int error = memcmp(output, output_ref, output_size_bytes);\n    printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n    #ifdef EXAMPLE\n      for (int i = 0; i < n; i++) {\n        printf(\"%f \", output[i]);\n      }\n      printf(\"\\n\");\n    #endif\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      flip_kernel<scalar_t>(\n        d_input,\n        d_output,\n        n,\n        d_flip_dims,\n        num_flip_dims,\n        d_strides,\n        d_strides_contiguous,\n        d_shape,\n        num_dims);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  free(input);\n  free(output);\n  free(output_ref);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "flip", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <vector>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\n\n\n\n\n\ntemplate <typename scalar_t>\nvoid flip_kernel(\n    sycl::nd_item<1> &item,\n    const scalar_t* in_tensor,\n          scalar_t* out_tensor,\n    int64_t  n,\n    const int64_t* flip_dims,\n    const int64_t  flip_dims_size,\n    const int64_t* strides,\n    const int64_t* strides_contiguous,\n    const int64_t* shape,\n    const int64_t  total_dims)\n{\n  int64_t linear_index = item.get_global_id(0);\n\n  if (linear_index >= n) return;\n\n  int64_t cur_indices = linear_index;\n  int64_t rem = 0;\n  int64_t dst_offset = 0;\n\n  for (int64_t i = 0; i < total_dims; i++) {\n    int64_t temp = cur_indices;\n    cur_indices = cur_indices / strides_contiguous[i];\n    rem = temp - cur_indices * strides_contiguous[i];\n    for (int64_t j = 0; j < flip_dims_size; j++) {\n      \n\n      if (i == flip_dims[j]) {\n        cur_indices = shape[i] - 1 - cur_indices;\n      }\n    }\n    dst_offset += cur_indices * strides[i];\n    cur_indices = rem;\n  }\n  out_tensor[linear_index] = in_tensor[dst_offset];\n}\n\n\n\nvoid print_property (const char* name, std::vector<int64_t> p)\n{\n  printf(\"%s: ( \", name);\n  for (uint64_t i = 0; i < p.size(); i++) {\n    printf(\"%lu \", p[i]);\n  }\n  printf(\")\\n\");\n}\n\ntemplate <typename scalar_t>\nvoid flip (const int64_t num_dims, const int64_t num_flip_dims,\n           const int32_t dim_size, const int32_t repeat)\n{\n  std::vector<int64_t> flip;\n  std::vector<int64_t> shape;\n  std::vector<int64_t> stride;\n\n  for (int64_t i = 0; i < num_dims; i++) {\n#ifdef EXAMPLE\n    shape.push_back(2);\n#else\n    shape.push_back(dim_size);\n#endif\n  }\n\n  int64_t n = 1;\n  for (int64_t i = 0; i < num_dims; i++) {\n    n = n * shape[i];\n  }\n\n  for (int64_t i = 0; i < num_flip_dims; i++) {\n    flip.push_back(i);\n  }\n\n  stride.push_back(shape[1] * shape[2]);\n  stride.push_back(shape[2]);\n  stride.push_back(1);\n\n  print_property(\"shape\", shape);\n  print_property(\"flip_dims\", flip);\n  print_property(\"stride\", stride);\n\n  int64_t dims_bytes = num_dims * sizeof(int64_t);\n  int64_t flip_dims_bytes = num_flip_dims * sizeof(int64_t);\n  int64_t input_size_bytes = n * sizeof(scalar_t);\n  int64_t output_size_bytes = input_size_bytes;\n\n  scalar_t *input = (scalar_t*) malloc (input_size_bytes);\n\n  for (int i = 0; i < n; i++) {\n    input[i] = (scalar_t) i;\n  }\n\n  scalar_t *output = (scalar_t*) malloc(output_size_bytes);\n  scalar_t *output_ref = (scalar_t*) malloc(output_size_bytes);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  scalar_t *d_input, *d_output;\n  d_input = sycl::malloc_device<scalar_t>(n, q);\n  q.memcpy(d_input, input, input_size_bytes);\n\n  d_output = sycl::malloc_device<scalar_t>(n, q);\n\n  int64_t *d_flip_dims, *d_shape, *d_strides, *d_strides_contiguous;\n\n  d_flip_dims = sycl::malloc_device<int64_t>(num_flip_dims, q);\n  q.memcpy(d_flip_dims, flip.data(), flip_dims_bytes);\n\n  d_shape = sycl::malloc_device<int64_t>(num_dims, q);\n  q.memcpy(d_shape, shape.data(), dims_bytes);\n\n  d_strides = sycl::malloc_device<int64_t>(num_dims, q);\n  q.memcpy(d_strides, stride.data(), dims_bytes);\n\n  d_strides_contiguous = sycl::malloc_device<int64_t>(num_dims, q);\n  q.memcpy(d_strides_contiguous, stride.data(), dims_bytes);\n\n  const int threadsPerBlock = 256;\n\n  sycl::range<1> gws ((n + threadsPerBlock - 1) / threadsPerBlock * threadsPerBlock);\n  sycl::range<1> lws (threadsPerBlock);\n\n  \n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      flip_kernel<scalar_t>(\n        item,\n        d_input,\n        d_output,\n        n,\n        d_flip_dims,\n        num_flip_dims,\n        d_strides,\n        d_strides_contiguous,\n        d_shape,\n        num_dims);\n    });\n  });\n\n  flip_kernel_cpu<scalar_t>(\n    input, output_ref, n, flip.data(), num_flip_dims,\n    stride.data(), stride.data(), shape.data(), num_dims);\n\n  q.memcpy(output, d_output, output_size_bytes).wait();\n  int error = memcmp(output, output_ref, output_size_bytes);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n#ifdef EXAMPLE\n  for (int i = 0; i < n; i++) {\n    printf(\"%f \", output[i]);\n  }\n  printf(\"\\n\");\n#endif\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        flip_kernel<scalar_t>(\n          item,\n          d_input,\n          d_output,\n          n,\n          d_flip_dims,\n          num_flip_dims,\n          d_strides,\n          d_strides_contiguous,\n          d_shape,\n          num_dims);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of the flip kernel: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(input);\n  free(output);\n  free(output_ref);\n  sycl::free(d_input, q);\n  sycl::free(d_output, q);\n  sycl::free(d_flip_dims, q);\n  sycl::free(d_shape, q);\n  sycl::free(d_strides, q);\n  sycl::free(d_strides_contiguous, q);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <number of dimensions> <size of each dimension> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int64_t num_dims = atoi(argv[1]);\n  const int64_t dim_size = atoi(argv[2]);\n  const int32_t repeat = atoi(argv[3]);\n\n#ifdef EXAMPLE\n  const int64_t num_flip_dims = 2;\n#else\n  const int64_t num_flip_dims = num_dims;\n#endif\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  flip<float>(num_dims, num_flip_dims, dim_size, repeat);\n\n  printf(\"=========== Data type is FP64 ==========\\n\");\n  flip<double>(num_dims, num_flip_dims, dim_size, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "floydwarshall", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n\n#define MAXDISTANCE    (200)\n\n\n\nunsigned int minimum(unsigned int a, unsigned int b) \n{\n  return (b < a) ? b : a;\n}\n\n\n\nvoid floydWarshallCPUReference(unsigned int * pathDistanceMatrix,\n    unsigned int * pathMatrix, unsigned int numNodes)\n{\n  unsigned int distanceYtoX, distanceYtoK, distanceKtoX, indirectDistance;\n\n  \n\n  unsigned int width = numNodes;\n  unsigned int yXwidth;\n\n  \n\n  for(unsigned int k = 0; k < numNodes; ++k)\n  {\n    for(unsigned int y = 0; y < numNodes; ++y)\n    {\n      yXwidth =  y*numNodes;\n      for(unsigned int x = 0; x < numNodes; ++x)\n      {\n        distanceYtoX = pathDistanceMatrix[yXwidth + x];\n        distanceYtoK = pathDistanceMatrix[yXwidth + k];\n        distanceKtoX = pathDistanceMatrix[k * width + x];\n\n        indirectDistance = distanceYtoK + distanceKtoX;\n\n        if(indirectDistance < distanceYtoX)\n        {\n          pathDistanceMatrix[yXwidth + x] = indirectDistance;\n          pathMatrix[yXwidth + x]         = k;\n        }\n      }\n    }\n  }\n}\n\n\n\n\n\n__global__ void floydWarshallPass(\n    unsigned int *__restrict__ pathDistanceBuffer,\n    unsigned int *__restrict__ pathBuffer,\n    const unsigned int numNodes,\n    const unsigned int pass)\n{\n  int xValue = threadIdx.x + blockIdx.x * blockDim.x;\n  int yValue = threadIdx.y + blockIdx.y * blockDim.y;\n\n  int k = pass;\n  int oldWeight = pathDistanceBuffer[yValue * numNodes + xValue];\n  int tempWeight = pathDistanceBuffer[yValue * numNodes + k] + \n                   pathDistanceBuffer[k * numNodes + xValue];\n\n  if (tempWeight < oldWeight)\n  {\n    pathDistanceBuffer[yValue * numNodes + xValue] = tempWeight;\n    pathBuffer[yValue * numNodes + xValue] = k;\n  }\n}\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of nodes> <iterations> <block size>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  unsigned int numNodes = atoi(argv[1]);\n  unsigned int numIterations = atoi(argv[2]);\n  unsigned int blockSize = atoi(argv[3]);\n\n  \n\n  if(numNodes % blockSize != 0) {\n    numNodes = (numNodes / blockSize + 1) * blockSize;\n  }\n\n  \n\n  unsigned int* pathMatrix = NULL;\n  unsigned int* pathDistanceMatrix = NULL;\n  unsigned int* verificationPathDistanceMatrix = NULL;\n  unsigned int* verificationPathMatrix = NULL;\n  unsigned int matrixSizeBytes;\n\n  matrixSizeBytes = numNodes * numNodes * sizeof(unsigned int);\n  pathDistanceMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathDistanceMatrix != NULL);\n\n  pathMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathMatrix != NULL) ;\n\n  \n\n  srand(2);\n  for(unsigned int i = 0; i < numNodes; i++)\n    for(unsigned int j = 0; j < numNodes; j++)\n    {\n      int index = i*numNodes + j;\n      pathDistanceMatrix[index] = rand() % (MAXDISTANCE + 1);\n    }\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    unsigned int iXWidth = i * numNodes;\n    pathDistanceMatrix[iXWidth + i] = 0;\n  }\n\n  \n\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    for(unsigned int j = 0; j < i; ++j)\n    {\n      pathMatrix[i * numNodes + j] = i;\n      pathMatrix[j * numNodes + i] = j;\n    }\n    pathMatrix[i * numNodes + i] = i;\n  }\n\n  verificationPathDistanceMatrix = (unsigned int *) malloc(numNodes * numNodes * sizeof(int));\n  assert (verificationPathDistanceMatrix != NULL);\n\n  verificationPathMatrix = (unsigned int *) malloc(numNodes * numNodes * sizeof(int));\n  assert(verificationPathMatrix != NULL);\n\n  memcpy(verificationPathDistanceMatrix, pathDistanceMatrix,\n      numNodes * numNodes * sizeof(int));\n  memcpy(verificationPathMatrix, pathMatrix, numNodes*numNodes*sizeof(int));\n\n  unsigned int numPasses = numNodes;\n\n  unsigned int globalThreads[2] = {numNodes, numNodes};\n  unsigned int localThreads[2] = {blockSize, blockSize};\n\n  if((unsigned int)(localThreads[0] * localThreads[0]) >256)\n  {\n    blockSize = 16;\n    localThreads[0] = blockSize;\n    localThreads[1] = blockSize;\n  }\n\n  dim3 grids( globalThreads[0]/localThreads[0], globalThreads[1]/localThreads[1]);\n  dim3 threads (localThreads[0],localThreads[1]);\n\n  unsigned int *pathDistanceBuffer, *pathBuffer;\n  cudaMalloc((void**)&pathDistanceBuffer, matrixSizeBytes);\n  cudaMalloc((void**)&pathBuffer, matrixSizeBytes);\n\n  float total_time = 0.f;\n\n  \n\n  \n\n  for (unsigned int n = 0; n < numIterations; n++) {\n    \n\n\n    cudaMemcpy(pathDistanceBuffer, pathDistanceMatrix, matrixSizeBytes, cudaMemcpyHostToDevice);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for(unsigned int i = 0; i < numPasses; i++)\n    {\n      floydWarshallPass <<< grids, threads >>> (pathDistanceBuffer,pathBuffer,numNodes,i);\n    }\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n  }\n\n  printf(\"Average kernel execution time %f (s)\\n\", (total_time * 1e-9f) / numIterations);\n\n  cudaMemcpy(pathDistanceMatrix, pathDistanceBuffer, matrixSizeBytes, cudaMemcpyDeviceToHost);\n  cudaFree(pathDistanceBuffer);\n  cudaFree(pathBuffer);\n\n  \n\n  floydWarshallCPUReference(verificationPathDistanceMatrix, verificationPathMatrix, numNodes);\n  if(memcmp(pathDistanceMatrix, verificationPathDistanceMatrix, matrixSizeBytes) == 0)\n  {\n    printf(\"PASS\\n\");\n  }\n  else\n  {\n    printf(\"FAIL\\n\");\n    if (numNodes <= 8) \n    {\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"host: %u \", verificationPathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"device: %u \", pathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n    }\n  }\n\n  free(pathDistanceMatrix);\n  free(pathMatrix);\n  free(verificationPathDistanceMatrix);\n  free(verificationPathMatrix);\n  return 0;\n}\n"}}
{"kernel_name": "floydwarshall", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define MAXDISTANCE    (200)\n\n\n\nunsigned int minimum(unsigned int a, unsigned int b) \n{\n  return (b < a) ? b : a;\n}\n\n\n\nvoid floydWarshallCPUReference(unsigned int * pathDistanceMatrix,\n    unsigned int * pathMatrix, unsigned int numNodes)\n{\n  unsigned int distanceYtoX, distanceYtoK, distanceKtoX, indirectDistance;\n\n  \n\n  unsigned int width = numNodes;\n  unsigned int yXwidth;\n\n  \n\n  for(unsigned int k = 0; k < numNodes; ++k)\n  {\n    for(unsigned int y = 0; y < numNodes; ++y)\n    {\n      yXwidth =  y*numNodes;\n      for(unsigned int x = 0; x < numNodes; ++x)\n      {\n        distanceYtoX = pathDistanceMatrix[yXwidth + x];\n        distanceYtoK = pathDistanceMatrix[yXwidth + k];\n        distanceKtoX = pathDistanceMatrix[k * width + x];\n\n        indirectDistance = distanceYtoK + distanceKtoX;\n\n        if(indirectDistance < distanceYtoX)\n        {\n          pathDistanceMatrix[yXwidth + x] = indirectDistance;\n          pathMatrix[yXwidth + x]         = k;\n        }\n      }\n    }\n  }\n}\n\n\n\n\n\n__global__ void floydWarshallPass(\n    unsigned int *__restrict__ pathDistanceBuffer,\n    unsigned int *__restrict__ pathBuffer,\n    const unsigned int numNodes,\n    const unsigned int pass)\n{\n  int xValue = threadIdx.x + blockIdx.x * blockDim.x;\n  int yValue = threadIdx.y + blockIdx.y * blockDim.y;\n\n  int k = pass;\n  int oldWeight = pathDistanceBuffer[yValue * numNodes + xValue];\n  int tempWeight = pathDistanceBuffer[yValue * numNodes + k] + \n                   pathDistanceBuffer[k * numNodes + xValue];\n\n  if (tempWeight < oldWeight)\n  {\n    pathDistanceBuffer[yValue * numNodes + xValue] = tempWeight;\n    pathBuffer[yValue * numNodes + xValue] = k;\n  }\n}\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of nodes> <iterations> <block size>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  unsigned int numNodes = atoi(argv[1]);\n  unsigned int numIterations = atoi(argv[2]);\n  unsigned int blockSize = atoi(argv[3]);\n\n  \n\n  if(numNodes % blockSize != 0) {\n    numNodes = (numNodes / blockSize + 1) * blockSize;\n  }\n\n  \n\n  unsigned int* pathMatrix = NULL;\n  unsigned int* pathDistanceMatrix = NULL;\n  unsigned int* verificationPathDistanceMatrix = NULL;\n  unsigned int* verificationPathMatrix = NULL;\n  unsigned int matrixSizeBytes;\n\n  matrixSizeBytes = numNodes * numNodes * sizeof(unsigned int);\n  pathDistanceMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathDistanceMatrix != NULL);\n\n  pathMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathMatrix != NULL) ;\n\n  \n\n  srand(2);\n  for(unsigned int i = 0; i < numNodes; i++)\n    for(unsigned int j = 0; j < numNodes; j++)\n    {\n      int index = i*numNodes + j;\n      pathDistanceMatrix[index] = rand() % (MAXDISTANCE + 1);\n    }\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    unsigned int iXWidth = i * numNodes;\n    pathDistanceMatrix[iXWidth + i] = 0;\n  }\n\n  \n\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    for(unsigned int j = 0; j < i; ++j)\n    {\n      pathMatrix[i * numNodes + j] = i;\n      pathMatrix[j * numNodes + i] = j;\n    }\n    pathMatrix[i * numNodes + i] = i;\n  }\n\n  verificationPathDistanceMatrix = (unsigned int *) malloc(numNodes * numNodes * sizeof(int));\n  assert (verificationPathDistanceMatrix != NULL);\n\n  verificationPathMatrix = (unsigned int *) malloc(numNodes * numNodes * sizeof(int));\n  assert(verificationPathMatrix != NULL);\n\n  memcpy(verificationPathDistanceMatrix, pathDistanceMatrix,\n      numNodes * numNodes * sizeof(int));\n  memcpy(verificationPathMatrix, pathMatrix, numNodes*numNodes*sizeof(int));\n\n  unsigned int numPasses = numNodes;\n\n  unsigned int globalThreads[2] = {numNodes, numNodes};\n  unsigned int localThreads[2] = {blockSize, blockSize};\n\n  if((unsigned int)(localThreads[0] * localThreads[0]) >256)\n  {\n    blockSize = 16;\n    localThreads[0] = blockSize;\n    localThreads[1] = blockSize;\n  }\n\n  dim3 grids( globalThreads[0]/localThreads[0], globalThreads[1]/localThreads[1]);\n  dim3 threads (localThreads[0],localThreads[1]);\n\n  unsigned int *pathDistanceBuffer, *pathBuffer;\n  hipMalloc((void**)&pathDistanceBuffer, matrixSizeBytes);\n  hipMalloc((void**)&pathBuffer, matrixSizeBytes);\n\n  float total_time = 0.f;\n\n  \n\n  \n\n  for (unsigned int n = 0; n < numIterations; n++) {\n    \n\n\n    hipMemcpy(pathDistanceBuffer, pathDistanceMatrix, matrixSizeBytes, hipMemcpyHostToDevice);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for(unsigned int i = 0; i < numPasses; i++)\n    {\n      hipLaunchKernelGGL(floydWarshallPass, grids, threads , 0, 0, pathDistanceBuffer,pathBuffer,numNodes,i);\n    }\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n  }\n\n  printf(\"Average kernel execution time %f (s)\\n\", (total_time * 1e-9f) / numIterations);\n\n  hipMemcpy(pathDistanceMatrix, pathDistanceBuffer, matrixSizeBytes, hipMemcpyDeviceToHost);\n  hipFree(pathDistanceBuffer);\n  hipFree(pathBuffer);\n\n  \n\n  floydWarshallCPUReference(verificationPathDistanceMatrix, verificationPathMatrix, numNodes);\n  if(memcmp(pathDistanceMatrix, verificationPathDistanceMatrix, matrixSizeBytes) == 0)\n  {\n    printf(\"PASS\\n\");\n  }\n  else\n  {\n    printf(\"FAIL\\n\");\n    if (numNodes <= 8) \n    {\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"host: %u \", verificationPathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"device: %u \", pathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n    }\n  }\n\n  free(pathDistanceMatrix);\n  free(pathMatrix);\n  free(verificationPathDistanceMatrix);\n  free(verificationPathMatrix);\n  return 0;\n}\n"}}
{"kernel_name": "floydwarshall", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n\n#define MAXDISTANCE    (200)\n\n\n\nunsigned int minimum(unsigned int a, unsigned int b) \n{\n  return (b < a) ? b : a;\n}\n\n\n\nvoid floydWarshallCPUReference(unsigned int * pathDistanceMatrix,\n    unsigned int * pathMatrix, unsigned int numNodes)\n{\n  unsigned int distanceYtoX, distanceYtoK, distanceKtoX, indirectDistance;\n\n  \n\n  unsigned int width = numNodes;\n  unsigned int yXwidth;\n\n  \n\n\n  for(unsigned int k = 0; k < numNodes; ++k)\n  {\n    for(unsigned int y = 0; y < numNodes; ++y)\n    {\n      yXwidth =  y*numNodes;\n      for(unsigned int x = 0; x < numNodes; ++x)\n      {\n        distanceYtoX = pathDistanceMatrix[yXwidth + x];\n        distanceYtoK = pathDistanceMatrix[yXwidth + k];\n        distanceKtoX = pathDistanceMatrix[k * width + x];\n\n        indirectDistance = distanceYtoK + distanceKtoX;\n\n        if(indirectDistance < distanceYtoX)\n        {\n          pathDistanceMatrix[yXwidth + x] = indirectDistance;\n          pathMatrix[yXwidth + x]         = k;\n        }\n      }\n    }\n  }\n}\n\n\n\n\n\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of nodes> <iterations> <block size>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  unsigned int numNodes = atoi(argv[1]);\n  unsigned int numIterations = atoi(argv[2]);\n  unsigned int blockSize = atoi(argv[3]);\n\n  \n\n  if(numNodes % blockSize != 0) {\n    numNodes = (numNodes / blockSize + 1) * blockSize;\n  }\n\n  \n\n  unsigned int* pathMatrix = NULL;\n  unsigned int* pathDistanceMatrix = NULL;\n  unsigned int* verificationPathDistanceMatrix = NULL;\n  unsigned int* verificationPathMatrix = NULL;\n  unsigned int matrixSize;\n  unsigned int matrixSizeBytes;\n\n  matrixSize = numNodes * numNodes;\n  matrixSizeBytes = numNodes * numNodes * sizeof(unsigned int);\n  pathDistanceMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathDistanceMatrix != NULL) ;\n\n  pathMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathMatrix != NULL) ;\n\n  \n\n  srand(2);\n  for(unsigned int i = 0; i < numNodes; i++)\n    for(unsigned int j = 0; j < numNodes; j++)\n    {\n      int index = i*numNodes + j;\n      pathDistanceMatrix[index] = rand() % (MAXDISTANCE + 1);\n    }\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    unsigned int iXWidth = i * numNodes;\n    pathDistanceMatrix[iXWidth + i] = 0;\n  }\n\n  \n\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    for(unsigned int j = 0; j < i; ++j)\n    {\n      pathMatrix[i * numNodes + j] = i;\n      pathMatrix[j * numNodes + i] = j;\n    }\n    pathMatrix[i * numNodes + i] = i;\n  }\n\n  verificationPathDistanceMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (verificationPathDistanceMatrix != NULL);\n\n  verificationPathMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert(verificationPathMatrix != NULL);\n\n  memcpy(verificationPathDistanceMatrix, pathDistanceMatrix, matrixSizeBytes);\n  memcpy(verificationPathMatrix, pathMatrix, matrixSizeBytes);\n\n  unsigned int numPasses = numNodes;\n\n  #pragma omp target data map(alloc: pathDistanceMatrix[0:matrixSize], \\\n                                     pathMatrix[0:matrixSize])\n  {\n    float total_time = 0.f;\n\n    for (unsigned int n = 0; n < numIterations; n++) {\n      \n\n\n      #pragma omp target update to (pathDistanceMatrix[0:matrixSize]) \n\n      auto start = std::chrono::steady_clock::now();\n\n      for(unsigned int k = 0; k < numPasses; k++)\n      {\n        #pragma omp target teams distribute parallel for collapse(2) \\\n        thread_limit (blockSize*blockSize) nowait\n        for(unsigned int y = 0; y < numNodes; ++y)\n        {\n          for(unsigned int x = 0; x < numNodes; ++x)\n          {\n            unsigned int distanceYtoX = pathDistanceMatrix[y*numNodes + x];\n            unsigned int distanceYtoK = pathDistanceMatrix[y*numNodes + k];\n            unsigned int distanceKtoX = pathDistanceMatrix[k*numNodes + x];\n            unsigned int indirectDistance = distanceYtoK + distanceKtoX;\n\n            if(indirectDistance < distanceYtoX)\n            {\n              pathDistanceMatrix[y*numNodes + x] = indirectDistance;\n              pathMatrix[y*numNodes + x]         = k;\n            }\n          }\n        }\n      }\n      #pragma omp taskwait\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      total_time += time;\n    }\n\n    printf(\"Average kernel execution time %f (s)\\n\", (total_time * 1e-9f) / numIterations);\n\n    #pragma omp target update from (pathDistanceMatrix[0:matrixSize]) \n  }\n\n  \n\n  floydWarshallCPUReference(verificationPathDistanceMatrix,\n      verificationPathMatrix, numNodes);\n  if(memcmp(pathDistanceMatrix, verificationPathDistanceMatrix,\n        numNodes*numNodes*sizeof(unsigned int)) == 0)\n  {\n    printf(\"PASS\\n\");\n  }\n  else\n  {\n    printf(\"FAIL\\n\");\n    if (numNodes <= 8) \n    {\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"host: %u \", verificationPathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"device: %u \", pathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n    }\n  }\n\n  free(pathDistanceMatrix);\n  free(pathMatrix);\n  free(verificationPathDistanceMatrix);\n  free(verificationPathMatrix);\n  return 0;\n}\n"}}
{"kernel_name": "floydwarshall", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <string.h>\n#include <chrono>\n\n#define MAXDISTANCE    (200)\n\n\n\nunsigned int minimum(unsigned int a, unsigned int b) \n{\n  return (b < a) ? b : a;\n}\n\n\n\nvoid floydWarshallCPUReference(unsigned int * pathDistanceMatrix,\n    unsigned int * pathMatrix, unsigned int numNodes)\n{\n  unsigned int distanceYtoX, distanceYtoK, distanceKtoX, indirectDistance;\n\n  \n\n  unsigned int width = numNodes;\n  unsigned int yXwidth;\n\n  \n\n\n  for(unsigned int k = 0; k < numNodes; ++k)\n  {\n    for(unsigned int y = 0; y < numNodes; ++y)\n    {\n      yXwidth =  y*numNodes;\n      for(unsigned int x = 0; x < numNodes; ++x)\n      {\n        distanceYtoX = pathDistanceMatrix[yXwidth + x];\n        distanceYtoK = pathDistanceMatrix[yXwidth + k];\n        distanceKtoX = pathDistanceMatrix[k * width + x];\n\n        indirectDistance = distanceYtoK + distanceKtoX;\n\n        if(indirectDistance < distanceYtoX)\n        {\n          pathDistanceMatrix[yXwidth + x] = indirectDistance;\n          pathMatrix[yXwidth + x]         = k;\n        }\n      }\n    }\n  }\n}\n\n\n\n\n\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of nodes> <iterations> <block size>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  unsigned int numNodes = atoi(argv[1]);\n  unsigned int numIterations = atoi(argv[2]);\n  unsigned int blockSize = atoi(argv[3]);\n\n  \n\n  if(numNodes % blockSize != 0) {\n    numNodes = (numNodes / blockSize + 1) * blockSize;\n  }\n\n  \n\n  unsigned int* pathMatrix = NULL;\n  unsigned int* pathDistanceMatrix = NULL;\n  unsigned int* verificationPathDistanceMatrix = NULL;\n  unsigned int* verificationPathMatrix = NULL;\n  unsigned int matrixSize;\n  unsigned int matrixSizeBytes;\n\n  matrixSize = numNodes * numNodes;\n  matrixSizeBytes = numNodes * numNodes * sizeof(unsigned int);\n  pathDistanceMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathDistanceMatrix != NULL) ;\n\n  pathMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathMatrix != NULL) ;\n\n  \n\n  srand(2);\n  for(unsigned int i = 0; i < numNodes; i++)\n    for(unsigned int j = 0; j < numNodes; j++)\n    {\n      int index = i*numNodes + j;\n      pathDistanceMatrix[index] = rand() % (MAXDISTANCE + 1);\n    }\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    unsigned int iXWidth = i * numNodes;\n    pathDistanceMatrix[iXWidth + i] = 0;\n  }\n\n  \n\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    for(unsigned int j = 0; j < i; ++j)\n    {\n      pathMatrix[i * numNodes + j] = i;\n      pathMatrix[j * numNodes + i] = j;\n    }\n    pathMatrix[i * numNodes + i] = i;\n  }\n\n  verificationPathDistanceMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (verificationPathDistanceMatrix != NULL);\n\n  verificationPathMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert(verificationPathMatrix != NULL);\n\n  memcpy(verificationPathDistanceMatrix, pathDistanceMatrix, matrixSizeBytes);\n  memcpy(verificationPathMatrix, pathMatrix, matrixSizeBytes);\n\n  unsigned int numPasses = numNodes;\n\n    {\n    float total_time = 0.f;\n\n    for (unsigned int n = 0; n < numIterations; n++) {\n      \n\n\n      \n      auto start = std::chrono::steady_clock::now();\n\n      for(unsigned int k = 0; k < numPasses; k++)\n      {\n                for(unsigned int y = 0; y < numNodes; ++y)\n        {\n          for(unsigned int x = 0; x < numNodes; ++x)\n          {\n            unsigned int distanceYtoX = pathDistanceMatrix[y*numNodes + x];\n            unsigned int distanceYtoK = pathDistanceMatrix[y*numNodes + k];\n            unsigned int distanceKtoX = pathDistanceMatrix[k*numNodes + x];\n            unsigned int indirectDistance = distanceYtoK + distanceKtoX;\n\n            if(indirectDistance < distanceYtoX)\n            {\n              pathDistanceMatrix[y*numNodes + x] = indirectDistance;\n              pathMatrix[y*numNodes + x]         = k;\n            }\n          }\n        }\n      }\n      \n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      total_time += time;\n    }\n\n    printf(\"Average kernel execution time %f (s)\\n\", (total_time * 1e-9f) / numIterations);\n\n      }\n\n  \n\n  floydWarshallCPUReference(verificationPathDistanceMatrix,\n      verificationPathMatrix, numNodes);\n  if(memcmp(pathDistanceMatrix, verificationPathDistanceMatrix,\n        numNodes*numNodes*sizeof(unsigned int)) == 0)\n  {\n    printf(\"PASS\\n\");\n  }\n  else\n  {\n    printf(\"FAIL\\n\");\n    if (numNodes <= 8) \n    {\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"host: %u \", verificationPathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"device: %u \", pathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n    }\n  }\n\n  free(pathDistanceMatrix);\n  free(pathMatrix);\n  free(verificationPathDistanceMatrix);\n  free(verificationPathMatrix);\n  return 0;\n}"}}
{"kernel_name": "floydwarshall", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define MAXDISTANCE    (200)\n\n\n\nunsigned int minimum(unsigned int a, unsigned int b) \n{\n  return (b < a) ? b : a;\n}\n\n\n\nvoid floydWarshallCPUReference(unsigned int * pathDistanceMatrix,\n    unsigned int * pathMatrix, unsigned int numNodes)\n{\n  unsigned int distanceYtoX, distanceYtoK, distanceKtoX, indirectDistance;\n\n  \n\n  unsigned int width = numNodes;\n  unsigned int yXwidth;\n\n  \n\n  for(unsigned int k = 0; k < numNodes; ++k)\n  {\n    for(unsigned int y = 0; y < numNodes; ++y)\n    {\n      yXwidth =  y*numNodes;\n      for(unsigned int x = 0; x < numNodes; ++x)\n      {\n        distanceYtoX = pathDistanceMatrix[yXwidth + x];\n        distanceYtoK = pathDistanceMatrix[yXwidth + k];\n        distanceKtoX = pathDistanceMatrix[k * width + x];\n\n        indirectDistance = distanceYtoK + distanceKtoX;\n\n        if(indirectDistance < distanceYtoX)\n        {\n          pathDistanceMatrix[yXwidth + x] = indirectDistance;\n          pathMatrix[yXwidth + x]         = k;\n        }\n      }\n    }\n  }\n}\n\n\n\n\n\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <number of nodes> <iterations> <block size>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  unsigned int numNodes = atoi(argv[1]);\n  unsigned int numIterations = atoi(argv[2]);\n  unsigned int blockSize = atoi(argv[3]);\n\n  \n\n  if(numNodes % blockSize != 0) {\n    numNodes = (numNodes / blockSize + 1) * blockSize;\n  }\n\n  \n\n  unsigned int* pathMatrix = NULL;\n  unsigned int* pathDistanceMatrix = NULL;\n  unsigned int* verificationPathDistanceMatrix = NULL;\n  unsigned int* verificationPathMatrix = NULL;\n  unsigned int matrixSize;\n  unsigned int matrixSizeBytes;\n\n  matrixSize = numNodes * numNodes;\n  matrixSizeBytes = numNodes * numNodes * sizeof(unsigned int);\n  pathDistanceMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathDistanceMatrix != NULL) ;\n\n  pathMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (pathMatrix != NULL) ;\n\n  \n\n  srand(2);\n  for(unsigned int i = 0; i < numNodes; i++)\n    for(unsigned int j = 0; j < numNodes; j++)\n    {\n      int index = i*numNodes + j;\n      pathDistanceMatrix[index] = rand() % (MAXDISTANCE + 1);\n    }\n\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    unsigned int iXWidth = i * numNodes;\n    pathDistanceMatrix[iXWidth + i] = 0;\n  }\n\n  \n\n  for(unsigned int i = 0; i < numNodes; ++i)\n  {\n    for(unsigned int j = 0; j < i; ++j)\n    {\n      pathMatrix[i * numNodes + j] = i;\n      pathMatrix[j * numNodes + i] = j;\n    }\n    pathMatrix[i * numNodes + i] = i;\n  }\n\n  verificationPathDistanceMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert (verificationPathDistanceMatrix != NULL);\n\n  verificationPathMatrix = (unsigned int *) malloc(matrixSizeBytes);\n  assert(verificationPathMatrix != NULL);\n\n  memcpy(verificationPathDistanceMatrix, pathDistanceMatrix, matrixSizeBytes);\n  memcpy(verificationPathMatrix, pathMatrix, matrixSizeBytes);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  unsigned int numPasses = numNodes;\n\n  unsigned int globalThreads[2] = {numNodes, numNodes};\n  unsigned int localThreads[2] = {blockSize, blockSize};\n\n  if((unsigned int)(localThreads[0] * localThreads[0]) >256)\n  {\n    blockSize = 16;\n    localThreads[0] = blockSize;\n    localThreads[1] = blockSize;\n  }\n\n  sycl::range<2> gws (globalThreads[0], globalThreads[1]);\n  sycl::range<2> lws (localThreads[0], localThreads[1]);\n\n  unsigned int *pathDistanceBuffer = sycl::malloc_device<unsigned int>(matrixSize, q);\n  unsigned int *pathBuffer = sycl::malloc_device<unsigned int>(matrixSize, q);\n\n  float total_time = 0.f;\n\n  for (unsigned int n = 0; n < numIterations; n++) {\n    \n\n\n    q.memcpy(pathDistanceBuffer, pathDistanceMatrix, matrixSizeBytes);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for(unsigned int k = 0; k < numPasses; k++)\n    {\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class path_distance>(\n          sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n          int xValue = item.get_global_id(1);\n          int yValue = item.get_global_id(0); \n\n          int oldWeight = pathDistanceBuffer[yValue * numNodes + xValue];\n          int tempWeight = pathDistanceBuffer[yValue * numNodes + k] + \n                           pathDistanceBuffer[k * numNodes + xValue];\n\n          if (tempWeight < oldWeight)\n          {\n              pathDistanceBuffer[yValue * numNodes + xValue] = tempWeight;\n              pathBuffer[yValue * numNodes + xValue] = k;\n          }\n        });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    total_time += time;\n  }\n\n  printf(\"Average kernel execution time %f (s)\\n\", (total_time * 1e-9f) / numIterations);\n\n  q.memcpy(pathDistanceMatrix, pathDistanceBuffer, matrixSizeBytes).wait();\n  sycl::free(pathDistanceBuffer, q);\n  sycl::free(pathBuffer, q);\n\n  \n\n  floydWarshallCPUReference(verificationPathDistanceMatrix,\n      verificationPathMatrix, numNodes);\n  if(memcmp(pathDistanceMatrix, verificationPathDistanceMatrix,\n        numNodes*numNodes*sizeof(unsigned int)) == 0)\n  {\n    printf(\"PASS\\n\");\n  }\n  else\n  {\n    printf(\"FAIL\\n\");\n    if (numNodes <= 8) \n    {\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"host: %u \", verificationPathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n      for (unsigned int i = 0; i < numNodes; i++) {\n        for (unsigned int j = 0; j < numNodes; j++)\n          printf(\"device: %u \", pathDistanceMatrix[i*numNodes+j]);\n        printf(\"\\n\");\n      }\n    }\n  }\n\n  free(pathDistanceMatrix);\n  free(pathMatrix);\n  free(verificationPathDistanceMatrix);\n  free(verificationPathMatrix);\n  return 0;\n}\n"}}
{"kernel_name": "floydwarshall2", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n#include <cstdio>\n#include <limits>\n#include <sys/time.h>\n#include <cuda.h>\n#include \"graph.h\"\n\nusing mtype = int;\n\nstatic const int ws = 32; \n\nstatic const int tile = 64; \n\nstatic const int ThreadsPerBlock = ws * ws;\n\n\n\nstatic __global__ void init1(\n  const int nodes,\n  mtype* const AdjMat,\n  const int upper)\n{\n  const int idx = threadIdx.x + blockIdx.x * blockDim.x;\n  const int i = idx / upper;\n  if (i < upper) {\n    const int j = idx % upper;\n    AdjMat[idx] = ((i == j) && (i < nodes)) ? 0 : (INT_MAX / 2);\n  }\n}\n\n\n\nstatic __global__ void init2(\n  const ECLgraph g,\n  mtype* const AdjMat,\n  const int upper)\n{\n  const int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if (i < g.nodes) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      const int nei = g.nlist[j];\n      AdjMat[i * upper + nei] = g.eweight[j];\n    }\n  }\n}\n\n\n\nstatic __global__ __launch_bounds__(ThreadsPerBlock, 1)\nvoid FW0_64(\n  mtype* const __restrict__ AdjMat,\n  const int upper,\n  mtype* const __restrict__ krows,\n  mtype* const __restrict__ kcols)\n{\n  __shared__ mtype temp[tile * tile];\n  __shared__ mtype krow[tile * tile];\n\n  const int warp_a = threadIdx.x / ws; \n\n  const int warp_b = warp_a + ws; \n\n  const int lane_a = threadIdx.x % ws; \n\n  const int lane_b = lane_a + ws; \n\n\n  const int idx0_aa = warp_a * upper + lane_a; \n\n  const int idx0_ab = warp_a * upper + lane_b; \n\n  const int idx0_ba = warp_b * upper + lane_a; \n\n  const int idx0_bb = warp_b * upper + lane_b; \n\n\n  const int idx1_aa = lane_a * tile + warp_a;\n  const int idx1_ab = lane_b * tile + warp_a;\n  const int idx1_ba = lane_a * tile + warp_b;\n  const int idx1_bb = lane_b * tile + warp_b;\n\n  int idx2_a = lane_a;\n  int idx2_b = lane_b;\n\n  mtype ij_aa = AdjMat[idx0_aa];\n  mtype ij_ab = AdjMat[idx0_ab];\n  mtype ij_ba = AdjMat[idx0_ba];\n  mtype ij_bb = AdjMat[idx0_bb];\n\n  #pragma unroll 64\n  for (int k = 0; k < tile; k++) {\n    if (warp_a == k) krow[idx2_a] = ij_aa;\n    if (warp_a == k) krow[idx2_b] = ij_ab;\n    if (warp_b == k) krow[idx2_a] = ij_ba;\n    if (warp_b == k) krow[idx2_b] = ij_bb;\n    __syncthreads();\n\n    mtype ik_a, ik_b;\n    if (k < ws) {\n      ik_a = __shfl_sync(~0, ij_aa, k);\n      ik_b = __shfl_sync(~0, ij_ba, k);\n    } else {\n      ik_a = __shfl_sync(~0, ij_ab, k - ws);\n      ik_b = __shfl_sync(~0, ij_bb, k - ws);\n    }\n\n    const mtype kr_a = krow[idx2_a];\n    const mtype kr_b = krow[idx2_b];\n\n    ij_aa = min(ij_aa, ik_a + kr_a);\n    ij_ab = min(ij_ab, ik_a + kr_b);\n    ij_ba = min(ij_ba, ik_b + kr_a);\n    ij_bb = min(ij_bb, ik_b + kr_b);\n\n    if (warp_a == k) krows[idx0_aa] = ij_aa;\n    if (warp_a == k) krows[idx0_ab] = ij_ab;\n    if (warp_b == k) krows[idx0_ba] = ij_ba;\n    if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n    if (lane_a == k) temp[idx1_aa] = ij_aa;\n    if (lane_a == k) temp[idx1_ba] = ij_ba;\n    if (lane_b == k) temp[idx1_ab] = ij_ab;\n    if (lane_b == k) temp[idx1_bb] = ij_bb;\n\n    idx2_a += tile;\n    idx2_b += tile;\n  }\n\n  __syncthreads();\n  kcols[idx0_aa] = temp[warp_a * tile + lane_a];\n  kcols[idx0_ab] = temp[warp_a * tile + lane_b];\n  kcols[idx0_ba] = temp[warp_b * tile + lane_a];\n  kcols[idx0_bb] = temp[warp_b * tile + lane_b];\n  AdjMat[idx0_aa] = ij_aa;\n  AdjMat[idx0_ab] = ij_ab;\n  AdjMat[idx0_ba] = ij_ba;\n  AdjMat[idx0_bb] = ij_bb;\n}\n\n\n\nstatic __global__ __launch_bounds__(ThreadsPerBlock, 2048 / ThreadsPerBlock)\nvoid FWrowcol_64(\n  mtype* const __restrict__ AdjMat,\n  const int upper,\n  mtype* const __restrict__ krows,\n  mtype* const __restrict__ kcols,\n  const int x, const int subm1)\n{\n  __shared__ mtype temp[tile * tile];\n  __shared__ mtype krow[tile * tile];\n\n  const int warp_a = threadIdx.x / ws; \n\n  const int warp_b = warp_a + ws; \n\n  const int lane_a = threadIdx.x % ws; \n\n  const int lane_b = lane_a + ws; \n\n\n  int y = blockIdx.x;\n\n  if (y < subm1) {\n    if (y >= x) y++;\n    const int i_a = warp_a + x * tile;\n    const int i_b = warp_b + x * tile;\n    const int j_a = lane_a + y * tile;\n    const int j_b = lane_b + y * tile;\n\n    const int idx0_aa = i_a * upper + j_a;\n    const int idx0_ab = i_a * upper + j_b;\n    const int idx0_ba = i_b * upper + j_a;\n    const int idx0_bb = i_b * upper + j_b;\n\n    int idx1_a = warp_a;\n    int idx1_b = warp_b;\n    int idx2_a = lane_a;\n    int idx2_b = lane_b;\n\n    temp[warp_a * tile + lane_a] = kcols[i_a * upper + lane_a + x * tile];\n    temp[warp_a * tile + lane_b] = kcols[i_a * upper + lane_b + x * tile];\n    temp[warp_b * tile + lane_a] = kcols[i_b * upper + lane_a + x * tile];\n    temp[warp_b * tile + lane_b] = kcols[i_b * upper + lane_b + x * tile];\n    __syncthreads();\n\n    mtype ij_aa = AdjMat[idx0_aa];\n    mtype ij_ab = AdjMat[idx0_ab];\n    mtype ij_ba = AdjMat[idx0_ba];\n    mtype ij_bb = AdjMat[idx0_bb];\n\n    const mtype orig_aa = ij_aa;\n    const mtype orig_ab = ij_ab;\n    const mtype orig_ba = ij_ba;\n    const mtype orig_bb = ij_bb;\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      if (warp_a == k) krow[idx2_a] = ij_aa;\n      if (warp_a == k) krow[idx2_b] = ij_ab;\n      if (warp_b == k) krow[idx2_a] = ij_ba;\n      if (warp_b == k) krow[idx2_b] = ij_bb;\n      __syncthreads();\n\n      const mtype ik_a = temp[idx1_a];\n      const mtype ik_b = temp[idx1_b];\n      const mtype kr_a = krow[idx2_a];\n      const mtype kr_b = krow[idx2_b];\n\n      ij_aa = min(ij_aa, ik_a + kr_a);\n      ij_ab = min(ij_ab, ik_a + kr_b);\n      ij_ba = min(ij_ba, ik_b + kr_a);\n      ij_bb = min(ij_bb, ik_b + kr_b);\n\n      if (warp_a == k) krows[idx0_aa] = ij_aa;\n      if (warp_a == k) krows[idx0_ab] = ij_ab;\n      if (warp_b == k) krows[idx0_ba] = ij_ba;\n      if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n      idx1_a += tile;\n      idx1_b += tile;\n      idx2_a += tile;\n      idx2_b += tile;\n    }\n    if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n    if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n    if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n    if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n  } else {\n    y -= subm1;\n    if (y >= x) y++;\n    const int i_a = warp_a + y * tile;\n    const int i_b = warp_b + y * tile;\n\n    const int j_a = lane_a + x * tile;\n    const int j_b = lane_b + x * tile;\n\n    const int idx0_aa = i_a * upper + j_a;\n    const int idx0_ab = i_a * upper + j_b;\n    const int idx0_ba = i_b * upper + j_a;\n    const int idx0_bb = i_b * upper + j_b;\n\n    const int idx1_aa = lane_a * tile + warp_a;\n    const int idx1_ab = lane_b * tile + warp_a;\n    const int idx1_ba = lane_a * tile + warp_b;\n    const int idx1_bb = lane_b * tile + warp_b;\n\n    int idx2_a = (x * tile) * upper + j_a;\n    int idx2_b = (x * tile) * upper + j_b;\n\n    mtype ij_aa = AdjMat[idx0_aa];\n    mtype ij_ab = AdjMat[idx0_ab];\n    mtype ij_ba = AdjMat[idx0_ba];\n    mtype ij_bb = AdjMat[idx0_bb];\n\n    const mtype orig_aa = ij_aa;\n    const mtype orig_ab = ij_ab;\n    const mtype orig_ba = ij_ba;\n    const mtype orig_bb = ij_bb;\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      mtype ik_a, ik_b;\n      if (k < ws) {\n        ik_a = __shfl_sync(~0, ij_aa, k);\n        ik_b = __shfl_sync(~0, ij_ba, k);\n      }\n      if (k >= ws) {\n        ik_a = __shfl_sync(~0, ij_ab, k - ws);\n        ik_b = __shfl_sync(~0, ij_bb, k - ws);\n      }\n      const mtype kr_a = krows[idx2_a];\n      const mtype kr_b = krows[idx2_b];\n\n      ij_aa = min(ij_aa, ik_a + kr_a);\n      ij_ab = min(ij_ab, ik_a + kr_b);\n      ij_ba = min(ij_ba, ik_b + kr_a);\n      ij_bb = min(ij_bb, ik_b + kr_b);\n\n      if (lane_a == k) temp[idx1_aa] = ij_aa;\n      if (lane_a == k) temp[idx1_ba] = ij_ba;\n      if (lane_b == k) temp[idx1_ab] = ij_ab;\n      if (lane_b == k) temp[idx1_bb] = ij_bb;\n\n      idx2_a += upper;\n      idx2_b += upper;\n    }\n    __syncthreads();\n\n    kcols[idx0_aa] = temp[warp_a * tile + lane_a];\n    kcols[idx0_ab] = temp[warp_a * tile + lane_b];\n    kcols[idx0_ba] = temp[warp_b * tile + lane_a];\n    kcols[idx0_bb] = temp[warp_b * tile + lane_b];\n\n    if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n    if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n    if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n    if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n  }\n}\n\n\n\nstatic __global__ __launch_bounds__(ThreadsPerBlock, 2048 / ThreadsPerBlock)\nvoid FWrem_64(\n  mtype* const __restrict__ AdjMat, \n  const int upper,\n  mtype* const __restrict__ krows,\n  mtype* const __restrict__ kcols,\n  const int x, const int subm1)\n{\n  int y = blockIdx.x / subm1;\n  int z = blockIdx.x % subm1;\n  if (y >= x) y++;\n  if (z >= x) z++;\n\n  const int warp_a = threadIdx.x / ws;\n  const int warp_b = warp_a + ws;\n\n  const int lane_a = threadIdx.x % ws;\n  const int lane_b = lane_a + ws;\n\n  const int i_a = warp_a + y * tile;\n  const int i_b = warp_b + y * tile;\n  const int j_a = lane_a + z * tile;\n  const int j_b = lane_b + z * tile;\n\n  const int idx0_aa = i_a * upper + j_a; \n\n  const int idx0_ab = i_a * upper + j_b; \n\n  const int idx0_ba = i_b * upper + j_a; \n\n  const int idx0_bb = i_b * upper + j_b; \n\n\n  __shared__ mtype s_kj[tile * tile];\n  __shared__ mtype s_ik[tile * tile];\n\n  s_kj[warp_a * tile + lane_a] = krows[(x * tile + warp_a) * upper + j_a];\n  s_kj[warp_a * tile + lane_b] = krows[(x * tile + warp_a) * upper + j_b];\n  s_kj[warp_b * tile + lane_a] = krows[(x * tile + warp_b) * upper + j_a];\n  s_kj[warp_b * tile + lane_b] = krows[(x * tile + warp_b) * upper + j_b];\n\n  s_ik[warp_a * tile + lane_a] = kcols[i_a * upper + lane_a + x * tile];\n  s_ik[warp_a * tile + lane_b] = kcols[i_a * upper + lane_b + x * tile];\n  s_ik[warp_b * tile + lane_a] = kcols[i_b * upper + lane_a + x * tile];\n  s_ik[warp_b * tile + lane_b] = kcols[i_b * upper + lane_b + x * tile];\n\n  mtype ij_aa = AdjMat[idx0_aa];\n  mtype ij_ab = AdjMat[idx0_ab];\n  mtype ij_ba = AdjMat[idx0_ba];\n  mtype ij_bb = AdjMat[idx0_bb];\n\n  const mtype orig_aa = ij_aa;\n  const mtype orig_ab = ij_ab;\n  const mtype orig_ba = ij_ba;\n  const mtype orig_bb = ij_bb;\n\n  __syncthreads();\n  int idx1_a = warp_a;\n  int idx1_b = warp_b;\n\n  int idx2_a = lane_a;\n  int idx2_b = lane_b;\n\n  #pragma unroll 64\n  for (int k = 0; k < tile; k++) {\n    const mtype sk_a = s_kj[idx2_a];\n    const mtype sk_b = s_kj[idx2_b];\n\n    ij_aa = min(ij_aa, s_ik[idx1_a] + sk_a);\n    ij_ab = min(ij_ab, s_ik[idx1_a] + sk_b);\n    ij_ba = min(ij_ba, s_ik[idx1_b] + sk_a);\n    ij_bb = min(ij_bb, s_ik[idx1_b] + sk_b);\n\n    idx1_a += tile;\n    idx1_b += tile;\n\n    idx2_a += tile;\n    idx2_b += tile;\n  }\n\n  if ((y == z) && (y == x + 1) && (x != subm1)) { \n\n    const int idx1_aa = lane_a * tile + warp_a;\n    const int idx1_ab = lane_b * tile + warp_a;\n    const int idx1_ba = lane_a * tile + warp_b;\n    const int idx1_bb = lane_b * tile + warp_b;\n\n    int idx2_a = lane_a;\n    int idx2_b = lane_b;\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      if (warp_a == k) s_kj[idx2_a] = ij_aa;\n      if (warp_a == k) s_kj[idx2_b] = ij_ab;\n      if (warp_b == k) s_kj[idx2_a] = ij_ba;\n      if (warp_b == k) s_kj[idx2_b] = ij_bb;\n      __syncthreads();\n\n      mtype ik_a, ik_b;\n      if (k < ws) {\n        ik_a = __shfl_sync(~0, ij_aa, k);\n        ik_b = __shfl_sync(~0, ij_ba, k);\n      }\n      else {\n        ik_a = __shfl_sync(~0, ij_ab, k - ws);\n        ik_b = __shfl_sync(~0, ij_bb, k - ws);\n      }\n\n      const mtype sk_a = s_kj[idx2_a];\n      const mtype sk_b = s_kj[idx2_b];\n\n      ij_aa = min(ij_aa, ik_a + sk_a);\n      ij_ab = min(ij_ab, ik_a + sk_b);\n      ij_ba = min(ij_ba, ik_b + sk_a);\n      ij_bb = min(ij_bb, ik_b + sk_b);\n\n      if (warp_a == k) krows[idx0_aa] = ij_aa;\n      if (warp_a == k) krows[idx0_ab] = ij_ab;\n      if (warp_b == k) krows[idx0_ba] = ij_ba;\n      if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n      if (lane_a == k) s_ik[idx1_aa] = ij_aa;\n      if (lane_a == k) s_ik[idx1_ba] = ij_ba;\n      if (lane_b == k) s_ik[idx1_ab] = ij_ab;\n      if (lane_b == k) s_ik[idx1_bb] = ij_bb;\n      idx2_a += tile;\n      idx2_b += tile;\n    }\n    __syncthreads();\n\n    kcols[idx0_aa] = s_ik[warp_a * tile + lane_a];\n    kcols[idx0_ab] = s_ik[warp_a * tile + lane_b];\n    kcols[idx0_ba] = s_ik[warp_b * tile + lane_a];\n    kcols[idx0_bb] = s_ik[warp_b * tile + lane_b];\n  }\n\n  if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n  if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n  if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n  if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n}\n\nstatic void FW_gpu_64(const ECLgraph g, mtype* const AdjMat, const int repeat)\n{\n  \n\n  ECLgraph d_g = g;\n  cudaMalloc((void **)&d_g.nindex, sizeof(int) * (g.nodes + 1));\n  cudaMalloc((void **)&d_g.nlist, sizeof(int) * g.edges);\n  cudaMalloc((void **)&d_g.eweight, sizeof(int) * g.edges);\n  cudaMemcpy(d_g.nindex, g.nindex, sizeof(int) * (g.nodes + 1), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_g.nlist, g.nlist, sizeof(int) * g.edges, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_g.eweight, g.eweight, sizeof(int) * g.edges, cudaMemcpyHostToDevice);\n\n  \n\n  const int sub = (g.nodes + tile - 1) / tile;\n\n  const int upper = sub * tile; \n\n  mtype* d_AdjMat;\n  if (cudaSuccess != cudaMalloc((void **)&d_AdjMat, sizeof(mtype) * upper * upper))\n    fprintf(stderr, \"ERROR: could not allocate memory\\n\");\n\n  mtype* d_krows;\n  if (cudaSuccess != cudaMalloc((void **)&d_krows, sizeof(mtype) * upper * upper))\n    fprintf(stderr, \"ERROR: could not allocate memory\\n\");\n\n  mtype* d_kcols;\n  if (cudaSuccess != cudaMalloc((void **)&d_kcols, sizeof(mtype) * upper * upper))\n    fprintf(stderr, \"ERROR: could not allocate memory\\n\");\n\n  printf(\"GPU matrix size: %.1f MB\\n\", sizeof(mtype) * upper * upper / (1024.0 * 1024.0));\n\n  timeval start, end;\n\n  cudaDeviceSynchronize();\n  gettimeofday(&start, NULL);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    init1<<<(upper * upper + ThreadsPerBlock - 1) / ThreadsPerBlock, ThreadsPerBlock>>>(g.nodes, d_AdjMat, upper);\n    init2<<<(g.nodes + ThreadsPerBlock - 1) / ThreadsPerBlock, ThreadsPerBlock>>>(d_g, d_AdjMat, upper);\n  }\n\n  cudaDeviceSynchronize();\n  gettimeofday(&end, NULL);\n  const double inittime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"Average kernel (initialization) time: %10.6f s\\n\", inittime / repeat);\n\n  const int subm1 = sub - 1;\n  gettimeofday(&start, NULL);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    FW0_64<<<1, ThreadsPerBlock>>>(d_AdjMat, upper, d_krows, d_kcols);\n\n    if (sub > 1) {\n      for (int x = 0; x < sub; x++) {\n        FWrowcol_64<<<2 * subm1, ThreadsPerBlock>>>(d_AdjMat, upper, d_krows, d_kcols, x, subm1);\n        FWrem_64<<<subm1 * subm1, ThreadsPerBlock>>>(d_AdjMat, upper, d_krows, d_kcols, x, subm1);\n      }\n    }\n  }\n  cudaDeviceSynchronize();\n  gettimeofday(&end, NULL);\n  const double comptime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"Average kernel (compute) time: %10.6f s\\n\", comptime / repeat);\n\n  \n\n  if (cudaSuccess != cudaMemcpy(AdjMat, d_AdjMat, sizeof(mtype) * upper * upper, cudaMemcpyDeviceToHost))\n    fprintf(stderr, \"ERROR: copying from device failed\\n\");\n\n  \n\n  cudaFree(d_g.nindex);\n  cudaFree(d_g.nlist);\n  cudaFree(d_g.eweight);\n  cudaFree(d_AdjMat);\n  cudaFree(d_krows);\n  cudaFree(d_kcols);\n}\n\nstatic void FW_cpu(const ECLgraph g, mtype* const AdjMat)\n{\n  timeval start, end;\n  gettimeofday(&start, NULL);\n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = 0; j < g.nodes; j++) {\n      AdjMat[i * g.nodes + j] = ((i == j) ? 0 : (INT_MAX / 2));\n    }\n  }\n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      const int nei = g.nlist[j];\n      AdjMat[i * g.nodes + nei] = g.eweight[j];\n    }\n  }\n\n  gettimeofday(&end, NULL);\n  const double inittime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"CPU init time: %10.6f s\\n\", inittime);\n\n  gettimeofday(&start, NULL);\n\n  for (int k = 0; k < g.nodes; k++) {\n    for (int i = 0; i < g.nodes; i++) {\n      for (int j = 0; j < g.nodes; j++) {\n        if (AdjMat[i * g.nodes + j] > AdjMat[i * g.nodes + k] + AdjMat[k * g.nodes + j]) {\n          AdjMat[i * g.nodes + j] = AdjMat[i * g.nodes + k] + AdjMat[k * g.nodes + j];\n        }\n      }\n    }\n  }\n\n  gettimeofday(&end, NULL);\n  const double comptime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"CPU comp time: %10.6f s\\n\", comptime);\n}\n\nint main(int argc, char* argv[])\n{\n  printf(\"ECL-APSP v1.0 (%s)\\n\", __FILE__);\n  printf(\"Copyright 2021 Texas State University\\n\");\n  if (argc != 3) {\n    fprintf(stderr, \"USAGE: %s <input_graph_name> <repeat>\\n\\n\", argv[0]);\n    return 1;\n  }\n  if (ThreadsPerBlock != 1024) {\n    fprintf(stderr, \"Threads per block must be 1024\\n\\n\");\n    return 1;\n  }\n\n  \n\n  mtype* AdjMat1 = NULL;\n  mtype* AdjMat2 = NULL;\n\n  \n\n  int upper_64;\n  int diffcount;\n  int gn;\n\n  \n\n  ECLgraph g = readECLgraph(argv[1]);\n  printf(\"input: %s\\n\", argv[1]);\n  printf(\"nodes: %d\\n\", g.nodes);\n  printf(\"edges: %d\\n\", g.edges);\n\n  const int repeat = atoi(argv[2]);\n\n  if (g.eweight == NULL) {\n    fprintf(stderr, \"ERROR: input graph has no edge weights\\n\\n\");\n    goto DONE;\n  }\n\n  \n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      if (g.eweight[j] < 0) g.eweight[j] = -g.eweight[j];\n    }\n  }\n\n  \n\n  upper_64 = ((g.nodes + tile - 1) / tile) * tile;  \n\n  AdjMat1 = (mtype*) malloc (sizeof(mtype) * upper_64 * upper_64);\n  if (AdjMat1 == NULL) {\n    fprintf(stderr, \"ERROR: memory allocation (AdjMat1) fails\\n\\n\");\n    goto DONE;\n  }\n    \n  FW_gpu_64(g, AdjMat1, repeat);\n\n  \n\n  AdjMat2 = (mtype*) malloc (sizeof(mtype) * g.nodes * g.nodes);\n  if (AdjMat2 == NULL) {\n    fprintf(stderr, \"ERROR: memory allocation (AdjMat2) fails\\n\\n\");\n    goto DONE;\n  }\n\n  FW_cpu(g, AdjMat2);\n\n  \n\n  diffcount = 0;\n  gn = g.nodes;\n  for (int i = 0; i < gn; ++i) {\n    for (int j = 0; j < gn; ++j) {\n      if (AdjMat1[i * upper_64 + j] != AdjMat2[i * g.nodes + j]) {\n        diffcount++;\n      }\n    }\n  }\n\n  if (diffcount > 0) {\n    printf(\"ERROR: results differ in %d places!\\n\", diffcount);\n  } else {\n    printf(\"results match\\n\");\n  }\n\n  DONE:\n  \n\n  if (AdjMat1) free(AdjMat1);\n  if (AdjMat2) free(AdjMat2);\n  freeECLgraph(g);\n  return 0;\n}\n"}}
{"kernel_name": "floydwarshall2", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n#include <cstdio>\n#include <limits>\n#include <sys/time.h>\n#include <hip/hip_runtime.h>\n#include \"graph.h\"\n\nusing mtype = int;\n\nstatic const int ws = 32; \n\nstatic const int tile = 64; \n\nstatic const int ThreadsPerBlock = ws * ws;\n\n\n\nstatic __global__ void init1(\n  const int nodes,\n  mtype* const AdjMat,\n  const int upper)\n{\n  const int idx = threadIdx.x + blockIdx.x * blockDim.x;\n  const int i = idx / upper;\n  if (i < upper) {\n    const int j = idx % upper;\n    AdjMat[idx] = ((i == j) && (i < nodes)) ? 0 : (INT_MAX / 2);\n  }\n}\n\n\n\nstatic __global__ void init2(\n  const ECLgraph g,\n  mtype* const AdjMat,\n  const int upper)\n{\n  const int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if (i < g.nodes) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      const int nei = g.nlist[j];\n      AdjMat[i * upper + nei] = g.eweight[j];\n    }\n  }\n}\n\n\n\nstatic __global__ __launch_bounds__(ThreadsPerBlock, 1)\nvoid FW0_64(\n  mtype* const __restrict__ AdjMat,\n  const int upper,\n  mtype* const __restrict__ krows,\n  mtype* const __restrict__ kcols)\n{\n  __shared__ mtype temp[tile * tile];\n  __shared__ mtype krow[tile * tile];\n\n  const int warp_a = threadIdx.x / ws; \n\n  const int warp_b = warp_a + ws; \n\n  const int lane_a = threadIdx.x % ws; \n\n  const int lane_b = lane_a + ws; \n\n\n  const int idx0_aa = warp_a * upper + lane_a; \n\n  const int idx0_ab = warp_a * upper + lane_b; \n\n  const int idx0_ba = warp_b * upper + lane_a; \n\n  const int idx0_bb = warp_b * upper + lane_b; \n\n\n  const int idx1_aa = lane_a * tile + warp_a;\n  const int idx1_ab = lane_b * tile + warp_a;\n  const int idx1_ba = lane_a * tile + warp_b;\n  const int idx1_bb = lane_b * tile + warp_b;\n\n  int idx2_a = lane_a;\n  int idx2_b = lane_b;\n\n  mtype ij_aa = AdjMat[idx0_aa];\n  mtype ij_ab = AdjMat[idx0_ab];\n  mtype ij_ba = AdjMat[idx0_ba];\n  mtype ij_bb = AdjMat[idx0_bb];\n\n  #pragma unroll 64\n  for (int k = 0; k < tile; k++) {\n    if (warp_a == k) krow[idx2_a] = ij_aa;\n    if (warp_a == k) krow[idx2_b] = ij_ab;\n    if (warp_b == k) krow[idx2_a] = ij_ba;\n    if (warp_b == k) krow[idx2_b] = ij_bb;\n    __syncthreads();\n\n    mtype ik_a, ik_b;\n    if (k < ws) {\n      ik_a = __shfl(ij_aa, k, ws);\n      ik_b = __shfl(ij_ba, k, ws);\n    } else {\n      ik_a = __shfl(ij_ab, k - ws, ws);\n      ik_b = __shfl(ij_bb, k - ws, ws);\n    }\n\n    const mtype kr_a = krow[idx2_a];\n    const mtype kr_b = krow[idx2_b];\n\n    ij_aa = min(ij_aa, ik_a + kr_a);\n    ij_ab = min(ij_ab, ik_a + kr_b);\n    ij_ba = min(ij_ba, ik_b + kr_a);\n    ij_bb = min(ij_bb, ik_b + kr_b);\n\n    if (warp_a == k) krows[idx0_aa] = ij_aa;\n    if (warp_a == k) krows[idx0_ab] = ij_ab;\n    if (warp_b == k) krows[idx0_ba] = ij_ba;\n    if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n    if (lane_a == k) temp[idx1_aa] = ij_aa;\n    if (lane_a == k) temp[idx1_ba] = ij_ba;\n    if (lane_b == k) temp[idx1_ab] = ij_ab;\n    if (lane_b == k) temp[idx1_bb] = ij_bb;\n\n    idx2_a += tile;\n    idx2_b += tile;\n  }\n\n  __syncthreads();\n  kcols[idx0_aa] = temp[warp_a * tile + lane_a];\n  kcols[idx0_ab] = temp[warp_a * tile + lane_b];\n  kcols[idx0_ba] = temp[warp_b * tile + lane_a];\n  kcols[idx0_bb] = temp[warp_b * tile + lane_b];\n  AdjMat[idx0_aa] = ij_aa;\n  AdjMat[idx0_ab] = ij_ab;\n  AdjMat[idx0_ba] = ij_ba;\n  AdjMat[idx0_bb] = ij_bb;\n}\n\n\n\nstatic __global__ __launch_bounds__(ThreadsPerBlock, 2048 / ThreadsPerBlock)\nvoid FWrowcol_64(\n  mtype* const __restrict__ AdjMat,\n  const int upper,\n  mtype* const __restrict__ krows,\n  mtype* const __restrict__ kcols,\n  const int x, const int subm1)\n{\n  __shared__ mtype temp[tile * tile];\n  __shared__ mtype krow[tile * tile];\n\n  const int warp_a = threadIdx.x / ws; \n\n  const int warp_b = warp_a + ws; \n\n  const int lane_a = threadIdx.x % ws; \n\n  const int lane_b = lane_a + ws; \n\n\n  int y = blockIdx.x;\n\n  if (y < subm1) {\n    if (y >= x) y++;\n    const int i_a = warp_a + x * tile;\n    const int i_b = warp_b + x * tile;\n    const int j_a = lane_a + y * tile;\n    const int j_b = lane_b + y * tile;\n\n    const int idx0_aa = i_a * upper + j_a;\n    const int idx0_ab = i_a * upper + j_b;\n    const int idx0_ba = i_b * upper + j_a;\n    const int idx0_bb = i_b * upper + j_b;\n\n    int idx1_a = warp_a;\n    int idx1_b = warp_b;\n    int idx2_a = lane_a;\n    int idx2_b = lane_b;\n\n    temp[warp_a * tile + lane_a] = kcols[i_a * upper + lane_a + x * tile];\n    temp[warp_a * tile + lane_b] = kcols[i_a * upper + lane_b + x * tile];\n    temp[warp_b * tile + lane_a] = kcols[i_b * upper + lane_a + x * tile];\n    temp[warp_b * tile + lane_b] = kcols[i_b * upper + lane_b + x * tile];\n    __syncthreads();\n\n    mtype ij_aa = AdjMat[idx0_aa];\n    mtype ij_ab = AdjMat[idx0_ab];\n    mtype ij_ba = AdjMat[idx0_ba];\n    mtype ij_bb = AdjMat[idx0_bb];\n\n    const mtype orig_aa = ij_aa;\n    const mtype orig_ab = ij_ab;\n    const mtype orig_ba = ij_ba;\n    const mtype orig_bb = ij_bb;\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      if (warp_a == k) krow[idx2_a] = ij_aa;\n      if (warp_a == k) krow[idx2_b] = ij_ab;\n      if (warp_b == k) krow[idx2_a] = ij_ba;\n      if (warp_b == k) krow[idx2_b] = ij_bb;\n      __syncthreads();\n\n      const mtype ik_a = temp[idx1_a];\n      const mtype ik_b = temp[idx1_b];\n      const mtype kr_a = krow[idx2_a];\n      const mtype kr_b = krow[idx2_b];\n\n      ij_aa = min(ij_aa, ik_a + kr_a);\n      ij_ab = min(ij_ab, ik_a + kr_b);\n      ij_ba = min(ij_ba, ik_b + kr_a);\n      ij_bb = min(ij_bb, ik_b + kr_b);\n\n      if (warp_a == k) krows[idx0_aa] = ij_aa;\n      if (warp_a == k) krows[idx0_ab] = ij_ab;\n      if (warp_b == k) krows[idx0_ba] = ij_ba;\n      if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n      idx1_a += tile;\n      idx1_b += tile;\n      idx2_a += tile;\n      idx2_b += tile;\n    }\n    if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n    if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n    if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n    if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n  } else {\n    y -= subm1;\n    if (y >= x) y++;\n    const int i_a = warp_a + y * tile;\n    const int i_b = warp_b + y * tile;\n\n    const int j_a = lane_a + x * tile;\n    const int j_b = lane_b + x * tile;\n\n    const int idx0_aa = i_a * upper + j_a;\n    const int idx0_ab = i_a * upper + j_b;\n    const int idx0_ba = i_b * upper + j_a;\n    const int idx0_bb = i_b * upper + j_b;\n\n    const int idx1_aa = lane_a * tile + warp_a;\n    const int idx1_ab = lane_b * tile + warp_a;\n    const int idx1_ba = lane_a * tile + warp_b;\n    const int idx1_bb = lane_b * tile + warp_b;\n\n    int idx2_a = (x * tile) * upper + j_a;\n    int idx2_b = (x * tile) * upper + j_b;\n\n    mtype ij_aa = AdjMat[idx0_aa];\n    mtype ij_ab = AdjMat[idx0_ab];\n    mtype ij_ba = AdjMat[idx0_ba];\n    mtype ij_bb = AdjMat[idx0_bb];\n\n    const mtype orig_aa = ij_aa;\n    const mtype orig_ab = ij_ab;\n    const mtype orig_ba = ij_ba;\n    const mtype orig_bb = ij_bb;\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      mtype ik_a, ik_b;\n      if (k < ws) {\n        ik_a = __shfl(ij_aa, k, ws);\n        ik_b = __shfl(ij_ba, k, ws);\n      }\n      else {\n        ik_a = __shfl(ij_ab, k - ws, ws);\n        ik_b = __shfl(ij_bb, k - ws, ws);\n      }\n      const mtype kr_a = krows[idx2_a];\n      const mtype kr_b = krows[idx2_b];\n\n      ij_aa = min(ij_aa, ik_a + kr_a);\n      ij_ab = min(ij_ab, ik_a + kr_b);\n      ij_ba = min(ij_ba, ik_b + kr_a);\n      ij_bb = min(ij_bb, ik_b + kr_b);\n\n      if (lane_a == k) temp[idx1_aa] = ij_aa;\n      if (lane_a == k) temp[idx1_ba] = ij_ba;\n      if (lane_b == k) temp[idx1_ab] = ij_ab;\n      if (lane_b == k) temp[idx1_bb] = ij_bb;\n\n      idx2_a += upper;\n      idx2_b += upper;\n    }\n    __syncthreads();\n\n    kcols[idx0_aa] = temp[warp_a * tile + lane_a];\n    kcols[idx0_ab] = temp[warp_a * tile + lane_b];\n    kcols[idx0_ba] = temp[warp_b * tile + lane_a];\n    kcols[idx0_bb] = temp[warp_b * tile + lane_b];\n\n    if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n    if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n    if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n    if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n  }\n}\n\n\n\nstatic __global__ __launch_bounds__(ThreadsPerBlock, 2048 / ThreadsPerBlock)\nvoid FWrem_64(\n  mtype* const __restrict__ AdjMat, \n  const int upper,\n  mtype* const __restrict__ krows,\n  mtype* const __restrict__ kcols,\n  const int x, const int subm1)\n{\n  int y = blockIdx.x / subm1;\n  int z = blockIdx.x % subm1;\n  if (y >= x) y++;\n  if (z >= x) z++;\n\n  const int warp_a = threadIdx.x / ws;\n  const int warp_b = warp_a + ws;\n\n  const int lane_a = threadIdx.x % ws;\n  const int lane_b = lane_a + ws;\n\n  const int i_a = warp_a + y * tile;\n  const int i_b = warp_b + y * tile;\n  const int j_a = lane_a + z * tile;\n  const int j_b = lane_b + z * tile;\n\n  const int idx0_aa = i_a * upper + j_a; \n\n  const int idx0_ab = i_a * upper + j_b; \n\n  const int idx0_ba = i_b * upper + j_a; \n\n  const int idx0_bb = i_b * upper + j_b; \n\n\n  __shared__ mtype s_kj[tile * tile];\n  __shared__ mtype s_ik[tile * tile];\n\n  s_kj[warp_a * tile + lane_a] = krows[(x * tile + warp_a) * upper + j_a];\n  s_kj[warp_a * tile + lane_b] = krows[(x * tile + warp_a) * upper + j_b];\n  s_kj[warp_b * tile + lane_a] = krows[(x * tile + warp_b) * upper + j_a];\n  s_kj[warp_b * tile + lane_b] = krows[(x * tile + warp_b) * upper + j_b];\n\n  s_ik[warp_a * tile + lane_a] = kcols[i_a * upper + lane_a + x * tile];\n  s_ik[warp_a * tile + lane_b] = kcols[i_a * upper + lane_b + x * tile];\n  s_ik[warp_b * tile + lane_a] = kcols[i_b * upper + lane_a + x * tile];\n  s_ik[warp_b * tile + lane_b] = kcols[i_b * upper + lane_b + x * tile];\n\n  mtype ij_aa = AdjMat[idx0_aa];\n  mtype ij_ab = AdjMat[idx0_ab];\n  mtype ij_ba = AdjMat[idx0_ba];\n  mtype ij_bb = AdjMat[idx0_bb];\n\n  const mtype orig_aa = ij_aa;\n  const mtype orig_ab = ij_ab;\n  const mtype orig_ba = ij_ba;\n  const mtype orig_bb = ij_bb;\n\n  __syncthreads();\n  int idx1_a = warp_a;\n  int idx1_b = warp_b;\n\n  int idx2_a = lane_a;\n  int idx2_b = lane_b;\n\n  #pragma unroll 64\n  for (int k = 0; k < tile; k++) {\n    const mtype sk_a = s_kj[idx2_a];\n    const mtype sk_b = s_kj[idx2_b];\n\n    ij_aa = min(ij_aa, s_ik[idx1_a] + sk_a);\n    ij_ab = min(ij_ab, s_ik[idx1_a] + sk_b);\n    ij_ba = min(ij_ba, s_ik[idx1_b] + sk_a);\n    ij_bb = min(ij_bb, s_ik[idx1_b] + sk_b);\n\n    idx1_a += tile;\n    idx1_b += tile;\n\n    idx2_a += tile;\n    idx2_b += tile;\n  }\n\n  if ((y == z) && (y == x + 1) && (x != subm1)) { \n\n    const int idx1_aa = lane_a * tile + warp_a;\n    const int idx1_ab = lane_b * tile + warp_a;\n    const int idx1_ba = lane_a * tile + warp_b;\n    const int idx1_bb = lane_b * tile + warp_b;\n\n    int idx2_a = lane_a;\n    int idx2_b = lane_b;\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      if (warp_a == k) s_kj[idx2_a] = ij_aa;\n      if (warp_a == k) s_kj[idx2_b] = ij_ab;\n      if (warp_b == k) s_kj[idx2_a] = ij_ba;\n      if (warp_b == k) s_kj[idx2_b] = ij_bb;\n      __syncthreads();\n\n      mtype ik_a, ik_b;\n      if (k < ws) {\n        ik_a = __shfl(ij_aa, k, ws);\n        ik_b = __shfl(ij_ba, k, ws);\n      }\n      else {\n        ik_a = __shfl(ij_ab, k - ws, ws);\n        ik_b = __shfl(ij_bb, k - ws, ws);\n      }\n\n      const mtype sk_a = s_kj[idx2_a];\n      const mtype sk_b = s_kj[idx2_b];\n\n      ij_aa = min(ij_aa, ik_a + sk_a);\n      ij_ab = min(ij_ab, ik_a + sk_b);\n      ij_ba = min(ij_ba, ik_b + sk_a);\n      ij_bb = min(ij_bb, ik_b + sk_b);\n\n      if (warp_a == k) krows[idx0_aa] = ij_aa;\n      if (warp_a == k) krows[idx0_ab] = ij_ab;\n      if (warp_b == k) krows[idx0_ba] = ij_ba;\n      if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n      if (lane_a == k) s_ik[idx1_aa] = ij_aa;\n      if (lane_a == k) s_ik[idx1_ba] = ij_ba;\n      if (lane_b == k) s_ik[idx1_ab] = ij_ab;\n      if (lane_b == k) s_ik[idx1_bb] = ij_bb;\n      idx2_a += tile;\n      idx2_b += tile;\n    }\n    __syncthreads();\n\n    kcols[idx0_aa] = s_ik[warp_a * tile + lane_a];\n    kcols[idx0_ab] = s_ik[warp_a * tile + lane_b];\n    kcols[idx0_ba] = s_ik[warp_b * tile + lane_a];\n    kcols[idx0_bb] = s_ik[warp_b * tile + lane_b];\n  }\n\n  if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n  if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n  if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n  if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n}\n\nstatic void FW_gpu_64(const ECLgraph g, mtype* const AdjMat, const int repeat)\n{\n  \n\n  ECLgraph d_g = g;\n  hipMalloc((void **)&d_g.nindex, sizeof(int) * (g.nodes + 1));\n  hipMalloc((void **)&d_g.nlist, sizeof(int) * g.edges);\n  hipMalloc((void **)&d_g.eweight, sizeof(int) * g.edges);\n  hipMemcpy(d_g.nindex, g.nindex, sizeof(int) * (g.nodes + 1), hipMemcpyHostToDevice);\n  hipMemcpy(d_g.nlist, g.nlist, sizeof(int) * g.edges, hipMemcpyHostToDevice);\n  hipMemcpy(d_g.eweight, g.eweight, sizeof(int) * g.edges, hipMemcpyHostToDevice);\n\n  \n\n  const int sub = (g.nodes + tile - 1) / tile;\n\n  const int upper = sub * tile; \n\n  mtype* d_AdjMat;\n  if (hipSuccess != hipMalloc((void **)&d_AdjMat, sizeof(mtype) * upper * upper))\n    fprintf(stderr, \"ERROR: could not allocate memory\\n\");\n\n  mtype* d_krows;\n  if (hipSuccess != hipMalloc((void **)&d_krows, sizeof(mtype) * upper * upper))\n    fprintf(stderr, \"ERROR: could not allocate memory\\n\");\n\n  mtype* d_kcols;\n  if (hipSuccess != hipMalloc((void **)&d_kcols, sizeof(mtype) * upper * upper))\n    fprintf(stderr, \"ERROR: could not allocate memory\\n\");\n\n  printf(\"GPU matrix size: %.1f MB\\n\", sizeof(mtype) * upper * upper / (1024.0 * 1024.0));\n\n  timeval start, end;\n\n  hipDeviceSynchronize();\n  gettimeofday(&start, NULL);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    init1<<<(upper * upper + ThreadsPerBlock - 1) / ThreadsPerBlock, ThreadsPerBlock>>>(g.nodes, d_AdjMat, upper);\n    init2<<<(g.nodes + ThreadsPerBlock - 1) / ThreadsPerBlock, ThreadsPerBlock>>>(d_g, d_AdjMat, upper);\n  }\n\n  hipDeviceSynchronize();\n  gettimeofday(&end, NULL);\n  const double inittime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"Average kernel (initialization) time: %10.6f s\\n\", inittime / repeat);\n\n  const int subm1 = sub - 1;\n  gettimeofday(&start, NULL);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    FW0_64<<<1, ThreadsPerBlock>>>(d_AdjMat, upper, d_krows, d_kcols);\n\n    if (sub > 1) {\n      for (int x = 0; x < sub; x++) {\n        FWrowcol_64<<<2 * subm1, ThreadsPerBlock>>>(d_AdjMat, upper, d_krows, d_kcols, x, subm1);\n        FWrem_64<<<subm1 * subm1, ThreadsPerBlock>>>(d_AdjMat, upper, d_krows, d_kcols, x, subm1);\n      }\n    }\n  }\n  hipDeviceSynchronize();\n  gettimeofday(&end, NULL);\n  const double comptime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"Average kernel (compute) time: %10.6f s\\n\", comptime / repeat);\n\n  \n\n  if (hipSuccess != hipMemcpy(AdjMat, d_AdjMat, sizeof(mtype) * upper * upper, hipMemcpyDeviceToHost))\n    fprintf(stderr, \"ERROR: copying from device failed\\n\");\n\n  \n\n  hipFree(d_g.nindex);\n  hipFree(d_g.nlist);\n  hipFree(d_g.eweight);\n  hipFree(d_AdjMat);\n  hipFree(d_krows);\n  hipFree(d_kcols);\n}\n\nstatic void FW_cpu(const ECLgraph g, mtype* const AdjMat)\n{\n  timeval start, end;\n  gettimeofday(&start, NULL);\n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = 0; j < g.nodes; j++) {\n      AdjMat[i * g.nodes + j] = ((i == j) ? 0 : (INT_MAX / 2));\n    }\n  }\n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      const int nei = g.nlist[j];\n      AdjMat[i * g.nodes + nei] = g.eweight[j];\n    }\n  }\n\n  gettimeofday(&end, NULL);\n  const double inittime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"CPU init time: %10.6f s\\n\", inittime);\n\n  gettimeofday(&start, NULL);\n\n  for (int k = 0; k < g.nodes; k++) {\n    for (int i = 0; i < g.nodes; i++) {\n      for (int j = 0; j < g.nodes; j++) {\n        if (AdjMat[i * g.nodes + j] > AdjMat[i * g.nodes + k] + AdjMat[k * g.nodes + j]) {\n          AdjMat[i * g.nodes + j] = AdjMat[i * g.nodes + k] + AdjMat[k * g.nodes + j];\n        }\n      }\n    }\n  }\n\n  gettimeofday(&end, NULL);\n  const double comptime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"CPU comp time: %10.6f s\\n\", comptime);\n}\n\nint main(int argc, char* argv[])\n{\n  printf(\"ECL-APSP v1.0 (%s)\\n\", __FILE__);\n  printf(\"Copyright 2021 Texas State University\\n\");\n  if (argc != 3) {\n    fprintf(stderr, \"USAGE: %s <input_graph_name> <repeat>\\n\\n\", argv[0]);\n    return 1;\n  }\n  if (ThreadsPerBlock != 1024) {\n    fprintf(stderr, \"Threads per block must be 1024\\n\\n\");\n    return 1;\n  }\n\n  \n\n  mtype* AdjMat1 = NULL;\n  mtype* AdjMat2 = NULL;\n\n  \n\n  int upper_64;\n  int diffcount;\n  int gn;\n\n  \n\n  ECLgraph g = readECLgraph(argv[1]);\n  printf(\"input: %s\\n\", argv[1]);\n  printf(\"nodes: %d\\n\", g.nodes);\n  printf(\"edges: %d\\n\", g.edges);\n\n  const int repeat = atoi(argv[2]);\n\n  if (g.eweight == NULL) {\n    fprintf(stderr, \"ERROR: input graph has no edge weights\\n\\n\");\n    goto DONE;\n  }\n\n  \n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      if (g.eweight[j] < 0) g.eweight[j] = -g.eweight[j];\n    }\n  }\n\n  \n\n  upper_64 = ((g.nodes + tile - 1) / tile) * tile;  \n\n  AdjMat1 = (mtype*) malloc (sizeof(mtype) * upper_64 * upper_64);\n  if (AdjMat1 == NULL) {\n    fprintf(stderr, \"ERROR: memory allocation (AdjMat1) fails\\n\\n\");\n    goto DONE;\n  }\n    \n  FW_gpu_64(g, AdjMat1, repeat);\n\n  \n\n  AdjMat2 = (mtype*) malloc (sizeof(mtype) * g.nodes * g.nodes);\n  if (AdjMat2 == NULL) {\n    fprintf(stderr, \"ERROR: memory allocation (AdjMat2) fails\\n\\n\");\n    goto DONE;\n  }\n\n  FW_cpu(g, AdjMat2);\n\n  \n\n  diffcount = 0;\n  gn = g.nodes;\n  for (int i = 0; i < gn; ++i) {\n    for (int j = 0; j < gn; ++j) {\n      if (AdjMat1[i * upper_64 + j] != AdjMat2[i * g.nodes + j]) {\n        diffcount++;\n      }\n    }\n  }\n\n  if (diffcount > 0) {\n    printf(\"ERROR: results differ in %d places!\\n\", diffcount);\n  } else {\n    printf(\"results match\\n\");\n  }\n\n  DONE:\n  \n\n  if (AdjMat1) free(AdjMat1);\n  if (AdjMat2) free(AdjMat2);\n  freeECLgraph(g);\n  return 0;\n}\n"}}
{"kernel_name": "floydwarshall2", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <limits>\n#include <sys/time.h>\n#include <sycl/sycl.hpp>\n#include \"graph.h\"\n\nusing mtype = int;\n\nstatic const int ws = 32; \n\nstatic const int tile = 64; \n\nstatic const int TPB = ws * ws; \n\n\n\n\nstatic void init1(const int nodes, mtype* const AdjMat, const int upper,\n                  sycl::nd_item<1> &item)\n{\n  const int idx = item.get_global_id(0);\n  const int i = idx / upper;\n  if (i < upper) {\n    const int j = idx % upper;\n    AdjMat[idx] = ((i == j) && (i < nodes)) ? 0 : (INT_MAX / 2);\n  }\n}\n\n\n\nstatic void init2(const ECLgraph g, mtype* const AdjMat, const int upper,\n                  sycl::nd_item<1> &item)\n{\n  const int i = item.get_global_id(0);\n  if (i < g.nodes) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      const int nei = g.nlist[j];\n      AdjMat[i * upper + nei] = g.eweight[j];\n    }\n  }\n}\n\n\n\nstatic \nvoid FW0_64(mtype* const __restrict AdjMat, const int upper, \n            mtype* const __restrict krows, mtype* const __restrict kcols,\n            sycl::nd_item<1> &item, mtype *__restrict temp, mtype *__restrict krow)\n{\n  const int warp_a = item.get_local_id(0) / ws; \n\n  const int warp_b = warp_a + ws; \n\n  const int lane_a = item.get_local_id(0) % ws; \n\n  const int lane_b = lane_a + ws; \n\n\n  const int idx0_aa = warp_a * upper + lane_a; \n\n  const int idx0_ab = warp_a * upper + lane_b; \n\n  const int idx0_ba = warp_b * upper + lane_a; \n\n  const int idx0_bb = warp_b * upper + lane_b; \n\n\n  const int idx1_aa = lane_a * tile + warp_a;\n  const int idx1_ab = lane_b * tile + warp_a;\n  const int idx1_ba = lane_a * tile + warp_b;\n  const int idx1_bb = lane_b * tile + warp_b;\n\n  int idx2_a = lane_a;\n  int idx2_b = lane_b;\n\n  mtype ij_aa = AdjMat[idx0_aa];\n  mtype ij_ab = AdjMat[idx0_ab];\n  mtype ij_ba = AdjMat[idx0_ba];\n  mtype ij_bb = AdjMat[idx0_bb];\n\n  auto sg = item.get_sub_group();\n\n  # pragma unroll 64\n  for (int k = 0; k < tile; k++) {\n    if (warp_a == k) krow[idx2_a] = ij_aa;\n    if (warp_a == k) krow[idx2_b] = ij_ab;\n    if (warp_b == k) krow[idx2_a] = ij_ba;\n    if (warp_b == k) krow[idx2_b] = ij_bb;\n\n    item.barrier(sycl::access::fence_space::local_space);\n\n    mtype ik_a, ik_b;\n\n    if (k < ws) {\n      ik_a = sycl::select_from_group(sg, ij_aa, k);\n      ik_b = sycl::select_from_group(item.get_sub_group(), ij_ba, k);\n    } else {\n      ik_a = sycl::select_from_group(item.get_sub_group(), ij_ab, k - ws);\n      ik_b = sycl::select_from_group(item.get_sub_group(), ij_bb, k - ws);\n    }\n\n    const mtype kr_a = krow[idx2_a];\n    const mtype kr_b = krow[idx2_b];\n\n    ij_aa = sycl::min((int)ij_aa, (int)(ik_a + kr_a));\n    ij_ab = sycl::min((int)ij_ab, (int)(ik_a + kr_b));\n    ij_ba = sycl::min((int)ij_ba, (int)(ik_b + kr_a));\n    ij_bb = sycl::min((int)ij_bb, (int)(ik_b + kr_b));\n\n    if (warp_a == k) krows[idx0_aa] = ij_aa;\n    if (warp_a == k) krows[idx0_ab] = ij_ab;\n    if (warp_b == k) krows[idx0_ba] = ij_ba;\n    if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n    if (lane_a == k) temp[idx1_aa] = ij_aa;\n    if (lane_a == k) temp[idx1_ba] = ij_ba;\n    if (lane_b == k) temp[idx1_ab] = ij_ab;\n    if (lane_b == k) temp[idx1_bb] = ij_bb;\n\n    idx2_a += tile;\n    idx2_b += tile;\n  }\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  kcols[idx0_aa] = temp[warp_a * tile + lane_a];\n  kcols[idx0_ab] = temp[warp_a * tile + lane_b];\n  kcols[idx0_ba] = temp[warp_b * tile + lane_a];\n  kcols[idx0_bb] = temp[warp_b * tile + lane_b];\n  AdjMat[idx0_aa] = ij_aa;\n  AdjMat[idx0_ab] = ij_ab;\n  AdjMat[idx0_ba] = ij_ba;\n  AdjMat[idx0_bb] = ij_bb;\n}\n\n\n\nstatic \nvoid FWrowcol_64(mtype* const __restrict AdjMat, const int upper, \n    mtype* const __restrict krows,\n    mtype* const __restrict kcols,\n    const int x, const int subm1,\n    sycl::nd_item<1> &item, mtype *__restrict temp, mtype *__restrict krow)\n{\n\n  const int warp_a = item.get_local_id(0) / ws; \n\n  const int warp_b = warp_a + ws; \n\n  const int lane_a = item.get_local_id(0) % ws; \n\n  const int lane_b = lane_a + ws; \n\n\n  int y = item.get_group(0);\n\n  if (y < subm1) {\n    if (y >= x) y++;\n    const int i_a = warp_a + x * tile;\n    const int i_b = warp_b + x * tile;\n    const int j_a = lane_a + y * tile;\n    const int j_b = lane_b + y * tile;\n\n    const int idx0_aa = i_a * upper + j_a;\n    const int idx0_ab = i_a * upper + j_b;\n    const int idx0_ba = i_b * upper + j_a;\n    const int idx0_bb = i_b * upper + j_b;\n\n    int idx1_a = warp_a;\n    int idx1_b = warp_b;\n    int idx2_a = lane_a;\n    int idx2_b = lane_b;\n\n    temp[warp_a * tile + lane_a] = kcols[i_a * upper + lane_a + x * tile];\n    temp[warp_a * tile + lane_b] = kcols[i_a * upper + lane_b + x * tile];\n    temp[warp_b * tile + lane_a] = kcols[i_b * upper + lane_a + x * tile];\n    temp[warp_b * tile + lane_b] = kcols[i_b * upper + lane_b + x * tile];\n\n    item.barrier(sycl::access::fence_space::local_space);\n\n    mtype ij_aa = AdjMat[idx0_aa];\n    mtype ij_ab = AdjMat[idx0_ab];\n    mtype ij_ba = AdjMat[idx0_ba];\n    mtype ij_bb = AdjMat[idx0_bb];\n\n    const mtype orig_aa = ij_aa;\n    const mtype orig_ab = ij_ab;\n    const mtype orig_ba = ij_ba;\n    const mtype orig_bb = ij_bb;\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      if (warp_a == k) krow[idx2_a] = ij_aa;\n      if (warp_a == k) krow[idx2_b] = ij_ab;\n      if (warp_b == k) krow[idx2_a] = ij_ba;\n      if (warp_b == k) krow[idx2_b] = ij_bb;\n\n      item.barrier(sycl::access::fence_space::local_space);\n\n      const mtype ik_a = temp[idx1_a];\n      const mtype ik_b = temp[idx1_b];\n      const mtype kr_a = krow[idx2_a];\n      const mtype kr_b = krow[idx2_b];\n\n      ij_aa = sycl::min((int)ij_aa, (int)(ik_a + kr_a));\n      ij_ab = sycl::min((int)ij_ab, (int)(ik_a + kr_b));\n      ij_ba = sycl::min((int)ij_ba, (int)(ik_b + kr_a));\n      ij_bb = sycl::min((int)ij_bb, (int)(ik_b + kr_b));\n\n      if (warp_a == k) krows[idx0_aa] = ij_aa;\n      if (warp_a == k) krows[idx0_ab] = ij_ab;\n      if (warp_b == k) krows[idx0_ba] = ij_ba;\n      if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n      idx1_a += tile;\n      idx1_b += tile;\n      idx2_a += tile;\n      idx2_b += tile;\n    }\n    if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n    if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n    if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n    if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n  } else {\n    y -= subm1;\n    if (y >= x) y++;\n    const int i_a = warp_a + y * tile;\n    const int i_b = warp_b + y * tile;\n\n    const int j_a = lane_a + x * tile;\n    const int j_b = lane_b + x * tile;\n\n    const int idx0_aa = i_a * upper + j_a;\n    const int idx0_ab = i_a * upper + j_b;\n    const int idx0_ba = i_b * upper + j_a;\n    const int idx0_bb = i_b * upper + j_b;\n\n    const int idx1_aa = lane_a * tile + warp_a;\n    const int idx1_ab = lane_b * tile + warp_a;\n    const int idx1_ba = lane_a * tile + warp_b;\n    const int idx1_bb = lane_b * tile + warp_b;\n\n    int idx2_a = (x * tile) * upper + j_a;\n    int idx2_b = (x * tile) * upper + j_b;\n\n    mtype ij_aa = AdjMat[idx0_aa];\n    mtype ij_ab = AdjMat[idx0_ab];\n    mtype ij_ba = AdjMat[idx0_ba];\n    mtype ij_bb = AdjMat[idx0_bb];\n\n    const mtype orig_aa = ij_aa;\n    const mtype orig_ab = ij_ab;\n    const mtype orig_ba = ij_ba;\n    const mtype orig_bb = ij_bb;\n\n    auto sg = item.get_sub_group();\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      mtype ik_a, ik_b;\n      if (k < ws) {\n        ik_a = sycl::select_from_group(sg, ij_aa, k);\n        ik_b = sycl::select_from_group(sg, ij_ba, k);\n      }\n      if (k >= ws) {\n        ik_a = sycl::select_from_group(sg, ij_ab, k - ws);\n        ik_b = sycl::select_from_group(sg, ij_bb, k - ws);\n      }\n      const mtype kr_a = krows[idx2_a];\n      const mtype kr_b = krows[idx2_b];\n\n      ij_aa = sycl::min((int)ij_aa, (int)(ik_a + kr_a));\n      ij_ab = sycl::min((int)ij_ab, (int)(ik_a + kr_b));\n      ij_ba = sycl::min((int)ij_ba, (int)(ik_b + kr_a));\n      ij_bb = sycl::min((int)ij_bb, (int)(ik_b + kr_b));\n\n      if (lane_a == k) temp[idx1_aa] = ij_aa;\n      if (lane_a == k) temp[idx1_ba] = ij_ba;\n      if (lane_b == k) temp[idx1_ab] = ij_ab;\n      if (lane_b == k) temp[idx1_bb] = ij_bb;\n\n      idx2_a += upper;\n      idx2_b += upper;\n    }\n\n    item.barrier(sycl::access::fence_space::local_space);\n\n    kcols[idx0_aa] = temp[warp_a * tile + lane_a];\n    kcols[idx0_ab] = temp[warp_a * tile + lane_b];\n    kcols[idx0_ba] = temp[warp_b * tile + lane_a];\n    kcols[idx0_bb] = temp[warp_b * tile + lane_b];\n\n    if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n    if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n    if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n    if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n  }\n}\n\n\n\nstatic \nvoid FWrem_64(mtype* const __restrict AdjMat,\n    const int upper, mtype* const __restrict krows,\n    mtype* const __restrict kcols, const int x, const int subm1,\n    sycl::nd_item<1> &item, mtype *__restrict s_kj, mtype *__restrict s_ik)\n{\n  int y = item.get_group(0) / subm1;\n  int z = item.get_group(0) % subm1;\n  if (y >= x) y++;\n  if (z >= x) z++;\n\n  const int warp_a = item.get_local_id(0) / ws;\n  const int warp_b = warp_a + ws;\n\n  const int lane_a = item.get_local_id(0) % ws;\n  const int lane_b = lane_a + ws;\n\n  const int i_a = warp_a + y * tile;\n  const int i_b = warp_b + y * tile;\n  const int j_a = lane_a + z * tile;\n  const int j_b = lane_b + z * tile;\n\n  const int idx0_aa = i_a * upper + j_a; \n\n  const int idx0_ab = i_a * upper + j_b; \n\n  const int idx0_ba = i_b * upper + j_a; \n\n  const int idx0_bb = i_b * upper + j_b; \n\n\n  s_kj[warp_a * tile + lane_a] = krows[(x * tile + warp_a) * upper + j_a];\n  s_kj[warp_a * tile + lane_b] = krows[(x * tile + warp_a) * upper + j_b];\n  s_kj[warp_b * tile + lane_a] = krows[(x * tile + warp_b) * upper + j_a];\n  s_kj[warp_b * tile + lane_b] = krows[(x * tile + warp_b) * upper + j_b];\n\n  s_ik[warp_a * tile + lane_a] = kcols[i_a * upper + lane_a + x * tile];\n  s_ik[warp_a * tile + lane_b] = kcols[i_a * upper + lane_b + x * tile];\n  s_ik[warp_b * tile + lane_a] = kcols[i_b * upper + lane_a + x * tile];\n  s_ik[warp_b * tile + lane_b] = kcols[i_b * upper + lane_b + x * tile];\n\n  mtype ij_aa = AdjMat[idx0_aa];\n  mtype ij_ab = AdjMat[idx0_ab];\n  mtype ij_ba = AdjMat[idx0_ba];\n  mtype ij_bb = AdjMat[idx0_bb];\n\n  const mtype orig_aa = ij_aa;\n  const mtype orig_ab = ij_ab;\n  const mtype orig_ba = ij_ba;\n  const mtype orig_bb = ij_bb;\n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  int idx1_a = warp_a;\n  int idx1_b = warp_b;\n\n  int idx2_a = lane_a;\n  int idx2_b = lane_b;\n\n  #pragma unroll 64\n  for (int k = 0; k < tile; k++) {\n    const mtype sk_a = s_kj[idx2_a];\n    const mtype sk_b = s_kj[idx2_b];\n\n    ij_aa = sycl::min((int)ij_aa, (int)(s_ik[idx1_a] + sk_a));\n    ij_ab = sycl::min((int)ij_ab, (int)(s_ik[idx1_a] + sk_b));\n    ij_ba = sycl::min((int)ij_ba, (int)(s_ik[idx1_b] + sk_a));\n    ij_bb = sycl::min((int)ij_bb, (int)(s_ik[idx1_b] + sk_b));\n\n    idx1_a += tile;\n    idx1_b += tile;\n\n    idx2_a += tile;\n    idx2_b += tile;\n  }\n\n  if ((y == z) && (y == x + 1) && (x != subm1)) { \n\n    const int idx1_aa = lane_a * tile + warp_a;\n    const int idx1_ab = lane_b * tile + warp_a;\n    const int idx1_ba = lane_a * tile + warp_b;\n    const int idx1_bb = lane_b * tile + warp_b;\n\n    int idx2_a = lane_a;\n    int idx2_b = lane_b;\n\n    #pragma unroll 64\n    for (int k = 0; k < tile; k++) {\n      if (warp_a == k) s_kj[idx2_a] = ij_aa;\n      if (warp_a == k) s_kj[idx2_b] = ij_ab;\n      if (warp_b == k) s_kj[idx2_a] = ij_ba;\n      if (warp_b == k) s_kj[idx2_b] = ij_bb;\n\n      item.barrier(sycl::access::fence_space::local_space);\n\n      mtype ik_a, ik_b;\n      auto sg = item.get_sub_group(); \n      if (k < ws) {\n        ik_a = sycl::select_from_group(sg, ij_aa, k);\n        ik_b = sycl::select_from_group(sg, ij_ba, k);\n      }\n      else {\n        ik_a = sycl::select_from_group(sg, ij_ab, k - ws);\n        ik_b = sycl::select_from_group(sg, ij_bb, k - ws);\n      }\n\n      const mtype sk_a = s_kj[idx2_a];\n      const mtype sk_b = s_kj[idx2_b];\n\n      ij_aa = sycl::min((int)ij_aa, (int)(ik_a + sk_a));\n      ij_ab = sycl::min((int)ij_ab, (int)(ik_a + sk_b));\n      ij_ba = sycl::min((int)ij_ba, (int)(ik_b + sk_a));\n      ij_bb = sycl::min((int)ij_bb, (int)(ik_b + sk_b));\n\n      if (warp_a == k) krows[idx0_aa] = ij_aa;\n      if (warp_a == k) krows[idx0_ab] = ij_ab;\n      if (warp_b == k) krows[idx0_ba] = ij_ba;\n      if (warp_b == k) krows[idx0_bb] = ij_bb;\n\n      if (lane_a == k) s_ik[idx1_aa] = ij_aa;\n      if (lane_a == k) s_ik[idx1_ba] = ij_ba;\n      if (lane_b == k) s_ik[idx1_ab] = ij_ab;\n      if (lane_b == k) s_ik[idx1_bb] = ij_bb;\n      idx2_a += tile;\n      idx2_b += tile;\n    }\n\n    item.barrier(sycl::access::fence_space::local_space);\n\n    kcols[idx0_aa] = s_ik[warp_a * tile + lane_a];\n    kcols[idx0_ab] = s_ik[warp_a * tile + lane_b];\n    kcols[idx0_ba] = s_ik[warp_b * tile + lane_a];\n    kcols[idx0_bb] = s_ik[warp_b * tile + lane_b];\n  }\n\n  if (ij_aa != orig_aa) AdjMat[idx0_aa] = ij_aa;\n  if (ij_ab != orig_ab) AdjMat[idx0_ab] = ij_ab;\n  if (ij_ba != orig_ba) AdjMat[idx0_ba] = ij_ba;\n  if (ij_bb != orig_bb) AdjMat[idx0_bb] = ij_bb;\n}\n\nstatic void FW_gpu_64(const ECLgraph g, mtype *const AdjMat, const int repeat) {\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  const int wgs = q.get_device().get_info<sycl::info::device::max_work_group_size>();\n  if (wgs < TPB) {\n    printf(\"The max work group size supported is less than %d required for the program\\n\", TPB);\n    return;\n  }\n\n  \n\n  ECLgraph d_g = g;\n  d_g.nindex = sycl::malloc_device<int>((g.nodes + 1), q);\n  q.memcpy(d_g.nindex, g.nindex, sizeof(int) * (g.nodes + 1));\n\n  d_g.nlist = sycl::malloc_device<int>(g.edges, q);\n  q.memcpy(d_g.nlist, g.nlist, sizeof(int) * g.edges);\n\n  d_g.eweight = sycl::malloc_device<int>(g.edges, q);\n  q.memcpy(d_g.eweight, g.eweight, sizeof(int) * g.edges);\n\n  \n\n  const int sub = (g.nodes + tile - 1) / tile;\n\n  const int upper = sub * tile; \n\n  mtype* d_AdjMat = sycl::malloc_device<mtype>(upper * upper, q);\n\n  mtype* d_krows = sycl::malloc_device<mtype>(upper * upper, q);\n\n  mtype* d_kcols = sycl::malloc_device<mtype>(upper * upper, q);\n\n  printf(\"GPU matrix size: %.1f MB\\n\", sizeof(mtype) * upper * upper / (1024.0 * 1024.0));\n\n  timeval start, end;\n\n  sycl::range<1> init_gws ((upper*upper+TPB-1)/TPB*TPB);\n  sycl::range<1> lws (TPB);\n  sycl::range<1> init2_gws ((g.nodes+TPB-1)/TPB*TPB);\n\n  gettimeofday(&start, NULL);\n\n  q.wait();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(init_gws, lws), [=](sycl::nd_item<1> item) {\n        init1(g.nodes, d_AdjMat, upper, item);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(init2_gws, lws), [=](sycl::nd_item<1> item) {\n        init2(d_g, d_AdjMat, upper, item);\n      });\n    });\n  }\n  q.wait();\n  gettimeofday(&end, NULL);\n  const double inittime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"Average kernel (initialization) time: %10.6f s\\n\", inittime / repeat);\n\n  const int subm1 = sub - 1;\n  gettimeofday(&start, NULL);\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    q.submit([&](sycl::handler &cgh) {\n      sycl::local_accessor<mtype, 1> temp(sycl::range<1>(tile * tile), cgh);\n      sycl::local_accessor<mtype, 1> krow(sycl::range<1>(tile * tile), cgh);\n      cgh.parallel_for(sycl::nd_range<1>(lws, lws),\n          [=](sycl::nd_item<1> item) [[sycl::reqd_sub_group_size(32)]] {\n            FW0_64(d_AdjMat, upper, d_krows, d_kcols, item,\n                   temp.get_pointer(), krow.get_pointer());\n      });\n    });\n\n    if (sub > 1) {\n      sycl::range<1> fw64_gws (2 * subm1 * TPB);\n      sycl::range<1> fw64r_gws (subm1 * subm1 * TPB);\n\n      for (int x = 0; x < sub; x++) {\n        q.submit([&](sycl::handler &cgh) {\n          sycl::local_accessor<mtype, 1> temp(sycl::range<1>(tile * tile), cgh);\n          sycl::local_accessor<mtype, 1> krow(sycl::range<1>(tile * tile), cgh);\n          cgh.parallel_for(sycl::nd_range<1>(fw64_gws, lws),\n              [=](sycl::nd_item<1> item) [[sycl::reqd_sub_group_size(32)]] {\n                FWrowcol_64(d_AdjMat, upper, d_krows, d_kcols, x, subm1, item,\n                            temp.get_pointer(),\n                            krow.get_pointer());\n          });\n        });\n\n        q.submit([&](sycl::handler &cgh) {\n          sycl::local_accessor<mtype, 1> s_kj(sycl::range<1>(tile * tile), cgh);\n          sycl::local_accessor<mtype, 1> s_ik(sycl::range<1>(tile * tile), cgh);\n          cgh.parallel_for(\n              sycl::nd_range<1>(fw64r_gws, lws),\n              [=](sycl::nd_item<1> item) [[sycl::reqd_sub_group_size(32)]] {\n                FWrem_64(d_AdjMat, upper, d_krows, d_kcols, x, subm1, item,\n                         s_kj.get_pointer(), s_ik.get_pointer());\n          });\n        });\n      }\n    }\n  }\n  q.wait();\n  gettimeofday(&end, NULL);\n  const double comptime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"Average kernel (compute) time: %10.6f s\\n\", comptime / repeat);\n\n  \n\n  q.memcpy(AdjMat, d_AdjMat, sizeof(mtype) * upper * upper).wait();\n\n  \n\n  sycl::free(d_g.nindex, q);\n  sycl::free(d_g.nlist, q);\n  sycl::free(d_g.eweight, q);\n  sycl::free(d_AdjMat, q);\n  sycl::free(d_krows, q);\n  sycl::free(d_kcols, q);\n}\n\nstatic void FW_cpu(const ECLgraph g, mtype* const AdjMat)\n{\n  timeval start, end;\n  gettimeofday(&start, NULL);\n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = 0; j < g.nodes; j++) {\n      AdjMat[i * g.nodes + j] = ((i == j) ? 0 : (INT_MAX / 2));\n    }\n  }\n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      const int nei = g.nlist[j];\n      AdjMat[i * g.nodes + nei] = g.eweight[j];\n    }\n  }\n\n  gettimeofday(&end, NULL);\n  const double inittime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"CPU init time: %10.6f s\\n\", inittime);\n\n  gettimeofday(&start, NULL);\n\n  for (int k = 0; k < g.nodes; k++) {\n    for (int i = 0; i < g.nodes; i++) {\n      for (int j = 0; j < g.nodes; j++) {\n        if (AdjMat[i * g.nodes + j] > AdjMat[i * g.nodes + k] + AdjMat[k * g.nodes + j]) {\n          AdjMat[i * g.nodes + j] = AdjMat[i * g.nodes + k] + AdjMat[k * g.nodes + j];\n        }\n      }\n    }\n  }\n\n  gettimeofday(&end, NULL);\n  const double comptime = end.tv_sec - start.tv_sec + (end.tv_usec - start.tv_usec) / 1000000.0;\n  printf(\"CPU comp time: %10.6f s\\n\", comptime);\n}\n\nint main(int argc, char* argv[])\n{\n  printf(\"ECL-APSP v1.0 (%s)\\n\", __FILE__);\n  printf(\"Copyright 2021 Texas State University\\n\");\n  if (argc != 3) {\n    fprintf(stderr, \"USAGE: %s <input_graph_name> <repeat>\\n\\n\", argv[0]);\n    return 1;\n  }\n  if (TPB != 1024) {\n    fprintf(stderr, \"Work-group size must be 1024\\n\\n\");\n    return 1;\n  }\n\n  \n\n  mtype* AdjMat1 = NULL;\n  mtype* AdjMat2 = NULL;\n\n  \n\n  int upper_64;\n  int diffcount;\n  int gn;\n\n  \n\n  ECLgraph g = readECLgraph(argv[1]);\n  printf(\"input: %s\\n\", argv[1]);\n  printf(\"nodes: %d\\n\", g.nodes);\n  printf(\"edges: %d\\n\", g.edges);\n\n  const int repeat = atoi(argv[2]);\n\n  if (g.eweight == NULL) {\n    fprintf(stderr, \"ERROR: input graph has no edge weights\\n\\n\");\n    goto DONE;\n  }\n\n  \n\n  for (int i = 0; i < g.nodes; i++) {\n    for (int j = g.nindex[i]; j < g.nindex[i + 1]; j++) {\n      if (g.eweight[j] < 0) g.eweight[j] = -g.eweight[j];\n    }\n  }\n\n  \n\n  upper_64 = ((g.nodes + tile - 1) / tile) * tile;  \n\n  AdjMat1 = (mtype*) malloc (sizeof(mtype) * upper_64 * upper_64);\n  if (AdjMat1 == NULL) {\n    fprintf(stderr, \"ERROR: memory allocation (AdjMat1) fails\\n\\n\");\n    goto DONE;\n  }\n\n  FW_gpu_64(g, AdjMat1, repeat);\n\n  \n\n  AdjMat2 = (mtype*) malloc (sizeof(mtype) * g.nodes * g.nodes);\n  if (AdjMat2 == NULL) {\n    fprintf(stderr, \"ERROR: memory allocation (AdjMat2) fails\\n\\n\");\n    goto DONE;\n  }\n\n  FW_cpu(g, AdjMat2);\n\n  \n\n  diffcount = 0;\n  gn = g.nodes;\n  for (int i = 0; i < gn; ++i) {\n    for (int j = 0; j < gn; ++j) {\n      if (AdjMat1[i * upper_64 + j] != AdjMat2[i * g.nodes + j]) {\n        diffcount++;\n      }\n    }\n  }\n\n  if (diffcount > 0) {\n    printf(\"ERROR: results differ in %d places!\\n\", diffcount);\n  } else {\n    printf(\"results match\\n\");\n  }\n\n  DONE:\n  \n\n  if (AdjMat1) free(AdjMat1);\n  if (AdjMat2) free(AdjMat2);\n  freeECLgraph(g);\n  return 0;\n}\n"}}
{"kernel_name": "frechet", "parallel_api": "cuda", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h> \n\n#include <random>\n\n#define n_d 10000 \n\n\ndouble norm1(int i, int j, const double *c1, const double *c2)\n{\n  double dist, diff; \n\n  int k; \n\n\n  \n\n  dist = 0.0;\n\n  for (k = 0; k < n_d; k++)\n  {\n    \n\n    diff = *(c1 + (i - 1)*n_d + k) - *(c2 + (j - 1)*n_d + k);\n    \n\n    dist += fabs(diff);\n  }\n\n  return dist;\n}\n\ndouble recursive_norm1(int i, int j, int n_2, double *ca,\n                       const double *c1, const double *c2)\n{\n  \n\n  double *ca_ij = ca + (i - 1)*n_2 + (j - 1);\n\n  \n\n  if (*ca_ij > -1.0) \n  {\n    return *ca_ij;\n  }\n  else if ((i == 1) && (j == 1))\n  {\n    *ca_ij = norm1(1, 1, c1, c2);\n  }\n  else if ((i > 1) && (j == 1))\n  {\n    *ca_ij = fmax(recursive_norm1(i - 1, 1, n_2, ca, c1, c2), norm1(i, 1, c1, c2));\n  }\n  else if ((i == 1) && (j > 1))\n  {\n    *ca_ij = fmax(recursive_norm1(1, j - 1, n_2, ca, c1, c2), norm1(1, j, c1, c2));\n  }\n  else if ((i > 1) && (j > 1))\n  {\n    *ca_ij = fmax(\n        fmin(fmin(\n            recursive_norm1(i - 1, j    , n_2, ca, c1, c2),\n            recursive_norm1(i - 1, j - 1, n_2, ca, c1, c2)),\n            recursive_norm1(i,     j - 1, n_2, ca, c1, c2)),\n        norm1(i, j, c1, c2));\n  }\n  else\n  {\n    *ca_ij = INFINITY;\n  }\n\n  return *ca_ij;\n}\n\nvoid distance_norm1 (\n  int n_1, int n_2,\n  double *__restrict__ ca,\n  const double *__restrict__ c1,\n  const double *__restrict__ c2)\n{\n  for (int i = 1; i <= n_1; i++)\n    for (int j = 1; j <= n_2; j++)\n      recursive_norm1(i, j, n_2, ca, c1, c2);\n}\n\nvoid discrete_frechet_distance(const int s, const int n_1, const int n_2, const int iter)\n{\n  double *ca, *c1, *c2;\n  int k; \n\n\n  int ca_size = n_1*n_2*sizeof(double);\n  int c1_size = n_1*n_d*sizeof(double);\n  int c2_size = n_2*n_d*sizeof(double);\n\n  \n\n  ca = (double *) malloc (ca_size);\n\n  \n\n  c1 = (double *) malloc (c1_size);\n  c2 = (double *) malloc (c2_size);\n\n  \n\n  for (k = 0; k < n_1*n_2; k++)\n  {\n    ca[k] = -1.0;\n  }\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<double> dis(-1.0, 1.0);\n\n  for (k = 0; k < n_1 * n_d; k++)\n  {\n    c1[k] = dis(gen);\n  }\n\n  for (k = 0; k < n_2 * n_d; k++)\n  {\n    c2[k] = dis(gen);\n  }\n\n  distance_norm1(n_1, n_2, ca, c1, c2);\n\n  double checkSum = 0;\n  for (k = 0; k < n_1 * n_2; k++)\n    checkSum += ca[k];\n  printf(\"checkSum: %lf\\n\", checkSum);\n\n  \n\n  free(ca);\n  free(c1);\n  free(c2);\n}\n\nint main(int argc, char* argv[])\n{\n  \n\n  const int n_1 = atoi(argv[1]);\n  const int n_2 = atoi(argv[2]);\n  const int iter = atoi(argv[3]);\n\n  for (int i = 0; i < 3; i++)\n    discrete_frechet_distance(i, n_1, n_2, iter);\n\n  return 0;\n}\n\n", "main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h> \n\n#include <random>\n#include <chrono>\n#include <cuda.h>\n\n#define n_d 10000 \n\n\n#include \"norm1.h\"\n#include \"norm2.h\"\n#include \"norm3.h\"\n\nvoid discrete_frechet_distance(const int s, const int n_1, const int n_2, const int repeat)\n{\n  double *ca, *c1, *c2;\n  int k; \n\n\n  int ca_size = n_1*n_2*sizeof(double);\n  int c1_size = n_1*n_d*sizeof(double);\n  int c2_size = n_2*n_d*sizeof(double);\n\n  \n\n  ca = (double *) malloc (ca_size);\n\n  \n\n  c1 = (double *) malloc (c1_size);\n  c2 = (double *) malloc (c2_size);\n\n  \n\n  for (k = 0; k < n_1*n_2; k++)\n  {\n    ca[k] = -1.0;\n  }\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<double> dis(-1.0, 1.0);\n\n  for (k = 0; k < n_1 * n_d; k++)\n  {\n    c1[k] = dis(gen);\n  }\n\n  for (k = 0; k < n_2 * n_d; k++)\n  {\n    c2[k] = dis(gen);\n  }\n\n  double *d_ca, *d_c1, *d_c2;\n  cudaMalloc((void**)&d_ca, ca_size);\n  cudaMalloc((void**)&d_c1, c1_size);\n  cudaMalloc((void**)&d_c2, c2_size);\n\n  cudaMemcpy(d_ca, ca, ca_size, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_c1, c1, c1_size, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_c2, c2, c2_size, cudaMemcpyHostToDevice);\n\n  \n\n  dim3 grids ((n_1+15)/16, (n_2+15)/16); \n  dim3 blocks (16, 16);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  \n  if (s == 0)\n    for (k = 0; k < repeat; k++)\n      distance_norm1<<<grids, blocks>>>(n_1, n_2, d_ca, d_c1, d_c2);\n\n  else if (s == 1)\n    for (k = 0; k < repeat; k++)\n      distance_norm2<<<grids, blocks>>>(n_1, n_2, d_ca, d_c1, d_c2);\n\n  else if (s == 2)\n    for (k = 0; k < repeat; k++)\n      distance_norm3<<<grids, blocks>>>(n_1, n_2, d_ca, d_c1, d_c2);\n \n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(ca, d_ca, ca_size, cudaMemcpyDeviceToHost);\n\n  double checkSum = 0;\n  for (k = 0; k < n_1 * n_2; k++)\n    checkSum += ca[k];\n  printf(\"checkSum: %lf\\n\", checkSum);\n\n  \n\n  free(ca);\n  free(c1);\n  free(c2);\n  cudaFree(d_ca);\n  cudaFree(d_c1);\n  cudaFree(d_c2);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <n_1> <n_2> <repeat>\\n\", argv[0]); \n    printf(\"  n_1: number of points of the 1st curve\");\n    printf(\"  n_2: number of points of the 2nd curve\");\n    return 1;\n  }\n                      \n  \n\n  const int n_1 = atoi(argv[1]);\n  const int n_2 = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  for (int i = 0; i < 3; i++)\n    discrete_frechet_distance(i, n_1, n_2, repeat);\n\n  return 0;\n}\n\n"}}
{"kernel_name": "frechet", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h> \n\n#include <random>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define n_d 10000 \n\n\n#include \"norm1.h\"\n#include \"norm2.h\"\n#include \"norm3.h\"\n\nvoid discrete_frechet_distance(const int s, const int n_1, const int n_2, const int repeat)\n{\n  double *ca, *c1, *c2;\n  int k; \n\n\n  int ca_size = n_1*n_2*sizeof(double);\n  int c1_size = n_1*n_d*sizeof(double);\n  int c2_size = n_2*n_d*sizeof(double);\n\n  \n\n  ca = (double *) malloc (ca_size);\n\n  \n\n  c1 = (double *) malloc (c1_size);\n  c2 = (double *) malloc (c2_size);\n\n  \n\n  for (k = 0; k < n_1*n_2; k++)\n  {\n    ca[k] = -1.0;\n  }\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<double> dis(-1.0, 1.0);\n\n  for (k = 0; k < n_1 * n_d; k++)\n  {\n    c1[k] = dis(gen);\n  }\n\n  for (k = 0; k < n_2 * n_d; k++)\n  {\n    c2[k] = dis(gen);\n  }\n\n  double *d_ca, *d_c1, *d_c2;\n  hipMalloc((void**)&d_ca, ca_size);\n  hipMalloc((void**)&d_c1, c1_size);\n  hipMalloc((void**)&d_c2, c2_size);\n\n  hipMemcpy(d_ca, ca, ca_size, hipMemcpyHostToDevice);\n  hipMemcpy(d_c1, c1, c1_size, hipMemcpyHostToDevice);\n  hipMemcpy(d_c2, c2, c2_size, hipMemcpyHostToDevice);\n\n  \n\n  dim3 grids ((n_1+15)/16, (n_2+15)/16); \n  dim3 blocks (16, 16);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  \n  if (s == 0)\n    for (k = 0; k < repeat; k++)\n      hipLaunchKernelGGL(distance_norm1, grids, blocks, 0, 0, n_1, n_2, d_ca, d_c1, d_c2);\n\n  else if (s == 1)\n    for (k = 0; k < repeat; k++)\n      hipLaunchKernelGGL(distance_norm2, grids, blocks, 0, 0, n_1, n_2, d_ca, d_c1, d_c2);\n\n  else if (s == 2)\n    for (k = 0; k < repeat; k++)\n      hipLaunchKernelGGL(distance_norm3, grids, blocks, 0, 0, n_1, n_2, d_ca, d_c1, d_c2);\n \n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(ca, d_ca, ca_size, hipMemcpyDeviceToHost);\n\n  double checkSum = 0;\n  for (k = 0; k < n_1 * n_2; k++)\n    checkSum += ca[k];\n  printf(\"checkSum: %lf\\n\", checkSum);\n\n  \n\n  free(ca);\n  free(c1);\n  free(c2);\n  hipFree(d_ca);\n  hipFree(d_c1);\n  hipFree(d_c2);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <n_1> <n_2> <repeat>\\n\", argv[0]); \n    printf(\"  n_1: number of points of the 1st curve\");\n    printf(\"  n_2: number of points of the 2nd curve\");\n    return 1;\n  }\n                      \n  \n\n  const int n_1 = atoi(argv[1]);\n  const int n_2 = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  for (int i = 0; i < 3; i++)\n    discrete_frechet_distance(i, n_1, n_2, repeat);\n\n  return 0;\n}\n\n"}}
{"kernel_name": "frechet", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h> \n\n#include <random>\n#include <chrono>\n\n#define n_d 10000 \n\n#include \"norm1.h\"\n#include \"norm2.h\"\n#include \"norm3.h\"\n\nvoid discrete_frechet_distance(const int s, const int n_1, const int n_2, const int repeat)\n{\n  double *ca, *c1, *c2;\n  int k; \n\n\n  int ca_size = n_1*n_2*sizeof(double);\n  int c1_size = n_1*n_d*sizeof(double);\n  int c2_size = n_2*n_d*sizeof(double);\n\n  \n\n  ca = (double *) malloc (ca_size);\n\n  \n\n  c1 = (double *) malloc (c1_size);\n  c2 = (double *) malloc (c2_size);\n\n  \n\n  for (k = 0; k < n_1*n_2; k++)\n  {\n    ca[k] = -1.0;\n  }\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<double> dis(-1.0, 1.0);\n\n  for (k = 0; k < n_1 * n_d; k++)\n  {\n    c1[k] = dis(gen);\n  }\n\n  for (k = 0; k < n_2 * n_d; k++)\n  {\n    c2[k] = dis(gen);\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (s == 0)\n    for (k = 0; k < repeat; k++)\n      distance_norm1(n_1, n_2, ca, c1, c2);\n\n  else if (s == 1)\n    for (k = 0; k < repeat; k++)\n      distance_norm2(n_1, n_2, ca, c1, c2);\n\n  else if (s == 2)\n    for (k = 0; k < repeat; k++)\n      distance_norm3(n_1, n_2, ca, c1, c2);\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  double checkSum = 0;\n  for (k = 0; k < n_1 * n_2; k++)\n    checkSum += ca[k];\n  printf(\"checkSum: %lf\\n\", checkSum);\n\n  \n\n  free(ca);\n  free(c1);\n  free(c2);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <n_1> <n_2> <repeat>\\n\", argv[0]); \n    printf(\"  n_1: number of points of the 1st curve\");\n    printf(\"  n_2: number of points of the 2nd curve\");\n    return 1;\n  }\n\n  \n\n  const int n_1 = atoi(argv[1]);\n  const int n_2 = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  for (int i = 0; i < 3; i++)\n    discrete_frechet_distance(i, n_1, n_2, repeat);\n\n  return 0;\n}\n\n"}}
{"kernel_name": "frechet", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h> \n\n#include <random>\n#include <chrono>\n\n#define n_d 10000 \n\n#include \"norm1.h\"\n#include \"norm2.h\"\n#include \"norm3.h\"\n\nvoid discrete_frechet_distance(const int s, const int n_1, const int n_2, const int repeat)\n{\n  double *ca, *c1, *c2;\n  int k; \n\n\n  int ca_size = n_1*n_2*sizeof(double);\n  int c1_size = n_1*n_d*sizeof(double);\n  int c2_size = n_2*n_d*sizeof(double);\n\n  \n\n  ca = (double *) malloc (ca_size);\n\n  \n\n  c1 = (double *) malloc (c1_size);\n  c2 = (double *) malloc (c2_size);\n\n  \n\n  for (k = 0; k < n_1*n_2; k++)\n  {\n    ca[k] = -1.0;\n  }\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<double> dis(-1.0, 1.0);\n\n  for (k = 0; k < n_1 * n_d; k++)\n  {\n    c1[k] = dis(gen);\n  }\n\n  for (k = 0; k < n_2 * n_d; k++)\n  {\n    c2[k] = dis(gen);\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (s == 0)\n    for (k = 0; k < repeat; k++)\n      distance_norm1(n_1, n_2, ca, c1, c2);\n\n  else if (s == 1)\n    for (k = 0; k < repeat; k++)\n      distance_norm2(n_1, n_2, ca, c1, c2);\n\n  else if (s == 2)\n    for (k = 0; k < repeat; k++)\n      distance_norm3(n_1, n_2, ca, c1, c2);\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  double checkSum = 0;\n  for (k = 0; k < n_1 * n_2; k++)\n    checkSum += ca[k];\n  printf(\"checkSum: %lf\\n\", checkSum);\n\n  \n\n  free(ca);\n  free(c1);\n  free(c2);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <n_1> <n_2> <repeat>\\n\", argv[0]); \n    printf(\"  n_1: number of points of the 1st curve\");\n    printf(\"  n_2: number of points of the 2nd curve\");\n    return 1;\n  }\n\n  \n\n  const int n_1 = atoi(argv[1]);\n  const int n_2 = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  for (int i = 0; i < 3; i++)\n    discrete_frechet_distance(i, n_1, n_2, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "frechet", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h> \n\n#include <random>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define n_d 10000 \n\n\n#include \"norm1.h\"\n#include \"norm2.h\"\n#include \"norm3.h\"\n\nvoid discrete_frechet_distance(const int s, const int n_1, const int n_2, const int repeat)\n{\n  double *ca, *c1, *c2;\n  int k; \n\n\n  int ca_size = n_1*n_2*sizeof(double);\n  int c1_size = n_1*n_d*sizeof(double);\n  int c2_size = n_2*n_d*sizeof(double);\n\n  \n\n  ca = (double *) malloc (ca_size);\n\n  \n\n  c1 = (double *) malloc (c1_size);\n  c2 = (double *) malloc (c2_size);\n\n  \n\n  for (k = 0; k < n_1*n_2; k++)\n  {\n    ca[k] = -1.0;\n  }\n\n  std::mt19937 gen(19937);\n  std::uniform_real_distribution<double> dis(-1.0, 1.0);\n\n  for (k = 0; k < n_1 * n_d; k++)\n  {\n    c1[k] = dis(gen);\n  }\n\n  for (k = 0; k < n_2 * n_d; k++)\n  {\n    c2[k] = dis(gen);\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double *d_ca, *d_c1, *d_c2;\n  d_ca = (double*) sycl::malloc_device(ca_size, q);\n  d_c1 = (double*) sycl::malloc_device(c1_size, q);\n  d_c2 = (double*) sycl::malloc_device(c2_size, q);\n\n  q.memcpy(d_ca, ca, ca_size);\n  q.memcpy(d_c1, c1, c1_size);\n  q.memcpy(d_c2, c2, c2_size);\n  q.wait();\n\n  \n\n  sycl::range<2> gws ((n_2+15)/16*16, (n_1+15)/16*16);\n  sycl::range<2> lws (16, 16);\n\n  auto start = std::chrono::steady_clock::now();\n\n  if (s == 0)\n    for (k = 0; k < repeat; k++)\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class k1>(sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n          distance_norm1(item, n_1, n_2, d_ca, d_c1, d_c2);\n        });\n      });\n\n  else if (s == 1)\n    for (k = 0; k < repeat; k++)\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class k2>(sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n          distance_norm2(item, n_1, n_2, d_ca, d_c1, d_c2);\n        });\n      });\n\n  else if (s == 2)\n    for (k = 0; k < repeat; k++)\n      q.submit([&] (sycl::handler &cgh) {\n        cgh.parallel_for<class k3>(sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n          distance_norm3(item, n_1, n_2, d_ca, d_c1, d_c2);\n        });\n      });\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(ca, d_ca, ca_size).wait();\n\n  double checkSum = 0;\n  for (k = 0; k < n_1 * n_2; k++)\n    checkSum += ca[k];\n  printf(\"checkSum: %lf\\n\", checkSum);\n\n  \n\n  free(ca);\n  free(c1);\n  free(c2);\n  sycl::free(d_ca, q);\n  sycl::free(d_c1, q);\n  sycl::free(d_c2, q);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 4) {\n    printf(\"Usage: %s <n_1> <n_2> <repeat>\\n\", argv[0]);\n    printf(\"  n_1: number of points of the 1st curve\");\n    printf(\"  n_2: number of points of the 2nd curve\");\n    return 1;\n  }\n\n  \n\n  const int n_1 = atoi(argv[1]);\n  const int n_2 = atoi(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  for (int i = 0; i < 3; i++)\n    discrete_frechet_distance(i, n_1, n_2, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "haversine", "parallel_api": "cuda", "code": {"distance.cu": "#include \"distance.h\"\n\n__global__ void compute_haversine_distance(\n  const double4 *__restrict__ p,\n        double*__restrict__ distance,\n  const int n)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) {\n    auto ay = p[i].x * DEGREE_TO_RADIAN;  \n\n    auto ax = p[i].y * DEGREE_TO_RADIAN;  \n\n    auto by = p[i].z * DEGREE_TO_RADIAN;  \n\n    auto bx = p[i].w * DEGREE_TO_RADIAN;  \n\n\n    \n\n    auto x        = (bx - ax) / 2.0;\n    auto y        = (by - ay) / 2.0;\n    auto sinysqrd = sin(y) * sin(y);\n    auto sinxsqrd = sin(x) * sin(x);\n    auto scale    = cos(ay) * cos(by);\n    distance[i] = 2.0 * EARTH_RADIUS_KM * asin(sqrt(sinysqrd + sinxsqrd * scale));\n  }\n}\n\nvoid distance_device(const double4* loc, double* dist, const int n, const int iteration) {\n\n  dim3 grids ((n+255)/256);\n  dim3 threads (256);\n\n  double4 *d_loc;\n  double *d_dist;\n  cudaMalloc((void**)&d_loc, sizeof(double4)*n);\n  cudaMemcpy(d_loc, loc, sizeof(double4)*n, cudaMemcpyHostToDevice);\n  cudaMalloc((void**)&d_dist, sizeof(double)*n);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iteration; i++) {\n    compute_haversine_distance<<<grids, threads>>>(d_loc, d_dist, n);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / iteration);\n\n  cudaMemcpy(dist, d_dist, sizeof(double)*n, cudaMemcpyDeviceToHost);\n  cudaFree(d_loc);\n  cudaFree(d_dist);\n}\n", "main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include \"distance.h\"\n\nvoid distance_device(const double4* loc, double* dist, const int N, const int iteration);\n\nvoid verify(int size, const double *output, const double *expected_output) {\n  double error_rate = 0;\n  for (int i = 0; i < size; i++) {\n    if (fabs(output[i] - expected_output[i]) > error_rate) {\n      error_rate = fabs(output[i] - expected_output[i]);\n    }\n  }\n  printf(\"The maximum error in distance is %f\\n\", error_rate); \n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <file> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const char* filename = argv[1];\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Reading city locations from file %s...\\n\", filename);\n  FILE* fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    perror (\"Error opening the file\");\n    exit(-1);\n  }\n\n  int num_cities = 2097152; \n\n  int num_ref_cities = 6; \n\n  int index_map[] ={436483, 1952407, 627919, 377884, 442703, 1863423};\n  int N = num_cities * num_ref_cities;\n  int city = 0;\n  double lat, lon;\n\n  double4* input  = (double4*) aligned_alloc(4096, N*sizeof(double4));\n  double*  output = (double*) aligned_alloc(4096, N*sizeof(double));\n  double*  expected_output = (double*) malloc(N*sizeof(double));\n\n  while (fscanf(fp, \"%lf %lf\\n\", &lat, &lon) != EOF) { \n    input[city].x = lat;\n    input[city].y = lon;\n    city++;\n    if (city == num_cities) break;  \n  }\n  fclose(fp);\n\n  \n\n  for (int c = 1;  c < num_ref_cities; c++) {\n    std::copy(input, input+num_cities, input+c*num_cities);\n  }\n  \n\n  for (int c = 0;  c < num_ref_cities; c++) {\n    int index = index_map[c] - 1;\n    for(int j = c*num_cities; j < (c+1)*num_cities; ++j) {\n      input[j].z = input[index].x;\n      input[j].w = input[index].y;\n    }\n  }\n\n  \n\n  for (int i = 0; i < N; i++)\n  {\n    double a_lat = input[i].x;\n    double a_lon = input[i].y;\n    double b_lat = input[i].z;\n    double b_lon = input[i].w;\n\n    auto ax = a_lon * DEGREE_TO_RADIAN;\n    auto ay = a_lat * DEGREE_TO_RADIAN;\n    auto bx = b_lon * DEGREE_TO_RADIAN;\n    auto by = b_lat * DEGREE_TO_RADIAN;\n\n    \n\n    auto x        = (bx - ax) / 2.0;\n    auto y        = (by - ay) / 2.0;\n    auto sinysqrd = sin(y) * sin(y);\n    auto sinxsqrd = sin(x) * sin(x);\n    auto scale    = cos(ay) * cos(by);\n    expected_output[i] = 2.0 * EARTH_RADIUS_KM * asin(sqrt(sinysqrd + sinxsqrd * scale));\n  }\n\n  distance_device(input, output, N, repeat);\n\n  verify(N, output, expected_output);\n\n  free(input);\n  free(output);\n  free(expected_output);\n  return 0;\n}\n\n"}}
{"kernel_name": "haversine", "parallel_api": "hip", "code": {"distance.cu": "#include \"distance.h\"\n\n__global__ void compute_haversine_distance(\n  const double4 *__restrict__ p,\n        double*__restrict__ distance,\n  const int n)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < n) {\n    auto ay = p[i].x * DEGREE_TO_RADIAN;  \n\n    auto ax = p[i].y * DEGREE_TO_RADIAN;  \n\n    auto by = p[i].z * DEGREE_TO_RADIAN;  \n\n    auto bx = p[i].w * DEGREE_TO_RADIAN;  \n\n\n    \n\n    auto x        = (bx - ax) / 2.0;\n    auto y        = (by - ay) / 2.0;\n    auto sinysqrd = sin(y) * sin(y);\n    auto sinxsqrd = sin(x) * sin(x);\n    auto scale    = cos(ay) * cos(by);\n    distance[i] = 2.0 * EARTH_RADIUS_KM * asin(sqrt(sinysqrd + sinxsqrd * scale));\n  }\n}\n\nvoid distance_device(const double4* loc, double* dist, const int n, const int iteration) {\n\n  dim3 grids ((n+255)/256);\n  dim3 threads (256);\n\n  double4 *d_loc;\n  double *d_dist;\n  hipMalloc((void**)&d_loc, sizeof(double4)*n);\n  hipMemcpy(d_loc, loc, sizeof(double4)*n, hipMemcpyHostToDevice);\n  hipMalloc((void**)&d_dist, sizeof(double)*n);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iteration; i++) {\n    hipLaunchKernelGGL(compute_haversine_distance, grids, threads, 0, 0, d_loc, d_dist, n);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / iteration);\n\n  hipMemcpy(dist, d_dist, sizeof(double)*n, hipMemcpyDeviceToHost);\n  hipFree(d_loc);\n  hipFree(d_dist);\n}\n"}}
{"kernel_name": "haversine", "parallel_api": "omp", "code": {"distance.cpp": "#include \"distance.h\"\n\nvoid distance_device(const double4* loc, double* dist, const int n, const int iteration) {\n  \n  #pragma omp target data map(to: loc[0:n]) map(from: dist[0:n])\n  {\n    for (int i = 0; i < iteration; i++) {\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (int p = 0; p < n; p++) {\n        auto ay = loc[p].x * DEGREE_TO_RADIAN;  \n\n        auto ax = loc[p].y * DEGREE_TO_RADIAN;  \n\n        auto by = loc[p].z * DEGREE_TO_RADIAN;  \n\n        auto bx = loc[p].w * DEGREE_TO_RADIAN;  \n\n\n        \n\n        auto x        = (bx - ax) / 2.0;\n        auto y        = (by - ay) / 2.0;\n        auto sinysqrd = sin(y) * sin(y);\n        auto sinxsqrd = sin(x) * sin(x);\n        auto scale    = cos(ay) * cos(by);\n        dist[p] = 2.0 * EARTH_RADIUS_KM * asin(sqrt(sinysqrd + sinxsqrd * scale));\n      }\n    }\n  }\n}\n"}}
{"kernel_name": "haversine", "parallel_api": "serial", "code": {"distance.cpp": "#include \"distance.h\"\n\nvoid distance_device(const double4* loc, double* dist, const int n, const int iteration) {\n  \n    {\n    for (int i = 0; i < iteration; i++) {\n            for (int p = 0; p < n; p++) {\n        auto ay = loc[p].x * DEGREE_TO_RADIAN;  \n\n        auto ax = loc[p].y * DEGREE_TO_RADIAN;  \n\n        auto by = loc[p].z * DEGREE_TO_RADIAN;  \n\n        auto bx = loc[p].w * DEGREE_TO_RADIAN;  \n\n\n        \n\n        auto x        = (bx - ax) / 2.0;\n        auto y        = (by - ay) / 2.0;\n        auto sinysqrd = sin(y) * sin(y);\n        auto sinxsqrd = sin(x) * sin(x);\n        auto scale    = cos(ay) * cos(by);\n        dist[p] = 2.0 * EARTH_RADIUS_KM * asin(sqrt(sinysqrd + sinxsqrd * scale));\n      }\n    }\n  }\n}"}}
{"kernel_name": "haversine", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include \"distance.h\"\n\nvoid distance_device(const sycl::double4* loc, double* dist,\n                     const int n, const int iteration) {\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  sycl::range<1> gws ((n+255)/256*256);\n  sycl::range<1> lws (256);\n\n  sycl::double4 *in = sycl::malloc_device<sycl::double4>(n, q);\n  q.memcpy(in, loc, sizeof(sycl::double4) * n);\n\n  double *out = sycl::malloc_device<double>(n, q);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iteration; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class haversine>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i < n) {\n          auto ay = in[i].x() * DEGREE_TO_RADIAN;  \n\n          auto ax = in[i].y() * DEGREE_TO_RADIAN;  \n\n          auto by = in[i].z() * DEGREE_TO_RADIAN;  \n\n          auto bx = in[i].w() * DEGREE_TO_RADIAN;  \n\n\n          \n\n          auto x        = (bx - ax) / 2.0;\n          auto y        = (by - ay) / 2.0;\n          auto sinysqrd = sycl::sin(y) * sycl::sin(y);\n          auto sinxsqrd = sycl::sin(x) * sycl::sin(x);\n          auto scale    = sycl::cos(ay) * sycl::cos(by);\n          out[i] = 2.0 * EARTH_RADIUS_KM * sycl::asin(sycl::sqrt(sinysqrd + sinxsqrd * scale));\n        }\n      });\n    });\n  }\n  \n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time %f (s)\\n\", (time * 1e-9f) / iteration);\n\n  q.memcpy(dist, out, sizeof(double) * n).wait();\n  sycl::free(in, q);\n  sycl::free(out, q);\n}\n\nvoid verify(int size, const double *output, const double *expected_output) {\n  double error_rate = 0;\n  for (int i = 0; i < size; i++) {\n    if (fabs(output[i] - expected_output[i]) > error_rate) {\n      error_rate = fabs(output[i] - expected_output[i]);\n    }\n  }\n  printf(\"The maximum error in distance is %f\\n\", error_rate); \n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <file> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const char* filename = argv[1];\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Reading city locations from file %s...\\n\", filename);\n  FILE* fp = fopen(filename, \"r\");\n  if (fp == NULL) {\n    perror (\"Error opening the file\");\n    exit(-1);\n  }\n\n  int num_cities = 2097152; \n\n  int num_ref_cities = 6; \n\n  int index_map[] ={436483, 1952407, 627919, 377884, 442703, 1863423};\n  int N = num_cities * num_ref_cities;\n  int city = 0;\n  double lat, lon;\n\n  sycl::double4* input  = (sycl::double4*) aligned_alloc(4096, N*sizeof(sycl::double4));\n  double*  output = (double*) aligned_alloc(4096, N*sizeof(double));\n  double*  expected_output = (double*) malloc(N*sizeof(double));\n\n  while (fscanf(fp, \"%lf %lf\\n\", &lat, &lon) != EOF) { \n    input[city].x() = lat;\n    input[city].y() = lon;\n    city++;\n    if (city == num_cities) break;  \n  }\n  fclose(fp);\n\n  \n\n  for (int c = 1;  c < num_ref_cities; c++) {\n    std::copy(input, input+num_cities, input+c*num_cities);\n  }\n  \n\n  for (int c = 0;  c < num_ref_cities; c++) {\n    int index = index_map[c] - 1;\n    for(int j = c*num_cities; j < (c+1)*num_cities; ++j) {\n      input[j].z() = input[index].x();\n      input[j].w() = input[index].y();\n    }\n  }\n\n  \n\n  for (int i = 0; i < N; i++)\n  {\n    double a_lat = input[i].x();\n    double a_lon = input[i].y();\n    double b_lat = input[i].z();\n    double b_lon = input[i].w();\n\n    auto ax = a_lon * DEGREE_TO_RADIAN;\n    auto ay = a_lat * DEGREE_TO_RADIAN;\n    auto bx = b_lon * DEGREE_TO_RADIAN;\n    auto by = b_lat * DEGREE_TO_RADIAN;\n\n    \n\n    auto x        = (bx - ax) / 2.0;\n    auto y        = (by - ay) / 2.0;\n    auto sinysqrd = sin(y) * sin(y);\n    auto sinxsqrd = sin(x) * sin(x);\n    auto scale    = cos(ay) * cos(by);\n    expected_output[i] = 2.0 * EARTH_RADIUS_KM * asin(sqrt(sinysqrd + sinxsqrd * scale));\n  }\n\n  distance_device(input, output, N, repeat);\n\n  verify(N, output, expected_output);\n\n  free(input);\n  free(output);\n  free(expected_output);\n  return 0;\n}\n"}}
{"kernel_name": "log2", "parallel_api": "cuda", "code": {"main.cu": "#include <iostream>\n#include <fstream>\n#include <iomanip>\n#include <vector>\n#include <cmath>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    std::cout << \"Usage: ./main <config filename>\\n\";\n    return 1;\n  }\n\n  std::ifstream message_file (argv[1]);\n\n  std::string placeholder;\n  message_file >> placeholder;\n  long ceilingVal;\n  message_file >> ceilingVal;\n\n  message_file >> placeholder;\n  int repeat;\n  message_file >> repeat;\n\n  message_file >> placeholder;\n  int precision_count;\n  message_file >> precision_count;\n\n  std::vector<int> precision(precision_count, 0);\n  message_file >> placeholder;\n\n  for (int i = 0; i < precision_count; ++i) {\n    message_file >> precision[i];\n  }\n\n  std::vector<float> inputs;\n\n  long i = 1;\n  int increment = 1;\n\n  while (i <= ceilingVal) {\n    inputs.push_back((float) i);\n    i += increment;\n  }\n\n  size_t inputs_size = inputs.size();\n\n  std::cout << \"Number of precision counts : \" \n            << precision_count << std::endl\n            << \" Number of inputs to evaluate for each precision: \"\n            << inputs_size << std::endl\n            << \" Number of runs for each precision : \" << repeat << std::endl;\n\n  std::vector<float> empty_vector(inputs_size, 0);\n\n#ifdef HOST\n  \n\n  std::vector<std::vector<float>> output_vals(precision_count, empty_vector);\n\n  for(int i = 0; i < precision_count; ++i) {\n    for(int k = 0; k < repeat; ++k) {\n      for(size_t j = 0; j < inputs_size; ++j) {\n        output_vals[i][j] = binary_log(inputs[j], precision[i]);\n      }\n    }\n  }\n#endif\n\n  \n\n  std::vector<float> d_output_vals(inputs_size * precision_count);\n\n  \n\n  log2_approx(inputs, d_output_vals, precision, \n              inputs.size(), precision_count, repeat);\n\n  \n\n  std::vector<float> ref_vals(inputs_size, 0);\n  for (size_t i = 0; i < inputs_size; ++i)\n    ref_vals[i] = log2f (inputs[i]);\n\n  \n\n#ifdef HOST\n  std::cout << \"-------------- SUMMARY (Host results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (output_vals[i][j] - ref_vals[j]) * (output_vals[i][j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n#endif\n\n  std::cout << \"-------------- SUMMARY (Device results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (d_output_vals[i*inputs_size+j] - ref_vals[j]) * (d_output_vals[i*inputs_size+j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "log2", "parallel_api": "hip", "code": {"main.cu": "#include <iostream>\n#include <fstream>\n#include <iomanip>\n#include <vector>\n#include <cmath>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    std::cout << \"Usage: ./main <config filename>\\n\";\n    return 1;\n  }\n\n  std::ifstream message_file (argv[1]);\n\n  std::string placeholder;\n  message_file >> placeholder;\n  long ceilingVal;\n  message_file >> ceilingVal;\n\n  message_file >> placeholder;\n  int repeat;\n  message_file >> repeat;\n\n  message_file >> placeholder;\n  int precision_count;\n  message_file >> precision_count;\n\n  std::vector<int> precision(precision_count, 0);\n  message_file >> placeholder;\n\n  for (int i = 0; i < precision_count; ++i) {\n    message_file >> precision[i];\n  }\n\n  std::vector<float> inputs;\n\n  long i = 1;\n  int increment = 1;\n\n  while (i <= ceilingVal) {\n    inputs.push_back((float) i);\n    i += increment;\n  }\n\n  size_t inputs_size = inputs.size();\n\n  std::cout << \"Number of precision counts : \" \n            << precision_count << std::endl\n            << \" Number of inputs to evaluate for each precision: \"\n            << inputs_size << std::endl\n            << \" Number of runs for each precision : \" << repeat << std::endl;\n\n  std::vector<float> empty_vector(inputs_size, 0);\n\n#ifdef HOST\n  \n\n  std::vector<std::vector<float>> output_vals(precision_count, empty_vector);\n\n  for(int i = 0; i < precision_count; ++i) {\n    for(int k = 0; k < repeat; ++k) {\n      for(size_t j = 0; j < inputs_size; ++j) {\n        output_vals[i][j] = binary_log(inputs[j], precision[i]);\n      }\n    }\n  }\n#endif\n\n  \n\n  std::vector<float> d_output_vals(inputs_size * precision_count);\n\n  \n\n  log2_approx(inputs, d_output_vals, precision, \n              inputs.size(), precision_count, repeat);\n\n  \n\n  std::vector<float> ref_vals(inputs_size, 0);\n  for (size_t i = 0; i < inputs_size; ++i)\n    ref_vals[i] = log2f (inputs[i]);\n\n  \n\n#ifdef HOST\n  std::cout << \"-------------- SUMMARY (Host results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (output_vals[i][j] - ref_vals[j]) * (output_vals[i][j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n#endif\n\n  std::cout << \"-------------- SUMMARY (Device results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (d_output_vals[i*inputs_size+j] - ref_vals[j]) * (d_output_vals[i*inputs_size+j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "log2", "parallel_api": "omp", "code": {"main.cpp": "#include <iostream>\n#include <fstream>\n#include <iomanip>\n#include <vector>\n#include <cmath>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    std::cout << \"Usage: ./main <config filename>\\n\";\n    return 1;\n  }\n\n  std::ifstream message_file (argv[1]);\n\n  std::string placeholder;\n  message_file >> placeholder;\n  long ceilingVal;\n  message_file >> ceilingVal;\n\n  message_file >> placeholder;\n  int repeat;\n  message_file >> repeat;\n\n  message_file >> placeholder;\n  int precision_count;\n  message_file >> precision_count;\n\n  std::vector<int> precision(precision_count, 0);\n  message_file >> placeholder;\n\n  for (int i = 0; i < precision_count; ++i) {\n    message_file >> precision[i];\n  }\n\n  std::vector<float> inputs;\n\n  long i = 1;\n  int increment = 1;\n\n  while (i <= ceilingVal) {\n    inputs.push_back((float) i);\n    i += increment;\n  }\n\n  size_t inputs_size = inputs.size();\n\n  std::cout << \"Number of precision counts : \" \n            << precision_count << std::endl\n            << \" Number of inputs to evaluate for each precision: \"\n            << inputs_size << std::endl\n            << \" Number of runs for each precision : \" << repeat << std::endl;\n\n  std::vector<float> empty_vector(inputs_size, 0);\n\n#ifdef HOST\n  \n\n  std::vector<std::vector<float>> output_vals(precision_count, empty_vector);\n\n  for(int i = 0; i < precision_count; ++i) {\n    for(int k = 0; k < repeat; ++k) {\n      for(size_t j = 0; j < inputs_size; ++j) {\n        output_vals[i][j] = binary_log(inputs[j], precision[i]);\n      }\n    }\n  }\n#endif\n\n  \n\n  std::vector<float> d_output_vals(inputs_size * precision_count);\n\n  \n\n  log2_approx(inputs, d_output_vals, precision, \n              inputs.size(), precision_count, repeat);\n\n  \n\n  std::vector<float> ref_vals(inputs_size, 0);\n  for (size_t i = 0; i < inputs_size; ++i)\n    ref_vals[i] = log2f (inputs[i]);\n\n  \n\n#ifdef HOST\n  std::cout << \"-------------- SUMMARY (Host results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (output_vals[i][j] - ref_vals[j]) * (output_vals[i][j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n#endif\n\n  std::cout << \"-------------- SUMMARY (Device results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (d_output_vals[i*inputs_size+j] - ref_vals[j]) * (d_output_vals[i*inputs_size+j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "log2", "parallel_api": "serial", "code": {"main.cpp": "#include <iostream>\n#include <fstream>\n#include <iomanip>\n#include <vector>\n#include <cmath>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    std::cout << \"Usage: ./main <config filename>\\n\";\n    return 1;\n  }\n\n  std::ifstream message_file (argv[1]);\n\n  std::string placeholder;\n  message_file >> placeholder;\n  long ceilingVal;\n  message_file >> ceilingVal;\n\n  message_file >> placeholder;\n  int repeat;\n  message_file >> repeat;\n\n  message_file >> placeholder;\n  int precision_count;\n  message_file >> precision_count;\n\n  std::vector<int> precision(precision_count, 0);\n  message_file >> placeholder;\n\n  for (int i = 0; i < precision_count; ++i) {\n    message_file >> precision[i];\n  }\n\n  std::vector<float> inputs;\n\n  long i = 1;\n  int increment = 1;\n\n  while (i <= ceilingVal) {\n    inputs.push_back((float) i);\n    i += increment;\n  }\n\n  size_t inputs_size = inputs.size();\n\n  std::cout << \"Number of precision counts : \" \n            << precision_count << std::endl\n            << \" Number of inputs to evaluate for each precision: \"\n            << inputs_size << std::endl\n            << \" Number of runs for each precision : \" << repeat << std::endl;\n\n  std::vector<float> empty_vector(inputs_size, 0);\n\n#ifdef HOST\n  \n\n  std::vector<std::vector<float>> output_vals(precision_count, empty_vector);\n\n  for(int i = 0; i < precision_count; ++i) {\n    for(int k = 0; k < repeat; ++k) {\n      for(size_t j = 0; j < inputs_size; ++j) {\n        output_vals[i][j] = binary_log(inputs[j], precision[i]);\n      }\n    }\n  }\n#endif\n\n  \n\n  std::vector<float> d_output_vals(inputs_size * precision_count);\n\n  \n\n  log2_approx(inputs, d_output_vals, precision, \n              inputs.size(), precision_count, repeat);\n\n  \n\n  std::vector<float> ref_vals(inputs_size, 0);\n  for (size_t i = 0; i < inputs_size; ++i)\n    ref_vals[i] = log2f (inputs[i]);\n\n  \n\n#ifdef HOST\n  std::cout << \"-------------- SUMMARY (Host results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (output_vals[i][j] - ref_vals[j]) * (output_vals[i][j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n#endif\n\n  std::cout << \"-------------- SUMMARY (Device results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (d_output_vals[i*inputs_size+j] - ref_vals[j]) * (d_output_vals[i*inputs_size+j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n\n  return 0;\n}"}}
{"kernel_name": "log2", "parallel_api": "sycl", "code": {"main.cpp": "#include <iostream>\n#include <fstream>\n#include <iomanip>\n#include <vector>\n#include <cmath>\n#include \"kernel.h\"\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    std::cout << \"Usage: ./main <config filename>\\n\";\n    return 1;\n  }\n\n  std::ifstream message_file (argv[1]);\n\n  std::string placeholder;\n  message_file >> placeholder;\n  long ceilingVal;\n  message_file >> ceilingVal;\n\n  message_file >> placeholder;\n  int repeat;\n  message_file >> repeat;\n\n  message_file >> placeholder;\n  int precision_count;\n  message_file >> precision_count;\n\n  std::vector<int> precision(precision_count, 0);\n  message_file >> placeholder;\n\n  for (int i = 0; i < precision_count; ++i) {\n    message_file >> precision[i];\n  }\n\n  std::vector<float> inputs;\n\n  long i = 1;\n  int increment = 1;\n\n  while (i <= ceilingVal) {\n    inputs.push_back((float) i);\n    i += increment;\n  }\n\n  size_t inputs_size = inputs.size();\n\n  std::cout << \"Number of precision counts : \" \n            << precision_count << std::endl\n            << \" Number of inputs to evaluate for each precision: \"\n            << inputs_size << std::endl\n            << \" Number of runs for each precision : \" << repeat << std::endl;\n\n  std::vector<float> empty_vector(inputs_size, 0);\n\n#ifdef HOST\n  \n\n  std::vector<std::vector<float>> output_vals(precision_count, empty_vector);\n\n  for(int i = 0; i < precision_count; ++i) {\n    for(int k = 0; k < repeat; ++k) {\n      for(size_t j = 0; j < inputs_size; ++j) {\n        output_vals[i][j] = binary_log(inputs[j], precision[i]);\n      }\n    }\n  }\n#endif\n\n  \n\n  std::vector<float> d_output_vals(inputs_size * precision_count);\n\n  \n\n  log2_approx(inputs, d_output_vals, precision, \n              inputs.size(), precision_count, repeat);\n\n  \n\n  std::vector<float> ref_vals(inputs_size, 0);\n  for (size_t i = 0; i < inputs_size; ++i)\n    ref_vals[i] = log2f (inputs[i]);\n\n  \n\n#ifdef HOST\n  std::cout << \"-------------- SUMMARY (Host results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (output_vals[i][j] - ref_vals[j]) * (output_vals[i][j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n#endif\n\n  std::cout << \"-------------- SUMMARY (Device results):\" << \" --------------\" << std::endl<<std::endl;\n  for (int i = 0; i < precision_count; ++i){\n    std::cout << \"----- Iterative approximation with \" << precision[i] <<\" bits of precision -----\" << std::endl;\n    float s = 0;\n    for (size_t j = 0; j < inputs_size; ++j){\n      s += (d_output_vals[i*inputs_size+j] - ref_vals[j]) * (d_output_vals[i*inputs_size+j] - ref_vals[j]);\n    }\n    s /= inputs.size();\n    std::cout << \"RMSE : \" << sqrtf(s) << std::endl;\n  }\n\n  return 0;\n}\n"}}
{"kernel_name": "lud", "parallel_api": "cuda", "code": {"lud.cu": "#include <stdio.h>\n#include <unistd.h>\n#include <getopt.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n#include \"common.h\"\n\n#define BLOCK_SIZE 16\n\n#include \"lud_kernels.cu\"\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nstatic int do_verify = 0;\n\nstatic struct option long_options[] = {\n  \n\n  {\"input\", 1, NULL, 'i'},\n  {\"size\", 1, NULL, 's'},\n  {\"verify\", 0, NULL, 'v'},\n  {0,0,0,0}\n};\n\nint main ( int argc, char *argv[] )\n{\n  printf(\"WG size of kernel = %d X %d\\n\", BLOCK_SIZE, BLOCK_SIZE);\n  int matrix_dim = 32; \n\n  int opt, option_index=0;\n  func_ret_t ret;\n  const char *input_file = NULL;\n  float *m, *mm;\n  stopwatch sw;\n\n  while ((opt = getopt_long(argc, argv, \"::vs:i:\", \n          long_options, &option_index)) != -1 ) {\n    switch(opt){\n      case 'i':\n        input_file = optarg;\n        break;\n      case 'v':\n        do_verify = 1;\n        break;\n      case 's':\n        matrix_dim = atoi(optarg);\n        printf(\"Generate input matrix internally, size=%d\\n\", matrix_dim);\n        break;\n      case '?':\n        fprintf(stderr, \"invalid option\\n\");\n        break;\n      case ':':\n        fprintf(stderr, \"missing argument\\n\");\n        break;\n      default:\n        fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\", argv[0]);\n        exit(EXIT_FAILURE);\n    }\n  }\n\n  if ( (optind < argc) || (optind == 1)) {\n    fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\", argv[0]);\n    exit(EXIT_FAILURE);\n  }  \n\n  if (input_file) {\n    printf(\"Reading matrix from file %s\\n\", input_file);\n    ret = create_matrix_from_file(&m, input_file, &matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix from file %s\\n\", input_file);\n      exit(EXIT_FAILURE);\n    }\n  } \n\n  else if (matrix_dim) {\n    printf(\"Creating matrix internally size=%d\\n\", matrix_dim);\n    ret = create_matrix(&m, matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix internally size=%d\\n\", matrix_dim);\n      exit(EXIT_FAILURE);\n    }\n  }\n\n  else {\n    printf(\"No input file specified!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  if (do_verify){\n    printf(\"Before LUD\\n\");\n    \n\n    matrix_duplicate(m, &mm, matrix_dim);\n  }\n\n  \n\n  stopwatch_start(&sw);\n\n  float *d_m;\n  cudaMalloc((void**)&d_m, matrix_dim*matrix_dim*sizeof(float));\n  cudaMemcpy(d_m, m, matrix_dim*matrix_dim*sizeof(float), cudaMemcpyHostToDevice);\n\n  int offset;\n  int i=0;\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  \n  for (i=0; i < matrix_dim-BLOCK_SIZE; i += BLOCK_SIZE) {\n    offset = i;  \n\n    lud_diagonal<<<1, BLOCK_SIZE>>>(d_m, matrix_dim, offset);\n    lud_perimeter<<<(matrix_dim-i)/BLOCK_SIZE-1, 2*BLOCK_SIZE>>>(d_m, matrix_dim, offset);\n    lud_internal<<< dim3((matrix_dim-i)/BLOCK_SIZE-1, (matrix_dim-i)/BLOCK_SIZE-1),\n\t    dim3(BLOCK_SIZE, BLOCK_SIZE)>>>(d_m, matrix_dim, offset);\n  } \n\n\n  offset = i;  \n\n  lud_diagonal<<<1, BLOCK_SIZE>>>(d_m, matrix_dim, offset);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time : %f (s)\\n\", time * 1e-9f);\n\n  cudaMemcpy(m, d_m, matrix_dim*matrix_dim*sizeof(float), cudaMemcpyDeviceToHost);\n\n  \n\n  stopwatch_stop(&sw);\n  printf(\"Device offloading time (s): %lf\\n\", get_interval_by_sec(&sw));\n\n  if (do_verify){\n    printf(\"After LUD\\n\");\n    \n\n    printf(\">>>Verify<<<<\\n\");\n    lud_verify(mm, m, matrix_dim); \n    free(mm);\n  }\n\n  free(m);\n  cudaFree(d_m);\n  return 0;\n}\n", "common.cu": "#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <time.h>\n#include <math.h>\n\n#include \"common.h\"\n\nvoid stopwatch_start(stopwatch *sw){\n    if (sw == NULL)\n        return;\n\n    bzero(&sw->begin, sizeof(struct timeval));\n    bzero(&sw->end  , sizeof(struct timeval));\n\n    gettimeofday(&sw->begin, NULL);\n}\n\nvoid stopwatch_stop(stopwatch *sw){\n    if (sw == NULL)\n        return;\n\n    gettimeofday(&sw->end, NULL);\n}\n\ndouble \nget_interval_by_sec(stopwatch *sw){\n    if (sw == NULL)\n        return 0;\n    return ((double)(sw->end.tv_sec-sw->begin.tv_sec)+(double)(sw->end.tv_usec-sw->begin.tv_usec)/1000000);\n}\n\nint \nget_interval_by_usec(stopwatch *sw){\n    if (sw == NULL)\n        return 0;\n    return ((sw->end.tv_sec-sw->begin.tv_sec)*1000000+(sw->end.tv_usec-sw->begin.tv_usec));\n}\n\nfunc_ret_t \ncreate_matrix_from_file(float **mp, const char* filename, int *size_p){\n  int i, j, size;\n  float *m;\n  FILE *fp = NULL;\n\n  fp = fopen(filename, \"rb\");\n  if ( fp == NULL) {\n      return RET_FAILURE;\n  }\n\n  fscanf(fp, \"%d\\n\", &size);\n\n  m = (float*) malloc(sizeof(float)*size*size);\n  if ( m == NULL) {\n      fclose(fp);\n      return RET_FAILURE;\n  }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n          fscanf(fp, \"%f \", m+i*size+j);\n      }\n  }\n\n  fclose(fp);\n\n  *size_p = size;\n  *mp = m;\n\n  return RET_SUCCESS;\n}\n\n\nvoid\nmatrix_multiply(float *inputa, float *inputb, float *output, int size){\n  int i, j, k;\n\n  for (i=0; i < size; i++)\n    for (k=0; k < size; k++)\n      for (j=0; j < size; j++)\n        output[i*size+j] = inputa[i*size+k] * inputb[k*size+j];\n\n}\n\nvoid\nlud_verify(float *m, float *lu, int matrix_dim){\n  int i,j,k;\n  float *tmp = (float*)malloc(matrix_dim*matrix_dim*sizeof(float));\n\n  for (i=0; i < matrix_dim; i ++)\n    for (j=0; j< matrix_dim; j++) {\n        float sum = 0;\n        float l,u;\n        for (k=0; k <= MIN(i,j); k++){\n            if ( i==k)\n              l=1;\n            else\n              l=lu[i*matrix_dim+k];\n            u=lu[k*matrix_dim+j];\n            sum+=l*u;\n        }\n        tmp[i*matrix_dim+j] = sum;\n    }\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  for (i=0; i<matrix_dim; i++){\n      for (j=0; j<matrix_dim; j++){\n          if ( fabs(m[i*matrix_dim+j]-tmp[i*matrix_dim+j]) > 0.0001)\n            printf(\"dismatch at (%d, %d): (o)%f (n)%f\\n\", i, j, m[i*matrix_dim+j], tmp[i*matrix_dim+j]);\n      }\n  }\n  free(tmp);\n}\n\nvoid\nmatrix_duplicate(float *src, float **dst, int matrix_dim) {\n    int s = matrix_dim*matrix_dim*sizeof(float);\n   float *p = (float *) malloc (s);\n   memcpy(p, src, s);\n   *dst = p;\n}\n\nvoid\nprint_matrix(float *m, int matrix_dim) {\n    int i, j;\n    for (i=0; i<matrix_dim;i++) {\n      for (j=0; j<matrix_dim;j++)\n        printf(\"%f \", m[i*matrix_dim+j]);\n      printf(\"\\n\");\n    }\n}\n\n\n\n\n\nfunc_ret_t\ncreate_matrix(float **mp, int size){\n  float *m;\n  int i,j;\n  float lamda = -0.001;\n  float coe[2*size-1];\n  float coe_i =0.0;\n\n  for (i=0; i < size; i++)\n    {\n      coe_i = 10*exp(lamda*i); \n      j=size-1+i;     \n      coe[j]=coe_i;\n      j=size-1-i;     \n      coe[j]=coe_i;\n    }\n\n  m = (float*) malloc(sizeof(float)*size*size);\n  if ( m == NULL) {\n      return RET_FAILURE;\n  }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n\tm[i*size+j]=coe[size-1-i+j];\n      }\n  }\n\n  *mp = m;\n\n  return RET_SUCCESS;\n}\n", "lud_kernels.cu": "__global__ void\nlud_diagonal (float *m, const int matrix_dim, const int offset) {\n  __shared__ float shadow [BLOCK_SIZE*BLOCK_SIZE];\n  int i,j;\n  int tx = threadIdx.x;\n\n  int array_offset = offset*matrix_dim+offset;\n  for(i=0; i < BLOCK_SIZE; i++){\n    shadow[i * BLOCK_SIZE + tx]=m[array_offset + tx];\n    array_offset += matrix_dim;\n  }\n\n  __syncthreads();\n\n  for(i=0; i < BLOCK_SIZE-1; i++) {\n\n    if (tx>i){\n      for(j=0; j < i; j++)\n        shadow[tx * BLOCK_SIZE + i] -= shadow[tx * BLOCK_SIZE + j] * shadow[j * BLOCK_SIZE + i];\n      shadow[tx * BLOCK_SIZE + i] /= shadow[i * BLOCK_SIZE + i];\n    }\n\n    __syncthreads();\n    if (tx>i){\n\n      for(j=0; j < i+1; j++)\n        shadow[(i+1) * BLOCK_SIZE + tx] -= shadow[(i+1) * BLOCK_SIZE + j]*shadow[j * BLOCK_SIZE + tx];\n    }\n\n    __syncthreads();\n  }\n\n  array_offset = (offset+1)*matrix_dim+offset;\n  for(i=1; i < BLOCK_SIZE; i++){\n    m[array_offset+tx]=shadow[i * BLOCK_SIZE + tx];\n    array_offset += matrix_dim;\n  }\n}\n\n__global__ void\nlud_perimeter (float *m, const int matrix_dim, const int offset) {\n  __shared__ float dia [BLOCK_SIZE*BLOCK_SIZE];\n  __shared__ float peri_row [BLOCK_SIZE*BLOCK_SIZE];\n  __shared__ float peri_col [BLOCK_SIZE*BLOCK_SIZE];\n\n  int i,j, array_offset;\n  int idx;\n\n  int  bx = blockIdx.x;  \n  int  tx = threadIdx.x;\n\n  if (tx < BLOCK_SIZE) {\n    idx = tx;\n    array_offset = offset*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE/2; i++){\n      dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n\n    array_offset = offset*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE; i++) {\n      peri_row[i * BLOCK_SIZE+ idx]=m[array_offset+(bx+1)*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n\n  } else {\n    idx = tx-BLOCK_SIZE;\n\n    array_offset = (offset+BLOCK_SIZE/2)*matrix_dim+offset;\n    for (i=BLOCK_SIZE/2; i < BLOCK_SIZE; i++){\n      dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n\n    array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE; i++) {\n      peri_col[i * BLOCK_SIZE + idx] = m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n\n  }\n  __syncthreads();\n\n  if (tx < BLOCK_SIZE) { \n\n    idx=tx;\n    for(i=1; i < BLOCK_SIZE; i++){\n      for (j=0; j < i; j++)\n        peri_row[i * BLOCK_SIZE + idx]-=dia[i * BLOCK_SIZE+ j]*peri_row[j * BLOCK_SIZE + idx];\n    }\n  } else { \n\n    idx=tx - BLOCK_SIZE;\n    for(i=0; i < BLOCK_SIZE; i++){\n      for(j=0; j < i; j++)\n        peri_col[idx * BLOCK_SIZE + i]-=peri_col[idx * BLOCK_SIZE+ j]*dia[j * BLOCK_SIZE + i];\n      peri_col[idx * BLOCK_SIZE + i] /= dia[i * BLOCK_SIZE+ i];\n    }\n  }\n\n  __syncthreads();\n\n  if (tx < BLOCK_SIZE) { \n\n    idx=tx;\n    array_offset = (offset+1)*matrix_dim+offset;\n    for(i=1; i < BLOCK_SIZE; i++){\n      m[array_offset+(bx+1)*BLOCK_SIZE+idx] = peri_row[i*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n  } else { \n\n    idx=tx - BLOCK_SIZE;\n    array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for(i=0; i < BLOCK_SIZE; i++){\n      m[array_offset+idx] =  peri_col[i*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n  }\n}\n\n__global__ void\nlud_internal (float *m, const int matrix_dim, const int offset) {\n  __shared__ float peri_row [BLOCK_SIZE*BLOCK_SIZE];\n  __shared__ float peri_col [BLOCK_SIZE*BLOCK_SIZE];\n  int  bx = blockIdx.x;  \n  int  by = blockIdx.y;  \n\n  int  tx = threadIdx.x;\n  int  ty = threadIdx.y;\n\n  float sum;\n\n  int global_row_id = offset + (by+1)*BLOCK_SIZE;\n  int global_col_id = offset + (bx+1)*BLOCK_SIZE;\n\n  peri_row[ty * BLOCK_SIZE + tx] = m[(offset+ty)*matrix_dim+global_col_id+tx];\n  peri_col[ty * BLOCK_SIZE + tx] = m[(global_row_id+ty)*matrix_dim+offset+tx];\n\n  __syncthreads();\n\n  int i;\n  sum = 0;\n  for (i=0; i < BLOCK_SIZE; i++)\n    sum += peri_col[ty * BLOCK_SIZE + i]; \n\n\n  m[(global_row_id+ty)*matrix_dim+global_col_id+tx] -= sum;\n}\n"}}
{"kernel_name": "lud", "parallel_api": "hip", "code": {"lud.cu": "#include <stdio.h>\n#include <unistd.h>\n#include <getopt.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"common.h\"\n\n#define BLOCK_SIZE 16\n\n#include \"lud_kernels.cu\"\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nstatic int do_verify = 0;\n\nstatic struct option long_options[] = {\n  \n\n  {\"input\", 1, NULL, 'i'},\n  {\"size\", 1, NULL, 's'},\n  {\"verify\", 0, NULL, 'v'},\n  {0,0,0,0}\n};\n\nint main ( int argc, char *argv[] )\n{\n  printf(\"WG size of kernel = %d X %d\\n\", BLOCK_SIZE, BLOCK_SIZE);\n  int matrix_dim = 32; \n\n  int opt, option_index=0;\n  func_ret_t ret;\n  const char *input_file = NULL;\n  float *m, *mm;\n  stopwatch sw;\n\n  while ((opt = getopt_long(argc, argv, \"::vs:i:\", \n          long_options, &option_index)) != -1 ) {\n    switch(opt){\n      case 'i':\n        input_file = optarg;\n        break;\n      case 'v':\n        do_verify = 1;\n        break;\n      case 's':\n        matrix_dim = atoi(optarg);\n        printf(\"Generate input matrix internally, size =%d\\n\", matrix_dim);\n        break;\n      case '?':\n        fprintf(stderr, \"invalid option\\n\");\n        break;\n      case ':':\n        fprintf(stderr, \"missing argument\\n\");\n        break;\n      default:\n        fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\",\n            argv[0]);\n        exit(EXIT_FAILURE);\n    }\n  }\n\n  if ( (optind < argc) || (optind == 1)) {\n    fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\", argv[0]);\n    exit(EXIT_FAILURE);\n  }  \n\n  if (input_file) {\n    printf(\"Reading matrix from file %s\\n\", input_file);\n    ret = create_matrix_from_file(&m, input_file, &matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix from file %s\\n\", input_file);\n      exit(EXIT_FAILURE);\n    }\n  } \n\n  else if (matrix_dim) {\n    printf(\"Creating matrix internally size=%d\\n\", matrix_dim);\n    ret = create_matrix(&m, matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix internally size=%d\\n\", matrix_dim);\n      exit(EXIT_FAILURE);\n    }\n  }\n\n  else {\n    printf(\"No input file specified!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  if (do_verify){\n    printf(\"Before LUD\\n\");\n    \n\n    matrix_duplicate(m, &mm, matrix_dim);\n  }\n\n  \n\n  stopwatch_start(&sw);\n\n  float *d_m;\n  hipMalloc((void**)&d_m, matrix_dim*matrix_dim*sizeof(float));\n  hipMemcpy(d_m, m, matrix_dim*matrix_dim*sizeof(float), hipMemcpyHostToDevice);\n\n  int offset;\n  int i=0;\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  \n  for (i=0; i < matrix_dim-BLOCK_SIZE; i += BLOCK_SIZE) {\n    offset = i;  \n\n    hipLaunchKernelGGL(lud_diagonal, 1, BLOCK_SIZE, 0, 0, d_m, matrix_dim, offset);\n    lud_perimeter<<<(matrix_dim-i)/BLOCK_SIZE-1, 2*BLOCK_SIZE>>>(d_m, matrix_dim, offset);\n    hipLaunchKernelGGL(lud_internal, dim3((matrix_dim-i)/BLOCK_SIZE-1, (matrix_dim-i)/BLOCK_SIZE-1),\n                                     dim3(BLOCK_SIZE, BLOCK_SIZE), 0, 0, d_m, matrix_dim, offset);\n  } \n\n\n  offset = i;  \n\n  hipLaunchKernelGGL(lud_diagonal, 1, BLOCK_SIZE, 0, 0, d_m, matrix_dim, offset);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time : %f (s)\\n\", time * 1e-9f);\n\n  hipMemcpy(m, d_m, matrix_dim*matrix_dim*sizeof(float), hipMemcpyDeviceToHost);\n\n  \n\n  stopwatch_stop(&sw);\n  printf(\"Device offloading time (s): %lf\\n\", get_interval_by_sec(&sw));\n\n  if (do_verify){\n    printf(\"After LUD\\n\");\n    \n\n    printf(\">>>Verify<<<<\\n\");\n    lud_verify(mm, m, matrix_dim); \n    free(mm);\n  }\n\n  free(m);\n  hipFree(d_m);\n  return 0;\n}\n", "common.cu": "#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <time.h>\n#include <math.h>\n\n#include \"common.h\"\n\nvoid stopwatch_start(stopwatch *sw){\n    if (sw == NULL)\n        return;\n\n    bzero(&sw->begin, sizeof(struct timeval));\n    bzero(&sw->end  , sizeof(struct timeval));\n\n    gettimeofday(&sw->begin, NULL);\n}\n\nvoid stopwatch_stop(stopwatch *sw){\n    if (sw == NULL)\n        return;\n\n    gettimeofday(&sw->end, NULL);\n}\n\ndouble \nget_interval_by_sec(stopwatch *sw){\n    if (sw == NULL)\n        return 0;\n    return ((double)(sw->end.tv_sec-sw->begin.tv_sec)+(double)(sw->end.tv_usec-sw->begin.tv_usec)/1000000);\n}\n\nint \nget_interval_by_usec(stopwatch *sw){\n    if (sw == NULL)\n        return 0;\n    return ((sw->end.tv_sec-sw->begin.tv_sec)*1000000+(sw->end.tv_usec-sw->begin.tv_usec));\n}\n\nfunc_ret_t \ncreate_matrix_from_file(float **mp, const char* filename, int *size_p){\n  int i, j, size;\n  float *m;\n  FILE *fp = NULL;\n\n  fp = fopen(filename, \"rb\");\n  if ( fp == NULL) {\n      return RET_FAILURE;\n  }\n\n  fscanf(fp, \"%d\\n\", &size);\n\n  m = (float*) malloc(sizeof(float)*size*size);\n  if ( m == NULL) {\n      fclose(fp);\n      return RET_FAILURE;\n  }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n          fscanf(fp, \"%f \", m+i*size+j);\n      }\n  }\n\n  fclose(fp);\n\n  *size_p = size;\n  *mp = m;\n\n  return RET_SUCCESS;\n}\n\n\nvoid\nmatrix_multiply(float *inputa, float *inputb, float *output, int size){\n  int i, j, k;\n\n  for (i=0; i < size; i++)\n    for (k=0; k < size; k++)\n      for (j=0; j < size; j++)\n        output[i*size+j] = inputa[i*size+k] * inputb[k*size+j];\n\n}\n\nvoid\nlud_verify(float *m, float *lu, int matrix_dim){\n  int i,j,k;\n  float *tmp = (float*)malloc(matrix_dim*matrix_dim*sizeof(float));\n\n  for (i=0; i < matrix_dim; i ++)\n    for (j=0; j< matrix_dim; j++) {\n        float sum = 0;\n        float l,u;\n        for (k=0; k <= MIN(i,j); k++){\n            if ( i==k)\n              l=1;\n            else\n              l=lu[i*matrix_dim+k];\n            u=lu[k*matrix_dim+j];\n            sum+=l*u;\n        }\n        tmp[i*matrix_dim+j] = sum;\n    }\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  for (i=0; i<matrix_dim; i++){\n      for (j=0; j<matrix_dim; j++){\n          if ( fabs(m[i*matrix_dim+j]-tmp[i*matrix_dim+j]) > 0.0001)\n            printf(\"dismatch at (%d, %d): (o)%f (n)%f\\n\", i, j, m[i*matrix_dim+j], tmp[i*matrix_dim+j]);\n      }\n  }\n  free(tmp);\n}\n\nvoid\nmatrix_duplicate(float *src, float **dst, int matrix_dim) {\n    int s = matrix_dim*matrix_dim*sizeof(float);\n   float *p = (float *) malloc (s);\n   memcpy(p, src, s);\n   *dst = p;\n}\n\nvoid\nprint_matrix(float *m, int matrix_dim) {\n    int i, j;\n    for (i=0; i<matrix_dim;i++) {\n      for (j=0; j<matrix_dim;j++)\n        printf(\"%f \", m[i*matrix_dim+j]);\n      printf(\"\\n\");\n    }\n}\n\n\n\n\n\nfunc_ret_t\ncreate_matrix(float **mp, int size){\n  float *m;\n  int i,j;\n  float lamda = -0.001;\n  float coe[2*size-1];\n  float coe_i =0.0;\n\n  for (i=0; i < size; i++)\n    {\n      coe_i = 10*exp(lamda*i); \n      j=size-1+i;     \n      coe[j]=coe_i;\n      j=size-1-i;     \n      coe[j]=coe_i;\n    }\n\n  m = (float*) malloc(sizeof(float)*size*size);\n  if ( m == NULL) {\n      return RET_FAILURE;\n  }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n\tm[i*size+j]=coe[size-1-i+j];\n      }\n  }\n\n  *mp = m;\n\n  return RET_SUCCESS;\n}\n", "lud_kernels.cu": "__global__ void\nlud_diagonal (float *m, const int matrix_dim, const int offset) {\n  __shared__ float shadow [BLOCK_SIZE*BLOCK_SIZE];\n  int i,j;\n  int tx = threadIdx.x;\n\n  int array_offset = offset*matrix_dim+offset;\n  for(i=0; i < BLOCK_SIZE; i++){\n    shadow[i * BLOCK_SIZE + tx]=m[array_offset + tx];\n    array_offset += matrix_dim;\n  }\n\n  __syncthreads();\n\n  for(i=0; i < BLOCK_SIZE-1; i++) {\n\n    if (tx>i){\n      for(j=0; j < i; j++)\n        shadow[tx * BLOCK_SIZE + i] -= shadow[tx * BLOCK_SIZE + j] * shadow[j * BLOCK_SIZE + i];\n      shadow[tx * BLOCK_SIZE + i] /= shadow[i * BLOCK_SIZE + i];\n    }\n\n    __syncthreads();\n    if (tx>i){\n\n      for(j=0; j < i+1; j++)\n        shadow[(i+1) * BLOCK_SIZE + tx] -= shadow[(i+1) * BLOCK_SIZE + j]*shadow[j * BLOCK_SIZE + tx];\n    }\n\n    __syncthreads();\n  }\n\n  array_offset = (offset+1)*matrix_dim+offset;\n  for(i=1; i < BLOCK_SIZE; i++){\n    m[array_offset+tx]=shadow[i * BLOCK_SIZE + tx];\n    array_offset += matrix_dim;\n  }\n}\n\n__global__ void\nlud_perimeter (float *m, const int matrix_dim, const int offset) {\n  __shared__ float dia [BLOCK_SIZE*BLOCK_SIZE];\n  __shared__ float peri_row [BLOCK_SIZE*BLOCK_SIZE];\n  __shared__ float peri_col [BLOCK_SIZE*BLOCK_SIZE];\n\n  int i,j, array_offset;\n  int idx;\n\n  int  bx = blockIdx.x;  \n  int  tx = threadIdx.x;\n\n  if (tx < BLOCK_SIZE) {\n    idx = tx;\n    array_offset = offset*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE/2; i++){\n      dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n\n    array_offset = offset*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE; i++) {\n      peri_row[i * BLOCK_SIZE+ idx]=m[array_offset+(bx+1)*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n\n  } else {\n    idx = tx-BLOCK_SIZE;\n\n    array_offset = (offset+BLOCK_SIZE/2)*matrix_dim+offset;\n    for (i=BLOCK_SIZE/2; i < BLOCK_SIZE; i++){\n      dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n\n    array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE; i++) {\n      peri_col[i * BLOCK_SIZE + idx] = m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n\n  }\n  __syncthreads();\n\n  if (tx < BLOCK_SIZE) { \n\n    idx=tx;\n    for(i=1; i < BLOCK_SIZE; i++){\n      for (j=0; j < i; j++)\n        peri_row[i * BLOCK_SIZE + idx]-=dia[i * BLOCK_SIZE+ j]*peri_row[j * BLOCK_SIZE + idx];\n    }\n  } else { \n\n    idx=tx - BLOCK_SIZE;\n    for(i=0; i < BLOCK_SIZE; i++){\n      for(j=0; j < i; j++)\n        peri_col[idx * BLOCK_SIZE + i]-=peri_col[idx * BLOCK_SIZE+ j]*dia[j * BLOCK_SIZE + i];\n      peri_col[idx * BLOCK_SIZE + i] /= dia[i * BLOCK_SIZE+ i];\n    }\n  }\n\n  __syncthreads();\n\n  if (tx < BLOCK_SIZE) { \n\n    idx=tx;\n    array_offset = (offset+1)*matrix_dim+offset;\n    for(i=1; i < BLOCK_SIZE; i++){\n      m[array_offset+(bx+1)*BLOCK_SIZE+idx] = peri_row[i*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n  } else { \n\n    idx=tx - BLOCK_SIZE;\n    array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for(i=0; i < BLOCK_SIZE; i++){\n      m[array_offset+idx] =  peri_col[i*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n  }\n}\n\n__global__ void\nlud_internal (float *m, const int matrix_dim, const int offset) {\n  __shared__ float peri_row [BLOCK_SIZE*BLOCK_SIZE];\n  __shared__ float peri_col [BLOCK_SIZE*BLOCK_SIZE];\n  int  bx = blockIdx.x;  \n  int  by = blockIdx.y;  \n\n  int  tx = threadIdx.x;\n  int  ty = threadIdx.y;\n\n  float sum;\n\n  int global_row_id = offset + (by+1)*BLOCK_SIZE;\n  int global_col_id = offset + (bx+1)*BLOCK_SIZE;\n\n  peri_row[ty * BLOCK_SIZE + tx] = m[(offset+ty)*matrix_dim+global_col_id+tx];\n  peri_col[ty * BLOCK_SIZE + tx] = m[(global_row_id+ty)*matrix_dim+offset+tx];\n\n  __syncthreads();\n\n  int i;\n  sum = 0;\n  for (i=0; i < BLOCK_SIZE; i++)\n    sum += peri_col[ty * BLOCK_SIZE + i]; \n\n\n  m[(global_row_id+ty)*matrix_dim+global_col_id+tx] -= sum;\n}\n"}}
{"kernel_name": "lud", "parallel_api": "omp", "code": {"lud.cpp": "#include <stdio.h>\n#include <unistd.h>\n#include <getopt.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n#include \"common.h\"\n\n#define BLOCK_SIZE 16\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nstatic int do_verify = 0;\nvoid lud_cuda(float *d_m, int matrix_dim);\n\nstatic struct option long_options[] = {\n  \n\n  {\"input\", 1, NULL, 'i'},\n  {\"size\", 1, NULL, 's'},\n  {\"verify\", 0, NULL, 'v'},\n  {0,0,0,0}\n};\n\nint main ( int argc, char *argv[] )\n{\n  printf(\"WG size of kernel = %d X %d\\n\", BLOCK_SIZE, BLOCK_SIZE);\n  int matrix_dim = 32; \n\n  int opt, option_index=0;\n  func_ret_t ret;\n  const char *input_file = NULL;\n  float *m, *mm;\n  stopwatch sw;\n\n  while ((opt = getopt_long(argc, argv, \"::vs:i:\", \n          long_options, &option_index)) != -1 ) {\n    switch(opt){\n      case 'i':\n        input_file = optarg;\n        break;\n      case 'v':\n        do_verify = 1;\n        break;\n      case 's':\n        matrix_dim = atoi(optarg);\n        printf(\"Generate input matrix internally, size =%d\\n\", matrix_dim);\n        break;\n      case '?':\n        fprintf(stderr, \"invalid option\\n\");\n        break;\n      case ':':\n        fprintf(stderr, \"missing argument\\n\");\n        break;\n      default:\n        fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\",\n            argv[0]);\n        exit(EXIT_FAILURE);\n    }\n  }\n\n  if ( (optind < argc) || (optind == 1)) {\n    fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\", argv[0]);\n    exit(EXIT_FAILURE);\n  }  \n\n  if (input_file) {\n    printf(\"Reading matrix from file %s\\n\", input_file);\n    ret = create_matrix_from_file(&m, input_file, &matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix from file %s\\n\", input_file);\n      exit(EXIT_FAILURE);\n    }\n  } \n\n  else if (matrix_dim) {\n    printf(\"Creating matrix internally size=%d\\n\", matrix_dim);\n    ret = create_matrix(&m, matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix internally size=%d\\n\", matrix_dim);\n      exit(EXIT_FAILURE);\n    }\n  }\n  else {\n    printf(\"No input file specified!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  if (do_verify){\n    printf(\"Before LUD\\n\");\n    \n\n    matrix_duplicate(m, &mm, matrix_dim);\n  }\n\n  \n\n  stopwatch_start(&sw);\n\n  #pragma omp target data map(tofrom: m[0:matrix_dim*matrix_dim])\n  {\n  int offset;\n  int i=0;\n  \n  auto start = std::chrono::steady_clock::now();\n\n  for (i=0; i < matrix_dim-BLOCK_SIZE; i += BLOCK_SIZE) {\n    offset = i;  \n\n    #pragma omp target teams num_teams(1) thread_limit(BLOCK_SIZE)\n    {\n      float shadow[BLOCK_SIZE * BLOCK_SIZE];\n      #pragma omp parallel\n      {\n        int i,j;\n        int tx = omp_get_thread_num() ;\n      \n        int array_offset = offset*matrix_dim+offset;\n        for(i=0; i < BLOCK_SIZE; i++){\n          shadow[i * BLOCK_SIZE + tx]=m[array_offset + tx];\n          array_offset += matrix_dim;\n        }\n        \n        #pragma omp barrier\n        \n        for(i=0; i < BLOCK_SIZE-1; i++) {\n      \n          if (tx>i){\n            for(j=0; j < i; j++)\n              shadow[tx * BLOCK_SIZE + i] -= shadow[tx * BLOCK_SIZE + j] * shadow[j * BLOCK_SIZE + i];\n          shadow[tx * BLOCK_SIZE + i] /= shadow[i * BLOCK_SIZE + i];\n          }\n      \n          #pragma omp barrier\n          if (tx>i){\n      \n            for(j=0; j < i+1; j++)\n              shadow[(i+1) * BLOCK_SIZE + tx] -= shadow[(i+1) * BLOCK_SIZE + j]*shadow[j * BLOCK_SIZE + tx];\n          }\n          \n          #pragma omp barrier\n        }\n      \n        array_offset = (offset+1)*matrix_dim+offset;\n        for(i=1; i < BLOCK_SIZE; i++){\n          m[array_offset+tx]=shadow[i * BLOCK_SIZE + tx];\n          array_offset += matrix_dim;\n        }\n      }\n    }\n\n    #pragma omp target teams num_teams((matrix_dim-i)/BLOCK_SIZE-1) thread_limit(2*BLOCK_SIZE)\n    {\n      float dia[BLOCK_SIZE * BLOCK_SIZE];\n      float peri_row[BLOCK_SIZE * BLOCK_SIZE];\n      float peri_col[BLOCK_SIZE * BLOCK_SIZE];\n      #pragma omp parallel\n      {\n         int i,j, array_offset;\n         int idx;\n\n         int  bx = omp_get_team_num();  \n         int  tx = omp_get_thread_num();\n\n         if (tx < BLOCK_SIZE) {\n           idx = tx;\n           array_offset = offset*matrix_dim+offset;\n           for (i=0; i < BLOCK_SIZE/2; i++){\n           dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n           array_offset += matrix_dim;\n           }\n         \n         array_offset = offset*matrix_dim+offset;\n         for (i=0; i < BLOCK_SIZE; i++) {\n           peri_row[i * BLOCK_SIZE+ idx]=m[array_offset+(bx+1)*BLOCK_SIZE+idx];\n           array_offset += matrix_dim;\n         }\n\n         } else {\n         idx = tx-BLOCK_SIZE;\n         \n         array_offset = (offset+BLOCK_SIZE/2)*matrix_dim+offset;\n         for (i=BLOCK_SIZE/2; i < BLOCK_SIZE; i++){\n           dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n           array_offset += matrix_dim;\n         }\n         \n         array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n         for (i=0; i < BLOCK_SIZE; i++) {\n           peri_col[i * BLOCK_SIZE + idx] = m[array_offset+idx];\n           array_offset += matrix_dim;\n         }\n       }\n       #pragma omp barrier\n\n       if (tx < BLOCK_SIZE) { \n\n         idx=tx;\n         for(i=1; i < BLOCK_SIZE; i++){\n           for (j=0; j < i; j++)\n             peri_row[i * BLOCK_SIZE + idx]-=dia[i * BLOCK_SIZE+ j]*peri_row[j * BLOCK_SIZE + idx];\n         }\n       } else { \n\n         idx=tx - BLOCK_SIZE;\n         for(i=0; i < BLOCK_SIZE; i++){\n           for(j=0; j < i; j++)\n             peri_col[idx * BLOCK_SIZE + i]-=peri_col[idx * BLOCK_SIZE+ j]*dia[j * BLOCK_SIZE + i];\n            peri_col[idx * BLOCK_SIZE + i] /= dia[i * BLOCK_SIZE+ i];\n         }\n       }\n\n       #pragma omp barrier\n       if (tx < BLOCK_SIZE) { \n\n         idx=tx;\n         array_offset = (offset+1)*matrix_dim+offset;\n         for(i=1; i < BLOCK_SIZE; i++){\n           m[array_offset+(bx+1)*BLOCK_SIZE+idx] = peri_row[i*BLOCK_SIZE+idx];\n           array_offset += matrix_dim;\n         }\n       } else { \n\n         idx=tx - BLOCK_SIZE;\n         array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n         for(i=0; i < BLOCK_SIZE; i++){\n           m[array_offset+idx] =  peri_col[i*BLOCK_SIZE+idx];\n           array_offset += matrix_dim;\n         }\n       }\n      }\n    }\n\n    #pragma omp target teams num_teams(((matrix_dim-i)/BLOCK_SIZE-1) * ((matrix_dim-i)/BLOCK_SIZE-1)) \\\n                              thread_limit(BLOCK_SIZE*BLOCK_SIZE)\n    {\n      float peri_row[BLOCK_SIZE * BLOCK_SIZE];\n      float peri_col[BLOCK_SIZE * BLOCK_SIZE];\n      #pragma omp parallel\n      {\n        int  bx = omp_get_team_num() % ((matrix_dim-i)/BLOCK_SIZE-1); \n\n        int  by = omp_get_team_num() / ((matrix_dim-i)/BLOCK_SIZE-1); \n\n        \n        int  tx = omp_get_thread_num() % BLOCK_SIZE; \n\n        int  ty = omp_get_thread_num() / BLOCK_SIZE; \n\n\n        int i;\n        float sum;\n\n        int global_row_id = offset + (by+1)*BLOCK_SIZE;\n        int global_col_id = offset + (bx+1)*BLOCK_SIZE;\n\n        peri_row[ty * BLOCK_SIZE + tx] = m[(offset+ty)*matrix_dim+global_col_id+tx];\n        peri_col[ty * BLOCK_SIZE + tx] = m[(global_row_id+ty)*matrix_dim+offset+tx];\n\n        #pragma omp barrier\n\n        sum = 0;\n        for (i=0; i < BLOCK_SIZE; i++)\n          sum += peri_col[ty * BLOCK_SIZE + i] * peri_row[i * BLOCK_SIZE + tx];\n        m[(global_row_id+ty)*matrix_dim+global_col_id+tx] -= sum;\n      }\n    }\n  } \n\n\n  offset = i;  \n\n  #pragma omp target teams num_teams(1) thread_limit(BLOCK_SIZE)\n  {\n    float shadow[BLOCK_SIZE * BLOCK_SIZE];\n    #pragma omp parallel\n    {\n      int i,j;\n      int tx = omp_get_thread_num() ;\n    \n      int array_offset = offset*matrix_dim+offset;\n      for(i=0; i < BLOCK_SIZE; i++){\n        shadow[i * BLOCK_SIZE + tx]=m[array_offset + tx];\n        array_offset += matrix_dim;\n      }\n      \n      #pragma omp barrier\n      \n      for(i=0; i < BLOCK_SIZE-1; i++) {\n        if (tx>i) {\n          for(j=0; j < i; j++)\n            shadow[tx * BLOCK_SIZE + i] -= shadow[tx * BLOCK_SIZE + j] * shadow[j * BLOCK_SIZE + i];\n          shadow[tx * BLOCK_SIZE + i] /= shadow[i * BLOCK_SIZE + i];\n        }\n    \n        #pragma omp barrier\n        if (tx>i){\n          for(j=0; j < i+1; j++)\n            shadow[(i+1) * BLOCK_SIZE + tx] -= shadow[(i+1) * BLOCK_SIZE + j]*shadow[j * BLOCK_SIZE + tx];\n        }\n\n        #pragma omp barrier\n      }\n    \n      array_offset = (offset+1)*matrix_dim+offset;\n      for(i=1; i < BLOCK_SIZE; i++){\n        m[array_offset+tx]=shadow[i * BLOCK_SIZE + tx];\n        array_offset += matrix_dim;\n      }\n    }\n   }\n\n   auto end = std::chrono::steady_clock::now();\n   auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n   printf(\"Total kernel execution time : %f (s)\\n\", time * 1e-9f);\n  } \n\n\n  \n\n  stopwatch_stop(&sw);\n  printf(\"Device offloading time (s): %lf\\n\", get_interval_by_sec(&sw));\n\n  if (do_verify){\n    printf(\"After LUD\\n\");\n    \n\n    printf(\">>>Verify<<<<\\n\");\n    lud_verify(mm, m, matrix_dim); \n    free(mm);\n  }\n\n  free(m);\n}\n", "common.c": "#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <time.h>\n#include <math.h>\n\n#include \"common.h\"\n\nvoid stopwatch_start(stopwatch *sw){\n    if (sw == NULL)\n        return;\n\n    bzero(&sw->begin, sizeof(struct timeval));\n    bzero(&sw->end  , sizeof(struct timeval));\n\n    gettimeofday(&sw->begin, NULL);\n}\n\nvoid stopwatch_stop(stopwatch *sw){\n    if (sw == NULL)\n        return;\n\n    gettimeofday(&sw->end, NULL);\n}\n\ndouble \nget_interval_by_sec(stopwatch *sw){\n    if (sw == NULL)\n        return 0;\n    return ((double)(sw->end.tv_sec-sw->begin.tv_sec)+(double)(sw->end.tv_usec-sw->begin.tv_usec)/1000000);\n}\n\nint \nget_interval_by_usec(stopwatch *sw){\n    if (sw == NULL)\n        return 0;\n    return ((sw->end.tv_sec-sw->begin.tv_sec)*1000000+(sw->end.tv_usec-sw->begin.tv_usec));\n}\n\nfunc_ret_t \ncreate_matrix_from_file(float **mp, const char* filename, int *size_p){\n  int i, j, size;\n  float *m;\n  FILE *fp = NULL;\n\n  fp = fopen(filename, \"rb\");\n  if ( fp == NULL) {\n      return RET_FAILURE;\n  }\n\n  fscanf(fp, \"%d\\n\", &size);\n\n  m = (float*) malloc(sizeof(float)*size*size);\n  if ( m == NULL) {\n      fclose(fp);\n      return RET_FAILURE;\n  }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n          fscanf(fp, \"%f \", m+i*size+j);\n      }\n  }\n\n  fclose(fp);\n\n  *size_p = size;\n  *mp = m;\n\n  return RET_SUCCESS;\n}\n\n\nvoid\nmatrix_multiply(float *inputa, float *inputb, float *output, int size){\n  int i, j, k;\n\n  for (i=0; i < size; i++)\n    for (k=0; k < size; k++)\n      for (j=0; j < size; j++)\n        output[i*size+j] = inputa[i*size+k] * inputb[k*size+j];\n\n}\n\nvoid\nlud_verify(float *m, float *lu, int matrix_dim){\n  int i,j,k;\n  float *tmp = (float*)malloc(matrix_dim*matrix_dim*sizeof(float));\n\n  for (i=0; i < matrix_dim; i ++)\n    for (j=0; j< matrix_dim; j++) {\n        float sum = 0;\n        float l,u;\n        for (k=0; k <= MIN(i,j); k++){\n            if ( i==k)\n              l=1;\n            else\n              l=lu[i*matrix_dim+k];\n            u=lu[k*matrix_dim+j];\n            sum+=l*u;\n        }\n        tmp[i*matrix_dim+j] = sum;\n    }\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  for (i=0; i<matrix_dim; i++){\n      for (j=0; j<matrix_dim; j++){\n          if ( fabs(m[i*matrix_dim+j]-tmp[i*matrix_dim+j]) > 0.0001)\n            printf(\"dismatch at (%d, %d): (o)%f (n)%f\\n\", i, j, m[i*matrix_dim+j], tmp[i*matrix_dim+j]);\n      }\n  }\n  free(tmp);\n}\n\nvoid\nmatrix_duplicate(float *src, float **dst, int matrix_dim) {\n    int s = matrix_dim*matrix_dim*sizeof(float);\n   float *p = (float *) malloc (s);\n   memcpy(p, src, s);\n   *dst = p;\n}\n\nvoid\nprint_matrix(float *m, int matrix_dim) {\n    int i, j;\n    for (i=0; i<matrix_dim;i++) {\n      for (j=0; j<matrix_dim;j++)\n        printf(\"%f \", m[i*matrix_dim+j]);\n      printf(\"\\n\");\n    }\n}\n\n\n\n\n\nfunc_ret_t\ncreate_matrix(float **mp, int size){\n  float *m;\n  int i,j;\n  float lamda = -0.001;\n  float coe[2*size-1];\n  float coe_i =0.0;\n\n  for (i=0; i < size; i++)\n    {\n      coe_i = 10*exp(lamda*i); \n      j=size-1+i;     \n      coe[j]=coe_i;\n      j=size-1-i;     \n      coe[j]=coe_i;\n    }\n\n  m = (float*) malloc(sizeof(float)*size*size);\n  if ( m == NULL) {\n      return RET_FAILURE;\n  }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n\tm[i*size+j]=coe[size-1-i+j];\n      }\n  }\n\n  *mp = m;\n\n  return RET_SUCCESS;\n}\n"}}
{"kernel_name": "lud", "parallel_api": "serial", "code": {"lud.cpp": "#include <stdio.h>\n#include <unistd.h>\n#include <getopt.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <string.h>\n#include <chrono>\n#include \"common.h\"\n\n#define BLOCK_SIZE 16\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nstatic int do_verify = 0;\nvoid lud_cuda(float *d_m, int matrix_dim);\n\nstatic struct option long_options[] = {\n  \n\n  {\"input\", 1, NULL, 'i'},\n  {\"size\", 1, NULL, 's'},\n  {\"verify\", 0, NULL, 'v'},\n  {0,0,0,0}\n};\n\nint main ( int argc, char *argv[] )\n{\n  printf(\"WG size of kernel = %d X %d\\n\", BLOCK_SIZE, BLOCK_SIZE);\n  int matrix_dim = 32; \n\n  int opt, option_index=0;\n  func_ret_t ret;\n  const char *input_file = NULL;\n  float *m, *mm;\n  stopwatch sw;\n\n  while ((opt = getopt_long(argc, argv, \"::vs:i:\", \n          long_options, &option_index)) != -1 ) {\n    switch(opt){\n      case 'i':\n        input_file = optarg;\n        break;\n      case 'v':\n        do_verify = 1;\n        break;\n      case 's':\n        matrix_dim = atoi(optarg);\n        printf(\"Generate input matrix internally, size =%d\\n\", matrix_dim);\n        break;\n      case '?':\n        fprintf(stderr, \"invalid option\\n\");\n        break;\n      case ':':\n        fprintf(stderr, \"missing argument\\n\");\n        break;\n      default:\n        fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\",\n            argv[0]);\n        exit(EXIT_FAILURE);\n    }\n  }\n\n  if ( (optind < argc) || (optind == 1)) {\n    fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\", argv[0]);\n    exit(EXIT_FAILURE);\n  }  \n\n  if (input_file) {\n    printf(\"Reading matrix from file %s\\n\", input_file);\n    ret = create_matrix_from_file(&m, input_file, &matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix from file %s\\n\", input_file);\n      exit(EXIT_FAILURE);\n    }\n  } \n\n  else if (matrix_dim) {\n    printf(\"Creating matrix internally size=%d\\n\", matrix_dim);\n    ret = create_matrix(&m, matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix internally size=%d\\n\", matrix_dim);\n      exit(EXIT_FAILURE);\n    }\n  }\n  else {\n    printf(\"No input file specified!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  if (do_verify){\n    printf(\"Before LUD\\n\");\n    \n\n    matrix_duplicate(m, &mm, matrix_dim);\n  }\n\n  \n\n  stopwatch_start(&sw);\n\n    {\n  int offset;\n  int i=0;\n  \n  auto start = std::chrono::steady_clock::now();\n\n  for (i=0; i < matrix_dim-BLOCK_SIZE; i += BLOCK_SIZE) {\n    offset = i;  \n\n        {\n      float shadow[BLOCK_SIZE * BLOCK_SIZE];\n            {\n        int i,j;\n        int tx = omp_get_thread_num() ;\n      \n        int array_offset = offset*matrix_dim+offset;\n        for(i=0; i < BLOCK_SIZE; i++){\n          shadow[i * BLOCK_SIZE + tx]=m[array_offset + tx];\n          array_offset += matrix_dim;\n        }\n        \n                \n        for(i=0; i < BLOCK_SIZE-1; i++) {\n      \n          if (tx>i){\n            for(j=0; j < i; j++)\n              shadow[tx * BLOCK_SIZE + i] -= shadow[tx * BLOCK_SIZE + j] * shadow[j * BLOCK_SIZE + i];\n          shadow[tx * BLOCK_SIZE + i] /= shadow[i * BLOCK_SIZE + i];\n          }\n      \n                    if (tx>i){\n      \n            for(j=0; j < i+1; j++)\n              shadow[(i+1) * BLOCK_SIZE + tx] -= shadow[(i+1) * BLOCK_SIZE + j]*shadow[j * BLOCK_SIZE + tx];\n          }\n          \n                  }\n      \n        array_offset = (offset+1)*matrix_dim+offset;\n        for(i=1; i < BLOCK_SIZE; i++){\n          m[array_offset+tx]=shadow[i * BLOCK_SIZE + tx];\n          array_offset += matrix_dim;\n        }\n      }\n    }\n\n        {\n      float dia[BLOCK_SIZE * BLOCK_SIZE];\n      float peri_row[BLOCK_SIZE * BLOCK_SIZE];\n      float peri_col[BLOCK_SIZE * BLOCK_SIZE];\n            {\n         int i,j, array_offset;\n         int idx;\n\n         int  bx = omp_get_team_num();  \n         int  tx = omp_get_thread_num();\n\n         if (tx < BLOCK_SIZE) {\n           idx = tx;\n           array_offset = offset*matrix_dim+offset;\n           for (i=0; i < BLOCK_SIZE/2; i++){\n           dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n           array_offset += matrix_dim;\n           }\n         \n         array_offset = offset*matrix_dim+offset;\n         for (i=0; i < BLOCK_SIZE; i++) {\n           peri_row[i * BLOCK_SIZE+ idx]=m[array_offset+(bx+1)*BLOCK_SIZE+idx];\n           array_offset += matrix_dim;\n         }\n\n         } else {\n         idx = tx-BLOCK_SIZE;\n         \n         array_offset = (offset+BLOCK_SIZE/2)*matrix_dim+offset;\n         for (i=BLOCK_SIZE/2; i < BLOCK_SIZE; i++){\n           dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n           array_offset += matrix_dim;\n         }\n         \n         array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n         for (i=0; i < BLOCK_SIZE; i++) {\n           peri_col[i * BLOCK_SIZE + idx] = m[array_offset+idx];\n           array_offset += matrix_dim;\n         }\n       }\n       \n       if (tx < BLOCK_SIZE) { \n\n         idx=tx;\n         for(i=1; i < BLOCK_SIZE; i++){\n           for (j=0; j < i; j++)\n             peri_row[i * BLOCK_SIZE + idx]-=dia[i * BLOCK_SIZE+ j]*peri_row[j * BLOCK_SIZE + idx];\n         }\n       } else { \n\n         idx=tx - BLOCK_SIZE;\n         for(i=0; i < BLOCK_SIZE; i++){\n           for(j=0; j < i; j++)\n             peri_col[idx * BLOCK_SIZE + i]-=peri_col[idx * BLOCK_SIZE+ j]*dia[j * BLOCK_SIZE + i];\n            peri_col[idx * BLOCK_SIZE + i] /= dia[i * BLOCK_SIZE+ i];\n         }\n       }\n\n              if (tx < BLOCK_SIZE) { \n\n         idx=tx;\n         array_offset = (offset+1)*matrix_dim+offset;\n         for(i=1; i < BLOCK_SIZE; i++){\n           m[array_offset+(bx+1)*BLOCK_SIZE+idx] = peri_row[i*BLOCK_SIZE+idx];\n           array_offset += matrix_dim;\n         }\n       } else { \n\n         idx=tx - BLOCK_SIZE;\n         array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n         for(i=0; i < BLOCK_SIZE; i++){\n           m[array_offset+idx] =  peri_col[i*BLOCK_SIZE+idx];\n           array_offset += matrix_dim;\n         }\n       }\n      }\n    }\n\n        {\n      float peri_row[BLOCK_SIZE * BLOCK_SIZE];\n      float peri_col[BLOCK_SIZE * BLOCK_SIZE];\n            {\n        int  bx = omp_get_team_num() % ((matrix_dim-i)/BLOCK_SIZE-1); \n\n        int  by = omp_get_team_num() / ((matrix_dim-i)/BLOCK_SIZE-1); \n\n        \n        int  tx = omp_get_thread_num() % BLOCK_SIZE; \n\n        int  ty = omp_get_thread_num() / BLOCK_SIZE; \n\n\n        int i;\n        float sum;\n\n        int global_row_id = offset + (by+1)*BLOCK_SIZE;\n        int global_col_id = offset + (bx+1)*BLOCK_SIZE;\n\n        peri_row[ty * BLOCK_SIZE + tx] = m[(offset+ty)*matrix_dim+global_col_id+tx];\n        peri_col[ty * BLOCK_SIZE + tx] = m[(global_row_id+ty)*matrix_dim+offset+tx];\n\n        \n        sum = 0;\n        for (i=0; i < BLOCK_SIZE; i++)\n          sum += peri_col[ty * BLOCK_SIZE + i] * peri_row[i * BLOCK_SIZE + tx];\n        m[(global_row_id+ty)*matrix_dim+global_col_id+tx] -= sum;\n      }\n    }\n  } \n\n\n  offset = i;  \n\n    {\n    float shadow[BLOCK_SIZE * BLOCK_SIZE];\n        {\n      int i,j;\n      int tx = omp_get_thread_num() ;\n    \n      int array_offset = offset*matrix_dim+offset;\n      for(i=0; i < BLOCK_SIZE; i++){\n        shadow[i * BLOCK_SIZE + tx]=m[array_offset + tx];\n        array_offset += matrix_dim;\n      }\n      \n            \n      for(i=0; i < BLOCK_SIZE-1; i++) {\n        if (tx>i) {\n          for(j=0; j < i; j++)\n            shadow[tx * BLOCK_SIZE + i] -= shadow[tx * BLOCK_SIZE + j] * shadow[j * BLOCK_SIZE + i];\n          shadow[tx * BLOCK_SIZE + i] /= shadow[i * BLOCK_SIZE + i];\n        }\n    \n                if (tx>i){\n          for(j=0; j < i+1; j++)\n            shadow[(i+1) * BLOCK_SIZE + tx] -= shadow[(i+1) * BLOCK_SIZE + j]*shadow[j * BLOCK_SIZE + tx];\n        }\n\n              }\n    \n      array_offset = (offset+1)*matrix_dim+offset;\n      for(i=1; i < BLOCK_SIZE; i++){\n        m[array_offset+tx]=shadow[i * BLOCK_SIZE + tx];\n        array_offset += matrix_dim;\n      }\n    }\n   }\n\n   auto end = std::chrono::steady_clock::now();\n   auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n   printf(\"Total kernel execution time : %f (s)\\n\", time * 1e-9f);\n  } \n\n\n  \n\n  stopwatch_stop(&sw);\n  printf(\"Device offloading time (s): %lf\\n\", get_interval_by_sec(&sw));\n\n  if (do_verify){\n    printf(\"After LUD\\n\");\n    \n\n    printf(\">>>Verify<<<<\\n\");\n    lud_verify(mm, m, matrix_dim); \n    free(mm);\n  }\n\n  free(m);\n}", "common.c": "#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <time.h>\n#include <math.h>\n\n#include \"common.h\"\n\nvoid stopwatch_start(stopwatch *sw){\n    if (sw == NULL)\n        return;\n\n    bzero(&sw->begin, sizeof(struct timeval));\n    bzero(&sw->end  , sizeof(struct timeval));\n\n    gettimeofday(&sw->begin, NULL);\n}\n\nvoid stopwatch_stop(stopwatch *sw){\n    if (sw == NULL)\n        return;\n\n    gettimeofday(&sw->end, NULL);\n}\n\ndouble \nget_interval_by_sec(stopwatch *sw){\n    if (sw == NULL)\n        return 0;\n    return ((double)(sw->end.tv_sec-sw->begin.tv_sec)+(double)(sw->end.tv_usec-sw->begin.tv_usec)/1000000);\n}\n\nint \nget_interval_by_usec(stopwatch *sw){\n    if (sw == NULL)\n        return 0;\n    return ((sw->end.tv_sec-sw->begin.tv_sec)*1000000+(sw->end.tv_usec-sw->begin.tv_usec));\n}\n\nfunc_ret_t \ncreate_matrix_from_file(float **mp, const char* filename, int *size_p){\n  int i, j, size;\n  float *m;\n  FILE *fp = NULL;\n\n  fp = fopen(filename, \"rb\");\n  if ( fp == NULL) {\n      return RET_FAILURE;\n  }\n\n  fscanf(fp, \"%d\\n\", &size);\n\n  m = (float*) malloc(sizeof(float)*size*size);\n  if ( m == NULL) {\n      fclose(fp);\n      return RET_FAILURE;\n  }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n          fscanf(fp, \"%f \", m+i*size+j);\n      }\n  }\n\n  fclose(fp);\n\n  *size_p = size;\n  *mp = m;\n\n  return RET_SUCCESS;\n}\n\n\nvoid\nmatrix_multiply(float *inputa, float *inputb, float *output, int size){\n  int i, j, k;\n\n  for (i=0; i < size; i++)\n    for (k=0; k < size; k++)\n      for (j=0; j < size; j++)\n        output[i*size+j] = inputa[i*size+k] * inputb[k*size+j];\n\n}\n\nvoid\nlud_verify(float *m, float *lu, int matrix_dim){\n  int i,j,k;\n  float *tmp = (float*)malloc(matrix_dim*matrix_dim*sizeof(float));\n\n  for (i=0; i < matrix_dim; i ++)\n    for (j=0; j< matrix_dim; j++) {\n        float sum = 0;\n        float l,u;\n        for (k=0; k <= MIN(i,j); k++){\n            if ( i==k)\n              l=1;\n            else\n              l=lu[i*matrix_dim+k];\n            u=lu[k*matrix_dim+j];\n            sum+=l*u;\n        }\n        tmp[i*matrix_dim+j] = sum;\n    }\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n  for (i=0; i<matrix_dim; i++){\n      for (j=0; j<matrix_dim; j++){\n          if ( fabs(m[i*matrix_dim+j]-tmp[i*matrix_dim+j]) > 0.0001)\n            printf(\"dismatch at (%d, %d): (o)%f (n)%f\\n\", i, j, m[i*matrix_dim+j], tmp[i*matrix_dim+j]);\n      }\n  }\n  free(tmp);\n}\n\nvoid\nmatrix_duplicate(float *src, float **dst, int matrix_dim) {\n    int s = matrix_dim*matrix_dim*sizeof(float);\n   float *p = (float *) malloc (s);\n   memcpy(p, src, s);\n   *dst = p;\n}\n\nvoid\nprint_matrix(float *m, int matrix_dim) {\n    int i, j;\n    for (i=0; i<matrix_dim;i++) {\n      for (j=0; j<matrix_dim;j++)\n        printf(\"%f \", m[i*matrix_dim+j]);\n      printf(\"\\n\");\n    }\n}\n\n\n\n\n\nfunc_ret_t\ncreate_matrix(float **mp, int size){\n  float *m;\n  int i,j;\n  float lamda = -0.001;\n  float coe[2*size-1];\n  float coe_i =0.0;\n\n  for (i=0; i < size; i++)\n    {\n      coe_i = 10*exp(lamda*i); \n      j=size-1+i;     \n      coe[j]=coe_i;\n      j=size-1-i;     \n      coe[j]=coe_i;\n    }\n\n  m = (float*) malloc(sizeof(float)*size*size);\n  if ( m == NULL) {\n      return RET_FAILURE;\n  }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n\tm[i*size+j]=coe[size-1-i+j];\n      }\n  }\n\n  *mp = m;\n\n  return RET_SUCCESS;\n}"}}
{"kernel_name": "lzss", "parallel_api": "cuda", "code": {"main.cu": "#include <cuda.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <cmath>\n#include <chrono>\n#include <cub/cub.cuh>\n#include \"utils.h\"\n\n#define BLOCK_SIZE 2048    \n\n#define THREAD_SIZE 128     \n\n#define WINDOW_SIZE 32     \n\n#define INPUT_TYPE uint32_t \n\n\n\n\n\n\ntemplate <typename T>\n__global__ void compressKernelI(const T *input, uint32_t numOfBlocks,\n                                uint32_t *__restrict__ flagArrSizeGlobal,\n                                uint32_t *__restrict__ compressedDataSizeGlobal,\n                                uint8_t *__restrict__ tmpFlagArrGlobal,\n                                uint8_t *__restrict__ tmpCompressedDataGlobal,\n                                int minEncodeLength)\n{\n  \n\n  const uint32_t blockSize = BLOCK_SIZE / sizeof(T);\n\n  \n\n  const uint32_t threadSize = THREAD_SIZE;\n\n  \n\n  \n\n  __shared__ T buffer[blockSize];\n  __shared__ uint8_t lengthBuffer[blockSize];\n  __shared__ uint8_t offsetBuffer[blockSize];\n  __shared__ uint32_t prefixBuffer[blockSize + 1];\n\n  \n\n  int tid = 0;\n\n  \n\n  for (int i = 0; i < blockSize / threadSize; i++)\n  {\n    buffer[threadIdx.x + threadSize * i] =\n        input[blockIdx.x * blockSize + threadIdx.x + threadSize * i];\n  }\n\n  \n\n  __syncthreads();\n\n  \n\n  for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n       iteration++)\n  {\n    \n\n    tid = threadIdx.x + iteration * threadSize;\n    int bufferStart = tid;\n    int bufferPointer = bufferStart;\n    int windowStart =\n        bufferStart - int(WINDOW_SIZE) < 0 ? 0 : bufferStart - WINDOW_SIZE;\n    int windowPointer = windowStart;\n\n    uint8_t maxLen = 0;\n    uint8_t maxOffset = 0;\n    uint8_t len = 0;\n    uint8_t offset = 0;\n\n    while (windowPointer < bufferStart && bufferPointer < blockSize)\n    {\n      if (buffer[bufferPointer] == buffer[windowPointer])\n      {\n        if (offset == 0)\n        {\n          offset = bufferPointer - windowPointer;\n        }\n        len++;\n        bufferPointer++;\n      }\n      else\n      {\n        if (len > maxLen)\n        {\n          maxLen = len;\n          maxOffset = offset;\n        }\n        len = 0;\n        offset = 0;\n        bufferPointer = bufferStart;\n      }\n      windowPointer++;\n    }\n    if (len > maxLen)\n    {\n      maxLen = len;\n      maxOffset = offset;\n    }\n\n    lengthBuffer[threadIdx.x + iteration * threadSize] = maxLen;\n    offsetBuffer[threadIdx.x + iteration * threadSize] = maxOffset;\n\n    \n\n    prefixBuffer[threadIdx.x + iteration * threadSize] = 0;\n  }\n  __syncthreads();\n\n  \n\n  uint32_t flagCount = 0;\n  __shared__ uint8_t byteFlagArr[(blockSize / 8)];\n\n  if (threadIdx.x == 0)\n  {\n    uint8_t flagPosition = 0x01;\n    uint8_t byteFlag = 0;\n\n    int encodeIndex = 0;\n\n    while (encodeIndex < blockSize)\n    {\n      \n\n      if (lengthBuffer[encodeIndex] < minEncodeLength)\n      {\n        prefixBuffer[encodeIndex] = sizeof(T);\n        encodeIndex++;\n      }\n      \n\n      else\n      {\n        prefixBuffer[encodeIndex] = 2;\n        encodeIndex += lengthBuffer[encodeIndex];\n        byteFlag |= flagPosition;\n      }\n      \n\n      if (flagPosition == 0x80)\n      {\n        byteFlagArr[flagCount] = byteFlag;\n        flagCount++;\n        flagPosition = 0x01;\n        byteFlag = 0;\n        continue;\n      }\n      flagPosition <<= 1;\n    }\n    if (flagPosition != 0x01)\n    {\n      byteFlagArr[flagCount] = byteFlag;\n      flagCount++;\n    }\n  }\n  __syncthreads();\n\n  \n\n  int prefixSumOffset = 1;\n  for (uint32_t d = blockSize >> 1; d > 0; d = d >> 1)\n  {\n    for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n         iteration++)\n    {\n      tid = threadIdx.x + iteration * threadSize;\n      if (tid < d)\n      {\n        int ai = prefixSumOffset * (2 * tid + 1) - 1;\n        int bi = prefixSumOffset * (2 * tid + 2) - 1;\n        prefixBuffer[bi] += prefixBuffer[ai];\n      }\n      __syncthreads();\n    }\n    prefixSumOffset *= 2;\n  }\n\n  \n\n  if (threadIdx.x == 0)\n  {\n    \n\n    compressedDataSizeGlobal[blockIdx.x] = prefixBuffer[blockSize - 1];\n    flagArrSizeGlobal[blockIdx.x] = flagCount;\n    prefixBuffer[blockSize] = prefixBuffer[blockSize - 1];\n    prefixBuffer[blockSize - 1] = 0;\n  }\n  __syncthreads();\n\n  \n\n  for (int d = 1; d < blockSize; d *= 2)\n  {\n    prefixSumOffset >>= 1;\n    for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n         iteration++)\n    {\n      tid = threadIdx.x + iteration * threadSize;\n\n      if (tid < d)\n      {\n        int ai = prefixSumOffset * (2 * tid + 1) - 1;\n        int bi = prefixSumOffset * (2 * tid + 2) - 1;\n\n        uint32_t t = prefixBuffer[ai];\n        prefixBuffer[ai] = prefixBuffer[bi];\n        prefixBuffer[bi] += t;\n      }\n      __syncthreads();\n    }\n  }\n\n  \n\n  int tmpCompressedDataGlobalOffset;\n  tmpCompressedDataGlobalOffset = blockSize * blockIdx.x * sizeof(T);\n  for (int iteration = 0; iteration < (int)(blockSize / threadSize); iteration++)\n  {\n    tid = threadIdx.x + iteration * threadSize;\n    if (prefixBuffer[tid + 1] != prefixBuffer[tid])\n    {\n      if (lengthBuffer[tid] < minEncodeLength)\n      {\n        uint32_t tmpOffset = prefixBuffer[tid];\n        uint8_t *bytePtr = (uint8_t *)&buffer[tid];\n        for (int tmpIndex = 0; tmpIndex < sizeof(T); tmpIndex++)\n        {\n          tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset + tmpIndex] = *(bytePtr + tmpIndex);\n        }\n      }\n      else\n      {\n        uint32_t tmpOffset = prefixBuffer[tid];\n        tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset] = lengthBuffer[tid];\n        tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset + 1] = offsetBuffer[tid];\n      }\n    }\n  }\n\n  \n\n  if (threadIdx.x == 0)\n  {\n    for (int flagArrIndex = 0; flagArrIndex < flagCount; flagArrIndex++)\n    {\n      tmpFlagArrGlobal[blockSize / 8 * blockIdx.x + flagArrIndex] = byteFlagArr[flagArrIndex];\n    }\n  }\n}\n\n\n\ntemplate <typename T>\n__global__ void compressKernelIII(uint32_t numOfBlocks,\n                                  const uint32_t *__restrict__ flagArrOffsetGlobal,\n                                  const uint32_t *__restrict__ compressedDataOffsetGlobal,\n                                  const uint8_t *__restrict__ tmpFlagArrGlobal,\n                                  const uint8_t *__restrict__ tmpCompressedDataGlobal,\n                                  uint8_t *__restrict__ flagArrGlobal,\n                                  uint8_t *__restrict__ compressedDataGlobal)\n{\n  \n\n  const int blockSize = BLOCK_SIZE / sizeof(T);\n\n  \n\n  const int threadSize = THREAD_SIZE;\n\n  \n\n  int blockIndex = blockIdx.x;\n\n  int flagArrOffset = flagArrOffsetGlobal[blockIndex];\n  int flagArrSize = flagArrOffsetGlobal[blockIndex + 1] - flagArrOffsetGlobal[blockIndex];\n\n  int compressedDataOffset = compressedDataOffsetGlobal[blockIndex];\n  int compressedDataSize = compressedDataOffsetGlobal[blockIndex + 1] - compressedDataOffsetGlobal[blockIndex];\n\n  int tid = threadIdx.x;\n\n  while (tid < flagArrSize)\n  {\n    flagArrGlobal[flagArrOffset + tid] = tmpFlagArrGlobal[blockSize / 8 * blockIndex + tid];\n    tid += threadSize;\n  }\n\n  tid = threadIdx.x;\n\n  while (tid < compressedDataSize)\n  {\n    compressedDataGlobal[compressedDataOffset + tid] = tmpCompressedDataGlobal[blockSize * sizeof(T) * blockIndex + tid];\n    tid += threadSize;\n  }\n}\n\n\n\ntemplate <typename T>\n__global__ void decompressKernel(T *output, uint32_t numOfBlocks,\n                                 const uint32_t *__restrict__ flagArrOffsetGlobal,\n                                 const uint32_t *__restrict__ compressedDataOffsetGlobal,\n                                 const uint8_t *__restrict__ flagArrGlobal,\n                                 const uint8_t *__restrict__ compressedDataGlobal)\n{\n  \n\n  const uint32_t blockSize = BLOCK_SIZE / sizeof(T);\n\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (tid < numOfBlocks)\n  {\n    int flagArrOffset = flagArrOffsetGlobal[tid];\n    int flagArrSize = flagArrOffsetGlobal[tid + 1] - flagArrOffsetGlobal[tid];\n\n    int compressedDataOffset = compressedDataOffsetGlobal[tid];\n\n    uint32_t dataPointsIndex = 0;\n    uint32_t compressedDataIndex = 0;\n\n    uint8_t byteFlag;\n\n    for (int flagArrayIndex = 0; flagArrayIndex < flagArrSize; flagArrayIndex++)\n    {\n      byteFlag = flagArrGlobal[flagArrOffset + flagArrayIndex];\n\n      for (int bitCount = 0; bitCount < 8; bitCount++)\n      {\n        int matchFlag = (byteFlag >> bitCount) & 0x1;\n        if (matchFlag == 1)\n        {\n          int length = compressedDataGlobal[compressedDataOffset + compressedDataIndex];\n          int offset = compressedDataGlobal[compressedDataOffset + compressedDataIndex + 1];\n          compressedDataIndex += 2;\n          int dataPointsStart = dataPointsIndex;\n          for (int tmpDecompIndex = 0; tmpDecompIndex < length; tmpDecompIndex++)\n          {\n            output[tid * blockSize + dataPointsIndex] = output[tid * blockSize + dataPointsStart - offset + tmpDecompIndex];\n            dataPointsIndex++;\n          }\n        }\n        else\n        {\n          uint8_t *tmpPtr = (uint8_t *)&output[tid * blockSize + dataPointsIndex];\n          for (int tmpDecompIndex = 0; tmpDecompIndex < sizeof(T); tmpDecompIndex++)\n          {\n            *(tmpPtr + tmpDecompIndex) = compressedDataGlobal[compressedDataOffset + compressedDataIndex + tmpDecompIndex];\n          }\n\n          compressedDataIndex += sizeof(T);\n          dataPointsIndex++;\n        }\n        if (dataPointsIndex >= blockSize)\n        {\n          return;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  std::string inputFileName;\n  int opt;\n  int repeat = 1;\n\n  \n\n  while ((opt = getopt(argc, argv, \"i:n:h\")) != -1)\n  {\n    switch (opt)\n    {\n    case 'i': \n\n      inputFileName = optarg;\n      break;\n\n    case 'n':\n      repeat = atoi(optarg);\n      break;\n\n    case 'h': \n\n      printf(\" Usage for compression and decompression: ./main -i {inputfile} -n {repeat}\\n\");\n      return 0;\n    }\n  }\n\n  INPUT_TYPE *hostArray = io::read_binary_to_new_array<INPUT_TYPE>(inputFileName);\n\n#ifdef DEBUG\n  int debugOffset = 0;\n\n  printf(\"print the first 1024 elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    std::cout << hostArray[tmpIndex + debugOffset] << \"\\t\";\n  }\n  printf(\"\\n\");\n#endif\n\n  INPUT_TYPE *deviceArray;\n  INPUT_TYPE *deviceOutput;\n  uint32_t fileSize = io::FileSize(inputFileName);\n\n  uint32_t *flagArrSizeGlobal;\n  uint32_t *flagArrOffsetGlobal;\n  uint32_t *compressedDataSizeGlobal;\n  uint32_t *compressedDataOffsetGlobal;\n  uint8_t *tmpFlagArrGlobal;\n  uint8_t *tmpCompressedDataGlobal;\n  uint8_t *flagArrGlobal;\n  uint8_t *compressedDataGlobal;\n\n  \n\n  uint32_t paddingSize = fileSize % BLOCK_SIZE == 0 ? 0 : BLOCK_SIZE - fileSize % BLOCK_SIZE;\n\n  \n\n  uint32_t datatypeSize =\n      static_cast<uint32_t>((fileSize + paddingSize) / sizeof(INPUT_TYPE));\n\n  uint32_t numOfBlocks = datatypeSize * sizeof(INPUT_TYPE) / BLOCK_SIZE;\n\n  INPUT_TYPE *hostOutput = (INPUT_TYPE *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n\n  \n\n  cudaMalloc((void **)&deviceArray, fileSize + paddingSize);\n  cudaMalloc((void **)&deviceOutput, fileSize + paddingSize);\n\n  cudaMalloc((void **)&flagArrSizeGlobal, sizeof(uint32_t) * (numOfBlocks + 1));\n  cudaMalloc((void **)&flagArrOffsetGlobal, sizeof(uint32_t) * (numOfBlocks + 1));\n  cudaMalloc((void **)&compressedDataSizeGlobal, sizeof(uint32_t) * (numOfBlocks + 1));\n  cudaMalloc((void **)&compressedDataOffsetGlobal, sizeof(uint32_t) * (numOfBlocks + 1));\n  cudaMalloc((void **)&tmpFlagArrGlobal, sizeof(uint8_t) * datatypeSize / 8);\n  cudaMalloc((void **)&tmpCompressedDataGlobal, sizeof(INPUT_TYPE) * datatypeSize);\n  cudaMalloc((void **)&flagArrGlobal, sizeof(uint8_t) * datatypeSize / 8);\n  cudaMalloc((void **)&compressedDataGlobal, sizeof(INPUT_TYPE) * datatypeSize);\n\n  \n\n  cudaMemset(deviceArray, 0, fileSize + paddingSize);\n  cudaMemset(deviceOutput, 0, fileSize + paddingSize);\n  cudaMemset(flagArrSizeGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  cudaMemset(flagArrOffsetGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  cudaMemset(compressedDataSizeGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  cudaMemset(compressedDataOffsetGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  cudaMemset(tmpFlagArrGlobal, 0, sizeof(uint8_t) * datatypeSize / 8);\n  cudaMemset(tmpCompressedDataGlobal, 0, sizeof(INPUT_TYPE) * datatypeSize);\n\n  \n\n\n  \n\n  cudaMemcpy(deviceArray, hostArray, fileSize, cudaMemcpyHostToDevice);\n\n  \n\n\n  dim3 gridDim(numOfBlocks);\n  dim3 blockDim(THREAD_SIZE);\n\n  dim3 deGridDim(ceil(float(numOfBlocks) / 32));\n  dim3 deBlockDim(32);\n\n  uint32_t *flagArrOffsetGlobalHost;\n  uint32_t *compressedDataOffsetGlobalHost;\n  uint8_t *tmpFlagArrGlobalHost;\n  uint8_t *tmpCompressedDataGlobalHost;\n  uint8_t *flagArrGlobalHost;\n  uint8_t *compressedDataGlobalHost;\n\n  flagArrOffsetGlobalHost = (uint32_t *)malloc(sizeof(uint32_t) * (numOfBlocks + 1));\n  compressedDataOffsetGlobalHost = (uint32_t *)malloc(sizeof(uint32_t) * (numOfBlocks + 1));\n  tmpFlagArrGlobalHost = (uint8_t *)malloc(sizeof(uint8_t) * datatypeSize / 8);\n  tmpCompressedDataGlobalHost = (uint8_t *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n  flagArrGlobalHost = (uint8_t *)malloc(sizeof(uint8_t) * datatypeSize / 8);\n  compressedDataGlobalHost = (uint8_t *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n\n  int minEncodeLength = sizeof(INPUT_TYPE) == 1 ? 2 : 1;\n\n  cudaDeviceSynchronize();\n  auto compStart = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    compressKernelI<INPUT_TYPE><<<gridDim, blockDim>>>(deviceArray, numOfBlocks, flagArrSizeGlobal, compressedDataSizeGlobal, tmpFlagArrGlobal, tmpCompressedDataGlobal, minEncodeLength);\n\n    \n\n    void *flag_d_temp_storage = NULL;\n    size_t flag_temp_storage_bytes = 0;\n    cub::DeviceScan::ExclusiveSum(flag_d_temp_storage, flag_temp_storage_bytes, flagArrSizeGlobal, flagArrOffsetGlobal, numOfBlocks + 1);\n\n    \n\n    cudaMalloc(&flag_d_temp_storage, flag_temp_storage_bytes);\n\n    \n\n    cub::DeviceScan::ExclusiveSum(flag_d_temp_storage, flag_temp_storage_bytes, flagArrSizeGlobal, flagArrOffsetGlobal, numOfBlocks + 1);\n\n    \n\n    void *data_d_temp_storage = NULL;\n    size_t data_temp_storage_bytes = 0;\n    cub::DeviceScan::ExclusiveSum(data_d_temp_storage, data_temp_storage_bytes, compressedDataSizeGlobal, compressedDataOffsetGlobal, numOfBlocks + 1);\n\n    \n\n    cudaMalloc(&data_d_temp_storage, data_temp_storage_bytes);\n\n    \n\n    cub::DeviceScan::ExclusiveSum(data_d_temp_storage, data_temp_storage_bytes, compressedDataSizeGlobal, compressedDataOffsetGlobal, numOfBlocks + 1);\n\n    compressKernelIII<INPUT_TYPE><<<gridDim, blockDim>>>(numOfBlocks, flagArrOffsetGlobal, compressedDataOffsetGlobal, tmpFlagArrGlobal, tmpCompressedDataGlobal, flagArrGlobal, compressedDataGlobal);\n\n    cudaDeviceSynchronize();\n\n    cudaFree(flag_d_temp_storage);\n    cudaFree(data_d_temp_storage);\n  }\n  auto compStop = std::chrono::steady_clock::now();\n\n  auto decompStart = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    decompressKernel<INPUT_TYPE><<<deGridDim, deBlockDim>>>(deviceOutput, numOfBlocks, flagArrOffsetGlobal, compressedDataOffsetGlobal, flagArrGlobal, compressedDataGlobal);\n    cudaDeviceSynchronize();\n  }\n  auto decompStop = std::chrono::steady_clock::now();\n\n  \n\n  cudaMemcpy(flagArrOffsetGlobalHost, flagArrOffsetGlobal, sizeof(uint32_t) * (numOfBlocks + 1), cudaMemcpyDeviceToHost);\n  cudaMemcpy(compressedDataOffsetGlobalHost, compressedDataOffsetGlobal, sizeof(uint32_t) * (numOfBlocks + 1), cudaMemcpyDeviceToHost);\n  cudaMemcpy(tmpFlagArrGlobalHost, tmpFlagArrGlobal, sizeof(uint8_t) * datatypeSize / 8, cudaMemcpyDeviceToHost);\n  cudaMemcpy(tmpCompressedDataGlobalHost, tmpCompressedDataGlobal, sizeof(INPUT_TYPE) * datatypeSize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(flagArrGlobalHost, flagArrGlobal, sizeof(uint8_t) * datatypeSize / 8, cudaMemcpyDeviceToHost);\n  cudaMemcpy(compressedDataGlobalHost, compressedDataGlobal, sizeof(INPUT_TYPE) * datatypeSize, cudaMemcpyDeviceToHost);\n  cudaMemcpy(hostOutput, deviceOutput, fileSize, cudaMemcpyDeviceToHost);\n\n#ifdef DEBUG\n  printf(\"print the first 1024 flag array offset elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", flagArrOffsetGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 compressed data offset elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", compressedDataOffsetGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 flag array elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", flagArrGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 compressed data elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", compressedDataGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n#endif\n\n  \n\n  for (uint32_t verifyIndex = 0; verifyIndex < fileSize / sizeof(INPUT_TYPE); verifyIndex++)\n  {\n    if (hostArray[verifyIndex] != hostOutput[verifyIndex])\n    {\n      printf(\"verification failed!!! Index %d is wrong\\n\", verifyIndex);\n      std::cout << \"hostArray: \" << hostArray[verifyIndex] << \", hostOutput: \" << hostOutput[verifyIndex] << std::endl;\n      break;\n    }\n  }\n\n  float originalSize = fileSize;\n  float compressedSize = sizeof(uint32_t) * (numOfBlocks + 1) * 2 + flagArrOffsetGlobalHost[numOfBlocks] + compressedDataOffsetGlobalHost[numOfBlocks];\n  float compressionRatio = originalSize / compressedSize;\n  std::cout << \"compression ratio: \" << compressionRatio << std::endl;\n\n  float compTime = std::chrono::duration<float, std::milli>(compStop - compStart).count();\n  float decompTime = std::chrono::duration<float, std::milli>(decompStop - decompStart).count();\n  float compTp = float(fileSize) / 1024 / 1024 / (compTime / repeat);\n  float decompTp = float(fileSize) / 1024 / 1024 / (decompTime / repeat);\n  std::cout << \"compression e2e throughput: \" << compTp << \" GB/s\" << std::endl;\n  std::cout << \"decompression e2e throughput: \" << decompTp << \" GB/s\" << std::endl;\n\n  \n\n  free(flagArrOffsetGlobalHost);\n  free(compressedDataOffsetGlobalHost);\n  free(tmpFlagArrGlobalHost);\n  free(tmpCompressedDataGlobalHost);\n  free(flagArrGlobalHost);\n  free(compressedDataGlobalHost);\n\n  cudaFree(deviceArray);\n  cudaFree(deviceOutput);\n\n  cudaFree(flagArrSizeGlobal);\n  cudaFree(flagArrOffsetGlobal);\n  cudaFree(compressedDataSizeGlobal);\n  cudaFree(compressedDataOffsetGlobal);\n  cudaFree(tmpFlagArrGlobal);\n  cudaFree(tmpCompressedDataGlobal);\n  cudaFree(flagArrGlobal);\n  cudaFree(compressedDataGlobal);\n\n  free(hostOutput);\n  delete hostArray;\n\n  return 0;\n}\n"}}
{"kernel_name": "lzss", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <cmath>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include <hipcub/hipcub.hpp>\n#include \"utils.h\"\n\n#define BLOCK_SIZE 2048    \n\n#define THREAD_SIZE 128     \n\n#define WINDOW_SIZE 32     \n\n#define INPUT_TYPE uint32_t \n\n\n\n\n\n\ntemplate <typename T>\n__global__ void compressKernelI(const T *input, uint32_t numOfBlocks,\n                                uint32_t *__restrict__ flagArrSizeGlobal,\n                                uint32_t *__restrict__ compressedDataSizeGlobal,\n                                uint8_t *__restrict__ tmpFlagArrGlobal,\n                                uint8_t *__restrict__ tmpCompressedDataGlobal,\n                                int minEncodeLength)\n{\n  \n\n  const uint32_t blockSize = BLOCK_SIZE / sizeof(T);\n\n  \n\n  const uint32_t threadSize = THREAD_SIZE;\n\n  \n\n  \n\n  __shared__ T buffer[blockSize];\n  __shared__ uint8_t lengthBuffer[blockSize];\n  __shared__ uint8_t offsetBuffer[blockSize];\n  __shared__ uint32_t prefixBuffer[blockSize + 1];\n\n  \n\n  int tid = 0;\n\n  \n\n  for (int i = 0; i < blockSize / threadSize; i++)\n  {\n    buffer[threadIdx.x + threadSize * i] =\n        input[blockIdx.x * blockSize + threadIdx.x + threadSize * i];\n  }\n\n  \n\n  __syncthreads();\n\n  \n\n  for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n       iteration++)\n  {\n    \n\n    tid = threadIdx.x + iteration * threadSize;\n    int bufferStart = tid;\n    int bufferPointer = bufferStart;\n    int windowStart =\n        bufferStart - int(WINDOW_SIZE) < 0 ? 0 : bufferStart - WINDOW_SIZE;\n    int windowPointer = windowStart;\n\n    uint8_t maxLen = 0;\n    uint8_t maxOffset = 0;\n    uint8_t len = 0;\n    uint8_t offset = 0;\n\n    while (windowPointer < bufferStart && bufferPointer < blockSize)\n    {\n      if (buffer[bufferPointer] == buffer[windowPointer])\n      {\n        if (offset == 0)\n        {\n          offset = bufferPointer - windowPointer;\n        }\n        len++;\n        bufferPointer++;\n      }\n      else\n      {\n        if (len > maxLen)\n        {\n          maxLen = len;\n          maxOffset = offset;\n        }\n        len = 0;\n        offset = 0;\n        bufferPointer = bufferStart;\n      }\n      windowPointer++;\n    }\n    if (len > maxLen)\n    {\n      maxLen = len;\n      maxOffset = offset;\n    }\n\n    lengthBuffer[threadIdx.x + iteration * threadSize] = maxLen;\n    offsetBuffer[threadIdx.x + iteration * threadSize] = maxOffset;\n\n    \n\n    prefixBuffer[threadIdx.x + iteration * threadSize] = 0;\n  }\n  __syncthreads();\n\n  \n\n  uint32_t flagCount = 0;\n  __shared__ uint8_t byteFlagArr[(blockSize / 8)];\n\n  if (threadIdx.x == 0)\n  {\n    uint8_t flagPosition = 0x01;\n    uint8_t byteFlag = 0;\n\n    int encodeIndex = 0;\n\n    while (encodeIndex < blockSize)\n    {\n      \n\n      if (lengthBuffer[encodeIndex] < minEncodeLength)\n      {\n        prefixBuffer[encodeIndex] = sizeof(T);\n        encodeIndex++;\n      }\n      \n\n      else\n      {\n        prefixBuffer[encodeIndex] = 2;\n        encodeIndex += lengthBuffer[encodeIndex];\n        byteFlag |= flagPosition;\n      }\n      \n\n      if (flagPosition == 0x80)\n      {\n        byteFlagArr[flagCount] = byteFlag;\n        flagCount++;\n        flagPosition = 0x01;\n        byteFlag = 0;\n        continue;\n      }\n      flagPosition <<= 1;\n    }\n    if (flagPosition != 0x01)\n    {\n      byteFlagArr[flagCount] = byteFlag;\n      flagCount++;\n    }\n  }\n  __syncthreads();\n\n  \n\n  int prefixSumOffset = 1;\n  for (uint32_t d = blockSize >> 1; d > 0; d = d >> 1)\n  {\n    for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n         iteration++)\n    {\n      tid = threadIdx.x + iteration * threadSize;\n      if (tid < d)\n      {\n        int ai = prefixSumOffset * (2 * tid + 1) - 1;\n        int bi = prefixSumOffset * (2 * tid + 2) - 1;\n        prefixBuffer[bi] += prefixBuffer[ai];\n      }\n      __syncthreads();\n    }\n    prefixSumOffset *= 2;\n  }\n\n  \n\n  if (threadIdx.x == 0)\n  {\n    \n\n    compressedDataSizeGlobal[blockIdx.x] = prefixBuffer[blockSize - 1];\n    flagArrSizeGlobal[blockIdx.x] = flagCount;\n    prefixBuffer[blockSize] = prefixBuffer[blockSize - 1];\n    prefixBuffer[blockSize - 1] = 0;\n  }\n  __syncthreads();\n\n  \n\n  for (int d = 1; d < blockSize; d *= 2)\n  {\n    prefixSumOffset >>= 1;\n    for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n         iteration++)\n    {\n      tid = threadIdx.x + iteration * threadSize;\n\n      if (tid < d)\n      {\n        int ai = prefixSumOffset * (2 * tid + 1) - 1;\n        int bi = prefixSumOffset * (2 * tid + 2) - 1;\n\n        uint32_t t = prefixBuffer[ai];\n        prefixBuffer[ai] = prefixBuffer[bi];\n        prefixBuffer[bi] += t;\n      }\n      __syncthreads();\n    }\n  }\n\n  \n\n  int tmpCompressedDataGlobalOffset;\n  tmpCompressedDataGlobalOffset = blockSize * blockIdx.x * sizeof(T);\n  for (int iteration = 0; iteration < (int)(blockSize / threadSize); iteration++)\n  {\n    tid = threadIdx.x + iteration * threadSize;\n    if (prefixBuffer[tid + 1] != prefixBuffer[tid])\n    {\n      if (lengthBuffer[tid] < minEncodeLength)\n      {\n        uint32_t tmpOffset = prefixBuffer[tid];\n        uint8_t *bytePtr = (uint8_t *)&buffer[tid];\n        for (int tmpIndex = 0; tmpIndex < sizeof(T); tmpIndex++)\n        {\n          tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset + tmpIndex] = *(bytePtr + tmpIndex);\n        }\n      }\n      else\n      {\n        uint32_t tmpOffset = prefixBuffer[tid];\n        tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset] = lengthBuffer[tid];\n        tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset + 1] = offsetBuffer[tid];\n      }\n    }\n  }\n\n  \n\n  if (threadIdx.x == 0)\n  {\n    for (int flagArrIndex = 0; flagArrIndex < flagCount; flagArrIndex++)\n    {\n      tmpFlagArrGlobal[blockSize / 8 * blockIdx.x + flagArrIndex] = byteFlagArr[flagArrIndex];\n    }\n  }\n}\n\n\n\ntemplate <typename T>\n__global__ void compressKernelIII(uint32_t numOfBlocks,\n                                  const uint32_t *__restrict__ flagArrOffsetGlobal,\n                                  const uint32_t *__restrict__ compressedDataOffsetGlobal,\n                                  const uint8_t *__restrict__ tmpFlagArrGlobal,\n                                  const uint8_t *__restrict__ tmpCompressedDataGlobal,\n                                  uint8_t *__restrict__ flagArrGlobal,\n                                  uint8_t *__restrict__ compressedDataGlobal)\n{\n  \n\n  const int blockSize = BLOCK_SIZE / sizeof(T);\n\n  \n\n  const int threadSize = THREAD_SIZE;\n\n  \n\n  int blockIndex = blockIdx.x;\n\n  int flagArrOffset = flagArrOffsetGlobal[blockIndex];\n  int flagArrSize = flagArrOffsetGlobal[blockIndex + 1] - flagArrOffsetGlobal[blockIndex];\n\n  int compressedDataOffset = compressedDataOffsetGlobal[blockIndex];\n  int compressedDataSize = compressedDataOffsetGlobal[blockIndex + 1] - compressedDataOffsetGlobal[blockIndex];\n\n  int tid = threadIdx.x;\n\n  while (tid < flagArrSize)\n  {\n    flagArrGlobal[flagArrOffset + tid] = tmpFlagArrGlobal[blockSize / 8 * blockIndex + tid];\n    tid += threadSize;\n  }\n\n  tid = threadIdx.x;\n\n  while (tid < compressedDataSize)\n  {\n    compressedDataGlobal[compressedDataOffset + tid] = tmpCompressedDataGlobal[blockSize * sizeof(T) * blockIndex + tid];\n    tid += threadSize;\n  }\n}\n\n\n\ntemplate <typename T>\n__global__ void decompressKernel(T *output, uint32_t numOfBlocks,\n                                 const uint32_t *__restrict__ flagArrOffsetGlobal,\n                                 const uint32_t *__restrict__ compressedDataOffsetGlobal,\n                                 const uint8_t *__restrict__ flagArrGlobal,\n                                 const uint8_t *__restrict__ compressedDataGlobal)\n{\n  \n\n  const uint32_t blockSize = BLOCK_SIZE / sizeof(T);\n\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (tid < numOfBlocks)\n  {\n    int flagArrOffset = flagArrOffsetGlobal[tid];\n    int flagArrSize = flagArrOffsetGlobal[tid + 1] - flagArrOffsetGlobal[tid];\n\n    int compressedDataOffset = compressedDataOffsetGlobal[tid];\n\n    uint32_t dataPointsIndex = 0;\n    uint32_t compressedDataIndex = 0;\n\n    uint8_t byteFlag;\n\n    for (int flagArrayIndex = 0; flagArrayIndex < flagArrSize; flagArrayIndex++)\n    {\n      byteFlag = flagArrGlobal[flagArrOffset + flagArrayIndex];\n\n      for (int bitCount = 0; bitCount < 8; bitCount++)\n      {\n        int matchFlag = (byteFlag >> bitCount) & 0x1;\n        if (matchFlag == 1)\n        {\n          int length = compressedDataGlobal[compressedDataOffset + compressedDataIndex];\n          int offset = compressedDataGlobal[compressedDataOffset + compressedDataIndex + 1];\n          compressedDataIndex += 2;\n          int dataPointsStart = dataPointsIndex;\n          for (int tmpDecompIndex = 0; tmpDecompIndex < length; tmpDecompIndex++)\n          {\n            output[tid * blockSize + dataPointsIndex] = output[tid * blockSize + dataPointsStart - offset + tmpDecompIndex];\n            dataPointsIndex++;\n          }\n        }\n        else\n        {\n          uint8_t *tmpPtr = (uint8_t *)&output[tid * blockSize + dataPointsIndex];\n          for (int tmpDecompIndex = 0; tmpDecompIndex < sizeof(T); tmpDecompIndex++)\n          {\n            *(tmpPtr + tmpDecompIndex) = compressedDataGlobal[compressedDataOffset + compressedDataIndex + tmpDecompIndex];\n          }\n\n          compressedDataIndex += sizeof(T);\n          dataPointsIndex++;\n        }\n        if (dataPointsIndex >= blockSize)\n        {\n          return;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  std::string inputFileName;\n  int opt;\n\n  \n\n  while ((opt = getopt(argc, argv, \"i:h\")) != -1)\n  {\n    switch (opt)\n    {\n    case 'i': \n\n      inputFileName = optarg;\n      break;\n\n    case 'h': \n\n      printf(\" Usage for compression and decompression: ./main -i {inputfile}\\n\");\n      return 0;\n    }\n  }\n\n  INPUT_TYPE *hostArray = io::read_binary_to_new_array<INPUT_TYPE>(inputFileName);\n\n#ifdef DEBUG\n  int debugOffset = 0;\n\n  printf(\"print the first 1024 elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    std::cout << hostArray[tmpIndex + debugOffset] << \"\\t\";\n  }\n  printf(\"\\n\");\n#endif\n\n  INPUT_TYPE *deviceArray;\n  INPUT_TYPE *deviceOutput;\n  uint32_t fileSize = io::FileSize(inputFileName);\n\n  uint32_t *flagArrSizeGlobal;\n  uint32_t *flagArrOffsetGlobal;\n  uint32_t *compressedDataSizeGlobal;\n  uint32_t *compressedDataOffsetGlobal;\n  uint8_t *tmpFlagArrGlobal;\n  uint8_t *tmpCompressedDataGlobal;\n  uint8_t *flagArrGlobal;\n  uint8_t *compressedDataGlobal;\n\n  \n\n  uint32_t paddingSize = fileSize % BLOCK_SIZE == 0 ? 0 : BLOCK_SIZE - fileSize % BLOCK_SIZE;\n\n  \n\n  uint32_t datatypeSize =\n      static_cast<uint32_t>((fileSize + paddingSize) / sizeof(INPUT_TYPE));\n\n  uint32_t numOfBlocks = datatypeSize * sizeof(INPUT_TYPE) / BLOCK_SIZE;\n\n  INPUT_TYPE *hostOutput = (INPUT_TYPE *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n\n  \n\n  hipMalloc((void **)&deviceArray, fileSize + paddingSize);\n  hipMalloc((void **)&deviceOutput, fileSize + paddingSize);\n\n  hipMalloc((void **)&flagArrSizeGlobal, sizeof(uint32_t) * (numOfBlocks + 1));\n  hipMalloc((void **)&flagArrOffsetGlobal, sizeof(uint32_t) * (numOfBlocks + 1));\n  hipMalloc((void **)&compressedDataSizeGlobal, sizeof(uint32_t) * (numOfBlocks + 1));\n  hipMalloc((void **)&compressedDataOffsetGlobal, sizeof(uint32_t) * (numOfBlocks + 1));\n  hipMalloc((void **)&tmpFlagArrGlobal, sizeof(uint8_t) * datatypeSize / 8);\n  hipMalloc((void **)&tmpCompressedDataGlobal, sizeof(INPUT_TYPE) * datatypeSize);\n  hipMalloc((void **)&flagArrGlobal, sizeof(uint8_t) * datatypeSize / 8);\n  hipMalloc((void **)&compressedDataGlobal, sizeof(INPUT_TYPE) * datatypeSize);\n\n  \n\n  hipMemset(deviceArray, 0, fileSize + paddingSize);\n  hipMemset(deviceOutput, 0, fileSize + paddingSize);\n  hipMemset(flagArrSizeGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  hipMemset(flagArrOffsetGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  hipMemset(compressedDataSizeGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  hipMemset(compressedDataOffsetGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  hipMemset(tmpFlagArrGlobal, 0, sizeof(uint8_t) * datatypeSize / 8);\n  hipMemset(tmpCompressedDataGlobal, 0, sizeof(INPUT_TYPE) * datatypeSize);\n\n  \n\n\n  \n\n  hipMemcpy(deviceArray, hostArray, fileSize, hipMemcpyHostToDevice);\n\n  \n\n\n  dim3 gridDim(numOfBlocks);\n  dim3 blockDim(THREAD_SIZE);\n\n  dim3 deGridDim(ceil(float(numOfBlocks) / 32));\n  dim3 deBlockDim(32);\n\n  uint32_t *flagArrOffsetGlobalHost;\n  uint32_t *compressedDataOffsetGlobalHost;\n  uint8_t *tmpFlagArrGlobalHost;\n  uint8_t *tmpCompressedDataGlobalHost;\n  uint8_t *flagArrGlobalHost;\n  uint8_t *compressedDataGlobalHost;\n\n  flagArrOffsetGlobalHost = (uint32_t *)malloc(sizeof(uint32_t) * (numOfBlocks + 1));\n  compressedDataOffsetGlobalHost = (uint32_t *)malloc(sizeof(uint32_t) * (numOfBlocks + 1));\n  tmpFlagArrGlobalHost = (uint8_t *)malloc(sizeof(uint8_t) * datatypeSize / 8);\n  tmpCompressedDataGlobalHost = (uint8_t *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n  flagArrGlobalHost = (uint8_t *)malloc(sizeof(uint8_t) * datatypeSize / 8);\n  compressedDataGlobalHost = (uint8_t *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n\n  int minEncodeLength = sizeof(INPUT_TYPE) == 1 ? 2 : 1;\n\n  hipDeviceSynchronize();\n  auto compStart = std::chrono::steady_clock::now();\n\n  \n\n  compressKernelI<INPUT_TYPE><<<gridDim, blockDim>>>(deviceArray, numOfBlocks, flagArrSizeGlobal, compressedDataSizeGlobal, tmpFlagArrGlobal, tmpCompressedDataGlobal, minEncodeLength);\n\n  \n\n  void *flag_d_temp_storage = NULL;\n  size_t flag_temp_storage_bytes = 0;\n  hipcub::DeviceScan::ExclusiveSum(flag_d_temp_storage, flag_temp_storage_bytes, flagArrSizeGlobal, flagArrOffsetGlobal, numOfBlocks + 1);\n\n  \n\n  hipMalloc(&flag_d_temp_storage, flag_temp_storage_bytes);\n\n  \n\n  hipcub::DeviceScan::ExclusiveSum(flag_d_temp_storage, flag_temp_storage_bytes, flagArrSizeGlobal, flagArrOffsetGlobal, numOfBlocks + 1);\n\n  \n\n  void *data_d_temp_storage = NULL;\n  size_t data_temp_storage_bytes = 0;\n  hipcub::DeviceScan::ExclusiveSum(data_d_temp_storage, data_temp_storage_bytes, compressedDataSizeGlobal, compressedDataOffsetGlobal, numOfBlocks + 1);\n\n  \n\n  hipMalloc(&data_d_temp_storage, data_temp_storage_bytes);\n\n  \n\n  hipcub::DeviceScan::ExclusiveSum(data_d_temp_storage, data_temp_storage_bytes, compressedDataSizeGlobal, compressedDataOffsetGlobal, numOfBlocks + 1);\n\n  compressKernelIII<INPUT_TYPE><<<gridDim, blockDim>>>(numOfBlocks, flagArrOffsetGlobal, compressedDataOffsetGlobal, tmpFlagArrGlobal, tmpCompressedDataGlobal, flagArrGlobal, compressedDataGlobal);\n\n\n  hipDeviceSynchronize();\n  auto compStop = std::chrono::steady_clock::now();\n\n  auto decompStart = std::chrono::steady_clock::now();\n\n  decompressKernel<INPUT_TYPE><<<deGridDim, deBlockDim>>>(deviceOutput, numOfBlocks, flagArrOffsetGlobal, compressedDataOffsetGlobal, flagArrGlobal, compressedDataGlobal);\n\n  hipDeviceSynchronize();\n  auto decompStop = std::chrono::steady_clock::now();\n\n  \n\n  hipMemcpy(flagArrOffsetGlobalHost, flagArrOffsetGlobal, sizeof(uint32_t) * (numOfBlocks + 1), hipMemcpyDeviceToHost);\n  hipMemcpy(compressedDataOffsetGlobalHost, compressedDataOffsetGlobal, sizeof(uint32_t) * (numOfBlocks + 1), hipMemcpyDeviceToHost);\n  hipMemcpy(tmpFlagArrGlobalHost, tmpFlagArrGlobal, sizeof(uint8_t) * datatypeSize / 8, hipMemcpyDeviceToHost);\n  hipMemcpy(tmpCompressedDataGlobalHost, tmpCompressedDataGlobal, sizeof(INPUT_TYPE) * datatypeSize, hipMemcpyDeviceToHost);\n  hipMemcpy(flagArrGlobalHost, flagArrGlobal, sizeof(uint8_t) * datatypeSize / 8, hipMemcpyDeviceToHost);\n  hipMemcpy(compressedDataGlobalHost, compressedDataGlobal, sizeof(INPUT_TYPE) * datatypeSize, hipMemcpyDeviceToHost);\n\n  hipMemcpy(hostOutput, deviceOutput, fileSize, hipMemcpyDeviceToHost);\n\n#ifdef DEBUG\n  printf(\"print the first 1024 flag array offset elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", flagArrOffsetGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 compressed data offset elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", compressedDataOffsetGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 flag array elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", flagArrGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 compressed data elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", compressedDataGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n#endif\n\n  \n\n  for (uint32_t verifyIndex = 0; verifyIndex < fileSize / sizeof(INPUT_TYPE); verifyIndex++)\n  {\n    if (hostArray[verifyIndex] != hostOutput[verifyIndex])\n    {\n      printf(\"verification failed!!! Index %d is wrong\\n\", verifyIndex);\n      std::cout << \"hostArray: \" << hostArray[verifyIndex] << \", hostOutput: \" << hostOutput[verifyIndex] << std::endl;\n      break;\n    }\n  }\n\n  float originalSize = fileSize;\n  float compressedSize = sizeof(uint32_t) * (numOfBlocks + 1) * 2 + flagArrOffsetGlobalHost[numOfBlocks] + compressedDataOffsetGlobalHost[numOfBlocks];\n  float compressionRatio = originalSize / compressedSize;\n  std::cout << \"compression ratio: \" << compressionRatio << std::endl;\n\n  float compTime = std::chrono::duration<float, std::milli>(compStop - compStart).count();\n  float decompTime = std::chrono::duration<float, std::milli>(decompStop - decompStart).count();\n  float compTp = float(fileSize) / 1024 / 1024 / compTime;\n  float decompTp = float(fileSize) / 1024 / 1024 / decompTime;\n  std::cout << \"compression e2e throughput: \" << compTp << \" GB/s\" << std::endl;\n  std::cout << \"decompression e2e throughput: \" << decompTp << \" GB/s\" << std::endl;\n\n  \n\n  free(flagArrOffsetGlobalHost);\n  free(compressedDataOffsetGlobalHost);\n  free(tmpFlagArrGlobalHost);\n  free(tmpCompressedDataGlobalHost);\n  free(flagArrGlobalHost);\n  free(compressedDataGlobalHost);\n\n  hipFree(deviceArray);\n  hipFree(deviceOutput);\n\n  hipFree(flagArrSizeGlobal);\n  hipFree(flagArrOffsetGlobal);\n  hipFree(compressedDataSizeGlobal);\n  hipFree(compressedDataOffsetGlobal);\n  hipFree(tmpFlagArrGlobal);\n  hipFree(tmpCompressedDataGlobal);\n  hipFree(flagArrGlobal);\n  hipFree(compressedDataGlobal);\n\n  hipFree(flag_d_temp_storage);\n  hipFree(data_d_temp_storage);\n\n  free(hostOutput);\n\n  delete hostArray;\n\n  return 0;\n}\n"}}
{"kernel_name": "lzss", "parallel_api": "sycl", "code": {"main.cpp": "#include <oneapi/dpl/execution>\n#include <oneapi/dpl/algorithm>\n#include <sycl/sycl.hpp>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <cmath>\n#include <chrono>\n#include \"utils.h\"\n\n#define BLOCK_SIZE 2048    \n\n#define THREAD_SIZE 128     \n\n#define WINDOW_SIZE 32     \n\n#define INPUT_TYPE uint32_t \n\n\n\n\ntemplate <typename T>\nvoid compressKernelI(const T *input, uint32_t numOfBlocks,\n                     uint32_t *__restrict flagArrSizeGlobal,\n                     uint32_t *__restrict compressedDataSizeGlobal,\n                     uint8_t *__restrict tmpFlagArrGlobal,\n                     uint8_t *__restrict tmpCompressedDataGlobal,\n                     int minEncodeLength,\n                     const sycl::nd_item<3> &item,\n                     T *__restrict buffer,\n                     uint8_t *__restrict lengthBuffer,\n                     uint8_t *__restrict offsetBuffer,\n                     uint32_t *__restrict prefixBuffer,\n                     uint8_t *__restrict byteFlagArr)\n{\n  \n\n  const uint32_t blockSize = BLOCK_SIZE / sizeof(T);\n\n  \n\n  const uint32_t threadSize = THREAD_SIZE;\n\n  \n\n  \n\n\n  \n\n  int tid = 0;\n\n  \n\n  for (int i = 0; i < blockSize / threadSize; i++)\n  {\n    buffer[item.get_local_id(2) + threadSize * i] =\n        input[item.get_group(2) * blockSize + item.get_local_id(2) +\n              threadSize * i];\n  }\n\n  \n\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n       iteration++)\n  {\n    \n\n    tid = item.get_local_id(2) + iteration * threadSize;\n    int bufferStart = tid;\n    int bufferPointer = bufferStart;\n    int windowStart =\n        bufferStart - int(WINDOW_SIZE) < 0 ? 0 : bufferStart - WINDOW_SIZE;\n    int windowPointer = windowStart;\n\n    uint8_t maxLen = 0;\n    uint8_t maxOffset = 0;\n    uint8_t len = 0;\n    uint8_t offset = 0;\n\n    while (windowPointer < bufferStart && bufferPointer < blockSize)\n    {\n      if (buffer[bufferPointer] == buffer[windowPointer])\n      {\n        if (offset == 0)\n        {\n          offset = bufferPointer - windowPointer;\n        }\n        len++;\n        bufferPointer++;\n      }\n      else\n      {\n        if (len > maxLen)\n        {\n          maxLen = len;\n          maxOffset = offset;\n        }\n        len = 0;\n        offset = 0;\n        bufferPointer = bufferStart;\n      }\n      windowPointer++;\n    }\n    if (len > maxLen)\n    {\n      maxLen = len;\n      maxOffset = offset;\n    }\n\n    lengthBuffer[item.get_local_id(2) + iteration * threadSize] = maxLen;\n    offsetBuffer[item.get_local_id(2) + iteration * threadSize] = maxOffset;\n\n    \n\n    prefixBuffer[item.get_local_id(2) + iteration * threadSize] = 0;\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  uint32_t flagCount = 0;\n\n  if (item.get_local_id(2) == 0)\n  {\n    uint8_t flagPosition = 0x01;\n    uint8_t byteFlag = 0;\n\n    int encodeIndex = 0;\n\n    while (encodeIndex < blockSize)\n    {\n      \n\n      if (lengthBuffer[encodeIndex] < minEncodeLength)\n      {\n        prefixBuffer[encodeIndex] = sizeof(T);\n        encodeIndex++;\n      }\n      \n\n      else\n      {\n        prefixBuffer[encodeIndex] = 2;\n        encodeIndex += lengthBuffer[encodeIndex];\n        byteFlag |= flagPosition;\n      }\n      \n\n      if (flagPosition == 0x80)\n      {\n        byteFlagArr[flagCount] = byteFlag;\n        flagCount++;\n        flagPosition = 0x01;\n        byteFlag = 0;\n        continue;\n      }\n      flagPosition <<= 1;\n    }\n    if (flagPosition != 0x01)\n    {\n      byteFlagArr[flagCount] = byteFlag;\n      flagCount++;\n    }\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  int prefixSumOffset = 1;\n  for (uint32_t d = blockSize >> 1; d > 0; d = d >> 1)\n  {\n    for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n         iteration++)\n    {\n      tid = item.get_local_id(2) + iteration * threadSize;\n      if (tid < d)\n      {\n        int ai = prefixSumOffset * (2 * tid + 1) - 1;\n        int bi = prefixSumOffset * (2 * tid + 2) - 1;\n        prefixBuffer[bi] += prefixBuffer[ai];\n      }\n      item.barrier(sycl::access::fence_space::local_space);\n    }\n    prefixSumOffset *= 2;\n  }\n\n  \n\n  if (item.get_local_id(2) == 0)\n  {\n    \n\n    compressedDataSizeGlobal[item.get_group(2)] =\n        prefixBuffer[blockSize - 1];\n    flagArrSizeGlobal[item.get_group(2)] = flagCount;\n    prefixBuffer[blockSize] = prefixBuffer[blockSize - 1];\n    prefixBuffer[blockSize - 1] = 0;\n  }\n  item.barrier(sycl::access::fence_space::local_space);\n\n  \n\n  for (int d = 1; d < blockSize; d *= 2)\n  {\n    prefixSumOffset >>= 1;\n    for (int iteration = 0; iteration < (int)(blockSize / threadSize);\n         iteration++)\n    {\n      tid = item.get_local_id(2) + iteration * threadSize;\n\n      if (tid < d)\n      {\n        int ai = prefixSumOffset * (2 * tid + 1) - 1;\n        int bi = prefixSumOffset * (2 * tid + 2) - 1;\n\n        uint32_t t = prefixBuffer[ai];\n        prefixBuffer[ai] = prefixBuffer[bi];\n        prefixBuffer[bi] += t;\n      }\n      item.barrier(sycl::access::fence_space::local_space);\n    }\n  }\n\n  \n\n  int tmpCompressedDataGlobalOffset;\n  tmpCompressedDataGlobalOffset = blockSize * item.get_group(2) * sizeof(T);\n  for (int iteration = 0; iteration < (int)(blockSize / threadSize); iteration++)\n  {\n    tid = item.get_local_id(2) + iteration * threadSize;\n    if (prefixBuffer[tid + 1] != prefixBuffer[tid])\n    {\n      if (lengthBuffer[tid] < minEncodeLength)\n      {\n        uint32_t tmpOffset = prefixBuffer[tid];\n        uint8_t *bytePtr = (uint8_t *)&buffer[tid];\n        for (int tmpIndex = 0; tmpIndex < sizeof(T); tmpIndex++)\n        {\n          tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset + tmpIndex] = *(bytePtr + tmpIndex);\n        }\n      }\n      else\n      {\n        uint32_t tmpOffset = prefixBuffer[tid];\n        tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset] = lengthBuffer[tid];\n        tmpCompressedDataGlobal[tmpCompressedDataGlobalOffset + tmpOffset + 1] = offsetBuffer[tid];\n      }\n    }\n  }\n\n  \n\n  if (item.get_local_id(2) == 0)\n  {\n    for (int flagArrIndex = 0; flagArrIndex < flagCount; flagArrIndex++)\n    {\n      tmpFlagArrGlobal[blockSize / 8 * item.get_group(2) + flagArrIndex] =\n          byteFlagArr[flagArrIndex];\n    }\n  }\n}\n\n\n\ntemplate <typename T>\nvoid compressKernelIII(uint32_t numOfBlocks,\n                       const uint32_t *__restrict flagArrOffsetGlobal,\n                       const uint32_t *__restrict compressedDataOffsetGlobal,\n                       const uint8_t *__restrict tmpFlagArrGlobal,\n                       const uint8_t *__restrict tmpCompressedDataGlobal,\n                       uint8_t *__restrict flagArrGlobal,\n                       uint8_t *__restrict compressedDataGlobal,\n                       const sycl::nd_item<3> &item)\n{\n  \n\n  const int blockSize = BLOCK_SIZE / sizeof(T);\n\n  \n\n  const int threadSize = THREAD_SIZE;\n\n  \n\n  int blockIndex = item.get_group(2);\n\n  int flagArrOffset = flagArrOffsetGlobal[blockIndex];\n  int flagArrSize = flagArrOffsetGlobal[blockIndex + 1] - flagArrOffsetGlobal[blockIndex];\n\n  int compressedDataOffset = compressedDataOffsetGlobal[blockIndex];\n  int compressedDataSize = compressedDataOffsetGlobal[blockIndex + 1] - compressedDataOffsetGlobal[blockIndex];\n\n  int tid = item.get_local_id(2);\n\n  while (tid < flagArrSize)\n  {\n    flagArrGlobal[flagArrOffset + tid] = tmpFlagArrGlobal[blockSize / 8 * blockIndex + tid];\n    tid += threadSize;\n  }\n\n  tid = item.get_local_id(2);\n\n  while (tid < compressedDataSize)\n  {\n    compressedDataGlobal[compressedDataOffset + tid] = tmpCompressedDataGlobal[blockSize * sizeof(T) * blockIndex + tid];\n    tid += threadSize;\n  }\n}\n\n\n\ntemplate <typename T>\nvoid decompressKernel(T *output, uint32_t numOfBlocks,\n                      const uint32_t *__restrict flagArrOffsetGlobal,\n                      const uint32_t *__restrict compressedDataOffsetGlobal,\n                      const uint8_t *__restrict flagArrGlobal,\n                      const uint8_t *__restrict compressedDataGlobal,\n                      const sycl::nd_item<3> &item)\n{\n  \n\n  const uint32_t blockSize = BLOCK_SIZE / sizeof(T);\n\n  int tid = item.get_group(2) * item.get_local_range(2) +\n            item.get_local_id(2);\n\n  if (tid < numOfBlocks)\n  {\n    int flagArrOffset = flagArrOffsetGlobal[tid];\n    int flagArrSize = flagArrOffsetGlobal[tid + 1] - flagArrOffsetGlobal[tid];\n\n    int compressedDataOffset = compressedDataOffsetGlobal[tid];\n\n    uint32_t dataPointsIndex = 0;\n    uint32_t compressedDataIndex = 0;\n\n    uint8_t byteFlag;\n\n    for (int flagArrayIndex = 0; flagArrayIndex < flagArrSize; flagArrayIndex++)\n    {\n      byteFlag = flagArrGlobal[flagArrOffset + flagArrayIndex];\n\n      for (int bitCount = 0; bitCount < 8; bitCount++)\n      {\n        int matchFlag = (byteFlag >> bitCount) & 0x1;\n        if (matchFlag == 1)\n        {\n          int length = compressedDataGlobal[compressedDataOffset + compressedDataIndex];\n          int offset = compressedDataGlobal[compressedDataOffset + compressedDataIndex + 1];\n          compressedDataIndex += 2;\n          int dataPointsStart = dataPointsIndex;\n          for (int tmpDecompIndex = 0; tmpDecompIndex < length; tmpDecompIndex++)\n          {\n            output[tid * blockSize + dataPointsIndex] = output[tid * blockSize + dataPointsStart - offset + tmpDecompIndex];\n            dataPointsIndex++;\n          }\n        }\n        else\n        {\n          uint8_t *tmpPtr = (uint8_t *)&output[tid * blockSize + dataPointsIndex];\n          for (int tmpDecompIndex = 0; tmpDecompIndex < sizeof(T); tmpDecompIndex++)\n          {\n            *(tmpPtr + tmpDecompIndex) = compressedDataGlobal[compressedDataOffset + compressedDataIndex + tmpDecompIndex];\n          }\n\n          compressedDataIndex += sizeof(T);\n          dataPointsIndex++;\n        }\n        if (dataPointsIndex >= blockSize)\n        {\n          return;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  std::string inputFileName;\n  int opt;\n\n  \n\n  while ((opt = getopt(argc, argv, \"i:h\")) != -1)\n  {\n    switch (opt)\n    {\n    case 'i': \n\n      inputFileName = optarg;\n      break;\n\n    case 'h': \n\n      printf(\" Usage for compression and decompression: ./main -i {inputfile}\\n\");\n      return 0;\n    }\n  }\n\n  INPUT_TYPE *hostArray = io::read_binary_to_new_array<INPUT_TYPE>(inputFileName);\n\n#ifdef DEBUG\n  int debugOffset = 0;\n\n  printf(\"print the first 1024 elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    std::cout << hostArray[tmpIndex + debugOffset] << \"\\t\";\n  }\n  printf(\"\\n\");\n#endif\n\n  INPUT_TYPE *deviceArray;\n  INPUT_TYPE *deviceOutput;\n  uint32_t fileSize = io::FileSize(inputFileName);\n\n  uint32_t *flagArrSizeGlobal;\n  uint32_t *flagArrOffsetGlobal;\n  uint32_t *compressedDataSizeGlobal;\n  uint32_t *compressedDataOffsetGlobal;\n  uint8_t *tmpFlagArrGlobal;\n  uint8_t *tmpCompressedDataGlobal;\n  uint8_t *flagArrGlobal;\n  uint8_t *compressedDataGlobal;\n\n  \n\n  uint32_t paddingSize = fileSize % BLOCK_SIZE == 0 ? 0 : BLOCK_SIZE - fileSize % BLOCK_SIZE;\n\n  \n\n  uint32_t datatypeSize =\n      static_cast<uint32_t>((fileSize + paddingSize) / sizeof(INPUT_TYPE));\n\n  uint32_t numOfBlocks = datatypeSize * sizeof(INPUT_TYPE) / BLOCK_SIZE;\n\n  INPUT_TYPE *hostOutput = (INPUT_TYPE *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  deviceArray = (uint32_t *)sycl::malloc_device(fileSize + paddingSize, q);\n  deviceOutput = (uint32_t *)sycl::malloc_device(fileSize + paddingSize, q);\n\n  flagArrSizeGlobal = sycl::malloc_device<uint32_t>((numOfBlocks + 1), q);\n  flagArrOffsetGlobal = sycl::malloc_device<uint32_t>((numOfBlocks + 1), q);\n  compressedDataSizeGlobal = sycl::malloc_device<uint32_t>((numOfBlocks + 1), q);\n  compressedDataOffsetGlobal = sycl::malloc_device<uint32_t>((numOfBlocks + 1), q);\n  tmpFlagArrGlobal = sycl::malloc_device<uint8_t>(datatypeSize / 8, q);\n  tmpCompressedDataGlobal = (uint8_t*) sycl::malloc_device(sizeof(INPUT_TYPE) * datatypeSize, q);\n  flagArrGlobal = sycl::malloc_device<uint8_t>(datatypeSize / 8, q);\n  compressedDataGlobal = (uint8_t*) sycl::malloc_device(sizeof(INPUT_TYPE) * datatypeSize, q);\n\n  \n\n  q.memset(deviceArray, 0, fileSize + paddingSize);\n  q.memset(deviceOutput, 0, fileSize + paddingSize);\n  q.memset(flagArrSizeGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  q.memset(flagArrOffsetGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  q.memset(compressedDataSizeGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  q.memset(compressedDataOffsetGlobal, 0, sizeof(uint32_t) * (numOfBlocks + 1));\n  q.memset(tmpFlagArrGlobal, 0, sizeof(uint8_t) * datatypeSize / 8);\n  q.memset(tmpCompressedDataGlobal, 0, sizeof(INPUT_TYPE) * datatypeSize);\n\n  \n\n  q.memcpy(deviceArray, hostArray, fileSize);\n\n  \n\n\n  sycl::range<3> gridDim(1, 1, numOfBlocks);\n  sycl::range<3> blockDim(1, 1, THREAD_SIZE);\n\n  sycl::range<3> deGridDim(1, 1, ceil(float(numOfBlocks) / 32));\n  sycl::range<3> deBlockDim(1, 1, 32);\n\n  uint32_t *flagArrOffsetGlobalHost;\n  uint32_t *compressedDataOffsetGlobalHost;\n  uint8_t *tmpFlagArrGlobalHost;\n  uint8_t *tmpCompressedDataGlobalHost;\n  uint8_t *flagArrGlobalHost;\n  uint8_t *compressedDataGlobalHost;\n\n  flagArrOffsetGlobalHost = (uint32_t *)malloc(sizeof(uint32_t) * (numOfBlocks + 1));\n  compressedDataOffsetGlobalHost = (uint32_t *)malloc(sizeof(uint32_t) * (numOfBlocks + 1));\n  tmpFlagArrGlobalHost = (uint8_t *)malloc(sizeof(uint8_t) * datatypeSize / 8);\n  tmpCompressedDataGlobalHost = (uint8_t *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n  flagArrGlobalHost = (uint8_t *)malloc(sizeof(uint8_t) * datatypeSize / 8);\n  compressedDataGlobalHost = (uint8_t *)malloc(sizeof(INPUT_TYPE) * datatypeSize);\n\n  int minEncodeLength = sizeof(INPUT_TYPE) == 1 ? 2 : 1;\n\n  const uint32_t blockSize = BLOCK_SIZE / sizeof(INPUT_TYPE);\n\n  q.wait();\n  auto compStart = std::chrono::steady_clock::now();\n\n  \n\n  q.submit([&](sycl::handler &cgh) {\n    sycl::local_accessor<INPUT_TYPE, 1> buffer_acc(\n        sycl::range<1>(blockSize), cgh);\n    sycl::local_accessor<uint8_t, 1> lengthBuffer_acc(\n        sycl::range<1>(blockSize), cgh);\n    sycl::local_accessor<uint8_t, 1> offsetBuffer_acc(\n        sycl::range<1>(blockSize), cgh);\n    sycl::local_accessor<uint32_t, 1> prefixBuffer_acc(\n        sycl::range<1>(blockSize + 1), cgh);\n    sycl::local_accessor<uint8_t, 1> byteFlagArr_acc(\n        sycl::range<1>((blockSize / 8)), cgh);\n\n    cgh.parallel_for(\n        sycl::nd_range<3>(gridDim * blockDim, blockDim),\n        [=](sycl::nd_item<3> item) {\n          compressKernelI<INPUT_TYPE>(\n              deviceArray, numOfBlocks, flagArrSizeGlobal,\n              compressedDataSizeGlobal, tmpFlagArrGlobal,\n              tmpCompressedDataGlobal, minEncodeLength, item,\n              buffer_acc.get_multi_ptr<sycl::access::decorated::no>().get(),\n              lengthBuffer_acc.get_multi_ptr<sycl::access::decorated::no>().get(),\n              offsetBuffer_acc.get_multi_ptr<sycl::access::decorated::no>().get(),\n              prefixBuffer_acc.get_multi_ptr<sycl::access::decorated::no>().get(),\n              byteFlagArr_acc.get_multi_ptr<sycl::access::decorated::no>().get());\n        });\n  });\n\n  \n\n\n  \n\n  oneapi::dpl::exclusive_scan(\n      oneapi::dpl::execution::device_policy(q), flagArrSizeGlobal,\n      flagArrSizeGlobal + numOfBlocks + 1, flagArrOffsetGlobal,\n      typename std::iterator_traits<decltype(flagArrSizeGlobal)>::value_type{});\n\n  \n\n\n  \n\n  oneapi::dpl::exclusive_scan(\n      oneapi::dpl::execution::device_policy(q), compressedDataSizeGlobal,\n      compressedDataSizeGlobal + numOfBlocks + 1, compressedDataOffsetGlobal,\n      typename std::iterator_traits<\n          decltype(compressedDataSizeGlobal)>::value_type{});\n\n  q.parallel_for(sycl::nd_range<3>(gridDim * blockDim, blockDim),\n      [=](sycl::nd_item<3> item) {\n        compressKernelIII<INPUT_TYPE>(\n            numOfBlocks, flagArrOffsetGlobal, compressedDataOffsetGlobal,\n            tmpFlagArrGlobal, tmpCompressedDataGlobal, flagArrGlobal,\n            compressedDataGlobal, item);\n      });\n\n  q.wait();\n  auto compStop = std::chrono::steady_clock::now();\n\n  auto decompStart = std::chrono::steady_clock::now();\n\n  q.parallel_for(sycl::nd_range<3>(deGridDim * deBlockDim, deBlockDim),\n                 [=](sycl::nd_item<3> item) {\n                           decompressKernel<INPUT_TYPE>(\n                               deviceOutput, numOfBlocks, flagArrOffsetGlobal,\n                               compressedDataOffsetGlobal, flagArrGlobal,\n                               compressedDataGlobal, item);\n                         });\n  q.wait();\n  auto decompStop = std::chrono::steady_clock::now();\n\n  \n\n  q.memcpy(flagArrOffsetGlobalHost, flagArrOffsetGlobal,\n               sizeof(uint32_t) * (numOfBlocks + 1));\n  q.memcpy(compressedDataOffsetGlobalHost, compressedDataOffsetGlobal,\n               sizeof(uint32_t) * (numOfBlocks + 1));\n  q.memcpy(tmpFlagArrGlobalHost, tmpFlagArrGlobal,\n               sizeof(uint8_t) * datatypeSize / 8);\n  q.memcpy(tmpCompressedDataGlobalHost, tmpCompressedDataGlobal,\n               sizeof(INPUT_TYPE) * datatypeSize);\n  q.memcpy(flagArrGlobalHost, flagArrGlobal,\n               sizeof(uint8_t) * datatypeSize / 8);\n  q.memcpy(compressedDataGlobalHost, compressedDataGlobal,\n               sizeof(INPUT_TYPE) * datatypeSize);\n\n  q.memcpy(hostOutput, deviceOutput, fileSize);\n  q.wait();\n\n#ifdef DEBUG\n  printf(\"print the first 1024 flag array offset elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", flagArrOffsetGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 compressed data offset elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", compressedDataOffsetGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 flag array elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", flagArrGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  printf(\"print the first 1024 compressed data elements:\\n\");\n  for (int tmpIndex = 0; tmpIndex < 1024; tmpIndex++)\n  {\n    printf(\"%d\\t\", compressedDataGlobalHost[tmpIndex]);\n  }\n  printf(\"\\n\");\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n#endif\n\n  \n\n  for (int verifyIndex = 0; verifyIndex < fileSize / sizeof(INPUT_TYPE); verifyIndex++)\n  {\n    if (hostArray[verifyIndex] != hostOutput[verifyIndex])\n    {\n      printf(\"verification failed!!! Index %d is wrong\\n\", verifyIndex);\n      std::cout << \"hostArray: \" << hostArray[verifyIndex] << \", hostOutput: \" << hostOutput[verifyIndex] << std::endl;\n      break;\n    }\n  }\n\n  float originalSize = fileSize;\n  float compressedSize = sizeof(uint32_t) * (numOfBlocks + 1) * 2 + flagArrOffsetGlobalHost[numOfBlocks] + compressedDataOffsetGlobalHost[numOfBlocks];\n  float compressionRatio = originalSize / compressedSize;\n  std::cout << \"compression ratio: \" << compressionRatio << std::endl;\n\n  float compTime = std::chrono::duration<float, std::milli>(compStop - compStart).count();\n  float decompTime = std::chrono::duration<float, std::milli>(decompStop - decompStart).count();\n  float compTp = float(fileSize) / 1024 / 1024 / compTime;\n  float decompTp = float(fileSize) / 1024 / 1024 / decompTime;\n  std::cout << \"compression e2e throughput: \" << compTp << \" GB/s\" << std::endl;\n  std::cout << \"decompression e2e throughput: \" << decompTp << \" GB/s\" << std::endl;\n\n  \n\n  free(flagArrOffsetGlobalHost);\n  free(compressedDataOffsetGlobalHost);\n  free(tmpFlagArrGlobalHost);\n  free(tmpCompressedDataGlobalHost);\n  free(flagArrGlobalHost);\n  free(compressedDataGlobalHost);\n\n  sycl::free(deviceArray, q);\n  sycl::free(deviceOutput, q);\n\n  sycl::free(flagArrSizeGlobal, q);\n  sycl::free(flagArrOffsetGlobal, q);\n  sycl::free(compressedDataSizeGlobal, q);\n  sycl::free(compressedDataOffsetGlobal, q);\n  sycl::free(tmpFlagArrGlobal, q);\n  sycl::free(tmpCompressedDataGlobal, q);\n  sycl::free(flagArrGlobal, q);\n  sycl::free(compressedDataGlobal, q);\n\n  free(hostOutput);\n\n  delete hostArray;\n\n  return 0;\n}\n"}}
{"kernel_name": "memtest", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <chrono>\n#include <cuda.h>\n#include \"kernels.h\"\n\n\n\nvoid check (const unsigned *err_cnt) {\n  unsigned err = 0;\n  \n\n  cudaMemcpy(&err, err_cnt, sizeof(unsigned), cudaMemcpyDeviceToHost);\n\n  printf(\"%s\", err ? \"x\" : \".\");\n\n  \n\n  cudaMemset(&err, 0, sizeof(unsigned));\n}\n\n\n\nvoid moving_inversion (\n    unsigned *err_cnt,\n    unsigned long *err_addr,\n    unsigned long *err_expect,\n    unsigned long *err_current,\n    unsigned long *err_second_read,\n    char *dev_mem,\n    unsigned long mem_size,\n    unsigned long p1)\n{\n  unsigned long p2 = ~p1;\n  dim3 grid (1024);\n  dim3 block (64);\n\n  kernel_write <<<grid, block>>> (dev_mem, mem_size, p1);\n\n  for(int i = 0; i < 10; i++){\n    kernel_read_write <<<grid, block>>> (\n        dev_mem, \n        mem_size,\n        p1, p2,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n    p1 = p2;\n    p2 = ~p1;\n  }\n\n  kernel_read <<<grid, block>>> (dev_mem, mem_size,\n      p1, \n      err_cnt,\n      err_addr,\n      err_expect,\n      err_current,\n      err_second_read);\n\n  check(err_cnt);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  printf(\"Note: x indicates an error and . indicates no error when running each test\\n\");\n\n  unsigned err_count = 0;\n\n  unsigned *err_cnt;\n  cudaMalloc((void**)&err_cnt, sizeof(unsigned));\n  cudaMemcpy(err_cnt, &err_count, sizeof(unsigned), cudaMemcpyHostToDevice);\n\n  unsigned long *err_addr;\n  cudaMalloc((void**)&err_addr, sizeof(unsigned long) * (MAX_ERR_RECORD_COUNT));\n\n  unsigned long *err_expect;\n  cudaMalloc((void**)&err_expect, sizeof(unsigned long) * (MAX_ERR_RECORD_COUNT));\n\n  unsigned long *err_current;\n  cudaMalloc((void**)&err_current, sizeof(unsigned long) * (MAX_ERR_RECORD_COUNT));\n\n  unsigned long *err_second_read;\n  cudaMalloc((void**)&err_second_read, sizeof(unsigned long) * (MAX_ERR_RECORD_COUNT));\n\n  \n\n  unsigned long mem_size = 2*1024*1024*1024UL;\n  char *dev_mem;\n  cudaMalloc((void**)&dev_mem, mem_size);\n\n  printf(\"\\ntest0: \");\n  dim3 grid0 (1024);\n  dim3 block0 (64);\n\n  for (int i = 0; i < repeat; i++) {\n    kernel0_write <<<grid0, block0>>> (dev_mem, mem_size);\n\n    kernel0_read <<<grid0, block0>>> (dev_mem, mem_size,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n  }\n\n  check(err_cnt);\n\n  printf(\"\\ntest1: \");\n  dim3 grid1 (1024);\n  dim3 block1 (64);\n\n  for (int i = 0; i < repeat; i++) {\n    kernel1_write <<<grid1, block1>>> (dev_mem, mem_size);\n\n    kernel1_read <<<grid1, block1>>> (dev_mem, mem_size,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n  }\n\n  check(err_cnt);\n\n  printf(\"\\ntest2: \");\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = 0;\n    unsigned long p2 = ~p1;\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p1);\n\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p2);\n  }\n\n  printf(\"\\ntest3: \");\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = 0x8080808080808080;\n    unsigned long p2 = ~p1;\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p1);\n\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p2);\n  }\n\n  printf(\"\\ntest4: \");\n  srand(123);\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = rand();\n    p1 = (p1 << 32) | rand();\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p1);\n  }\n\n  printf(\"\\ntest5: \");\n  dim3 grid5 (64*1024);\n  dim3 block5 (64);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  \n  for (int i = 0; i < repeat; i++) {\n    kernel5_init <<<grid5, block5>>> (dev_mem, mem_size);\n\n    kernel5_move <<<grid5, block5>>> (dev_mem, mem_size);\n\n    kernel5_check <<<grid5, block5>>> (dev_mem, mem_size,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  \n  check(err_cnt);\n\n  printf(\"\\nAverage kernel execution time (test5): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaFree(err_cnt);\n  cudaFree(err_addr);\n  cudaFree(err_expect);\n  cudaFree(err_current);\n  cudaFree(err_second_read);\n  cudaFree(dev_mem);\n  return 0;\n}\n"}}
{"kernel_name": "memtest", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"kernels.h\"\n\n\n\nvoid check (const unsigned *err_cnt) {\n  unsigned err = 0;\n  \n\n  hipMemcpy(&err, err_cnt, sizeof(unsigned), hipMemcpyDeviceToHost);\n\n  printf(\"%s\", err ? \"x\" : \".\");\n\n  \n\n  hipMemset(&err, 0, sizeof(unsigned));\n}\n\n\n\nvoid moving_inversion (\n    unsigned *err_cnt,\n    unsigned long *err_addr,\n    unsigned long *err_expect,\n    unsigned long *err_current,\n    unsigned long *err_second_read,\n    char *dev_mem,\n    unsigned long mem_size,\n    unsigned long p1)\n{\n  unsigned long p2 = ~p1;\n  dim3 grid (1024);\n  dim3 block (64);\n\n  hipLaunchKernelGGL(kernel_write, grid, block, 0, 0, dev_mem, mem_size, p1);\n\n  for(int i = 0; i < 10; i++){\n    hipLaunchKernelGGL(kernel_read_write, grid, block, 0, 0, \n        dev_mem, \n        mem_size,\n        p1, p2,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n    p1 = p2;\n    p2 = ~p1;\n  }\n\n  hipLaunchKernelGGL(kernel_read, grid, block, 0, 0, dev_mem, mem_size,\n      p1, \n      err_cnt,\n      err_addr,\n      err_expect,\n      err_current,\n      err_second_read);\n\n  check(err_cnt);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  printf(\"Note: x indicates an error and . indicates no error when running each test\\n\");\n\n  unsigned err_count = 0;\n\n  unsigned *err_cnt;\n  hipMalloc((void**)&err_cnt, sizeof(unsigned));\n  hipMemcpy(err_cnt, &err_count, sizeof(unsigned), hipMemcpyHostToDevice);\n\n  unsigned long *err_addr;\n  hipMalloc((void**)&err_addr, sizeof(unsigned long) * (MAX_ERR_RECORD_COUNT));\n\n  unsigned long *err_expect;\n  hipMalloc((void**)&err_expect, sizeof(unsigned long) * (MAX_ERR_RECORD_COUNT));\n\n  unsigned long *err_current;\n  hipMalloc((void**)&err_current, sizeof(unsigned long) * (MAX_ERR_RECORD_COUNT));\n\n  unsigned long *err_second_read;\n  hipMalloc((void**)&err_second_read, sizeof(unsigned long) * (MAX_ERR_RECORD_COUNT));\n\n  \n\n  unsigned long mem_size = 2*1024*1024*1024UL;\n  char *dev_mem;\n  hipMalloc((void**)&dev_mem, mem_size);\n\n  printf(\"\\ntest0: \");\n  dim3 grid0 (1024);\n  dim3 block0 (64);\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(kernel0_write, grid0, block0, 0, 0, dev_mem, mem_size);\n\n    hipLaunchKernelGGL(kernel0_read, grid0, block0, 0, 0, dev_mem, mem_size,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n  }\n\n  check(err_cnt);\n\n  printf(\"\\ntest1: \");\n  dim3 grid1 (1024);\n  dim3 block1 (64);\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(kernel1_write, grid1, block1, 0, 0, dev_mem, mem_size);\n\n    hipLaunchKernelGGL(kernel1_read, grid1, block1, 0, 0, dev_mem, mem_size,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n  }\n\n  check(err_cnt);\n\n  printf(\"\\ntest2: \");\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = 0;\n    unsigned long p2 = ~p1;\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p1);\n\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p2);\n  }\n\n  printf(\"\\ntest3: \");\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = 0x8080808080808080;\n    unsigned long p2 = ~p1;\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p1);\n\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p2);\n  }\n\n  printf(\"\\ntest4: \");\n  srand(123);\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = rand();\n    p1 = (p1 << 32) | rand();\n    moving_inversion (err_cnt, err_addr, err_expect, err_current,\n        err_second_read, dev_mem, mem_size, p1);\n  }\n\n  printf(\"\\ntest5: \");\n  dim3 grid5 (64*1024);\n  dim3 block5 (64);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n  \n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(kernel5_init, grid5, block5, 0, 0, dev_mem, mem_size);\n\n    hipLaunchKernelGGL(kernel5_move, grid5, block5, 0, 0, dev_mem, mem_size);\n\n    hipLaunchKernelGGL(kernel5_check, grid5, block5, 0, 0, dev_mem, mem_size,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  \n  check(err_cnt);\n\n  printf(\"\\nAverage kernel execution time (test5): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipFree(err_cnt);\n  hipFree(err_addr);\n  hipFree(err_expect);\n  hipFree(err_current);\n  hipFree(err_second_read);\n  hipFree(dev_mem);\n  return 0;\n}\n"}}
{"kernel_name": "memtest", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <omp.h>\n#include \"kernels.h\"\n\n\n\nvoid check (unsigned *err_cnt) {\n  \n\n  #pragma omp target update from (err_cnt[0:1])\n\n  printf(\"%s\", err_cnt[0] ? \"x\" : \".\");\n\n  \n\n  #pragma omp target \n  err_cnt[0] = 0;\n}\n\n\n\nvoid moving_inversion (\n    unsigned *err_cnt,\n    unsigned long *err_addr,\n    unsigned long *err_expect,\n    unsigned long *err_current,\n    unsigned long *err_second_read,\n    char *dev_mem,\n    unsigned long mem_size,\n    unsigned long p1)\n{\n  unsigned long p2 = ~p1;\n\n  kernel_write(dev_mem, mem_size, p1);\n\n  for(int i = 0; i < 10; i++){\n    kernel_read_write(\n        dev_mem, \n        mem_size,\n        p1, p2,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n    p1 = p2;\n    p2 = ~p1;\n  }\n\n  kernel_read(dev_mem, mem_size,\n      p1, \n      err_cnt,\n      err_addr,\n      err_expect,\n      err_current,\n      err_second_read);\n\n  check(err_cnt);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned err_cnt[1] = {0};\n  unsigned long *err_addr = (unsigned long*) malloc (sizeof(unsigned long) * MAX_ERR_RECORD_COUNT);\n  unsigned long *err_expect = (unsigned long*) malloc (sizeof(unsigned long) * MAX_ERR_RECORD_COUNT);\n  unsigned long *err_current = (unsigned long*) malloc (sizeof(unsigned long) * MAX_ERR_RECORD_COUNT);\n  unsigned long *err_second_read = (unsigned long*) malloc (sizeof(unsigned long) * MAX_ERR_RECORD_COUNT);\n\n  \n\n  unsigned long mem_size = 2*1024*1024*1024UL;\n  char *dev_mem = (char*) malloc (mem_size);\n\n  #pragma omp target data map(to:err_cnt[0:1]) \\\n                          map(alloc: err_addr[0:MAX_ERR_RECORD_COUNT], \\\n                                     err_expect[0:MAX_ERR_RECORD_COUNT], \\\n                                     err_current[0:MAX_ERR_RECORD_COUNT], \\\n                                     err_second_read[0:MAX_ERR_RECORD_COUNT], \\\n                                     dev_mem[0:mem_size])\n  {\n    printf(\"\\ntest0: \");\n\n    for (int i = 0; i < repeat; i++) {\n      kernel0_write(dev_mem, mem_size);\n\n      kernel0_read(dev_mem, mem_size,\n          err_cnt,\n          err_addr,\n          err_expect,\n          err_current,\n          err_second_read);\n    }\n\n    check(err_cnt);\n\n    printf(\"\\ntest1: \");\n\n    for (int i = 0; i < repeat; i++) {\n      kernel1_write(dev_mem, mem_size);\n\n      kernel1_read(dev_mem, mem_size,\n          err_cnt,\n          err_addr,\n          err_expect,\n          err_current,\n          err_second_read);\n    }\n\n    check(err_cnt);\n\n    printf(\"\\ntest2: \");\n    for (int i = 0; i < repeat; i++) {\n      unsigned long p1 = 0;\n      unsigned long p2 = ~p1;\n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p1);\n\n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p2);\n    }\n\n    printf(\"\\ntest3: \");\n    for (int i = 0; i < repeat; i++) {\n      unsigned long p1 = 0x8080808080808080;\n      unsigned long p2 = ~p1;\n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p1);\n  \n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p2);\n    }\n  \n    printf(\"\\ntest4: \");\n    srand(123);\n    for (int i = 0; i < repeat; i++) {\n      unsigned long p1 = rand();\n      p1 = (p1 << 32) | rand();\n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p1);\n    }\n\n    printf(\"\\ntest5: \");\n\n    auto start = std::chrono::steady_clock::now();\n    \n    for (int i = 0; i < repeat; i++) {\n      kernel5_init(dev_mem, mem_size);\n\n      kernel5_move(dev_mem, mem_size);\n\n      kernel5_check(dev_mem, mem_size,\n          err_cnt,\n          err_addr,\n          err_expect,\n          err_current,\n          err_second_read);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    \n    check(err_cnt);\n\n    printf(\"\\nAverage kernel execution time (test5): %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  free(err_addr);\n  free(err_expect);\n  free(err_current);\n  free(err_second_read);\n  free(dev_mem);\n  return 0;\n}\n"}}
{"kernel_name": "memtest", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include \"kernels.h\"\n\n\n\nvoid check (unsigned *err_cnt) {\n  \n\n  \n  printf(\"%s\", err_cnt[0] ? \"x\" : \".\");\n\n  \n\n    err_cnt[0] = 0;\n}\n\n\n\nvoid moving_inversion (\n    unsigned *err_cnt,\n    unsigned long *err_addr,\n    unsigned long *err_expect,\n    unsigned long *err_current,\n    unsigned long *err_second_read,\n    char *dev_mem,\n    unsigned long mem_size,\n    unsigned long p1)\n{\n  unsigned long p2 = ~p1;\n\n  kernel_write(dev_mem, mem_size, p1);\n\n  for(int i = 0; i < 10; i++){\n    kernel_read_write(\n        dev_mem, \n        mem_size,\n        p1, p2,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n    p1 = p2;\n    p2 = ~p1;\n  }\n\n  kernel_read(dev_mem, mem_size,\n      p1, \n      err_cnt,\n      err_addr,\n      err_expect,\n      err_current,\n      err_second_read);\n\n  check(err_cnt);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned err_cnt[1] = {0};\n  unsigned long *err_addr = (unsigned long*) malloc (sizeof(unsigned long) * MAX_ERR_RECORD_COUNT);\n  unsigned long *err_expect = (unsigned long*) malloc (sizeof(unsigned long) * MAX_ERR_RECORD_COUNT);\n  unsigned long *err_current = (unsigned long*) malloc (sizeof(unsigned long) * MAX_ERR_RECORD_COUNT);\n  unsigned long *err_second_read = (unsigned long*) malloc (sizeof(unsigned long) * MAX_ERR_RECORD_COUNT);\n\n  \n\n  unsigned long mem_size = 2*1024*1024*1024UL;\n  char *dev_mem = (char*) malloc (mem_size);\n\n    {\n    printf(\"\\ntest0: \");\n\n    for (int i = 0; i < repeat; i++) {\n      kernel0_write(dev_mem, mem_size);\n\n      kernel0_read(dev_mem, mem_size,\n          err_cnt,\n          err_addr,\n          err_expect,\n          err_current,\n          err_second_read);\n    }\n\n    check(err_cnt);\n\n    printf(\"\\ntest1: \");\n\n    for (int i = 0; i < repeat; i++) {\n      kernel1_write(dev_mem, mem_size);\n\n      kernel1_read(dev_mem, mem_size,\n          err_cnt,\n          err_addr,\n          err_expect,\n          err_current,\n          err_second_read);\n    }\n\n    check(err_cnt);\n\n    printf(\"\\ntest2: \");\n    for (int i = 0; i < repeat; i++) {\n      unsigned long p1 = 0;\n      unsigned long p2 = ~p1;\n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p1);\n\n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p2);\n    }\n\n    printf(\"\\ntest3: \");\n    for (int i = 0; i < repeat; i++) {\n      unsigned long p1 = 0x8080808080808080;\n      unsigned long p2 = ~p1;\n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p1);\n  \n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p2);\n    }\n  \n    printf(\"\\ntest4: \");\n    srand(123);\n    for (int i = 0; i < repeat; i++) {\n      unsigned long p1 = rand();\n      p1 = (p1 << 32) | rand();\n      moving_inversion (err_cnt, err_addr, err_expect, err_current,\n          err_second_read, dev_mem, mem_size, p1);\n    }\n\n    printf(\"\\ntest5: \");\n\n    auto start = std::chrono::steady_clock::now();\n    \n    for (int i = 0; i < repeat; i++) {\n      kernel5_init(dev_mem, mem_size);\n\n      kernel5_move(dev_mem, mem_size);\n\n      kernel5_check(dev_mem, mem_size,\n          err_cnt,\n          err_addr,\n          err_expect,\n          err_current,\n          err_second_read);\n    }\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    \n    check(err_cnt);\n\n    printf(\"\\nAverage kernel execution time (test5): %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n\n  free(err_addr);\n  free(err_expect);\n  free(err_current);\n  free(err_second_read);\n  free(dev_mem);\n  return 0;\n}"}}
{"kernel_name": "memtest", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n\n\n\nvoid check (sycl::queue &q, unsigned *err_cnt) {\n  unsigned err = 0;\n  \n\n  q.memcpy(&err, err_cnt, sizeof(unsigned)).wait();\n\n  printf(\"%s\", err ? \"x\" : \".\");\n\n  \n\n  q.memset(err_cnt, 0, sizeof(unsigned));\n}\n\n\n\nvoid moving_inversion (\n  sycl::queue &q,\n  unsigned *err_cnt,\n  unsigned long *err_addr,\n  unsigned long *err_expect,\n  unsigned long *err_current,\n  unsigned long *err_second_read,\n  char *dev_mem,\n  unsigned long mem_size,\n  unsigned long p1)\n{\n\n  unsigned long p2 = ~p1;\n  sycl::range<1> gws (64*1024);\n  sycl::range<1> lws (64);\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class test_write_pattern>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      kernel_write(item, dev_mem, mem_size, p1);\n    });\n  });\n\n  for(int i = 0; i < 10; i++){\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class test_pattern_readwrite>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        kernel_read_write(\n          item,\n          dev_mem,\n          mem_size,\n          p1, p2,\n          err_cnt,\n          err_addr,\n          err_expect,\n          err_current,\n          err_second_read);\n      });\n    });\n    p1 = p2;\n    p2 = ~p1;\n  }\n\n  q.submit([&] (sycl::handler &cgh) {\n    cgh.parallel_for<class test_pattern_read>(\n      sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      kernel_read(\n        item,\n        dev_mem,\n        mem_size,\n        p1,\n        err_cnt,\n        err_addr,\n        err_expect,\n        err_current,\n        err_second_read);\n    });\n  });\n\n  check(q, err_cnt);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  printf(\"Note: x indicates an error and . indicates no error when running each test\\n\");\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  unsigned err_count = 0;\n\n  unsigned *err_cnt = sycl::malloc_device<unsigned>(1, q);\n  q.memcpy(err_cnt, &err_count, sizeof(unsigned));\n\n  unsigned long *err_addr = sycl::malloc_device<unsigned long>(MAX_ERR_RECORD_COUNT, q);\n  unsigned long *err_expect = sycl::malloc_device<unsigned long>(MAX_ERR_RECORD_COUNT, q);\n  unsigned long *err_current = sycl::malloc_device<unsigned long>(MAX_ERR_RECORD_COUNT, q);\n  unsigned long *err_second_read = sycl::malloc_device<unsigned long>(MAX_ERR_RECORD_COUNT, q);\n\n  \n\n  unsigned long mem_size = 2*1024*1024*1024UL;\n  char *dev_mem = sycl::malloc_device<char>(mem_size, q);\n\n  printf(\"\\ntest0: \");\n  sycl::range<1> gws0 (64*1024);\n  sycl::range<1> lws0 (64);\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class test_k0_write>(\n        sycl::nd_range<1>(gws0, lws0), [=] (sycl::nd_item<1> item) {\n        kernel0_write(item, dev_mem, mem_size);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class test_k0_read>(\n        sycl::nd_range<1>(gws0, lws0), [=] (sycl::nd_item<1> item) {\n        kernel0_read(item, dev_mem, mem_size,\n                     err_cnt,\n                     err_addr,\n                     err_expect,\n                     err_current,\n                     err_second_read);\n      });\n    });\n  }\n\n  check(q, err_cnt);\n\n  printf(\"\\ntest1: \");\n  sycl::range<1> gws1 (64*1024);\n  sycl::range<1> lws1 (64);\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class test_k1_write>(\n        sycl::nd_range<1>(gws1, lws1), [=] (sycl::nd_item<1> item) {\n        kernel1_write(item, dev_mem, mem_size);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class test_k1_read>(\n        sycl::nd_range<1>(gws1, lws1), [=] (sycl::nd_item<1> item) {\n        kernel1_read(item, dev_mem, mem_size,\n                     err_cnt,\n                     err_addr,\n                     err_expect,\n                     err_current,\n                     err_second_read);\n      });\n    });\n  }\n  check(q, err_cnt);\n\n  printf(\"\\ntest2: \");\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = 0;\n    unsigned long p2 = ~p1;\n    moving_inversion (q, err_cnt, err_addr, err_expect, err_current,\n                      err_second_read, dev_mem, mem_size, p1);\n\n    moving_inversion (q, err_cnt, err_addr, err_expect, err_current,\n                      err_second_read, dev_mem, mem_size, p2);\n  }\n\n  printf(\"\\ntest3: \");\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = 0x8080808080808080;\n    unsigned long p2 = ~p1;\n    moving_inversion (q, err_cnt, err_addr, err_expect, err_current,\n                      err_second_read, dev_mem, mem_size, p1);\n\n    moving_inversion (q, err_cnt, err_addr, err_expect, err_current,\n                      err_second_read, dev_mem, mem_size, p2);\n  }\n\n  printf(\"\\ntest4: \");\n  srand(123);\n  for (int i = 0; i < repeat; i++) {\n    unsigned long p1 = rand();\n    p1 = (p1 << 32) | rand();\n    moving_inversion (q, err_cnt, err_addr, err_expect, err_current,\n                      err_second_read, dev_mem, mem_size, p1);\n  }\n\n  printf(\"\\ntest5: \");\n  sycl::range<1> gws5 (64*1024);\n  sycl::range<1> lws5 (64);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class test_k5_init>(\n        sycl::nd_range<1>(gws5, lws5), [=] (sycl::nd_item<1> item) {\n        kernel5_init(item, dev_mem, mem_size);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class test_k5_move>(\n        sycl::nd_range<1>(gws5, lws5), [=] (sycl::nd_item<1> item) {\n        kernel5_move(item, dev_mem, mem_size);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class test_k5_check>(\n        sycl::nd_range<1>(gws5, lws5), [=] (sycl::nd_item<1> item) {\n        kernel5_check(item, dev_mem, mem_size,\n                      err_cnt,\n                      err_addr,\n                      err_expect,\n                      err_current,\n                      err_second_read);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  check(q, err_cnt);\n\n  printf(\"\\nAverage kernel execution time (test5): %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  sycl::free(err_cnt, q);\n  sycl::free(err_addr, q);\n  sycl::free(err_expect, q);\n  sycl::free(err_current, q);\n  sycl::free(err_second_read, q);\n  sycl::free(dev_mem, q);\n  return 0;\n}\n"}}
{"kernel_name": "mf-sgd", "parallel_api": "cuda", "code": {"main.cpp": "#include \"sgd.h\"\n\nusing namespace std;\n\nbool is_numerical(char *str)\n{\n  int c = 0;\n  while(*str != '\\0')\n  {\n    if(isdigit(*str))\n      c++;\n    str++;\n  }\n  return c > 0;\n}\n\nArgument parse_argument(int argc, char **argv)\n{\n  vector<string> args;\n  for(int i = 0; i < argc; i++)\n    args.push_back(string(argv[i]));\n\n  if(argc == 1)\n    throw invalid_argument(\"error\");\n\n  Argument arg;\n  int i;\n  for(i = 1;i < argc; i++)\n  {\n    if(args[i].compare(\"-g\") == 0)\n    {\n      if((i + 1) >= argc)\n        throw invalid_argument(\"need to specify the id of GPUs\\\n            after -g\");\n      i++;\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-g should be followed by a number\");\n      arg.param.gpu = atoi(argv[i]);\n\n    }\n    else if(args[i].compare(\"-l\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify lambda after -l\");\n      i++;\n\n      char *pch = strtok(argv[i], \",\");\n      if(!is_numerical(pch))\n        throw invalid_argument(\"regularization coefficient should be a number\");\n      arg.param.lambda_p = (SGDRate)strtod(pch, NULL);\n      arg.param.lambda_q = (SGDRate)strtod(pch, NULL);\n      pch = strtok(NULL, \",\");\n      if(pch != NULL)\n      {\n        if(!is_numerical(pch))\n          throw invalid_argument(\"regularization coefficient should be a number\");\n        arg.param.lambda_q = (SGDRate)strtod(pch, NULL);\n      }\n    }\n    else if(args[i].compare(\"-k\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of factors after -k\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-k should be followed by a number\");\n      arg.param.k = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-t\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of iterations after -t\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-i should be followed by a number\");\n      arg.param.num_iters = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-r\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -r\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-r should be followed by a number\");\n      arg.param.lrate = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-a\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -a\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-a should be followed by a number\");\n      arg.param.alpha = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-b\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -b\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-b should be followed by a number\");\n      arg.param.beta = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-s\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of parallel workers\\\n            after -s(multiples of 4)\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-s should be followed by a number which is multiple of 4\");\n      arg.param.num_workers = ((atoi(argv[i]) + 3)/4)*4;\n    }\n    else if(args[i].compare(\"-u\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of u grid after -u\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-u should be followed by a number\");\n      arg.param.u_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-v\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of v grid after -v\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-v should be followed by a number\");\n      arg.param.v_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-x\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of x grid\\\n            after -x\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-x should be followed by a number\");\n      arg.param.x_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-y\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of y grid after -y\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-y should be followed by a number\");\n      arg.param.y_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-p\") == 0)\n    {\n      if(i == argc-1)\n        throw invalid_argument(\"need to specify path after -p\");\n      i++;\n\n      arg.va_path = string(args[i]);\n    }\n    else break;\n  }\n\n  if(i >= argc)\n    throw invalid_argument(\"training data not specified\");\n\n  arg.tr_path = string(args[i++]);\n\n  if(i < argc)\n  {\n    arg.model_path = string(args[i]);\n  }\n  else if(i == argc)\n  {\n    const char *ptr = strrchr(&*arg.tr_path.begin(), '/');\n    if(!ptr)\n      ptr = arg.tr_path.c_str();\n    else\n      ++ptr;\n    arg.model_path = string(ptr) + \".model\";\n  }\n  else\n  {\n    throw invalid_argument(\"invalid argument\");\n  }\n\n  if(arg.param.u_grid*arg.param.v_grid == 1)\n  {\n    arg.param.x_grid = 1;\n    arg.param.y_grid = 1;\n  }\n  arg.param.ux = arg.param.u_grid*arg.param.x_grid;\n  arg.param.vy = arg.param.v_grid*arg.param.y_grid;\n\n  return arg;\n}\n\n\n\nint save_model(mf_model const *model, char const *path)\n{\n  printf(\"save_model ...\\n\");\n\n  char command[1024];\n  sprintf(command, \"rm -f %s\", path);\n  int sys_ret = system(command);\n\n  FILE* fptr = fopen(path, \"w\");\n  if(fptr == NULL)\n  {\n    printf(\"save model failed\\n\");\n    return 1;\n  }\n\n  int f = 0;\n  fwrite(&f, sizeof(int), 1, fptr);\n  fwrite(&(model->m), sizeof(int), 1, fptr);\n  fwrite(&(model->n), sizeof(int), 1, fptr);\n  fwrite(&(model->k), sizeof(int), 1, fptr);\n  fwrite(&(model->b), sizeof(float), 1, fptr);\n\n  auto write = [&] (float *ptr, int size)\n  {\n    for(SGDIndex i = 0; i < size; i++)\n    {\n      SGDRate *ptr1 = ptr + (long long)i*model->k;\n      size_t write_size = fwrite(ptr1, sizeof(float), model->k, fptr);\n    }\n  };\n  printf(\"saving feature p(%d)...\\n\", model->m);\n  write(model->floatp, model->m);\n  printf(\"saving feature q(%d)...\\n\", model->n);\n  write(model->floatq, model->n);\n\n  fclose(fptr);\n  return 0;\n}\n\nint main(int argc, char**argv)\n{\n\n  Argument arg;\n  try\n  {  \n    arg = parse_argument(argc,argv);\n    arg.print_arg();\n\n    fflush(stdout);\n  }\n  catch(invalid_argument &e)\n  {\n    cout << e.what() << endl;\n    return 1;\n  }\n\n  int deviceCount = 0;\n  cudaError_t error_id = cudaGetDeviceCount(&deviceCount);\n  cudaSetDevice(arg.param.gpu%deviceCount);\n\n  mf_problem tr,va;\n\n  tr = read_problem(arg.tr_path);\n  tr.u_grid = arg.param.u_grid;\n  tr.v_grid = arg.param.v_grid;\n  tr.x_grid = arg.param.x_grid;\n  tr.y_grid = arg.param.y_grid;\n  tr.ux = arg.param.ux;\n  tr.vy = arg.param.vy;\n\n  mf_model* model = sgd_train(&tr, &va, arg.param);\n\n  save_model(model, arg.model_path.c_str());\n\n  cudaFreeHost(model->floatp);\n  cudaFreeHost(model->floatq);\n  cudaFreeHost(model->halfp);\n  cudaFreeHost(model->halfq);\n  cudaFreeHost(tr.R);\n\n  printf(\"\\ntraining application finished...\\n\\n\\n\");\n\n  return 0;\n}\n", "sgd.cu": "#include <unistd.h>  \n\n#include \"sgd.h\"\n\nusing namespace std;\n\nSGDIndex* gen_random_map(SGDIndex size)\n{\n  srand(123);\n  vector<SGDIndex> map(size, 0);\n  for(SGDIndex i = 0; i < size; i++) map[i] = i;\n\n  random_device rd;\n  mt19937 g(rd());\n  shuffle(map.begin(), map.end(), g);\n\n  int*map_ptr = new int[size];\n  for(int i = 0;i < size;i++)map_ptr[i] = map[i];\n\n  return map_ptr;\n}\n\nSGDIndex* gen_inv_map(SGDIndex*map,int size)\n{\n  int*inv_map = new int[size];\n  for(int i = 0;i < size;i++)inv_map[map[i]] = i;\n  return inv_map;\n}\n\nstruct sort_node_by_p\n{\n  bool operator() (mf_node const &lhs, mf_node const& rhs)\n  {\n    return tie(lhs.u, lhs.v) < tie(rhs.u, rhs.v);\n  }\n};\n\nstruct sort_node_by_q\n{\n  bool operator() (mf_node const &lhs, mf_node const &rhs)\n  {\n    return tie(lhs.v, lhs.u) < tie(rhs.v, rhs.u);\n  }\n};\n\nvoid collect_data(mf_problem *prob, SGDRate& ave, SGDRate& std_dev)\n{\n  double ex = 0;\n  double ex2 = 0;\n\n  for(long long i = 0; i < prob->nnz; i++)\n  {\n    SGDRate r = prob->R[i].rate;\n    ex += (double)r;\n    ex2 += (double)r*r;\n  }\n  ex  = ex/(double)prob->nnz;\n  ex2 = ex2/(double)prob->nnz;\n\n  ave = (SGDRate)ex;\n  std_dev = (SGDRate)sqrt(ex2-ex*ex);\n}\n\nvoid scale_problem(mf_problem*prob, float scale, long long u_seg, long long v_seg)\n{\n  if(prob->ux*prob->vy == 1)\n  {\n    for(long long i = 0;i < prob->nnz; i++)\n    {   \n      prob->R[i].rate = prob->R[i].rate*scale;\n    }\n  }\n  else\n  {\n    for(long long i = 0;i < prob->nnz; i++)\n    {   \n      prob->R[i].rate = prob->R[i].rate*scale;\n\n      long long tmp_u = prob->R[i].u;\n      while(tmp_u >= u_seg)tmp_u = tmp_u - u_seg;\n      prob->R[i].u = tmp_u;\n\n      long long tmp_v = prob->R[i].v;\n      while(tmp_v >= v_seg)tmp_v = tmp_v - v_seg;\n      prob->R[i].v = tmp_v;\n    }\n  }\n}\n\nvoid shuffle_problem(mf_problem*prob, SGDIndex*p_map, SGDIndex*q_map)\n{\n  for(long long i = 0; i < prob->nnz; i++)\n  {\n    mf_node &N = prob->R[i];\n    N.u = p_map[N.u];\n    N.v = q_map[N.v];\n  }\n}\n\nstruct pthread_arg\n{\n  int thread_id; \n  string path;\n  mf_node *R;\n  long long offset;\n  long long size;\n  int max_m;\n  int max_n;\n};\n\nvoid *read_problem_thread(void *argument)\n{\n  pthread_arg *arg = (pthread_arg*)argument;\n\n  FILE*fptr = fopen(arg->path.c_str(), \"rb\");\n  if(fptr == NULL)\n  {\n    printf(\"file %s open failed\\n\", arg->path.c_str());\n    exit(0);\n  }\n\n  int max_m = -1;\n  int max_n = -1;\n\n  for(long long idx = 0;idx < arg->size;idx ++)\n  {\n    int flag = 0;\n    int u,v;\n    float r;\n\n    flag += fread(&u, sizeof(int), 1, fptr); \n    flag += fread(&v, sizeof(int), 1, fptr); \n    flag += fread(&r, sizeof(float), 1, fptr); \n\n    if(flag != 3)break;\n\n    if(u + 1 > max_m)max_m = u + 1;\n    if(v + 1 > max_n)max_n = v + 1;\n\n    arg->R[idx + arg->offset].u = u;\n    arg->R[idx + arg->offset].v = v;\n    arg->R[idx + arg->offset].rate = r;\n\n  }\n  fclose(fptr);\n\n  arg->max_m = max_m;\n  arg->max_n = max_n;\n  return NULL;\n}\n\nmf_problem read_problem(string path)\n{\n  printf(\"read problem called\\n\");\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  mf_problem prob;\n  prob.m = 1;\n  prob.n = 1;\n  prob.nnz = 0;\n  prob.R = NULL;\n\n  int num_files = 0;\n  vector<string> file_names;\n  for(int i = 0; i < 80; i++)\n  {\n    stringstream tmp_name_stream;\n    tmp_name_stream << path << i;\n    string tmp_name = tmp_name_stream.str();\n\n    if(access(tmp_name.c_str(), F_OK) != -1)file_names.push_back(tmp_name);\n  }\n  num_files = file_names.size();\n\n  if(num_files <= 0)\n  {\n    if(path.empty())\n    {\n      printf(\"file %s open failed\\n\", path.c_str());\n      exit(0);\n      return prob;\n    }\n\n    FILE*fptr = fopen(path.c_str(), \"rb\");\n    if(fptr == NULL)\n    {\n      printf(\"file %s open failed\\n\", path.c_str());\n      exit(0);\n      return prob;\n    }\n    fseek(fptr, 0L, SEEK_END);\n    prob.nnz = ftell(fptr)/12;\n    printf(\"prob.nnz = %lld\\n\", prob.nnz);\n\n    mf_node *R;\n    cudaMallocHost((void**)&R,sizeof(mf_node)*prob.nnz); \n\n    rewind(fptr);\n\n    long long idx = 0;\n    while(true)\n    {\n      int flag = 0;\n      int u,v;\n      float r;\n\n      flag += fread(&u, sizeof(int), 1, fptr); \n      flag += fread(&v, sizeof(int), 1, fptr); \n      flag += fread(&r, sizeof(float), 1, fptr); \n      if(flag != 3)break;\n\n      if(u + 1 > prob.m)prob.m = u + 1;\n      if(v + 1 > prob.n)prob.n = v + 1;\n\n      R[idx].u = u;\n      R[idx].v = v;\n      R[idx].rate = r;\n      idx ++;\n      \n\n    }\n    prob.R = R;\n\n    fclose(fptr);\n\n    printf(\"m:%d, n:%d, nnz:%lld\\n\",prob.m, prob.n, prob.nnz);\n  }\n  else\n  {\n    \n\n    long long size_list[128];\n    long long offset_list[128];\n    pthread_t threads[128];\n    pthread_arg pthread_arg_list[128];\n\n    \n\n    FILE*fptrs[80];\n    prob.nnz = 0;\n    for(int i = 0;i < num_files;i++)\n    {\n      fptrs[i] = fopen(file_names[i].c_str(), \"rb\");\n      fseek(fptrs[i], 0L, SEEK_END);\n      size_list[i] = ftell(fptrs[i])/12;\n      prob.nnz +=  size_list[i];\n      fclose(fptrs[i]);\n    }\n\n    \n\n    for(int i = 1;i < num_files;i++)\n    {\n      offset_list[i] = offset_list[i-1] + size_list[i-1];\n    }\n\n    \n\n    mf_node *R;\n    cudaMallocHost((void**)&R,sizeof(mf_node)*prob.nnz); \n    prob.R = R;\n\n    \n\n    for(int i = 0;i < num_files; i++)\n    {\n      pthread_arg_list[i].thread_id = i;\n      pthread_arg_list[i].path = file_names[i];\n      pthread_arg_list[i].R = prob.R;\n      pthread_arg_list[i].offset = offset_list[i];\n      pthread_arg_list[i].size = size_list[i];\n      pthread_create(&(threads[i]), NULL, read_problem_thread, (void*)(&(pthread_arg_list[i])));\n    }\n\n    for(int i = 0;i < num_files;i++)\n    {\n      pthread_join(threads[i], NULL);\n    }\n    prob.m = -1;\n    prob.n = -1;\n    for(int i = 0;i < num_files;i++)\n    {\n      if(pthread_arg_list[i].max_m >= prob.m) prob.m = pthread_arg_list[i].max_m;\n      if(pthread_arg_list[i].max_n >= prob.n) prob.n = pthread_arg_list[i].max_n;\n    }\n    printf(\"m:%d, n:%d, nnz:%lld\\n\",prob.m, prob.n, prob.nnz);\n  }\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n\n  return prob;\n}\n\nvoid grid_problem(mf_problem* prob)\n{\n  printf(\"grid problem ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  \n\n  long long u_seg, v_seg;\n  if(prob->ux == 1)u_seg = prob->m;\n  else u_seg = (long long)ceil((double)prob->m/prob->ux);\n  if(prob->vy == 1)v_seg = prob->n;\n  else v_seg = (long long)ceil((double)prob->n/prob->vy);\n\n  prob->u_seg = u_seg;\n  prob->v_seg = v_seg;\n\n  auto get_grid_id = [=](int u, int v)\n  {\n    return ((u/u_seg)*prob->vy + v/v_seg);\n  };\n\n  \n\n  prob->gridSize = new long long[prob->ux*prob->vy]();\n\n  long long *gridSize = prob->gridSize;\n  for(long long i = 0;i < prob->nnz;i++)\n  {\n    int tmp_u = prob->R[i].u;\n    int tmp_v = prob->R[i].v;\n    gridSize[get_grid_id(tmp_u, tmp_v)] ++;\n  }\n\n  long long max_grid_size = 0;\n  for(int i = 0;i < prob->ux*prob->vy; i++)\n  {\n    \n\n    if(max_grid_size < prob->gridSize[i])max_grid_size = prob->gridSize[i];\n  }\n  prob->maxGridSize = max_grid_size;\n\n  \n\n  mf_node**R2D = new mf_node*[prob->ux*prob->vy + 1];\n  mf_node* R = prob->R;\n  R2D[0] = R;\n  for(int grid = 0;grid < prob->ux*prob->vy; grid++)R2D[grid + 1] = R2D[grid] + gridSize[grid];\n\n  prob->R2D = R2D;\n\n  \n\n  mf_node**pivots = new mf_node*[prob->ux*prob->vy];\n  for(int i = 0;i < prob->ux*prob->vy; i++)pivots[i] = R2D[i];\n\n  for(int grid = 0; grid < prob->ux*prob->vy; grid++)\n  {\n    for(mf_node*pivot = pivots[grid]; pivot != R2D[grid + 1];)\n    {\n      int corre_grid = get_grid_id(pivot->u, pivot->v);\n      if(corre_grid == grid)\n      {  \n        pivot ++;\n        continue;\n      }\n      mf_node *next = pivots[corre_grid];\n      swap(*pivot, *next);\n      pivots[corre_grid] ++;\n    }\n  }\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\n__device__\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n__device__\nvoid LCG_random_init(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n}\n\n__global__ void init_rand_state(unsigned int seed, unsigned int *state)\n{\n  int i = blockIdx.x*blockDim.x + threadIdx.x;\n  state[i] = seed ^ i;\n  LCG_random_init(state+i);\n}\n\n__global__ void random_init(\n    unsigned int *__restrict__ state,\n    int state_size,\n    half *__restrict__ array,\n    long long array_size,\n    long long k, \n    float scale)\n{\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int state_id = tid % state_size;\n  for(int i = 0;i < array_size;i += gridDim.x*blockDim.x)\n  {\n    int idx = i + tid;\n    if(idx >= array_size) break;\n    array[idx] = __float2half(LCG_random(state+state_id)*scale);\n  }\n}\n\nvoid init_feature(short *feature_vec, int grid, long long seg, int k)\n{\n  float scale = (float)sqrt(1.0/k);\n\n  half *gpu_vec;\n  cudaMalloc((void**)&gpu_vec, seg*k*sizeof(half));\n\n  int state_size = (seg/256 + 1)*256;\n  printf(\"state_size (a multiple of 256):%d\\n\", state_size);\n  unsigned int* d_state;\n  cudaMalloc((void**)&d_state, sizeof(unsigned int)*state_size);\n\n  init_rand_state<<<state_size/256, 256>>>(5551212, d_state);\n\n  const int blockSize = 256;\n  const int blockNum = (seg*k + 255)/256;\n  printf(\"\\tnumber of thread blocks:%d\\n\", blockNum);\n  printf(\"\\tarraysize:%lld\\n\", seg*k);\n\n  for(int i = 0;i < grid; i++)\n  {\n    printf(\"grid:%d\\n\",i);\n    random_init<<<blockNum, blockSize>>>(d_state, state_size, gpu_vec, seg*k, k, scale);\n    cudaMemcpy(feature_vec + i*seg*k,gpu_vec,sizeof(half)*seg*k, cudaMemcpyDeviceToHost);\n  }\n\n  cudaFree(d_state);\n  cudaFree(gpu_vec);\n}\n\nmf_model* init_model(mf_problem*prob, int k, float ave)\n{\n  printf(\"init model ...\\n\");\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  mf_model *model = new mf_model;\n  model->fun = 0;\n  model->m = prob->m;\n  model->n = prob->n;\n\n  model->u_grid = prob->u_grid;\n  model->v_grid = prob->v_grid;\n\n  model->x_grid = prob->x_grid;\n  model->y_grid = prob->y_grid;\n\n  model->ux = prob->ux;\n  model->vy = prob->vy;\n\n  model->u_seg = prob->u_seg;\n  model->v_seg = prob->v_seg;\n  model->k = k;\n  model->b = ave;\n\n  \n\n  cudaMallocHost((void**)&model->floatp, sizeof(float)*model->ux*model->u_seg*k);\n  cudaMallocHost((void**)&model->floatq, sizeof(float)*model->vy*model->v_seg*k);\n\n  cudaMallocHost((void**)&model->halfp, sizeof(short)*model->ux*model->u_seg*k);\n  cudaMallocHost((void**)&model->halfq, sizeof(short)*model->vy*model->v_seg*k);\n\n  gpuErr(cudaPeekAtLastError());\n\n  \n\n  init_feature(model->halfp, model->ux, model->u_seg, k);\n  init_feature(model->halfq, model->vy, model->v_seg, k);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n\n  return model;\n}\n\n#include \"sgd_k128_kernel_hogwild_warp32.h\"\n\n__global__ void init_rand_state(unsigned int seed, unsigned int *state, int size)\n{\n  int i = blockIdx.x*blockDim.x + threadIdx.x;\n  state[i] = seed ^ i;\n  if(i < size) LCG_random_init(state+i);\n}\n\n\n__global__ void transform_half(\n  const half *__restrict__ gpu_half_feature,\n  float *__restrict__ gpu_float_feature,\n  long long vec_size)\n{\n  int tid = blockIdx.x*blockDim.x + threadIdx.x;\n  int number_threads = gridDim.x*blockDim.x;\n\n  for(long long i = tid;i < vec_size;i += number_threads)\n  {\n    gpu_float_feature[i] = __half2float(gpu_half_feature[i]); \n  }\n}\n\nvoid transform_feature_vector(short *half_feature, float *float_feature,\n                              int m, int grid, long long seg, int k)\n{\n  half *gpu_half_feature;\n  float *gpu_float_feature;\n\n  cudaMalloc((void**)&gpu_half_feature, sizeof(half)*seg*k);\n  cudaMalloc((void**)&gpu_float_feature, sizeof(float)*seg*k);\n  gpuErr(cudaPeekAtLastError());\n\n  for(int i = 0;i < grid;i++)\n  {\n    cudaMemcpy(gpu_half_feature, half_feature + i*seg*k, sizeof(half)*seg*k, cudaMemcpyHostToDevice);\n    gpuErr(cudaPeekAtLastError());\n\n    int num_blocks = (seg*k+255)/256;\n    if(num_blocks > 8*24)num_blocks = 8*24;\n\n    transform_half<<<num_blocks,256>>>(gpu_half_feature, gpu_float_feature, seg*k);\n\n    gpuErr(cudaPeekAtLastError());\n    cudaMemcpy(float_feature + i*seg*k, gpu_float_feature, sizeof(float)*seg*k, cudaMemcpyDeviceToHost);\n    gpuErr(cudaPeekAtLastError());\n  }\n\n  cudaFree(gpu_half_feature);\n  cudaFree(gpu_float_feature);\n  gpuErr(cudaPeekAtLastError());\n}\n\nvoid sgd_update_k128(Parameter para, mf_model *model, mf_problem *prob, float scale)\n{\n  printf(\"sgd_update_k128 ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  \n\n  unsigned int *rand_state;\n  cudaMalloc((void**)&rand_state, sizeof(unsigned int)*para.num_workers);\n  gpuErr(cudaPeekAtLastError());\n\n  init_rand_state<<<((para.num_workers+255)/256),256>>>(5551212, rand_state, para.num_workers);\n  gpuErr(cudaPeekAtLastError());\n\n  \n\n  float dynamic_rate[1024];\n  float alpha = para.alpha;\n  float beta  = para.beta;\n  float lrate = para.lrate;\n\n  for(int i = 0;i < (para.num_iters + 4);i++)\n  {\n    double tmp_rate = alpha/(1 + beta*pow(i, 1.5)) + lrate;\n    dynamic_rate[i] = tmp_rate;\n  }\n  float *gpu_dynamic_rate;\n  cudaMalloc((void**)&gpu_dynamic_rate, sizeof(float)*1024);\n  gpuErr(cudaPeekAtLastError());\n  cudaMemcpy(gpu_dynamic_rate, dynamic_rate, sizeof(float)*1024, cudaMemcpyHostToDevice);\n  gpuErr(cudaPeekAtLastError());\n\n  \n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    cudaMalloc((void**)&(prob->gpuR), sizeof(mf_node)*prob->maxGridSize);\n    prob->cur_u_id = -1;\n    prob->cur_v_id = -1;\n  }\n  else\n  {\n    cudaMalloc((void**)&(prob->gpuRptrs[0]), sizeof(mf_node)*prob->maxGridSize);\n    cudaMalloc((void**)&(prob->gpuRptrs[1]), sizeof(mf_node)*prob->maxGridSize);\n    prob->cur_global_x_id[0] = -1;\n    prob->cur_global_x_id[1] = -1;\n    prob->cur_global_y_id[0] = -1;\n    prob->cur_global_y_id[1] = -1;\n  }\n\n  \n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    cudaMalloc((void**)&model->gpuHalfp, sizeof(half)*model->u_seg*model->k);\n    cudaMalloc((void**)&model->gpuHalfq, sizeof(half)*model->v_seg*model->k);\n    model->cur_u_id = -1;\n    model->cur_v_id = -1;\n  }\n  else\n  {\n    cudaMalloc((void**)&model->gpuHalfPptrs[0], sizeof(half)*model->u_seg*model->k);\n    cudaMalloc((void**)&model->gpuHalfPptrs[1], sizeof(half)*model->u_seg*model->k);\n    cudaMalloc((void**)&model->gpuHalfQptrs[0], sizeof(half)*model->v_seg*model->k);\n    cudaMalloc((void**)&model->gpuHalfQptrs[1], sizeof(half)*model->v_seg*model->k);\n\n    model->cur_global_x_id[0] = -1;\n    model->cur_global_x_id[1] = -1;\n    model->cur_global_y_id[0] = -1;\n    model->cur_global_y_id[1] = -1;\n  }   \n\n  \n\n  int update_vector_size = 128;\n  int *update_count_per_block = new int[prob->ux*prob->vy]();\n  int max_update_count_per_block = -1;\n  for(int cur_grid_id = 0;cur_grid_id < prob->ux*prob->vy; cur_grid_id ++)\n  {\n    update_count_per_block[cur_grid_id] = (ceil)(1.0*prob->gridSize[cur_grid_id]/(para.num_workers*update_vector_size));   \n    if(max_update_count_per_block < update_count_per_block[cur_grid_id])\n    {\n      max_update_count_per_block = update_count_per_block[cur_grid_id];\n    }\n  }\n\n  \n\n  random_device rd;\n  mt19937 g(rd());\n\n  \n\n  if(prob->u_grid*prob->v_grid == 1)\n  {\n    cudaMemcpy(prob->gpuR, prob->R2D[0], sizeof(mf_node)*prob->gridSize[0], cudaMemcpyHostToDevice);\n    cudaMemcpy(model->gpuHalfp, model->halfp, sizeof(half)*model->u_seg*model->k, cudaMemcpyHostToDevice);\n    cudaMemcpy(model->gpuHalfq, model->halfq, sizeof(half)*model->v_seg*model->k, cudaMemcpyHostToDevice);\n\n    sgd_k128_kernel_hogwild_warp32_lrate<<<para.num_workers/4,128>>>(\n        prob->gpuR,\n        prob->gridSize[0],\n        model->gpuHalfp,\n        model->gpuHalfq,\n        rand_state,\n        gpu_dynamic_rate,\n        model->u_seg,\n        model->v_seg,\n        model->k,\n        para.num_iters,\n        0,\n        max_update_count_per_block,\n        update_count_per_block[0],\n        update_vector_size,\n        para.lambda_p,\n        para.lambda_q,\n        prob->u_grid,\n        prob->v_grid,\n        0,\n        0);\n    cudaMemcpy(model->halfp, model->gpuHalfp, sizeof(half)*model->u_seg*model->k, cudaMemcpyDeviceToHost);\n    cudaMemcpy(model->halfq, model->gpuHalfq, sizeof(half)*model->v_seg*model->k, cudaMemcpyDeviceToHost);\n  }\n  else if(prob->x_grid*prob->y_grid == 1)\n  {\n    \n\n    vector<int> u_id_vec(prob->u_grid, 0);\n    vector<int> v_id_vec(prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid;i++) u_id_vec[i] = i;\n    for(int i = 0;i < prob->v_grid;i++) v_id_vec[i] = i;\n\n    for(int iter = 0;iter < para.num_iters; iter ++)\n    {\n      shuffle(u_id_vec.begin(), u_id_vec.end(), g);\n      for(int u_ite = 0;u_ite < prob->u_grid; u_ite ++)\n      {\n\n        shuffle(v_id_vec.begin(), v_id_vec.end(), g);\n        for(int v_ite = 0;v_ite < prob->v_grid; v_ite ++)\n        {\n          int cur_u_id = u_id_vec[u_ite];\n          int cur_v_id = v_id_vec[v_ite];\n\n          int cur_grid_id = cur_u_id*prob->v_grid + cur_v_id;\n          \n\n          if(prob->cur_u_id != cur_u_id || prob->cur_v_id != cur_v_id)\n          {\n            cudaMemcpy(prob->gpuR, prob->R2D[cur_grid_id], sizeof(mf_node)*prob->gridSize[cur_grid_id], cudaMemcpyHostToDevice);\n          }\n          gpuErr(cudaPeekAtLastError());\n          prob->cur_u_id = cur_u_id;\n          prob->cur_v_id = cur_v_id;\n\n          \n\n          if(model->cur_u_id == -1)\n          {\n            short *p_tmp = model->halfp + model->u_seg*model->k*cur_u_id; \n            cudaMemcpy(model->gpuHalfp, p_tmp, sizeof(half)*model->u_seg*model->k, cudaMemcpyHostToDevice);\n            gpuErr(cudaPeekAtLastError());\n          }\n          else if(model->cur_u_id != cur_u_id)\n          {\n            short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_u_id;\n            cudaMemcpy(p_tmp, model->gpuHalfp, sizeof(half)*model->u_seg*model->k, cudaMemcpyDeviceToHost);\n            gpuErr(cudaPeekAtLastError());\n\n            p_tmp = model->halfp + model->u_seg*model->k*cur_u_id;\n            cudaMemcpy(model->gpuHalfp, p_tmp, sizeof(half)*model->u_seg*model->k, cudaMemcpyHostToDevice);\n            gpuErr(cudaPeekAtLastError());\n          }\n          model->cur_u_id = cur_u_id;\n          gpuErr(cudaPeekAtLastError());\n\n          \n\n          if(model->cur_v_id == -1)\n          {\n            short *q_tmp = model->halfq + model->v_seg*model->k*cur_v_id;\n            cudaMemcpy(model->gpuHalfq, q_tmp, sizeof(half)*model->v_seg*model->k, cudaMemcpyHostToDevice);\n            gpuErr(cudaPeekAtLastError());\n          }\n          else if(model->cur_v_id != cur_v_id)\n          {\n            short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_v_id;\n            cudaMemcpy(q_tmp, model->gpuHalfq, sizeof(half)*model->v_seg*model->k, cudaMemcpyDeviceToHost);\n            gpuErr(cudaPeekAtLastError());\n\n            q_tmp = model->halfq + model->v_seg*model->k*cur_v_id;\n            cudaMemcpy(model->gpuHalfq, q_tmp, sizeof(half)*model->v_seg*model->k, cudaMemcpyHostToDevice);\n            gpuErr(cudaPeekAtLastError());\n          }\n          model->cur_v_id = cur_v_id;\n          gpuErr(cudaPeekAtLastError());\n\n          \n\n          sgd_k128_kernel_hogwild_warp32_lrate<<<para.num_workers/4,128>>>(\n              prob->gpuR,\n              prob->gridSize[cur_grid_id],\n              model->gpuHalfp,\n              model->gpuHalfq,\n              rand_state,\n              gpu_dynamic_rate,\n              model->u_seg,\n              model->v_seg,\n              model->k,\n              1,\n              iter,\n              max_update_count_per_block,\n              update_count_per_block[cur_grid_id],\n              update_vector_size,\n              para.lambda_p,\n              para.lambda_q,\n              prob->u_grid,\n              prob->v_grid,\n              cur_u_id,\n              cur_v_id);\n          gpuErr(cudaPeekAtLastError());\n        }\n      }\n      cudaDeviceSynchronize();\n\n    }\n    cudaDeviceSynchronize();\n\n    \n\n\n    \n\n    if(model->cur_u_id >= 0)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_u_id;\n      cudaMemcpy(p_tmp, model->gpuHalfp, sizeof(half)*model->u_seg*model->k, cudaMemcpyDeviceToHost);\n      gpuErr(cudaPeekAtLastError());\n    }\n    \n\n    if(model->cur_v_id >= 0)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_v_id;\n      cudaMemcpy(q_tmp, model->gpuHalfq, sizeof(half)*model->v_seg*model->k, cudaMemcpyDeviceToHost);\n      gpuErr(cudaPeekAtLastError());\n    }\n  }\n  else\n  {\n    \n\n    int *global_x_list = new int[prob->x_grid*prob->y_grid];\n    int *global_y_list = new int[prob->x_grid*prob->y_grid];\n    int *global_id_list = new int[prob->x_grid*prob->y_grid];\n\n    \n\n    cudaStream_t stream_com, stream_mem_d2h, stream_mem_h2d;\n    cudaStreamCreate(&stream_com);\n    cudaStreamCreate(&stream_mem_d2h);\n    cudaStreamCreate(&stream_mem_h2d);\n\n    \n\n    vector<int> u_id_vec(prob->u_grid, 0);\n    vector<int> v_id_vec(prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid;i++)u_id_vec[i] = i;\n    for(int i = 0;i < prob->v_grid;i++)v_id_vec[i] = i;\n\n    vector<int> x_id_vec(prob->x_grid, 0);\n    vector<int> y_id_vec(prob->y_grid, 0);\n    for(int i = 0;i < prob->x_grid;i++)x_id_vec[i] = i;\n    for(int i = 0;i < prob->y_grid;i++)y_id_vec[i] = i;\n\n    \n\n    vector<int> uv_id_vec(prob->u_grid*prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid*prob->v_grid; i++)uv_id_vec[i] = i;\n    vector<int> xy_id_vec(prob->x_grid*prob->y_grid, 0);\n    for(int i = 0;i < prob->x_grid*prob->y_grid; i++)xy_id_vec[i] = i;\n\n    for(int iter = 0;iter < para.num_iters; iter ++)\n    {\n      shuffle(uv_id_vec.begin(), uv_id_vec.end(), g);\n      shuffle(u_id_vec.begin(), u_id_vec.end(), g);\n\n      for(int u_ite = 0;u_ite < prob->u_grid; u_ite ++)\n      {\n        shuffle(v_id_vec.begin(), v_id_vec.begin(), g);\n        for(int v_ite = 0;v_ite < prob->v_grid; v_ite ++)\n        {\n\n          \n\n          int tmp_uv_id = u_ite*prob->v_grid + v_ite;\n          int cur_u_id = uv_id_vec[tmp_uv_id]/prob->v_grid;\n          int cur_v_id = uv_id_vec[tmp_uv_id]%prob->v_grid;\n\n          \n\n          shuffle(x_id_vec.begin(), x_id_vec.end(), g);\n          shuffle(xy_id_vec.begin(), xy_id_vec.end(), g);\n\n          for(int local_x_ite = 0;local_x_ite < prob->x_grid;local_x_ite ++)\n          {\n            shuffle(y_id_vec.begin(),y_id_vec.end(), g);\n            for(int local_y_ite = 0;local_y_ite < prob->y_grid;local_y_ite ++)\n            {\n\n              \n\n              int tmp_xy_id = local_x_ite*prob->y_grid + local_y_ite;\n              int cur_x_id = xy_id_vec[tmp_xy_id]/prob->y_grid;\n              int cur_y_id = xy_id_vec[tmp_xy_id]%prob->y_grid;\n\n              int local_id = cur_x_id*prob->y_grid + cur_y_id;\n\n              int global_x = cur_u_id*prob->x_grid + cur_x_id;\n              int global_y = cur_v_id*prob->y_grid + cur_y_id;\n              int global_id = global_x*prob->vy + global_y;\n\n              global_x_list[local_id] = global_x;\n              global_y_list[local_id] = global_y;\n              global_id_list[local_id] = global_id;\n\n            }\n          }\n\n          \n\n          for(int i = -1;i < prob->x_grid*prob->y_grid;i++)\n          {\n            \n\n            if(i >= 0)\n            {\n\n              sgd_k128_kernel_hogwild_warp32_lrate<<<para.num_workers/4,128, 0, stream_com>>>(\n                  prob->gpuRptrs[i%2],\n                  prob->gridSize[global_id_list[i]],\n                  model->gpuHalfPptrs[i%2],\n                  model->gpuHalfQptrs[i%2],\n                  rand_state,\n                  gpu_dynamic_rate,\n                  model->u_seg,\n                  model->v_seg,\n                  model->k,\n                  1,\n                  iter,\n                  max_update_count_per_block,\n                  update_count_per_block[global_id_list[i]],\n                  update_vector_size,\n                  para.lambda_p,\n                  para.lambda_q,\n                  prob->ux,\n                  prob->vy,\n                  global_x_list[i],\n                  global_y_list[i]);\n            }\n\n            \n\n            if(i != (prob->x_grid*prob->y_grid - 1))\n            {\n              int next_global_x = global_x_list[i+1];\n              int next_global_y = global_y_list[i+1];\n              int next_global_id = global_id_list[i+1];\n\n              \n\n              if(prob->cur_global_x_id[(i+1)%2] !=  next_global_x || prob->cur_global_y_id[(i+1)%2] != next_global_y)\n              {\n                cudaMemcpyAsync(prob->gpuRptrs[(i+1)%2], \n                    prob->R2D[next_global_id], \n                    sizeof(mf_node)*prob->gridSize[next_global_id],\n                    cudaMemcpyHostToDevice,\n                    stream_mem_h2d);\n              }\n\n              \n\n              if(model->cur_global_x_id[(i+1)%2] == -1)\n              {\n                if(model->cur_global_x_id[(i+2)%2] == next_global_x)\n                {\n                  model->cur_global_x_id[(i+2)%2] = -1;\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n\n                  half *tmp_ptr = model->gpuHalfPptrs[(i+1)%2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = tmp_ptr;\n                }\n                else\n                {\n                  short *p_tmp = model->halfp + model->u_seg*model->k*next_global_x;\n                  cudaMemcpyAsync(model->gpuHalfPptrs[(i+1)%2],\n                      p_tmp,    \n                      sizeof(half)*model->u_seg*model->k,\n                      cudaMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n              }\n              else if(model->cur_global_x_id[(i+1)%2] != next_global_x)\n              {\n                if(model->cur_global_x_id[(i+2)%2] == -1)\n                {\n                  \n\n                  int tmp = model->cur_global_x_id[(i+1)%2];\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                  model->cur_global_x_id[(i+2)%2] = tmp;\n\n                  \n\n                  half *p_tmp = model->gpuHalfPptrs[(i+1)%2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = p_tmp;\n\n                  \n\n                  short *p_tmp_trans = model->halfp + model->u_seg*model->k*next_global_x;\n                  cudaMemcpyAsync(model->gpuHalfPptrs[(i+1)%2],\n                      p_tmp_trans,    \n                      sizeof(half)*model->u_seg*model->k,\n                      cudaMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n                else if(model->cur_global_x_id[(i+2)%2] == next_global_x)\n                {\n                  \n\n                  int tmp = model->cur_global_x_id[(i+1)%2];\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                  model->cur_global_x_id[(i+2)%2] = tmp;\n\n                  \n\n                  half *p_tmp = model->gpuHalfPptrs[(i+1)%2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = p_tmp;\n                }\n                else\n                {\n                  short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[(i+1)%2];\n                  cudaMemcpyAsync(p_tmp,\n                      model->gpuHalfPptrs[(i+1)%2],\n                      sizeof(half)*model->u_seg*model->k,\n                      cudaMemcpyDeviceToHost,\n                      stream_mem_d2h);\n\n                  p_tmp = model->halfp + model->u_seg*model->k*next_global_x;\n                  cudaMemcpyAsync(model->gpuHalfPptrs[(i+1)%2],\n                      p_tmp,\n                      sizeof(half)*model->u_seg*model->k,\n                      cudaMemcpyHostToDevice,\n                      stream_mem_h2d);\n\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n              }\n\n              \n\n              if(model->cur_global_y_id[(i+1)%2] == -1)\n              {\n                if(model->cur_global_y_id[(i+2)%2] == next_global_y)\n                {\n                  model->cur_global_y_id[(i+2)%2] = -1;\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n\n                  half *tmp_ptr = model->gpuHalfQptrs[(i+1)%2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = tmp_ptr;\n                }\n                else\n                {\n                  short *q_tmp = model->halfq + model->v_seg*model->k*next_global_y;\n                  cudaMemcpyAsync(model->gpuHalfQptrs[(i+1)%2],\n                      q_tmp,\n                      sizeof(half)*model->v_seg*model->k,\n                      cudaMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n              }\n              else if(model->cur_global_y_id[(i+1)%2] != next_global_y)\n              {\n                if(model->cur_global_y_id[(i+2)%2] == -1)\n                {\n                  \n\n                  int tmp = model->cur_global_y_id[(i+1)%2];\n                  model->cur_global_y_id[(i+1)%2] = model->cur_global_y_id[(i+2)%2];\n                  model->cur_global_y_id[(i+2)%2] = tmp;\n\n                  \n\n                  half *q_tmp = model->gpuHalfQptrs[(i+1)%2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = q_tmp;\n\n                  short *q_tmp_trans = model->halfq + model->v_seg*model->k*next_global_y;\n                  cudaMemcpyAsync(model->gpuHalfQptrs[(i+1)%2],\n                      q_tmp_trans,\n                      sizeof(half)*model->v_seg*model->k,\n                      cudaMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n                else if(model->cur_global_y_id[(i+2)%2] == next_global_y)\n                {\n                  \n\n                  int tmp = model->cur_global_y_id[(i+1)%2];\n                  model->cur_global_y_id[(i+1)%2] = model->cur_global_y_id[(i+2)%2];\n                  model->cur_global_y_id[(i+2)%2] = tmp;\n\n                  \n\n                  half *q_tmp = model->gpuHalfQptrs[(i+1)%2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = q_tmp;\n                }\n                else\n                {\n                  short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[(i+1)%2];\n                  cudaMemcpyAsync(q_tmp,\n                      model->gpuHalfQptrs[(i+1)%2],\n                      sizeof(half)*model->v_seg*model->k,\n                      cudaMemcpyDeviceToHost,\n                      stream_mem_d2h);\n\n                  q_tmp = model->halfq + model->v_seg*model->k*next_global_y;\n                  cudaMemcpyAsync(model->gpuHalfQptrs[(i+1)%2],\n                      q_tmp,\n                      sizeof(half)*model->v_seg*model->k,\n                      cudaMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n              }\n            }\n            cudaDeviceSynchronize();\n          }   \n        }\n      }\n      cudaDeviceSynchronize();\n    }\n    cudaDeviceSynchronize();\n\n    \n\n    if(model->cur_global_x_id[0] != -1)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[0];\n      cudaMemcpy(p_tmp, model->gpuHalfPptrs[0], sizeof(half)*model->u_seg*model->k, cudaMemcpyDeviceToHost);\n    }\n    if(model->cur_global_x_id[1] != -1)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[1];\n      cudaMemcpy(p_tmp, model->gpuHalfPptrs[1], sizeof(half)*model->u_seg*model->k, cudaMemcpyDeviceToHost);\n    }\n\n    \n\n    if(model->cur_global_y_id[0] != -1)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[0];\n      cudaMemcpy(q_tmp, model->gpuHalfQptrs[0], sizeof(half)*model->v_seg*model->k, cudaMemcpyDeviceToHost);\n    }\n    if(model->cur_global_y_id[1] != -1)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[1];\n      cudaMemcpy(q_tmp, model->gpuHalfQptrs[1], sizeof(half)*model->v_seg*model->k, cudaMemcpyDeviceToHost);\n    }\n  }   \n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    cudaFree(model->gpuHalfp);\n    cudaFree(model->gpuHalfq);\n    cudaFree(prob->gpuR);\n  }\n  else\n  {\n    cudaFree(model->gpuHalfPptrs[0]);\n    cudaFree(model->gpuHalfPptrs[1]);\n    cudaFree(model->gpuHalfQptrs[0]);\n    cudaFree(model->gpuHalfQptrs[1]);\n    cudaFree(prob->gpuRptrs[0]);\n    cudaFree(prob->gpuRptrs[1]);\n  }\n\n  gpuErr(cudaPeekAtLastError());\n\n  \n\n  cudaDeviceSynchronize();\n  transform_feature_vector(model->halfp, model->floatp, model->m, model->ux, model->u_seg, model->k);\n  transform_feature_vector(model->halfq, model->floatq, model->n, model->vy, model->v_seg, model->k);\n\n  cudaFree(gpu_dynamic_rate);\n  cudaFree(rand_state);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\nvoid scale_model(mf_model *model, float scale)\n{\n  printf(\"scale model ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  float factor_scale = sqrt(scale);\n  for(long long i = 0; i < ((long long)model->m)*model->k; i++)model->floatp[i] = model->floatp[i]*factor_scale;\n\n\n  for(long long i = 0; i < model->n*model->k; i++)model->floatq[i] = model->floatq[i]*factor_scale;\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\n\nvoid shuffle_model(mf_model *model, int* inv_p_map, int* inv_q_map)\n{\n  printf(\"shuffle model ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  auto inv_shuffle1 = [] (float *vec, int *map, int size, int k)\n  {\n    for(int pivot = 0; pivot < size;)\n    {\n      if(pivot == map[pivot])\n      {\n        ++pivot;\n        continue;\n      }\n\n      int next = map[pivot];\n\n      for(SGDIndex d = 0; d < k; d++)swap(*(vec + (long long)pivot*k+d), *(vec+(long long)next*k+d));\n\n      map[pivot] = map[next];\n      map[next] = next;\n    }\n  };\n\n  inv_shuffle1(model->floatp, inv_p_map, model->m, model->k);\n  inv_shuffle1(model->floatq, inv_q_map, model->n, model->k);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\n\n\nmf_model*sgd_train(mf_problem*tr, mf_problem*te, Parameter para)\n{\n  printf(\"sgd_train called\\n\");\n\n  \n\n  SGDRate ave;\n  SGDRate std_dev;\n  SGDRate scale = 1.0;\n\n  collect_data(tr, ave, std_dev);\n  scale = max((SGDRate)1e-4, std_dev);\n\n  \n\n  int* p_map = gen_random_map(tr->m);\n  int* q_map = gen_random_map(tr->n);\n  int* inv_p_map = gen_inv_map(p_map, tr->m);\n  int* inv_q_map = gen_inv_map(q_map, tr->n);\n\n  shuffle_problem(tr, p_map, q_map);\n\n  grid_problem(tr); \n\n  \n\n  scale_problem(tr, 1.0/scale, tr->u_seg, tr->v_seg);\n  para.lambda_p = para.lambda_p/scale;\n  para.lambda_q = para.lambda_q/scale;\n\n  \n\n  mf_model*model = init_model(tr, para.k, ave/std_dev);\n\n  \n\n  sgd_update_k128(para, model, tr, scale);\n\n  \n\n  scale_model(model, scale);\n\n  \n\n  shuffle_model(model, inv_p_map, inv_q_map);\n\n  return model;\n}\n"}}
{"kernel_name": "mf-sgd", "parallel_api": "hip", "code": {"main.cpp": "#include \"sgd.h\"\n\nusing namespace std;\n\nbool is_numerical(char *str)\n{\n  int c = 0;\n  while(*str != '\\0')\n  {\n    if(isdigit(*str))\n      c++;\n    str++;\n  }\n  return c > 0;\n}\n\nArgument parse_argument(int argc, char **argv)\n{\n  vector<string> args;\n  for(int i = 0; i < argc; i++)\n    args.push_back(string(argv[i]));\n\n  if(argc == 1)\n    throw invalid_argument(\"error\");\n\n  Argument arg;\n  int i;\n  for(i = 1;i < argc; i++)\n  {\n    if(args[i].compare(\"-g\") == 0)\n    {\n      if((i + 1) >= argc)\n        throw invalid_argument(\"need to specify the id of GPUs\\\n            after -g\");\n      i++;\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-g should be followed by a number\");\n      arg.param.gpu = atoi(argv[i]);\n\n    }\n    else if(args[i].compare(\"-l\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify lambda after -l\");\n      i++;\n\n      char *pch = strtok(argv[i], \",\");\n      if(!is_numerical(pch))\n        throw invalid_argument(\"regularization coefficient should be a number\");\n      arg.param.lambda_p = (SGDRate)strtod(pch, NULL);\n      arg.param.lambda_q = (SGDRate)strtod(pch, NULL);\n      pch = strtok(NULL, \",\");\n      if(pch != NULL)\n      {\n        if(!is_numerical(pch))\n          throw invalid_argument(\"regularization coefficient should be a number\");\n        arg.param.lambda_q = (SGDRate)strtod(pch, NULL);\n      }\n    }\n    else if(args[i].compare(\"-k\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of factors after -k\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-k should be followed by a number\");\n      arg.param.k = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-t\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of iterations after -t\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-i should be followed by a number\");\n      arg.param.num_iters = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-r\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -r\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-r should be followed by a number\");\n      arg.param.lrate = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-a\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -a\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-a should be followed by a number\");\n      arg.param.alpha = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-b\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -b\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-b should be followed by a number\");\n      arg.param.beta = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-s\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of parallel workers\\\n            after -s(multiples of 4)\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-s should be followed by a number which is multiple of 4\");\n      arg.param.num_workers = ((atoi(argv[i]) + 3)/4)*4;\n    }\n    else if(args[i].compare(\"-u\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of u grid after -u\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-u should be followed by a number\");\n      arg.param.u_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-v\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of v grid after -v\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-v should be followed by a number\");\n      arg.param.v_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-x\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of x grid\\\n            after -x\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-x should be followed by a number\");\n      arg.param.x_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-y\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of y grid after -y\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-y should be followed by a number\");\n      arg.param.y_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-p\") == 0)\n    {\n      if(i == argc-1)\n        throw invalid_argument(\"need to specify path after -p\");\n      i++;\n\n      arg.va_path = string(args[i]);\n    }\n    else break;\n  }\n\n  if(i >= argc)\n    throw invalid_argument(\"training data not specified\");\n\n  arg.tr_path = string(args[i++]);\n\n  if(i < argc)\n  {\n    arg.model_path = string(args[i]);\n  }\n  else if(i == argc)\n  {\n    const char *ptr = strrchr(&*arg.tr_path.begin(), '/');\n    if(!ptr)\n      ptr = arg.tr_path.c_str();\n    else\n      ++ptr;\n    arg.model_path = string(ptr) + \".model\";\n  }\n  else\n  {\n    throw invalid_argument(\"invalid argument\");\n  }\n\n  if(arg.param.u_grid*arg.param.v_grid == 1)\n  {\n    arg.param.x_grid = 1;\n    arg.param.y_grid = 1;\n  }\n  arg.param.ux = arg.param.u_grid*arg.param.x_grid;\n  arg.param.vy = arg.param.v_grid*arg.param.y_grid;\n\n  return arg;\n}\n\n\n\nint save_model(mf_model const *model, char const *path)\n{\n  printf(\"save_model ...\\n\");\n\n  char command[1024];\n  sprintf(command, \"rm -f %s\", path);\n  int sys_ret = system(command);\n\n  FILE* fptr = fopen(path, \"w\");\n  if(fptr == NULL)\n  {\n    printf(\"save model failed\\n\");\n    return 1;\n  }\n\n  int f = 0;\n  fwrite(&f, sizeof(int), 1, fptr);\n  fwrite(&(model->m), sizeof(int), 1, fptr);\n  fwrite(&(model->n), sizeof(int), 1, fptr);\n  fwrite(&(model->k), sizeof(int), 1, fptr);\n  fwrite(&(model->b), sizeof(float), 1, fptr);\n\n  auto write = [&] (float *ptr, int size)\n  {\n    for(SGDIndex i = 0; i < size; i++)\n    {\n      SGDRate *ptr1 = ptr + (long long)i*model->k;\n      size_t write_size = fwrite(ptr1, sizeof(float), model->k, fptr);\n    }\n  };\n  printf(\"saving feature p(%d)...\\n\", model->m);\n  write(model->floatp, model->m);\n  printf(\"saving feature q(%d)...\\n\", model->n);\n  write(model->floatq, model->n);\n\n  fclose(fptr);\n  return 0;\n}\n\nint main(int argc, char**argv)\n{\n\n  Argument arg;\n  try\n  {  \n    arg = parse_argument(argc,argv);\n    arg.print_arg();\n\n    fflush(stdout);\n  }\n  catch(invalid_argument &e)\n  {\n    cout << e.what() << endl;\n    return 1;\n  }\n\n  int deviceCount = 0;\n  hipError_t error_id = hipGetDeviceCount(&deviceCount);\n  hipSetDevice(arg.param.gpu%deviceCount);\n\n  mf_problem tr,va;\n\n  tr = read_problem(arg.tr_path);\n  tr.u_grid = arg.param.u_grid;\n  tr.v_grid = arg.param.v_grid;\n  tr.x_grid = arg.param.x_grid;\n  tr.y_grid = arg.param.y_grid;\n  tr.ux = arg.param.ux;\n  tr.vy = arg.param.vy;\n\n  mf_model* model = sgd_train(&tr, &va, arg.param);\n\n  save_model(model, arg.model_path.c_str());\n\n  hipHostFree(model->floatp);\n  hipHostFree(model->floatq);\n  hipHostFree(model->halfp);\n  hipHostFree(model->halfq);\n  hipHostFree(tr.R);\n\n  printf(\"\\ntraining application finished...\\n\\n\\n\");\n\n  return 0;\n}\n", "sgd.cu": "#include <unistd.h>  \n\n#include \"sgd.h\"\n\nusing namespace std;\n\nSGDIndex* gen_random_map(SGDIndex size)\n{\n  srand(123);\n  vector<SGDIndex> map(size, 0);\n  for(SGDIndex i = 0; i < size; i++) map[i] = i;\n\n  random_device rd;\n  mt19937 g(rd());\n  shuffle(map.begin(), map.end(), g);\n\n  int*map_ptr = new int[size];\n  for(int i = 0;i < size;i++)map_ptr[i] = map[i];\n\n  return map_ptr;\n}\n\nSGDIndex* gen_inv_map(SGDIndex*map,int size)\n{\n  int*inv_map = new int[size];\n  for(int i = 0;i < size;i++)inv_map[map[i]] = i;\n  return inv_map;\n}\n\nstruct sort_node_by_p\n{\n  bool operator() (mf_node const &lhs, mf_node const& rhs)\n  {\n    return tie(lhs.u, lhs.v) < tie(rhs.u, rhs.v);\n  }\n};\n\nstruct sort_node_by_q\n{\n  bool operator() (mf_node const &lhs, mf_node const &rhs)\n  {\n    return tie(lhs.v, lhs.u) < tie(rhs.v, rhs.u);\n  }\n};\n\nvoid collect_data(mf_problem *prob, SGDRate& ave, SGDRate& std_dev)\n{\n  double ex = 0;\n  double ex2 = 0;\n\n  for(long long i = 0; i < prob->nnz; i++)\n  {\n    SGDRate r = prob->R[i].rate;\n    ex += (double)r;\n    ex2 += (double)r*r;\n  }\n  ex  = ex/(double)prob->nnz;\n  ex2 = ex2/(double)prob->nnz;\n\n  ave = (SGDRate)ex;\n  std_dev = (SGDRate)sqrt(ex2-ex*ex);\n}\n\nvoid scale_problem(mf_problem*prob, float scale, long long u_seg, long long v_seg)\n{\n  if(prob->ux*prob->vy == 1)\n  {\n    for(long long i = 0;i < prob->nnz; i++)\n    {   \n      prob->R[i].rate = prob->R[i].rate*scale;\n    }\n  }\n  else\n  {\n    for(long long i = 0;i < prob->nnz; i++)\n    {   \n      prob->R[i].rate = prob->R[i].rate*scale;\n\n      long long tmp_u = prob->R[i].u;\n      while(tmp_u >= u_seg)tmp_u = tmp_u - u_seg;\n      prob->R[i].u = tmp_u;\n\n      long long tmp_v = prob->R[i].v;\n      while(tmp_v >= v_seg)tmp_v = tmp_v - v_seg;\n      prob->R[i].v = tmp_v;\n    }\n  }\n}\n\nvoid shuffle_problem(mf_problem*prob, SGDIndex*p_map, SGDIndex*q_map)\n{\n  for(long long i = 0; i < prob->nnz; i++)\n  {\n    mf_node &N = prob->R[i];\n    N.u = p_map[N.u];\n    N.v = q_map[N.v];\n  }\n}\n\nstruct pthread_arg\n{\n  int thread_id; \n  string path;\n  mf_node *R;\n  long long offset;\n  long long size;\n  int max_m;\n  int max_n;\n};\n\nvoid *read_problem_thread(void *argument)\n{\n  pthread_arg *arg = (pthread_arg*)argument;\n\n  FILE*fptr = fopen(arg->path.c_str(), \"rb\");\n  if(fptr == NULL)\n  {\n    printf(\"file %s open failed\\n\", arg->path.c_str());\n    exit(0);\n  }\n\n  int max_m = -1;\n  int max_n = -1;\n\n  for(long long idx = 0;idx < arg->size;idx ++)\n  {\n    int flag = 0;\n    int u,v;\n    float r;\n\n    flag += fread(&u, sizeof(int), 1, fptr); \n    flag += fread(&v, sizeof(int), 1, fptr); \n    flag += fread(&r, sizeof(float), 1, fptr); \n\n    if(flag != 3)break;\n\n    if(u + 1 > max_m)max_m = u + 1;\n    if(v + 1 > max_n)max_n = v + 1;\n\n    arg->R[idx + arg->offset].u = u;\n    arg->R[idx + arg->offset].v = v;\n    arg->R[idx + arg->offset].rate = r;\n\n  }\n  fclose(fptr);\n\n  arg->max_m = max_m;\n  arg->max_n = max_n;\n  return NULL;\n}\n\nmf_problem read_problem(string path)\n{\n  printf(\"read problem called\\n\");\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  mf_problem prob;\n  prob.m = 1;\n  prob.n = 1;\n  prob.nnz = 0;\n  prob.R = NULL;\n\n  int num_files = 0;\n  vector<string> file_names;\n  for(int i = 0; i < 80; i++)\n  {\n    stringstream tmp_name_stream;\n    tmp_name_stream << path << i;\n    string tmp_name = tmp_name_stream.str();\n\n    if(access(tmp_name.c_str(), F_OK) != -1)file_names.push_back(tmp_name);\n  }\n  num_files = file_names.size();\n\n  if(num_files <= 0)\n  {\n    if(path.empty())\n    {\n      printf(\"file %s open failed\\n\", path.c_str());\n      exit(0);\n      return prob;\n    }\n\n    FILE*fptr = fopen(path.c_str(), \"rb\");\n    if(fptr == NULL)\n    {\n      printf(\"file %s open failed\\n\", path.c_str());\n      exit(0);\n      return prob;\n    }\n    fseek(fptr, 0L, SEEK_END);\n    prob.nnz = ftell(fptr)/12;\n    printf(\"prob.nnz = %lld\\n\", prob.nnz);\n\n    mf_node *R;\n    hipMallocHost((void**)&R,sizeof(mf_node)*prob.nnz); \n\n    rewind(fptr);\n\n    long long idx = 0;\n    while(true)\n    {\n      int flag = 0;\n      int u,v;\n      float r;\n\n      flag += fread(&u, sizeof(int), 1, fptr); \n      flag += fread(&v, sizeof(int), 1, fptr); \n      flag += fread(&r, sizeof(float), 1, fptr); \n      if(flag != 3)break;\n\n      if(u + 1 > prob.m)prob.m = u + 1;\n      if(v + 1 > prob.n)prob.n = v + 1;\n\n      R[idx].u = u;\n      R[idx].v = v;\n      R[idx].rate = r;\n      idx ++;\n      \n\n    }\n    prob.R = R;\n\n    fclose(fptr);\n\n    printf(\"m:%d, n:%d, nnz:%lld\\n\",prob.m, prob.n, prob.nnz);\n  }\n  else\n  {\n    \n\n    long long size_list[128];\n    long long offset_list[128];\n    pthread_t threads[128];\n    pthread_arg pthread_arg_list[128];\n\n    \n\n    FILE*fptrs[80];\n    prob.nnz = 0;\n    for(int i = 0;i < num_files;i++)\n    {\n      fptrs[i] = fopen(file_names[i].c_str(), \"rb\");\n      fseek(fptrs[i], 0L, SEEK_END);\n      size_list[i] = ftell(fptrs[i])/12;\n      prob.nnz +=  size_list[i];\n      fclose(fptrs[i]);\n    }\n\n    \n\n    for(int i = 1;i < num_files;i++)\n    {\n      offset_list[i] = offset_list[i-1] + size_list[i-1];\n    }\n\n    \n\n    mf_node *R;\n    hipMallocHost((void**)&R,sizeof(mf_node)*prob.nnz); \n    prob.R = R;\n\n    \n\n    for(int i = 0;i < num_files; i++)\n    {\n      pthread_arg_list[i].thread_id = i;\n      pthread_arg_list[i].path = file_names[i];\n      pthread_arg_list[i].R = prob.R;\n      pthread_arg_list[i].offset = offset_list[i];\n      pthread_arg_list[i].size = size_list[i];\n      pthread_create(&(threads[i]), NULL, read_problem_thread, (void*)(&(pthread_arg_list[i])));\n    }\n\n    for(int i = 0;i < num_files;i++)\n    {\n      pthread_join(threads[i], NULL);\n    }\n    prob.m = -1;\n    prob.n = -1;\n    for(int i = 0;i < num_files;i++)\n    {\n      if(pthread_arg_list[i].max_m >= prob.m) prob.m = pthread_arg_list[i].max_m;\n      if(pthread_arg_list[i].max_n >= prob.n) prob.n = pthread_arg_list[i].max_n;\n    }\n    printf(\"m:%d, n:%d, nnz:%lld\\n\",prob.m, prob.n, prob.nnz);\n  }\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n\n  return prob;\n}\n\nvoid grid_problem(mf_problem* prob)\n{\n  printf(\"grid problem ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  \n\n  long long u_seg, v_seg;\n  if(prob->ux == 1)u_seg = prob->m;\n  else u_seg = (long long)ceil((double)prob->m/prob->ux);\n  if(prob->vy == 1)v_seg = prob->n;\n  else v_seg = (long long)ceil((double)prob->n/prob->vy);\n\n  prob->u_seg = u_seg;\n  prob->v_seg = v_seg;\n\n  auto get_grid_id = [=](int u, int v)\n  {\n    return ((u/u_seg)*prob->vy + v/v_seg);\n  };\n\n  \n\n  prob->gridSize = new long long[prob->ux*prob->vy]();\n\n  long long *gridSize = prob->gridSize;\n  for(long long i = 0;i < prob->nnz;i++)\n  {\n    int tmp_u = prob->R[i].u;\n    int tmp_v = prob->R[i].v;\n    gridSize[get_grid_id(tmp_u, tmp_v)] ++;\n  }\n\n  long long max_grid_size = 0;\n  for(int i = 0;i < prob->ux*prob->vy; i++)\n  {\n    \n\n    if(max_grid_size < prob->gridSize[i])max_grid_size = prob->gridSize[i];\n  }\n  prob->maxGridSize = max_grid_size;\n\n  \n\n  mf_node**R2D = new mf_node*[prob->ux*prob->vy + 1];\n  mf_node* R = prob->R;\n  R2D[0] = R;\n  for(int grid = 0;grid < prob->ux*prob->vy; grid++)R2D[grid + 1] = R2D[grid] + gridSize[grid];\n\n  prob->R2D = R2D;\n\n  \n\n  mf_node**pivots = new mf_node*[prob->ux*prob->vy];\n  for(int i = 0;i < prob->ux*prob->vy; i++)pivots[i] = R2D[i];\n\n  for(int grid = 0; grid < prob->ux*prob->vy; grid++)\n  {\n    for(mf_node*pivot = pivots[grid]; pivot != R2D[grid + 1];)\n    {\n      int corre_grid = get_grid_id(pivot->u, pivot->v);\n      if(corre_grid == grid)\n      {  \n        pivot ++;\n        continue;\n      }\n      mf_node *next = pivots[corre_grid];\n      swap(*pivot, *next);\n      pivots[corre_grid] ++;\n    }\n  }\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\n__device__\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\n__device__\nvoid LCG_random_init(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n}\n\n__global__ void init_rand_state(unsigned int seed, unsigned int *state)\n{\n  int i = blockIdx.x*blockDim.x + threadIdx.x;\n  state[i] = seed ^ i;\n  LCG_random_init(state+i);\n}\n\n__global__ void random_init(\n    unsigned int *__restrict__ state,\n    int state_size,\n    half *__restrict__ array,\n    long long array_size,\n    long long k, \n    float scale)\n{\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int state_id = tid % state_size;\n  for(int i = 0;i < array_size;i += gridDim.x*blockDim.x)\n  {\n    int idx = i + tid;\n    if(idx >= array_size) break;\n    array[idx] = __float2half(LCG_random(state+state_id)*scale);\n  }\n}\n\nvoid init_feature(short *feature_vec, int grid, long long seg, int k)\n{\n  float scale = (float)sqrt(1.0/k);\n\n  half *gpu_vec;\n  hipMalloc((void**)&gpu_vec, seg*k*sizeof(half));\n\n  int state_size = (seg/256 + 1)*256;\n  printf(\"state_size (a multiple of 256):%d\\n\", state_size);\n  unsigned int* d_state;\n  hipMalloc((void**)&d_state, sizeof(unsigned int)*state_size);\n\n  hipLaunchKernelGGL(init_rand_state, state_size/256, 256, 0, 0, 5551212, d_state);\n\n  const int blockSize = 256;\n  const int blockNum = (seg*k + 255)/256;\n  printf(\"\\tnumber of thread blocks:%d\\n\", blockNum);\n  printf(\"\\tarraysize:%lld\\n\", seg*k);\n\n  for(int i = 0;i < grid; i++)\n  {\n    printf(\"grid:%d\\n\",i);\n    hipLaunchKernelGGL(random_init, blockNum, blockSize, 0, 0, d_state, state_size, gpu_vec, seg*k, k, scale);\n    hipMemcpy(feature_vec + i*seg*k,gpu_vec,sizeof(half)*seg*k, hipMemcpyDeviceToHost);\n  }\n\n  hipFree(d_state);\n  hipFree(gpu_vec);\n}\n\nmf_model* init_model(mf_problem*prob, int k, float ave)\n{\n  printf(\"init model ...\\n\");\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  mf_model *model = new mf_model;\n  model->fun = 0;\n  model->m = prob->m;\n  model->n = prob->n;\n\n  model->u_grid = prob->u_grid;\n  model->v_grid = prob->v_grid;\n\n  model->x_grid = prob->x_grid;\n  model->y_grid = prob->y_grid;\n\n  model->ux = prob->ux;\n  model->vy = prob->vy;\n\n  model->u_seg = prob->u_seg;\n  model->v_seg = prob->v_seg;\n  model->k = k;\n  model->b = ave;\n\n  \n\n  hipMallocHost((void**)&model->floatp, sizeof(float)*model->ux*model->u_seg*k);\n  hipMallocHost((void**)&model->floatq, sizeof(float)*model->vy*model->v_seg*k);\n\n  hipMallocHost((void**)&model->halfp, sizeof(short)*model->ux*model->u_seg*k);\n  hipMallocHost((void**)&model->halfq, sizeof(short)*model->vy*model->v_seg*k);\n\n  gpuErr(hipPeekAtLastError());\n\n  \n\n  init_feature(model->halfp, model->ux, model->u_seg, k);\n  init_feature(model->halfq, model->vy, model->v_seg, k);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n\n  return model;\n}\n\n#include \"sgd_k128_kernel_hogwild_warp32.h\"\n\n__global__ void init_rand_state(unsigned int seed, unsigned int *state, int size)\n{\n  int i = blockIdx.x*blockDim.x + threadIdx.x;\n  state[i] = seed ^ i;\n  if(i < size) LCG_random_init(state+i);\n}\n\n\n__global__ void transform_half(\n  const half *__restrict__ gpu_half_feature,\n  float *__restrict__ gpu_float_feature,\n  long long vec_size)\n{\n  int tid = blockIdx.x*blockDim.x + threadIdx.x;\n  int number_threads = gridDim.x*blockDim.x;\n\n  for(long long i = tid;i < vec_size;i += number_threads)\n  {\n    gpu_float_feature[i] = __half2float(gpu_half_feature[i]); \n  }\n}\n\nvoid transform_feature_vector(short *half_feature, float *float_feature,\n                              int m, int grid, long long seg, int k)\n{\n  half *gpu_half_feature;\n  float *gpu_float_feature;\n\n  hipMalloc((void**)&gpu_half_feature, sizeof(half)*seg*k);\n  hipMalloc((void**)&gpu_float_feature, sizeof(float)*seg*k);\n  gpuErr(hipPeekAtLastError());\n\n  for(int i = 0;i < grid;i++)\n  {\n    hipMemcpy(gpu_half_feature, half_feature + i*seg*k, sizeof(half)*seg*k, hipMemcpyHostToDevice);\n    gpuErr(hipPeekAtLastError());\n\n    int num_blocks = (seg*k+255)/256;\n    if(num_blocks > 8*24)num_blocks = 8*24;\n\n    hipLaunchKernelGGL(transform_half, num_blocks, 256, 0, 0, gpu_half_feature, gpu_float_feature, seg*k);\n\n    gpuErr(hipPeekAtLastError());\n    hipMemcpy(float_feature + i*seg*k, gpu_float_feature, sizeof(float)*seg*k, hipMemcpyDeviceToHost);\n    gpuErr(hipPeekAtLastError());\n  }\n\n  hipFree(gpu_half_feature);\n  hipFree(gpu_float_feature);\n  gpuErr(hipPeekAtLastError());\n}\n\nvoid sgd_update_k128(Parameter para, mf_model *model, mf_problem *prob, float scale)\n{\n  printf(\"sgd_update_k128 ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  \n\n  unsigned int *rand_state;\n  hipMalloc((void**)&rand_state, sizeof(unsigned int)*para.num_workers);\n  gpuErr(hipPeekAtLastError());\n\n  init_rand_state<<<((para.num_workers+255)/256),256>>>(5551212, rand_state, para.num_workers);\n  gpuErr(hipPeekAtLastError());\n\n  \n\n  float dynamic_rate[1024];\n  float alpha = para.alpha;\n  float beta  = para.beta;\n  float lrate = para.lrate;\n\n  for(int i = 0;i < (para.num_iters + 4);i++)\n  {\n    double tmp_rate = alpha/(1 + beta*pow(i, 1.5)) + lrate;\n    dynamic_rate[i] = tmp_rate;\n  }\n  float *gpu_dynamic_rate;\n  hipMalloc((void**)&gpu_dynamic_rate, sizeof(float)*1024);\n  gpuErr(hipPeekAtLastError());\n  hipMemcpy(gpu_dynamic_rate, dynamic_rate, sizeof(float)*1024, hipMemcpyHostToDevice);\n  gpuErr(hipPeekAtLastError());\n\n  \n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    hipMalloc((void**)&(prob->gpuR), sizeof(mf_node)*prob->maxGridSize);\n    prob->cur_u_id = -1;\n    prob->cur_v_id = -1;\n  }\n  else\n  {\n    hipMalloc((void**)&(prob->gpuRptrs[0]), sizeof(mf_node)*prob->maxGridSize);\n    hipMalloc((void**)&(prob->gpuRptrs[1]), sizeof(mf_node)*prob->maxGridSize);\n    prob->cur_global_x_id[0] = -1;\n    prob->cur_global_x_id[1] = -1;\n    prob->cur_global_y_id[0] = -1;\n    prob->cur_global_y_id[1] = -1;\n  }\n\n  \n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    hipMalloc((void**)&model->gpuHalfp, sizeof(half)*model->u_seg*model->k);\n    hipMalloc((void**)&model->gpuHalfq, sizeof(half)*model->v_seg*model->k);\n    model->cur_u_id = -1;\n    model->cur_v_id = -1;\n  }\n  else\n  {\n    hipMalloc((void**)&model->gpuHalfPptrs[0], sizeof(half)*model->u_seg*model->k);\n    hipMalloc((void**)&model->gpuHalfPptrs[1], sizeof(half)*model->u_seg*model->k);\n    hipMalloc((void**)&model->gpuHalfQptrs[0], sizeof(half)*model->v_seg*model->k);\n    hipMalloc((void**)&model->gpuHalfQptrs[1], sizeof(half)*model->v_seg*model->k);\n\n    model->cur_global_x_id[0] = -1;\n    model->cur_global_x_id[1] = -1;\n    model->cur_global_y_id[0] = -1;\n    model->cur_global_y_id[1] = -1;\n  }   \n\n  \n\n  int update_vector_size = 128;\n  int *update_count_per_block = new int[prob->ux*prob->vy]();\n  int max_update_count_per_block = -1;\n  for(int cur_grid_id = 0;cur_grid_id < prob->ux*prob->vy; cur_grid_id ++)\n  {\n    update_count_per_block[cur_grid_id] = (ceil)(1.0*prob->gridSize[cur_grid_id]/(para.num_workers*update_vector_size));   \n    if(max_update_count_per_block < update_count_per_block[cur_grid_id])\n    {\n      max_update_count_per_block = update_count_per_block[cur_grid_id];\n    }\n  }\n\n  \n\n  random_device rd;\n  mt19937 g(rd());\n\n  \n\n  if(prob->u_grid*prob->v_grid == 1)\n  {\n    hipMemcpy(prob->gpuR, prob->R2D[0], sizeof(mf_node)*prob->gridSize[0], hipMemcpyHostToDevice);\n    hipMemcpy(model->gpuHalfp, model->halfp, sizeof(half)*model->u_seg*model->k, hipMemcpyHostToDevice);\n    hipMemcpy(model->gpuHalfq, model->halfq, sizeof(half)*model->v_seg*model->k, hipMemcpyHostToDevice);\n\n    hipLaunchKernelGGL(sgd_k128_kernel_hogwild_warp32_lrate, para.num_workers/4, 128, 0, 0, \n        prob->gpuR,\n        prob->gridSize[0],\n        model->gpuHalfp,\n        model->gpuHalfq,\n        rand_state,\n        gpu_dynamic_rate,\n        model->u_seg,\n        model->v_seg,\n        model->k,\n        para.num_iters,\n        0,\n        max_update_count_per_block,\n        update_count_per_block[0],\n        update_vector_size,\n        para.lambda_p,\n        para.lambda_q,\n        prob->u_grid,\n        prob->v_grid,\n        0,\n        0);\n    hipMemcpy(model->halfp, model->gpuHalfp, sizeof(half)*model->u_seg*model->k, hipMemcpyDeviceToHost);\n    hipMemcpy(model->halfq, model->gpuHalfq, sizeof(half)*model->v_seg*model->k, hipMemcpyDeviceToHost);\n  }\n  else if(prob->x_grid*prob->y_grid == 1)\n  {\n    \n\n    vector<int> u_id_vec(prob->u_grid, 0);\n    vector<int> v_id_vec(prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid;i++) u_id_vec[i] = i;\n    for(int i = 0;i < prob->v_grid;i++) v_id_vec[i] = i;\n\n    for(int iter = 0;iter < para.num_iters; iter ++)\n    {\n      shuffle(u_id_vec.begin(), u_id_vec.end(), g);\n      for(int u_ite = 0;u_ite < prob->u_grid; u_ite ++)\n      {\n\n        shuffle(v_id_vec.begin(), v_id_vec.end(), g);\n        for(int v_ite = 0;v_ite < prob->v_grid; v_ite ++)\n        {\n          int cur_u_id = u_id_vec[u_ite];\n          int cur_v_id = v_id_vec[v_ite];\n\n          int cur_grid_id = cur_u_id*prob->v_grid + cur_v_id;\n          \n\n          if(prob->cur_u_id != cur_u_id || prob->cur_v_id != cur_v_id)\n          {\n            hipMemcpy(prob->gpuR, prob->R2D[cur_grid_id], sizeof(mf_node)*prob->gridSize[cur_grid_id], hipMemcpyHostToDevice);\n          }\n          gpuErr(hipPeekAtLastError());\n          prob->cur_u_id = cur_u_id;\n          prob->cur_v_id = cur_v_id;\n\n          \n\n          if(model->cur_u_id == -1)\n          {\n            short *p_tmp = model->halfp + model->u_seg*model->k*cur_u_id; \n            hipMemcpy(model->gpuHalfp, p_tmp, sizeof(half)*model->u_seg*model->k, hipMemcpyHostToDevice);\n            gpuErr(hipPeekAtLastError());\n          }\n          else if(model->cur_u_id != cur_u_id)\n          {\n            short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_u_id;\n            hipMemcpy(p_tmp, model->gpuHalfp, sizeof(half)*model->u_seg*model->k, hipMemcpyDeviceToHost);\n            gpuErr(hipPeekAtLastError());\n\n            p_tmp = model->halfp + model->u_seg*model->k*cur_u_id;\n            hipMemcpy(model->gpuHalfp, p_tmp, sizeof(half)*model->u_seg*model->k, hipMemcpyHostToDevice);\n            gpuErr(hipPeekAtLastError());\n          }\n          model->cur_u_id = cur_u_id;\n          gpuErr(hipPeekAtLastError());\n\n          \n\n          if(model->cur_v_id == -1)\n          {\n            short *q_tmp = model->halfq + model->v_seg*model->k*cur_v_id;\n            hipMemcpy(model->gpuHalfq, q_tmp, sizeof(half)*model->v_seg*model->k, hipMemcpyHostToDevice);\n            gpuErr(hipPeekAtLastError());\n          }\n          else if(model->cur_v_id != cur_v_id)\n          {\n            short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_v_id;\n            hipMemcpy(q_tmp, model->gpuHalfq, sizeof(half)*model->v_seg*model->k, hipMemcpyDeviceToHost);\n            gpuErr(hipPeekAtLastError());\n\n            q_tmp = model->halfq + model->v_seg*model->k*cur_v_id;\n            hipMemcpy(model->gpuHalfq, q_tmp, sizeof(half)*model->v_seg*model->k, hipMemcpyHostToDevice);\n            gpuErr(hipPeekAtLastError());\n          }\n          model->cur_v_id = cur_v_id;\n          gpuErr(hipPeekAtLastError());\n\n          \n\n          hipLaunchKernelGGL(sgd_k128_kernel_hogwild_warp32_lrate, para.num_workers/4, 128, 0, 0, \n              prob->gpuR,\n              prob->gridSize[cur_grid_id],\n              model->gpuHalfp,\n              model->gpuHalfq,\n              rand_state,\n              gpu_dynamic_rate,\n              model->u_seg,\n              model->v_seg,\n              model->k,\n              1,\n              iter,\n              max_update_count_per_block,\n              update_count_per_block[cur_grid_id],\n              update_vector_size,\n              para.lambda_p,\n              para.lambda_q,\n              prob->u_grid,\n              prob->v_grid,\n              cur_u_id,\n              cur_v_id);\n          gpuErr(hipPeekAtLastError());\n        }\n      }\n      hipDeviceSynchronize();\n\n    }\n    hipDeviceSynchronize();\n\n    \n\n\n    \n\n    if(model->cur_u_id >= 0)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_u_id;\n      hipMemcpy(p_tmp, model->gpuHalfp, sizeof(half)*model->u_seg*model->k, hipMemcpyDeviceToHost);\n      gpuErr(hipPeekAtLastError());\n    }\n    \n\n    if(model->cur_v_id >= 0)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_v_id;\n      hipMemcpy(q_tmp, model->gpuHalfq, sizeof(half)*model->v_seg*model->k, hipMemcpyDeviceToHost);\n      gpuErr(hipPeekAtLastError());\n    }\n  }\n  else\n  {\n    \n\n    int *global_x_list = new int[prob->x_grid*prob->y_grid];\n    int *global_y_list = new int[prob->x_grid*prob->y_grid];\n    int *global_id_list = new int[prob->x_grid*prob->y_grid];\n\n    \n\n    hipStream_t stream_com, stream_mem_d2h, stream_mem_h2d;\n    hipStreamCreate(&stream_com);\n    hipStreamCreate(&stream_mem_d2h);\n    hipStreamCreate(&stream_mem_h2d);\n\n    \n\n    vector<int> u_id_vec(prob->u_grid, 0);\n    vector<int> v_id_vec(prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid;i++)u_id_vec[i] = i;\n    for(int i = 0;i < prob->v_grid;i++)v_id_vec[i] = i;\n\n    vector<int> x_id_vec(prob->x_grid, 0);\n    vector<int> y_id_vec(prob->y_grid, 0);\n    for(int i = 0;i < prob->x_grid;i++)x_id_vec[i] = i;\n    for(int i = 0;i < prob->y_grid;i++)y_id_vec[i] = i;\n\n    \n\n    vector<int> uv_id_vec(prob->u_grid*prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid*prob->v_grid; i++)uv_id_vec[i] = i;\n    vector<int> xy_id_vec(prob->x_grid*prob->y_grid, 0);\n    for(int i = 0;i < prob->x_grid*prob->y_grid; i++)xy_id_vec[i] = i;\n\n    for(int iter = 0;iter < para.num_iters; iter ++)\n    {\n      shuffle(uv_id_vec.begin(), uv_id_vec.end(), g);\n      shuffle(u_id_vec.begin(), u_id_vec.end(), g);\n\n      for(int u_ite = 0;u_ite < prob->u_grid; u_ite ++)\n      {\n        shuffle(v_id_vec.begin(), v_id_vec.begin(), g);\n        for(int v_ite = 0;v_ite < prob->v_grid; v_ite ++)\n        {\n\n          \n\n          int tmp_uv_id = u_ite*prob->v_grid + v_ite;\n          int cur_u_id = uv_id_vec[tmp_uv_id]/prob->v_grid;\n          int cur_v_id = uv_id_vec[tmp_uv_id]%prob->v_grid;\n\n          \n\n          shuffle(x_id_vec.begin(), x_id_vec.end(), g);\n          shuffle(xy_id_vec.begin(), xy_id_vec.end(), g);\n\n          for(int local_x_ite = 0;local_x_ite < prob->x_grid;local_x_ite ++)\n          {\n            shuffle(y_id_vec.begin(),y_id_vec.end(), g);\n            for(int local_y_ite = 0;local_y_ite < prob->y_grid;local_y_ite ++)\n            {\n\n              \n\n              int tmp_xy_id = local_x_ite*prob->y_grid + local_y_ite;\n              int cur_x_id = xy_id_vec[tmp_xy_id]/prob->y_grid;\n              int cur_y_id = xy_id_vec[tmp_xy_id]%prob->y_grid;\n\n              int local_id = cur_x_id*prob->y_grid + cur_y_id;\n\n              int global_x = cur_u_id*prob->x_grid + cur_x_id;\n              int global_y = cur_v_id*prob->y_grid + cur_y_id;\n              int global_id = global_x*prob->vy + global_y;\n\n              global_x_list[local_id] = global_x;\n              global_y_list[local_id] = global_y;\n              global_id_list[local_id] = global_id;\n\n            }\n          }\n\n          \n\n          for(int i = -1;i < prob->x_grid*prob->y_grid;i++)\n          {\n            \n\n            if(i >= 0)\n            {\n\n              hipLaunchKernelGGL(sgd_k128_kernel_hogwild_warp32_lrate, para.num_workers/4, 128, 0, stream_com, \n                  prob->gpuRptrs[i%2],\n                  prob->gridSize[global_id_list[i]],\n                  model->gpuHalfPptrs[i%2],\n                  model->gpuHalfQptrs[i%2],\n                  rand_state,\n                  gpu_dynamic_rate,\n                  model->u_seg,\n                  model->v_seg,\n                  model->k,\n                  1,\n                  iter,\n                  max_update_count_per_block,\n                  update_count_per_block[global_id_list[i]],\n                  update_vector_size,\n                  para.lambda_p,\n                  para.lambda_q,\n                  prob->ux,\n                  prob->vy,\n                  global_x_list[i],\n                  global_y_list[i]);\n            }\n\n            \n\n            if(i != (prob->x_grid*prob->y_grid - 1))\n            {\n              int next_global_x = global_x_list[i+1];\n              int next_global_y = global_y_list[i+1];\n              int next_global_id = global_id_list[i+1];\n\n              \n\n              if(prob->cur_global_x_id[(i+1)%2] !=  next_global_x || prob->cur_global_y_id[(i+1)%2] != next_global_y)\n              {\n                hipMemcpyAsync(prob->gpuRptrs[(i+1)%2], \n                    prob->R2D[next_global_id], \n                    sizeof(mf_node)*prob->gridSize[next_global_id],\n                    hipMemcpyHostToDevice,\n                    stream_mem_h2d);\n              }\n\n              \n\n              if(model->cur_global_x_id[(i+1)%2] == -1)\n              {\n                if(model->cur_global_x_id[(i+2)%2] == next_global_x)\n                {\n                  model->cur_global_x_id[(i+2)%2] = -1;\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n\n                  half *tmp_ptr = model->gpuHalfPptrs[(i+1)%2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = tmp_ptr;\n                }\n                else\n                {\n                  short *p_tmp = model->halfp + model->u_seg*model->k*next_global_x;\n                  hipMemcpyAsync(model->gpuHalfPptrs[(i+1)%2],\n                      p_tmp,    \n                      sizeof(half)*model->u_seg*model->k,\n                      hipMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n              }\n              else if(model->cur_global_x_id[(i+1)%2] != next_global_x)\n              {\n                if(model->cur_global_x_id[(i+2)%2] == -1)\n                {\n                  \n\n                  int tmp = model->cur_global_x_id[(i+1)%2];\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                  model->cur_global_x_id[(i+2)%2] = tmp;\n\n                  \n\n                  half *p_tmp = model->gpuHalfPptrs[(i+1)%2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = p_tmp;\n\n                  \n\n                  short *p_tmp_trans = model->halfp + model->u_seg*model->k*next_global_x;\n                  hipMemcpyAsync(model->gpuHalfPptrs[(i+1)%2],\n                      p_tmp_trans,    \n                      sizeof(half)*model->u_seg*model->k,\n                      hipMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n                else if(model->cur_global_x_id[(i+2)%2] == next_global_x)\n                {\n                  \n\n                  int tmp = model->cur_global_x_id[(i+1)%2];\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                  model->cur_global_x_id[(i+2)%2] = tmp;\n\n                  \n\n                  half *p_tmp = model->gpuHalfPptrs[(i+1)%2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = p_tmp;\n                }\n                else\n                {\n                  short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[(i+1)%2];\n                  hipMemcpyAsync(p_tmp,\n                      model->gpuHalfPptrs[(i+1)%2],\n                      sizeof(half)*model->u_seg*model->k,\n                      hipMemcpyDeviceToHost,\n                      stream_mem_d2h);\n\n                  p_tmp = model->halfp + model->u_seg*model->k*next_global_x;\n                  hipMemcpyAsync(model->gpuHalfPptrs[(i+1)%2],\n                      p_tmp,\n                      sizeof(half)*model->u_seg*model->k,\n                      hipMemcpyHostToDevice,\n                      stream_mem_h2d);\n\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n              }\n\n              \n\n              if(model->cur_global_y_id[(i+1)%2] == -1)\n              {\n                if(model->cur_global_y_id[(i+2)%2] == next_global_y)\n                {\n                  model->cur_global_y_id[(i+2)%2] = -1;\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n\n                  half *tmp_ptr = model->gpuHalfQptrs[(i+1)%2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = tmp_ptr;\n                }\n                else\n                {\n                  short *q_tmp = model->halfq + model->v_seg*model->k*next_global_y;\n                  hipMemcpyAsync(model->gpuHalfQptrs[(i+1)%2],\n                      q_tmp,\n                      sizeof(half)*model->v_seg*model->k,\n                      hipMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n              }\n              else if(model->cur_global_y_id[(i+1)%2] != next_global_y)\n              {\n                if(model->cur_global_y_id[(i+2)%2] == -1)\n                {\n                  \n\n                  int tmp = model->cur_global_y_id[(i+1)%2];\n                  model->cur_global_y_id[(i+1)%2] = model->cur_global_y_id[(i+2)%2];\n                  model->cur_global_y_id[(i+2)%2] = tmp;\n\n                  \n\n                  half *q_tmp = model->gpuHalfQptrs[(i+1)%2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = q_tmp;\n\n                  short *q_tmp_trans = model->halfq + model->v_seg*model->k*next_global_y;\n                  hipMemcpyAsync(model->gpuHalfQptrs[(i+1)%2],\n                      q_tmp_trans,\n                      sizeof(half)*model->v_seg*model->k,\n                      hipMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n                else if(model->cur_global_y_id[(i+2)%2] == next_global_y)\n                {\n                  \n\n                  int tmp = model->cur_global_y_id[(i+1)%2];\n                  model->cur_global_y_id[(i+1)%2] = model->cur_global_y_id[(i+2)%2];\n                  model->cur_global_y_id[(i+2)%2] = tmp;\n\n                  \n\n                  half *q_tmp = model->gpuHalfQptrs[(i+1)%2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = q_tmp;\n                }\n                else\n                {\n                  short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[(i+1)%2];\n                  hipMemcpyAsync(q_tmp,\n                      model->gpuHalfQptrs[(i+1)%2],\n                      sizeof(half)*model->v_seg*model->k,\n                      hipMemcpyDeviceToHost,\n                      stream_mem_d2h);\n\n                  q_tmp = model->halfq + model->v_seg*model->k*next_global_y;\n                  hipMemcpyAsync(model->gpuHalfQptrs[(i+1)%2],\n                      q_tmp,\n                      sizeof(half)*model->v_seg*model->k,\n                      hipMemcpyHostToDevice,\n                      stream_mem_h2d);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n              }\n            }\n            hipDeviceSynchronize();\n          }   \n        }\n      }\n      hipDeviceSynchronize();\n    }\n    hipDeviceSynchronize();\n\n    \n\n    if(model->cur_global_x_id[0] != -1)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[0];\n      hipMemcpy(p_tmp, model->gpuHalfPptrs[0], sizeof(half)*model->u_seg*model->k, hipMemcpyDeviceToHost);\n    }\n    if(model->cur_global_x_id[1] != -1)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[1];\n      hipMemcpy(p_tmp, model->gpuHalfPptrs[1], sizeof(half)*model->u_seg*model->k, hipMemcpyDeviceToHost);\n    }\n\n    \n\n    if(model->cur_global_y_id[0] != -1)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[0];\n      hipMemcpy(q_tmp, model->gpuHalfQptrs[0], sizeof(half)*model->v_seg*model->k, hipMemcpyDeviceToHost);\n    }\n    if(model->cur_global_y_id[1] != -1)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[1];\n      hipMemcpy(q_tmp, model->gpuHalfQptrs[1], sizeof(half)*model->v_seg*model->k, hipMemcpyDeviceToHost);\n    }\n  }   \n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    hipFree(model->gpuHalfp);\n    hipFree(model->gpuHalfq);\n    hipFree(prob->gpuR);\n  }\n  else\n  {\n    hipFree(model->gpuHalfPptrs[0]);\n    hipFree(model->gpuHalfPptrs[1]);\n    hipFree(model->gpuHalfQptrs[0]);\n    hipFree(model->gpuHalfQptrs[1]);\n    hipFree(prob->gpuRptrs[0]);\n    hipFree(prob->gpuRptrs[1]);\n  }\n\n  gpuErr(hipPeekAtLastError());\n\n  \n\n  hipDeviceSynchronize();\n  transform_feature_vector(model->halfp, model->floatp, model->m, model->ux, model->u_seg, model->k);\n  transform_feature_vector(model->halfq, model->floatq, model->n, model->vy, model->v_seg, model->k);\n\n  hipFree(gpu_dynamic_rate);\n  hipFree(rand_state);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\nvoid scale_model(mf_model *model, float scale)\n{\n  printf(\"scale model ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  float factor_scale = sqrt(scale);\n  for(long long i = 0; i < ((long long)model->m)*model->k; i++)model->floatp[i] = model->floatp[i]*factor_scale;\n\n\n  for(long long i = 0; i < model->n*model->k; i++)model->floatq[i] = model->floatq[i]*factor_scale;\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\n\nvoid shuffle_model(mf_model *model, int* inv_p_map, int* inv_q_map)\n{\n  printf(\"shuffle model ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  auto inv_shuffle1 = [] (float *vec, int *map, int size, int k)\n  {\n    for(int pivot = 0; pivot < size;)\n    {\n      if(pivot == map[pivot])\n      {\n        ++pivot;\n        continue;\n      }\n\n      int next = map[pivot];\n\n      for(SGDIndex d = 0; d < k; d++)swap(*(vec + (long long)pivot*k+d), *(vec+(long long)next*k+d));\n\n      map[pivot] = map[next];\n      map[next] = next;\n    }\n  };\n\n  inv_shuffle1(model->floatp, inv_p_map, model->m, model->k);\n  inv_shuffle1(model->floatq, inv_q_map, model->n, model->k);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\n\n\nmf_model*sgd_train(mf_problem*tr, mf_problem*te, Parameter para)\n{\n  printf(\"sgd_train called\\n\");\n\n  \n\n  SGDRate ave;\n  SGDRate std_dev;\n  SGDRate scale = 1.0;\n\n  collect_data(tr, ave, std_dev);\n  scale = max((SGDRate)1e-4, std_dev);\n\n  \n\n  int* p_map = gen_random_map(tr->m);\n  int* q_map = gen_random_map(tr->n);\n  int* inv_p_map = gen_inv_map(p_map, tr->m);\n  int* inv_q_map = gen_inv_map(q_map, tr->n);\n\n  shuffle_problem(tr, p_map, q_map);\n\n  grid_problem(tr); \n\n  \n\n  scale_problem(tr, 1.0/scale, tr->u_seg, tr->v_seg);\n  para.lambda_p = para.lambda_p/scale;\n  para.lambda_q = para.lambda_q/scale;\n\n  \n\n  mf_model*model = init_model(tr, para.k, ave/std_dev);\n\n  \n\n  sgd_update_k128(para, model, tr, scale);\n\n  \n\n  scale_model(model, scale);\n\n  \n\n  shuffle_model(model, inv_p_map, inv_q_map);\n\n  return model;\n}\n"}}
{"kernel_name": "mf-sgd", "parallel_api": "sycl", "code": {"main.cpp": "#include \"sgd.h\"\n\nusing namespace std;\n\nbool is_numerical(char *str)\n{\n  int c = 0;\n  while(*str != '\\0')\n  {\n    if(isdigit(*str))\n      c++;\n    str++;\n  }\n  return c > 0;\n}\n\nArgument parse_argument(int argc, char **argv)\n{\n  vector<string> args;\n  for(int i = 0; i < argc; i++)\n    args.push_back(string(argv[i]));\n\n  if(argc == 1)\n    throw invalid_argument(\"error\");\n\n  Argument arg;\n  int i;\n  for(i = 1;i < argc; i++)\n  {\n    if(args[i].compare(\"-g\") == 0)\n    {\n      if((i + 1) >= argc)\n        throw invalid_argument(\"need to specify the id of GPUs\\\n            after -g\");\n      i++;\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-g should be followed by a number\");\n      arg.param.gpu = atoi(argv[i]);\n\n    }\n    else if(args[i].compare(\"-l\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify lambda after -l\");\n      i++;\n\n      char *pch = strtok(argv[i], \",\");\n      if(!is_numerical(pch))\n        throw invalid_argument(\"regularization coefficient should be a number\");\n      arg.param.lambda_p = (SGDRate)strtod(pch, NULL);\n      arg.param.lambda_q = (SGDRate)strtod(pch, NULL);\n      pch = strtok(NULL, \",\");\n      if(pch != NULL)\n      {\n        if(!is_numerical(pch))\n          throw invalid_argument(\"regularization coefficient should be a number\");\n        arg.param.lambda_q = (SGDRate)strtod(pch, NULL);\n      }\n    }\n    else if(args[i].compare(\"-k\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of factors after -k\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-k should be followed by a number\");\n      arg.param.k = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-t\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of iterations after -t\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-i should be followed by a number\");\n      arg.param.num_iters = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-r\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -r\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-r should be followed by a number\");\n      arg.param.lrate = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-a\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -a\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-a should be followed by a number\");\n      arg.param.alpha = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-b\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify eta after -b\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-b should be followed by a number\");\n      arg.param.beta = (SGDRate)atof(argv[i]);\n    }\n    else if(args[i].compare(\"-s\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of parallel workers\\\n            after -s(multiples of 4)\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-s should be followed by a number which is multiple of 4\");\n      arg.param.num_workers = ((atoi(argv[i]) + 3)/4)*4;\n    }\n    else if(args[i].compare(\"-u\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of u grid after -u\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-u should be followed by a number\");\n      arg.param.u_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-v\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of v grid after -v\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-v should be followed by a number\");\n      arg.param.v_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-x\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of x grid\\\n            after -x\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-x should be followed by a number\");\n      arg.param.x_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-y\") == 0)\n    {\n      if((i+1) >= argc)\n        throw invalid_argument(\"need to specify number of y grid after -y\");\n      i++;\n\n      if(!is_numerical(argv[i]))\n        throw invalid_argument(\"-y should be followed by a number\");\n      arg.param.y_grid = atoi(argv[i]);\n    }\n    else if(args[i].compare(\"-p\") == 0)\n    {\n      if(i == argc-1)\n        throw invalid_argument(\"need to specify path after -p\");\n      i++;\n\n      arg.va_path = string(args[i]);\n    }\n    else break;\n  }\n\n  if(i >= argc)\n    throw invalid_argument(\"training data not specified\");\n\n  arg.tr_path = string(args[i++]);\n\n  if(i < argc)\n  {\n    arg.model_path = string(args[i]);\n  }\n  else if(i == argc)\n  {\n    const char *ptr = strrchr(&*arg.tr_path.begin(), '/');\n    if(!ptr)\n      ptr = arg.tr_path.c_str();\n    else\n      ++ptr;\n    arg.model_path = string(ptr) + \".model\";\n  }\n  else\n  {\n    throw invalid_argument(\"invalid argument\");\n  }\n\n  if(arg.param.u_grid*arg.param.v_grid == 1)\n  {\n    arg.param.x_grid = 1;\n    arg.param.y_grid = 1;\n  }\n  arg.param.ux = arg.param.u_grid*arg.param.x_grid;\n  arg.param.vy = arg.param.v_grid*arg.param.y_grid;\n\n  return arg;\n}\n\n\n\nint save_model(mf_model const *model, char const *path)\n{\n  printf(\"save_model ...\\n\");\n\n  char command[1024];\n  sprintf(command, \"rm -f %s\", path);\n  int sys_ret = system(command);\n\n  FILE* fptr = fopen(path, \"w\");\n  if(fptr == NULL)\n  {\n    printf(\"save model failed\\n\");\n    return 1;\n  }\n\n  int f = 0;\n  fwrite(&f, sizeof(int), 1, fptr);\n  fwrite(&(model->m), sizeof(int), 1, fptr);\n  fwrite(&(model->n), sizeof(int), 1, fptr);\n  fwrite(&(model->k), sizeof(int), 1, fptr);\n  fwrite(&(model->b), sizeof(float), 1, fptr);\n\n  auto write = [&] (float *ptr, int size)\n  {\n    for(SGDIndex i = 0; i < size; i++)\n    {\n      SGDRate *ptr1 = ptr + (long long)i*model->k;\n      size_t write_size = fwrite(ptr1, sizeof(float), model->k, fptr);\n    }\n  };\n  printf(\"saving feature p(%d)...\\n\", model->m);\n  write(model->floatp, model->m);\n  printf(\"saving feature q(%d)...\\n\", model->n);\n  write(model->floatq, model->n);\n\n  fclose(fptr);\n  return 0;\n}\n\nint main(int argc, char**argv)\n{\n\n  Argument arg;\n  try\n  {  \n    arg = parse_argument(argc,argv);\n    arg.print_arg();\n\n    fflush(stdout);\n  }\n  catch(invalid_argument &e)\n  {\n    std::cout << e.what() << std::endl;\n    return 1;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  mf_problem tr,va;\n\n  tr = read_problem(q, arg.tr_path);\n  tr.u_grid = arg.param.u_grid;\n  tr.v_grid = arg.param.v_grid;\n  tr.x_grid = arg.param.x_grid;\n  tr.y_grid = arg.param.y_grid;\n  tr.ux = arg.param.ux;\n  tr.vy = arg.param.vy;\n\n  mf_model* model = sgd_train(q, &tr, &va, arg.param);\n\n  save_model(model, arg.model_path.c_str());\n\n  sycl::free(model->floatp, q);\n  sycl::free(model->floatq, q);\n  sycl::free(model->halfp, q);\n  sycl::free(model->halfq, q);\n  sycl::free(tr.R, q);\n\n  printf(\"\\ntraining application finished...\\n\\n\\n\");\n\n  return 0;\n}\n", "sgd.cpp": "#include <unistd.h> \n\n#include \"sgd.h\"\n\nusing namespace std;\n\nSGDIndex* gen_random_map(SGDIndex size)\n{\n  srand(123);\n  vector<SGDIndex> map(size, 0);\n  for(SGDIndex i = 0; i < size; i++) map[i] = i;\n\n  random_device rd;\n  mt19937 g(rd());\n  shuffle(map.begin(), map.end(), g);\n\n  int*map_ptr = new int[size];\n  for(int i = 0;i < size;i++)map_ptr[i] = map[i];\n\n  return map_ptr;\n}\n\nSGDIndex* gen_inv_map(SGDIndex*map,int size)\n{\n  int*inv_map = new int[size];\n  for(int i = 0;i < size;i++)inv_map[map[i]] = i;\n  return inv_map;\n}\n\nstruct sort_node_by_p\n{\n  bool operator() (mf_node const &lhs, mf_node const& rhs)\n  {\n    return tie(lhs.u, lhs.v) < tie(rhs.u, rhs.v);\n  }\n};\n\nstruct sort_node_by_q\n{\n  bool operator() (mf_node const &lhs, mf_node const &rhs)\n  {\n    return tie(lhs.v, lhs.u) < tie(rhs.v, rhs.u);\n  }\n};\n\nvoid collect_data(mf_problem *prob, SGDRate& ave, SGDRate& std_dev)\n{\n  double ex = 0;\n  double ex2 = 0;\n\n  for(long long i = 0; i < prob->nnz; i++)\n  {\n    SGDRate r = prob->R[i].rate;\n    ex += (double)r;\n    ex2 += (double)r*r;\n  }\n  ex  = ex/(double)prob->nnz;\n  ex2 = ex2/(double)prob->nnz;\n\n  ave = (SGDRate)ex;\n  std_dev = (SGDRate)sqrt(ex2-ex*ex);\n}\n\nvoid scale_problem(mf_problem*prob, float scale, long long u_seg, long long v_seg)\n{\n  if(prob->ux*prob->vy == 1)\n  {\n    for(long long i = 0;i < prob->nnz; i++)\n    {   \n      prob->R[i].rate = prob->R[i].rate*scale;\n    }\n  }\n  else\n  {\n    for(long long i = 0;i < prob->nnz; i++)\n    {   \n      prob->R[i].rate = prob->R[i].rate*scale;\n\n      long long tmp_u = prob->R[i].u;\n      while(tmp_u >= u_seg)tmp_u = tmp_u - u_seg;\n      prob->R[i].u = tmp_u;\n\n      long long tmp_v = prob->R[i].v;\n      while(tmp_v >= v_seg)tmp_v = tmp_v - v_seg;\n      prob->R[i].v = tmp_v;\n    }\n  }\n}\n\nvoid shuffle_problem(mf_problem*prob, SGDIndex*p_map, SGDIndex*q_map)\n{\n  for(long long i = 0; i < prob->nnz; i++)\n  {\n    mf_node &N = prob->R[i];\n    N.u = p_map[N.u];\n    N.v = q_map[N.v];\n  }\n}\n\nstruct pthread_arg\n{\n  int thread_id; \n  string path;\n  mf_node *R;\n  long long offset;\n  long long size;\n  int max_m;\n  int max_n;\n};\n\nvoid *read_problem_thread(void *argument)\n{\n  pthread_arg *arg = (pthread_arg*)argument;\n\n  FILE*fptr = fopen(arg->path.c_str(), \"rb\");\n  if(fptr == NULL)\n  {\n    printf(\"file %s open failed\\n\", arg->path.c_str());\n    exit(0);\n  }\n\n  int max_m = -1;\n  int max_n = -1;\n\n  for(long long idx = 0;idx < arg->size;idx ++)\n  {\n    int flag = 0;\n    int u,v;\n    float r;\n\n    flag += fread(&u, sizeof(int), 1, fptr); \n    flag += fread(&v, sizeof(int), 1, fptr); \n    flag += fread(&r, sizeof(float), 1, fptr); \n\n    if(flag != 3)break;\n\n    if(u + 1 > max_m)max_m = u + 1;\n    if(v + 1 > max_n)max_n = v + 1;\n\n    arg->R[idx + arg->offset].u = u;\n    arg->R[idx + arg->offset].v = v;\n    arg->R[idx + arg->offset].rate = r;\n\n  }\n  fclose(fptr);\n\n  arg->max_m = max_m;\n  arg->max_n = max_n;\n  return NULL;\n}\n\nmf_problem read_problem(sycl::queue &q, string path)\n{\n  printf(\"read problem called\\n\");\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  mf_problem prob;\n  prob.m = 1;\n  prob.n = 1;\n  prob.nnz = 0;\n  prob.R = NULL;\n\n  int num_files = 0;\n  vector<string> file_names;\n  for(int i = 0; i < 80; i++)\n  {\n    stringstream tmp_name_stream;\n    tmp_name_stream << path << i;\n    string tmp_name = tmp_name_stream.str();\n\n    if(access(tmp_name.c_str(), F_OK) != -1)file_names.push_back(tmp_name);\n  }\n  num_files = file_names.size();\n\n  if(num_files <= 0)\n  {\n    if(path.empty())\n    {\n      printf(\"file %s open failed\\n\", path.c_str());\n      exit(0);\n      return prob;\n    }\n\n    FILE*fptr = fopen(path.c_str(), \"rb\");\n    if(fptr == NULL)\n    {\n      printf(\"file %s open failed\\n\", path.c_str());\n      exit(0);\n      return prob;\n    }\n    fseek(fptr, 0L, SEEK_END);\n    prob.nnz = ftell(fptr)/12;\n    printf(\"prob.nnz = %lld\\n\", prob.nnz);\n\n    mf_node *R = (mf_node *)sycl::malloc_host(sizeof(mf_node) * prob.nnz, q);\n\n    rewind(fptr);\n\n    long long idx = 0;\n    while(true)\n    {\n      int flag = 0;\n      int u,v;\n      float r;\n\n      flag += fread(&u, sizeof(int), 1, fptr); \n      flag += fread(&v, sizeof(int), 1, fptr); \n      flag += fread(&r, sizeof(float), 1, fptr); \n      if(flag != 3)break;\n\n      if(u + 1 > prob.m)prob.m = u + 1;\n      if(v + 1 > prob.n)prob.n = v + 1;\n\n      R[idx].u = u;\n      R[idx].v = v;\n      R[idx].rate = r;\n      idx ++;\n      \n\n    }\n    prob.R = R;\n\n    fclose(fptr);\n\n    printf(\"m:%d, n:%d, nnz:%lld\\n\",prob.m, prob.n, prob.nnz);\n  }\n  else\n  {\n    \n\n    long long size_list[128];\n    long long offset_list[128];\n    pthread_t threads[128];\n    pthread_arg pthread_arg_list[128];\n\n    \n\n    FILE*fptrs[80];\n    prob.nnz = 0;\n    for(int i = 0;i < num_files;i++)\n    {\n      fptrs[i] = fopen(file_names[i].c_str(), \"rb\");\n      fseek(fptrs[i], 0L, SEEK_END);\n      size_list[i] = ftell(fptrs[i])/12;\n      prob.nnz +=  size_list[i];\n      fclose(fptrs[i]);\n    }\n\n    \n\n    for(int i = 1;i < num_files;i++)\n    {\n      offset_list[i] = offset_list[i-1] + size_list[i-1];\n    }\n\n    \n\n    mf_node *R = (mf_node *)sycl::malloc_host(sizeof(mf_node) * prob.nnz, q);\n    prob.R = R;\n\n    \n\n    for(int i = 0;i < num_files; i++)\n    {\n      pthread_arg_list[i].thread_id = i;\n      pthread_arg_list[i].path = file_names[i];\n      pthread_arg_list[i].R = prob.R;\n      pthread_arg_list[i].offset = offset_list[i];\n      pthread_arg_list[i].size = size_list[i];\n      pthread_create(&(threads[i]), NULL, read_problem_thread, (void*)(&(pthread_arg_list[i])));\n    }\n\n    for(int i = 0;i < num_files;i++)\n    {\n      pthread_join(threads[i], NULL);\n    }\n    prob.m = -1;\n    prob.n = -1;\n    for(int i = 0;i < num_files;i++)\n    {\n      if(pthread_arg_list[i].max_m >= prob.m) prob.m = pthread_arg_list[i].max_m;\n      if(pthread_arg_list[i].max_n >= prob.n) prob.n = pthread_arg_list[i].max_n;\n    }\n    printf(\"m:%d, n:%d, nnz:%lld\\n\",prob.m, prob.n, prob.nnz);\n  }\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n\n  return prob;\n}\n\nvoid grid_problem(mf_problem* prob)\n{\n  printf(\"grid problem ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  \n\n  long long u_seg, v_seg;\n  if(prob->ux == 1)u_seg = prob->m;\n  else u_seg = (long long)ceil((double)prob->m/prob->ux);\n  if(prob->vy == 1)v_seg = prob->n;\n  else v_seg = (long long)ceil((double)prob->n/prob->vy);\n\n  prob->u_seg = u_seg;\n  prob->v_seg = v_seg;\n\n  auto get_grid_id = [=](int u, int v)\n  {\n    return ((u/u_seg)*prob->vy + v/v_seg);\n  };\n\n  \n\n  prob->gridSize = new long long[prob->ux*prob->vy]();\n\n  long long *gridSize = prob->gridSize;\n  for(long long i = 0;i < prob->nnz;i++)\n  {\n    int tmp_u = prob->R[i].u;\n    int tmp_v = prob->R[i].v;\n    gridSize[get_grid_id(tmp_u, tmp_v)] ++;\n  }\n\n  long long max_grid_size = 0;\n  for(int i = 0;i < prob->ux*prob->vy; i++)\n  {\n    \n\n    if(max_grid_size < prob->gridSize[i])max_grid_size = prob->gridSize[i];\n  }\n  prob->maxGridSize = max_grid_size;\n\n  \n\n  mf_node**R2D = new mf_node*[prob->ux*prob->vy + 1];\n  mf_node* R = prob->R;\n  R2D[0] = R;\n  for(int grid = 0;grid < prob->ux*prob->vy; grid++)R2D[grid + 1] = R2D[grid] + gridSize[grid];\n\n  prob->R2D = R2D;\n\n  \n\n  mf_node**pivots = new mf_node*[prob->ux*prob->vy];\n  for(int i = 0;i < prob->ux*prob->vy; i++)pivots[i] = R2D[i];\n\n  for(int grid = 0; grid < prob->ux*prob->vy; grid++)\n  {\n    for(mf_node*pivot = pivots[grid]; pivot != R2D[grid + 1];)\n    {\n      int corre_grid = get_grid_id(pivot->u, pivot->v);\n      if(corre_grid == grid)\n      {  \n        pivot ++;\n        continue;\n      }\n      mf_node *next = pivots[corre_grid];\n      swap(*pivot, *next);\n      pivots[corre_grid] ++;\n    }\n  }\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\nfloat LCG_random(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n  return (float) (*seed) / (float) m;\n}\n\nvoid LCG_random_init(unsigned int * seed) {\n  const unsigned int m = 2147483648;\n  const unsigned int a = 26757677;\n  const unsigned int c = 1;\n  *seed = (a * (*seed) + c) % m;\n}\n\nvoid init_rand_state(unsigned int seed, unsigned int *state,\n                     sycl::nd_item<1> &item)\n{\n  int i = item.get_global_id(0);\n  state[i] = seed ^ i;\n  LCG_random_init(state+i);\n}\n\nvoid random_init(unsigned int *__restrict state,\n                 int state_size, sycl::half *__restrict array,\n                 long long array_size, long long k, float scale,\n                 sycl::nd_item<1> &item)\n{\n  int tid = item.get_global_id(0);\n  int state_id = tid % state_size;\n  for (int i = 0; i < array_size;\n       i += item.get_group_range(0) * item.get_local_range(0))\n  {\n    int idx = i + tid;\n    if(idx >= array_size) break;\n    array[idx] = sycl::vec<float, 1>{LCG_random(state + state_id) * scale}\n                     .convert<sycl::half, sycl::rounding_mode::automatic>()[0];\n  }\n}\n\nvoid init_feature(sycl::queue &q, short *feature_vec, int grid, long long seg, int k)\n{\n  float scale = (float)sqrt(1.0/k);\n\n  sycl::half *gpu_vec = (sycl::half *)sycl::malloc_device(seg * k * sizeof(sycl::half), q);\n\n  int state_size = (seg/256 + 1)*256;\n  printf(\"state_size (a multiple of 256):%d\\n\", state_size);\n  unsigned int* d_state = sycl::malloc_device<unsigned int>(state_size, q);\n\n  sycl::range<1> gws_rng (state_size);\n  sycl::range<1> lws_rng (256);\n  q.parallel_for(sycl::nd_range<1>(gws_rng, lws_rng), [=](sycl::nd_item<1> item) {\n    init_rand_state(5551212, d_state, item);\n  });\n\n  const int blockSize = 256;\n  const int blockNum = (seg*k + 255)/256;\n  printf(\"\\tnumber of thread blocks:%d\\n\", blockNum);\n  printf(\"\\tarraysize:%lld\\n\", seg*k);\n\n  for(int i = 0;i < grid; i++)\n  {\n    printf(\"grid:%d\\n\",i);\n    sycl::range<1> gws_init (blockSize * blockNum);\n    sycl::range<1> lws_init (blockSize);\n    q.parallel_for(sycl::nd_range<1>(gws_init, lws_init), [=](sycl::nd_item<1> item) {\n      random_init(d_state, state_size, gpu_vec, seg * k, k, scale, item);\n    }).wait();\n    q.memcpy(feature_vec + i * seg * k, gpu_vec, sizeof(sycl::half) * seg * k).wait();\n  }\n\n  sycl::free(d_state, q);\n  sycl::free(gpu_vec, q);\n}\n\nmf_model* init_model(sycl::queue &q, mf_problem*prob, int k, float ave)\n{\n  printf(\"init model ...\\n\");\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  mf_model *model = new mf_model;\n  float scale_factor = sqrtf(1.f/k);\n  model->fun = 0;\n  model->m = prob->m;\n  model->n = prob->n;\n\n  model->u_grid = prob->u_grid;\n  model->v_grid = prob->v_grid;\n\n  model->x_grid = prob->x_grid;\n  model->y_grid = prob->y_grid;\n\n  model->ux = prob->ux;\n  model->vy = prob->vy;\n\n  model->u_seg = prob->u_seg;\n  model->v_seg = prob->v_seg;\n  model->k = k;\n  model->b = ave;\n\n  \n\n  model->floatp = (float *)sycl::malloc_host(\n      sizeof(float) * model->ux * model->u_seg * k, q);\n  model->floatq = (float *)sycl::malloc_host(\n      sizeof(float) * model->vy * model->v_seg * k, q);\n\n  model->halfp = (short *)sycl::malloc_host(\n      sizeof(short) * model->ux * model->u_seg * k, q);\n  model->halfq = (short *)sycl::malloc_host(\n      sizeof(short) * model->vy * model->v_seg * k, q);\n\n  \n\n  init_feature(q, model->halfp, model->ux, model->u_seg, k);\n  init_feature(q, model->halfq, model->vy, model->v_seg, k);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n\n  return model;\n}\n\n#include \"sgd_k128_kernel_hogwild_warp32.h\"\n#include <cmath>\n\nvoid init_rand_state(unsigned int seed, unsigned int *state, int size,\n                     sycl::nd_item<1> &item)\n{\n  int i = item.get_global_id(0);\n  state[i] = seed ^ i;\n  if(i < size) LCG_random_init(state+i);\n}\n\nvoid transform_half(const sycl::half *__restrict gpu_half_feature,\n                    float *__restrict gpu_float_feature,\n                    long long vec_size, sycl::nd_item<1> &item)\n{\n  int tid = item.get_global_id(0);\n  int number_threads = item.get_group_range(0) * item.get_local_range(0);\n\n  for(long long i = tid;i < vec_size;i += number_threads)\n  {\n    gpu_float_feature[i] =\n        sycl::vec<sycl::half, 1>{gpu_half_feature[i]}\n            .convert<float, sycl::rounding_mode::automatic>()[0];\n  }\n}\n\nvoid transform_feature_vector(sycl::queue &q, short *half_feature, float *float_feature,\n                              int m, int grid, long long seg, int k)\n{\n  sycl::half *gpu_half_feature = \n    (sycl::half *)sycl::malloc_device(sizeof(sycl::half) * seg * k, q);\n\n  float *gpu_float_feature = (float *)sycl::malloc_device(sizeof(float) * seg * k, q);\n\n  for(int i = 0;i < grid;i++)\n  {\n    q.memcpy(gpu_half_feature, half_feature + i * seg * k,\n                sizeof(sycl::half) * seg * k).wait();\n\n    int num_blocks = (seg*k+255)/256;\n    if(num_blocks > 8*24)num_blocks = 8*24;\n\n    sycl::range<1> gws (num_blocks * 256);\n    sycl::range<1> lws (256);\n    q.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      transform_half(gpu_half_feature, gpu_float_feature, seg * k, item);\n    }).wait();\n\n    q.memcpy(float_feature + i * seg * k, gpu_float_feature,\n             sizeof(float) * seg * k).wait();\n  }\n\n  sycl::free(gpu_half_feature, q);\n  sycl::free(gpu_float_feature, q);\n}\n\nvoid sgd_update_k128(sycl::queue &q, Parameter para, mf_model *model, mf_problem *prob, float scale)\n{\n  printf(\"sgd_update_k128 ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  \n\n  unsigned int *rand_state = sycl::malloc_device<unsigned int>(para.num_workers, q);\n\n  sycl::range<1> gws_rng ((para.num_workers + 255) / 256 * 256);\n  sycl::range<1> lws_rng (256);\n  q.parallel_for(sycl::nd_range<1>(gws_rng, lws_rng), [=](sycl::nd_item<1> item) {\n    init_rand_state(5551212, rand_state, para.num_workers, item);\n  });\n\n  \n\n  float dynamic_rate[1024];\n  float alpha = para.alpha;\n  float beta  = para.beta;\n  float lrate = para.lrate;\n\n  for(int i = 0;i < (para.num_iters + 4);i++)\n  {\n    double tmp_rate = alpha / (1 + beta * pow(i, 1.5)) + lrate;\n    dynamic_rate[i] = tmp_rate;\n  }\n  float *gpu_dynamic_rate = sycl::malloc_device<float>(1024, q);\n  q.memcpy(gpu_dynamic_rate, dynamic_rate, sizeof(float) * 1024).wait();\n\n  \n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    prob->gpuR = (struct mf_node *)sycl::malloc_device(\n        sizeof(mf_node) * prob->maxGridSize, q);\n    prob->cur_u_id = -1;\n    prob->cur_v_id = -1;\n  }\n  else\n  {\n    prob->gpuRptrs[0] = (struct mf_node *)sycl::malloc_device(\n        sizeof(mf_node) * prob->maxGridSize, q);\n    prob->gpuRptrs[1] = (struct mf_node *)sycl::malloc_device(\n        sizeof(mf_node) * prob->maxGridSize, q);\n    prob->cur_global_x_id[0] = -1;\n    prob->cur_global_x_id[1] = -1;\n    prob->cur_global_y_id[0] = -1;\n    prob->cur_global_y_id[1] = -1;\n  }\n\n  \n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    model->gpuHalfp = (sycl::half *)sycl::malloc_device(\n        sizeof(sycl::half) * model->u_seg * model->k, q);\n    model->gpuHalfq = (sycl::half *)sycl::malloc_device(\n        sizeof(sycl::half) * model->v_seg * model->k, q);\n    model->cur_u_id = -1;\n    model->cur_v_id = -1;\n  }\n  else\n  {\n    model->gpuHalfPptrs[0] = (sycl::half *)sycl::malloc_device(\n        sizeof(sycl::half) * model->u_seg * model->k, q);\n    model->gpuHalfPptrs[1] = (sycl::half *)sycl::malloc_device(\n        sizeof(sycl::half) * model->u_seg * model->k, q);\n    model->gpuHalfQptrs[0] = (sycl::half *)sycl::malloc_device(\n        sizeof(sycl::half) * model->v_seg * model->k, q);\n    model->gpuHalfQptrs[1] = (sycl::half *)sycl::malloc_device(\n        sizeof(sycl::half) * model->v_seg * model->k, q);\n\n    model->cur_global_x_id[0] = -1;\n    model->cur_global_x_id[1] = -1;\n    model->cur_global_y_id[0] = -1;\n    model->cur_global_y_id[1] = -1;\n  }   \n\n  \n\n  int update_vector_size = 128;\n  int *update_count_per_block = new int[prob->ux*prob->vy]();\n  int max_update_count_per_block = -1;\n  for(int cur_grid_id = 0;cur_grid_id < prob->ux*prob->vy; cur_grid_id ++)\n  {\n    update_count_per_block[cur_grid_id] = \n      (ceil)(1.0*prob->gridSize[cur_grid_id]/(para.num_workers*update_vector_size));   \n    if(max_update_count_per_block < update_count_per_block[cur_grid_id])\n    {\n      max_update_count_per_block = update_count_per_block[cur_grid_id];\n    }\n  }\n\n  \n\n  random_device rd;\n  mt19937 g(rd());\n\n  \n\n  if(prob->u_grid*prob->v_grid == 1)\n  {\n    q.memcpy(prob->gpuR, prob->R2D[0], sizeof(mf_node) * prob->gridSize[0]);\n    q.memcpy(model->gpuHalfp, model->halfp, sizeof(sycl::half) * model->u_seg * model->k);\n    q.memcpy(model->gpuHalfq, model->halfq, sizeof(sycl::half) * model->v_seg * model->k);\n    q.wait();\n\n    sycl::range<1> gws (para.num_workers / 4 * 128);\n    sycl::range<1> lws (128);\n    q.submit([&](sycl::handler &cgh) {\n      auto prob_gpuR = prob->gpuR;\n      auto prob_gridSize = prob->gridSize[0];\n      auto model_gpuHalfp = model->gpuHalfp;\n      auto model_gpuHalfq = model->gpuHalfq;\n      auto model_u_seg = model->u_seg;\n      auto model_v_seg = model->v_seg;\n      auto model_k = model->k;\n      auto update_count_per_block0 = update_count_per_block[0];\n      auto prob_u_grid = prob->u_grid;\n      auto prob_v_grid = prob->v_grid;\n      auto lambda_p = para.lambda_p; \n      auto lambda_q = para.lambda_q; \n\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n        [[intel::reqd_sub_group_size(32)]] {\n            sgd_k128_kernel_hogwild_warp32_lrate(\n                prob_gpuR, prob_gridSize, model_gpuHalfp,\n                model_gpuHalfq, rand_state, gpu_dynamic_rate,\n                model_u_seg, model_v_seg, model_k, para.num_iters,\n                0, max_update_count_per_block, update_count_per_block0,\n                update_vector_size, lambda_p, lambda_q,\n                prob_u_grid, prob_v_grid, 0, 0, item);\n          });\n    }).wait();\n\n    q.memcpy(model->halfp, model->gpuHalfp, sizeof(sycl::half) * model->u_seg * model->k);\n    q.memcpy(model->halfq, model->gpuHalfq, sizeof(sycl::half) * model->v_seg * model->k);\n    q.wait();\n  }\n  else if(prob->x_grid*prob->y_grid == 1)\n  {\n    \n\n    vector<int> u_id_vec(prob->u_grid, 0);\n    vector<int> v_id_vec(prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid;i++) u_id_vec[i] = i;\n    for(int i = 0;i < prob->v_grid;i++) v_id_vec[i] = i;\n\n    for(int iter = 0;iter < para.num_iters; iter ++)\n    {\n      shuffle(u_id_vec.begin(), u_id_vec.end(), g);\n      for(int u_ite = 0;u_ite < prob->u_grid; u_ite ++)\n      {\n\n        shuffle(v_id_vec.begin(), v_id_vec.end(), g);\n        for(int v_ite = 0;v_ite < prob->v_grid; v_ite ++)\n        {\n          int cur_u_id = u_id_vec[u_ite];\n          int cur_v_id = v_id_vec[v_ite];\n\n          int cur_grid_id = cur_u_id*prob->v_grid + cur_v_id;\n          \n\n          if(prob->cur_u_id != cur_u_id || prob->cur_v_id != cur_v_id)\n          {\n            q.memcpy(prob->gpuR, prob->R2D[cur_grid_id],\n                     sizeof(mf_node) * prob->gridSize[cur_grid_id]).wait();\n          }\n\n          prob->cur_u_id = cur_u_id;\n          prob->cur_v_id = cur_v_id;\n\n          \n\n          if(model->cur_u_id == -1)\n          {\n            short *p_tmp = model->halfp + model->u_seg*model->k*cur_u_id;\n            q.memcpy(model->gpuHalfp, p_tmp,\n                     sizeof(sycl::half) * model->u_seg * model->k).wait();\n          }\n          else if(model->cur_u_id != cur_u_id)\n          {\n            short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_u_id;\n            q.memcpy(p_tmp, model->gpuHalfp,\n                     sizeof(sycl::half) * model->u_seg * model->k).wait();\n\n            p_tmp = model->halfp + model->u_seg*model->k*cur_u_id;\n            q.memcpy(model->gpuHalfp, p_tmp,\n                     sizeof(sycl::half) * model->u_seg * model->k).wait();\n          }\n          model->cur_u_id = cur_u_id;\n\n          \n\n          if(model->cur_v_id == -1)\n          {\n            short *q_tmp = model->halfq + model->v_seg*model->k*cur_v_id;\n            q.memcpy(model->gpuHalfq, q_tmp,\n                     sizeof(sycl::half) * model->v_seg * model->k).wait();\n          }\n          else if(model->cur_v_id != cur_v_id)\n          {\n            short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_v_id;\n            q.memcpy(q_tmp, model->gpuHalfq,\n                     sizeof(sycl::half) * model->v_seg * model->k).wait();\n\n            q_tmp = model->halfq + model->v_seg*model->k*cur_v_id;\n            q.memcpy(model->gpuHalfq, q_tmp,\n                     sizeof(sycl::half) * model->v_seg * model->k).wait();\n          }\n          model->cur_v_id = cur_v_id;\n\n          \n\n          sycl::range<1> gws (para.num_workers / 4 * 128);\n          sycl::range<1> lws (128);\n          q.submit([&](sycl::handler &cgh) {\n            auto prob_gpuR = prob->gpuR;\n            auto prob_gridSize_cur_grid_id = prob->gridSize[cur_grid_id];\n            auto model_gpuHalfp = model->gpuHalfp;\n            auto model_gpuHalfq = model->gpuHalfq;\n            auto model_u_seg = model->u_seg;\n            auto model_v_seg = model->v_seg;\n            auto model_k = model->k;\n            auto update_count_per_block_cur_grid_id =\n                update_count_per_block[cur_grid_id];\n            auto prob_u_grid = prob->u_grid;\n            auto prob_v_grid = prob->v_grid;\n            auto lambda_p = para.lambda_p;\n            auto lambda_q = para.lambda_q;\n\n            cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n              [[intel::reqd_sub_group_size(32)]] {\n              sgd_k128_kernel_hogwild_warp32_lrate(\n                prob_gpuR, prob_gridSize_cur_grid_id,\n                model_gpuHalfp, model_gpuHalfq, rand_state,\n                gpu_dynamic_rate, model_u_seg, model_v_seg,\n                model_k, 1, iter, max_update_count_per_block,\n                update_count_per_block_cur_grid_id,\n                update_vector_size, lambda_p, lambda_q,\n                prob_u_grid, prob_v_grid, cur_u_id,\n                cur_v_id, item);\n            });\n          }).wait();\n        }\n      }\n      q.wait();\n    }\n    q.wait();\n\n    \n\n\n    \n\n    if(model->cur_u_id >= 0)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_u_id;\n      q.memcpy(p_tmp, model->gpuHalfp, sizeof(sycl::half) * model->u_seg * model->k).wait();\n    }\n    \n\n    if(model->cur_v_id >= 0)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_v_id;\n      q.memcpy(q_tmp, model->gpuHalfq, sizeof(sycl::half) * model->v_seg * model->k).wait();\n    }\n  }\n  else\n  {\n    \n\n    int *global_x_list = new int[prob->x_grid*prob->y_grid];\n    int *global_y_list = new int[prob->x_grid*prob->y_grid];\n    int *global_id_list = new int[prob->x_grid*prob->y_grid];\n\n    \n\n    vector<int> u_id_vec(prob->u_grid, 0);\n    vector<int> v_id_vec(prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid;i++)u_id_vec[i] = i;\n    for(int i = 0;i < prob->v_grid;i++)v_id_vec[i] = i;\n\n    vector<int> x_id_vec(prob->x_grid, 0);\n    vector<int> y_id_vec(prob->y_grid, 0);\n    for(int i = 0;i < prob->x_grid;i++)x_id_vec[i] = i;\n    for(int i = 0;i < prob->y_grid;i++)y_id_vec[i] = i;\n\n    \n\n    vector<int> uv_id_vec(prob->u_grid*prob->v_grid, 0);\n    for(int i = 0;i < prob->u_grid*prob->v_grid; i++)uv_id_vec[i] = i;\n    vector<int> xy_id_vec(prob->x_grid*prob->y_grid, 0);\n    for(int i = 0;i < prob->x_grid*prob->y_grid; i++)xy_id_vec[i] = i;\n\n    for(int iter = 0;iter < para.num_iters; iter ++)\n    {\n      shuffle(uv_id_vec.begin(), uv_id_vec.end(), g);\n      shuffle(u_id_vec.begin(), u_id_vec.end(), g);\n\n      for(int u_ite = 0;u_ite < prob->u_grid; u_ite ++)\n      {\n        shuffle(v_id_vec.begin(), v_id_vec.begin(), g);\n        for(int v_ite = 0;v_ite < prob->v_grid; v_ite ++)\n        {\n\n          \n\n          int tmp_uv_id = u_ite*prob->v_grid + v_ite;\n          int cur_u_id = uv_id_vec[tmp_uv_id]/prob->v_grid;\n          int cur_v_id = uv_id_vec[tmp_uv_id]%prob->v_grid;\n\n          \n\n          shuffle(x_id_vec.begin(), x_id_vec.end(), g);\n          shuffle(xy_id_vec.begin(), xy_id_vec.end(), g);\n\n          for(int local_x_ite = 0;local_x_ite < prob->x_grid;local_x_ite ++)\n          {\n            shuffle(y_id_vec.begin(),y_id_vec.end(), g);\n            for(int local_y_ite = 0;local_y_ite < prob->y_grid;local_y_ite ++)\n            {\n\n              \n\n              int tmp_xy_id = local_x_ite*prob->y_grid + local_y_ite;\n              int cur_x_id = xy_id_vec[tmp_xy_id]/prob->y_grid;\n              int cur_y_id = xy_id_vec[tmp_xy_id]%prob->y_grid;\n\n              int local_id = cur_x_id*prob->y_grid + cur_y_id;\n\n              int global_x = cur_u_id*prob->x_grid + cur_x_id;\n              int global_y = cur_v_id*prob->y_grid + cur_y_id;\n              int global_id = global_x*prob->vy + global_y;\n\n              global_x_list[local_id] = global_x;\n              global_y_list[local_id] = global_y;\n              global_id_list[local_id] = global_id;\n\n            }\n          }\n\n          \n\n          for(int i = -1;i < prob->x_grid*prob->y_grid;i++)\n          {\n            \n\n            if(i >= 0)\n            {\n              sycl::range<1> gws (para.num_workers / 4 * 128);\n              sycl::range<1> lws (128);\n              q.submit([&](sycl::handler &cgh) {\n                auto prob_gpuRptrs_i_ct0 = prob->gpuRptrs[i % 2];\n                auto prob_gridSize_global_id_list_i_ct1 =\n                    prob->gridSize[global_id_list[i]];\n                auto model_gpuHalfPptrs_i_ct2 = model->gpuHalfPptrs[i % 2];\n                auto model_gpuHalfQptrs_i_ct3 = model->gpuHalfQptrs[i % 2];\n                auto model_u_seg_ct6 = model->u_seg;\n                auto model_v_seg_ct7 = model->v_seg;\n                auto model_k_ct8 = model->k;\n                auto update_count_per_block_global_id_list_i_ct12 =\n                    update_count_per_block[global_id_list[i]];\n                auto prob_ux_ct16 = prob->ux;\n                auto prob_vy_ct17 = prob->vy;\n                auto global_x_list_i_ct18 = global_x_list[i];\n                auto global_y_list_i_ct19 = global_y_list[i];\n                auto lambda_p = para.lambda_p; \n                auto lambda_q = para.lambda_q; \n\n                cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item)\n                  [[intel::reqd_sub_group_size(32)]] {\n                  sgd_k128_kernel_hogwild_warp32_lrate(\n                    prob_gpuRptrs_i_ct0,\n                    prob_gridSize_global_id_list_i_ct1,\n                    model_gpuHalfPptrs_i_ct2,\n                    model_gpuHalfQptrs_i_ct3, rand_state,\n                    gpu_dynamic_rate, model_u_seg_ct6,\n                    model_v_seg_ct7, model_k_ct8, 1, iter,\n                    max_update_count_per_block,\n                    update_count_per_block_global_id_list_i_ct12,\n                    update_vector_size, lambda_p, lambda_q,\n                    prob_ux_ct16, prob_vy_ct17, global_x_list_i_ct18,\n                    global_y_list_i_ct19, item);\n                });\n              }).wait();\n            }\n\n            \n\n            if(i != (prob->x_grid*prob->y_grid - 1))\n            {\n              int next_global_x = global_x_list[i+1];\n              int next_global_y = global_y_list[i+1];\n              int next_global_id = global_id_list[i+1];\n\n              \n\n              if(prob->cur_global_x_id[(i+1)%2] !=  next_global_x || prob->cur_global_y_id[(i+1)%2] != next_global_y)\n              {\n                q.memcpy(prob->gpuRptrs[(i + 1) % 2], prob->R2D[next_global_id],\n                    sizeof(mf_node) * prob->gridSize[next_global_id]);\n              }\n\n              \n\n              if(model->cur_global_x_id[(i+1)%2] == -1)\n              {\n                if(model->cur_global_x_id[(i+2)%2] == next_global_x)\n                {\n                  model->cur_global_x_id[(i+2)%2] = -1;\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n\n                  sycl::half *tmp_ptr = model->gpuHalfPptrs[(i + 1) % 2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = tmp_ptr;\n                }\n                else\n                {\n                  short *p_tmp = model->halfp + model->u_seg*model->k*next_global_x;\n                  q.memcpy(model->gpuHalfPptrs[(i + 1) % 2], p_tmp,\n                      sizeof(sycl::half) * model->u_seg * model->k);\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n              }\n              else if(model->cur_global_x_id[(i+1)%2] != next_global_x)\n              {\n                if(model->cur_global_x_id[(i+2)%2] == -1)\n                {\n                  \n\n                  int tmp = model->cur_global_x_id[(i+1)%2];\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                  model->cur_global_x_id[(i+2)%2] = tmp;\n\n                  \n\n                  sycl::half *p_tmp = model->gpuHalfPptrs[(i + 1) % 2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = p_tmp;\n\n                  \n\n                  short *p_tmp_trans = model->halfp + model->u_seg*model->k*next_global_x;\n                  q.memcpy(\n                      model->gpuHalfPptrs[(i + 1) % 2], p_tmp_trans,\n                      sizeof(sycl::half) * model->u_seg * model->k);\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n                else if(model->cur_global_x_id[(i+2)%2] == next_global_x)\n                {\n                  \n\n                  int tmp = model->cur_global_x_id[(i+1)%2];\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                  model->cur_global_x_id[(i+2)%2] = tmp;\n\n                  \n\n                  sycl::half *p_tmp = model->gpuHalfPptrs[(i + 1) % 2];\n                  model->gpuHalfPptrs[(i+1)%2] = model->gpuHalfPptrs[(i+2)%2];\n                  model->gpuHalfPptrs[(i+2)%2] = p_tmp;\n                }\n                else\n                {\n                  short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[(i+1)%2];\n                  q.memcpy(\n                      p_tmp, model->gpuHalfPptrs[(i + 1) % 2],\n                      sizeof(sycl::half) * model->u_seg * model->k);\n\n                  p_tmp = model->halfp + model->u_seg*model->k*next_global_x;\n                  q.memcpy(\n                      model->gpuHalfPptrs[(i + 1) % 2], p_tmp,\n                      sizeof(sycl::half) * model->u_seg * model->k);\n\n                  model->cur_global_x_id[(i+1)%2] = next_global_x;\n                }\n              }\n\n              \n\n              if(model->cur_global_y_id[(i+1)%2] == -1)\n              {\n                if(model->cur_global_y_id[(i+2)%2] == next_global_y)\n                {\n                  model->cur_global_y_id[(i+2)%2] = -1;\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n\n                  sycl::half *tmp_ptr = model->gpuHalfQptrs[(i + 1) % 2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = tmp_ptr;\n                }\n                else\n                {\n                  short *q_tmp = model->halfq + model->v_seg*model->k*next_global_y;\n                  q.memcpy(\n                      model->gpuHalfQptrs[(i + 1) % 2], q_tmp,\n                      sizeof(sycl::half) * model->v_seg * model->k);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n              }\n              else if(model->cur_global_y_id[(i+1)%2] != next_global_y)\n              {\n                if(model->cur_global_y_id[(i+2)%2] == -1)\n                {\n                  \n\n                  int tmp = model->cur_global_y_id[(i+1)%2];\n                  model->cur_global_y_id[(i+1)%2] = model->cur_global_y_id[(i+2)%2];\n                  model->cur_global_y_id[(i+2)%2] = tmp;\n\n                  \n\n                  sycl::half *q_tmp = model->gpuHalfQptrs[(i + 1) % 2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = q_tmp;\n\n                  short *q_tmp_trans = model->halfq + model->v_seg*model->k*next_global_y;\n                  q.memcpy(\n                      model->gpuHalfQptrs[(i + 1) % 2], q_tmp_trans,\n                      sizeof(sycl::half) * model->v_seg * model->k);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n                else if(model->cur_global_y_id[(i+2)%2] == next_global_y)\n                {\n                  \n\n                  int tmp = model->cur_global_y_id[(i+1)%2];\n                  model->cur_global_y_id[(i+1)%2] = model->cur_global_y_id[(i+2)%2];\n                  model->cur_global_y_id[(i+2)%2] = tmp;\n\n                  \n\n                  sycl::half *q_tmp = model->gpuHalfQptrs[(i + 1) % 2];\n                  model->gpuHalfQptrs[(i+1)%2] = model->gpuHalfQptrs[(i+2)%2];\n                  model->gpuHalfQptrs[(i+2)%2] = q_tmp;\n                }\n                else\n                {\n                  short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[(i+1)%2];\n                  q.memcpy(q_tmp, model->gpuHalfQptrs[(i + 1) % 2],\n                      sizeof(sycl::half) * model->v_seg * model->k);\n\n                  q_tmp = model->halfq + model->v_seg*model->k*next_global_y;\n                  q.memcpy(\n                      model->gpuHalfQptrs[(i + 1) % 2], q_tmp,\n                      sizeof(sycl::half) * model->v_seg * model->k);\n                  model->cur_global_y_id[(i+1)%2] = next_global_y;\n                }\n              }\n            }\n            q.wait();\n          }\n        }\n      }\n      q.wait();\n    }\n    q.wait();\n\n    \n\n    if(model->cur_global_x_id[0] != -1)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[0];\n      q.memcpy(p_tmp, model->gpuHalfPptrs[0], sizeof(sycl::half) * model->u_seg * model->k).wait();\n    }\n    if(model->cur_global_x_id[1] != -1)\n    {\n      short *p_tmp = model->halfp + model->u_seg*model->k*model->cur_global_x_id[1];\n      q.memcpy(p_tmp, model->gpuHalfPptrs[1], sizeof(sycl::half) * model->u_seg * model->k).wait();\n    }\n\n    \n\n    if(model->cur_global_y_id[0] != -1)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[0];\n      q.memcpy(q_tmp, model->gpuHalfQptrs[0], sizeof(sycl::half) * model->v_seg * model->k).wait();\n    }\n    if(model->cur_global_y_id[1] != -1)\n    {\n      short *q_tmp = model->halfq + model->v_seg*model->k*model->cur_global_y_id[1];\n      q.memcpy(q_tmp, model->gpuHalfQptrs[1], sizeof(sycl::half) * model->v_seg * model->k).wait();\n    }\n  }\n\n  if(prob->x_grid*prob->y_grid == 1)\n  {\n    sycl::free(model->gpuHalfp, q);\n    sycl::free(model->gpuHalfq, q);\n    sycl::free(prob->gpuR, q);\n  }\n  else\n  {\n    sycl::free(model->gpuHalfPptrs[0], q);\n    sycl::free(model->gpuHalfPptrs[1], q);\n    sycl::free(model->gpuHalfQptrs[0], q);\n    sycl::free(model->gpuHalfQptrs[1], q);\n    sycl::free(prob->gpuRptrs[0], q);\n    sycl::free(prob->gpuRptrs[1], q);\n  }\n\n  \n\n  transform_feature_vector(q, model->halfp, model->floatp, model->m, model->ux, model->u_seg, model->k);\n  transform_feature_vector(q, model->halfq, model->floatq, model->n, model->vy, model->v_seg, model->k);\n\n  sycl::free(gpu_dynamic_rate, q);\n  sycl::free(rand_state, q);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\nvoid scale_model(mf_model *model, float scale)\n{\n  printf(\"scale model ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  float factor_scale = sqrt(scale);\n  for(long long i = 0; i < ((long long)model->m)*model->k; i++)model->floatp[i] = model->floatp[i]*factor_scale;\n\n\n  for(long long i = 0; i < model->n*model->k; i++)model->floatq[i] = model->floatq[i]*factor_scale;\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\n\nvoid shuffle_model(mf_model *model, int* inv_p_map, int* inv_q_map)\n{\n  printf(\"shuffle model ...\\n\");\n\n  struct timespec begin, end;\n  double elapsed;\n  clock_gettime(CLOCK_MONOTONIC, &begin);\n\n  auto inv_shuffle1 = [] (float *vec, int *map, int size, int k)\n  {\n    for(int pivot = 0; pivot < size;)\n    {\n      if(pivot == map[pivot])\n      {\n        ++pivot;\n        continue;\n      }\n\n      int next = map[pivot];\n\n      for(SGDIndex d = 0; d < k; d++)swap(*(vec + (long long)pivot*k+d), *(vec+(long long)next*k+d));\n\n      map[pivot] = map[next];\n      map[next] = next;\n    }\n  };\n\n  inv_shuffle1(model->floatp, inv_p_map, model->m, model->k);\n  inv_shuffle1(model->floatq, inv_q_map, model->n, model->k);\n\n  clock_gettime(CLOCK_MONOTONIC, &end);\n  elapsed = end.tv_sec - begin.tv_sec;\n  elapsed += (end.tv_nsec - begin.tv_nsec) / 1000000000.0;\n  printf(\"time elapsed:%.8fs\\n\\n\\n\",elapsed);\n}\n\n\n\nmf_model*sgd_train(sycl::queue &q, mf_problem*tr, mf_problem*te, Parameter para)\n{\n  printf(\"sgd_train called\\n\");\n\n  \n\n  SGDRate ave;\n  SGDRate std_dev;\n  SGDRate scale = 1.0;\n\n  collect_data(tr, ave, std_dev);\n  scale = fmaxf((SGDRate)1e-4, std_dev);\n\n  \n\n  int* p_map = gen_random_map(tr->m);\n  int* q_map = gen_random_map(tr->n);\n  int* inv_p_map = gen_inv_map(p_map, tr->m);\n  int* inv_q_map = gen_inv_map(q_map, tr->n);\n\n  shuffle_problem(tr, p_map, q_map);\n\n  grid_problem(tr); \n\n  \n\n  scale_problem(tr, 1.0/scale, tr->u_seg, tr->v_seg);\n  para.lambda_p = para.lambda_p/scale;\n  para.lambda_q = para.lambda_q/scale;\n\n  \n\n  mf_model*model = init_model(q, tr, para.k, ave/std_dev);\n\n  \n\n  sgd_update_k128(q, para, model, tr, scale);\n\n  \n\n  scale_model(model, scale);\n\n  \n\n  shuffle_model(model, inv_p_map, inv_q_map);\n\n  return model;\n}\n"}}
{"kernel_name": "mrc", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"reference.h\"\n\n__global__\nvoid MRCGradient (\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\n__global__\nvoid MRCGradient2(\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n  float *d_X1, *d_X2, *d_O, *d_dX1, *d_dX2;\n  int *d_Y;\n  cudaMalloc((void**)&d_X1, size_bytes);\n  cudaMemcpy(d_X1, h_X1, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_X2, size_bytes);\n  cudaMemcpy(d_X2, h_X2, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_O, size_bytes);\n  cudaMemcpy(d_O, h_O, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_Y, size_bytes);\n  cudaMemcpy(d_Y, h_Y, size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_dX1, size_bytes);\n  cudaMalloc((void**)&d_dX2, size_bytes);\n\n  dim3 grid ((length + 255) / 256);\n  dim3 block (256);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    MRCGradient <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n    MRCGradient2 <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n  }\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) \n    MRCGradient <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) \n    MRCGradient2 <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  cudaMemcpy(h_dX1, d_dX1, size_bytes, cudaMemcpyDeviceToHost); \n  cudaMemcpy(h_dX2, d_dX2, size_bytes, cudaMemcpyDeviceToHost); \n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_X1);\n  cudaFree(d_X2);\n  cudaFree(d_O);\n  cudaFree(d_Y);\n  cudaFree(d_dX1);\n  cudaFree(d_dX2);\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}\n"}}
{"kernel_name": "mrc", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n__global__\nvoid MRCGradient (\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\n__global__\nvoid MRCGradient2(\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n  float *d_X1, *d_X2, *d_O, *d_dX1, *d_dX2;\n  int *d_Y;\n  hipMalloc((void**)&d_X1, size_bytes);\n  hipMemcpy(d_X1, h_X1, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_X2, size_bytes);\n  hipMemcpy(d_X2, h_X2, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_O, size_bytes);\n  hipMemcpy(d_O, h_O, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_Y, size_bytes);\n  hipMemcpy(d_Y, h_Y, size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_dX1, size_bytes);\n  hipMalloc((void**)&d_dX2, size_bytes);\n\n  dim3 grid ((length + 255) / 256);\n  dim3 block (256);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    MRCGradient <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n    MRCGradient2 <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n  }\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) \n    MRCGradient <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) \n    MRCGradient2 <<<grid, block>>> (length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  hipMemcpy(h_dX1, d_dX1, size_bytes, hipMemcpyDeviceToHost); \n  hipMemcpy(h_dX2, d_dX2, size_bytes, hipMemcpyDeviceToHost); \n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_X1);\n  hipFree(d_X2);\n  hipFree(d_O);\n  hipFree(d_Y);\n  hipFree(d_dX1);\n  hipFree(d_dX2);\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}\n"}}
{"kernel_name": "mrc", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"reference.h\"\n\nvoid MRCGradient (\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict dX1, float*__restrict dX2) {\n  #pragma omp target teams distribute parallel for num_threads(256)\n  for (int i = 0; i < N; i++) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\nvoid MRCGradient2(\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict dX1, float*__restrict dX2) {\n  #pragma omp target teams distribute parallel for num_threads(256)\n  for (int i = 0; i < N; i++) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n  #pragma omp target data map(to: h_X1[0:length], \\\n                                  h_X2[0:length], \\\n                                  h_O[0:length], \\\n                                  h_Y[0:length]) \\\n                          map(from: h_dX1[0:length],\\\n                                    h_dX2[0:length])\n  {\n    \n\n    for (int i = 0; i < repeat; i++) {\n      MRCGradient(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n      MRCGradient2(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n    }\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) \n      MRCGradient(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) \n      MRCGradient2(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}\n"}}
{"kernel_name": "mrc", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\nvoid MRCGradient (\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict dX1, float*__restrict dX2) {\n    for (int i = 0; i < N; i++) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\nvoid MRCGradient2(\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict dX1, float*__restrict dX2) {\n    for (int i = 0; i < N; i++) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n    {\n    \n\n    for (int i = 0; i < repeat; i++) {\n      MRCGradient(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n      MRCGradient2(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n    }\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) \n      MRCGradient(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) \n      MRCGradient2(length, h_Y, h_X1, h_X2, h_O, m, h_dX1, h_dX2);\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}"}}
{"kernel_name": "mrc", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nvoid MRCGradient (\n    sycl::nd_item<1> &item,\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2) {\n  int i = item.get_global_id(0);\n  if (i < N) {\n    float dist = -Y[i] * (X1[i] - X2[i]) + margin;\n    if (dist < 0.f) {\n      dX1[i] = dX2[i] = 0.f;\n    } else {\n      dX1[i] = -Y[i] * dOutput[i];\n      dX2[i] = Y[i] * dOutput[i];\n    }\n  }\n}\n\nvoid MRCGradient2(\n    sycl::nd_item<1> &item,\n    const int N, const int* Y, const float* X1, const float* X2, const float* dOutput,\n    const float margin, float*__restrict__ dX1, float*__restrict__ dX2) {\n  int i = item.get_global_id(0);\n  if (i < N) {\n    float y = Y[i];\n    float o = dOutput[i];\n    float dist = -y * (X1[i] - X2[i]) + margin;\n    dX1[i] = dist < 0.f ? 0.f : -y * o;\n    dX2[i] = dist < 0.f ? 0.f : y * o;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  size_t size_bytes = length * sizeof(float);\n\n  float *h_X1  = (float*) malloc (size_bytes);\n  float *h_X2  = (float*) malloc (size_bytes);\n  float *h_O   = (float*) malloc (size_bytes);\n    int *h_Y   = (  int*) malloc (size_bytes);\n  float *h_dX1 = (float*) malloc (size_bytes);\n  float *h_dX2 = (float*) malloc (size_bytes);\n  float *r_dX1 = (float*) malloc (size_bytes);\n  float *r_dX2 = (float*) malloc (size_bytes);\n\n  const float m = 0.01;  \n\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-2.f, 2.f);\n  for (int i = 0; i < length; i++) {\n    h_X1[i] = distr(g);\n    h_X2[i] = distr(g);\n    h_O[i] = distr(g);\n    h_Y[i] = (distr(g) < 0) ? -1 : 1;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_X1, *d_X2, *d_O, *d_dX1, *d_dX2;\n  int *d_Y;\n  d_X1 = sycl::malloc_device<float>(length, q);\n  q.memcpy(d_X1, h_X1, size_bytes);\n\n  d_X2 = sycl::malloc_device<float>(length, q);\n  q.memcpy(d_X2, h_X2, size_bytes);\n\n  d_O = sycl::malloc_device<float>(length, q);\n  q.memcpy(d_O, h_O, size_bytes);\n\n  d_Y = sycl::malloc_device<int>(length, q);\n  q.memcpy(d_Y, h_Y, size_bytes);\n\n  d_dX1 = sycl::malloc_device<float>(length, q);\n  d_dX2 = sycl::malloc_device<float>(length, q);\n\n  sycl::range<1> gws ((length + 255) / 256 * 256);\n  sycl::range<1> lws (256);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        MRCGradient(item, length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n      });\n    });\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        MRCGradient2(item, length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n      });\n    });\n  }\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        MRCGradient(item, length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        MRCGradient2(item, length, d_Y, d_X1, d_X2, d_O, m, d_dX1, d_dX2);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of MRC2 kernel: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  q.memcpy(h_dX1, d_dX1, size_bytes).wait();\n  q.memcpy(h_dX2, d_dX2, size_bytes).wait();\n\n  reference (length, h_Y, h_X1, h_X2, h_O, m, r_dX1, r_dX2);\n\n  bool ok = true;\n  for (int i = 0; i < length; i++) {\n    if (fabs(h_dX1[i] - r_dX1[i]) > 1e-3 || fabs(h_dX2[i] - r_dX2[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_X1, q);\n  sycl::free(d_X2, q);\n  sycl::free(d_O, q);\n  sycl::free(d_Y, q);\n  sycl::free(d_dX1, q);\n  sycl::free(d_dX2, q);\n\n  free(h_X1);\n  free(h_X2);\n  free(h_O);\n  free(h_Y);\n  free(h_dX1);\n  free(h_dX2);\n\n  return 0;\n}\n"}}
{"kernel_name": "nlll", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t, \n          typename index_t, int NLL_LOSS_THREADS>\n__global__\nvoid nll_loss_forward_reduce2d_kernel(\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n  __shared__ accscalar_t sm_inputs[NLL_LOSS_THREADS],\n                         acc_weight[NLL_LOSS_THREADS];\n\n  int tid = threadIdx.x;\n  sm_inputs[tid] = static_cast<accscalar_t>(0);\n  acc_weight[tid] = static_cast<accscalar_t>(0);\n\n  for (int i = tid; i < nframe; i += NLL_LOSS_THREADS) {\n    index_t t = target[i];\n    if (t != ignore_index) {\n      scalar_t cur_weight =\n          weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n      sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n      acc_weight[tid] += cur_weight;\n    }\n  }\n\n  __syncthreads();\n\n  if (tid == 0) {\n    accscalar_t output_acc = 0;\n    accscalar_t total_weight_acc = 0;\n    for (int i = 0; i < NLL_LOSS_THREADS; ++i) {\n      output_acc += sm_inputs[i];\n      total_weight_acc += acc_weight[i];\n    }\n    *total_weight = static_cast<scalar_t>(total_weight_acc);\n    if (size_average) {\n      *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n    } else {\n      *output = static_cast<scalar_t>(output_acc);\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  int64_t weights_size = nframe;\n  int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  int64_t target_size = nframe;\n  int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  int output_size_bytes = sizeof(scalar_t);\n\n  scalar_t h_output;\n  scalar_t h_total_weight;\n\n  scalar_t *d_output;\n  scalar_t *d_total_weight;\n  scalar_t *d_input;\n   index_t *d_target;\n  scalar_t *d_weights;\n\n  cudaMalloc((void**)&d_input, input_size_bytes); \n  cudaMemcpy(d_input, h_input, input_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_weights, weights_size_bytes); \n  cudaMemcpy(d_weights, h_weights, weights_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_target, target_size_bytes); \n  cudaMemcpy(d_target, h_target, target_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaMalloc((void**)&d_total_weight, output_size_bytes); \n  cudaMalloc((void**)&d_output, output_size_bytes); \n\n  dim3 grid (1);\n  dim3 block (GPU_THREADS);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    nll_loss_forward_reduce2d_kernel\n      <scalar_t, scalar_t, index_t, GPU_THREADS>\n      <<<grid, block>>>(d_output,\n                        d_total_weight,\n                        d_input,\n                        d_target,\n                        d_weights,\n                        size_average,\n                        nframe,\n                        kdim,\n                        ignore_index);\n  }\n  cudaDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n  printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  cudaMemcpy(&h_output, d_output, output_size_bytes, cudaMemcpyDeviceToHost);\n  cudaMemcpy(&h_total_weight, d_total_weight, output_size_bytes, cudaMemcpyDeviceToHost);\n\n  bool ok = true;\n  if (fabs(h_output - r_output) > 1e-1 ||\n      fabs(h_total_weight - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output, (float)r_output, \n                            (float)h_total_weight, (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_output);\n  cudaFree(d_total_weight);\n  cudaFree(d_input);\n  cudaFree(d_target);\n  cudaFree(d_weights);\n}\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n  \n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}\n"}}
{"kernel_name": "nlll", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t, \n          typename index_t, int NLL_LOSS_THREADS>\n__global__\nvoid nll_loss_forward_reduce2d_kernel(\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n  __shared__ accscalar_t sm_inputs[NLL_LOSS_THREADS],\n                         acc_weight[NLL_LOSS_THREADS];\n\n  int tid = threadIdx.x;\n  sm_inputs[tid] = static_cast<accscalar_t>(0);\n  acc_weight[tid] = static_cast<accscalar_t>(0);\n\n  for (int i = tid; i < nframe; i += NLL_LOSS_THREADS) {\n    index_t t = target[i];\n    if (t != ignore_index) {\n      scalar_t cur_weight =\n          weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n      sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n      acc_weight[tid] += cur_weight;\n    }\n  }\n\n  __syncthreads();\n\n  if (tid == 0) {\n    accscalar_t output_acc = 0;\n    accscalar_t total_weight_acc = 0;\n    for (int i = 0; i < NLL_LOSS_THREADS; ++i) {\n      output_acc += sm_inputs[i];\n      total_weight_acc += acc_weight[i];\n    }\n    *total_weight = static_cast<scalar_t>(total_weight_acc);\n    if (size_average) {\n      *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n    } else {\n      *output = static_cast<scalar_t>(output_acc);\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  int64_t weights_size = nframe;\n  int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  int64_t target_size = nframe;\n  int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  int output_size_bytes = sizeof(scalar_t);\n\n  scalar_t h_output;\n  scalar_t h_total_weight;\n\n  scalar_t *d_output;\n  scalar_t *d_total_weight;\n  scalar_t *d_input;\n   index_t *d_target;\n  scalar_t *d_weights;\n\n  hipMalloc((void**)&d_input, input_size_bytes); \n  hipMemcpy(d_input, h_input, input_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_weights, weights_size_bytes); \n  hipMemcpy(d_weights, h_weights, weights_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_target, target_size_bytes); \n  hipMemcpy(d_target, h_target, target_size_bytes, hipMemcpyHostToDevice);\n\n  hipMalloc((void**)&d_total_weight, output_size_bytes); \n  hipMalloc((void**)&d_output, output_size_bytes); \n\n  dim3 grid (1);\n  dim3 block (GPU_THREADS);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    nll_loss_forward_reduce2d_kernel\n      <scalar_t, scalar_t, index_t, GPU_THREADS>\n      <<<grid, block>>>(d_output,\n                        d_total_weight,\n                        d_input,\n                        d_target,\n                        d_weights,\n                        size_average,\n                        nframe,\n                        kdim,\n                        ignore_index);\n  }\n  hipDeviceSynchronize();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n  printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  hipMemcpy(&h_output, d_output, output_size_bytes, hipMemcpyDeviceToHost);\n  hipMemcpy(&h_total_weight, d_total_weight, output_size_bytes, hipMemcpyDeviceToHost);\n\n  bool ok = true;\n  if (fabs(h_output - r_output) > 1e-1 ||\n      fabs(h_total_weight - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output, (float)r_output, \n                            (float)h_total_weight, (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_output);\n  hipFree(d_total_weight);\n  hipFree(d_input);\n  hipFree(d_target);\n  hipFree(d_weights);\n}\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n  \n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}\n"}}
{"kernel_name": "nlll", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t, \n          typename index_t, int NLL_LOSS_THREADS>\nvoid nll_loss_forward_reduce2d_kernel(\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n  #pragma omp target teams num_teams(1) thread_limit(NLL_LOSS_THREADS)\n  {\n    accscalar_t sm_inputs[NLL_LOSS_THREADS],\n                acc_weight[NLL_LOSS_THREADS];\n    #pragma omp parallel\n    {\n      int tid = omp_get_thread_num();\n      int nthreads = omp_get_num_threads();\n\n      sm_inputs[tid] = static_cast<accscalar_t>(0);\n      acc_weight[tid] = static_cast<accscalar_t>(0);\n\n      \n\n      for (int i = tid; i < nframe; i += nthreads) {\n        index_t t = target[i];\n        if (t != ignore_index) {\n          scalar_t cur_weight =\n              weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n          sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n          acc_weight[tid] += cur_weight;\n        }\n      }\n\n      #pragma omp barrier\n\n      if (tid == 0) {\n        accscalar_t output_acc = 0;\n        accscalar_t total_weight_acc = 0;\n        \n\n        for (int i = 0; i < nthreads; ++i) {\n          output_acc += sm_inputs[i];\n          total_weight_acc += acc_weight[i];\n        }\n        *total_weight = static_cast<scalar_t>(total_weight_acc);\n        if (size_average) {\n          *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n        } else {\n          *output = static_cast<scalar_t>(output_acc);\n        }\n      }\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t weights_size = nframe;\n  int64_t target_size = nframe;\n\n  scalar_t h_output[1];\n  scalar_t h_total_weight[1];\n\n  #pragma omp target data map(to: h_input[0:input_size], \\\n                                  h_weights[0:weights_size], \\\n                                  h_target[0:target_size]) \\\n                          map(from: h_output[0:1], h_total_weight[0:1])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      nll_loss_forward_reduce2d_kernel\n        <scalar_t, scalar_t, index_t, GPU_THREADS>(\n        h_output,\n        h_total_weight,\n        h_input,\n        h_target,\n        h_weights,\n        size_average,\n        nframe,\n        kdim,\n        ignore_index);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n    printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n\n  }\n\n  bool ok = true;\n  if (fabs(h_output[0] - r_output) > 1e-1 ||\n      fabs(h_total_weight[0] - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output[0], (float)r_output, \n                            (float)h_total_weight[0], (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n  \n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}\n"}}
{"kernel_name": "nlll", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t, \n          typename index_t, int NLL_LOSS_THREADS>\nvoid nll_loss_forward_reduce2d_kernel(\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n    {\n    accscalar_t sm_inputs[NLL_LOSS_THREADS],\n                acc_weight[NLL_LOSS_THREADS];\n        {\n      int tid = omp_get_thread_num();\n      int nthreads = omp_get_num_threads();\n\n      sm_inputs[tid] = static_cast<accscalar_t>(0);\n      acc_weight[tid] = static_cast<accscalar_t>(0);\n\n      \n\n      for (int i = tid; i < nframe; i += nthreads) {\n        index_t t = target[i];\n        if (t != ignore_index) {\n          scalar_t cur_weight =\n              weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n          sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n          acc_weight[tid] += cur_weight;\n        }\n      }\n\n      \n      if (tid == 0) {\n        accscalar_t output_acc = 0;\n        accscalar_t total_weight_acc = 0;\n        \n\n        for (int i = 0; i < nthreads; ++i) {\n          output_acc += sm_inputs[i];\n          total_weight_acc += acc_weight[i];\n        }\n        *total_weight = static_cast<scalar_t>(total_weight_acc);\n        if (size_average) {\n          *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n        } else {\n          *output = static_cast<scalar_t>(output_acc);\n        }\n      }\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t weights_size = nframe;\n  int64_t target_size = nframe;\n\n  scalar_t h_output[1];\n  scalar_t h_total_weight[1];\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      nll_loss_forward_reduce2d_kernel\n        <scalar_t, scalar_t, index_t, GPU_THREADS>(\n        h_output,\n        h_total_weight,\n        h_input,\n        h_target,\n        h_weights,\n        size_average,\n        nframe,\n        kdim,\n        ignore_index);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n    printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n\n  }\n\n  bool ok = true;\n  if (fabs(h_output[0] - r_output) > 1e-1 ||\n      fabs(h_total_weight[0] - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output[0], (float)r_output, \n                            (float)h_total_weight[0], (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n  \n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}"}}
{"kernel_name": "nlll", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\ntemplate <typename scalar_t, typename accscalar_t,\n          typename index_t, int NLL_LOSS_THREADS>\nvoid nll_loss_forward_reduce2d_kernel(\n    sycl::nd_item<1> &item,\n    scalar_t* __restrict__ output,\n    scalar_t* __restrict__ total_weight,\n    const scalar_t* __restrict__ input,\n    const index_t*  __restrict__ target,\n    const scalar_t* __restrict__ weights,\n    bool size_average,\n    int64_t nframe,\n    int64_t kdim,\n    int64_t ignore_index)\n{\n   auto g = item.get_group();\n\n   sycl::multi_ptr<accscalar_t[NLL_LOSS_THREADS], sycl::access::address_space::local_space>\n     ip = sycl::ext::oneapi::group_local_memory_for_overwrite<accscalar_t[NLL_LOSS_THREADS]>(g);\n   accscalar_t* sm_inputs = *ip;\n\n   sycl::multi_ptr<accscalar_t[NLL_LOSS_THREADS], sycl::access::address_space::local_space>\n     wp = sycl::ext::oneapi::group_local_memory_for_overwrite<accscalar_t[NLL_LOSS_THREADS]>(g);\n   accscalar_t* acc_weight = *wp;\n\n  int tid = item.get_local_id(0);\n  sm_inputs[tid] = static_cast<accscalar_t>(0);\n  acc_weight[tid] = static_cast<accscalar_t>(0);\n\n  for (int i = tid; i < nframe; i += NLL_LOSS_THREADS) {\n    index_t t = target[i];\n    if (t != ignore_index) {\n      scalar_t cur_weight =\n          weights != nullptr ? weights[t] : static_cast<scalar_t>(1);\n      sm_inputs[tid] -= input[i * kdim + t] * cur_weight;\n      acc_weight[tid] += cur_weight;\n    }\n  }\n\n  group_barrier(g, sycl::memory_scope::work_group);\n\n  if (tid == 0) {\n    accscalar_t output_acc = 0;\n    accscalar_t total_weight_acc = 0;\n    for (int i = 0; i < NLL_LOSS_THREADS; ++i) {\n      output_acc += sm_inputs[i];\n      total_weight_acc += acc_weight[i];\n    }\n    *total_weight = static_cast<scalar_t>(total_weight_acc);\n    if (size_average) {\n      *output = static_cast<scalar_t>(output_acc / total_weight_acc);\n    } else {\n      *output = static_cast<scalar_t>(output_acc);\n    }\n  }\n}\n\ntemplate <typename scalar_t, typename index_t, int GPU_THREADS>\nvoid eval(const int64_t nframe,\n          const int64_t kdim,\n          const int64_t n_classes,\n          const bool size_average,\n          const int64_t ignore_index,\n          const scalar_t r_output,\n          const scalar_t r_total_weight,\n          scalar_t *h_input,\n          scalar_t *h_weights,\n           index_t *h_target,\n          const int repeat)\n{\n  int64_t input_size = nframe * kdim * n_classes;\n  int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  int64_t weights_size = nframe;\n  int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  int64_t target_size = nframe;\n  int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  int output_size_bytes = sizeof(scalar_t);\n\n  scalar_t h_output;\n  scalar_t h_total_weight;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  scalar_t *d_output = sycl::malloc_device<scalar_t>(1, q);\n  scalar_t *d_total_weight = sycl::malloc_device<scalar_t>(1, q);\n  scalar_t *d_input = sycl::malloc_device<scalar_t>(input_size, q);\n   index_t *d_target = sycl::malloc_device<index_t>(target_size, q);\n  scalar_t *d_weights = sycl::malloc_device<scalar_t>(weights_size, q);\n\n  q.memcpy(d_input, h_input, input_size_bytes);\n\n  q.memcpy(d_weights, h_weights, weights_size_bytes);\n\n  q.memcpy(d_target, h_target, target_size_bytes);\n\n  sycl::range<1> gws (GPU_THREADS);\n  sycl::range<1> lws (GPU_THREADS);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        nll_loss_forward_reduce2d_kernel\n          <scalar_t, scalar_t, index_t, GPU_THREADS>(\n                        item,\n                        d_output,\n                        d_total_weight,\n                        d_input,\n                        d_target,\n                        d_weights,\n                        size_average,\n                        nframe,\n                        kdim,\n                        ignore_index);\n      });\n    });\n  }\n  q.wait();\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"\\nThread block size: %d\\n\", GPU_THREADS);\n  printf(\"Average execution time of nll loss forward reduce 2D kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  q.memcpy(&h_output, d_output, output_size_bytes);\n  q.memcpy(&h_total_weight, d_total_weight, output_size_bytes);\n  q.wait();\n\n  bool ok = true;\n  if (fabs(h_output - r_output) > 1e-1 || fabs(h_total_weight - r_total_weight) > 1e-1) {\n    printf(\"%f %f %f %f\\n\", (float)h_output, (float)r_output,\n                            (float)h_total_weight, (float)r_total_weight);\n    ok = false;\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_output, q);\n  sycl::free(d_total_weight, q);\n  sycl::free(d_input, q);\n  sycl::free(d_target, q);\n  sycl::free(d_weights, q);\n}\n\n\ntemplate <typename scalar_t, typename index_t>\nvoid driver(char** argv) {\n  const int64_t nframe = atol(argv[1]);\n  const int64_t kdim = atol(argv[2]);\n  const int64_t n_classes = atol(argv[3]);\n  const int repeat = atoi(argv[4]);\n\n  const int64_t input_size = nframe * kdim * n_classes;\n  const int64_t input_size_bytes = input_size * sizeof(scalar_t);\n\n  const int64_t weights_size = nframe;\n  const int64_t weights_size_bytes = weights_size * sizeof(scalar_t);\n\n  const int64_t target_size = nframe;\n  const int64_t target_size_bytes = target_size * sizeof(index_t);\n\n  scalar_t *h_input = (scalar_t*) malloc (input_size_bytes);\n  scalar_t *h_weights = (scalar_t*) malloc (weights_size_bytes);\n  index_t *h_target = (index_t*) malloc (target_size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<scalar_t> d1 (-1.f, 1.f);\n  std::uniform_int_distribution<index_t> d2 (0, n_classes-1);\n\n  printf(\"Initialization of input data may take a while..\\n\");\n  for (int64_t i = 0; i < input_size; i++)\n    h_input[i] = d1(g);\n\n  for (int64_t i = 0; i < weights_size; i++)\n    h_weights[i] = d1(g);\n\n  for (int64_t i = 0; i < target_size; i++)\n    h_target[i] = d2(g);\n\n  const bool size_average = true;\n\n  \n\n  const int64_t ignore_index = n_classes / 2;\n\n  \n\n  scalar_t r_output;\n  scalar_t r_total_weight;\n\n  reference<scalar_t, scalar_t, index_t>(\n    &r_output, &r_total_weight,\n    h_input, h_target, h_weights,\n    size_average, nframe, kdim, ignore_index);\n\n  #define EVAL(nThreads) \\\n  eval<scalar_t, index_t, nThreads>(nframe, kdim, n_classes, \\\n                                    size_average, ignore_index, \\\n                                    r_output, r_total_weight, \\\n                                    h_input, h_weights, h_target, repeat)\n  EVAL(64);\n  EVAL(128);\n  EVAL(256);\n  EVAL(512);\n  EVAL(1024);\n\n  free(h_input);\n  free(h_target);\n  free(h_weights);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 5) {\n    printf(\"Usage: %s <minibatch> <kdim> <classes> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  printf(\"=========== Data type is FP32 ==========\\n\");\n  driver<float, int>(argv);\n\n  return 0;\n}\n"}}
{"kernel_name": "nosync", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <future>\n#include <iostream>\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h> \n\n#include <thrust/sequence.h>\n#include <thrust/reduce.h>\n#include <cuda_runtime.h>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  std::cout << \"Thrust version: \" << THRUST_VERSION << \"\\n\";\n\n  \n\n  cudaStream_t s;\n  cudaError_t err = cudaStreamCreate(&s);\n  if (err != cudaSuccess)\n  {\n    std::cerr << \"Error creating stream: \" << cudaGetErrorString(err) << \"\\n\";\n    return 1;\n  }\n\n  int sum = -1;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for(int i = 0; i < repeat; i++)\n  {\n    thrust::device_vector<int> d_vec(n);\n    thrust::device_vector<int> d_res(n);\n\n    \n\n    \n\n    \n\n#if THRUST_VERSION < 101700\n    auto nosync_exec_policy = thrust::cuda::par.on(s);\n#else\n    auto nosync_exec_policy = thrust::cuda::par_nosync.on(s);\n#endif\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    thrust::sequence(nosync_exec_policy, d_vec.begin(), d_vec.end());\n\n    \n\n    auto sync_exec_policy = thrust::cuda::par.on(s);\n\n    auto begin = d_vec.begin();\n    auto end = d_vec.end();\n    auto binary_op = thrust::plus<int>();\n    \n\n    \n\n    std::future<int> future_result = std::async(std::launch::async, [=]\n    {\n      return thrust::reduce(begin, end, 0, binary_op);\n    });\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    thrust::inclusive_scan(sync_exec_policy,\n                           d_vec.cbegin(),\n                           d_vec.cend(),\n                           d_res.begin());\n\n    \n\n    sum = future_result.get() - \n           \n\n          d_res.back();\n\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time: \" << (time * 1e-3f) / repeat << \" (us)\\n\";\n\n  \n\n  err = cudaStreamDestroy(s);\n  if (err != cudaSuccess)\n  {\n    std::cerr << \"Error destroying stream: \" << cudaGetErrorString(err) << \"\\n\";\n    return 1;\n  }\n\n  \n\n  std::cout << ((sum == 0) ? \"PASS\" : \"FAIL\") << \"\\n\";\n\n  return 0;\n}\n"}}
{"kernel_name": "nosync", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <future>\n#include <iostream>\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h> \n\n#include <thrust/sequence.h>\n#include <thrust/reduce.h>\n#include <hip/hip_runtime.h>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  std::cout << \"Thrust version: \" << THRUST_VERSION << \"\\n\";\n\n  \n\n  hipStream_t s;\n  hipError_t err = hipStreamCreate(&s);\n  if (err != hipSuccess)\n  {\n    std::cerr << \"Error creating stream: \" << hipGetErrorString(err) << \"\\n\";\n    return 1;\n  }\n\n  int sum = -1;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for(int i = 0; i < repeat; i++)\n  {\n    thrust::device_vector<int> d_vec(n);\n    thrust::device_vector<int> d_res(n);\n\n    \n\n    auto nosync_exec_policy = thrust::hip::par_nosync.on(s);\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    thrust::sequence(nosync_exec_policy, d_vec.begin(), d_vec.end());\n\n    \n\n    auto sync_exec_policy = thrust::hip::par.on(s);\n\n    auto begin = d_vec.begin();\n    auto end = d_vec.end();\n    auto binary_op = thrust::plus<int>();\n    \n\n    \n\n    std::future<int> future_result = std::async(std::launch::async, [=]\n    {\n      return thrust::reduce(begin, end, 0, binary_op);\n    });\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    thrust::inclusive_scan(sync_exec_policy,\n                           d_vec.cbegin(),\n                           d_vec.cend(),\n                           d_res.begin());\n\n    \n\n    sum = future_result.get() - \n           \n\n          d_res.back();\n\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time: \" << (time * 1e-3f) / repeat << \" (us)\\n\";\n\n  \n\n  err = hipStreamDestroy(s);\n  if (err != hipSuccess)\n  {\n    std::cerr << \"Error destroying stream: \" << hipGetErrorString(err) << \"\\n\";\n    return 1;\n  }\n\n  \n\n  std::cout << ((sum == 0) ? \"PASS\" : \"FAIL\") << \"\\n\";\n\n  return 0;\n}\n"}}
{"kernel_name": "nosync", "parallel_api": "sycl", "code": {"main.cpp": "#include <oneapi/dpl/numeric>\n#include <oneapi/dpl/execution>\n#include <oneapi/dpl/algorithm>  \n\n#include <oneapi/dpl/iterator>   \n\n#ifdef ASYNC_API\n#include <oneapi/dpl/async>\n#endif\n#include <sycl/sycl.hpp>\n#include <chrono>\n#include <iostream>\n\nint main(int argc, char *argv[]) try {\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  std::cout << \"oneDPL version: \"\n            << ONEDPL_VERSION_MAJOR << \".\"\n            << ONEDPL_VERSION_MINOR << \".\"\n            << ONEDPL_VERSION_PATCH << \"\\n\";\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int sum = -1;\n\n  auto policy = oneapi::dpl::execution::make_device_policy(q);\n\n  auto start = std::chrono::steady_clock::now();\n\n  for(int i = 0; i < repeat; i++)\n  {\n    sycl::buffer<int, 1> d_vec(n);\n    sycl::buffer<int, 1> d_res(n);\n\n    auto res_begin = oneapi::dpl::begin(d_res, sycl::write_only, sycl::no_init);\n    auto vals_begin = oneapi::dpl::begin(d_vec, sycl::write_only, sycl::no_init);\n    auto scan_begin = oneapi::dpl::begin(d_vec, sycl::read_only);\n    auto scan_end = oneapi::dpl::end(d_vec, sycl::read_only);\n    auto counting_begin = oneapi::dpl::counting_iterator<int>{0};\n\n    #ifdef ASYNC_API\n    \n\n    auto c = oneapi::dpl::experimental::copy_async(\n             policy, counting_begin, counting_begin + n, vals_begin);\n\n    auto r = oneapi::dpl::experimental::reduce_async(\n             policy, scan_begin, scan_end, c);\n\n    \n\n    auto s = oneapi::dpl::experimental::inclusive_scan_async(policy, scan_begin, scan_end, res_begin, c);\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.depends_on(s);\n      auto acc = d_res.get_access<sycl::access::mode::read>(cgh, sycl::range<1>(1), sycl::id<1>(n-1));\n      cgh.copy(acc, &sum);\n    }).wait();\n\n    sum = r.get() - sum; \n\n    #else\n\n    std::copy(policy, counting_begin, counting_begin + n, vals_begin);\n    oneapi::dpl::inclusive_scan(policy, scan_begin, scan_end, res_begin);\n    auto s = oneapi::dpl::reduce(policy, scan_begin, scan_end);\n    q.submit([&] (sycl::handler &cgh) {\n      auto acc = d_res.get_access<sycl::access::mode::read>(cgh, sycl::range<1>(1), sycl::id<1>(n-1));\n      cgh.copy(acc, &sum);\n    }).wait();\n\n    sum = s - sum; \n\n    #endif\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time: \" << (time * 1e-3f) / repeat << \" (us)\\n\";\n\n  \n\n  std::cout << ((sum == 0) ? \"PASS\" : \"FAIL\") << \"\\n\";\n\n  return 0;\n}\ncatch (sycl::exception const &exc) {\n  std::cerr << exc.what() << \"Exception caught at file:\" << __FILE__\n            << \", line:\" << __LINE__ << std::endl;\n  std::exit(1);\n}\n"}}
{"kernel_name": "reverse", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n#include <cuda.h>\n\n__global__ void reverse (int *d, const int len)\n{\n  __shared__ int s[256];\n  int t = threadIdx.x;\n  s[t] = d[t];\n  __syncthreads();\n  d[t] = s[len-t-1];\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n  const int elem_size = len * sizeof(int);\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n  int *d_test;\n  cudaMalloc((void**)&d_test, elem_size);\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100, 9999);\n\n  long time = 0;\n\n  for (int i = 0; i < iteration; i++) {\n    const int count = distribution(generator);\n\n    cudaMemcpy(d_test, gold_even, elem_size, cudaMemcpyHostToDevice);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int j = 0; j < count; j++)\n      reverse<<<1, len>>> (d_test, len);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    cudaMemcpy(test, d_test, elem_size, cudaMemcpyDeviceToHost);\n\n    if (count % 2 == 0)\n      error = memcmp(test, gold_even, elem_size);\n    else\n      error = memcmp(test, gold_odd, elem_size);\n    \n    if (error) break;\n  }\n  \n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  cudaFree(d_test);\n  return 0;\n}\n"}}
{"kernel_name": "reverse", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n__global__ void reverse (int *d, const int len)\n{\n  __shared__ int s[256];\n  int t = threadIdx.x;\n  s[t] = d[t];\n  __syncthreads();\n  d[t] = s[len-t-1];\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n  const int elem_size = len * sizeof(int);\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n  int *d_test;\n  hipMalloc((void**)&d_test, elem_size);\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100, 9999);\n\n  long time = 0;\n\n  for (int i = 0; i < iteration; i++) {\n    const int count = distribution(generator);\n\n    hipMemcpy(d_test, gold_even, elem_size, hipMemcpyHostToDevice);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int j = 0; j < count; j++)\n      hipLaunchKernelGGL(reverse, 1, len, 0, 0, d_test, len);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    hipMemcpy(test, d_test, elem_size, hipMemcpyDeviceToHost);\n\n    if (count % 2 == 0)\n      error = memcmp(test, gold_even, elem_size);\n    else\n      error = memcmp(test, gold_odd, elem_size);\n    \n    if (error) break;\n  }\n  \n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  hipFree(d_test);\n  return 0;\n}\n"}}
{"kernel_name": "reverse", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n#include <omp.h>\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n  const int elem_size = len * sizeof(int);\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100, 9999);\n\n  long time = 0;\n\n  #pragma omp target data map(alloc: test[0:len]) \n  {\n    for (int i = 0; i < iteration; i++) {\n      const int count = distribution(generator);\n\n      memcpy(test, gold_even, elem_size);\n      #pragma omp target update to (test[0:len])\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (int j = 0; j < count; j++) {\n        #pragma omp target teams num_teams(1) thread_limit(len)\n        {\n          int s[len];\n          #pragma omp parallel \n          {\n            int t = omp_get_thread_num();\n            s[t] = test[t];\n            #pragma omp barrier\n            test[t] = s[len-t-1];\n          }\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n      #pragma omp target update from (test[0:len])\n\n      if (count % 2 == 0)\n        error = memcmp(test, gold_even, elem_size);\n      else\n        error = memcmp(test, gold_odd, elem_size);\n      \n      if (error) break;\n    }\n  }\n\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  return 0;\n}\n"}}
{"kernel_name": "reverse", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n  const int elem_size = len * sizeof(int);\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100, 9999);\n\n  long time = 0;\n\n    {\n    for (int i = 0; i < iteration; i++) {\n      const int count = distribution(generator);\n\n      memcpy(test, gold_even, elem_size);\n      \n      auto start = std::chrono::steady_clock::now();\n\n      for (int j = 0; j < count; j++) {\n                {\n          int s[len];\n                    {\n            int t = omp_get_thread_num();\n            s[t] = test[t];\n                        test[t] = s[len-t-1];\n          }\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n      \n      if (count % 2 == 0)\n        error = memcmp(test, gold_even, elem_size);\n      else\n        error = memcmp(test, gold_odd, elem_size);\n      \n      if (error) break;\n    }\n  }\n\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  return 0;\n}"}}
{"kernel_name": "reverse", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_test = sycl::malloc_device<int>(len, q);\n  sycl::range<1> gws (len);\n  sycl::range<1> lws (len);\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100,9999);\n\n  long time = 0;\n\n  for (int i = 0; i < iteration; i++) {\n    const int count = distribution(generator);\n\n    q.memcpy(d_test, gold_even, sizeof(int) * len);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int j = 0; j < count; j++) {\n      q.submit([&](sycl::handler &cgh) {\n        sycl::local_accessor <int, 1> s (lws, cgh);\n        cgh.parallel_for<class blockReverse>(\n          sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n          int t = item.get_local_id(0);\n          s[t] = d_test[t];\n          item.barrier(sycl::access::fence_space::local_space);\n          d_test[t] = s[len-t-1];\n        });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    q.memcpy(test, d_test, sizeof(int) * len).wait();\n\n    if (count % 2 == 0)\n      error = memcmp(test, gold_even, len*sizeof(int));\n    else\n      error = memcmp(test, gold_odd, len*sizeof(int));\n\n    if (error) break;\n  }\n\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(d_test, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "rodrigues", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n__global__ \nvoid rotate (const int n, const float angle, const float3 w, float3 *d)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= n) return;\n\n  float s, c;\n  sincosf(angle, &s,&c);\n  \n  const float3 p = d[i];\n  const float mc = 1.f - c;\n\n  \n\n  float m1 = c+(w.x)*(w.x)*(mc);\n  float m2 = (w.z)*s+(w.x)*(w.y)*(mc);\n  float m3 =-(w.y)*s+(w.x)*(w.z)*(mc);\n  \n  float m4 =-(w.z)*s+(w.x)*(w.y)*(mc);\n  float m5 = c+(w.y)*(w.y)*(mc);\n  float m6 = (w.x)*s+(w.y)*(w.z)*(mc);\n  \n  float m7 = (w.y)*s+(w.x)*(w.z)*(mc);\n  float m8 =-(w.x)*s+(w.y)*(w.z)*(mc);\n  float m9 = c+(w.z)*(w.z)*(mc);\n\n  float ox = p.x*m1 + p.y*m2 + p.z*m3;\n  float oy = p.x*m4 + p.y*m5 + p.z*m6;\n  float oz = p.x*m7 + p.y*m8 + p.z*m9;\n  d[i] = {ox, oy, oz};\n}\n\n__global__ \nvoid rotate2 (const int n, const float angle, const float3 w, float4 *d)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= n) return;\n\n  float s, c;\n  sincosf(angle, &s,&c);\n  \n  const float4 p = d[i];\n  const float mc = 1.f - c;\n\n  \n\n  float m1 = c+(w.x)*(w.x)*(mc);\n  float m2 = (w.z)*s+(w.x)*(w.y)*(mc);\n  float m3 =-(w.y)*s+(w.x)*(w.z)*(mc);\n  \n  float m4 =-(w.z)*s+(w.x)*(w.y)*(mc);\n  float m5 = c+(w.y)*(w.y)*(mc);\n  float m6 = (w.x)*s+(w.y)*(w.z)*(mc);\n  \n  float m7 = (w.y)*s+(w.x)*(w.z)*(mc);\n  float m8 =-(w.x)*s+(w.y)*(w.z)*(mc);\n  float m9 = c+(w.z)*(w.z)*(mc);\n\n  float ox = p.x*m1 + p.y*m2 + p.z*m3;\n  float oy = p.x*m4 + p.y*m5 + p.z*m6;\n  float oz = p.x*m7 + p.y*m8 + p.z*m9;\n  d[i] = {ox, oy, oz, 0.f};\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n    \n  \n\n  const float wx = -0.3, wy = -0.6, wz = 0.15;\n  const float norm = 1.f / sqrtf(wx*wx + wy*wy + wz*wz);\n  const float3 w = make_float3(wx*norm, wy*norm, wz*norm);\n\n  const float angle = 0.5f;\n\n  float3 *h = (float3*) malloc (sizeof(float3) * n);\n  float4 *h2 = (float4*) malloc (sizeof(float4) * n);\n\n  srand(123);\n  for (int i = 0; i < n; i++) {\n    float a = rand();\n    float b = rand();\n    float c = rand();\n    float d = sqrtf(a*a + b*b + c*c);\n    h[i] = make_float3(a/d, b/d, c/d);\n    h2[i] = make_float4(a/d, b/d, c/d, 0.f);\n  }\n\n  dim3 grids ((n + 255) / 256);\n  dim3 blocks (256);\n \n  float3 *d;\n  cudaMalloc((void**)&d, sizeof(float3) * n);\n  cudaMemcpy(d, h, sizeof(float3) * n, cudaMemcpyHostToDevice);\n\n  float4 *d2;\n  cudaMalloc((void**)&d2, sizeof(float4) * n);\n  cudaMemcpy(d2, h2, sizeof(float4) * n, cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    rotate <<<grids, blocks>>> (n, angle, w, d);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (float3): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    rotate2 <<<grids, blocks>>> (n, angle, w, d2);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (float4): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaFree(d);\n  cudaFree(d2);\n  free(h);\n  free(h2);\n  return 0;\n}\n"}}
{"kernel_name": "rodrigues", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n__global__ \nvoid rotate (const int n, const float angle, const float3 w, float3 *d)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= n) return;\n\n  float s, c;\n  sincosf(angle, &s,&c);\n  \n  const float3 p = d[i];\n  const float mc = 1.f - c;\n\n  \n\n  float m1 = c+(w.x)*(w.x)*(mc);\n  float m2 = (w.z)*s+(w.x)*(w.y)*(mc);\n  float m3 =-(w.y)*s+(w.x)*(w.z)*(mc);\n  \n  float m4 =-(w.z)*s+(w.x)*(w.y)*(mc);\n  float m5 = c+(w.y)*(w.y)*(mc);\n  float m6 = (w.x)*s+(w.y)*(w.z)*(mc);\n  \n  float m7 = (w.y)*s+(w.x)*(w.z)*(mc);\n  float m8 =-(w.x)*s+(w.y)*(w.z)*(mc);\n  float m9 = c+(w.z)*(w.z)*(mc);\n\n  float ox = p.x*m1 + p.y*m2 + p.z*m3;\n  float oy = p.x*m4 + p.y*m5 + p.z*m6;\n  float oz = p.x*m7 + p.y*m8 + p.z*m9;\n  d[i] = {ox, oy, oz};\n}\n\n__global__ \nvoid rotate2 (const int n, const float angle, const float3 w, float4 *d)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= n) return;\n\n  float s, c;\n  sincosf(angle, &s,&c);\n  \n  const float4 p = d[i];\n  const float mc = 1.f - c;\n\n  \n\n  float m1 = c+(w.x)*(w.x)*(mc);\n  float m2 = (w.z)*s+(w.x)*(w.y)*(mc);\n  float m3 =-(w.y)*s+(w.x)*(w.z)*(mc);\n  \n  float m4 =-(w.z)*s+(w.x)*(w.y)*(mc);\n  float m5 = c+(w.y)*(w.y)*(mc);\n  float m6 = (w.x)*s+(w.y)*(w.z)*(mc);\n  \n  float m7 = (w.y)*s+(w.x)*(w.z)*(mc);\n  float m8 =-(w.x)*s+(w.y)*(w.z)*(mc);\n  float m9 = c+(w.z)*(w.z)*(mc);\n\n  float ox = p.x*m1 + p.y*m2 + p.z*m3;\n  float oy = p.x*m4 + p.y*m5 + p.z*m6;\n  float oz = p.x*m7 + p.y*m8 + p.z*m9;\n  d[i] = {ox, oy, oz, 0.f};\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n    \n  \n\n  const float wx = -0.3, wy = -0.6, wz = 0.15;\n  const float norm = 1.f / sqrtf(wx*wx + wy*wy + wz*wz);\n  const float3 w = make_float3(wx*norm, wy*norm, wz*norm);\n\n  float angle = 0.5f;\n\n  float3 *h = (float3*) malloc (sizeof(float3) * n);\n  float4 *h2 = (float4*) malloc (sizeof(float4) * n);\n\n  srand(123);\n  for (int i = 0; i < n; i++) {\n    float a = rand();\n    float b = rand();\n    float c = rand();\n    float d = sqrtf(a*a + b*b + c*c);\n    h[i] = make_float3(a/d, b/d, c/d);\n    h2[i] = make_float4(a/d, b/d, c/d, 0.f);\n  }\n\n  dim3 grids ((n + 255) / 256);\n  dim3 blocks (256);\n \n  float3 *d;\n  hipMalloc((void**)&d, sizeof(float3) * n);\n  hipMemcpy(d, h, sizeof(float3) * n, hipMemcpyHostToDevice);\n\n  float4 *d2;\n  hipMalloc((void**)&d2, sizeof(float4) * n);\n  hipMemcpy(d2, h2, sizeof(float4) * n, hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(rotate, grids, blocks, 0, 0, n, angle, w, d);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (float3): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(rotate2, grids, blocks, 0, 0, n, angle, w, d2);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (float4): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipFree(d);\n  hipFree(d2);\n  free(h);\n  free(h2);\n  return 0;\n}\n"}}
{"kernel_name": "rodrigues", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <math.h>\n#include <omp.h>\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z;\n}\nfloat3;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z, w;\n}\nfloat4;\n\ninline \nvoid rotate (const int n, const float angle, const float3 w, float3 *d)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < n; i++) {\n\n    float s, c;\n    sincosf(angle, &s,&c);\n    \n    const float3 p = d[i];\n    const float mc = 1.f - c;\n\n    \n\n    float m1 = c+(w.x)*(w.x)*(mc);\n    float m2 = (w.z)*s+(w.x)*(w.y)*(mc);\n    float m3 =-(w.y)*s+(w.x)*(w.z)*(mc);\n    \n    float m4 =-(w.z)*s+(w.x)*(w.y)*(mc);\n    float m5 = c+(w.y)*(w.y)*(mc);\n    float m6 = (w.x)*s+(w.y)*(w.z)*(mc);\n    \n    float m7 = (w.y)*s+(w.x)*(w.z)*(mc);\n    float m8 =-(w.x)*s+(w.y)*(w.z)*(mc);\n    float m9 = c+(w.z)*(w.z)*(mc);\n\n    float ox = p.x*m1 + p.y*m2 + p.z*m3;\n    float oy = p.x*m4 + p.y*m5 + p.z*m6;\n    float oz = p.x*m7 + p.y*m8 + p.z*m9;\n    d[i] = {ox, oy, oz};\n  }\n}\n\ninline \nvoid rotate2 (const int n, const float angle, const float3 w, float4 *d)\n{\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < n; i++) {\n    float s, c;\n    sincosf(angle, &s,&c);\n    \n    const float4 p = d[i];\n    const float mc = 1.f - c;\n\n    \n\n    float m1 = c+(w.x)*(w.x)*(mc);\n    float m2 = (w.z)*s+(w.x)*(w.y)*(mc);\n    float m3 =-(w.y)*s+(w.x)*(w.z)*(mc);\n    \n    float m4 =-(w.z)*s+(w.x)*(w.y)*(mc);\n    float m5 = c+(w.y)*(w.y)*(mc);\n    float m6 = (w.x)*s+(w.y)*(w.z)*(mc);\n    \n    float m7 = (w.y)*s+(w.x)*(w.z)*(mc);\n    float m8 =-(w.x)*s+(w.y)*(w.z)*(mc);\n    float m9 = c+(w.z)*(w.z)*(mc);\n\n    float ox = p.x*m1 + p.y*m2 + p.z*m3;\n    float oy = p.x*m4 + p.y*m5 + p.z*m6;\n    float oz = p.x*m7 + p.y*m8 + p.z*m9;\n    d[i] = {ox, oy, oz, 0.f};\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n    \n  \n\n  const float wx = -0.3, wy = -0.6, wz = 0.15;\n  const float norm = 1.f / sqrtf(wx*wx + wy*wy + wz*wz);\n  const float3 w = {wx*norm, wy*norm, wz*norm};\n\n  float angle = 0.5f;\n\n  float3 *h = (float3*) malloc (sizeof(float3) * n);\n  float4 *h2 = (float4*) malloc (sizeof(float4) * n);\n\n  srand(123);\n  for (int i = 0; i < n; i++) {\n    float a = rand();\n    float b = rand();\n    float c = rand();\n    float d = sqrtf(a*a + b*b + c*c);\n    h[i] = {a/d, b/d, c/d};\n    h2[i] = {a/d, b/d, c/d, 0.f};\n  }\n\n  #pragma omp target data map(to: h[0:n], h2[0:n])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      rotate(n, angle, w, h);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (float3): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      rotate2(n, angle, w, h2);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (float4): %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n\n  free(h);\n  free(h2);\n  return 0;\n}\n"}}
{"kernel_name": "rodrigues", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <math.h>\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z;\n}\nfloat3;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  float x, y, z, w;\n}\nfloat4;\n\ninline \nvoid rotate (const int n, const float angle, const float3 w, float3 *d)\n{\n    for (int i = 0; i < n; i++) {\n\n    float s, c;\n    sincosf(angle, &s,&c);\n    \n    const float3 p = d[i];\n    const float mc = 1.f - c;\n\n    \n\n    float m1 = c+(w.x)*(w.x)*(mc);\n    float m2 = (w.z)*s+(w.x)*(w.y)*(mc);\n    float m3 =-(w.y)*s+(w.x)*(w.z)*(mc);\n    \n    float m4 =-(w.z)*s+(w.x)*(w.y)*(mc);\n    float m5 = c+(w.y)*(w.y)*(mc);\n    float m6 = (w.x)*s+(w.y)*(w.z)*(mc);\n    \n    float m7 = (w.y)*s+(w.x)*(w.z)*(mc);\n    float m8 =-(w.x)*s+(w.y)*(w.z)*(mc);\n    float m9 = c+(w.z)*(w.z)*(mc);\n\n    float ox = p.x*m1 + p.y*m2 + p.z*m3;\n    float oy = p.x*m4 + p.y*m5 + p.z*m6;\n    float oz = p.x*m7 + p.y*m8 + p.z*m9;\n    d[i] = {ox, oy, oz};\n  }\n}\n\ninline \nvoid rotate2 (const int n, const float angle, const float3 w, float4 *d)\n{\n    for (int i = 0; i < n; i++) {\n    float s, c;\n    sincosf(angle, &s,&c);\n    \n    const float4 p = d[i];\n    const float mc = 1.f - c;\n\n    \n\n    float m1 = c+(w.x)*(w.x)*(mc);\n    float m2 = (w.z)*s+(w.x)*(w.y)*(mc);\n    float m3 =-(w.y)*s+(w.x)*(w.z)*(mc);\n    \n    float m4 =-(w.z)*s+(w.x)*(w.y)*(mc);\n    float m5 = c+(w.y)*(w.y)*(mc);\n    float m6 = (w.x)*s+(w.y)*(w.z)*(mc);\n    \n    float m7 = (w.y)*s+(w.x)*(w.z)*(mc);\n    float m8 =-(w.x)*s+(w.y)*(w.z)*(mc);\n    float m9 = c+(w.z)*(w.z)*(mc);\n\n    float ox = p.x*m1 + p.y*m2 + p.z*m3;\n    float oy = p.x*m4 + p.y*m5 + p.z*m6;\n    float oz = p.x*m7 + p.y*m8 + p.z*m9;\n    d[i] = {ox, oy, oz, 0.f};\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n    \n  \n\n  const float wx = -0.3, wy = -0.6, wz = 0.15;\n  const float norm = 1.f / sqrtf(wx*wx + wy*wy + wz*wz);\n  const float3 w = {wx*norm, wy*norm, wz*norm};\n\n  float angle = 0.5f;\n\n  float3 *h = (float3*) malloc (sizeof(float3) * n);\n  float4 *h2 = (float4*) malloc (sizeof(float4) * n);\n\n  srand(123);\n  for (int i = 0; i < n; i++) {\n    float a = rand();\n    float b = rand();\n    float c = rand();\n    float d = sqrtf(a*a + b*b + c*c);\n    h[i] = {a/d, b/d, c/d};\n    h2[i] = {a/d, b/d, c/d, 0.f};\n  }\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      rotate(n, angle, w, h);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (float3): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      rotate2(n, angle, w, h2);\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time (float4): %f (us)\\n\", (time * 1e-3f) / repeat);\n  }\n\n  free(h);\n  free(h2);\n  return 0;\n}"}}
{"kernel_name": "rodrigues", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nusing float3 = sycl::float3;\nusing float4 = sycl::float4;\n\nvoid rotate (sycl::nd_item<1> &item, const int n, const float angle, const float3 w,\n             float3 *d)\n{\n  int i = item.get_global_id(0);\n  if (i >= n) return;\n\n  float s, c;\n  s = sycl::sincos(angle, &c);\n\n  const float3 p = d[i];\n  const float mc = 1.f - c;\n\n  \n\n  float m1 = c+(w.x())*(w.x())*(mc);\n  float m2 = (w.z())*s+(w.x())*(w.y())*(mc);\n  float m3 =-(w.y())*s+(w.x())*(w.z())*(mc);\n\n  float m4 =-(w.z())*s+(w.x())*(w.y())*(mc);\n  float m5 = c+(w.y())*(w.y())*(mc);\n  float m6 = (w.x())*s+(w.y())*(w.z())*(mc);\n\n  float m7 = (w.y())*s+(w.x())*(w.z())*(mc);\n  float m8 =-(w.x())*s+(w.y())*(w.z())*(mc);\n  float m9 = c+(w.z())*(w.z())*(mc);\n\n  float ox = p.x()*m1 + p.y()*m2 + p.z()*m3;\n  float oy = p.x()*m4 + p.y()*m5 + p.z()*m6;\n  float oz = p.x()*m7 + p.y()*m8 + p.z()*m9;\n  d[i] = {ox, oy, oz};\n}\n\nvoid rotate2 (sycl::nd_item<1> &item, const int n, const float angle, const float3 w,\n              float4 *d)\n{\n  int i = item.get_global_id(0);\n  if (i >= n) return;\n\n  float s, c;\n  s = sycl::sincos(angle, &c);\n\n  const float4 p = d[i];\n  const float mc = 1.f - c;\n\n  \n\n  float m1 = c+(w.x())*(w.x())*(mc);\n  float m2 = (w.z())*s+(w.x())*(w.y())*(mc);\n  float m3 =-(w.y())*s+(w.x())*(w.z())*(mc);\n\n  float m4 =-(w.z())*s+(w.x())*(w.y())*(mc);\n  float m5 = c+(w.y())*(w.y())*(mc);\n  float m6 = (w.x())*s+(w.y())*(w.z())*(mc);\n\n  float m7 = (w.y())*s+(w.x())*(w.z())*(mc);\n  float m8 =-(w.x())*s+(w.y())*(w.z())*(mc);\n  float m9 = c+(w.z())*(w.z())*(mc);\n\n  float ox = p.x()*m1 + p.y()*m2 + p.z()*m3;\n  float oy = p.x()*m4 + p.y()*m5 + p.z()*m6;\n  float oz = p.x()*m7 + p.y()*m8 + p.z()*m9;\n  d[i] = {ox, oy, oz, 0.f};\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of points> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int n = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  \n\n  const float wx = -0.3, wy = -0.6, wz = 0.15;\n  const float norm = 1.f / sqrtf(wx*wx + wy*wy + wz*wz);\n  const float3 w = {wx*norm, wy*norm, wz*norm};\n\n  float angle = 0.5f;\n\n  float3 *h = (float3*) malloc (sizeof(float3) * n);\n  float4 *h2 = (float4*) malloc (sizeof(float4) * n);\n\n  srand(123);\n  for (int i = 0; i < n; i++) {\n    float a = rand();\n    float b = rand();\n    float c = rand();\n    float d = sqrtf(a*a + b*b + c*c);\n    h[i] = {a/d, b/d, c/d};\n    h2[i] = {a/d, b/d, c/d, 0.f};\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  sycl::range<1> gws ((n + 255) / 256 * 256);\n  sycl::range<1> lws  (256);\n\n  float3 *d = sycl::malloc_device<float3>(n, q);\n  q.memcpy(d, h, sizeof(float3) * n);\n\n  float4 *d2 = sycl::malloc_device<float4>(n, q);\n  q.memcpy(d2, h2, sizeof(float4) * n);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class rr>(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        rotate(item, n, angle, w, d);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (float3): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class rr2>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        rotate2(item, n, angle, w, d2);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (float4): %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  sycl::free(d, q);\n  sycl::free(d2, q);\n  free(h);\n  free(h2);\n  return 0;\n}\n"}}
{"kernel_name": "rtm8", "parallel_api": "cuda", "code": {"mysecond.c": "\n\n\n#include <sys/time.h>\n\n\n\n#ifdef UNDERSCORE\ndouble mysecond_()\n#else\ndouble mysecond()\n#endif\n{\n  struct timeval tp;\n  struct timezone tzp;\n\n  gettimeofday(&tp,&tzp);\n  return ( (double) tp.tv_sec + (double) tp.tv_usec * 1.e-6 );\n}\n", "rtm8.cu": "#include <iostream>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <vector>\n#include <cuda.h>\n\n#define nx 680\n#define ny 134\n#define nz 450\n\n#include \"mysecond.c\"\n\ninline __host__ __device__ int indexTo1D(int x, int y, int z){\n  return x + y*nx + z*nx*ny;\n}\n\nvoid rtm8_cpu(float* vsq, float* current_s, float* current_r, float* next_s, float* next_r, float* image, float* a, size_t N)\n{\n#ifdef _OPENMP\n  #pragma omp parallel for collapse(3)\n#endif\n  for (int z = 4; z < nz - 4; z++) {\n    for (int y = 4; y < ny - 4; y++) {\n      for (int x = 4; x < nx - 4; x++) {\n        float div =\n          a[0] * current_s[indexTo1D(x,y,z)] +\n          a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n              current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n              current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n              current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n              current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n              current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n              current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n              current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n              current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n\n        next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n          + vsq[indexTo1D(x,y,z)]*div;\n        div =\n          a[0] * current_r[indexTo1D(x,y,z)] +\n          a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n              current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n              current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n              current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n              current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n              current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n              current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n              current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n              current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n\n        next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n          - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n\n        image[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n      }\n    }\n  }\n}\n  \n\n__global__\nvoid rtm8(\n  const float*__restrict__ vsq,\n  const float*__restrict__ current_s,\n  const float*__restrict__ current_r,\n        float*__restrict__ next_s,\n        float*__restrict__ next_r,\n        float*__restrict__ image,\n  const float*__restrict__ a,\n  size_t N)\n{\n  unsigned x = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned y = blockIdx.y * blockDim.y + threadIdx.y;\n  unsigned z = blockIdx.z * blockDim.z + threadIdx.z;\n  float div;\n  if ((4 <= x && x < (nx - 4) ) && (4 <= y && y < (ny - 4)) && (4 <= z && z < (nz - 4))){\n    div =\n      a[0] * current_s[indexTo1D(x,y,z)] +\n      a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n          current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n          current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n      a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n          current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n          current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n      a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n          current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n          current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n      a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n          current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n          current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n\n    next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n      + vsq[indexTo1D(x,y,z)]*div;\n    div =\n      a[0] * current_r[indexTo1D(x,y,z)] +\n      a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n          current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n          current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n      a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n          current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n          current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n      a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n          current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n          current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n      a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n          current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n          current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n\n    next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n      - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n\n    image[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n  }\n}\n\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int ArraySize = nx * ny * nz;\n  float* next_s = (float*)malloc(ArraySize * sizeof(float));\n  float* current_s = (float*)malloc(ArraySize * sizeof(float));\n  float* next_r = (float*)malloc(ArraySize * sizeof(float));\n  float* current_r = (float*)malloc(ArraySize * sizeof(float));\n  float* vsq = (float*)malloc(ArraySize * sizeof(float));\n  float* image_gpu = (float*)malloc(ArraySize * sizeof(float));\n  float* image_cpu = (float*)malloc(ArraySize * sizeof(float));\n\n  float a[5];\n  double pts, t0, t1, dt, flops, pt_rate, flop_rate, speedup, memory;\n\n  memory = ArraySize*sizeof(float)*6;\n  pts = (double)repeat*(nx-8)*(ny-8)*(nz-8);\n  flops = 67*pts;\n  printf(\"memory (MB) = %lf\\n\", memory/1e6);\n  printf(\"pts (billions) = %lf\\n\", pts/1e9);\n  printf(\"Tflops = %lf\\n\", flops/1e12);\n\n  \n\n  a[0] = -1./560.;\n  a[1] = 8./315;\n  a[2] = -0.2;\n  a[3] = 1.6;\n  a[4] = -1435./504.;\n\n  for (int z = 0; z < nz; z++) {\n    for (int y = 0; y < ny; y++) {\n      for (int x = 0; x < nx; x++) {\n        vsq[indexTo1D(x,y,z)] = 1.0;\n        next_s[indexTo1D(x,y,z)] = 0;\n        current_s[indexTo1D(x,y,z)] = 1.0;\n        next_r[indexTo1D(x,y,z)] = 0;\n        current_r[indexTo1D(x,y,z)] = 1.0;\n        image_gpu[indexTo1D(x,y,z)] = image_cpu[indexTo1D(x,y,z)] = 0.5;\n      }\n    }\n  }\n\n  \n\n  float* vsq_d;\n  float* next_s_d;\n  float* current_s_d;\n  float* next_r_d;\n  float* current_r_d;\n  float* image_d;\n  float* a_d;\n\n  cudaMalloc(&vsq_d, ArraySize * sizeof(float));\n  cudaMalloc(&next_s_d, ArraySize * sizeof(float));\n  cudaMalloc(&current_s_d, ArraySize * sizeof(float));\n  cudaMalloc(&next_r_d, ArraySize * sizeof(float));\n  cudaMalloc(&current_r_d, ArraySize * sizeof(float));\n  cudaMalloc(&image_d, ArraySize * sizeof(float));\n  cudaMalloc(&a_d, 5 * sizeof(float));\n\n  cudaMemcpy(vsq_d, vsq, ArraySize * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(next_s_d, next_s, ArraySize * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(current_s_d, current_s, ArraySize * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(next_r_d, next_r, ArraySize * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(current_r_d, current_r, ArraySize * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(image_d, image_gpu, ArraySize * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(a_d, a, 5 * sizeof(float), cudaMemcpyHostToDevice);\n\n  int groupSize = 16;\n  int nx_pad = (nx + groupSize - 1) / groupSize ;\n  int ny_pad = (ny + groupSize - 1) / groupSize ;\n  int nz_pad = nz;\n\n  dim3 grids (nx_pad, ny_pad, nz_pad);\n  dim3 blocks (groupSize, groupSize, 1);\n\n  cudaDeviceSynchronize();\n  t0 = mysecond();\n\n  \n\n  for (int t = 0; t < repeat; t++) {\n    rtm8 <<<grids, blocks>>> (vsq_d, current_s_d, next_s_d, current_r_d,\n                              next_r_d, image_d, a_d, ArraySize);\n  }\n\n  cudaDeviceSynchronize();\n  t1 = mysecond();\n  dt = t1 - t0;\n\n  \n\n  cudaMemcpy(image_gpu, image_d, ArraySize * sizeof(float), cudaMemcpyDeviceToHost);\n\n  \n\n  t0 = mysecond();\n  for (int t = 0; t < repeat; t++) {\n    rtm8_cpu(vsq, current_s, next_s, current_r, next_r, image_cpu, a, ArraySize);\n  }\n  t1 = mysecond();\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < ArraySize; i++) {\n    if (fabsf(image_cpu[i] - image_gpu[i]) > 0.1) {\n      printf(\"@index %d host: %f device %f\\n\", i, image_cpu[i], image_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  pt_rate = pts/dt;\n  flop_rate = flops/dt;\n  speedup = (t1 - t0) / dt;\n  printf(\"dt = %lf\\n\", dt);\n  printf(\"pt_rate (millions/sec) = %lf\\n\", pt_rate/1e6);\n  printf(\"flop_rate (Gflops) = %lf\\n\", flop_rate/1e9);\n  printf(\"speedup over cpu = %lf\\n\", speedup);\n  printf(\"average kernel execution time = %lf (s)\\n\", dt / repeat);\n\n  \n\n  free(vsq);\n  free(next_s);\n  free(current_s);\n  free(next_r);\n  free(current_r);\n  free(image_cpu);\n  free(image_gpu);\n  cudaFree(vsq_d);\n  cudaFree(next_s_d);\n  cudaFree(current_s_d);\n  cudaFree(next_r_d);\n  cudaFree(current_r_d);\n  cudaFree(image_d);\n  cudaFree(a_d);\n\n  return 0;\n}\n"}}
{"kernel_name": "rtm8", "parallel_api": "hip", "code": {"mysecond.c": "\n\n\n#include <sys/time.h>\n\n\n\n#ifdef UNDERSCORE\ndouble mysecond_()\n#else\ndouble mysecond()\n#endif\n{\n  struct timeval tp;\n  struct timezone tzp;\n\n  gettimeofday(&tp,&tzp);\n  return ( (double) tp.tv_sec + (double) tp.tv_usec * 1.e-6 );\n}\n\n", "rtm8.cu": "#include <iostream>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <vector>\n#include <hip/hip_runtime.h>\n\n#define nx 680\n#define ny 134\n#define nz 450\n\n#include \"mysecond.c\"\n\ninline __host__ __device__ int indexTo1D(int x, int y, int z){\n  return x + y*nx + z*nx*ny;\n}\n\nvoid rtm8_cpu(float* vsq, float* current_s, float* current_r, float* next_s, float* next_r, float* image, float* a, size_t N)\n{\n#ifdef _OPENMP\n  #pragma omp parallel for collapse(3)\n#endif\n  for (int z = 4; z < nz - 4; z++) {\n    for (int y = 4; y < ny - 4; y++) {\n      for (int x = 4; x < nx - 4; x++) {\n        float div =\n          a[0] * current_s[indexTo1D(x,y,z)] +\n          a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n              current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n              current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n              current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n              current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n              current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n              current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n              current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n              current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n\n        next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n          + vsq[indexTo1D(x,y,z)]*div;\n        div =\n          a[0] * current_r[indexTo1D(x,y,z)] +\n          a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n              current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n              current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n              current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n              current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n              current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n              current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n              current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n              current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n\n        next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n          - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n\n        image[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n      }\n    }\n  }\n}\n  \n\n__global__\nvoid rtm8(\n  const float*__restrict__ vsq,\n  const float*__restrict__ current_s,\n  const float*__restrict__ current_r,\n        float*__restrict__ next_s,\n        float*__restrict__ next_r,\n        float*__restrict__ image,\n  const float*__restrict__ a,\n  size_t N)\n{\n  unsigned x = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned y = blockIdx.y * blockDim.y + threadIdx.y;\n  unsigned z = blockIdx.z * blockDim.z + threadIdx.z;\n  float div;\n  if ((4 <= x && x < (nx - 4) ) && (4 <= y && y < (ny - 4)) && (4 <= z && z < (nz - 4))){\n    div =\n      a[0] * current_s[indexTo1D(x,y,z)] +\n      a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n          current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n          current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n      a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n          current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n          current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n      a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n          current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n          current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n      a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n          current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n          current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n\n    next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n      + vsq[indexTo1D(x,y,z)]*div;\n    div =\n      a[0] * current_r[indexTo1D(x,y,z)] +\n      a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n          current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n          current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n      a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n          current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n          current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n      a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n          current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n          current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n      a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n          current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n          current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n\n    next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n      - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n\n    image[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n  }\n}\n\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int ArraySize = nx * ny * nz;\n  float* next_s = (float*)malloc(ArraySize * sizeof(float));\n  float* current_s = (float*)malloc(ArraySize * sizeof(float));\n  float* next_r = (float*)malloc(ArraySize * sizeof(float));\n  float* current_r = (float*)malloc(ArraySize * sizeof(float));\n  float* vsq = (float*)malloc(ArraySize * sizeof(float));\n  float* image_gpu = (float*)malloc(ArraySize * sizeof(float));\n  float* image_cpu = (float*)malloc(ArraySize * sizeof(float));\n\n  float a[5];\n  double pts, t0, t1, dt, flops, pt_rate, flop_rate, speedup, memory;\n\n  memory = ArraySize*sizeof(float)*6;\n  pts = (double)repeat*(nx-8)*(ny-8)*(nz-8);\n  flops = 67*pts;\n  printf(\"memory (MB) = %lf\\n\", memory/1e6);\n  printf(\"pts (billions) = %lf\\n\", pts/1e9);\n  printf(\"Tflops = %lf\\n\", flops/1e12);\n\n  \n\n  a[0] = -1./560.;\n  a[1] = 8./315;\n  a[2] = -0.2;\n  a[3] = 1.6;\n  a[4] = -1435./504.;\n\n  for (int z = 0; z < nz; z++) {\n    for (int y = 0; y < ny; y++) {\n      for (int x = 0; x < nx; x++) {\n        vsq[indexTo1D(x,y,z)] = 1.0;\n        next_s[indexTo1D(x,y,z)] = 0;\n        current_s[indexTo1D(x,y,z)] = 1.0;\n        next_r[indexTo1D(x,y,z)] = 0;\n        current_r[indexTo1D(x,y,z)] = 1.0;\n        image_gpu[indexTo1D(x,y,z)] = image_cpu[indexTo1D(x,y,z)] = 0.5;\n      }\n    }\n  }\n\n  \n\n  float* vsq_d;\n  float* next_s_d;\n  float* current_s_d;\n  float* next_r_d;\n  float* current_r_d;\n  float* image_d;\n  float* a_d;\n\n  hipMalloc(&vsq_d, ArraySize * sizeof(float));\n  hipMalloc(&next_s_d, ArraySize * sizeof(float));\n  hipMalloc(&current_s_d, ArraySize * sizeof(float));\n  hipMalloc(&next_r_d, ArraySize * sizeof(float));\n  hipMalloc(&current_r_d, ArraySize * sizeof(float));\n  hipMalloc(&image_d, ArraySize * sizeof(float));\n  hipMalloc(&a_d, 5 * sizeof(float));\n\n  hipMemcpy(vsq_d, vsq, ArraySize * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(next_s_d, next_s, ArraySize * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(current_s_d, current_s, ArraySize * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(next_r_d, next_r, ArraySize * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(current_r_d, current_r, ArraySize * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(image_d, image_gpu, ArraySize * sizeof(float), hipMemcpyHostToDevice);\n  hipMemcpy(a_d, a, 5 * sizeof(float), hipMemcpyHostToDevice);\n\n  int groupSize = 16;\n  int nx_pad = (nx + groupSize - 1) / groupSize ;\n  int ny_pad = (ny + groupSize - 1) / groupSize ;\n  int nz_pad = nz;\n\n  dim3 grids (nx_pad, ny_pad, nz_pad);\n  dim3 blocks (groupSize, groupSize, 1);\n\n  hipDeviceSynchronize();\n  t0 = mysecond();\n\n  \n\n  for (int t = 0; t < repeat; t++) {\n    rtm8 <<<grids, blocks>>> (vsq_d, current_s_d, next_s_d, current_r_d,\n                              next_r_d, image_d, a_d, ArraySize);\n  }\n\n  hipDeviceSynchronize();\n  t1 = mysecond();\n  dt = t1 - t0;\n\n  \n\n  hipMemcpy(image_gpu, image_d, ArraySize * sizeof(float), hipMemcpyDeviceToHost);\n\n  \n\n  t0 = mysecond();\n  for (int t = 0; t < repeat; t++) {\n    rtm8_cpu(vsq, current_s, next_s, current_r, next_r, image_cpu, a, ArraySize);\n  }\n  t1 = mysecond();\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < ArraySize; i++) {\n    if (fabsf(image_cpu[i] - image_gpu[i]) > 0.1) {\n      printf(\"@index %d host: %f device %f\\n\", i, image_cpu[i], image_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  pt_rate = pts/dt;\n  flop_rate = flops/dt;\n  speedup = (t1 - t0) / dt;\n  printf(\"dt = %lf\\n\", dt);\n  printf(\"pt_rate (millions/sec) = %lf\\n\", pt_rate/1e6);\n  printf(\"flop_rate (Gflops) = %lf\\n\", flop_rate/1e9);\n  printf(\"speedup over cpu = %lf\\n\", speedup);\n  printf(\"average kernel execution time = %lf (s)\\n\", dt / repeat);\n\n  \n\n  free(vsq);\n  free(next_s);\n  free(current_s);\n  free(next_r);\n  free(current_r);\n  free(image_cpu);\n  free(image_gpu);\n  hipFree(vsq_d);\n  hipFree(next_s_d);\n  hipFree(current_s_d);\n  hipFree(next_r_d);\n  hipFree(current_r_d);\n  hipFree(image_d);\n  hipFree(a_d);\n\n  return 0;\n}\n"}}
{"kernel_name": "rtm8", "parallel_api": "omp", "code": {"mysecond.c": "\n\n\n#include <sys/time.h>\n\n\n\n#ifdef UNDERSCORE\ndouble mysecond_()\n#else\ndouble mysecond()\n#endif\n{\n  struct timeval tp;\n  struct timezone tzp;\n\n  gettimeofday(&tp,&tzp);\n  return ( (double) tp.tv_sec + (double) tp.tv_usec * 1.e-6 );\n}\n", "rtm8.cpp": "#include <iostream>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <vector>\n\n#define nx 680\n#define ny 134\n#define nz 450\n\n#include \"mysecond.c\"\n\ninline int indexTo1D(int x, int y, int z){\n  return x + y*nx + z*nx*ny;\n}\n\nvoid rtm8_cpu(float* vsq, float* current_s, float* current_r, float* next_s, float* next_r, float* image, float* a, size_t N)\n{\n#ifdef _OPENMP\n#pragma omp parallel for collapse(3)\n#endif\n  for (int z = 4; z < nz - 4; z++) {\n    for (int y = 4; y < ny - 4; y++) {\n      for (int x = 4; x < nx - 4; x++) {\n        float div =\n          a[0] * current_s[indexTo1D(x,y,z)] +\n          a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n              current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n              current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n              current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n              current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n              current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n              current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n              current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n              current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n\n        next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n          + vsq[indexTo1D(x,y,z)]*div;\n        div =\n          a[0] * current_r[indexTo1D(x,y,z)] +\n          a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n              current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n              current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n              current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n              current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n              current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n              current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n              current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n              current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n\n        next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n          - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n\n        image[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int ArraySize = nx * ny * nz;\n  float* next_s = (float*)malloc(ArraySize * sizeof(float));\n  float* current_s = (float*)malloc(ArraySize * sizeof(float));\n  float* next_r = (float*)malloc(ArraySize * sizeof(float));\n  float* current_r = (float*)malloc(ArraySize * sizeof(float));\n  float* vsq = (float*)malloc(ArraySize * sizeof(float));\n  float* image_gpu = (float*)malloc(ArraySize * sizeof(float));\n  float* image_cpu = (float*)malloc(ArraySize * sizeof(float));\n\n  float a[5];\n  double pts, t0, t1, dt, flops, pt_rate, flop_rate, speedup, memory;\n\n  memory = ArraySize*sizeof(float)*6; \n  pts = (double)repeat*(nx-8)*(ny-8)*(nz-8);\n  flops = 67*pts;\n  printf(\"memory (MB) = %lf\\n\", memory/1e6);\n  printf(\"pts (billions) = %lf\\n\", pts/1e9);\n  printf(\"Tflops = %lf\\n\", flops/1e12);\n\n  \n\n  a[0] = -1./560.;\n  a[1] = 8./315;\n  a[2] = -0.2;\n  a[3] = 1.6;\n  a[4] = -1435./504.;\n\n  for (int z = 0; z < nz; z++) {\n    for (int y = 0; y < ny; y++) {\n      for (int x = 0; x < nx; x++) {\n        vsq[indexTo1D(x,y,z)] = 1.0;\n        next_s[indexTo1D(x,y,z)] = 0;\n        current_s[indexTo1D(x,y,z)] = 1.0;\n        next_r[indexTo1D(x,y,z)] = 0;\n        current_r[indexTo1D(x,y,z)] = 1.0;\n        image_gpu[indexTo1D(x,y,z)] = image_cpu[indexTo1D(x,y,z)] = 0.5;\n      }\n    }\n  }\n\n  #pragma omp target data map(to: current_s[0:ArraySize]) \\\n                          map(to: current_r[0:ArraySize]) \\\n                          map(to: a[0:5]) \\\n                          map(to: vsq[0:ArraySize]) \\\n                          map(alloc: next_r[0:ArraySize]) \\\n                          map(alloc: next_s[0:ArraySize]) \\\n                          map(tofrom: image_gpu[0:ArraySize]) \n  {\n    t0 = mysecond();\n  \n    for (int t = 0; t < repeat; t++) {\n      #pragma omp target teams distribute parallel for collapse(3) thread_limit(256)\n      for (int z = 4; z < nz - 4; z++) {\n        for (int y = 4; y < ny - 4; y++) {\n          for (int x = 4; x < nx - 4; x++) {\n            float div =\n              a[0] * current_s[indexTo1D(x,y,z)] +\n              a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n                  current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n                  current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n              a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n                  current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n                  current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n              a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n                  current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n                  current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n              a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n                  current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n                  current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n  \n            next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n              + vsq[indexTo1D(x,y,z)]*div;\n            div =\n              a[0] * current_r[indexTo1D(x,y,z)] +\n              a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n                  current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n                  current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n              a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n                  current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n                  current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n              a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n                  current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n                  current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n              a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n                  current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n                  current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n  \n            next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n              - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n  \n            image_gpu[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n  \t}\n        }\n      }\n    }\n  \n    t1 = mysecond();\n    dt = t1 - t0;\n  }\n\n  \n\n  t0 = mysecond();\n  for (int t = 0; t < repeat; t++) {\n    rtm8_cpu(vsq, current_s, next_s, current_r, next_r, image_cpu, a, ArraySize);\n  }\n  t1 = mysecond();\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < ArraySize; i++) {\n    if (fabsf(image_cpu[i] - image_gpu[i]) > 0.1) {\n      printf(\"@index %d host: %f device %f\\n\", i, image_cpu[i], image_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  pt_rate = pts/dt;\n  flop_rate = flops/dt;\n  speedup = (t1 - t0) / dt;\n  printf(\"dt = %lf\\n\", dt);\n  printf(\"pt_rate (millions/sec) = %lf\\n\", pt_rate/1e6);\n  printf(\"flop_rate (Gflops) = %lf\\n\", flop_rate/1e9);\n  printf(\"speedup over cpu = %lf\\n\", speedup);\n  printf(\"average kernel execution time = %lf (s)\\n\", dt / repeat);\n\n  \n\n  free(vsq);\n  free(next_s);\n  free(current_s);\n  free(next_r);\n  free(current_r);\n  free(image_cpu);\n  free(image_gpu);\n\n  return 0;\n}\n"}}
{"kernel_name": "rtm8", "parallel_api": "serial", "code": {"mysecond.c": "\n\n\n#include <sys/time.h>\n\n\n\n#ifdef UNDERSCORE\ndouble mysecond_()\n#else\ndouble mysecond()\n#endif\n{\n  struct timeval tp;\n  struct timezone tzp;\n\n  gettimeofday(&tp,&tzp);\n  return ( (double) tp.tv_sec + (double) tp.tv_usec * 1.e-6 );\n}", "rtm8.cpp": "#include <iostream>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <vector>\n\n#define nx 680\n#define ny 134\n#define nz 450\n\n#include \"mysecond.c\"\n\ninline int indexTo1D(int x, int y, int z){\n  return x + y*nx + z*nx*ny;\n}\n\nvoid rtm8_cpu(float* vsq, float* current_s, float* current_r, float* next_s, float* next_r, float* image, float* a, size_t N)\n{\n#ifdef _OPENMP\n#endif\n  for (int z = 4; z < nz - 4; z++) {\n    for (int y = 4; y < ny - 4; y++) {\n      for (int x = 4; x < nx - 4; x++) {\n        float div =\n          a[0] * current_s[indexTo1D(x,y,z)] +\n          a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n              current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n              current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n              current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n              current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n              current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n              current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n              current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n              current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n\n        next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n          + vsq[indexTo1D(x,y,z)]*div;\n        div =\n          a[0] * current_r[indexTo1D(x,y,z)] +\n          a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n              current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n              current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n              current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n              current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n              current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n              current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n              current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n              current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n\n        next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n          - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n\n        image[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n      }\n    }\n  }\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int ArraySize = nx * ny * nz;\n  float* next_s = (float*)malloc(ArraySize * sizeof(float));\n  float* current_s = (float*)malloc(ArraySize * sizeof(float));\n  float* next_r = (float*)malloc(ArraySize * sizeof(float));\n  float* current_r = (float*)malloc(ArraySize * sizeof(float));\n  float* vsq = (float*)malloc(ArraySize * sizeof(float));\n  float* image_gpu = (float*)malloc(ArraySize * sizeof(float));\n  float* image_cpu = (float*)malloc(ArraySize * sizeof(float));\n\n  float a[5];\n  double pts, t0, t1, dt, flops, pt_rate, flop_rate, speedup, memory;\n\n  memory = ArraySize*sizeof(float)*6; \n  pts = (double)repeat*(nx-8)*(ny-8)*(nz-8);\n  flops = 67*pts;\n  printf(\"memory (MB) = %lf\\n\", memory/1e6);\n  printf(\"pts (billions) = %lf\\n\", pts/1e9);\n  printf(\"Tflops = %lf\\n\", flops/1e12);\n\n  \n\n  a[0] = -1./560.;\n  a[1] = 8./315;\n  a[2] = -0.2;\n  a[3] = 1.6;\n  a[4] = -1435./504.;\n\n  for (int z = 0; z < nz; z++) {\n    for (int y = 0; y < ny; y++) {\n      for (int x = 0; x < nx; x++) {\n        vsq[indexTo1D(x,y,z)] = 1.0;\n        next_s[indexTo1D(x,y,z)] = 0;\n        current_s[indexTo1D(x,y,z)] = 1.0;\n        next_r[indexTo1D(x,y,z)] = 0;\n        current_r[indexTo1D(x,y,z)] = 1.0;\n        image_gpu[indexTo1D(x,y,z)] = image_cpu[indexTo1D(x,y,z)] = 0.5;\n      }\n    }\n  }\n\n    {\n    t0 = mysecond();\n  \n    for (int t = 0; t < repeat; t++) {\n            for (int z = 4; z < nz - 4; z++) {\n        for (int y = 4; y < ny - 4; y++) {\n          for (int x = 4; x < nx - 4; x++) {\n            float div =\n              a[0] * current_s[indexTo1D(x,y,z)] +\n              a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n                  current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n                  current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n              a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n                  current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n                  current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n              a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n                  current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n                  current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n              a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n                  current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n                  current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n  \n            next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n              + vsq[indexTo1D(x,y,z)]*div;\n            div =\n              a[0] * current_r[indexTo1D(x,y,z)] +\n              a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n                  current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n                  current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n              a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n                  current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n                  current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n              a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n                  current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n                  current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n              a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n                  current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n                  current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n  \n            next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n              - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n  \n            image_gpu[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n  \t}\n        }\n      }\n    }\n  \n    t1 = mysecond();\n    dt = t1 - t0;\n  }\n\n  \n\n  t0 = mysecond();\n  for (int t = 0; t < repeat; t++) {\n    rtm8_cpu(vsq, current_s, next_s, current_r, next_r, image_cpu, a, ArraySize);\n  }\n  t1 = mysecond();\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < ArraySize; i++) {\n    if (fabsf(image_cpu[i] - image_gpu[i]) > 0.1) {\n      printf(\"@index %d host: %f device %f\\n\", i, image_cpu[i], image_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  pt_rate = pts/dt;\n  flop_rate = flops/dt;\n  speedup = (t1 - t0) / dt;\n  printf(\"dt = %lf\\n\", dt);\n  printf(\"pt_rate (millions/sec) = %lf\\n\", pt_rate/1e6);\n  printf(\"flop_rate (Gflops) = %lf\\n\", flop_rate/1e9);\n  printf(\"speedup over cpu = %lf\\n\", speedup);\n  printf(\"average kernel execution time = %lf (s)\\n\", dt / repeat);\n\n  \n\n  free(vsq);\n  free(next_s);\n  free(current_s);\n  free(next_r);\n  free(current_r);\n  free(image_cpu);\n  free(image_gpu);\n\n  return 0;\n}"}}
{"kernel_name": "rtm8", "parallel_api": "sycl", "code": {"mysecond.c": "\n\n\n#include <sys/time.h>\n\n\n\n#ifdef UNDERSCORE\ndouble mysecond_()\n#else\ndouble mysecond()\n#endif\n{\n  struct timeval tp;\n  struct timezone tzp;\n\n  gettimeofday(&tp,&tzp);\n  return ( (double) tp.tv_sec + (double) tp.tv_usec * 1.e-6 );\n}\n", "rtm8.cpp": "#include <iostream>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <vector>\n#include <sycl/sycl.hpp>\n\n#define nx 680\n#define ny 134\n#define nz 450\n\n#include \"mysecond.c\"\n\ninline int indexTo1D(int x, int y, int z){\n  return x + y*nx + z*nx*ny;\n}\n\nvoid rtm8_cpu(float* vsq, float* current_s, float* current_r, float* next_s, float* next_r, float* image, float* a, size_t N)\n{\n#ifdef _OPENMP\n#pragma omp parallel for collapse(3)\n#endif\n  for (int z = 4; z < nz - 4; z++) {\n    for (int y = 4; y < ny - 4; y++) {\n      for (int x = 4; x < nx - 4; x++) {\n        float div =\n          a[0] * current_s[indexTo1D(x,y,z)] +\n          a[1] * (current_s[indexTo1D(x+1,y,z)] + current_s[indexTo1D(x-1,y,z)] +\n              current_s[indexTo1D(x,y+1,z)] + current_s[indexTo1D(x,y-1,z)] +\n              current_s[indexTo1D(x,y,z+1)] + current_s[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_s[indexTo1D(x+2,y,z)] + current_s[indexTo1D(x-2,y,z)] +\n              current_s[indexTo1D(x,y+2,z)] + current_s[indexTo1D(x,y-2,z)] +\n              current_s[indexTo1D(x,y,z+2)] + current_s[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_s[indexTo1D(x+3,y,z)] + current_s[indexTo1D(x-3,y,z)] +\n              current_s[indexTo1D(x,y+3,z)] + current_s[indexTo1D(x,y-3,z)] +\n              current_s[indexTo1D(x,y,z+3)] + current_s[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_s[indexTo1D(x+4,y,z)] + current_s[indexTo1D(x-4,y,z)] +\n              current_s[indexTo1D(x,y+4,z)] + current_s[indexTo1D(x,y-4,z)] +\n              current_s[indexTo1D(x,y,z+4)] + current_s[indexTo1D(x,y,z-4)]);\n\n        next_s[indexTo1D(x,y,z)] = 2*current_s[indexTo1D(x,y,z)] - next_s[indexTo1D(x,y,z)]\n          + vsq[indexTo1D(x,y,z)]*div;\n        div =\n          a[0] * current_r[indexTo1D(x,y,z)] +\n          a[1] * (current_r[indexTo1D(x+1,y,z)] + current_r[indexTo1D(x-1,y,z)] +\n              current_r[indexTo1D(x,y+1,z)] + current_r[indexTo1D(x,y-1,z)] +\n              current_r[indexTo1D(x,y,z+1)] + current_r[indexTo1D(x,y,z-1)]) +\n          a[2] * (current_r[indexTo1D(x+2,y,z)] + current_r[indexTo1D(x-2,y,z)] +\n              current_r[indexTo1D(x,y+2,z)] + current_r[indexTo1D(x,y-2,z)] +\n              current_r[indexTo1D(x,y,z+2)] + current_r[indexTo1D(x,y,z-2)]) +\n          a[3] * (current_r[indexTo1D(x+3,y,z)] + current_r[indexTo1D(x-3,y,z)] +\n              current_r[indexTo1D(x,y+3,z)] + current_r[indexTo1D(x,y-3,z)] +\n              current_r[indexTo1D(x,y,z+3)] + current_r[indexTo1D(x,y,z-3)]) +\n          a[4] * (current_r[indexTo1D(x+4,y,z)] + current_r[indexTo1D(x-4,y,z)] +\n              current_r[indexTo1D(x,y+4,z)] + current_r[indexTo1D(x,y-4,z)] +\n              current_r[indexTo1D(x,y,z+4)] + current_r[indexTo1D(x,y,z-4)]);\n\n        next_r[indexTo1D(x,y,z)] = 2 * current_r[indexTo1D(x,y,z)]\n          - next_r[indexTo1D(x,y,z)] + vsq[indexTo1D(x,y,z)] * div;\n\n        image[indexTo1D(x,y,z)] = next_s[indexTo1D(x,y,z)] * next_r[indexTo1D(x,y,z)];\n      }\n    }\n  }\n}\n\n\nint main(int argc, char *argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  const int ArraySize = nx * ny * nz;\n  float* next_s = (float*)malloc(ArraySize * sizeof(float));\n  float* current_s = (float*)malloc(ArraySize * sizeof(float));\n  float* next_r = (float*)malloc(ArraySize * sizeof(float));\n  float* current_r = (float*)malloc(ArraySize * sizeof(float));\n  float* vsq = (float*)malloc(ArraySize * sizeof(float));\n  float* image_gpu = (float*)malloc(ArraySize * sizeof(float));\n  float* image_cpu = (float*)malloc(ArraySize * sizeof(float));\n\n  float a[5];\n  double pts, t0, t1, dt, flops, pt_rate, flop_rate, speedup, memory;\n\n  memory = ArraySize*sizeof(float)*6;\n  pts = (double)repeat*(nx-8)*(ny-8)*(nz-8);\n  flops = 67*pts;\n  printf(\"memory (MB) = %lf\\n\", memory/1e6);\n  printf(\"pts (billions) = %lf\\n\", pts/1e9);\n  printf(\"Tflops = %lf\\n\", flops/1e12);\n\n  \n\n  a[0] = -1./560.;\n  a[1] = 8./315;\n  a[2] = -0.2;\n  a[3] = 1.6;\n  a[4] = -1435./504.;\n\n  for (int z = 0; z < nz; z++) {\n    for (int y = 0; y < ny; y++) {\n      for (int x = 0; x < nx; x++) {\n        vsq[indexTo1D(x,y,z)] = 1.0;\n        next_s[indexTo1D(x,y,z)] = 0;\n        current_s[indexTo1D(x,y,z)] = 1.0;\n        next_r[indexTo1D(x,y,z)] = 0;\n        current_r[indexTo1D(x,y,z)] = 1.0;\n        image_gpu[indexTo1D(x,y,z)] = image_cpu[indexTo1D(x,y,z)] = 0.5;\n      }\n    }\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  float *vsq_d = sycl::malloc_device<float>(ArraySize, q);\n  float *next_s_d = sycl::malloc_device<float>(ArraySize, q);\n  float *next_r_d = sycl::malloc_device<float>(ArraySize, q);\n  float *current_s_d = sycl::malloc_device<float>(ArraySize, q);\n  float *current_r_d = sycl::malloc_device<float>(ArraySize, q);\n  float *image_d = sycl::malloc_device<float>(ArraySize, q);\n  float *a_d = sycl::malloc_device<float>(5, q);\n\n  q.memcpy(vsq_d, vsq, ArraySize * sizeof(float));\n  q.memcpy(next_s_d, next_s, ArraySize * sizeof(float));\n  q.memcpy(current_s_d, current_s, ArraySize * sizeof(float));\n  q.memcpy(next_r_d, next_r, ArraySize * sizeof(float));\n  q.memcpy(current_r_d, current_r, ArraySize * sizeof(float));\n  q.memcpy(image_d, image_gpu, ArraySize * sizeof(float));\n  q.memcpy(a_d, a, 5 * sizeof(float));\n\n  int groupSize = 16;\n  int nx_pad = (nx + groupSize - 1) / groupSize * groupSize;\n  int ny_pad = (ny + groupSize - 1) / groupSize * groupSize;\n  int nz_pad = nz;\n\n  sycl::range<3> gws (nz_pad, ny_pad, nx_pad);\n  sycl::range<3> lws (1, groupSize, groupSize);\n\n  q.wait();\n  t0 = mysecond();\n\n  for (int t = 0; t < repeat; t++) {\n    q.submit([&](sycl::handler& cgh) {\n      cgh.parallel_for<class kernel1>(\n        sycl::nd_range<3>(gws, lws), [=] (sycl::nd_item<3> item) {\n        int x = item.get_global_id(2);\n        int y = item.get_global_id(1);\n        int z = item.get_global_id(0);\n        float div;\n        if ((4 <= x && x < (nx - 4) ) && (4 <= y && y < (ny - 4)) && (4 <= z && z < (nz - 4))){\n          div = a[0] * current_s_d[indexTo1D(x,y,z)] +\n                a[1] * (current_s_d[indexTo1D(x+1,y,z)] + current_s_d[indexTo1D(x-1,y,z)] +\n                  current_s_d[indexTo1D(x,y+1,z)] + current_s_d[indexTo1D(x,y-1,z)] +\n                  current_s_d[indexTo1D(x,y,z+1)] + current_s_d[indexTo1D(x,y,z-1)]) +\n                a[2] * (current_s_d[indexTo1D(x+2,y,z)] + current_s_d[indexTo1D(x-2,y,z)] +\n                  current_s_d[indexTo1D(x,y+2,z)] + current_s_d[indexTo1D(x,y-2,z)] +\n                  current_s_d[indexTo1D(x,y,z+2)] + current_s_d[indexTo1D(x,y,z-2)]) +\n                a[3] * (current_s_d[indexTo1D(x+3,y,z)] + current_s_d[indexTo1D(x-3,y,z)] +\n                  current_s_d[indexTo1D(x,y+3,z)] + current_s_d[indexTo1D(x,y-3,z)] +\n                  current_s_d[indexTo1D(x,y,z+3)] + current_s_d[indexTo1D(x,y,z-3)]) +\n                a[4] * (current_s_d[indexTo1D(x+4,y,z)] + current_s_d[indexTo1D(x-4,y,z)] +\n                  current_s_d[indexTo1D(x,y+4,z)] + current_s_d[indexTo1D(x,y-4,z)] +\n                  current_s_d[indexTo1D(x,y,z+4)] + current_s_d[indexTo1D(x,y,z-4)]);\n          \n          next_s_d[indexTo1D(x,y,z)] = 2*current_s_d[indexTo1D(x,y,z)] - next_s_d[indexTo1D(x,y,z)]\n                                       + vsq_d[indexTo1D(x,y,z)]*div;\n          div = a[0] * current_r_d[indexTo1D(x,y,z)] +\n                a[1] * (current_r_d[indexTo1D(x+1,y,z)] + current_r_d[indexTo1D(x-1,y,z)] +\n                    current_r_d[indexTo1D(x,y+1,z)] + current_r_d[indexTo1D(x,y-1,z)] +\n                    current_r_d[indexTo1D(x,y,z+1)] + current_r_d[indexTo1D(x,y,z-1)]) +\n                a[2] * (current_r_d[indexTo1D(x+2,y,z)] + current_r_d[indexTo1D(x-2,y,z)] +\n                    current_r_d[indexTo1D(x,y+2,z)] + current_r_d[indexTo1D(x,y-2,z)] +\n                    current_r_d[indexTo1D(x,y,z+2)] + current_r_d[indexTo1D(x,y,z-2)]) +\n                a[3] * (current_r_d[indexTo1D(x+3,y,z)] + current_r_d[indexTo1D(x-3,y,z)] +\n                    current_r_d[indexTo1D(x,y+3,z)] + current_r_d[indexTo1D(x,y-3,z)] +\n                    current_r_d[indexTo1D(x,y,z+3)] + current_r_d[indexTo1D(x,y,z-3)]) +\n                a[4] * (current_r_d[indexTo1D(x+4,y,z)] + current_r_d[indexTo1D(x-4,y,z)] +\n                    current_r_d[indexTo1D(x,y+4,z)] + current_r_d[indexTo1D(x,y-4,z)] +\n                    current_r_d[indexTo1D(x,y,z+4)] + current_r_d[indexTo1D(x,y,z-4)]);\n          \n          next_r_d[indexTo1D(x,y,z)] = 2 * current_r_d[indexTo1D(x,y,z)]\n                                       - next_r_d[indexTo1D(x,y,z)] + vsq_d[indexTo1D(x,y,z)] * div;\n          \n          image_d[indexTo1D(x,y,z)] = next_s_d[indexTo1D(x,y,z)] * next_r_d[indexTo1D(x,y,z)];\n        }\n      });\n    });\n  }\n\n  q.wait();\n  t1 = mysecond();\n  dt = t1 - t0;\n\n  q.memcpy(image_gpu, image_d, ArraySize * sizeof(float)).wait();\n\n  t0 = mysecond();\n  for (int t = 0; t < repeat; t++) {\n    rtm8_cpu(vsq, current_s, next_s, current_r, next_r, image_cpu, a, ArraySize);\n  }\n  t1 = mysecond();\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < ArraySize; i++) {\n    if (fabsf(image_cpu[i] - image_gpu[i]) > 0.1) {\n      printf(\"@index %d host: %f device %f\\n\", i, image_cpu[i], image_gpu[i]);\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  pt_rate = pts/dt;\n  flop_rate = flops/dt;\n  speedup = (t1 - t0) / dt;\n  printf(\"dt = %lf\\n\", dt);\n  printf(\"pt_rate (millions/sec) = %lf\\n\", pt_rate/1e6);\n  printf(\"flop_rate (Gflops) = %lf\\n\", flop_rate/1e9);\n  printf(\"speedup over cpu = %lf\\n\", speedup);\n  printf(\"average kernel execution time = %lf (s)\\n\", dt / repeat);\n\n  \n\n  free(vsq);\n  free(next_s);\n  free(current_s);\n  free(next_r);\n  free(current_r);\n  free(image_cpu);\n  free(image_gpu);\n  sycl::free(vsq_d, q);\n  sycl::free(next_s_d, q);\n  sycl::free(current_s_d, q);\n  sycl::free(next_r_d, q);\n  sycl::free(current_r_d, q);\n  sycl::free(image_d, q);\n  sycl::free(a_d, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "sad", "parallel_api": "cuda", "code": {"main.cu": "#include <iostream>\n#include <chrono>\n#include <cuda.h>\n#include \"bitmap_image.hpp\"\n\n#define check(stmt)                                          \\\n  do {                        \\\n    cudaError_t err = stmt;   \\\n    if (err != cudaSuccess) { \\\n      printf(\"[ERROR] Failed to run stmt %d, error body: %s\\n\", __LINE__, cudaGetErrorString(err));  \\\n      return -1; }            \\\n  } while (0)                 \\\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define FOUND_MIN     5000\n#define min(a, b) ((a) < (b) ? (a) : (b))\n\n__global__ void compute_sad_array(\n                    int*__restrict__ sad_array,\n    const unsigned char*__restrict__ image,\n    const unsigned char*__restrict__ kernel,\n    const int sad_array_size,\n    const int image_width,\n    const int image_height,\n    const int kernel_width,\n    const int kernel_height,\n    const int kernel_size)\n{\n  int col = blockIdx.x * blockDim.x + threadIdx.x;\n  int row = blockIdx.y * blockDim.y + threadIdx.y;\n  int sad_result = 0;\n\n  if (row < image_height && col < image_width) {\n    const int overlap_width = min(image_width - col, kernel_width);\n    const int overlap_height = min(image_height - row, kernel_height);\n    #pragma unroll 4\n    for (int kr = 0; kr < overlap_height; kr++) {\n      #pragma unroll 4\n      for (int kc = 0; kc < overlap_width; kc++) {\n        const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n        const int kernel_addr = (kr * kernel_width + kc) * 3;\n        const int m_r = (int)(image[image_addr + 0]);\n        const int m_g = (int)(image[image_addr + 1]);\n        const int m_b = (int)(image[image_addr + 2]);\n        const int t_r = (int)(kernel[kernel_addr + 0]);\n        const int t_g = (int)(kernel[kernel_addr + 1]);\n        const int t_b = (int)(kernel[kernel_addr + 2]);\n        const int error = abs(m_r - t_r) + abs(m_g - t_g) + abs(m_b - t_b);\n        sad_result += error;\n      }\n    }\n\n    int norm_sad = (int)(sad_result / (float)kernel_size);\n\n    int my_index_in_sad_array = row * image_width + col;\n    if (my_index_in_sad_array < sad_array_size) {\n      sad_array[my_index_in_sad_array] = norm_sad;\n    }\n  }\n}\n\n__global__ void find_min_in_sad_array(\n    const int sad_array_size,\n    const int* __restrict__ sad_array,\n          int* __restrict__ min_sad)\n{\n  unsigned int gid = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int stride = gridDim.x * blockDim.x;\n  unsigned int offset = 0;\n\n  __shared__ int cache[BLOCK_SIZE];\n\n  int temp = FOUND_MIN;\n  while (gid + offset < sad_array_size) {\n    temp = min(temp, sad_array[gid + offset]);\n    offset += stride;\n  }\n\n  cache[threadIdx.x] = temp;\n\n  __syncthreads();\n\n  unsigned int i = blockDim.x / 2;\n  while (i != 0) {\n    if (threadIdx.x < i)\n      cache[threadIdx.x] = min(cache[threadIdx.x], cache[threadIdx.x + i]);\n    __syncthreads();\n    i /= 2;\n  }\n\n  \n\n  if (threadIdx.x == 0)\n    atomicMin(min_sad, cache[0]);\n}\n\n__global__ void get_num_of_occurrences(\n    const int sad_array_size,\n    const int*__restrict__ sad_array,\n    const int*__restrict__ min_sad,\n          int*__restrict__ num_occurrences)\n{\n  unsigned int gid = threadIdx.x + blockIdx.x * blockDim.x;\n\n  __shared__ int s;\n\n  if (gid < sad_array_size) {\n\n    if (threadIdx.x == 0) s = 0;\n\n    __syncthreads();\n\n    if (sad_array[gid] == *min_sad)\n      atomicAdd(&s, 1);\n\n    __syncthreads();\n\n    \n\n    if (threadIdx.x == 0)\n      atomicAdd(num_occurrences, s);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n\n  \n\n  unsigned char* d_main_image;\n  unsigned char* d_template_image;\n  int* d_sad_array;\n  int* d_min_mse;\n  int* d_num_occurances;\n\n  check(cudaMalloc((void **)&d_main_image, 3 * main_size * sizeof(unsigned char)));\n  check(cudaMalloc((void **)&d_template_image, 3 * template_size * sizeof(unsigned char)));\n  check(cudaMalloc((void **)&d_sad_array, sad_array_size * sizeof(int)));\n  check(cudaMalloc((void **)&d_min_mse, sizeof(int)));\n  check(cudaMalloc((void **)&d_num_occurances, sizeof(int)));\n\n  dim3 grids((unsigned int)ceilf((float)main_width / BLOCK_SIZE_X),\n             (unsigned int)ceilf((float)main_height / BLOCK_SIZE_Y));\n  dim3 blocks(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n\n  dim3 grids_2((unsigned int)ceilf((float)sad_array_size / BLOCK_SIZE));\n  dim3 blocks_2(BLOCK_SIZE);\n\n  check(cudaMemcpy(d_main_image, h_main_image,\n                   3 * main_size * sizeof(unsigned char), cudaMemcpyHostToDevice));\n  check(cudaMemcpy(d_template_image, h_template_image,\n                   3 * template_size * sizeof(unsigned char), cudaMemcpyHostToDevice));\n\n  \n\n  double kernel_time = 0.0;\n\n  auto begin = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n\n    h_min_mse = THRESHOLD;\n    check(cudaMemset(d_num_occurances, 0, sizeof(int)));\n    check(cudaMemcpy(d_min_mse, &h_min_mse, sizeof(int), cudaMemcpyHostToDevice));\n\n    cudaDeviceSynchronize();\n    auto kbegin = std::chrono::steady_clock::now();\n\n    compute_sad_array <<< grids, blocks >>> (\n        d_sad_array, d_main_image, d_template_image, sad_array_size, \n        main_width, main_height, template_width, template_height, template_size);\n\n    find_min_in_sad_array <<< grids_2, blocks_2 >>> (\n        sad_array_size, d_sad_array, d_min_mse);\n\n    get_num_of_occurrences <<< grids_2, blocks_2 >>> (\n        sad_array_size, d_sad_array, d_min_mse, d_num_occurances);\n\n    cudaDeviceSynchronize();\n    auto kend = std::chrono::steady_clock::now();\n    kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n    check(cudaMemcpy(&h_min_mse, d_min_mse, sizeof(int), cudaMemcpyDeviceToHost));\n    check(cudaMemcpy(&h_num_occurances, d_num_occurances, sizeof(int), cudaMemcpyDeviceToHost));\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  float elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n  std::cout << \"Parallel Computation Results: \" << std::endl;\n  std::cout << \"Kernel time in msec: \" << kernel_time << std::endl; \n  std::cout << \"Elapsed time in msec: \" << elapsed_time << std::endl; \n  std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n  std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n  std::cout << \"Found Minimum: \" << h_min_mse << std::endl;\n  std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n\n  check(cudaFree(d_main_image));\n  check(cudaFree(d_template_image));\n  check(cudaFree(d_sad_array));\n  check(cudaFree(d_min_mse));\n  check(cudaFree(d_num_occurances));\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}\n"}}
{"kernel_name": "sad", "parallel_api": "hip", "code": {"main.cu": "#include <iostream>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"bitmap_image.hpp\"\n\n#define check(stmt)                                          \\\n  do {                        \\\n    hipError_t err = stmt;   \\\n    if (err != hipSuccess) { \\\n      printf(\"[ERROR] Failed to run stmt %d, error body: %s\\n\", __LINE__, hipGetErrorString(err));  \\\n      return -1; }            \\\n  } while (0)                 \\\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define FOUND_MIN     5000\n#define min(a, b) ((a) < (b) ? (a) : (b))\n\n__global__ void compute_sad_array(\n                    int*__restrict__ sad_array,\n    const unsigned char*__restrict__ image,\n    const unsigned char*__restrict__ kernel,\n    const int sad_array_size,\n    const int image_width,\n    const int image_height,\n    const int kernel_width,\n    const int kernel_height,\n    const int kernel_size)\n{\n  int col = blockIdx.x * blockDim.x + threadIdx.x;\n  int row = blockIdx.y * blockDim.y + threadIdx.y;\n  int sad_result = 0;\n\n  if (row < image_height && col < image_width) {\n    const int overlap_width = min(image_width - col, kernel_width);\n    const int overlap_height = min(image_height - row, kernel_height);\n    #pragma unroll 4\n    for (int kr = 0; kr < overlap_height; kr++) {\n      #pragma unroll 4\n      for (int kc = 0; kc < overlap_width; kc++) {\n        const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n        const int kernel_addr = (kr * kernel_width + kc) * 3;\n        const int m_r = (int)(image[image_addr + 0]);\n        const int m_g = (int)(image[image_addr + 1]);\n        const int m_b = (int)(image[image_addr + 2]);\n        const int t_r = (int)(kernel[kernel_addr + 0]);\n        const int t_g = (int)(kernel[kernel_addr + 1]);\n        const int t_b = (int)(kernel[kernel_addr + 2]);\n        const int error = abs(m_r - t_r) + abs(m_g - t_g) + abs(m_b - t_b);\n        sad_result += error;\n      }\n    }\n\n    int norm_sad = (int)(sad_result / (float)kernel_size);\n\n    int my_index_in_sad_array = row * image_width + col;\n    if (my_index_in_sad_array < sad_array_size) {\n      sad_array[my_index_in_sad_array] = norm_sad;\n    }\n  }\n}\n\n__global__ void find_min_in_sad_array(\n    const int sad_array_size,\n    const int* __restrict__ sad_array,\n          int* __restrict__ min_sad)\n{\n  unsigned int gid = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int stride = gridDim.x * blockDim.x;\n  unsigned int offset = 0;\n\n  __shared__ int cache[BLOCK_SIZE];\n\n  int temp = FOUND_MIN;\n  while (gid + offset < sad_array_size) {\n    temp = min(temp, sad_array[gid + offset]);\n    offset += stride;\n  }\n\n  cache[threadIdx.x] = temp;\n\n  __syncthreads();\n\n  unsigned int i = blockDim.x / 2;\n  while (i != 0) {\n    if (threadIdx.x < i)\n      cache[threadIdx.x] = min(cache[threadIdx.x], cache[threadIdx.x + i]);\n    __syncthreads();\n    i /= 2;\n  }\n\n  \n\n  if (threadIdx.x == 0)\n    atomicMin(min_sad, cache[0]);\n}\n\n__global__ void get_num_of_occurrences(\n    const int sad_array_size,\n    const int*__restrict__ sad_array,\n    const int*__restrict__ min_sad,\n          int*__restrict__ num_occurrences)\n{\n  unsigned int gid = threadIdx.x + blockIdx.x * blockDim.x;\n\n  __shared__ int s;\n\n  if (gid < sad_array_size) {\n\n    if (threadIdx.x == 0) s = 0;\n\n    __syncthreads();\n\n    if (sad_array[gid] == *min_sad)\n      atomicAdd(&s, 1);\n\n    __syncthreads();\n\n    \n\n    if (threadIdx.x == 0)\n      atomicAdd(num_occurrences, s);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n\n  \n\n  unsigned char* d_main_image;\n  unsigned char* d_template_image;\n  int* d_sad_array;\n  int* d_min_mse;\n  int* d_num_occurances;\n\n  check(hipMalloc((void **)&d_main_image, 3 * main_size * sizeof(unsigned char)));\n  check(hipMalloc((void **)&d_template_image, 3 * template_size * sizeof(unsigned char)));\n  check(hipMalloc((void **)&d_sad_array, sad_array_size * sizeof(int)));\n  check(hipMalloc((void **)&d_min_mse, sizeof(int)));\n  check(hipMalloc((void **)&d_num_occurances, sizeof(int)));\n\n  dim3 grids((unsigned int)ceilf((float)main_width / BLOCK_SIZE_X),\n             (unsigned int)ceilf((float)main_height / BLOCK_SIZE_Y));\n  dim3 blocks(BLOCK_SIZE_X, BLOCK_SIZE_Y, 1);\n\n  dim3 grids_2((unsigned int)ceilf((float)sad_array_size / BLOCK_SIZE));\n  dim3 blocks_2(BLOCK_SIZE);\n\n  check(hipMemcpy(d_main_image, h_main_image,\n                   3 * main_size * sizeof(unsigned char), hipMemcpyHostToDevice));\n  check(hipMemcpy(d_template_image, h_template_image,\n                   3 * template_size * sizeof(unsigned char), hipMemcpyHostToDevice));\n\n  \n\n  double kernel_time = 0.0;\n\n  auto begin = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n\n    h_min_mse = THRESHOLD;\n    check(hipMemset(d_num_occurances, 0, sizeof(int)));\n    check(hipMemcpy(d_min_mse, &h_min_mse, sizeof(int), hipMemcpyHostToDevice));\n\n    hipDeviceSynchronize();\n    auto kbegin = std::chrono::steady_clock::now();\n\n    hipLaunchKernelGGL(compute_sad_array, grids, blocks , 0, 0, \n        d_sad_array, d_main_image, d_template_image, sad_array_size, \n        main_width, main_height, template_width, template_height, template_size);\n\n    hipLaunchKernelGGL(find_min_in_sad_array, grids_2, blocks_2 , 0, 0, \n        sad_array_size, d_sad_array, d_min_mse);\n\n    hipLaunchKernelGGL(get_num_of_occurrences, grids_2, blocks_2 , 0, 0, \n        sad_array_size, d_sad_array, d_min_mse, d_num_occurances);\n\n    hipDeviceSynchronize();\n    auto kend = std::chrono::steady_clock::now();\n    kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n    check(hipMemcpy(&h_min_mse, d_min_mse, sizeof(int), hipMemcpyDeviceToHost));\n    check(hipMemcpy(&h_num_occurances, d_num_occurances, sizeof(int), hipMemcpyDeviceToHost));\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  float elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n  std::cout << \"Parallel Computation Results: \" << std::endl;\n  std::cout << \"Kernel time in msec: \" << kernel_time << std::endl; \n  std::cout << \"Elapsed time in msec: \" << elapsed_time << std::endl; \n  std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n  std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n  std::cout << \"Found Minimum: \" << h_min_mse << std::endl;\n  std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n\n  check(hipFree(d_main_image));\n  check(hipFree(d_template_image));\n  check(hipFree(d_sad_array));\n  check(hipFree(d_min_mse));\n  check(hipFree(d_num_occurances));\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}\n"}}
{"kernel_name": "sad", "parallel_api": "omp", "code": {"main.cpp": "#include <iostream>\n#include <chrono>\n#include <omp.h>\n#include \"bitmap_image.hpp\"\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define min(a, b) ((a) < (b) ? (a) : (b))\n\nvoid compute_sad_array(\n                    int*__restrict sad_array,\n    const unsigned char*__restrict image,\n    const unsigned char*__restrict kernel,\n    int sad_array_size,\n    int& min_mse,\n    int& num_occurrences,\n    int image_width, int image_height,\n    int kernel_width, int kernel_height,\n    int kernel_size,\n    double &kernel_time)\n{\n  auto kbegin = std::chrono::steady_clock::now();\n\n  #pragma omp target teams distribute parallel for collapse(2) thread_limit(BLOCK_SIZE)\n  for (int row = 0; row < image_height; row++) {\n    for (int col = 0; col < image_width; col++) {\n      int sad_result = 0;\n      const int overlap_width = min(image_width - col, kernel_width);\n      const int overlap_height = min(image_height - row, kernel_height);\n      #pragma unroll 4\n      for (int kr = 0; kr < overlap_height; kr++) {\n        #pragma unroll 4\n        for (int kc = 0; kc < overlap_width; kc++) {\n          const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n          const int kernel_addr = (kr * kernel_width + kc) * 3;\n          const int m_r = (int)(image[image_addr + 0]);\n          const int m_g = (int)(image[image_addr + 1]);\n          const int m_b = (int)(image[image_addr + 2]);\n          const int t_r = (int)(kernel[kernel_addr + 0]);\n          const int t_g = (int)(kernel[kernel_addr + 1]);\n          const int t_b = (int)(kernel[kernel_addr + 2]);\n          const int error = abs(m_r - t_r) + abs(m_g - t_g) + abs(m_b - t_b);\n          sad_result += error;\n        }\n      }\n\n      int norm_sad = (int)(sad_result / (float)kernel_size);\n\n      int my_index_in_sad_array = row * image_width + col;\n      if (my_index_in_sad_array < sad_array_size) {\n        sad_array[my_index_in_sad_array] = norm_sad;\n      }\n    }\n  }\n\n  int m = THRESHOLD;\n  #pragma omp target teams distribute parallel for thread_limit(256) \\\n    map(tofrom: m) reduction(min: m)\n  for (int i = 0; i < sad_array_size; i++) \n    m = min(m, sad_array[i]);\n\n  int n = 0; \n  #pragma omp target teams distribute parallel for thread_limit(256) \\\n    map(tofrom: n) reduction(+: n)\n  for (int i = 0; i < sad_array_size; i++) {\n    if (sad_array[i] == m) n++;\n  }\n\n  auto kend = std::chrono::steady_clock::now();\n  kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n  min_mse = m;\n  num_occurrences = n;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n  float elapsed_time; \n\n  #pragma omp target data map(to: h_main_image[0:3*main_size],\\\n                                  h_template_image[0:3*template_size]) \\\n                          map(alloc: h_sad_array[0:sad_array_size])\n  {\n    \n\n    double kernel_time = 0.0;\n\n    auto begin = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n\n      compute_sad_array(\n          h_sad_array, h_main_image, h_template_image, sad_array_size, \n          h_min_mse, h_num_occurances,\n          main_width, main_height,\n          template_width, template_height, template_size,\n          kernel_time);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n    std::cout << \"Parallel Computation Results: \" << std::endl;\n    std::cout << \"Kernel time in msec: \" << kernel_time << std::endl; \n    std::cout << \"Elapsed time in msec = \" << elapsed_time << std::endl; \n    std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n    std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n    std::cout << \"Found Minimum:  \" << h_min_mse << std::endl;\n    std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n  }\n\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}\n"}}
{"kernel_name": "sad", "parallel_api": "serial", "code": {"main.cpp": "#include <iostream>\n#include <chrono>\n#include \"bitmap_image.hpp\"\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define min(a, b) ((a) < (b) ? (a) : (b))\n\nvoid compute_sad_array(\n                    int*__restrict sad_array,\n    const unsigned char*__restrict image,\n    const unsigned char*__restrict kernel,\n    int sad_array_size,\n    int& min_mse,\n    int& num_occurrences,\n    int image_width, int image_height,\n    int kernel_width, int kernel_height,\n    int kernel_size,\n    double &kernel_time)\n{\n  auto kbegin = std::chrono::steady_clock::now();\n\n    for (int row = 0; row < image_height; row++) {\n    for (int col = 0; col < image_width; col++) {\n      int sad_result = 0;\n      const int overlap_width = min(image_width - col, kernel_width);\n      const int overlap_height = min(image_height - row, kernel_height);\n            for (int kr = 0; kr < overlap_height; kr++) {\n                for (int kc = 0; kc < overlap_width; kc++) {\n          const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n          const int kernel_addr = (kr * kernel_width + kc) * 3;\n          const int m_r = (int)(image[image_addr + 0]);\n          const int m_g = (int)(image[image_addr + 1]);\n          const int m_b = (int)(image[image_addr + 2]);\n          const int t_r = (int)(kernel[kernel_addr + 0]);\n          const int t_g = (int)(kernel[kernel_addr + 1]);\n          const int t_b = (int)(kernel[kernel_addr + 2]);\n          const int error = abs(m_r - t_r) + abs(m_g - t_g) + abs(m_b - t_b);\n          sad_result += error;\n        }\n      }\n\n      int norm_sad = (int)(sad_result / (float)kernel_size);\n\n      int my_index_in_sad_array = row * image_width + col;\n      if (my_index_in_sad_array < sad_array_size) {\n        sad_array[my_index_in_sad_array] = norm_sad;\n      }\n    }\n  }\n\n  int m = THRESHOLD;\n    for (int i = 0; i < sad_array_size; i++) \n    m = min(m, sad_array[i]);\n\n  int n = 0; \n    for (int i = 0; i < sad_array_size; i++) {\n    if (sad_array[i] == m) n++;\n  }\n\n  auto kend = std::chrono::steady_clock::now();\n  kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n  min_mse = m;\n  num_occurrences = n;\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n  float elapsed_time; \n\n    {\n    \n\n    double kernel_time = 0.0;\n\n    auto begin = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n\n      compute_sad_array(\n          h_sad_array, h_main_image, h_template_image, sad_array_size, \n          h_min_mse, h_num_occurances,\n          main_width, main_height,\n          template_width, template_height, template_size,\n          kernel_time);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n    std::cout << \"Parallel Computation Results: \" << std::endl;\n    std::cout << \"Kernel time in msec: \" << kernel_time << std::endl; \n    std::cout << \"Elapsed time in msec = \" << elapsed_time << std::endl; \n    std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n    std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n    std::cout << \"Found Minimum:  \" << h_min_mse << std::endl;\n    std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n  }\n\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}"}}
{"kernel_name": "sad", "parallel_api": "sycl", "code": {"main.cpp": "#include <iostream>\n#include <chrono>\n#include <sycl/sycl.hpp>\n#include \"bitmap_image.hpp\"\n\n#define BLOCK_SIZE_X  16\n#define BLOCK_SIZE_Y  16\n#define BLOCK_SIZE    (BLOCK_SIZE_X * BLOCK_SIZE_Y)\n\n#define THRESHOLD     20\n#define FOUND_MIN     5000\n#define min(a, b) ((a) < (b) ? (a) : (b))\n#define syncthreads() item.barrier(sycl::access::fence_space::local_space)\n\nvoid compute_sad_array(\n    sycl::nd_item<2> &item,\n                    int*__restrict sad_array,\n    const unsigned char*__restrict image,\n    const unsigned char*__restrict kernel,\n    const int sad_array_size,\n    const int image_width,\n    const int image_height,\n    const int kernel_width,\n    const int kernel_height,\n    const int kernel_size)\n{\n  int col = item.get_global_id(1);\n  int row = item.get_global_id(0);\n  int sad_result = 0;\n\n  if (row < image_height && col < image_width) {\n    const int overlap_width = min(image_width - col, kernel_width);\n    const int overlap_height = min(image_height - row, kernel_height);\n    #pragma unroll 4\n    for (int kr = 0; kr < overlap_height; kr++) {\n      #pragma unroll 4\n      for (int kc = 0; kc < overlap_width; kc++) {\n        const int image_addr = ((row + kr) * image_width + (col + kc)) * 3;\n        const int kernel_addr = (kr * kernel_width + kc) * 3;\n        const int m_r = (int)(image[image_addr + 0]);\n        const int m_g = (int)(image[image_addr + 1]);\n        const int m_b = (int)(image[image_addr + 2]);\n        const int t_r = (int)(kernel[kernel_addr + 0]);\n        const int t_g = (int)(kernel[kernel_addr + 1]);\n        const int t_b = (int)(kernel[kernel_addr + 2]);\n        const int error = sycl::abs(m_r - t_r) + sycl::abs(m_g - t_g) + sycl::abs(m_b - t_b);\n        sad_result += error;\n      }\n    }\n\n    int norm_sad = (int)(sad_result / (float)kernel_size);\n\n    int my_index_in_sad_array = row * image_width + col;\n    if (my_index_in_sad_array < sad_array_size) {\n      sad_array[my_index_in_sad_array] = norm_sad;\n    }\n  }\n}\n\n\nvoid find_min_in_sad_array(\n    sycl::nd_item<1> &item,\n    const int sad_array_size,\n          int* __restrict cache,\n    const int* __restrict sad_array,\n          int* __restrict min_sad)\n{\n  unsigned int lid = item.get_local_id(0);\n  unsigned int bsz = item.get_local_range(0);\n  unsigned int gid = item.get_group(0) * bsz + lid;\n  unsigned int stride = item.get_group_range(0) * bsz;\n  unsigned int offset = 0;\n\n  int temp = FOUND_MIN;\n  while (gid + offset < sad_array_size) {\n    temp = min(temp, sad_array[gid + offset]);\n    offset += stride;\n  }\n\n  cache[lid] = temp;\n\n  syncthreads();\n\n  unsigned int i = bsz / 2;\n  while (i != 0) {\n    if (lid < i)\n      cache[lid] = min(cache[lid], cache[lid + i]);\n    syncthreads();\n    i /= 2;\n  }\n\n  \n\n  if (lid == 0) {\n    \n\n    auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (min_sad[0]);\n    ao.fetch_min(cache[0]);\n  }\n}\n\nvoid get_num_of_occurrences(\n    sycl::nd_item<1> &item,\n    const int sad_array_size,\n          int &s,\n    const int*__restrict sad_array,\n    const int*__restrict min_sad,\n          int*__restrict num_occurrences)\n{\n  unsigned int gid = item.get_global_id(0);\n\n  if (gid < sad_array_size) {\n    unsigned int lid = item.get_local_id(0);\n\n    if (lid == 0) s = 0;\n\n    syncthreads();\n\n    if (sad_array[gid] == *min_sad) {\n      \n\n      auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (s);\n      ao.fetch_add(1);\n    }\n\n    syncthreads();\n\n    \n\n    if (lid == 0) {\n      \n\n      auto ao = sycl::atomic_ref<int,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::device,\n              sycl::access::address_space::global_space> (num_occurrences[0]);\n      ao.fetch_add(s);\n    }\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 4) {\n    std::cerr << \"Usage: ./main <image> <template image> <repeat>\\n\";\n    return 1;\n  }\n\n  bitmap_image main_image(argv[1]);\n  bitmap_image template_image(argv[2]);\n  const int repeat = atoi(argv[3]);\n\n  const int main_width = main_image.width();\n  const int main_height = main_image.height();\n  const int main_size = main_width * main_height;\n\n  const int template_width = template_image.width();\n  const int template_height = template_image.height();\n  const int template_size = template_width * template_height;\n\n  const int height_difference = main_height - template_height;\n  const int width_difference = main_width - template_width;\n  const int sad_array_size = (height_difference + 1) * (width_difference + 1);\n\n  \n\n  unsigned char* h_main_image = new unsigned char[3 * main_size];\n\n  for (int row = 0; row < main_height; row++) {\n    for (int col = 0; col < main_width; col++) {\n      rgb_t colors;\n      main_image.get_pixel(col, row, colors);\n      h_main_image[(row * main_width + col) * 3 + 0] = colors.red;\n      h_main_image[(row * main_width + col) * 3 + 1] = colors.green;\n      h_main_image[(row * main_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  unsigned char* h_template_image = new unsigned char[3 * template_size];\n\n  for (int row = 0; row < template_height; row++) {\n    for (int col = 0; col < template_width; col++) {\n      rgb_t colors;\n      template_image.get_pixel(col, row, colors);\n      h_template_image[(row * template_width + col) * 3 + 0] = colors.red;\n      h_template_image[(row * template_width + col) * 3 + 1] = colors.green;\n      h_template_image[(row * template_width + col) * 3 + 2] = colors.blue;\n    }\n  }\n\n  int* h_sad_array = new int[sad_array_size];\n  int h_num_occurances;\n  int h_min_mse;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  unsigned char *d_main_image = sycl::malloc_device<unsigned char>(3 * main_size, q);\n  q.memcpy(d_main_image, h_main_image, 3 * main_size * sizeof(unsigned char));\n\n  unsigned char *d_template_image = sycl::malloc_device<unsigned char>(3 * template_size, q);\n  q.memcpy(d_template_image, h_template_image, 3 * template_size * sizeof(unsigned char));\n\n  int *d_sad_array = sycl::malloc_device<int>(sad_array_size, q);\n  int *d_min_mse = sycl::malloc_device<int>(1, q);\n  int *d_num_occurances = sycl::malloc_device<int>(1, q);\n\n  sycl::range<2> gws ((unsigned int)ceilf((float)main_height / BLOCK_SIZE_Y) * BLOCK_SIZE_Y,\n                      (unsigned int)ceilf((float)main_width / BLOCK_SIZE_X) * BLOCK_SIZE_X );\n  sycl::range<2> lws (BLOCK_SIZE_Y, BLOCK_SIZE_X);\n\n  sycl::range<1> gws2 ((unsigned int)ceilf((float)sad_array_size / BLOCK_SIZE) * BLOCK_SIZE);\n  sycl::range<1> lws2 (BLOCK_SIZE);\n\n  \n\n  double kernel_time = 0.0;\n\n  auto begin = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n\n    h_min_mse = THRESHOLD;\n\n    q.memset(d_num_occurances, 0, sizeof(int));\n    q.memcpy(d_min_mse, &h_min_mse, sizeof(int));\n\n    q.wait();\n    auto kbegin = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class sad>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        compute_sad_array (\n          item,\n          d_sad_array,\n          d_main_image,\n          d_template_image,\n          sad_array_size,\n          main_width, main_height,\n          template_width, template_height,\n          template_size);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<int> cache (lws2, cgh);\n      cgh.parallel_for<class find_min>(\n        sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n        find_min_in_sad_array (\n          item,\n          sad_array_size,\n          cache.get_pointer(),\n          d_sad_array,\n          d_min_mse);\n      });\n    });\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<int, 0> sum (cgh);\n      cgh.parallel_for<class count>(\n        sycl::nd_range<1>(gws2, lws2), [=] (sycl::nd_item<1> item) {\n        get_num_of_occurrences (\n          item,\n          sad_array_size,\n          sum,\n          d_sad_array,\n          d_min_mse,\n          d_num_occurances);\n      });\n    });\n\n    q.wait();\n    auto kend = std::chrono::steady_clock::now();\n    kernel_time += std::chrono::duration_cast<std::chrono::milliseconds> (kend - kbegin).count();\n\n    q.memcpy(&h_min_mse, d_min_mse, sizeof(int));\n    q.memcpy(&h_num_occurances, d_num_occurances, sizeof(int));\n  }\n  q.wait();\n\n  auto end = std::chrono::steady_clock::now();\n  float elapsed_time = std::chrono::duration_cast<std::chrono::milliseconds> (end - begin).count();\n\n  std::cout << \"Parallel Computation Results: \" << std::endl;\n  std::cout << \"Kernel time in msec: \" << kernel_time << std::endl;\n  std::cout << \"Elapsed time in msec = \" << elapsed_time << std::endl;\n  std::cout << \"Main Image Dimensions: \" << main_width << \"*\" << main_height << std::endl;\n  std::cout << \"Template Image Dimensions: \" << template_width << \"*\" << template_height << std::endl;\n  std::cout << \"Found Minimum:  \" << h_min_mse << std::endl;\n  std::cout << \"Number of Occurances: \" << h_num_occurances << std::endl;\n\n  sycl::free(d_main_image, q);\n  sycl::free(d_template_image, q);\n  sycl::free(d_sad_array, q);\n  sycl::free(d_min_mse, q);\n  sycl::free(d_num_occurances, q);\n  delete[] h_main_image;\n  delete[] h_template_image;\n  delete[] h_sad_array;\n  return 0;\n}\n"}}
{"kernel_name": "sddmm-batch", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h> \n#include <chrono>\n#include <cuda_runtime_api.h>\n#include <cusparse.h>\n#include \"utils.h\"\n\n#define CHECK_CUDA(func)                                                       \\\n{                                                                              \\\n    cudaError_t status = (func);                                               \\\n    if (status != cudaSuccess) {                                               \\\n        printf(\"CUDA API failed at line %d with error: %s (%d)\\n\",             \\\n               __LINE__, cudaGetErrorString(status), status);                  \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\n#define CHECK_CUSPARSE(func)                                                   \\\n{                                                                              \\\n    cusparseStatus_t status = (func);                                          \\\n    if (status != CUSPARSE_STATUS_SUCCESS) {                                   \\\n        printf(\"CUSPARSE API failed at line %d with error: %s (%d)\\n\",         \\\n               __LINE__, cusparseGetErrorString(status), status);              \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  if (argc != 8) {\n    printf(\"Single-precision batched dense matrix - dense matrix multiplication into sparse matrix,\\n\");\n    printf(\"where the sparse matrix is represented in CSR (Compressed Sparse Row) storage format\\n\");\n    printf(\"Usage %s <number of batches> <M> <K> <N> <number of non-zero elements> <repeat> <verify>\\n\", argv[0]);\n    printf(\"SDDM (A, B, C) where (A: M * K, B: K * N, C: M * N)\\n\");\n    return 1;\n  }\n\n  int b, m, k, n, nnz, verify;\n\n  b = atoi(argv[1]); \n\n  m = atoi(argv[2]);\n  k = atoi(argv[3]);\n  n = atoi(argv[4]);\n  nnz = atoi(argv[5]);\n  repeat = atoi(argv[6]);\n  verify = atoi(argv[7]);\n\n  const int A_num_rows   = m;\n  const int A_num_cols   = k;\n  const int B_num_rows   = A_num_cols;\n  const int B_num_cols   = n;\n  const int C_nnz     = nnz;\n  const int lda       = A_num_cols;\n  const int ldb       = B_num_cols;\n  const int A_size    = lda * A_num_rows;\n  const int B_size    = ldb * B_num_rows;\n  const int C_size    = A_num_rows * B_num_cols;\n\n  const size_t value_size_bytes  = b * C_nnz * sizeof(float);\n  const size_t colidx_size_bytes = b * C_nnz * sizeof(int);\n  const size_t rowidx_size_bytes = b * (A_num_rows + 1) * sizeof(size_t);\n\n  float *hA = (float*) malloc (b * A_size * sizeof(float));\n  float *hB = (float*) malloc (b * B_size * sizeof(float));\n\n  \n\n  float *hC = (float*) malloc (b * C_size * sizeof(float));\n\n  float *hC_values = (float*) malloc (value_size_bytes);\n  int *hC_columns = (int*) malloc (colidx_size_bytes);\n  int *hC_offsets = (int*) malloc (rowidx_size_bytes);\n  float *hC_result  = (float*) malloc (value_size_bytes);\n\n  for (int i = 0; i < b; i++) {\n    init_matrix(hA + i * A_size, A_num_rows, A_num_cols, A_size);\n    init_matrix(hB + i * B_size, B_num_rows, B_num_cols, B_size);\n    init_matrix(hC + i * C_size, A_num_rows, B_num_cols, C_nnz);\n\n    \n\n    init_csr(hC_offsets + i * (A_num_rows+1),\n             hC_values + i * C_nnz,\n             hC_columns + i * C_nnz,\n             hC + i * C_size,\n             A_num_rows, B_num_cols, C_nnz);\n  }\n\n  if (verify) {\n    printf(\"Computing the reference SDDMM results (batch size = %d)..\\n\", b);\n    for (int i = 0; i < b; i++) {\n      sddmm (hA + i * A_size,\n             hB + i * B_size,\n             hC + i * C_size,\n             hC_result + i * C_nnz,\n             hC_offsets + i * (A_num_rows+1),\n             hC_columns + i * C_nnz,\n             A_num_cols, A_num_rows, B_num_cols);\n    }\n    printf(\"Done\\n\");\n  }\n\n  float alpha        = 1.0f;\n  float beta         = 0.0f;\n  \n\n  \n\n  int *dC_columns;\n  size_t *dC_offsets;\n  float *dC_values, *dB, *dA;\n  CHECK_CUDA( cudaMalloc((void**) &dA, b * A_size * sizeof(float)) )\n  CHECK_CUDA( cudaMalloc((void**) &dB, b * B_size * sizeof(float)) )\n  CHECK_CUDA( cudaMalloc((void**) &dC_offsets, rowidx_size_bytes) )\n  CHECK_CUDA( cudaMalloc((void**) &dC_columns, colidx_size_bytes) )\n  CHECK_CUDA( cudaMalloc((void**) &dC_values,  value_size_bytes) )\n\n  CHECK_CUDA( cudaMemcpy(dA, hA, b * A_size * sizeof(float),\n                         cudaMemcpyHostToDevice) )\n  CHECK_CUDA( cudaMemcpy(dB, hB, b * B_size * sizeof(float),\n                         cudaMemcpyHostToDevice) )\n  CHECK_CUDA( cudaMemcpy(dC_offsets, hC_offsets, rowidx_size_bytes,\n                         cudaMemcpyHostToDevice) )\n  CHECK_CUDA( cudaMemcpy(dC_columns, hC_columns, colidx_size_bytes,\n                         cudaMemcpyHostToDevice) )\n  CHECK_CUDA( cudaMemcpy(dC_values, hC_values, value_size_bytes,\n                         cudaMemcpyHostToDevice) )\n  \n\n  \n\n  cusparseHandle_t     handle = NULL;\n  cusparseDnMatDescr_t matA, matB;\n  cusparseSpMatDescr_t matC;\n  void*                dBuffer    = NULL;\n  size_t               bufferSize = 0;\n  CHECK_CUSPARSE( cusparseCreate(&handle) )\n  \n\n  CHECK_CUSPARSE( cusparseCreateDnMat(&matA, A_num_rows, A_num_cols, lda, dA,\n                                      CUDA_R_32F, CUSPARSE_ORDER_ROW) )\n  CHECK_CUSPARSE( cusparseDnMatSetStridedBatch(matA, b, A_size) )\n\n  \n\n  CHECK_CUSPARSE( cusparseCreateDnMat(&matB, A_num_cols, B_num_cols, ldb, dB,\n                                      CUDA_R_32F, CUSPARSE_ORDER_ROW) )\n  CHECK_CUSPARSE( cusparseDnMatSetStridedBatch(matB, b, B_size) )\n\n  \n\n  CHECK_CUSPARSE( cusparseCreateCsr(&matC, A_num_rows, B_num_cols, C_nnz,\n                                    dC_offsets, dC_columns, dC_values,\n                                    CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I,\n                                    CUSPARSE_INDEX_BASE_ZERO, CUDA_R_32F) )\n  CHECK_CUSPARSE( cusparseCsrSetStridedBatch(matC, b, A_num_rows+1, C_nnz) )\n\n  \n\n  CHECK_CUSPARSE( cusparseSDDMM_bufferSize(\n                               handle,\n                               CUSPARSE_OPERATION_NON_TRANSPOSE,\n                               CUSPARSE_OPERATION_NON_TRANSPOSE,\n                               &alpha, matA, matB, &beta, matC, CUDA_R_32F,\n                               CUSPARSE_SDDMM_ALG_DEFAULT, &bufferSize) )\n  CHECK_CUDA( cudaMalloc(&dBuffer, bufferSize) )\n\n  \n\n  CHECK_CUSPARSE( cusparseSDDMM_preprocess(\n                                handle,\n                                CUSPARSE_OPERATION_NON_TRANSPOSE,\n                                CUSPARSE_OPERATION_NON_TRANSPOSE,\n                                &alpha, matA, matB, &beta, matC, CUDA_R_32F,\n                                CUSPARSE_SDDMM_ALG_DEFAULT, dBuffer) )\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    CHECK_CUSPARSE( cusparseSDDMM(handle,\n                                  CUSPARSE_OPERATION_NON_TRANSPOSE,\n                                  CUSPARSE_OPERATION_NON_TRANSPOSE,\n                                  &alpha, matA, matB, &beta, matC, CUDA_R_32F,\n                                  CUSPARSE_SDDMM_ALG_DEFAULT, dBuffer) )\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SDDMM: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  CHECK_CUSPARSE( cusparseDestroyDnMat(matA) )\n  CHECK_CUSPARSE( cusparseDestroyDnMat(matB) )\n  CHECK_CUSPARSE( cusparseDestroySpMat(matC) )\n  CHECK_CUSPARSE( cusparseDestroy(handle) )\n\n  \n\n  if (verify) {\n    \n\n    CHECK_CUDA( cudaMemcpy(hC_values, dC_values, value_size_bytes,\n                           cudaMemcpyDeviceToHost) )\n    int correct = 1;\n\n    for (int i = 0; i < b; i++) {\n      float *v =  hC_values + i * C_nnz;\n      float *r =  hC_result + i * C_nnz;\n      for (int j = 0; j < C_nnz; j++) {\n        if (fabsf(v[j] - r[j]) > 1e-2f) {\n          printf(\"@batch%d index%d: %f != %f\\n\", i, j, v[j], r[j]);\n          correct = 0;\n          break;\n        }\n      }\n      if (!correct) break;\n    }\n    if (correct)\n        printf(\"sddmm_csr_batched_example test PASSED\\n\");\n    else\n        printf(\"sddmm_csr_batched_example test FAILED: wrong result\\n\");\n  }\n  \n\n  \n\n  CHECK_CUDA( cudaFree(dBuffer) )\n  CHECK_CUDA( cudaFree(dA) )\n  CHECK_CUDA( cudaFree(dB) )\n  CHECK_CUDA( cudaFree(dC_offsets) )\n  CHECK_CUDA( cudaFree(dC_columns) )\n  CHECK_CUDA( cudaFree(dC_values) )\n\n  free(hA);\n  free(hB);\n  free(hC);\n  free(hC_values);\n  free(hC_columns);\n  free(hC_offsets);\n  free(hC_result);\n\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "sddmm-batch", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h> \n#include <chrono>\n#include <hip/hip_runtime_api.h>\n#include <hipsparse/hipsparse.h>\n#include \"utils.h\"\n\n#define CHECK_HIP(func)                                                  \\\n{                                                                        \\\n    hipError_t status = (func);                                          \\\n    if (status != hipSuccess) {                                          \\\n        printf(\"HIP API failed at line %d with error: %s (%d)\\n\",        \\\n               __LINE__, hipGetErrorString(status), status);             \\\n        return EXIT_FAILURE;                                             \\\n    }                                                                    \\\n}\n\n#define CHECK_HIPSPARSE_ERROR_CASE__(token_) \\\n    case token_:                             \\\n        fprintf(stderr, \"HIPSPARSE API failed at line %d with error: %s\\n\",         \\\n               __LINE__, #token_); \\\n        break\n\n#define CHECK_HIPSPARSE(error)                                                      \\\n    {                                                                                     \\\n        auto local_error = (error);                                                       \\\n        if(local_error != HIPSPARSE_STATUS_SUCCESS)                                       \\\n        {                                                                                 \\\n            fprintf(stderr, \"hipSPARSE error: \");                                         \\\n            switch(local_error)                                                           \\\n            {                                                                             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_SUCCESS);                   \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_NOT_INITIALIZED);           \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ALLOC_FAILED);              \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INVALID_VALUE);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ARCH_MISMATCH);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_MAPPING_ERROR);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_EXECUTION_FAILED);          \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INTERNAL_ERROR);            \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_MATRIX_TYPE_NOT_SUPPORTED); \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ZERO_PIVOT);                \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_NOT_SUPPORTED);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INSUFFICIENT_RESOURCES);    \\\n            }                                                                             \\\n            fprintf(stderr, \"\\n\");                                                        \\\n            return local_error;                                                           \\\n        }                                                                                 \\\n    }                                                                                     \n\n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  if (argc != 8) {\n    printf(\"Single-precision batched dense matrix - dense matrix multiplication into sparse matrix,\\n\");\n    printf(\"where the sparse matrix is represented in CSR (Compressed Sparse Row) storage format\\n\");\n    printf(\"Usage %s <number of batches> <M> <K> <N> <number of non-zero elements> <repeat> <verify>\\n\", argv[0]);\n    printf(\"SDDM (A, B, C) where (A: M * K, B: K * N, C: M * N)\\n\");\n    return 1;\n  }\n\n  int b, m, k, n, nnz, verify;\n\n  b = atoi(argv[1]); \n\n  m = atoi(argv[2]);\n  k = atoi(argv[3]);\n  n = atoi(argv[4]);\n  nnz = atoi(argv[5]);\n  repeat = atoi(argv[6]);\n  verify = atoi(argv[7]);\n\n  const int A_num_rows   = m;\n  const int A_num_cols   = k;\n  const int B_num_rows   = A_num_cols;\n  const int B_num_cols   = n;\n  const int C_nnz     = nnz;\n  const int lda       = A_num_cols;\n  const int ldb       = B_num_cols;\n  const int A_size    = lda * A_num_rows;\n  const int B_size    = ldb * B_num_rows;\n  const int C_size    = A_num_rows * B_num_cols;\n\n  const size_t value_size_bytes  = b * C_nnz * sizeof(float);\n  const size_t colidx_size_bytes = b * C_nnz * sizeof(int);\n  const size_t rowidx_size_bytes = b * (A_num_rows + 1) * sizeof(size_t);\n\n  float *hA = (float*) malloc (b * A_size * sizeof(float));\n  float *hB = (float*) malloc (b * B_size * sizeof(float));\n\n  \n\n  float *hC = (float*) malloc (b * C_size * sizeof(float));\n\n  float *hC_values = (float*) malloc (value_size_bytes);\n  int *hC_columns = (int*) malloc (colidx_size_bytes);\n  int *hC_offsets = (int*) malloc (rowidx_size_bytes);\n  float *hC_result  = (float*) malloc (value_size_bytes);\n\n  for (int i = 0; i < b; i++) {\n    init_matrix(hA + i * A_size, A_num_rows, A_num_cols, A_size);\n    init_matrix(hB + i * B_size, B_num_rows, B_num_cols, B_size);\n    init_matrix(hC + i * C_size, A_num_rows, B_num_cols, C_nnz);\n\n    \n\n    init_csr(hC_offsets + i * (A_num_rows+1),\n             hC_values + i * C_nnz,\n             hC_columns + i * C_nnz,\n             hC + i * C_size,\n             A_num_rows, B_num_cols, C_nnz);\n  }\n\n  if (verify) {\n    printf(\"Computing the reference SDDMM results (batch size = %d)..\\n\", b);\n    for (int i = 0; i < b; i++) {\n      sddmm (hA + i * A_size,\n             hB + i * B_size,\n             hC + i * C_size,\n             hC_result + i * C_nnz,\n             hC_offsets + i * (A_num_rows+1),\n             hC_columns + i * C_nnz,\n             A_num_cols, A_num_rows, B_num_cols);\n    }\n    printf(\"Done\\n\");\n  }\n\n  float alpha        = 1.0f;\n  float beta         = 0.0f;\n  \n\n  \n\n  int *dC_columns;\n  size_t *dC_offsets;\n  float *dC_values, *dB, *dA;\n  CHECK_HIP( hipMalloc((void**) &dA, b * A_size * sizeof(float)) )\n  CHECK_HIP( hipMalloc((void**) &dB, b * B_size * sizeof(float)) )\n  CHECK_HIP( hipMalloc((void**) &dC_offsets, rowidx_size_bytes) )\n  CHECK_HIP( hipMalloc((void**) &dC_columns, colidx_size_bytes) )\n  CHECK_HIP( hipMalloc((void**) &dC_values,  value_size_bytes) )\n\n  CHECK_HIP( hipMemcpy(dA, hA, b * A_size * sizeof(float),\n                       hipMemcpyHostToDevice) )\n  CHECK_HIP( hipMemcpy(dB, hB, b * B_size * sizeof(float),\n                       hipMemcpyHostToDevice) )\n  CHECK_HIP( hipMemcpy(dC_offsets, hC_offsets, rowidx_size_bytes,\n                       hipMemcpyHostToDevice) )\n  CHECK_HIP( hipMemcpy(dC_columns, hC_columns, colidx_size_bytes,\n                       hipMemcpyHostToDevice) )\n  CHECK_HIP( hipMemcpy(dC_values, hC_values, value_size_bytes,\n                       hipMemcpyHostToDevice) )\n  \n\n  \n\n  hipsparseHandle_t     handle = NULL;\n  hipsparseDnMatDescr_t matA, matB;\n  hipsparseSpMatDescr_t matC;\n  void*                 dBuffer    = NULL;\n  size_t                bufferSize = 0;\n  CHECK_HIPSPARSE( hipsparseCreate(&handle) )\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateDnMat(&matA, A_num_rows, A_num_cols, lda, dA,\n                                        HIP_R_32F, HIPSPARSE_ORDER_ROW) )\n  CHECK_HIPSPARSE( hipsparseDnMatSetStridedBatch(matA, b, A_size) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateDnMat(&matB, A_num_cols, B_num_cols, ldb, dB,\n                                        HIP_R_32F, HIPSPARSE_ORDER_ROW) )\n  CHECK_HIPSPARSE( hipsparseDnMatSetStridedBatch(matB, b, B_size) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateCsr(&matC, A_num_rows, B_num_cols, C_nnz,\n                                      dC_offsets, dC_columns, dC_values,\n                                      HIPSPARSE_INDEX_32I, HIPSPARSE_INDEX_32I,\n                                      HIPSPARSE_INDEX_BASE_ZERO, HIP_R_32F) )\n  CHECK_HIPSPARSE( hipsparseCsrSetStridedBatch(matC, b, A_num_rows+1, C_nnz) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseSDDMM_bufferSize(\n                               handle,\n                               HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                               HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                               &alpha, matA, matB, &beta, matC, HIP_R_32F,\n                               HIPSPARSE_SDDMM_ALG_DEFAULT, &bufferSize) )\n  CHECK_HIP( hipMalloc(&dBuffer, bufferSize) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseSDDMM_preprocess(\n                                handle,\n                                HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                                HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                                &alpha, matA, matB, &beta, matC, HIP_R_32F,\n                                HIPSPARSE_SDDMM_ALG_DEFAULT, dBuffer) )\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    CHECK_HIPSPARSE( hipsparseSDDMM(handle,\n                                    HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                                    HIPSPARSE_OPERATION_NON_TRANSPOSE,\n                                    &alpha, matA, matB, &beta, matC, HIP_R_32F,\n                                    HIPSPARSE_SDDMM_ALG_DEFAULT, dBuffer) )\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of SDDMM: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  CHECK_HIPSPARSE( hipsparseDestroyDnMat(matA) )\n  CHECK_HIPSPARSE( hipsparseDestroyDnMat(matB) )\n  CHECK_HIPSPARSE( hipsparseDestroySpMat(matC) )\n  CHECK_HIPSPARSE( hipsparseDestroy(handle) )\n\n  \n\n  if (verify) {\n    \n\n    CHECK_HIP( hipMemcpy(hC_values, dC_values, value_size_bytes,\n                         hipMemcpyDeviceToHost) )\n    int correct = 1;\n\n    for (int i = 0; i < b; i++) {\n      float *v =  hC_values + i * C_nnz;\n      float *r =  hC_result + i * C_nnz;\n      for (int j = 0; j < C_nnz; j++) {\n        if (fabsf(v[j] - r[j]) > 1e-2f) {\n          printf(\"@batch%d index%d: %f != %f\\n\", i, j, v[j], r[j]);\n          correct = 0;\n          break;\n        }\n      }\n      if (!correct) break;\n    }\n    if (correct)\n        printf(\"sddmm_csr_batched_example test PASSED\\n\");\n    else\n        printf(\"sddmm_csr_batched_example test FAILED: wrong result\\n\");\n  }\n  \n\n  \n\n  CHECK_HIP( hipFree(dBuffer) )\n  CHECK_HIP( hipFree(dA) )\n  CHECK_HIP( hipFree(dB) )\n  CHECK_HIP( hipFree(dC_offsets) )\n  CHECK_HIP( hipFree(dC_columns) )\n  CHECK_HIP( hipFree(dC_values) )\n\n  free(hA);\n  free(hB);\n  free(hC);\n  free(hC_values);\n  free(hC_columns);\n  free(hC_offsets);\n  free(hC_result);\n\n  return EXIT_SUCCESS;\n}\n"}}
{"kernel_name": "slit", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#include <cuda.h>\n#include <cufft.h>\n#include <cuComplex.h>\n#include \"reference.h\"\n\n\n\n\n#define gpuErrChk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\ninline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n{\n  if (code != cudaSuccess)\n  {\n    fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n  }\n}\n\ndouble fft2(cuDoubleComplex *inData, cuDoubleComplex *outData,\n          const unsigned int N, const int repeat)\n{\n  cufftDoubleComplex *d_inData = NULL;\n\n  const size_t data_bytes = sizeof(cufftDoubleComplex) * N * N;\n\n  gpuErrChk(cudaMalloc(&d_inData, data_bytes));\n\n  cufftResult flag;\n  cufftHandle plan;\n\n  flag = cufftPlan2d(&plan, N, N, CUFFT_Z2Z);\n  if ( CUFFT_SUCCESS != flag ) printf(\"2D: cufftPlan2d fails!\\n\");\n\n  double time = 0.0;\n  for (int i = 0; i < repeat; i++) {\n    gpuErrChk(cudaMemcpy(d_inData, inData, data_bytes, cudaMemcpyHostToDevice));\n\n    gpuErrChk(cudaDeviceSynchronize());\n\n    auto start = std::chrono::steady_clock::now();\n\n    flag = cufftExecZ2Z(plan, d_inData, d_inData, CUFFT_FORWARD);\n    if ( CUFFT_SUCCESS != flag ) printf(\"2D: cufftExecR2C fails!\\n\");\n\n    gpuErrChk(cudaDeviceSynchronize());\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  gpuErrChk(cudaMemcpy(outData, d_inData, data_bytes, cudaMemcpyDeviceToHost));\n\n  flag = cufftDestroy(plan);\n  if ( CUFFT_SUCCESS != flag ) printf(\"2D: cufftDestroy fails!\\n\");\n  gpuErrChk(cudaFree(d_inData));\n\n  return time * 1e-6 / repeat;\n}\n\n\nint main(int argc, char** argv){\n\n  if (argc != 3) {\n    printf(\"Usage: %s <the transform size in the x and y dimensions> <repeat>\\n\",\n           argv[0]);\n    return 1;\n  }\n  const int N = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Running FFT for %d x %d = %d = 2 ^ %d data points...\\n\",\n         N, N, N*N, (int)(log(N*N)/log(2)));\n\n  \n\n  cuDoubleComplex * inputData = (cuDoubleComplex *)malloc(N * N * sizeof(cuDoubleComplex));\n\n  \n\n  cuDoubleComplex * fftData = (cuDoubleComplex *)malloc(N * N * sizeof(cuDoubleComplex));\n\n  \n\n  double * outputData = (double *)malloc(N * N * sizeof(double));\n\n  \n\n  double * inputData_ref = (double *)malloc(N * N * sizeof(double));\n  double * outputData_ref = (double *)malloc(N * N * sizeof(double));\n\n  const int slit_height = 4;\n  const int slit_width  = 2;\n  const int slit_dist   = 8;\n\n  \n\n  for (int j = 0; j < N; j++){\n    for (int i = 0; i < N; i++){\n      inputData[j * N + i] = make_cuDoubleComplex(0.0, 0.0);\n      inputData_ref[j * N + i] = 0.0;\n      if ((abs(i-N/2) <= slit_dist+slit_width) &&\n          (abs(i-N/2) >= slit_dist) &&\n          (abs(j-N/2) <= slit_height)){\n        inputData[j * N + i] = make_cuDoubleComplex(1.0, 0.0);\n        inputData_ref[j * N + i] = 1.0;\n      }\n    }\n  }\n\n  double avg_time = fft2(inputData, fftData, N, repeat);\n\n  printf(\"Average execution time of FFT: %lf ms\\n\", avg_time);\n\n  for(int i = 0; i < N*N; i++){\n    outputData[i] = cuCreal(fftData[i]) * cuCreal(fftData[i]) +\n                    cuCimag(fftData[i]) * cuCimag(fftData[i]);\n  }\n\n  reference(inputData_ref, outputData_ref, N);\n\n  bool ok = true;\n  for (int i = 0;i < N * N; i++) {\n    if (outputData[i] - outputData_ref[i] > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  free(inputData);\n  free(inputData_ref);\n  free(fftData);\n  free(outputData);\n  free(outputData_ref);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  return 0;\n}\n"}}
{"kernel_name": "slit", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#include <hip/hip_runtime.h>\n#include <hipfft.h>\n#include <hip/hip_complex.h>\n#include \"reference.h\"\n\n\n\n\n#define gpuErrChk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\ninline void gpuAssert(hipError_t code, const char *file, int line, bool abort=true)\n{\n  if (code != hipSuccess)\n  {\n    fprintf(stderr,\"GPUassert: %s %s %d\\n\", hipGetErrorString(code), file, line);\n  }\n}\n\ndouble fft2(hipDoubleComplex *inData, hipDoubleComplex *outData,\n          const unsigned int N, const int repeat)\n{\n  hipfftDoubleComplex *d_inData = NULL;\n\n  const size_t data_bytes = sizeof(hipfftDoubleComplex) * N * N;\n\n  gpuErrChk(hipMalloc(&d_inData, data_bytes));\n\n  hipfftResult flag;\n  hipfftHandle plan;\n\n  flag = hipfftPlan2d(&plan, N, N, HIPFFT_Z2Z);\n  if ( HIPFFT_SUCCESS != flag ) printf(\"2D: hipfftPlan2d fails!\\n\");\n\n  double time = 0.0;\n  for (int i = 0; i < repeat; i++) {\n    gpuErrChk(hipMemcpy(d_inData, inData, data_bytes, hipMemcpyHostToDevice));\n\n    gpuErrChk(hipDeviceSynchronize());\n\n    auto start = std::chrono::steady_clock::now();\n\n    flag = hipfftExecZ2Z(plan, d_inData, d_inData, HIPFFT_FORWARD);\n    if ( HIPFFT_SUCCESS != flag ) printf(\"2D: hipfftExecR2C fails!\\n\");\n\n    gpuErrChk(hipDeviceSynchronize());\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  }\n\n  gpuErrChk(hipMemcpy(outData, d_inData, data_bytes, hipMemcpyDeviceToHost));\n\n  flag = hipfftDestroy(plan);\n  if ( HIPFFT_SUCCESS != flag ) printf(\"2D: hipfftDestroy fails!\\n\");\n  gpuErrChk(hipFree(d_inData));\n\n  return time * 1e-6 / repeat;\n}\n\n\nint main(int argc, char** argv){\n\n  if (argc != 3) {\n    printf(\"Usage: %s <the transform size in the x and y dimensions> <repeat>\\n\",\n           argv[0]);\n    return 1;\n  }\n  const int N = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Running FFT for %d x %d = %d = 2 ^ %d data points...\\n\",\n         N, N, N*N, (int)(log(N*N)/log(2)));\n\n  \n\n  hipDoubleComplex * inputData = (hipDoubleComplex *)malloc(N * N * sizeof(hipDoubleComplex));\n\n  \n\n  hipDoubleComplex * fftData = (hipDoubleComplex *)malloc(N * N * sizeof(hipDoubleComplex));\n\n  \n\n  double * outputData = (double *)malloc(N * N * sizeof(double));\n\n  \n\n  double * inputData_ref = (double *)malloc(N * N * sizeof(double));\n  double * outputData_ref = (double *)malloc(N * N * sizeof(double));\n\n  const int slit_height = 4;\n  const int slit_width  = 2;\n  const int slit_dist   = 8;\n\n  \n\n  for (int j = 0; j < N; j++){\n    for (int i = 0; i < N; i++){\n      inputData[j * N + i] = make_hipDoubleComplex(0.0, 0.0);\n      inputData_ref[j * N + i] = 0.0;\n      if ((abs(i-N/2) <= slit_dist+slit_width) &&\n          (abs(i-N/2) >= slit_dist) &&\n          (abs(j-N/2) <= slit_height)){\n        inputData[j * N + i] = make_hipDoubleComplex(1.0, 0.0);\n        inputData_ref[j * N + i] = 1.0;\n      }\n    }\n  }\n\n  double avg_time = fft2(inputData, fftData, N, repeat);\n\n  printf(\"Average execution time of FFT: %lf ms\\n\", avg_time);\n\n  for(int i = 0; i < N*N; i++){\n    outputData[i] = hipCreal(fftData[i]) * hipCreal(fftData[i]) +\n                    hipCimag(fftData[i]) * hipCimag(fftData[i]);\n  }\n\n  reference(inputData_ref, outputData_ref, N);\n\n  bool ok = true;\n  for (int i = 0;i < N * N; i++) {\n    if (outputData[i] - outputData_ref[i] > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  free(inputData);\n  free(inputData_ref);\n  free(fftData);\n  free(outputData);\n  free(outputData_ref);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  return 0;\n}\n"}}
{"kernel_name": "slit", "parallel_api": "sycl", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <complex>\n#include <stdexcept>\n#include <sycl/sycl.hpp>\n#include \"oneapi/mkl.hpp\"\n#include \"reference.h\"\n\n\n\n\ndouble fft2(std::complex<double> *inData, std::complex<double> *outData, const unsigned int N,\n            const int repeat)\n{\n  double time = 0.0;\n  try {\n    \n\n    auto exception_handler = [] (sycl::exception_list exceptions) {\n      for (std::exception_ptr const& e : exceptions) {\n        try {\n          std::rethrow_exception(e);\n        } catch(sycl::exception const& e) {\n          std::cout << \"Caught asynchronous SYCL exception:\" << std::endl\n                    << e.what() << std::endl;\n        }\n      }\n    };\n\n    sycl::queue q(\n#ifdef USE_GPU\n      sycl::gpu_selector_v,\n#else\n      sycl::cpu_selector_v,\n#endif\n      exception_handler, sycl::property::queue::in_order());\n\n    const size_t data_bytes = sizeof(std::complex<double>) * N * N;\n    std::complex<double> *d_inData =\n       (std::complex<double> *)sycl::malloc_device(data_bytes, q);\n\n    \n\n    oneapi::mkl::dft::descriptor<oneapi::mkl::dft::precision::DOUBLE,\n                                 oneapi::mkl::dft::domain::COMPLEX> desc({N, N});\n\n    \n\n    desc.set_value(oneapi::mkl::dft::config_param::NUMBER_OF_TRANSFORMS,\n                   static_cast<std::int64_t>(1));\n    desc.set_value(oneapi::mkl::dft::config_param::PLACEMENT,\n                   oneapi::mkl::dft::config_value::INPLACE); \n\n\n    \n\n    desc.commit(q);\n\n    for (int i = 0; i < repeat; i++) {\n      q.memcpy(d_inData, inData, data_bytes).wait();\n\n      auto start = std::chrono::steady_clock::now();\n\n      \n\n      oneapi::mkl::dft::compute_forward(desc, d_inData).wait();\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    }\n\n    q.memcpy(outData, d_inData, data_bytes).wait();\n\n    sycl::free(d_inData, q);\n  }\n  catch(sycl::exception const& e) {\n      std::cout << \"\\t\\tSYCL exception during FFT\" << std::endl;\n      std::cout << \"\\t\\t\" << e.what() << std::endl;\n  }\n  catch(std::runtime_error const& e) {\n      std::cout << \"\\t\\truntime exception during FFT\" << std::endl;\n      std::cout << \"\\t\\t\" << e.what() << std::endl;\n  }\n\n  return time * 1e-6 / repeat;\n}\n\n\nint main(int argc, char** argv){\n\n  if (argc != 3) {\n    printf(\"Usage: %s <the transform size in the x and y dimensions> <repeat>\\n\",\n           argv[0]);\n    return 1;\n  }\n  const int N = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  printf(\"Running FFT for %d x %d = %d = 2 ^ %d data points...\\n\",\n         N, N, N*N, (int)(log(N*N)/log(2)));\n\n  \n\n  std::complex<double> *inputData =\n      (std::complex<double> *)malloc(N * N * sizeof(std::complex<double>));\n\n  \n\n  std::complex<double> *fftData =\n      (std::complex<double> *)malloc(N * N * sizeof(std::complex<double>));\n\n  \n\n  double * outputData = (double *)malloc(N * N * sizeof(double));\n\n  \n\n  double * inputData_ref = (double *)malloc(N * N * sizeof(double));\n  double * outputData_ref = (double *)malloc(N * N * sizeof(double));\n\n  const int slit_height = 4;\n  const int slit_width  = 2;\n  const int slit_dist   = 8;\n\n  \n\n  for (int j = 0; j < N; j++){\n    for (int i = 0; i < N; i++){\n      inputData[j * N + i] = std::complex<double>(0.0, 0.0);\n      inputData_ref[j * N + i] = 0.0;\n      if ((abs(i-N/2) <= slit_dist+slit_width) &&\n          (abs(i-N/2) >= slit_dist) &&\n          (abs(j-N/2) <= slit_height)){\n        inputData[j * N + i] = std::complex<double>(1.0, 0.0);\n        inputData_ref[j * N + i] = 1.0;\n      }\n    }\n  }\n\n  double avg_time = fft2(inputData, fftData, N, repeat);\n\n  printf(\"Average execution time of FFT: %lf ms\\n\", avg_time);\n\n  for(int i = 0; i < N*N; i++){\n    outputData[i] =\n        fftData[i].real() * fftData[i].real() + fftData[i].imag() * fftData[i].imag();\n  }\n\n  reference(inputData_ref, outputData_ref, N);\n\n  bool ok = true;\n  for (int i = 0;i < N * N; i++) {\n    if (outputData[i] - outputData_ref[i] > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n\n  free(inputData);\n  free(inputData_ref);\n  free(fftData);\n  free(outputData);\n  free(outputData_ref);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  return 0;\n}\n"}}
{"kernel_name": "spsort", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <cstdlib>\n#include <cstring>\n#include <chrono>\n#include <iostream>\n#include <type_traits>\n#include <cuda_runtime.h>\n#include <cusparse.h>\n#include \"utils.h\"\n\n#define CHECK_CUDA(func)                                                       \\\n{                                                                              \\\n    cudaError_t status = (func);                                               \\\n    if (status != cudaSuccess) {                                               \\\n        printf(\"CUDA API failed at line %d with error: %s (%d)\\n\",             \\\n               __LINE__, cudaGetErrorString(status), status);                  \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\n#define CHECK_CUSPARSE(func)                                                   \\\n{                                                                              \\\n    cusparseStatus_t status = (func);                                          \\\n    if (status != CUSPARSE_STATUS_SUCCESS) {                                   \\\n        printf(\"CUSPARSE API failed at line %d with error: %s (%d)\\n\",         \\\n               __LINE__, cusparseGetErrorString(status), status);              \\\n        return EXIT_FAILURE;                                                   \\\n    }                                                                          \\\n}\n\ntemplate <typename fp, typename intType>\nint sort_sparse_matrix(intType a_nrows, intType a_ncols,\n                       intType a_nnz, int repeat)\n{\n  fp *m = (fp*) malloc (sizeof(fp) * a_nrows * a_ncols);\n  init_matrix(m, a_nrows, a_ncols, a_nnz);\n\n  intType *ia = (intType*) malloc ((a_nrows+1) * sizeof(intType));\n  intType *ja = (intType*) malloc (a_nnz * sizeof(intType));\n  fp *a = (fp*) malloc (a_nnz * sizeof(fp));\n\n  \n\n  init_csr(ia, a, ja, m, a_nrows, a_ncols, a_nnz);\n\n  \n\n  intType *ia_result = (intType*) malloc ((a_nrows+1) * sizeof(intType));\n  intType *ja_result = (intType*) malloc (a_nnz * sizeof(intType));\n  fp *a_result = (fp*) malloc (a_nnz * sizeof(fp));\n\n  \n\n  memcpy(ia_result, ia, (a_nrows+1) * sizeof(intType));\n  memcpy(ja_result, ja, a_nnz * sizeof(intType));\n  memcpy(a_result, a, a_nnz * sizeof(fp));\n  shuffle_matrix_data<fp, intType>(ia_result, ja_result, a_result, a_nrows, a_nnz);\n\n  \n\n  \n\n  intType    *a_rowptr, *a_colind, *d_permutation;\n  fp *a_val, *a_val_sorted;\n  void   *d_buffer;\n  size_t bufferSize;\n  CHECK_CUDA( cudaMalloc((void**) &a_rowptr,      (a_nrows+1) * sizeof(intType)) )\n  CHECK_CUDA( cudaMalloc((void**) &a_colind,      a_nnz * sizeof(intType)) )\n  CHECK_CUDA( cudaMalloc((void**) &a_val,         a_nnz * sizeof(fp)) )\n  CHECK_CUDA( cudaMalloc((void**) &a_val_sorted,  a_nnz * sizeof(fp)) )\n  CHECK_CUDA( cudaMalloc((void**) &d_permutation, a_nnz * sizeof(intType)) )\n\n  CHECK_CUDA( cudaMemcpy(a_rowptr, ia_result, (a_nrows+1) * sizeof(intType),\n                         cudaMemcpyHostToDevice) )\n  CHECK_CUDA( cudaMemcpy(a_colind, ja_result, a_nnz * sizeof(intType),\n                         cudaMemcpyHostToDevice) )\n  CHECK_CUDA( cudaMemcpy(a_val, a_result, a_nnz * sizeof(fp),\n                         cudaMemcpyHostToDevice) )\n\n  std::cout << \"\\n\\t\\tBasic info of the sparse matrix:\\n\";\n\n  const fp ave_nnz_per_row = static_cast<fp>(a_nnz)/a_nrows;\n  std::cout << \"\\t\\t\\tA_nrows = A_ncols = \" << a_nrows << std::endl;\n  std::cout << \"\\t\\t\\tA_nnz   = \" << a_nnz << std::endl;\n\n  intType max_nnz_per_row = 0;\n  intType min_nnz_per_row = a_nnz;\n  for (intType row = 0; row < a_nrows; ++row) {\n    const intType loc_nnz_per_row = ia[row+1] - ia[row];\n\n    if (loc_nnz_per_row > max_nnz_per_row) \n      max_nnz_per_row = loc_nnz_per_row;\n\n    if (loc_nnz_per_row < min_nnz_per_row) \n      min_nnz_per_row = loc_nnz_per_row;\n  }\n\n  std::cout << \"\\t\\t\\t\\tmin_nnz_per_row = \" << min_nnz_per_row << std::endl;\n  std::cout << \"\\t\\t\\t\\tave_nnz_per_row = \" << ave_nnz_per_row << std::endl;\n  std::cout << \"\\t\\t\\t\\tmax_nnz_per_row = \" << max_nnz_per_row << std::endl;\n  std::cout << std::endl;\n  \n  \n\n  \n\n  cusparseHandle_t handle = NULL;\n  CHECK_CUSPARSE( cusparseCreate(&handle) )\n\n  cusparseMatDescr_t descr = 0;\n  CHECK_CUSPARSE( cusparseCreateMatDescr(&descr) )\n\n  CHECK_CUSPARSE( cusparseSetMatType(descr, CUSPARSE_MATRIX_TYPE_GENERAL) )\n  CHECK_CUSPARSE( cusparseSetMatIndexBase(descr, CUSPARSE_INDEX_BASE_ZERO) )\n\n  \n\n  CHECK_CUSPARSE( cusparseXcsrsort_bufferSizeExt(handle, a_nrows,\n                                                 a_ncols, a_nnz, a_rowptr,\n                                                 a_colind, &bufferSize) )\n  CHECK_CUDA( cudaMalloc(&d_buffer, bufferSize) )\n\n  \n\n  CHECK_CUDA( cudaMalloc((void**)&d_permutation, sizeof(intType)*a_nnz) )\n  CHECK_CUSPARSE( cusparseCreateIdentityPermutation(handle, a_nnz,\n                                                    d_permutation) )\n\n  \n\n  cusparseSpVecDescr_t vec_permutation;\n  cusparseDnVecDescr_t vec_values;\n\n  cudaDataType valueType;\n  if constexpr (std::is_same_v<fp, double>) \n\n    valueType = CUDA_R_64F;\n  else\n    valueType = CUDA_R_32F;\n\n  \n\n  CHECK_CUSPARSE( cusparseCreateSpVec(&vec_permutation, a_nnz, a_nnz,\n                                      d_permutation, a_val_sorted,\n                                      CUSPARSE_INDEX_32I,\n                                      CUSPARSE_INDEX_BASE_ZERO, valueType) )\n\n  \n\n  CHECK_CUSPARSE( cusparseCreateDnVec(&vec_values, a_nnz, a_val, valueType) )\n\n  CHECK_CUDA( cudaDeviceSynchronize() )\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    CHECK_CUSPARSE( cusparseXcsrsort(handle, a_nrows, a_ncols, a_nnz, descr,\n                                     a_rowptr, a_colind, d_permutation, d_buffer) )\n\n    CHECK_CUSPARSE( cusparseGather(handle, vec_values, vec_permutation) )\n\n  }\n\n  CHECK_CUDA( cudaDeviceSynchronize() )\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of CSR sort: \" << (time * 1e-3f) / repeat\n            << \" us\" << std::endl;\n\n  \n\n  CHECK_CUSPARSE( cusparseDestroySpVec(vec_permutation) )\n  CHECK_CUSPARSE( cusparseDestroyDnVec(vec_values) )\n  CHECK_CUSPARSE( cusparseDestroyMatDescr(descr) )\n  CHECK_CUSPARSE( cusparseDestroy(handle) )\n  \n\n  \n\n  CHECK_CUDA( cudaMemcpy(ia_result, a_rowptr, (a_nrows+1) * sizeof(intType),\n                         cudaMemcpyDeviceToHost) )\n  CHECK_CUDA( cudaMemcpy(ja_result, a_colind, a_nnz * sizeof(intType),\n                         cudaMemcpyDeviceToHost) )\n  CHECK_CUDA( cudaMemcpy(a_result, a_val_sorted, a_nnz * sizeof(fp),\n                         cudaMemcpyDeviceToHost) )\n\n  int error;\n\n  error = memcmp(ia_result, ia, (a_nrows+1) * sizeof(intType));\n  if (error) {\n    std::cout << \"Error: row index arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  error = memcmp(ja_result, ja, a_nnz * sizeof(intType));\n  if (error) {\n    std::cout << \"Error: column index arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  error = memcmp(a_result, a, a_nnz * sizeof(fp));\n  if (error) {\n    std::cout << \"Error: value arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  print_error:\n  if (error == 0)\n      std::cout << \"csrsort_example test PASSED\" << std::endl;\n  else\n      std::cout << \"csrsort_example test FAILED: wrong result\" << std::endl;\n  \n\n  \n\n  CHECK_CUDA( cudaFree(a_rowptr) )\n  CHECK_CUDA( cudaFree(a_colind) )\n  CHECK_CUDA( cudaFree(d_permutation) )\n  CHECK_CUDA( cudaFree(a_val) )\n  CHECK_CUDA( cudaFree(a_val_sorted) )\n  CHECK_CUDA( cudaFree(d_buffer) )\n\n  free(m);\n  free(ia);\n  free(ja);\n  free(a);\n  free(ia_result);\n  free(ja_result);\n  free(a_result);\n  return EXIT_SUCCESS;\n}\n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  if (argc != 5) {\n    std::cout << \"The function sorts the column indices of each row in a sparse MxN matrix\" << std::endl;\n    std::cout << \"The sparse matrix is represented in CSR (Compressed Sparse Row) storage format\" << std::endl;\n    std::cout << \"Usage \" << argv[0] << \" <M> <N> <nnz> <repeat>\" << std::endl;\n    std::cout << \"nnz is the number of non-zero elements\" << std::endl;\n    return 1;\n  }\n\n  int m, n, nnz;\n\n  m = atoi(argv[1]);\n  n = atoi(argv[2]);\n  nnz = atoi(argv[3]);\n  repeat = atoi(argv[4]);\n\n  int status = sort_sparse_matrix<float, int>(m, n, nnz, repeat);\n  if (status == EXIT_FAILURE) return status;\n\n  return status;\n}\n"}}
{"kernel_name": "spsort", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <cstdlib>\n#include <cstring>\n#include <chrono>\n#include <iostream>\n#include <type_traits>\n#include <hip/hip_runtime.h>\n#include <hipsparse/hipsparse.h>\n#include \"utils.h\"\n\n#define CHECK_HIP(func)                                                  \\\n{                                                                        \\\n    hipError_t status = (func);                                          \\\n    if (status != hipSuccess) {                                          \\\n        printf(\"HIP API failed at line %d with error: %s (%d)\\n\",        \\\n               __LINE__, hipGetErrorString(status), status);             \\\n        return EXIT_FAILURE;                                             \\\n    }                                                                    \\\n}\n\n#define CHECK_HIPSPARSE_ERROR_CASE__(token_) \\\n    case token_:                             \\\n        fprintf(stderr, \"HIPSPARSE API failed at line %d with error: %s\\n\",         \\\n               __LINE__, #token_); \\\n        break\n\n#define CHECK_HIPSPARSE(error)                                                      \\\n    {                                                                                     \\\n        auto local_error = (error);                                                       \\\n        if(local_error != HIPSPARSE_STATUS_SUCCESS)                                       \\\n        {                                                                                 \\\n            fprintf(stderr, \"hipSPARSE error: \");                                         \\\n            switch(local_error)                                                           \\\n            {                                                                             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_SUCCESS);                   \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_NOT_INITIALIZED);           \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ALLOC_FAILED);              \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INVALID_VALUE);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ARCH_MISMATCH);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_MAPPING_ERROR);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_EXECUTION_FAILED);          \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INTERNAL_ERROR);            \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_MATRIX_TYPE_NOT_SUPPORTED); \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_ZERO_PIVOT);                \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_NOT_SUPPORTED);             \\\n                CHECK_HIPSPARSE_ERROR_CASE__(HIPSPARSE_STATUS_INSUFFICIENT_RESOURCES);    \\\n            }                                                                             \\\n            fprintf(stderr, \"\\n\");                                                        \\\n            return local_error;                                                           \\\n        }                                                                                 \\\n    }                                                                                     \n\ntemplate <typename fp, typename intType>\nint sort_sparse_matrix(intType a_nrows, intType a_ncols,\n                       intType a_nnz, int repeat)\n{\n  fp *m = (fp*) malloc (sizeof(fp) * a_nrows * a_ncols);\n  init_matrix(m, a_nrows, a_ncols, a_nnz);\n\n  intType *ia = (intType*) malloc ((a_nrows+1) * sizeof(intType));\n  intType *ja = (intType*) malloc (a_nnz * sizeof(intType));\n  fp *a = (fp*) malloc (a_nnz * sizeof(fp));\n\n  \n\n  init_csr(ia, a, ja, m, a_nrows, a_ncols, a_nnz);\n\n  \n\n  intType *ia_result = (intType*) malloc ((a_nrows+1) * sizeof(intType));\n  intType *ja_result = (intType*) malloc (a_nnz * sizeof(intType));\n  fp *a_result = (fp*) malloc (a_nnz * sizeof(fp));\n\n  \n\n  memcpy(ia_result, ia, (a_nrows+1) * sizeof(intType));\n  memcpy(ja_result, ja, a_nnz * sizeof(intType));\n  memcpy(a_result, a, a_nnz * sizeof(fp));\n  shuffle_matrix_data<fp, intType>(ia_result, ja_result, a_result, a_nrows, a_nnz);\n\n  \n\n  \n\n  intType    *a_rowptr, *a_colind, *d_permutation;\n  fp *a_val, *a_val_sorted;\n  void   *d_buffer;\n  size_t bufferSize;\n  CHECK_HIP( hipMalloc((void**) &a_rowptr,      (a_nrows+1) * sizeof(intType)) )\n  CHECK_HIP( hipMalloc((void**) &a_colind,      a_nnz * sizeof(intType)) )\n  CHECK_HIP( hipMalloc((void**) &a_val,         a_nnz * sizeof(fp)) )\n  CHECK_HIP( hipMalloc((void**) &a_val_sorted,  a_nnz * sizeof(fp)) )\n  CHECK_HIP( hipMalloc((void**) &d_permutation, a_nnz * sizeof(intType)) )\n\n  CHECK_HIP( hipMemcpy(a_rowptr, ia_result, (a_nrows+1) * sizeof(intType),\n                       hipMemcpyHostToDevice) )\n  CHECK_HIP( hipMemcpy(a_colind, ja_result, a_nnz * sizeof(intType),\n                       hipMemcpyHostToDevice) )\n  CHECK_HIP( hipMemcpy(a_val, a_result, a_nnz * sizeof(fp),\n                       hipMemcpyHostToDevice) )\n\n  std::cout << \"\\n\\t\\tBasic info of the sparse matrix:\\n\";\n\n  const fp ave_nnz_per_row = static_cast<fp>(a_nnz)/a_nrows;\n  std::cout << \"\\t\\t\\tA_nrows = A_ncols = \" << a_nrows << std::endl;\n  std::cout << \"\\t\\t\\tA_nnz   = \" << a_nnz << std::endl;\n\n  intType max_nnz_per_row = 0;\n  intType min_nnz_per_row = a_nnz;\n  for (intType row = 0; row < a_nrows; ++row) {\n    const intType loc_nnz_per_row = ia[row+1] - ia[row];\n\n    if (loc_nnz_per_row > max_nnz_per_row) \n      max_nnz_per_row = loc_nnz_per_row;\n\n    if (loc_nnz_per_row < min_nnz_per_row) \n      min_nnz_per_row = loc_nnz_per_row;\n  }\n\n  std::cout << \"\\t\\t\\t\\tmin_nnz_per_row = \" << min_nnz_per_row << std::endl;\n  std::cout << \"\\t\\t\\t\\tave_nnz_per_row = \" << ave_nnz_per_row << std::endl;\n  std::cout << \"\\t\\t\\t\\tmax_nnz_per_row = \" << max_nnz_per_row << std::endl;\n  std::cout << std::endl;\n  \n  \n\n  \n\n  hipsparseHandle_t handle = NULL;\n  CHECK_HIPSPARSE( hipsparseCreate(&handle) )\n  hipsparseMatDescr_t descr = 0;\n  CHECK_HIPSPARSE( hipsparseCreateMatDescr(&descr) )\n\n  CHECK_HIPSPARSE( hipsparseSetMatType(descr, HIPSPARSE_MATRIX_TYPE_GENERAL) )\n  CHECK_HIPSPARSE( hipsparseSetMatIndexBase(descr, HIPSPARSE_INDEX_BASE_ZERO) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseXcsrsort_bufferSizeExt(handle, a_nrows,\n                                                 a_ncols, a_nnz, a_rowptr,\n                                                 a_colind, &bufferSize) )\n  CHECK_HIP( hipMalloc(&d_buffer, bufferSize) )\n\n  \n\n  CHECK_HIP( hipMalloc((void**)&d_permutation, sizeof(intType)*a_nnz) )\n  CHECK_HIPSPARSE( hipsparseCreateIdentityPermutation(handle, a_nnz,\n                                                      d_permutation) )\n\n  hipsparseSpVecDescr_t vec_permutation;\n  hipsparseDnVecDescr_t vec_values;\n\n  hipDataType valueType;\n  if constexpr (std::is_same_v<fp, double>) \n\n    valueType = HIP_R_64F;\n  else\n    valueType = HIP_R_32F;\n    \n  \n\n  CHECK_HIPSPARSE( hipsparseCreateSpVec(&vec_permutation, a_nnz, a_nnz,\n                                        d_permutation, a_val_sorted,\n                                        HIPSPARSE_INDEX_32I,\n                                        HIPSPARSE_INDEX_BASE_ZERO, valueType) )\n\n  \n\n  CHECK_HIPSPARSE( hipsparseCreateDnVec(&vec_values, a_nnz, a_val, valueType) )\n\n  CHECK_HIP( hipDeviceSynchronize() )\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    CHECK_HIPSPARSE( hipsparseXcsrsort(handle, a_nrows, a_ncols, a_nnz, descr,\n                                       a_rowptr, a_colind, d_permutation, d_buffer) )\n    CHECK_HIPSPARSE( hipsparseGather(handle, vec_values, vec_permutation) )\n\n    CHECK_HIP( hipDeviceSynchronize() )\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of CSR sort: \" << (time * 1e-3f) / repeat\n            << \" us\" << std::endl;\n\n  \n\n  CHECK_HIPSPARSE( hipsparseDestroySpVec(vec_permutation) )\n  CHECK_HIPSPARSE( hipsparseDestroyDnVec(vec_values) )\n  CHECK_HIPSPARSE( hipsparseDestroyMatDescr(descr) )\n  CHECK_HIPSPARSE( hipsparseDestroy(handle) )\n  \n\n  \n\n  CHECK_HIP( hipMemcpy(ia_result, a_rowptr, (a_nrows+1) * sizeof(intType),\n                       hipMemcpyDeviceToHost) )\n  CHECK_HIP( hipMemcpy(ja_result, a_colind, a_nnz * sizeof(intType),\n                       hipMemcpyDeviceToHost) )\n  CHECK_HIP( hipMemcpy(a_result, a_val_sorted, a_nnz * sizeof(fp),\n                       hipMemcpyDeviceToHost) )\n\n  int error;\n\n  error = memcmp(ia_result, ia, (a_nrows+1) * sizeof(intType));\n  if (error) {\n    std::cout << \"Error: row index arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  error = memcmp(ja_result, ja, a_nnz * sizeof(intType));\n  if (error) {\n    std::cout << \"Error: column index arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  error = memcmp(a_result, a, a_nnz * sizeof(fp));\n  if (error) {\n    std::cout << \"Error: value arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  print_error:\n  if (error == 0)\n      std::cout << \"csrsort_example test PASSED\" << std::endl;\n  else\n      std::cout << \"csrsort_example test FAILED: wrong result\" << std::endl;\n  \n\n  \n\n  CHECK_HIP( hipFree(a_rowptr) )\n  CHECK_HIP( hipFree(a_colind) )\n  CHECK_HIP( hipFree(d_permutation) )\n  CHECK_HIP( hipFree(a_val) )\n  CHECK_HIP( hipFree(a_val_sorted) )\n  CHECK_HIP( hipFree(d_buffer) )\n\n  free(m);\n  free(ia);\n  free(ja);\n  free(a);\n  free(ia_result);\n  free(ja_result);\n  free(a_result);\n  return EXIT_SUCCESS;\n}\n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  if (argc != 5) {\n    std::cout << \"The function sorts the column indices of each row in a sparse MxN matrix\" << std::endl;\n    std::cout << \"The sparse matrix is represented in CSR (Compressed Sparse Row) storage format\" << std::endl;\n    std::cout << \"Usage \" << argv[0] << \" <M> <N> <nnz> <repeat>\" << std::endl;\n    std::cout << \"nnz is the number of non-zero elements\" << std::endl;\n    return 1;\n  }\n\n  int m, n, nnz;\n\n  m = atoi(argv[1]);\n  n = atoi(argv[2]);\n  nnz = atoi(argv[3]);\n  repeat = atoi(argv[4]);\n\n  int status = sort_sparse_matrix<float, int>(m, n, nnz, repeat);\n  if (status == EXIT_FAILURE) return status;\n\n  return status;\n}\n"}}
{"kernel_name": "spsort", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n\n#include <oneapi/mkl.hpp>\n#include <sycl/sycl.hpp>\n#include \"utils.h\"\n\n\n\n\n\n\n\ntemplate <typename fp, typename intType>\nint sort_sparse_matrix(sycl::queue &q, intType a_nrows, intType a_ncols,\n                       intType a_nnz, int repeat)\n{\n  \n\n  oneapi::mkl::index_base a_index = oneapi::mkl::index_base::zero;\n\n  fp *m = (fp*) malloc (sizeof(fp) * a_nrows * a_ncols);\n  init_matrix(m, a_nrows, a_ncols, a_nnz);\n  \n\n  \n\n  \n\n  intType *ia = (intType*) malloc ((a_nrows+1) * sizeof(intType));\n  intType *ja = (intType*) malloc (a_nnz * sizeof(intType));\n  fp *a = (fp*) malloc (a_nnz * sizeof(fp));\n\n  \n\n  init_csr(ia, a, ja, m, a_nrows, a_ncols, a_nnz);\n\n  \n\n  intType *ia_result = (intType*) malloc ((a_nrows+1) * sizeof(intType));\n  intType *ja_result = (intType*) malloc (a_nnz * sizeof(intType));\n  fp *a_result = (fp*) malloc (a_nnz * sizeof(fp));\n\n  \n\n  memcpy(ia_result, ia, (a_nrows+1) * sizeof(intType));\n  memcpy(ja_result, ja, a_nnz * sizeof(intType));\n  memcpy(a_result, a, a_nnz * sizeof(fp));\n  shuffle_matrix_data<fp, intType>(ia_result, ja_result, a_result, a_nrows, a_nnz);\n\n  intType *a_rowptr = (intType *)malloc_device((a_nrows + 1) * sizeof(intType), q);\n  intType *a_colind = (intType *)malloc_device((a_nnz) * sizeof(intType), q);\n  fp *a_val         = (fp *)malloc_device((a_nnz) * sizeof(fp), q);\n\n  if (!a_rowptr || !a_colind || !a_val) {\n    printf(\"Failed to allocate USM memory\");\n    if (!a_rowptr) sycl::free(a_rowptr, q);\n    if (!a_colind) sycl::free(a_colind, q);\n    if (!a_val) sycl::free(a_val, q);\n    return 1;\n  }\n\n  \n\n  q.memcpy(a_rowptr, ia_result, (a_nrows+1) * sizeof(intType));\n  q.memcpy(a_colind, ja_result, a_nnz * sizeof(intType));\n  q.memcpy(a_val, a_result, a_nnz * sizeof(fp));\n\n  std::cout << \"\\n\\t\\tBasic info of the sparse matrix:\\n\";\n\n  const fp ave_nnz_per_row = static_cast<fp>(a_nnz)/a_nrows;\n  std::cout << \"\\t\\t\\tA_nrows = A_ncols = \" << a_nrows << std::endl;\n  std::cout << \"\\t\\t\\tA_nnz   = \" << a_nnz << std::endl;\n\n  intType max_nnz_per_row = 0;\n  intType min_nnz_per_row = a_nnz;\n  for (intType row = 0; row < a_nrows; ++row) {\n    const intType loc_nnz_per_row = ia[row+1] - ia[row];\n\n    if (loc_nnz_per_row > max_nnz_per_row) \n      max_nnz_per_row = loc_nnz_per_row;\n\n    if (loc_nnz_per_row < min_nnz_per_row) \n      min_nnz_per_row = loc_nnz_per_row;\n  }\n\n  std::cout << \"\\t\\t\\t\\tmin_nnz_per_row = \" << min_nnz_per_row << std::endl;\n  std::cout << \"\\t\\t\\t\\tave_nnz_per_row = \" << ave_nnz_per_row << std::endl;\n  std::cout << \"\\t\\t\\t\\tmax_nnz_per_row = \" << max_nnz_per_row << std::endl;\n  std::cout << std::endl;\n\n  \n\n  \n\n  \n\n\n  oneapi::mkl::sparse::matrix_handle_t A = nullptr;\n  oneapi::mkl::sparse::init_matrix_handle(&A);\n\n  oneapi::mkl::sparse::set_csr_data(q, A, a_nrows, a_ncols, a_index, a_rowptr,\n                                    a_colind, a_val, {}).wait();\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    \n\n    oneapi::mkl::sparse::sort_matrix(q, A, {}).wait();\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average execution time of CSR sort: \" << (time * 1e-3f) / repeat\n            << \" us\" << std::endl;\n\n  \n\n  oneapi::mkl::sparse::release_matrix_handle(q, &A, {}).wait();\n\n  q.memcpy(ia_result, a_rowptr, (a_nrows+1) * sizeof(intType));\n  q.memcpy(ja_result, a_colind, a_nnz * sizeof(intType));\n  q.memcpy(a_result, a_val, a_nnz * sizeof(fp));\n  q.wait();\n\n  int error;\n\n  error = memcmp(ia_result, ia, (a_nrows+1) * sizeof(intType));\n  if (error) {\n    std::cout << \"Error: row index arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  error = memcmp(ja_result, ja, a_nnz * sizeof(intType));\n  if (error) {\n    std::cout << \"Error: column index arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  error = memcmp(a_result, a, a_nnz * sizeof(fp));\n  if (error) {\n    std::cout << \"Error: value arrays mismatch\" << std::endl;\n    goto print_error;\n  }\n\n  print_error:\n  if (error == 0)\n      std::cout << \"csrsort_example test PASSED\" << std::endl;\n  else\n      std::cout << \"csrsort_example test FAILED: wrong result\" << std::endl;\n\n  sycl::free(a_rowptr, q);\n  sycl::free(a_colind, q);\n  sycl::free(a_val, q);\n  free(m);\n  free(ia);\n  free(ja);\n  free(a);\n  free(ia_result);\n  free(ja_result);\n  free(a_result);\n  return 0;\n}\n\nint main(int argc, char *argv[])\n{\n  int repeat = 1;\n\n  if (argc != 5) {\n    std::cout << \"The function sorts the column indices of each row in a sparse MxN matrix\" << std::endl;\n    std::cout << \"The sparse matrix is represented in CSR (Compressed Sparse Row) storage format\" << std::endl;\n    std::cout << \"Usage \" << argv[0] << \" <M> <N> <nnz> <repeat>\" << std::endl;\n    std::cout << \"nnz is the number of non-zero elements\" << std::endl;\n    return 1;\n  }\n\n  int m, n, nnz;\n\n  m = atoi(argv[1]);\n  n = atoi(argv[2]);\n  nnz = atoi(argv[3]);\n  repeat = atoi(argv[4]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int status = sort_sparse_matrix<float, int>(q, m, n, nnz, repeat);\n  if (status != 0) return status;\n\n  return status;\n}\n"}}
{"kernel_name": "surfel", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <cuda.h>\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\ntemplate<typename T>\n__global__ void surfel_render(\n  const T *__restrict__ s,\n  int N,\n  T f,\n  int w,\n  int h,\n  T *__restrict__ d)\n{\n  const int idx = threadIdx.x + blockIdx.x*blockDim.x;\n  const int idy = threadIdx.y + blockIdx.y*blockDim.y;\n\n  if(idx < w && idy < h)\n  {\n    T ray[3];\n    ray[0] = T(idx)-(w-1)*(T)0.5;\n    ray[1] = T(idy)-(h-1)*(T)0.5;\n    ray[2] = f;\n    T pt[3];\n    T n[3];\n    T p[3];\n    T dMin = 1e20;\n    \n    for (int i=0; i<N; ++i) {\n      p[0] = s[i*COL_DIM+COL_P_X];\n      p[1] = s[i*COL_DIM+COL_P_Y];\n      p[2] = s[i*COL_DIM+COL_P_Z];\n      n[0] = s[i*COL_DIM+COL_N_X];\n      n[1] = s[i*COL_DIM+COL_N_Y];\n      n[2] = s[i*COL_DIM+COL_N_Z];\n      T rSqMax = s[i*COL_DIM+COL_RSq];\n      T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n      T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n      T alpha = pDotn / dsDotRay;\n      pt[0] = ray[0]*alpha - p[0];\n      pt[1] = ray[1]*alpha - p[1];\n      pt[2] = ray[2]*alpha - p[2];\n      T t = ray[2]*alpha;\n      T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n      if (rSq < rSqMax && dMin > t) {\n        dMin = t; \n\n      }\n    }\n    d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n  }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *d_src, *d_dst;\n  cudaMalloc((void**)&d_dst, dst_size * sizeof(T));\n  cudaMalloc((void**)&d_src, src_size * sizeof(T));\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n  cudaMemcpy(d_src, h_src, src_size * sizeof(T), cudaMemcpyHostToDevice); \n\n  dim3 threads(16, 16);\n  dim3 blocks((w+15)/16, (h+15)/16);\n\n  for (int f = 0; f < 3; f++) {\n    printf(\"\\nf = %d\\n\", f);\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      surfel_render<T><<<blocks, threads>>>(d_src, n, inverseFocalLength[f], w, h, d_dst);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    cudaMemcpy(h_dst, d_dst, dst_size * sizeof(T), cudaMemcpyDeviceToHost); \n    T *min = std::min_element( h_dst, h_dst + w*h );\n    T *max = std::max_element( h_dst, h_dst + w*h );\n    printf(\"Value range [%e, %e]\\n\", *min, *max);\n  }\n\n  free(h_dst);\n  free(h_src);\n  cudaFree(d_dst);\n  cudaFree(d_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(n, w, h, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "surfel", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\ntemplate<typename T>\n__global__ void surfel_render(\n  const T *__restrict__ s,\n  int N,\n  T f,\n  int w,\n  int h,\n  T *__restrict__ d)\n{\n  const int idx = threadIdx.x + blockIdx.x*blockDim.x;\n  const int idy = threadIdx.y + blockIdx.y*blockDim.y;\n\n  if(idx < w && idy < h)\n  {\n    T ray[3];\n    ray[0] = T(idx)-(w-1)*(T)0.5;\n    ray[1] = T(idy)-(h-1)*(T)0.5;\n    ray[2] = f;\n    T pt[3];\n    T n[3];\n    T p[3];\n    T dMin = 1e20;\n    \n    for (int i=0; i<N; ++i) {\n      p[0] = s[i*COL_DIM+COL_P_X];\n      p[1] = s[i*COL_DIM+COL_P_Y];\n      p[2] = s[i*COL_DIM+COL_P_Z];\n      n[0] = s[i*COL_DIM+COL_N_X];\n      n[1] = s[i*COL_DIM+COL_N_Y];\n      n[2] = s[i*COL_DIM+COL_N_Z];\n      T rSqMax = s[i*COL_DIM+COL_RSq];\n      T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n      T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n      T alpha = pDotn / dsDotRay;\n      pt[0] = ray[0]*alpha - p[0];\n      pt[1] = ray[1]*alpha - p[1];\n      pt[2] = ray[2]*alpha - p[2];\n      T t = ray[2]*alpha;\n      T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n      if (rSq < rSqMax && dMin > t) {\n        dMin = t; \n\n      }\n    }\n    d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n  }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *d_src, *d_dst;\n  hipMalloc((void**)&d_dst, dst_size * sizeof(T));\n  hipMalloc((void**)&d_src, src_size * sizeof(T));\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n  hipMemcpy(d_src, h_src, src_size * sizeof(T), hipMemcpyHostToDevice); \n\n  dim3 threads(16, 16);\n  dim3 blocks((w+15)/16, (h+15)/16);\n\n  for (int f = 0; f < 3; f++) {\n    printf(\"\\nf = %d\\n\", f);\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      hipLaunchKernelGGL(HIP_KERNEL_NAME(surfel_render<T>), blocks, threads, 0, 0, d_src, n, inverseFocalLength[f], w, h, d_dst);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    hipMemcpy(h_dst, d_dst, dst_size * sizeof(T), hipMemcpyDeviceToHost); \n    T *min = std::min_element( h_dst, h_dst + w*h );\n    T *max = std::max_element( h_dst, h_dst + w*h );\n    printf(\"Value range [%e, %e]\\n\", *min, *max);\n  }\n\n  free(h_dst);\n  free(h_src);\n  hipFree(d_dst);\n  hipFree(d_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(n, w, h, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "surfel", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include <omp.h>\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\n  template<typename T>\nvoid surfel_render(\n    const T *__restrict s,\n    int N,\n    T f,\n    int w,\n    int h,\n    T *__restrict d)\n{\n  #pragma omp target teams distribute parallel for collapse(2) thread_limit(256)\n  for (int idy = 0; idy < h; idy++)\n    for (int idx = 0; idx < w; idx++) {\n\n      T ray[3];\n      ray[0] = T(idx)-(w-1)*(T)0.5;\n      ray[1] = T(idy)-(h-1)*(T)0.5;\n      ray[2] = f;\n      T pt[3];\n      T n[3];\n      T p[3];\n      T dMin = 1e20;\n\n      for (int i=0; i<N; ++i) {\n        p[0] = s[i*COL_DIM+COL_P_X];\n        p[1] = s[i*COL_DIM+COL_P_Y];\n        p[2] = s[i*COL_DIM+COL_P_Z];\n        n[0] = s[i*COL_DIM+COL_N_X];\n        n[1] = s[i*COL_DIM+COL_N_Y];\n        n[2] = s[i*COL_DIM+COL_N_Z];\n        T rSqMax = s[i*COL_DIM+COL_RSq];\n        T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n        T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n        T alpha = pDotn / dsDotRay;\n        pt[0] = ray[0]*alpha - p[0];\n        pt[1] = ray[1]*alpha - p[1];\n        pt[2] = ray[2]*alpha - p[2];\n        T t = ray[2]*alpha;\n        T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n        if (rSq < rSqMax && dMin > t) {\n          dMin = t; \n\n        }\n      }\n      d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n    }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n#pragma omp target data map(to: h_src[0:src_size]) \\\n                        map(alloc: h_dst[0:dst_size])\n  {\n    for (int f = 0; f < 3; f++) {\n      printf(\"\\nf = %d\\n\", f);\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++)\n        surfel_render<T>(h_src, n, inverseFocalLength[f], w, h, h_dst);\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n      #pragma omp target update from (h_dst[0:dst_size])\n      T *min = std::min_element( h_dst, h_dst + w*h );\n      T *max = std::max_element( h_dst, h_dst + w*h );\n      printf(\"value range [%e, %e]\\n\", *min, *max);\n    }\n  }\n\n  free(h_dst);\n  free(h_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(n, w, h, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "surfel", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\n  template<typename T>\nvoid surfel_render(\n    const T *__restrict s,\n    int N,\n    T f,\n    int w,\n    int h,\n    T *__restrict d)\n{\n    for (int idy = 0; idy < h; idy++)\n    for (int idx = 0; idx < w; idx++) {\n\n      T ray[3];\n      ray[0] = T(idx)-(w-1)*(T)0.5;\n      ray[1] = T(idy)-(h-1)*(T)0.5;\n      ray[2] = f;\n      T pt[3];\n      T n[3];\n      T p[3];\n      T dMin = 1e20;\n\n      for (int i=0; i<N; ++i) {\n        p[0] = s[i*COL_DIM+COL_P_X];\n        p[1] = s[i*COL_DIM+COL_P_Y];\n        p[2] = s[i*COL_DIM+COL_P_Z];\n        n[0] = s[i*COL_DIM+COL_N_X];\n        n[1] = s[i*COL_DIM+COL_N_Y];\n        n[2] = s[i*COL_DIM+COL_N_Z];\n        T rSqMax = s[i*COL_DIM+COL_RSq];\n        T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n        T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n        T alpha = pDotn / dsDotRay;\n        pt[0] = ray[0]*alpha - p[0];\n        pt[1] = ray[1]*alpha - p[1];\n        pt[2] = ray[2]*alpha - p[2];\n        T t = ray[2]*alpha;\n        T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n        if (rSq < rSqMax && dMin > t) {\n          dMin = t; \n\n        }\n      }\n      d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n    }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n  {\n    for (int f = 0; f < 3; f++) {\n      printf(\"\\nf = %d\\n\", f);\n      auto start = std::chrono::steady_clock::now();\n\n      for (int i = 0; i < repeat; i++)\n        surfel_render<T>(h_src, n, inverseFocalLength[f], w, h, h_dst);\n\n      auto end = std::chrono::steady_clock::now();\n      auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n      printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n            T *min = std::min_element( h_dst, h_dst + w*h );\n      T *max = std::max_element( h_dst, h_dst + w*h );\n      printf(\"value range [%e, %e]\\n\", *min, *max);\n    }\n  }\n\n  free(h_dst);\n  free(h_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(n, w, h, repeat);\n  return 0;\n}"}}
{"kernel_name": "surfel", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <algorithm>\n#include <chrono>\n#include \"common.h\"\n\n#define COL_P_X 0\n#define COL_P_Y 1\n#define COL_P_Z 2\n#define COL_N_X 3\n#define COL_N_Y 4\n#define COL_N_Z 5\n#define COL_RSq 6\n#define COL_DIM 7\n\n\n\ntemplate<typename T>\nclass k;\n\n\n\ntemplate<typename T>\nvoid surfel_render(\n  nd_item<2> &item,\n  const T *__restrict s,\n  int N,\n  T f,\n  int w,\n  int h,\n  T *__restrict d)\n{\n  const int idx = item.get_global_id(1);\n  const int idy = item.get_global_id(0);\n\n  if(idx < w && idy < h)\n  {\n    T ray[3];\n    ray[0] = T(idx)-(w-1)*(T)0.5;\n    ray[1] = T(idy)-(h-1)*(T)0.5;\n    ray[2] = f;\n    T pt[3];\n    T n[3];\n    T p[3];\n    T dMin = 1e20;\n    \n    for (int i=0; i<N; ++i) {\n      p[0] = s[i*COL_DIM+COL_P_X];\n      p[1] = s[i*COL_DIM+COL_P_Y];\n      p[2] = s[i*COL_DIM+COL_P_Z];\n      n[0] = s[i*COL_DIM+COL_N_X];\n      n[1] = s[i*COL_DIM+COL_N_Y];\n      n[2] = s[i*COL_DIM+COL_N_Z];\n      T rSqMax = s[i*COL_DIM+COL_RSq];\n      T pDotn = p[0]*n[0]+p[1]*n[1]+p[2]*n[2];\n      T dsDotRay = ray[0]*n[0] + ray[1]*n[1] + ray[2]*n[2];\n      T alpha = pDotn / dsDotRay;\n      pt[0] = ray[0]*alpha - p[0];\n      pt[1] = ray[1]*alpha - p[1];\n      pt[2] = ray[2]*alpha - p[2];\n      T t = ray[2]*alpha;\n      T rSq = pt[0] * pt[0] + pt[1] * pt[1] + pt[2] * pt[2];\n      if (rSq < rSqMax && dMin > t) {\n        dMin = t; \n\n      }\n    }\n    d[idy*w+idx] = dMin > (T)100 ? (T)0 : dMin;\n  }\n}\n\ntemplate <typename T>\nvoid surfelRenderTest(queue &q, int n, int w, int h, int repeat)\n{\n  const int src_size = n*7;\n  const int dst_size = w*h;\n\n  T *h_dst = (T*) malloc (dst_size * sizeof(T));\n  T *h_src = (T*) malloc (src_size * sizeof(T));\n\n  srand(123);\n  for (int i = 0; i < src_size; i++)\n    h_src[i] = rand() % 256;\n\n  T inverseFocalLength[3] = {0.005, 0.02, 0.036};\n\n  buffer<T, 1> d_src (h_src, src_size);\n  buffer<T, 1> d_dst (dst_size);\n\n  range<2> lws (16, 16);\n  range<2> gws ((h+15)/16*16, (w+15)/16*16);\n  for (int f = 0; f < 3; f++) {\n    printf(\"\\nf = %d\\n\", f);\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++)\n      q.submit([&] (handler &cgh) {\n        auto src = d_src.template get_access<sycl_read>(cgh);\n        auto dst = d_dst.template get_access<sycl_discard_write>(cgh);\n        cgh.parallel_for<class k<T>>(nd_range<2>(gws, lws), [=] (nd_item<2> item) {\n          surfel_render<T>(item, src.get_pointer(), n, \n                           inverseFocalLength[f], w, h,\n                           dst.get_pointer());\n        });\n      });\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n    q.submit([&] (handler &cgh) {\n      auto acc = d_dst.template get_access<sycl_read>(cgh);\n      cgh.copy(acc, h_dst);\n    }).wait();\n\n    T *min = std::min_element( h_dst, h_dst + w*h );\n    T *max = std::max_element( h_dst, h_dst + w*h );\n    printf(\"value range [%e, %e]\\n\", *min, *max);\n  }\n\n  free(h_dst);\n  free(h_src);\n}\n\nint main(int argc, char *argv[]) {\n  if (argc != 5) {\n    printf(\"Usage: %s <input height> <output width> <output height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int n = atoi(argv[1]);\n  int w = atoi(argv[2]);\n  int h = atoi(argv[3]);\n  int repeat = atoi(argv[4]);\n\n#ifdef USE_GPU\n  gpu_selector dev_sel;\n#else\n  cpu_selector dev_sel;\n#endif\n  queue q(dev_sel);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float32  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<float>(q, n, w, h, repeat);\n\n  printf(\"-------------------------------------\\n\");\n  printf(\" surfelRenderTest with type float64  \\n\");\n  printf(\"-------------------------------------\\n\");\n  surfelRenderTest<double>(q, n, w, h, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "testSNAP", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include <cuda.h>\n#include \"snap.h\"\n#include \"utils.cu\"\n\n#if REFDATA_TWOJ == 14\n#include \"refdata_2J14_W.h\"\n#elif REFDATA_TWOJ == 8\n#include \"refdata_2J8_W.h\"\n#elif REFDATA_TWOJ == 4\n#include \"refdata_2J4_W.h\"\n#else\n#include \"refdata_2J2_W.h\"\n#endif\n\n\nint nsteps = 1; \n\n\n__global__ void reset_ulisttot(COMPLEX *ulisttot, const int ulisttot_size) \n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < ulisttot_size) ulisttot[i] = {0.0, 0.0};\n}\n\n__global__ void set_ulisttot(\n    COMPLEX *__restrict__ ulisttot,\n    const int*__restrict__ idxu_block, \n    const int num_atoms,\n    const int twojmax,\n    const double wself) \n{\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  if (natom < num_atoms) \n    for (int j = 0; j <= twojmax; j++) {\n      int jju = idxu_block[j];\n      for (int ma = 0; ma <= j; ma++) {\n        ulisttot[INDEX_2D(natom, jju)] = { wself, 0.0 };\n        jju += j + 2;\n      }\n    }\n}\n\n__global__ void update_ulisttot(\n    const double*__restrict__ rij, \n    const double*__restrict__ rcutij,\n    const double*__restrict__ wj, \n    const int*__restrict__ ulist_parity, \n    const int*__restrict__ idxu_block, \n    const double*__restrict__ rootpqarray, \n    COMPLEX *__restrict__ ulist, \n    COMPLEX *__restrict__ ulisttot, \n    const int num_atoms,\n    const int num_nbor,\n    const int switch_flag, \n    const int twojmax, \n    const int jdimpq)\n{\n\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  int nbor = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (natom < num_atoms && nbor < num_nbor) {\n    double x = rij[ULIST_INDEX(natom, nbor, 0)];\n    double y = rij[ULIST_INDEX(natom, nbor, 1)];\n    double z = rij[ULIST_INDEX(natom, nbor, 2)];\n    double rsq = x * x + y * y + z * z;\n    double r = sqrt(rsq);\n\n    double theta0 = (r - rmin0) * rfac0 * MY_PI / (rcutij[INDEX_2D(natom, nbor)] - rmin0);\n    double z0 = r / tan(theta0);\n\n    double rootpq;\n    int jju, jjup;\n\n    \n\n\n    double r0inv = 1.0 / sqrt(r * r + z0 * z0);\n    double a_r = r0inv * z0;\n    double a_i = -r0inv * z;\n    double b_r = r0inv * y;\n    double b_i = -r0inv * x;\n\n    double sfac;\n\n    sfac = compute_sfac(r, rcutij[INDEX_2D(natom, nbor)], switch_flag);\n    sfac *= wj[INDEX_2D(natom, nbor)];\n\n    \n\n    \n\n\n    \n\n    \n\n\n    \n\n    \n\n\n    \n\n    \n\n    ulist[ULIST_INDEX(natom, nbor, 0)].re = 1.0;\n    ulist[ULIST_INDEX(natom, nbor, 0)].im = 0.0;\n\n    \n\n    jju = 1;\n    for (int j = 1; j <= twojmax; j++) {\n      int deljju = j + 1;\n      for (int mb = 0; 2 * mb <= j; mb++) {\n        ulist[ULIST_INDEX(natom, nbor, jju)].re = 0.0;\n        ulist[ULIST_INDEX(natom, nbor, jju)].im = 0.0;\n        jju += deljju;\n      }\n      int ncolhalf = deljju / 2;\n      jju += deljju * ncolhalf;\n    }\n\n    jju = 1;\n    jjup = 0;\n    for (int j = 1; j <= twojmax; j++) {\n      int deljju = j + 1;\n      int deljjup = j;\n      int mb_max = (j + 1) / 2;\n      int ma_max = j;\n      int m_max = ma_max * mb_max;\n\n      \n\n      for (int m_iter = 0; m_iter < m_max; ++m_iter) {\n        int mb = m_iter / ma_max;\n        int ma = m_iter % ma_max;\n        double up_r = ulist[ULIST_INDEX(natom, nbor, jjup)].re;\n        double up_i = ulist[ULIST_INDEX(natom, nbor, jjup)].im;\n\n        rootpq = rootpqarray[ROOTPQ_INDEX(j - ma, j - mb)];\n        ulist[ULIST_INDEX(natom, nbor, jju)].re += rootpq * (a_r * up_r + a_i * up_i);\n        ulist[ULIST_INDEX(natom, nbor, jju)].im += rootpq * (a_r * up_i - a_i * up_r);\n\n        rootpq = rootpqarray[ROOTPQ_INDEX(ma + 1, j - mb)];\n        ulist[ULIST_INDEX(natom, nbor, jju+1)].re = -rootpq * (b_r * up_r + b_i * up_i);\n        ulist[ULIST_INDEX(natom, nbor, jju+1)].im = -rootpq * (b_r * up_i - b_i * up_r);\n\n        \n\n\n        if (2 * (mb + 1) == j) {\n          rootpq = rootpqarray[ROOTPQ_INDEX(j - ma, mb + 1)];\n          ulist[ULIST_INDEX(natom, nbor, jju+deljju)].re += rootpq * (b_r * up_r - b_i * up_i);\n          ulist[ULIST_INDEX(natom, nbor, jju+deljju)].im += rootpq * (b_r * up_i + b_i * up_r);\n\n          rootpq = rootpqarray[ROOTPQ_INDEX(ma + 1, mb + 1)];\n          ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].re = rootpq * (a_r * up_r - a_i * up_i);\n          ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].im = rootpq * (a_r * up_i + a_i * up_r);\n        }\n\n        jju++;\n        jjup++;\n\n        if (ma == ma_max - 1)\n          jju++;\n      }\n\n      \n\n      \n\n      \n\n      \n\n      int jjui = idxu_block[j];\n      int jjuip = jjui + (j + 1) * (j + 1) - 1;\n      for (int mb = 0; 2 * mb < j; mb++) {\n        for (int ma = 0; ma <= j; ma++) {\n          ulist[ULIST_INDEX(natom, nbor, jjuip)].re = ulist_parity[jjui] * ulist[ULIST_INDEX(natom, nbor, jjui)].re;\n          ulist[ULIST_INDEX(natom, nbor, jjuip)].im = ulist_parity[jjui] * -ulist[ULIST_INDEX(natom, nbor, jjui)].im;\n          jjui++;\n          jjuip--;\n        }\n      }\n\n      \n\n      \n\n      if (j % 2 == 0)\n        jju += deljju;\n      int ncolhalf = deljju / 2;\n      jju += deljju * ncolhalf;\n      int ncolhalfp = deljjup / 2;\n      jjup += deljjup * ncolhalfp;\n    }\n\n    sfac = compute_sfac(r, rcutij[INDEX_2D(natom, nbor)], switch_flag);\n    sfac *= wj[INDEX_2D(natom, nbor)];\n\n    for (int j = 0; j <= twojmax; j++) {\n      int jju = idxu_block[j];\n      for (int mb = 0; mb <= j; mb++)\n        for (int ma = 0; ma <= j; ma++) {\n          atomicAdd(&(ulisttot[INDEX_2D(natom, jju)].re), sfac * ulist[ULIST_INDEX(natom, nbor, jju)].re);\n          atomicAdd(&(ulisttot[INDEX_2D(natom, jju)].im), sfac * ulist[ULIST_INDEX(natom, nbor, jju)].im);\n          jju++;\n        }\n    }\n  }\n}\n\n__global__ void reset_ylist(COMPLEX *ylist, const int ylist_size) \n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < ylist_size) ylist[i] = {0.0, 0.0};\n}\n\n__global__ void compute_yi (\n    const int*__restrict__ idxz,\n    const double*__restrict__ idxzbeta,\n    const double*__restrict__ cglist,\n    const int*__restrict__ idxcg_block,\n    const int*__restrict__ idxu_block,\n    const int*__restrict__ idxdu_block,\n    const COMPLEX*__restrict__ ulisttot,\n          COMPLEX*__restrict__ ylist,\n    const int num_atoms,\n    const int idxz_max,\n    const int jdim) \n{\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  int jjz = blockIdx.y * blockDim.y + threadIdx.y;\n  if (jjz < idxz_max && natom < num_atoms) {\n    const int j1 = idxz[IDXZ_INDEX(jjz, 0)];\n    const int j2 = idxz[IDXZ_INDEX(jjz, 1)];\n    const int j = idxz[IDXZ_INDEX(jjz, 2)];\n    const int ma1min = idxz[IDXZ_INDEX(jjz, 3)];\n    const int ma2max = idxz[IDXZ_INDEX(jjz, 4)];\n    const int na = idxz[IDXZ_INDEX(jjz, 5)];\n    const int mb1min = idxz[IDXZ_INDEX(jjz, 6)];\n    const int mb2max = idxz[IDXZ_INDEX(jjz, 7)];\n    const int nb = idxz[IDXZ_INDEX(jjz, 8)];\n\n    const double betaj = idxzbeta[jjz];\n\n    const double* cgblock = cglist + idxcg_block[j1 + jdim*j2 + jdim*jdim*j];\n\n    int mb = (2 * (mb1min + mb2max) - j1 - j2 + j) / 2;\n    int ma = (2 * (ma1min + ma2max) - j1 - j2 + j) / 2;\n    const int jjdu = idxdu_block[j] + (j + 1) * mb + ma;\n\n    int jju1 = idxu_block[j1] + (j1 + 1) * mb1min;\n    int jju2 = idxu_block[j2] + (j2 + 1) * mb2max;\n    int icgb = mb1min * (j2 + 1) + mb2max;\n\n    double ztmp_r = 0.0;\n    double ztmp_i = 0.0;\n\n    \n\n    \n\n    \n\n\n    for (int ib = 0; ib < nb; ib++) {\n\n      double suma1_r = 0.0;\n      double suma1_i = 0.0;\n\n      int ma1 = ma1min;\n      int ma2 = ma2max;\n      int icga = ma1min * (j2 + 1) + ma2max;\n\n      \n\n      \n\n      \n\n\n      for (int ia = 0; ia < na; ia++) {\n        suma1_r += cgblock[icga] *\n          (ulisttot[INDEX_2D(natom, jju1 + ma1)].re * ulisttot[INDEX_2D(natom, jju2 + ma2)].re -\n           ulisttot[INDEX_2D(natom, jju1 + ma1)].im * ulisttot[INDEX_2D(natom, jju2 + ma2)].im);\n\n        suma1_i += cgblock[icga] *\n          (ulisttot[INDEX_2D(natom, jju1 + ma1)].re * ulisttot[INDEX_2D(natom, jju2 + ma2)].im +\n           ulisttot[INDEX_2D(natom, jju1 + ma1)].im * ulisttot[INDEX_2D(natom, jju2 + ma2)].re);\n\n        ma1++;\n        ma2--;\n        icga += j2;\n      } \n\n\n      ztmp_r += cgblock[icgb] * suma1_r;\n      ztmp_i += cgblock[icgb] * suma1_i;\n      jju1 += j1 + 1;\n      jju2 -= j2 + 1;\n      icgb += j2;\n    } \n\n\n    \n\n\n    atomicAdd(&(ylist[INDEX_2D(natom, jjdu)].re), betaj * ztmp_r);\n    atomicAdd(&(ylist[INDEX_2D(natom, jjdu)].im), betaj * ztmp_i);\n\n  } \n\n}\n\n__global__ void compute_duidrj (\n    const double *__restrict__ wj,\n    const double *__restrict__ rij,\n    const double *__restrict__ rcutij,\n    const double*__restrict__ rootpqarray,\n    const COMPLEX*__restrict__ ulist,\n          COMPLEX*__restrict__ dulist,\n    const int num_atoms,\n    const int num_nbor,\n    const int twojmax,\n    const int idxdu_max,\n    const int jdimpq,\n    const int switch_flag)\n{\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  int nbor = blockIdx.y * blockDim.y + threadIdx.y;\n  if (natom < num_atoms && nbor < num_nbor) {\n    double wj_in = wj[INDEX_2D(natom, nbor)];\n    double rcut = rcutij[INDEX_2D(natom, nbor)];\n\n    double x = rij[ULIST_INDEX(natom, nbor, 0)];\n    double y = rij[ULIST_INDEX(natom, nbor, 1)];\n    double z = rij[ULIST_INDEX(natom, nbor, 2)];\n    double rsq = x * x + y * y + z * z;\n    double r = sqrt(rsq);\n    double rscale0 = rfac0 * MY_PI / (rcut - rmin0);\n    double theta0 = (r - rmin0) * rscale0;\n    double cs = cos(theta0);\n    double sn = sin(theta0);\n    double z0 = r * cs / sn;\n    double dz0dr = z0 / r - (r * rscale0) * (rsq + z0 * z0) / rsq;\n\n    compute_duarray(natom, nbor, num_atoms, num_nbor, \n        twojmax, idxdu_max, jdimpq, switch_flag,\n        x, y, z, z0, r, dz0dr, wj_in, rcut,\n        rootpqarray,\n        ulist,\n        dulist);\n  }\n}\n\n__global__ void compute_deidrj(\n    const int*__restrict__ idxdu_block,\n    const COMPLEX*__restrict__ dulist,\n    const COMPLEX*__restrict__ ylist,\n    double*__restrict__ dedr,\n    const int num_atoms,\n    const int num_nbor,\n    const int twojmax,\n    const int idxdu_max)\n{\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  int nbor = blockIdx.y * blockDim.y + threadIdx.y;\n  if (natom < num_atoms && nbor < num_nbor) {\n    for (int k = 0; k < 3; k++)\n      dedr[ULIST_INDEX(natom, nbor, k)] = 0.0;\n\n    for (int j = 0; j <= twojmax; j++) {\n      int jjdu = idxdu_block[j];\n\n      for (int mb = 0; 2 * mb < j; mb++)\n        for (int ma = 0; ma <= j; ma++) {\n\n          double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n          double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n          for (int k = 0; k < 3; k++)\n            dedr[ULIST_INDEX(natom, nbor, k)] +=\n              dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n              dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n          jjdu++;\n        } \n\n\n      \n\n\n      if (j % 2 == 0) {\n\n        int mb = j / 2;\n        for (int ma = 0; ma < mb; ma++) {\n          double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n          double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n          for (int k = 0; k < 3; k++)\n            dedr[ULIST_INDEX(natom, nbor, k)] +=\n              dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n              dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n          jjdu++;\n        }\n\n        double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n        double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n        for (int k = 0; k < 3; k++)\n          dedr[ULIST_INDEX(natom, nbor, k)] +=\n            (dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n             dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i) *\n            0.5;\n        jjdu++;\n\n      } \n\n\n    } \n\n\n    for (int k = 0; k < 3; k++)\n      dedr[ULIST_INDEX(natom, nbor, k)] *= 2.0;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  options(argc, argv);\n\n  const int switch_flag = 1;     \n\n\n  \n\n  double elapsed_ui = 0.0, \n         elapsed_yi = 0.0, \n         elapsed_duidrj = 0.0,\n         elapsed_deidrj = 0.0;\n\n  const int ninside = refdata.ninside;\n  const int ncoeff = refdata.ncoeff;\n  const int nlocal = refdata.nlocal;\n  const int nghost = refdata.nghost;\n  const int ntotal = nlocal + nghost;\n  const int twojmax = refdata.twojmax;\n  const double rcutfac = refdata.rcutfac;\n\n  const double wself = 1.0;\n  const int num_atoms = nlocal; \n  const int num_nbor = ninside; \n\n  \n\n  double* coeffi = (double*) malloc (sizeof(double) * (ncoeff+1));\n\n  for (int icoeff = 0; icoeff < ncoeff + 1; icoeff++)\n    coeffi[icoeff] = refdata.coeff[icoeff];\n\n  double* beta = coeffi + 1;\n\n  \n\n  const int jdim = twojmax + 1;\n\n  \n\n\n  int *idxcg_block = (int*) malloc(sizeof(int) * jdim * jdim * jdim);\n\n  int idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxcg_block[j1 + j2 *jdim + jdim*jdim*j] = idxcg_count;\n        for (int m1 = 0; m1 <= j1; m1++)\n          for (int m2 = 0; m2 <= j2; m2++)\n            idxcg_count++;\n      }\n  const int idxcg_max = idxcg_count;\n\n  \n\n  \n\n  \n\n\n  int* idxu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxu_block[j] = idxu_count;\n    for (int mb = 0; mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxu_count++;\n  }\n  const int idxu_max = idxu_count;\n\n  \n\n  \n\n  \n\n\n  \n\n  int* ulist_parity = (int*) malloc (sizeof(int) * idxu_max);\n  idxu_count = 0;\n  for (int j = 0; j <= twojmax; j++) {\n    int mbpar = 1;\n    for (int mb = 0; mb <= j; mb++) {\n      int mapar = mbpar;\n      for (int ma = 0; ma <= j; ma++) {\n        ulist_parity[idxu_count] = mapar;\n        mapar = -mapar;\n        idxu_count++;\n      }\n      mbpar = -mbpar;\n    }\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  int* idxdu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxdu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxdu_block[j] = idxdu_count;\n    for (int mb = 0; 2 * mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxdu_count++;\n  }\n  const int idxdu_max = idxdu_count;\n\n  \n\n\n  int idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1)\n          idxb_count++;\n\n  const int idxb_max = idxb_count;\n  SNA_BINDICES* idxb = (SNA_BINDICES*) malloc (sizeof(SNA_BINDICES) * idxb_max);\n\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1) {\n          idxb[idxb_count].j1 = j1;\n          idxb[idxb_count].j2 = j2;\n          idxb[idxb_count].j = j;\n          idxb_count++;\n        }\n\n  \n\n\n  int* idxb_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        if (j < j1)\n          continue;\n        idxb_block[j1*jdim*jdim+j2*jdim+j] = idxb_count;\n        idxb_count++;\n      }\n\n\n  \n\n\n  int idxz_count = 0;\n\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++)\n            idxz_count++;\n\n  const int idxz_max = idxz_count;\n  \n\n  int* idxz = (int*) malloc (sizeof(int) * idxz_max * 9);\n\n  \n\n  double* idxzbeta = (double*) malloc (sizeof(double) * idxz_max);\n\n  \n\n  int* idxz_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n\n  idxz_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxz_block[j1*jdim*jdim+j2*jdim+j] = idxz_count;\n\n        \n\n        \n\n        \n\n        \n\n\n        double betaj;\n        if (j >= j1) {\n          const int jjb = idxb_block[j1*jdim*jdim+j2*jdim+j];\n          if (j1 == j) {\n            if (j2 == j) {\n              betaj = 3 * beta[jjb];\n            }\n            else {\n              betaj = 2 * beta[jjb];\n            }\n          } else {\n            betaj = beta[jjb];\n          }\n        } else if (j >= j2) {\n          const int jjb = idxb_block[j*jdim*jdim+j2*jdim+j1];\n          if (j2 == j) {\n            betaj = 2 * beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n          else {\n            betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n        } else {\n          const int jjb = idxb_block[j2*jdim*jdim+j*jdim+j1];\n          betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n        }\n\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++) {\n\n            idxz[IDXZ_INDEX(idxz_count, 0)] = j1;\n            idxz[IDXZ_INDEX(idxz_count, 1)] = j2;\n            idxz[IDXZ_INDEX(idxz_count, 2)] = j;\n\n            int ma1min = MAX(0, (2 * ma - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 3)] = ma1min;\n            idxz[IDXZ_INDEX(idxz_count, 4)] = (2 * ma - j - (2 * ma1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 5)] =\n              MIN(j1, (2 * ma - j + j2 + j1) / 2) - ma1min + 1;\n\n            int mb1min = MAX(0, (2 * mb - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 6)] = mb1min;\n            idxz[IDXZ_INDEX(idxz_count, 7)] = (2 * mb - j - (2 * mb1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 8)] =\n              MIN(j1, (2 * mb - j + j2 + j1) / 2) - mb1min + 1;\n\n            idxzbeta[idxz_count] = betaj;\n\n            idxz_count++;\n          }\n      }\n  \n\n\n\n  if (compute_ncoeff(twojmax) != ncoeff) {\n    printf(\"ERROR: ncoeff from SNA does not match reference data\\n\");\n    exit(1);\n  }\n\n  \n\n\n  double *rij    = (double*) malloc(sizeof(double) * (num_atoms * num_nbor * 3));\n  double *inside = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *wj     = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *rcutij = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n\n  const int jdimpq = twojmax + 2;\n  double* rootpqarray = (double*) malloc(sizeof(double) * jdimpq * jdimpq);\n  double* cglist = (double*) malloc (sizeof(double) * idxcg_max);\n  double* dedr = (double*) malloc (sizeof(double) * num_atoms * num_nbor * 3); \n\n  COMPLEX* ulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * idxu_max); \n  COMPLEX* ylist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxdu_max);\n  COMPLEX* ulisttot = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxu_max);\n  COMPLEX* dulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * 3 * idxdu_max);\n\n  \n\n  for (int p = 1; p <= twojmax; p++)\n    for (int q = 1; q <= twojmax; q++)\n      rootpqarray[ROOTPQ_INDEX(p, q)] = sqrt(static_cast<double>(p) / q);\n\n  \n\n  double sum, dcg, sfaccg;\n  int m, aa2, bb2, cc2;\n  int ifac;\n\n  idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        for (int m1 = 0; m1 <= j1; m1++) {\n          aa2 = 2 * m1 - j1;\n\n          for (int m2 = 0; m2 <= j2; m2++) {\n\n            \n\n\n            bb2 = 2 * m2 - j2;\n            m = (aa2 + bb2 + j) / 2;\n\n            if (m < 0 || m > j) {\n              cglist[idxcg_count] = 0.0;\n              idxcg_count++;\n              continue;\n            }\n\n            sum = 0.0;\n\n            for (int z = MAX(0, MAX(-(j - j2 + aa2) / 2, -(j - j1 - bb2) / 2));\n                z <=\n                MIN((j1 + j2 - j) / 2, MIN((j1 - aa2) / 2, (j2 + bb2) / 2));\n                z++) {\n              ifac = z % 2 ? -1 : 1;\n              sum += ifac / (factorial(z) * factorial((j1 + j2 - j) / 2 - z) *\n                  factorial((j1 - aa2) / 2 - z) *\n                  factorial((j2 + bb2) / 2 - z) *\n                  factorial((j - j2 + aa2) / 2 + z) *\n                  factorial((j - j1 - bb2) / 2 + z));\n            }\n\n            cc2 = 2 * m - j;\n            dcg = deltacg(j1, j2, j);\n            sfaccg = sqrt(\n                factorial((j1 + aa2) / 2) * factorial((j1 - aa2) / 2) *\n                factorial((j2 + bb2) / 2) * factorial((j2 - bb2) / 2) *\n                factorial((j + cc2) / 2) * factorial((j - cc2) / 2) * (j + 1));\n\n            cglist[idxcg_count] = sum * dcg * sfaccg;\n            idxcg_count++;\n          }\n        }\n      }\n\n  double* f = (double*) malloc (sizeof(double) * ntotal * 3);\n\n  \n\n  double sumsqferr = 0.0;\n\n  int* d_idxu_block;\n  cudaMalloc((void**)&d_idxu_block, sizeof(int)*jdim);\n  cudaMemcpy(d_idxu_block, idxu_block, sizeof(int)*jdim, cudaMemcpyHostToDevice);\n\n  int* d_ulist_parity;\n  cudaMalloc((void**)&d_ulist_parity, sizeof(int)*idxu_max);\n  cudaMemcpy(d_ulist_parity, ulist_parity, sizeof(int)*idxu_max, cudaMemcpyHostToDevice);\n\n  double* d_rootpqarray;\n  cudaMalloc((void**)&d_rootpqarray, sizeof(double)*jdimpq*jdimpq);\n  cudaMemcpy(d_rootpqarray, rootpqarray, sizeof(double)*jdimpq*jdimpq, cudaMemcpyHostToDevice); \n\n  int* d_idxz;\n  cudaMalloc((void**)&d_idxz, sizeof(int)*idxz_max*9);\n  cudaMemcpy(d_idxz, idxz, sizeof(int)*idxz_max*9, cudaMemcpyHostToDevice);\n\n  double* d_idxzbeta;\n  cudaMalloc((void**)&d_idxzbeta, sizeof(double)*idxz_max);\n  cudaMemcpy(d_idxzbeta, idxzbeta, sizeof(double)*idxz_max, cudaMemcpyHostToDevice);\n\n  int* d_idxcg_block;\n  cudaMalloc((void**)&d_idxcg_block, sizeof(int)*jdim*jdim*jdim);\n  cudaMemcpy(d_idxcg_block, idxcg_block, sizeof(int)*jdim*jdim*jdim, cudaMemcpyHostToDevice);\n\n  int* d_idxdu_block;\n  cudaMalloc((void**)&d_idxdu_block, sizeof(int)*jdim);\n  cudaMemcpy(d_idxdu_block, idxdu_block, sizeof(int)*jdim, cudaMemcpyHostToDevice);\n\n  double* d_cglist;\n  cudaMalloc((void**)&d_cglist, sizeof(double)*idxcg_max);\n  cudaMemcpy(d_cglist, cglist, sizeof(double)*idxcg_max, cudaMemcpyHostToDevice);\n\n  COMPLEX* d_dulist;\n  cudaMalloc((void**)&d_dulist, sizeof(COMPLEX)*num_atoms*num_nbor*3*idxdu_max);\n  cudaMemcpy(d_dulist, dulist, sizeof(COMPLEX)*num_atoms*num_nbor*3*idxdu_max, cudaMemcpyHostToDevice);\n\n  COMPLEX* d_ulist;\n  cudaMalloc((void**)&d_ulist, sizeof(COMPLEX)*num_atoms*num_nbor*idxu_max);\n  cudaMemcpy(d_ulist, ulist, sizeof(COMPLEX)*num_atoms*num_nbor*idxu_max, cudaMemcpyHostToDevice);\n\n  double* d_dedr;\n  cudaMalloc((void**)&d_dedr, sizeof(double)*num_atoms*num_nbor*3);\n  cudaMemcpy(d_dedr, dedr, sizeof(double)*num_atoms*num_nbor*3, cudaMemcpyHostToDevice);\n\n  COMPLEX* d_ulisttot;\n  cudaMalloc((void**)&d_ulisttot, sizeof(COMPLEX)*num_atoms*idxu_max);\n\n  COMPLEX* d_ylist;\n  cudaMalloc((void**)&d_ylist, sizeof(COMPLEX)*num_atoms*idxdu_max);\n\n  double *d_rij;\n  cudaMalloc((void**)&d_rij, sizeof(double)*num_atoms*num_nbor*3);\n\n  double *d_rcutij;\n  cudaMalloc((void**)&d_rcutij, sizeof(double)*num_atoms*num_nbor);\n\n  double *d_wj;\n  cudaMalloc((void**)&d_wj, sizeof(double)*num_atoms*num_nbor);\n\n\n  \n\n\n  auto begin = myclock::now();\n\n  for (int istep = 0; istep < nsteps; istep++) {\n\n    time_point<system_clock> start, end;\n    duration<double> elapsed;\n\n    for (int j = 0; j < ntotal * 3; j++) {\n      f[j] = 0.0;\n    }\n\n    int jt = 0, jjt = 0;\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        \n\n        rij[ULIST_INDEX(natom, nbor, 0)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 1)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 2)] = refdata.rij[jt++];\n        inside[INDEX_2D(natom, nbor)] = refdata.jlist[jjt++];\n        wj[INDEX_2D(natom, nbor)] = 1.0;\n        rcutij[INDEX_2D(natom, nbor)] = rcutfac;\n      }\n    }\n\n    cudaMemcpy(d_rij, rij, sizeof(double)*num_atoms*num_nbor*3, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_rcutij, rcutij, sizeof(double)*num_atoms*num_nbor, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_wj, wj, sizeof(double)*num_atoms*num_nbor, cudaMemcpyHostToDevice);\n\n    \n\n    start = system_clock::now();\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    dim3 grid_k1 ((num_atoms*idxu_max+255)/256);\n    dim3 block_k1 (256);\n    reset_ulisttot<<<grid_k1, block_k1>>>(d_ulisttot, num_atoms*idxu_max);\n\n\n    dim3 grid_k2 ((num_atoms+255)/256);\n    dim3 block_k2 (256);\n    set_ulisttot<<<grid_k2, block_k2>>>(d_ulisttot, d_idxu_block, num_atoms, twojmax, wself);\n\n\n    dim3 grid_k3 ((num_atoms+15)/16, (num_nbor+15)/16);\n    dim3 block_k3 (16, 16);\n\n    update_ulisttot<<<grid_k3, block_k3>>>(\n        d_rij, \n        d_rcutij,\n        d_wj,\n        d_ulist_parity,\n        d_idxu_block,\n        d_rootpqarray,\n        d_ulist,\n        d_ulisttot,\n        num_atoms,\n        num_nbor,\n        switch_flag,\n        twojmax,\n        jdimpq);\n\n    cudaDeviceSynchronize();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_ui += elapsed.count();\n\n    start = system_clock::now();\n\n    \n\n    dim3 grid_k4 ((num_atoms*idxdu_max+255)/256);\n    dim3 block_k4 (256);\n\n    reset_ylist<<<grid_k4, block_k4>>>(d_ylist, num_atoms*idxdu_max);\n\n    dim3 grid_k5 ((num_atoms+15)/16, (idxz_max+15)/16);\n    dim3 block_k5 (16, 16);\n\n    compute_yi<<<grid_k5, block_k5>>>(\n        d_idxz,\n        d_idxzbeta,\n        d_cglist,\n        d_idxcg_block,\n        d_idxu_block,\n        d_idxdu_block,\n        d_ulisttot,\n        d_ylist,\n        num_atoms,\n        idxz_max,\n        jdim);\n\n    cudaDeviceSynchronize();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_yi += elapsed.count();\n\n    \n\n    start = system_clock::now();\n\n    dim3 grid_k6 ((num_atoms+15)/16, (num_nbor+15)/16);\n    dim3 block_k6 (16, 16);\n    compute_duidrj<<<grid_k6, block_k6>>>(\n        d_wj,\n        d_rij,\n        d_rcutij,\n        d_rootpqarray,\n        d_ulist,\n        d_dulist,\n        num_atoms,\n        num_nbor,\n        twojmax,\n        idxdu_max,\n        jdimpq,\n        switch_flag);\n\n    cudaDeviceSynchronize();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_duidrj += elapsed.count();\n\n    start = system_clock::now();\n\n    \n\n    dim3 grid_k7 ((num_atoms+15)/16, (num_nbor+15)/16);\n    dim3 block_k7 (16, 16);\n\n    compute_deidrj<<<grid_k7, block_k7>>>( \n        d_idxdu_block,\n        d_dulist,\n        d_ylist,\n        d_dedr,\n        num_atoms,\n        num_nbor,\n        twojmax,\n        idxdu_max);\n\n    cudaDeviceSynchronize();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_deidrj += elapsed.count();\n\n    cudaMemcpy(dedr, d_dedr, sizeof(double)*num_atoms*num_nbor*3, cudaMemcpyDeviceToHost);\n\n    \n\n    \n\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        int j = inside[INDEX_2D(natom, nbor)];\n        f[F_INDEX(natom, 0)] += dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(natom, 1)] += dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(natom, 2)] += dedr[ULIST_INDEX(natom, nbor, 2)];\n        f[F_INDEX(j, 0)] -= dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(j, 1)] -= dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(j, 2)] -= dedr[ULIST_INDEX(natom, nbor, 2)];\n\n      } \n\n    }   \n\n    \n\n    jt = 0;\n    for (int j = 0; j < ntotal; j++) {\n      double ferrx = f[F_INDEX(j, 0)] - refdata.fj[jt++];\n      double ferry = f[F_INDEX(j, 1)] - refdata.fj[jt++];\n      double ferrz = f[F_INDEX(j, 2)] - refdata.fj[jt++];\n      sumsqferr += ferrx * ferrx + ferry * ferry + ferrz * ferrz;\n    }\n  }\n  auto stop = myclock::now();\n  myduration elapsed = stop - begin;\n  double duration = elapsed.count(); \n\n  printf(\"-----------------------\\n\");\n  printf(\"Summary of TestSNAP run\\n\");\n  printf(\"-----------------------\\n\");\n  printf(\"natoms = %d \\n\", nlocal);\n  printf(\"nghostatoms = %d \\n\", nghost);\n  printf(\"nsteps = %d \\n\", nsteps);\n  printf(\"nneighs = %d \\n\", ninside);\n  printf(\"twojmax = %d \\n\", twojmax);\n  printf(\"duration = %g [sec]\\n\", duration);\n\n  \n\n  double ktime = elapsed_ui + elapsed_yi + elapsed_duidrj + elapsed_deidrj;\n  printf(\"step time = %g [msec/step]\\n\", 1000.0 * duration / nsteps);\n  printf(\"\\n Individual kernel timings for each step\\n\");\n  printf(\"   compute_ui = %g [msec/step]\\n\", 1000.0 * elapsed_ui / nsteps);\n  printf(\"   compute_yi = %g [msec/step]\\n\", 1000.0 * elapsed_yi / nsteps);\n  printf(\"   compute_duidrj = %g [msec/step]\\n\", 1000.0 * elapsed_duidrj / nsteps);\n  printf(\"   compute_deidrj = %g [msec/step]\\n\", 1000.0 * elapsed_deidrj / nsteps);\n  printf(\"   Total kernel time = %g [msec/step]\\n\", 1000.0 * ktime / nsteps);\n  printf(\"   Percentage of step time = %g%%\\n\\n\", ktime / duration * 100.0);\n  printf(\"grind time = %g [msec/atom-step]\\n\", 1000.0 * duration / (nlocal * nsteps));\n  printf(\"RMS |Fj| deviation %g [eV/A]\\n\", sqrt(sumsqferr / (ntotal * nsteps)));\n\n  cudaFree(d_idxu_block);\n  cudaFree(d_ulist_parity);\n  cudaFree(d_rootpqarray);\n  cudaFree(d_idxz);\n  cudaFree(d_idxzbeta);\n  cudaFree(d_idxcg_block);\n  cudaFree(d_idxdu_block);\n  cudaFree(d_cglist);\n  cudaFree(d_dulist);\n  cudaFree(d_ulist);\n  cudaFree(d_dedr);\n  cudaFree(d_ulisttot);\n  cudaFree(d_ylist);\n  cudaFree(d_rij);\n  cudaFree(d_rcutij);\n  cudaFree(d_wj);\n\n  free(coeffi);\n  free(idxcg_block);\n  free(idxu_block);\n  free(ulist_parity);\n  free(idxdu_block);\n  free(idxb);\n  free(idxb_block);\n  free(idxz);\n  free(idxzbeta);\n  free(idxz_block);\n  free(rij);\n  free(inside);\n  free(wj);\n  free(rcutij);\n  free(rootpqarray);\n  free(cglist);\n  free(dedr);\n  free(ulist);\n  free(ylist);\n  free(ulisttot);\n  free(dulist);\n  free(f);\n\n  return 0;\n}\n"}}
{"kernel_name": "testSNAP", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include <hip/hip_runtime.h>\n#include \"snap.h\"\n#include \"utils.cu\"\n\n#if REFDATA_TWOJ == 14\n#include \"refdata_2J14_W.h\"\n#elif REFDATA_TWOJ == 8\n#include \"refdata_2J8_W.h\"\n#elif REFDATA_TWOJ == 4\n#include \"refdata_2J4_W.h\"\n#else\n#include \"refdata_2J2_W.h\"\n#endif\n\n\nint nsteps = 1; \n\n\n__global__ void reset_ulisttot(COMPLEX *ulisttot, const int ulisttot_size) \n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < ulisttot_size) ulisttot[i] = {0.0, 0.0};\n}\n\n__global__ void set_ulisttot(\n    COMPLEX *__restrict__ ulisttot,\n    const int*__restrict__ idxu_block, \n    const int num_atoms,\n    const int twojmax,\n    const double wself) \n{\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  if (natom < num_atoms) \n    for (int j = 0; j <= twojmax; j++) {\n      int jju = idxu_block[j];\n      for (int ma = 0; ma <= j; ma++) {\n        ulisttot[INDEX_2D(natom, jju)] = { wself, 0.0 };\n        jju += j + 2;\n      }\n    }\n}\n\n__global__ void update_ulisttot(\n    const double*__restrict__ rij, \n    const double*__restrict__ rcutij,\n    const double*__restrict__ wj, \n    const int*__restrict__ ulist_parity, \n    const int*__restrict__ idxu_block, \n    const double*__restrict__ rootpqarray, \n    COMPLEX *__restrict__ ulist, \n    COMPLEX *__restrict__ ulisttot, \n    const int num_atoms,\n    const int num_nbor,\n    const int switch_flag, \n    const int twojmax, \n    const int jdimpq)\n{\n\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  int nbor = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (natom < num_atoms && nbor < num_nbor) {\n    double x = rij[ULIST_INDEX(natom, nbor, 0)];\n    double y = rij[ULIST_INDEX(natom, nbor, 1)];\n    double z = rij[ULIST_INDEX(natom, nbor, 2)];\n    double rsq = x * x + y * y + z * z;\n    double r = sqrt(rsq);\n\n    double theta0 = (r - rmin0) * rfac0 * MY_PI / (rcutij[INDEX_2D(natom, nbor)] - rmin0);\n    double z0 = r / tan(theta0);\n\n    double rootpq;\n    int jju, jjup;\n\n    \n\n\n    double r0inv = 1.0 / sqrt(r * r + z0 * z0);\n    double a_r = r0inv * z0;\n    double a_i = -r0inv * z;\n    double b_r = r0inv * y;\n    double b_i = -r0inv * x;\n\n    double sfac;\n\n    sfac = compute_sfac(r, rcutij[INDEX_2D(natom, nbor)], switch_flag);\n    sfac *= wj[INDEX_2D(natom, nbor)];\n\n    \n\n    \n\n\n    \n\n    \n\n\n    \n\n    \n\n\n    \n\n    \n\n    ulist[ULIST_INDEX(natom, nbor, 0)].re = 1.0;\n    ulist[ULIST_INDEX(natom, nbor, 0)].im = 0.0;\n\n    \n\n    jju = 1;\n    for (int j = 1; j <= twojmax; j++) {\n      int deljju = j + 1;\n      for (int mb = 0; 2 * mb <= j; mb++) {\n        ulist[ULIST_INDEX(natom, nbor, jju)].re = 0.0;\n        ulist[ULIST_INDEX(natom, nbor, jju)].im = 0.0;\n        jju += deljju;\n      }\n      int ncolhalf = deljju / 2;\n      jju += deljju * ncolhalf;\n    }\n\n    jju = 1;\n    jjup = 0;\n    for (int j = 1; j <= twojmax; j++) {\n      int deljju = j + 1;\n      int deljjup = j;\n      int mb_max = (j + 1) / 2;\n      int ma_max = j;\n      int m_max = ma_max * mb_max;\n\n      \n\n      for (int m_iter = 0; m_iter < m_max; ++m_iter) {\n        int mb = m_iter / ma_max;\n        int ma = m_iter % ma_max;\n        double up_r = ulist[ULIST_INDEX(natom, nbor, jjup)].re;\n        double up_i = ulist[ULIST_INDEX(natom, nbor, jjup)].im;\n\n        rootpq = rootpqarray[ROOTPQ_INDEX(j - ma, j - mb)];\n        ulist[ULIST_INDEX(natom, nbor, jju)].re += rootpq * (a_r * up_r + a_i * up_i);\n        ulist[ULIST_INDEX(natom, nbor, jju)].im += rootpq * (a_r * up_i - a_i * up_r);\n\n        rootpq = rootpqarray[ROOTPQ_INDEX(ma + 1, j - mb)];\n        ulist[ULIST_INDEX(natom, nbor, jju+1)].re = -rootpq * (b_r * up_r + b_i * up_i);\n        ulist[ULIST_INDEX(natom, nbor, jju+1)].im = -rootpq * (b_r * up_i - b_i * up_r);\n\n        \n\n\n        if (2 * (mb + 1) == j) {\n          rootpq = rootpqarray[ROOTPQ_INDEX(j - ma, mb + 1)];\n          ulist[ULIST_INDEX(natom, nbor, jju+deljju)].re += rootpq * (b_r * up_r - b_i * up_i);\n          ulist[ULIST_INDEX(natom, nbor, jju+deljju)].im += rootpq * (b_r * up_i + b_i * up_r);\n\n          rootpq = rootpqarray[ROOTPQ_INDEX(ma + 1, mb + 1)];\n          ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].re = rootpq * (a_r * up_r - a_i * up_i);\n          ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].im = rootpq * (a_r * up_i + a_i * up_r);\n        }\n\n        jju++;\n        jjup++;\n\n        if (ma == ma_max - 1)\n          jju++;\n      }\n\n      \n\n      \n\n      \n\n      \n\n      int jjui = idxu_block[j];\n      int jjuip = jjui + (j + 1) * (j + 1) - 1;\n      for (int mb = 0; 2 * mb < j; mb++) {\n        for (int ma = 0; ma <= j; ma++) {\n          ulist[ULIST_INDEX(natom, nbor, jjuip)].re = ulist_parity[jjui] * ulist[ULIST_INDEX(natom, nbor, jjui)].re;\n          ulist[ULIST_INDEX(natom, nbor, jjuip)].im = ulist_parity[jjui] * -ulist[ULIST_INDEX(natom, nbor, jjui)].im;\n          jjui++;\n          jjuip--;\n        }\n      }\n\n      \n\n      \n\n      if (j % 2 == 0)\n        jju += deljju;\n      int ncolhalf = deljju / 2;\n      jju += deljju * ncolhalf;\n      int ncolhalfp = deljjup / 2;\n      jjup += deljjup * ncolhalfp;\n    }\n\n    sfac = compute_sfac(r, rcutij[INDEX_2D(natom, nbor)], switch_flag);\n    sfac *= wj[INDEX_2D(natom, nbor)];\n\n    for (int j = 0; j <= twojmax; j++) {\n      int jju = idxu_block[j];\n      for (int mb = 0; mb <= j; mb++)\n        for (int ma = 0; ma <= j; ma++) {\n          atomicAdd(&(ulisttot[INDEX_2D(natom, jju)].re), sfac * ulist[ULIST_INDEX(natom, nbor, jju)].re);\n          atomicAdd(&(ulisttot[INDEX_2D(natom, jju)].im), sfac * ulist[ULIST_INDEX(natom, nbor, jju)].im);\n          jju++;\n        }\n    }\n  }\n}\n\n__global__ void reset_ylist(COMPLEX *ylist, const int ylist_size) \n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < ylist_size) ylist[i] = {0.0, 0.0};\n}\n\n__global__ void compute_yi (\n    const int*__restrict__ idxz,\n    const double*__restrict__ idxzbeta,\n    const double*__restrict__ cglist,\n    const int*__restrict__ idxcg_block,\n    const int*__restrict__ idxu_block,\n    const int*__restrict__ idxdu_block,\n    const COMPLEX*__restrict__ ulisttot,\n          COMPLEX*__restrict__ ylist,\n    const int num_atoms,\n    const int idxz_max,\n    const int jdim) \n{\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  int jjz = blockIdx.y * blockDim.y + threadIdx.y;\n  if (jjz < idxz_max && natom < num_atoms) {\n    const int j1 = idxz[IDXZ_INDEX(jjz, 0)];\n    const int j2 = idxz[IDXZ_INDEX(jjz, 1)];\n    const int j = idxz[IDXZ_INDEX(jjz, 2)];\n    const int ma1min = idxz[IDXZ_INDEX(jjz, 3)];\n    const int ma2max = idxz[IDXZ_INDEX(jjz, 4)];\n    const int na = idxz[IDXZ_INDEX(jjz, 5)];\n    const int mb1min = idxz[IDXZ_INDEX(jjz, 6)];\n    const int mb2max = idxz[IDXZ_INDEX(jjz, 7)];\n    const int nb = idxz[IDXZ_INDEX(jjz, 8)];\n\n    const double betaj = idxzbeta[jjz];\n\n    const double* cgblock = cglist + idxcg_block[j1 + jdim*j2 + jdim*jdim*j];\n\n    int mb = (2 * (mb1min + mb2max) - j1 - j2 + j) / 2;\n    int ma = (2 * (ma1min + ma2max) - j1 - j2 + j) / 2;\n    const int jjdu = idxdu_block[j] + (j + 1) * mb + ma;\n\n    int jju1 = idxu_block[j1] + (j1 + 1) * mb1min;\n    int jju2 = idxu_block[j2] + (j2 + 1) * mb2max;\n    int icgb = mb1min * (j2 + 1) + mb2max;\n\n    double ztmp_r = 0.0;\n    double ztmp_i = 0.0;\n\n    \n\n    \n\n    \n\n\n    for (int ib = 0; ib < nb; ib++) {\n\n      double suma1_r = 0.0;\n      double suma1_i = 0.0;\n\n      int ma1 = ma1min;\n      int ma2 = ma2max;\n      int icga = ma1min * (j2 + 1) + ma2max;\n\n      \n\n      \n\n      \n\n\n      for (int ia = 0; ia < na; ia++) {\n        suma1_r += cgblock[icga] *\n          (ulisttot[INDEX_2D(natom, jju1 + ma1)].re * ulisttot[INDEX_2D(natom, jju2 + ma2)].re -\n           ulisttot[INDEX_2D(natom, jju1 + ma1)].im * ulisttot[INDEX_2D(natom, jju2 + ma2)].im);\n\n        suma1_i += cgblock[icga] *\n          (ulisttot[INDEX_2D(natom, jju1 + ma1)].re * ulisttot[INDEX_2D(natom, jju2 + ma2)].im +\n           ulisttot[INDEX_2D(natom, jju1 + ma1)].im * ulisttot[INDEX_2D(natom, jju2 + ma2)].re);\n\n        ma1++;\n        ma2--;\n        icga += j2;\n      } \n\n\n      ztmp_r += cgblock[icgb] * suma1_r;\n      ztmp_i += cgblock[icgb] * suma1_i;\n      jju1 += j1 + 1;\n      jju2 -= j2 + 1;\n      icgb += j2;\n    } \n\n\n    \n\n\n    atomicAdd(&(ylist[INDEX_2D(natom, jjdu)].re), betaj * ztmp_r);\n    atomicAdd(&(ylist[INDEX_2D(natom, jjdu)].im), betaj * ztmp_i);\n\n  } \n\n}\n\n__global__ void compute_duidrj (\n    const double *__restrict__ wj,\n    const double *__restrict__ rij,\n    const double *__restrict__ rcutij,\n    const double*__restrict__ rootpqarray,\n    const COMPLEX*__restrict__ ulist,\n          COMPLEX*__restrict__ dulist,\n    const int num_atoms,\n    const int num_nbor,\n    const int twojmax,\n    const int idxdu_max,\n    const int jdimpq,\n    const int switch_flag)\n{\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  int nbor = blockIdx.y * blockDim.y + threadIdx.y;\n  if (natom < num_atoms && nbor < num_nbor) {\n    double wj_in = wj[INDEX_2D(natom, nbor)];\n    double rcut = rcutij[INDEX_2D(natom, nbor)];\n\n    double x = rij[ULIST_INDEX(natom, nbor, 0)];\n    double y = rij[ULIST_INDEX(natom, nbor, 1)];\n    double z = rij[ULIST_INDEX(natom, nbor, 2)];\n    double rsq = x * x + y * y + z * z;\n    double r = sqrt(rsq);\n    double rscale0 = rfac0 * MY_PI / (rcut - rmin0);\n    double theta0 = (r - rmin0) * rscale0;\n    double cs = cos(theta0);\n    double sn = sin(theta0);\n    double z0 = r * cs / sn;\n    double dz0dr = z0 / r - (r * rscale0) * (rsq + z0 * z0) / rsq;\n\n    compute_duarray(natom, nbor, num_atoms, num_nbor, \n        twojmax, idxdu_max, jdimpq, switch_flag,\n        x, y, z, z0, r, dz0dr, wj_in, rcut,\n        rootpqarray,\n        ulist,\n        dulist);\n  }\n}\n\n__global__ void compute_deidrj(\n    const int*__restrict__ idxdu_block,\n    const COMPLEX*__restrict__ dulist,\n    const COMPLEX*__restrict__ ylist,\n    double*__restrict__ dedr,\n    const int num_atoms,\n    const int num_nbor,\n    const int twojmax,\n    const int idxdu_max)\n{\n  int natom = blockIdx.x * blockDim.x + threadIdx.x;\n  int nbor = blockIdx.y * blockDim.y + threadIdx.y;\n  if (natom < num_atoms && nbor < num_nbor) {\n    for (int k = 0; k < 3; k++)\n      dedr[ULIST_INDEX(natom, nbor, k)] = 0.0;\n\n    for (int j = 0; j <= twojmax; j++) {\n      int jjdu = idxdu_block[j];\n\n      for (int mb = 0; 2 * mb < j; mb++)\n        for (int ma = 0; ma <= j; ma++) {\n\n          double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n          double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n          for (int k = 0; k < 3; k++)\n            dedr[ULIST_INDEX(natom, nbor, k)] +=\n              dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n              dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n          jjdu++;\n        } \n\n\n      \n\n\n      if (j % 2 == 0) {\n\n        int mb = j / 2;\n        for (int ma = 0; ma < mb; ma++) {\n          double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n          double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n          for (int k = 0; k < 3; k++)\n            dedr[ULIST_INDEX(natom, nbor, k)] +=\n              dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n              dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n          jjdu++;\n        }\n\n        double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n        double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n        for (int k = 0; k < 3; k++)\n          dedr[ULIST_INDEX(natom, nbor, k)] +=\n            (dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n             dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i) *\n            0.5;\n        jjdu++;\n\n      } \n\n\n    } \n\n\n    for (int k = 0; k < 3; k++)\n      dedr[ULIST_INDEX(natom, nbor, k)] *= 2.0;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  options(argc, argv);\n\n  const int switch_flag = 1;     \n\n\n  \n\n  double elapsed_ui = 0.0, \n         elapsed_yi = 0.0, \n         elapsed_duidrj = 0.0,\n         elapsed_deidrj = 0.0;\n\n  const int ninside = refdata.ninside;\n  const int ncoeff = refdata.ncoeff;\n  const int nlocal = refdata.nlocal;\n  const int nghost = refdata.nghost;\n  const int ntotal = nlocal + nghost;\n  const int twojmax = refdata.twojmax;\n  const double rcutfac = refdata.rcutfac;\n\n  const double wself = 1.0;\n  const int num_atoms = nlocal; \n  const int num_nbor = ninside; \n\n  \n\n  double* coeffi = (double*) malloc (sizeof(double) * (ncoeff+1));\n\n  for (int icoeff = 0; icoeff < ncoeff + 1; icoeff++)\n    coeffi[icoeff] = refdata.coeff[icoeff];\n\n  double* beta = coeffi + 1;\n\n  \n\n  const int jdim = twojmax + 1;\n\n  \n\n\n  int *idxcg_block = (int*) malloc(sizeof(int) * jdim * jdim * jdim);\n\n  int idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxcg_block[j1 + j2 *jdim + jdim*jdim*j] = idxcg_count;\n        for (int m1 = 0; m1 <= j1; m1++)\n          for (int m2 = 0; m2 <= j2; m2++)\n            idxcg_count++;\n      }\n  const int idxcg_max = idxcg_count;\n\n  \n\n  \n\n  \n\n\n  int* idxu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxu_block[j] = idxu_count;\n    for (int mb = 0; mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxu_count++;\n  }\n  const int idxu_max = idxu_count;\n\n  \n\n  \n\n  \n\n\n  \n\n  int* ulist_parity = (int*) malloc (sizeof(int) * idxu_max);\n  idxu_count = 0;\n  for (int j = 0; j <= twojmax; j++) {\n    int mbpar = 1;\n    for (int mb = 0; mb <= j; mb++) {\n      int mapar = mbpar;\n      for (int ma = 0; ma <= j; ma++) {\n        ulist_parity[idxu_count] = mapar;\n        mapar = -mapar;\n        idxu_count++;\n      }\n      mbpar = -mbpar;\n    }\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  int* idxdu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxdu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxdu_block[j] = idxdu_count;\n    for (int mb = 0; 2 * mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxdu_count++;\n  }\n  const int idxdu_max = idxdu_count;\n\n  \n\n\n  int idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1)\n          idxb_count++;\n\n  const int idxb_max = idxb_count;\n  SNA_BINDICES* idxb = (SNA_BINDICES*) malloc (sizeof(SNA_BINDICES) * idxb_max);\n\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1) {\n          idxb[idxb_count].j1 = j1;\n          idxb[idxb_count].j2 = j2;\n          idxb[idxb_count].j = j;\n          idxb_count++;\n        }\n\n  \n\n\n  int* idxb_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        if (j < j1)\n          continue;\n        idxb_block[j1*jdim*jdim+j2*jdim+j] = idxb_count;\n        idxb_count++;\n      }\n\n\n  \n\n\n  int idxz_count = 0;\n\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++)\n            idxz_count++;\n\n  const int idxz_max = idxz_count;\n  \n\n  int* idxz = (int*) malloc (sizeof(int) * idxz_max * 9);\n\n  \n\n  double* idxzbeta = (double*) malloc (sizeof(double) * idxz_max);\n\n  \n\n  int* idxz_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n\n  idxz_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxz_block[j1*jdim*jdim+j2*jdim+j] = idxz_count;\n\n        \n\n        \n\n        \n\n        \n\n\n        double betaj;\n        if (j >= j1) {\n          const int jjb = idxb_block[j1*jdim*jdim+j2*jdim+j];\n          if (j1 == j) {\n            if (j2 == j) {\n              betaj = 3 * beta[jjb];\n            }\n            else {\n              betaj = 2 * beta[jjb];\n            }\n          } else {\n            betaj = beta[jjb];\n          }\n        } else if (j >= j2) {\n          const int jjb = idxb_block[j*jdim*jdim+j2*jdim+j1];\n          if (j2 == j) {\n            betaj = 2 * beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n          else {\n            betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n        } else {\n          const int jjb = idxb_block[j2*jdim*jdim+j*jdim+j1];\n          betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n        }\n\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++) {\n\n            idxz[IDXZ_INDEX(idxz_count, 0)] = j1;\n            idxz[IDXZ_INDEX(idxz_count, 1)] = j2;\n            idxz[IDXZ_INDEX(idxz_count, 2)] = j;\n\n            int ma1min = MAX(0, (2 * ma - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 3)] = ma1min;\n            idxz[IDXZ_INDEX(idxz_count, 4)] = (2 * ma - j - (2 * ma1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 5)] =\n              MIN(j1, (2 * ma - j + j2 + j1) / 2) - ma1min + 1;\n\n            int mb1min = MAX(0, (2 * mb - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 6)] = mb1min;\n            idxz[IDXZ_INDEX(idxz_count, 7)] = (2 * mb - j - (2 * mb1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 8)] =\n              MIN(j1, (2 * mb - j + j2 + j1) / 2) - mb1min + 1;\n\n            idxzbeta[idxz_count] = betaj;\n\n            idxz_count++;\n          }\n      }\n  \n\n\n\n  if (compute_ncoeff(twojmax) != ncoeff) {\n    printf(\"ERROR: ncoeff from SNA does not match reference data\\n\");\n    exit(1);\n  }\n\n  \n\n\n  double *rij    = (double*) malloc(sizeof(double) * (num_atoms * num_nbor * 3));\n  double *inside = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *wj     = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *rcutij = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n\n  const int jdimpq = twojmax + 2;\n  double* rootpqarray = (double*) malloc(sizeof(double) * jdimpq * jdimpq);\n  double* cglist = (double*) malloc (sizeof(double) * idxcg_max);\n  double* dedr = (double*) malloc (sizeof(double) * num_atoms * num_nbor * 3); \n\n  COMPLEX* ulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * idxu_max); \n  COMPLEX* ylist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxdu_max);\n  COMPLEX* ulisttot = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxu_max);\n  COMPLEX* dulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * 3 * idxdu_max);\n\n  \n\n  for (int p = 1; p <= twojmax; p++)\n    for (int q = 1; q <= twojmax; q++)\n      rootpqarray[ROOTPQ_INDEX(p, q)] = sqrt(static_cast<double>(p) / q);\n\n  \n\n  double sum, dcg, sfaccg;\n  int m, aa2, bb2, cc2;\n  int ifac;\n\n  idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        for (int m1 = 0; m1 <= j1; m1++) {\n          aa2 = 2 * m1 - j1;\n\n          for (int m2 = 0; m2 <= j2; m2++) {\n\n            \n\n\n            bb2 = 2 * m2 - j2;\n            m = (aa2 + bb2 + j) / 2;\n\n            if (m < 0 || m > j) {\n              cglist[idxcg_count] = 0.0;\n              idxcg_count++;\n              continue;\n            }\n\n            sum = 0.0;\n\n            for (int z = MAX(0, MAX(-(j - j2 + aa2) / 2, -(j - j1 - bb2) / 2));\n                z <=\n                MIN((j1 + j2 - j) / 2, MIN((j1 - aa2) / 2, (j2 + bb2) / 2));\n                z++) {\n              ifac = z % 2 ? -1 : 1;\n              sum += ifac / (factorial(z) * factorial((j1 + j2 - j) / 2 - z) *\n                  factorial((j1 - aa2) / 2 - z) *\n                  factorial((j2 + bb2) / 2 - z) *\n                  factorial((j - j2 + aa2) / 2 + z) *\n                  factorial((j - j1 - bb2) / 2 + z));\n            }\n\n            cc2 = 2 * m - j;\n            dcg = deltacg(j1, j2, j);\n            sfaccg = sqrt(\n                factorial((j1 + aa2) / 2) * factorial((j1 - aa2) / 2) *\n                factorial((j2 + bb2) / 2) * factorial((j2 - bb2) / 2) *\n                factorial((j + cc2) / 2) * factorial((j - cc2) / 2) * (j + 1));\n\n            cglist[idxcg_count] = sum * dcg * sfaccg;\n            idxcg_count++;\n          }\n        }\n      }\n\n  double* f = (double*) malloc (sizeof(double) * ntotal * 3);\n\n  \n\n  double sumsqferr = 0.0;\n\n  int* d_idxu_block;\n  hipMalloc((void**)&d_idxu_block, sizeof(int)*jdim);\n  hipMemcpy(d_idxu_block, idxu_block, sizeof(int)*jdim, hipMemcpyHostToDevice);\n\n  int* d_ulist_parity;\n  hipMalloc((void**)&d_ulist_parity, sizeof(int)*idxu_max);\n  hipMemcpy(d_ulist_parity, ulist_parity, sizeof(int)*idxu_max, hipMemcpyHostToDevice);\n\n  double* d_rootpqarray;\n  hipMalloc((void**)&d_rootpqarray, sizeof(double)*jdimpq*jdimpq);\n  hipMemcpy(d_rootpqarray, rootpqarray, sizeof(double)*jdimpq*jdimpq, hipMemcpyHostToDevice); \n\n  int* d_idxz;\n  hipMalloc((void**)&d_idxz, sizeof(int)*idxz_max*9);\n  hipMemcpy(d_idxz, idxz, sizeof(int)*idxz_max*9, hipMemcpyHostToDevice);\n\n  double* d_idxzbeta;\n  hipMalloc((void**)&d_idxzbeta, sizeof(double)*idxz_max);\n  hipMemcpy(d_idxzbeta, idxzbeta, sizeof(double)*idxz_max, hipMemcpyHostToDevice);\n\n  int* d_idxcg_block;\n  hipMalloc((void**)&d_idxcg_block, sizeof(int)*jdim*jdim*jdim);\n  hipMemcpy(d_idxcg_block, idxcg_block, sizeof(int)*jdim*jdim*jdim, hipMemcpyHostToDevice);\n\n  int* d_idxdu_block;\n  hipMalloc((void**)&d_idxdu_block, sizeof(int)*jdim);\n  hipMemcpy(d_idxdu_block, idxdu_block, sizeof(int)*jdim, hipMemcpyHostToDevice);\n\n  double* d_cglist;\n  hipMalloc((void**)&d_cglist, sizeof(double)*idxcg_max);\n  hipMemcpy(d_cglist, cglist, sizeof(double)*idxcg_max, hipMemcpyHostToDevice);\n\n  COMPLEX* d_dulist;\n  hipMalloc((void**)&d_dulist, sizeof(COMPLEX)*num_atoms*num_nbor*3*idxdu_max);\n  hipMemcpy(d_dulist, dulist, sizeof(COMPLEX)*num_atoms*num_nbor*3*idxdu_max, hipMemcpyHostToDevice);\n\n  COMPLEX* d_ulist;\n  hipMalloc((void**)&d_ulist, sizeof(COMPLEX)*num_atoms*num_nbor*idxu_max);\n  hipMemcpy(d_ulist, ulist, sizeof(COMPLEX)*num_atoms*num_nbor*idxu_max, hipMemcpyHostToDevice);\n\n  double* d_dedr;\n  hipMalloc((void**)&d_dedr, sizeof(double)*num_atoms*num_nbor*3);\n  hipMemcpy(d_dedr, dedr, sizeof(double)*num_atoms*num_nbor*3, hipMemcpyHostToDevice);\n\n  COMPLEX* d_ulisttot;\n  hipMalloc((void**)&d_ulisttot, sizeof(COMPLEX)*num_atoms*idxu_max);\n\n  COMPLEX* d_ylist;\n  hipMalloc((void**)&d_ylist, sizeof(COMPLEX)*num_atoms*idxdu_max);\n\n  double *d_rij;\n  hipMalloc((void**)&d_rij, sizeof(double)*num_atoms*num_nbor*3);\n\n  double *d_rcutij;\n  hipMalloc((void**)&d_rcutij, sizeof(double)*num_atoms*num_nbor);\n\n  double *d_wj;\n  hipMalloc((void**)&d_wj, sizeof(double)*num_atoms*num_nbor);\n\n\n  \n\n\n  auto begin = myclock::now();\n\n  for (int istep = 0; istep < nsteps; istep++) {\n\n    time_point<system_clock> start, end;\n    duration<double> elapsed;\n\n    for (int j = 0; j < ntotal * 3; j++) {\n      f[j] = 0.0;\n    }\n\n    int jt = 0, jjt = 0;\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        \n\n        rij[ULIST_INDEX(natom, nbor, 0)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 1)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 2)] = refdata.rij[jt++];\n        inside[INDEX_2D(natom, nbor)] = refdata.jlist[jjt++];\n        wj[INDEX_2D(natom, nbor)] = 1.0;\n        rcutij[INDEX_2D(natom, nbor)] = rcutfac;\n      }\n    }\n\n    hipMemcpy(d_rij, rij, sizeof(double)*num_atoms*num_nbor*3, hipMemcpyHostToDevice);\n    hipMemcpy(d_rcutij, rcutij, sizeof(double)*num_atoms*num_nbor, hipMemcpyHostToDevice);\n    hipMemcpy(d_wj, wj, sizeof(double)*num_atoms*num_nbor, hipMemcpyHostToDevice);\n\n    \n\n    start = system_clock::now();\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    dim3 grid_k1 ((num_atoms*idxu_max+255)/256);\n    dim3 block_k1 (256);\n    hipLaunchKernelGGL(reset_ulisttot, grid_k1, block_k1, 0, 0, d_ulisttot, num_atoms*idxu_max);\n\n\n    dim3 grid_k2 ((num_atoms+255)/256);\n    dim3 block_k2 (256);\n    hipLaunchKernelGGL(set_ulisttot, grid_k2, block_k2, 0, 0, d_ulisttot, d_idxu_block, num_atoms, twojmax, wself);\n\n\n    dim3 grid_k3 ((num_atoms+15)/16, (num_nbor+15)/16);\n    dim3 block_k3 (16, 16);\n\n    hipLaunchKernelGGL(update_ulisttot, grid_k3, block_k3, 0, 0, \n        d_rij, \n        d_rcutij,\n        d_wj,\n        d_ulist_parity,\n        d_idxu_block,\n        d_rootpqarray,\n        d_ulist,\n        d_ulisttot,\n        num_atoms,\n        num_nbor,\n        switch_flag,\n        twojmax,\n        jdimpq);\n\n    hipDeviceSynchronize();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_ui += elapsed.count();\n\n    start = system_clock::now();\n\n    \n\n    dim3 grid_k4 ((num_atoms*idxdu_max+255)/256);\n    dim3 block_k4 (256);\n\n    hipLaunchKernelGGL(reset_ylist, grid_k4, block_k4, 0, 0, d_ylist, num_atoms*idxdu_max);\n\n    dim3 grid_k5 ((num_atoms+15)/16, (idxz_max+15)/16);\n    dim3 block_k5 (16, 16);\n\n    hipLaunchKernelGGL(compute_yi, grid_k5, block_k5, 0, 0, \n        d_idxz,\n        d_idxzbeta,\n        d_cglist,\n        d_idxcg_block,\n        d_idxu_block,\n        d_idxdu_block,\n        d_ulisttot,\n        d_ylist,\n        num_atoms,\n        idxz_max,\n        jdim);\n\n    hipDeviceSynchronize();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_yi += elapsed.count();\n\n    \n\n    start = system_clock::now();\n\n    dim3 grid_k6 ((num_atoms+15)/16, (num_nbor+15)/16);\n    dim3 block_k6 (16, 16);\n    hipLaunchKernelGGL(compute_duidrj, grid_k6, block_k6, 0, 0, \n        d_wj,\n        d_rij,\n        d_rcutij,\n        d_rootpqarray,\n        d_ulist,\n        d_dulist,\n        num_atoms,\n        num_nbor,\n        twojmax,\n        idxdu_max,\n        jdimpq,\n        switch_flag);\n\n    hipDeviceSynchronize();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_duidrj += elapsed.count();\n\n    start = system_clock::now();\n\n    \n\n    dim3 grid_k7 ((num_atoms+15)/16, (num_nbor+15)/16);\n    dim3 block_k7 (16, 16);\n\n    hipLaunchKernelGGL(compute_deidrj, grid_k7, block_k7, 0, 0,  \n        d_idxdu_block,\n        d_dulist,\n        d_ylist,\n        d_dedr,\n        num_atoms,\n        num_nbor,\n        twojmax,\n        idxdu_max);\n\n    hipDeviceSynchronize();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_deidrj += elapsed.count();\n\n    hipMemcpy(dedr, d_dedr, sizeof(double)*num_atoms*num_nbor*3, hipMemcpyDeviceToHost);\n\n    \n\n    \n\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        int j = inside[INDEX_2D(natom, nbor)];\n        f[F_INDEX(natom, 0)] += dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(natom, 1)] += dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(natom, 2)] += dedr[ULIST_INDEX(natom, nbor, 2)];\n        f[F_INDEX(j, 0)] -= dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(j, 1)] -= dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(j, 2)] -= dedr[ULIST_INDEX(natom, nbor, 2)];\n\n      } \n\n    }   \n\n    \n\n    jt = 0;\n    for (int j = 0; j < ntotal; j++) {\n      double ferrx = f[F_INDEX(j, 0)] - refdata.fj[jt++];\n      double ferry = f[F_INDEX(j, 1)] - refdata.fj[jt++];\n      double ferrz = f[F_INDEX(j, 2)] - refdata.fj[jt++];\n      sumsqferr += ferrx * ferrx + ferry * ferry + ferrz * ferrz;\n    }\n  }\n  auto stop = myclock::now();\n  myduration elapsed = stop - begin;\n  double duration = elapsed.count(); \n\n  printf(\"-----------------------\\n\");\n  printf(\"Summary of TestSNAP run\\n\");\n  printf(\"-----------------------\\n\");\n  printf(\"natoms = %d \\n\", nlocal);\n  printf(\"nghostatoms = %d \\n\", nghost);\n  printf(\"nsteps = %d \\n\", nsteps);\n  printf(\"nneighs = %d \\n\", ninside);\n  printf(\"twojmax = %d \\n\", twojmax);\n  printf(\"duration = %g [sec]\\n\", duration);\n\n  \n\n  double ktime = elapsed_ui + elapsed_yi + elapsed_duidrj + elapsed_deidrj;\n  printf(\"step time = %g [msec/step]\\n\", 1000.0 * duration / nsteps);\n  printf(\"\\n Individual kernel timings for each step\\n\");\n  printf(\"   compute_ui = %g [msec/step]\\n\", 1000.0 * elapsed_ui / nsteps);\n  printf(\"   compute_yi = %g [msec/step]\\n\", 1000.0 * elapsed_yi / nsteps);\n  printf(\"   compute_duidrj = %g [msec/step]\\n\", 1000.0 * elapsed_duidrj / nsteps);\n  printf(\"   compute_deidrj = %g [msec/step]\\n\", 1000.0 * elapsed_deidrj / nsteps);\n  printf(\"   Total kernel time = %g [msec/step]\\n\", 1000.0 * ktime / nsteps);\n  printf(\"   Percentage of step time = %g%%\\n\\n\", ktime / duration * 100.0);\n  printf(\"grind time = %g [msec/atom-step]\\n\", 1000.0 * duration / (nlocal * nsteps));\n  printf(\"RMS |Fj| deviation %g [eV/A]\\n\", sqrt(sumsqferr / (ntotal * nsteps)));\n\n  hipFree(d_idxu_block);\n  hipFree(d_ulist_parity);\n  hipFree(d_rootpqarray);\n  hipFree(d_idxz);\n  hipFree(d_idxzbeta);\n  hipFree(d_idxcg_block);\n  hipFree(d_idxdu_block);\n  hipFree(d_cglist);\n  hipFree(d_dulist);\n  hipFree(d_ulist);\n  hipFree(d_dedr);\n  hipFree(d_ulisttot);\n  hipFree(d_ylist);\n  hipFree(d_rij);\n  hipFree(d_rcutij);\n  hipFree(d_wj);\n\n  free(coeffi);\n  free(idxcg_block);\n  free(idxu_block);\n  free(ulist_parity);\n  free(idxdu_block);\n  free(idxb);\n  free(idxb_block);\n  free(idxz);\n  free(idxzbeta);\n  free(idxz_block);\n  free(rij);\n  free(inside);\n  free(wj);\n  free(rcutij);\n  free(rootpqarray);\n  free(cglist);\n  free(dedr);\n  free(ulist);\n  free(ylist);\n  free(ulisttot);\n  free(dulist);\n  free(f);\n\n  return 0;\n}\n"}}
{"kernel_name": "testSNAP", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include \"snap.h\"\n#include \"utils.cpp\"\n\n#if REFDATA_TWOJ == 14\n#include \"refdata_2J14_W.h\"\n#elif REFDATA_TWOJ == 8\n#include \"refdata_2J8_W.h\"\n#elif REFDATA_TWOJ == 4\n#include \"refdata_2J4_W.h\"\n#else\n#include \"refdata_2J2_W.h\"\n#endif\n\n\nint nsteps = 1; \n\n\nint main(int argc, char* argv[])\n{\n  options(argc, argv);\n\n  const int switch_flag = 1;     \n\n\n  \n\n  double elapsed_ui = 0.0, \n         elapsed_yi = 0.0, \n         elapsed_duidrj = 0.0,\n         elapsed_deidrj = 0.0;\n\n  const int ninside = refdata.ninside;\n  const int ncoeff = refdata.ncoeff;\n  const int nlocal = refdata.nlocal;\n  const int nghost = refdata.nghost;\n  const int ntotal = nlocal + nghost;\n  const int twojmax = refdata.twojmax;\n  const double rcutfac = refdata.rcutfac;\n\n  const double wself = 1.0;\n  const int num_atoms = nlocal; \n  const int num_nbor = ninside; \n\n  \n\n  double* coeffi = (double*) malloc (sizeof(double) * (ncoeff+1));\n\n  for (int icoeff = 0; icoeff < ncoeff + 1; icoeff++)\n    coeffi[icoeff] = refdata.coeff[icoeff];\n\n  double* beta = coeffi + 1;\n\n  \n\n  const int jdim = twojmax + 1;\n\n  \n\n\n  int *idxcg_block = (int*) malloc(sizeof(int) * jdim * jdim * jdim);\n\n  int idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxcg_block[j1 + j2 *jdim + jdim*jdim*j] = idxcg_count;\n        for (int m1 = 0; m1 <= j1; m1++)\n          for (int m2 = 0; m2 <= j2; m2++)\n            idxcg_count++;\n      }\n  const int idxcg_max = idxcg_count;\n\n  \n\n  \n\n  \n\n\n  int* idxu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxu_block[j] = idxu_count;\n    for (int mb = 0; mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxu_count++;\n  }\n  const int idxu_max = idxu_count;\n\n  \n\n  \n\n  \n\n\n  \n\n  int* ulist_parity = (int*) malloc (sizeof(int) * idxu_max);\n  idxu_count = 0;\n  for (int j = 0; j <= twojmax; j++) {\n    int mbpar = 1;\n    for (int mb = 0; mb <= j; mb++) {\n      int mapar = mbpar;\n      for (int ma = 0; ma <= j; ma++) {\n        ulist_parity[idxu_count] = mapar;\n        mapar = -mapar;\n        idxu_count++;\n      }\n      mbpar = -mbpar;\n    }\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  int* idxdu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxdu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxdu_block[j] = idxdu_count;\n    for (int mb = 0; 2 * mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxdu_count++;\n  }\n  const int idxdu_max = idxdu_count;\n\n  \n\n\n  int idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1)\n          idxb_count++;\n\n  const int idxb_max = idxb_count;\n  SNA_BINDICES* idxb = (SNA_BINDICES*) malloc (sizeof(SNA_BINDICES) * idxb_max);\n\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1) {\n          idxb[idxb_count].j1 = j1;\n          idxb[idxb_count].j2 = j2;\n          idxb[idxb_count].j = j;\n          idxb_count++;\n        }\n\n  \n\n\n  int* idxb_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        if (j < j1)\n          continue;\n        idxb_block[j1*jdim*jdim+j2*jdim+j] = idxb_count;\n        idxb_count++;\n      }\n\n\n  \n\n\n  int idxz_count = 0;\n\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++)\n            idxz_count++;\n\n  const int idxz_max = idxz_count;\n  \n\n  int* idxz = (int*) malloc (sizeof(int) * idxz_max * 9);\n\n  \n\n  double* idxzbeta = (double*) malloc (sizeof(double) * idxz_max);\n\n  \n\n  int* idxz_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n\n  idxz_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxz_block[j1*jdim*jdim+j2*jdim+j] = idxz_count;\n\n        \n\n        \n\n        \n\n        \n\n\n        double betaj;\n        if (j >= j1) {\n          const int jjb = idxb_block[j1*jdim*jdim+j2*jdim+j];\n          if (j1 == j) {\n            if (j2 == j) {\n              betaj = 3 * beta[jjb];\n            }\n            else {\n              betaj = 2 * beta[jjb];\n            }\n          } else {\n            betaj = beta[jjb];\n          }\n        } else if (j >= j2) {\n          const int jjb = idxb_block[j*jdim*jdim+j2*jdim+j1];\n          if (j2 == j) {\n            betaj = 2 * beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n          else {\n            betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n        } else {\n          const int jjb = idxb_block[j2*jdim*jdim+j*jdim+j1];\n          betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n        }\n\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++) {\n\n            idxz[IDXZ_INDEX(idxz_count, 0)] = j1;\n            idxz[IDXZ_INDEX(idxz_count, 1)] = j2;\n            idxz[IDXZ_INDEX(idxz_count, 2)] = j;\n\n            int ma1min = MAX(0, (2 * ma - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 3)] = ma1min;\n            idxz[IDXZ_INDEX(idxz_count, 4)] = (2 * ma - j - (2 * ma1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 5)] =\n              MIN(j1, (2 * ma - j + j2 + j1) / 2) - ma1min + 1;\n\n            int mb1min = MAX(0, (2 * mb - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 6)] = mb1min;\n            idxz[IDXZ_INDEX(idxz_count, 7)] = (2 * mb - j - (2 * mb1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 8)] =\n              MIN(j1, (2 * mb - j + j2 + j1) / 2) - mb1min + 1;\n\n            idxzbeta[idxz_count] = betaj;\n\n            idxz_count++;\n          }\n      }\n  \n\n\n\n  if (compute_ncoeff(twojmax) != ncoeff) {\n    printf(\"ERROR: ncoeff from SNA does not match reference data\\n\");\n    exit(1);\n  }\n\n  \n\n\n  double *rij    = (double*) malloc(sizeof(double) * (num_atoms * num_nbor * 3));\n  double *inside = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *wj     = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *rcutij = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n\n  const int jdimpq = twojmax + 2;\n  double* rootpqarray = (double*) malloc(sizeof(double) * jdimpq * jdimpq);\n  double* cglist = (double*) malloc (sizeof(double) * idxcg_max);\n  double* dedr = (double*) malloc (sizeof(double) * num_atoms * num_nbor * 3); \n\n  COMPLEX* ulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * idxu_max); \n  COMPLEX* ylist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxdu_max);\n  COMPLEX* ulisttot = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxu_max);\n  COMPLEX* dulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * 3 * idxdu_max);\n\n  \n\n  for (int p = 1; p <= twojmax; p++)\n    for (int q = 1; q <= twojmax; q++)\n      rootpqarray[ROOTPQ_INDEX(p, q)] = sqrt(static_cast<double>(p) / q);\n\n  \n\n  double sum, dcg, sfaccg;\n  int m, aa2, bb2, cc2;\n  int ifac;\n\n  idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        for (int m1 = 0; m1 <= j1; m1++) {\n          aa2 = 2 * m1 - j1;\n\n          for (int m2 = 0; m2 <= j2; m2++) {\n\n            \n\n\n            bb2 = 2 * m2 - j2;\n            m = (aa2 + bb2 + j) / 2;\n\n            if (m < 0 || m > j) {\n              cglist[idxcg_count] = 0.0;\n              idxcg_count++;\n              continue;\n            }\n\n            sum = 0.0;\n\n            for (int z = MAX(0, MAX(-(j - j2 + aa2) / 2, -(j - j1 - bb2) / 2));\n                z <=\n                MIN((j1 + j2 - j) / 2, MIN((j1 - aa2) / 2, (j2 + bb2) / 2));\n                z++) {\n              ifac = z % 2 ? -1 : 1;\n              sum += ifac / (factorial(z) * factorial((j1 + j2 - j) / 2 - z) *\n                  factorial((j1 - aa2) / 2 - z) *\n                  factorial((j2 + bb2) / 2 - z) *\n                  factorial((j - j2 + aa2) / 2 + z) *\n                  factorial((j - j1 - bb2) / 2 + z));\n            }\n\n            cc2 = 2 * m - j;\n            dcg = deltacg(j1, j2, j);\n            sfaccg = sqrt(\n                factorial((j1 + aa2) / 2) * factorial((j1 - aa2) / 2) *\n                factorial((j2 + bb2) / 2) * factorial((j2 - bb2) / 2) *\n                factorial((j + cc2) / 2) * factorial((j - cc2) / 2) * (j + 1));\n\n            cglist[idxcg_count] = sum * dcg * sfaccg;\n            idxcg_count++;\n          }\n        }\n      }\n\n  double* f = (double*) malloc (sizeof(double) * ntotal * 3);\n\n  \n\n  double sumsqferr = 0.0;\n\n#if defined(OPENMP_TARGET)\n#pragma omp target data map(to: idxu_block[0:jdim], \\\n                                ulist_parity[0:idxu_max], \\\n                                rootpqarray[0:jdimpq * jdimpq], \\\n                                idxz[0:idxz_max*9], \\\n                                idxzbeta[0:idxz_max], \\\n                                idxcg_block[0:jdim*jdim*jdim], \\\n                                idxdu_block[0:jdim], \\\n                                cglist[0:idxcg_max], \\\n                                ulist[0:num_atoms * num_nbor * idxu_max], \\\n                                dulist[0: num_atoms * num_nbor * 3 * idxdu_max], \\\n                                dedr[0:num_atoms * num_nbor * 3]) \\\n                       map(alloc: ulisttot[0:num_atoms * idxu_max], \\\n                                  ylist[0:num_atoms * idxdu_max], \\\n                                  rij[0:num_atoms*num_nbor*3], \\\n                                  rcutij[0:num_atoms*num_nbor], \\\n                                  wj[0:num_atoms*num_nbor])\n{\n#endif\n\n  \n\n\n  auto begin = myclock::now();\n  for (int istep = 0; istep < nsteps; istep++) {\n\n    time_point<system_clock> start, end;\n    duration<double> elapsed;\n\n    for (int j = 0; j < ntotal * 3; j++) {\n      f[j] = 0.0;\n    }\n\n    int jt = 0, jjt = 0;\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        rij[ULIST_INDEX(natom, nbor, 0)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 1)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 2)] = refdata.rij[jt++];\n        inside[INDEX_2D(natom, nbor)] = refdata.jlist[jjt++];\n        wj[INDEX_2D(natom, nbor)] = 1.0;\n        rcutij[INDEX_2D(natom, nbor)] = rcutfac;\n      }\n    }\n\n#if defined(OPENMP_TARGET)\n#pragma omp target update to(rij[0:num_atoms*num_nbor*3])\n#pragma omp target update to(rcutij[0:num_atoms*num_nbor])\n#pragma omp target update to(wj[0:num_atoms*num_nbor])\n#endif\n\n    \n\n    start = system_clock::now();\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n#if defined(OPENMP_TARGET)\n#pragma omp target teams distribute parallel for\n#else\n#pragma omp parallel for default(none) shared(ulisttot, num_atoms, idxu_max)\n#endif\n    for (int i = 0; i < num_atoms * idxu_max; ++i)\n      ulisttot[i] = { 0.0, 0.0 };\n\n#if (OPENMP_TARGET)\n#pragma omp target teams distribute parallel for\n#else\n#pragma omp parallel for default(none) shared(ulisttot, wself, idxu_block, num_atoms, twojmax)\n#endif\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int j = 0; j <= twojmax; j++) {\n        int jju = idxu_block[j];\n        for (int ma = 0; ma <= j; ma++) {\n          ulisttot[INDEX_2D(natom, jju)] = { wself, 0.0 };\n          jju += j + 2;\n        }\n      }\n    }\n\n#if (OPENMP_TARGET)\n#pragma omp target teams distribute parallel for collapse(2)\n#else\n#pragma omp parallel for collapse(2) default(none) \\\n    shared(rcutij, rij, wj, rootpqarray, ulist_parity, idxu_block, ulist, ulisttot, \\\n           num_atoms, num_nbor, twojmax, jdimpq, idxu_max, switch_flag)\n#endif\n    for (int nbor = 0; nbor < num_nbor; nbor++) {\n      for (int natom = 0; natom < num_atoms; natom++) {\n        double x = rij[ULIST_INDEX(natom, nbor, 0)];\n        double y = rij[ULIST_INDEX(natom, nbor, 1)];\n        double z = rij[ULIST_INDEX(natom, nbor, 2)];\n        double rsq = x * x + y * y + z * z;\n        double r = sqrt(rsq);\n\n        double theta0 = (r - rmin0) * rfac0 * MY_PI / (rcutij[INDEX_2D(natom, nbor)] - rmin0);\n        double z0 = r / tan(theta0);\n\n        double rootpq;\n        int jju, jjup;\n\n        \n\n\n        double r0inv = 1.0 / sqrt(r * r + z0 * z0);\n        double a_r = r0inv * z0;\n        double a_i = -r0inv * z;\n        double b_r = r0inv * y;\n        double b_i = -r0inv * x;\n\n        double sfac;\n\n        sfac = compute_sfac(r, rcutij[INDEX_2D(natom, nbor)], switch_flag);\n        sfac *= wj[INDEX_2D(natom, nbor)];\n\n        \n\n        \n\n\n        \n\n        \n\n\n        \n\n        \n\n\n        \n\n        \n\n        ulist[ULIST_INDEX(natom, nbor, 0)].re = 1.0;\n        ulist[ULIST_INDEX(natom, nbor, 0)].im = 0.0;\n\n        \n\n        jju = 1;\n        for (int j = 1; j <= twojmax; j++) {\n          int deljju = j + 1;\n          for (int mb = 0; 2 * mb <= j; mb++) {\n            ulist[ULIST_INDEX(natom, nbor, jju)].re = 0.0;\n            ulist[ULIST_INDEX(natom, nbor, jju)].im = 0.0;\n            jju += deljju;\n          }\n          int ncolhalf = deljju / 2;\n          jju += deljju * ncolhalf;\n        }\n\n        jju = 1;\n        jjup = 0;\n        for (int j = 1; j <= twojmax; j++) {\n          int deljju = j + 1;\n          int deljjup = j;\n          int mb_max = (j + 1) / 2;\n          int ma_max = j;\n          int m_max = ma_max * mb_max;\n\n          \n\n          for (int m_iter = 0; m_iter < m_max; ++m_iter) {\n            int mb = m_iter / ma_max;\n            int ma = m_iter % ma_max;\n            double up_r = ulist[ULIST_INDEX(natom, nbor, jjup)].re;\n            double up_i = ulist[ULIST_INDEX(natom, nbor, jjup)].im;\n\n            rootpq = rootpqarray[ROOTPQ_INDEX(j - ma, j - mb)];\n            ulist[ULIST_INDEX(natom, nbor, jju)].re += rootpq * (a_r * up_r + a_i * up_i);\n            ulist[ULIST_INDEX(natom, nbor, jju)].im += rootpq * (a_r * up_i - a_i * up_r);\n\n            rootpq = rootpqarray[ROOTPQ_INDEX(ma + 1, j - mb)];\n            ulist[ULIST_INDEX(natom, nbor, jju+1)].re = -rootpq * (b_r * up_r + b_i * up_i);\n            ulist[ULIST_INDEX(natom, nbor, jju+1)].im = -rootpq * (b_r * up_i - b_i * up_r);\n\n            \n\n\n            if (2 * (mb + 1) == j) {\n              rootpq = rootpqarray[ROOTPQ_INDEX(j - ma, mb + 1)];\n              ulist[ULIST_INDEX(natom, nbor, jju+deljju)].re += rootpq * (b_r * up_r - b_i * up_i);\n              ulist[ULIST_INDEX(natom, nbor, jju+deljju)].im += rootpq * (b_r * up_i + b_i * up_r);\n\n              rootpq = rootpqarray[ROOTPQ_INDEX(ma + 1, mb + 1)];\n              ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].re = rootpq * (a_r * up_r - a_i * up_i);\n              ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].im = rootpq * (a_r * up_i + a_i * up_r);\n            }\n\n            jju++;\n            jjup++;\n\n            if (ma == ma_max - 1)\n              jju++;\n          }\n\n          \n\n          \n\n          \n\n          \n\n          int jjui = idxu_block[j];\n          int jjuip = jjui + (j + 1) * (j + 1) - 1;\n          for (int mb = 0; 2 * mb < j; mb++) {\n            for (int ma = 0; ma <= j; ma++) {\n              ulist[ULIST_INDEX(natom, nbor, jjuip)].re = ulist_parity[jjui] * ulist[ULIST_INDEX(natom, nbor, jjui)].re;\n              ulist[ULIST_INDEX(natom, nbor, jjuip)].im = ulist_parity[jjui] * -ulist[ULIST_INDEX(natom, nbor, jjui)].im;\n              jjui++;\n              jjuip--;\n            }\n          }\n\n          \n\n          \n\n          if (j % 2 == 0)\n            jju += deljju;\n          int ncolhalf = deljju / 2;\n          jju += deljju * ncolhalf;\n          int ncolhalfp = deljjup / 2;\n          jjup += deljjup * ncolhalfp;\n        }\n\n\n        sfac = compute_sfac(r, rcutij[INDEX_2D(natom, nbor)], switch_flag);\n        sfac *= wj[INDEX_2D(natom, nbor)];\n\n        for (int j = 0; j <= twojmax; j++) {\n          int jju = idxu_block[j];\n          for (int mb = 0; mb <= j; mb++)\n            for (int ma = 0; ma <= j; ma++) {\n#pragma omp atomic\n              ulisttot[INDEX_2D(natom, jju)].re += sfac * ulist[ULIST_INDEX(natom, nbor, jju)].re;\n#pragma omp atomic\n              ulisttot[INDEX_2D(natom, jju)].im += sfac * ulist[ULIST_INDEX(natom, nbor, jju)].im;\n\n              jju++;\n            }\n        }\n      }\n    }\n\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_ui += elapsed.count();\n\n    start = system_clock::now();\n\n    \n\n\n    \n\n#if defined(OPENMP_TARGET)\n#pragma omp target teams distribute parallel for\n#else\n#pragma omp parallel for default(none) shared(num_atoms, idxdu_max, ylist)\n#endif\n    for (int i = 0; i < num_atoms * idxdu_max; i++)\n      ylist[i] = { 0.0, 0.0 };\n\n#if defined(OPENMP_TARGET)\n#pragma omp target teams distribute parallel for collapse(2)\n#else\n#pragma omp parallel for collapse(2) default(none) shared(idxz,                \\\n    idxzbeta,            \\\n    idxcg_block,         \\\n    idxdu_block,         \\\n    idxu_block,          \\\n    cglist,              \\\n    ulisttot,            \\\n    ylist, \\\n    jdim, num_atoms, idxz_max)\n#endif\n    for (int jjz = 0; jjz < idxz_max; jjz++)\n      for (int natom = 0; natom < num_atoms; natom++)\n          {\n            const int j1 = idxz[IDXZ_INDEX(jjz, 0)];\n            const int j2 = idxz[IDXZ_INDEX(jjz, 1)];\n            const int j = idxz[IDXZ_INDEX(jjz, 2)];\n            const int ma1min = idxz[IDXZ_INDEX(jjz, 3)];\n            const int ma2max = idxz[IDXZ_INDEX(jjz, 4)];\n            const int na = idxz[IDXZ_INDEX(jjz, 5)];\n            const int mb1min = idxz[IDXZ_INDEX(jjz, 6)];\n            const int mb2max = idxz[IDXZ_INDEX(jjz, 7)];\n            const int nb = idxz[IDXZ_INDEX(jjz, 8)];\n\n            const double betaj = idxzbeta[jjz];\n\n            \n\n            const double* cgblock = cglist + idxcg_block[j1 + jdim*j2 + jdim*jdim*j];\n\n            int mb = (2 * (mb1min + mb2max) - j1 - j2 + j) / 2;\n            int ma = (2 * (ma1min + ma2max) - j1 - j2 + j) / 2;\n            const int jjdu = idxdu_block[j] + (j + 1) * mb + ma;\n\n            int jju1 = idxu_block[j1] + (j1 + 1) * mb1min;\n            int jju2 = idxu_block[j2] + (j2 + 1) * mb2max;\n            int icgb = mb1min * (j2 + 1) + mb2max;\n\n            double ztmp_r = 0.0;\n            double ztmp_i = 0.0;\n\n            \n\n            \n\n            \n\n\n            for (int ib = 0; ib < nb; ib++) {\n\n              double suma1_r = 0.0;\n              double suma1_i = 0.0;\n\n              int ma1 = ma1min;\n              int ma2 = ma2max;\n              int icga = ma1min * (j2 + 1) + ma2max;\n\n              \n\n              \n\n              \n\n\n              for (int ia = 0; ia < na; ia++) {\n                suma1_r +=\n                  cgblock[icga] *\n                  (ulisttot[INDEX_2D(natom, jju1 + ma1)].re * ulisttot[INDEX_2D(natom, jju2 + ma2)].re -\n                   ulisttot[INDEX_2D(natom, jju1 + ma1)].im * ulisttot[INDEX_2D(natom, jju2 + ma2)].im);\n\n                suma1_i +=\n                  cgblock[icga] *\n                  (ulisttot[INDEX_2D(natom, jju1 + ma1)].re * ulisttot[INDEX_2D(natom, jju2 + ma2)].im +\n                   ulisttot[INDEX_2D(natom, jju1 + ma1)].im * ulisttot[INDEX_2D(natom, jju2 + ma2)].re);\n\n                ma1++;\n                ma2--;\n                icga += j2;\n              } \n\n\n              ztmp_r += cgblock[icgb] * suma1_r;\n              ztmp_i += cgblock[icgb] * suma1_i;\n              jju1 += j1 + 1;\n              jju2 -= j2 + 1;\n              icgb += j2;\n            } \n\n\n            \n\n\n#pragma omp atomic\n            ylist[INDEX_2D(natom, jjdu)].re += betaj * ztmp_r;\n#pragma omp atomic\n            ylist[INDEX_2D(natom, jjdu)].im += betaj * ztmp_i;\n\n          } \n\n\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_yi += elapsed.count();\n\n    \n\n    start = system_clock::now();\n#if defined(OPENMP_TARGET)\n#pragma omp target teams distribute parallel for collapse(2)\n#else\n#pragma omp parallel default(none) shared(rij, wj, rcutij, rootpqarray, dulist, ulist, \\\n                                          num_atoms, num_nbor, twojmax, idxdu_max, jdimpq, switch_flag)\n#pragma omp for collapse(2)\n#endif\n    for (int nbor = 0; nbor < num_nbor; nbor++) {\n      for (int natom = 0; natom < num_atoms; natom++) {\n        double wj_in = wj[INDEX_2D(natom, nbor)];\n        double rcut = rcutij[INDEX_2D(natom, nbor)];\n\n        double x = rij[ULIST_INDEX(natom, nbor, 0)];\n        double y = rij[ULIST_INDEX(natom, nbor, 1)];\n        double z = rij[ULIST_INDEX(natom, nbor, 2)];\n        double rsq = x * x + y * y + z * z;\n        double r = sqrt(rsq);\n        double rscale0 = rfac0 * MY_PI / (rcut - rmin0);\n        double theta0 = (r - rmin0) * rscale0;\n        double cs = cos(theta0);\n        double sn = sin(theta0);\n        double z0 = r * cs / sn;\n        double dz0dr = z0 / r - (r * rscale0) * (rsq + z0 * z0) / rsq;\n\n        compute_duarray(natom, nbor, num_atoms, num_nbor, twojmax, \n                        idxdu_max, jdimpq, switch_flag,\n                        x, y, z, z0, r, dz0dr, wj_in, rcut,\n                        rootpqarray, ulist, dulist);\n      }\n    }\n\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_duidrj += elapsed.count();\n\n    start = system_clock::now();\n    \n\n#if (OPENMP_TARGET)\n#pragma omp target teams distribute parallel for collapse(2)\n#else\n#pragma omp parallel for collapse(2)\n#endif\n    for (int nbor = 0; nbor < num_nbor; nbor++) {\n      for (int natom = 0; natom < num_atoms; natom++) {\n        for (int k = 0; k < 3; k++)\n          dedr[ULIST_INDEX(natom, nbor, k)] = 0.0;\n\n        for (int j = 0; j <= twojmax; j++) {\n          int jjdu = idxdu_block[j];\n\n          for (int mb = 0; 2 * mb < j; mb++)\n            for (int ma = 0; ma <= j; ma++) {\n\n              double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n              double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n              for (int k = 0; k < 3; k++)\n                dedr[ULIST_INDEX(natom, nbor, k)] +=\n                  dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                  dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n              jjdu++;\n            } \n\n\n          \n\n\n          if (j % 2 == 0) {\n\n            int mb = j / 2;\n            for (int ma = 0; ma < mb; ma++) {\n              double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n              double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n              for (int k = 0; k < 3; k++)\n                dedr[ULIST_INDEX(natom, nbor, k)] +=\n                  dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                  dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n              jjdu++;\n            }\n\n            double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n            double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n            for (int k = 0; k < 3; k++)\n              dedr[ULIST_INDEX(natom, nbor, k)] +=\n                (dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                 dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i) *\n                0.5;\n            jjdu++;\n\n          } \n\n\n        } \n\n\n        for (int k = 0; k < 3; k++)\n          dedr[ULIST_INDEX(natom, nbor, k)] *= 2.0;\n\n      } \n\n    }   \n\n\n#if defined(OPENMP_TARGET)\n#pragma omp target update from(dedr[0:num_atoms * num_nbor * 3])\n#endif\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_deidrj += elapsed.count();\n\n    \n\n    \n\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        int j = inside[INDEX_2D(natom, nbor)];\n        f[F_INDEX(natom, 0)] += dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(natom, 1)] += dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(natom, 2)] += dedr[ULIST_INDEX(natom, nbor, 2)];\n        f[F_INDEX(j, 0)] -= dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(j, 1)] -= dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(j, 2)] -= dedr[ULIST_INDEX(natom, nbor, 2)];\n\n      } \n\n    }   \n\n    \n\n    jt = 0;\n    for (int j = 0; j < ntotal; j++) {\n      double ferrx = f[F_INDEX(j, 0)] - refdata.fj[jt++];\n      double ferry = f[F_INDEX(j, 1)] - refdata.fj[jt++];\n      double ferrz = f[F_INDEX(j, 2)] - refdata.fj[jt++];\n      sumsqferr += ferrx * ferrx + ferry * ferry + ferrz * ferrz;\n    }\n\n  }\n  auto stop = myclock::now();\n  myduration elapsed = stop - begin;\n  double duration = elapsed.count(); \n\n  printf(\"-----------------------\\n\");\n  printf(\"Summary of TestSNAP run\\n\");\n  printf(\"-----------------------\\n\");\n  printf(\"natoms = %d \\n\", nlocal);\n  printf(\"nghostatoms = %d \\n\", nghost);\n  printf(\"nsteps = %d \\n\", nsteps);\n  printf(\"nneighs = %d \\n\", ninside);\n  printf(\"twojmax = %d \\n\", twojmax);\n  printf(\"duration = %g [sec]\\n\", duration);\n\n  \n\n  double ktime = elapsed_ui + elapsed_yi + elapsed_duidrj + elapsed_deidrj;\n  printf(\"step time = %g [msec/step]\\n\", 1000.0 * duration / nsteps);\n  printf(\"\\n Individual kernel timings for each step\\n\");\n  printf(\"   compute_ui = %g [msec/step]\\n\", 1000.0 * elapsed_ui / nsteps);\n  printf(\"   compute_yi = %g [msec/step]\\n\", 1000.0 * elapsed_yi / nsteps);\n  printf(\"   compute_duidrj = %g [msec/step]\\n\", 1000.0 * elapsed_duidrj / nsteps);\n  printf(\"   compute_deidrj = %g [msec/step]\\n\", 1000.0 * elapsed_deidrj / nsteps);\n  printf(\"   Total kernel time = %g [msec/step]\\n\", 1000.0 * ktime / nsteps);\n  printf(\"   Percentage of step time = %g%%\\n\\n\", ktime / duration * 100.0);\n  printf(\"grind time = %g [msec/atom-step]\\n\", 1000.0 * duration / (nlocal * nsteps));\n  printf(\"RMS |Fj| deviation %g [eV/A]\\n\", sqrt(sumsqferr / (ntotal * nsteps)));\n\n#if defined(OPENMP_TARGET)\n}\n#endif\n\n\n  free(coeffi);\n  free(idxcg_block);\n  free(idxu_block);\n  free(ulist_parity);\n  free(idxdu_block);\n  free(idxb);\n  free(idxb_block);\n  free(idxz);\n  free(idxzbeta);\n  free(idxz_block);\n  free(rij);\n  free(inside);\n  free(wj);\n  free(rcutij);\n  free(rootpqarray);\n  free(cglist);\n  free(dedr);\n  free(ulist);\n  free(ylist);\n  free(ulisttot);\n  free(dulist);\n  free(f);\n\n  return 0;\n}\n"}}
{"kernel_name": "testSNAP", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include \"snap.h\"\n#include \"utils.cpp\"\n\n#if REFDATA_TWOJ == 14\n#include \"refdata_2J14_W.h\"\n#elif REFDATA_TWOJ == 8\n#include \"refdata_2J8_W.h\"\n#elif REFDATA_TWOJ == 4\n#include \"refdata_2J4_W.h\"\n#else\n#include \"refdata_2J2_W.h\"\n#endif\n\n\nint nsteps = 1; \n\n\nint main(int argc, char* argv[])\n{\n  options(argc, argv);\n\n  const int switch_flag = 1;     \n\n\n  \n\n  double elapsed_ui = 0.0, \n         elapsed_yi = 0.0, \n         elapsed_duidrj = 0.0,\n         elapsed_deidrj = 0.0;\n\n  const int ninside = refdata.ninside;\n  const int ncoeff = refdata.ncoeff;\n  const int nlocal = refdata.nlocal;\n  const int nghost = refdata.nghost;\n  const int ntotal = nlocal + nghost;\n  const int twojmax = refdata.twojmax;\n  const double rcutfac = refdata.rcutfac;\n\n  const double wself = 1.0;\n  const int num_atoms = nlocal; \n  const int num_nbor = ninside; \n\n  \n\n  double* coeffi = (double*) malloc (sizeof(double) * (ncoeff+1));\n\n  for (int icoeff = 0; icoeff < ncoeff + 1; icoeff++)\n    coeffi[icoeff] = refdata.coeff[icoeff];\n\n  double* beta = coeffi + 1;\n\n  \n\n  const int jdim = twojmax + 1;\n\n  \n\n\n  int *idxcg_block = (int*) malloc(sizeof(int) * jdim * jdim * jdim);\n\n  int idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxcg_block[j1 + j2 *jdim + jdim*jdim*j] = idxcg_count;\n        for (int m1 = 0; m1 <= j1; m1++)\n          for (int m2 = 0; m2 <= j2; m2++)\n            idxcg_count++;\n      }\n  const int idxcg_max = idxcg_count;\n\n  \n\n  \n\n  \n\n\n  int* idxu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxu_block[j] = idxu_count;\n    for (int mb = 0; mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxu_count++;\n  }\n  const int idxu_max = idxu_count;\n\n  \n\n  \n\n  \n\n\n  \n\n  int* ulist_parity = (int*) malloc (sizeof(int) * idxu_max);\n  idxu_count = 0;\n  for (int j = 0; j <= twojmax; j++) {\n    int mbpar = 1;\n    for (int mb = 0; mb <= j; mb++) {\n      int mapar = mbpar;\n      for (int ma = 0; ma <= j; ma++) {\n        ulist_parity[idxu_count] = mapar;\n        mapar = -mapar;\n        idxu_count++;\n      }\n      mbpar = -mbpar;\n    }\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  int* idxdu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxdu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxdu_block[j] = idxdu_count;\n    for (int mb = 0; 2 * mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxdu_count++;\n  }\n  const int idxdu_max = idxdu_count;\n\n  \n\n\n  int idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1)\n          idxb_count++;\n\n  const int idxb_max = idxb_count;\n  SNA_BINDICES* idxb = (SNA_BINDICES*) malloc (sizeof(SNA_BINDICES) * idxb_max);\n\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1) {\n          idxb[idxb_count].j1 = j1;\n          idxb[idxb_count].j2 = j2;\n          idxb[idxb_count].j = j;\n          idxb_count++;\n        }\n\n  \n\n\n  int* idxb_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        if (j < j1)\n          continue;\n        idxb_block[j1*jdim*jdim+j2*jdim+j] = idxb_count;\n        idxb_count++;\n      }\n\n\n  \n\n\n  int idxz_count = 0;\n\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++)\n            idxz_count++;\n\n  const int idxz_max = idxz_count;\n  \n\n  int* idxz = (int*) malloc (sizeof(int) * idxz_max * 9);\n\n  \n\n  double* idxzbeta = (double*) malloc (sizeof(double) * idxz_max);\n\n  \n\n  int* idxz_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n\n  idxz_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxz_block[j1*jdim*jdim+j2*jdim+j] = idxz_count;\n\n        \n\n        \n\n        \n\n        \n\n\n        double betaj;\n        if (j >= j1) {\n          const int jjb = idxb_block[j1*jdim*jdim+j2*jdim+j];\n          if (j1 == j) {\n            if (j2 == j) {\n              betaj = 3 * beta[jjb];\n            }\n            else {\n              betaj = 2 * beta[jjb];\n            }\n          } else {\n            betaj = beta[jjb];\n          }\n        } else if (j >= j2) {\n          const int jjb = idxb_block[j*jdim*jdim+j2*jdim+j1];\n          if (j2 == j) {\n            betaj = 2 * beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n          else {\n            betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n        } else {\n          const int jjb = idxb_block[j2*jdim*jdim+j*jdim+j1];\n          betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n        }\n\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++) {\n\n            idxz[IDXZ_INDEX(idxz_count, 0)] = j1;\n            idxz[IDXZ_INDEX(idxz_count, 1)] = j2;\n            idxz[IDXZ_INDEX(idxz_count, 2)] = j;\n\n            int ma1min = MAX(0, (2 * ma - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 3)] = ma1min;\n            idxz[IDXZ_INDEX(idxz_count, 4)] = (2 * ma - j - (2 * ma1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 5)] =\n              MIN(j1, (2 * ma - j + j2 + j1) / 2) - ma1min + 1;\n\n            int mb1min = MAX(0, (2 * mb - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 6)] = mb1min;\n            idxz[IDXZ_INDEX(idxz_count, 7)] = (2 * mb - j - (2 * mb1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 8)] =\n              MIN(j1, (2 * mb - j + j2 + j1) / 2) - mb1min + 1;\n\n            idxzbeta[idxz_count] = betaj;\n\n            idxz_count++;\n          }\n      }\n  \n\n\n\n  if (compute_ncoeff(twojmax) != ncoeff) {\n    printf(\"ERROR: ncoeff from SNA does not match reference data\\n\");\n    exit(1);\n  }\n\n  \n\n\n  double *rij    = (double*) malloc(sizeof(double) * (num_atoms * num_nbor * 3));\n  double *inside = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *wj     = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *rcutij = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n\n  const int jdimpq = twojmax + 2;\n  double* rootpqarray = (double*) malloc(sizeof(double) * jdimpq * jdimpq);\n  double* cglist = (double*) malloc (sizeof(double) * idxcg_max);\n  double* dedr = (double*) malloc (sizeof(double) * num_atoms * num_nbor * 3); \n\n  COMPLEX* ulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * idxu_max); \n  COMPLEX* ylist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxdu_max);\n  COMPLEX* ulisttot = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxu_max);\n  COMPLEX* dulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * 3 * idxdu_max);\n\n  \n\n  for (int p = 1; p <= twojmax; p++)\n    for (int q = 1; q <= twojmax; q++)\n      rootpqarray[ROOTPQ_INDEX(p, q)] = sqrt(static_cast<double>(p) / q);\n\n  \n\n  double sum, dcg, sfaccg;\n  int m, aa2, bb2, cc2;\n  int ifac;\n\n  idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        for (int m1 = 0; m1 <= j1; m1++) {\n          aa2 = 2 * m1 - j1;\n\n          for (int m2 = 0; m2 <= j2; m2++) {\n\n            \n\n\n            bb2 = 2 * m2 - j2;\n            m = (aa2 + bb2 + j) / 2;\n\n            if (m < 0 || m > j) {\n              cglist[idxcg_count] = 0.0;\n              idxcg_count++;\n              continue;\n            }\n\n            sum = 0.0;\n\n            for (int z = MAX(0, MAX(-(j - j2 + aa2) / 2, -(j - j1 - bb2) / 2));\n                z <=\n                MIN((j1 + j2 - j) / 2, MIN((j1 - aa2) / 2, (j2 + bb2) / 2));\n                z++) {\n              ifac = z % 2 ? -1 : 1;\n              sum += ifac / (factorial(z) * factorial((j1 + j2 - j) / 2 - z) *\n                  factorial((j1 - aa2) / 2 - z) *\n                  factorial((j2 + bb2) / 2 - z) *\n                  factorial((j - j2 + aa2) / 2 + z) *\n                  factorial((j - j1 - bb2) / 2 + z));\n            }\n\n            cc2 = 2 * m - j;\n            dcg = deltacg(j1, j2, j);\n            sfaccg = sqrt(\n                factorial((j1 + aa2) / 2) * factorial((j1 - aa2) / 2) *\n                factorial((j2 + bb2) / 2) * factorial((j2 - bb2) / 2) *\n                factorial((j + cc2) / 2) * factorial((j - cc2) / 2) * (j + 1));\n\n            cglist[idxcg_count] = sum * dcg * sfaccg;\n            idxcg_count++;\n          }\n        }\n      }\n\n  double* f = (double*) malloc (sizeof(double) * ntotal * 3);\n\n  \n\n  double sumsqferr = 0.0;\n\n#if defined(OPENMP_TARGET)\n{\n\n  \n\n\n  auto begin = myclock::now();\n  for (int istep = 0; istep < nsteps; istep++) {\n\n    time_point<system_clock> start, end;\n    duration<double> elapsed;\n\n    for (int j = 0; j < ntotal * 3; j++) {\n      f[j] = 0.0;\n    }\n\n    int jt = 0, jjt = 0;\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        rij[ULIST_INDEX(natom, nbor, 0)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 1)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 2)] = refdata.rij[jt++];\n        inside[INDEX_2D(natom, nbor)] = refdata.jlist[jjt++];\n        wj[INDEX_2D(natom, nbor)] = 1.0;\n        rcutij[INDEX_2D(natom, nbor)] = rcutfac;\n      }\n    }\n\n#if defined(OPENMP_TARGET)\n#endif\n\n    \n\n    start = system_clock::now();\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n#if defined(OPENMP_TARGET)\n#else\n#endif\n    for (int i = 0; i < num_atoms * idxu_max; ++i)\n      ulisttot[i] = { 0.0, 0.0 };\n\n#if (OPENMP_TARGET)\n#else\n#endif\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int j = 0; j <= twojmax; j++) {\n        int jju = idxu_block[j];\n        for (int ma = 0; ma <= j; ma++) {\n          ulisttot[INDEX_2D(natom, jju)] = { wself, 0.0 };\n          jju += j + 2;\n        }\n      }\n    }\n\n#if (OPENMP_TARGET)\n#else\n#endif\n    for (int nbor = 0; nbor < num_nbor; nbor++) {\n      for (int natom = 0; natom < num_atoms; natom++) {\n        double x = rij[ULIST_INDEX(natom, nbor, 0)];\n        double y = rij[ULIST_INDEX(natom, nbor, 1)];\n        double z = rij[ULIST_INDEX(natom, nbor, 2)];\n        double rsq = x * x + y * y + z * z;\n        double r = sqrt(rsq);\n\n        double theta0 = (r - rmin0) * rfac0 * MY_PI / (rcutij[INDEX_2D(natom, nbor)] - rmin0);\n        double z0 = r / tan(theta0);\n\n        double rootpq;\n        int jju, jjup;\n\n        \n\n\n        double r0inv = 1.0 / sqrt(r * r + z0 * z0);\n        double a_r = r0inv * z0;\n        double a_i = -r0inv * z;\n        double b_r = r0inv * y;\n        double b_i = -r0inv * x;\n\n        double sfac;\n\n        sfac = compute_sfac(r, rcutij[INDEX_2D(natom, nbor)], switch_flag);\n        sfac *= wj[INDEX_2D(natom, nbor)];\n\n        \n\n        \n\n\n        \n\n        \n\n\n        \n\n        \n\n\n        \n\n        \n\n        ulist[ULIST_INDEX(natom, nbor, 0)].re = 1.0;\n        ulist[ULIST_INDEX(natom, nbor, 0)].im = 0.0;\n\n        \n\n        jju = 1;\n        for (int j = 1; j <= twojmax; j++) {\n          int deljju = j + 1;\n          for (int mb = 0; 2 * mb <= j; mb++) {\n            ulist[ULIST_INDEX(natom, nbor, jju)].re = 0.0;\n            ulist[ULIST_INDEX(natom, nbor, jju)].im = 0.0;\n            jju += deljju;\n          }\n          int ncolhalf = deljju / 2;\n          jju += deljju * ncolhalf;\n        }\n\n        jju = 1;\n        jjup = 0;\n        for (int j = 1; j <= twojmax; j++) {\n          int deljju = j + 1;\n          int deljjup = j;\n          int mb_max = (j + 1) / 2;\n          int ma_max = j;\n          int m_max = ma_max * mb_max;\n\n          \n\n          for (int m_iter = 0; m_iter < m_max; ++m_iter) {\n            int mb = m_iter / ma_max;\n            int ma = m_iter % ma_max;\n            double up_r = ulist[ULIST_INDEX(natom, nbor, jjup)].re;\n            double up_i = ulist[ULIST_INDEX(natom, nbor, jjup)].im;\n\n            rootpq = rootpqarray[ROOTPQ_INDEX(j - ma, j - mb)];\n            ulist[ULIST_INDEX(natom, nbor, jju)].re += rootpq * (a_r * up_r + a_i * up_i);\n            ulist[ULIST_INDEX(natom, nbor, jju)].im += rootpq * (a_r * up_i - a_i * up_r);\n\n            rootpq = rootpqarray[ROOTPQ_INDEX(ma + 1, j - mb)];\n            ulist[ULIST_INDEX(natom, nbor, jju+1)].re = -rootpq * (b_r * up_r + b_i * up_i);\n            ulist[ULIST_INDEX(natom, nbor, jju+1)].im = -rootpq * (b_r * up_i - b_i * up_r);\n\n            \n\n\n            if (2 * (mb + 1) == j) {\n              rootpq = rootpqarray[ROOTPQ_INDEX(j - ma, mb + 1)];\n              ulist[ULIST_INDEX(natom, nbor, jju+deljju)].re += rootpq * (b_r * up_r - b_i * up_i);\n              ulist[ULIST_INDEX(natom, nbor, jju+deljju)].im += rootpq * (b_r * up_i + b_i * up_r);\n\n              rootpq = rootpqarray[ROOTPQ_INDEX(ma + 1, mb + 1)];\n              ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].re = rootpq * (a_r * up_r - a_i * up_i);\n              ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].im = rootpq * (a_r * up_i + a_i * up_r);\n            }\n\n            jju++;\n            jjup++;\n\n            if (ma == ma_max - 1)\n              jju++;\n          }\n\n          \n\n          \n\n          \n\n          \n\n          int jjui = idxu_block[j];\n          int jjuip = jjui + (j + 1) * (j + 1) - 1;\n          for (int mb = 0; 2 * mb < j; mb++) {\n            for (int ma = 0; ma <= j; ma++) {\n              ulist[ULIST_INDEX(natom, nbor, jjuip)].re = ulist_parity[jjui] * ulist[ULIST_INDEX(natom, nbor, jjui)].re;\n              ulist[ULIST_INDEX(natom, nbor, jjuip)].im = ulist_parity[jjui] * -ulist[ULIST_INDEX(natom, nbor, jjui)].im;\n              jjui++;\n              jjuip--;\n            }\n          }\n\n          \n\n          \n\n          if (j % 2 == 0)\n            jju += deljju;\n          int ncolhalf = deljju / 2;\n          jju += deljju * ncolhalf;\n          int ncolhalfp = deljjup / 2;\n          jjup += deljjup * ncolhalfp;\n        }\n\n\n        sfac = compute_sfac(r, rcutij[INDEX_2D(natom, nbor)], switch_flag);\n        sfac *= wj[INDEX_2D(natom, nbor)];\n\n        for (int j = 0; j <= twojmax; j++) {\n          int jju = idxu_block[j];\n          for (int mb = 0; mb <= j; mb++)\n            for (int ma = 0; ma <= j; ma++) {\n              ulisttot[INDEX_2D(natom, jju)].re += sfac * ulist[ULIST_INDEX(natom, nbor, jju)].re;\n              ulisttot[INDEX_2D(natom, jju)].im += sfac * ulist[ULIST_INDEX(natom, nbor, jju)].im;\n\n              jju++;\n            }\n        }\n      }\n    }\n\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_ui += elapsed.count();\n\n    start = system_clock::now();\n\n    \n\n\n    \n\n#if defined(OPENMP_TARGET)\n#else\n#endif\n    for (int i = 0; i < num_atoms * idxdu_max; i++)\n      ylist[i] = { 0.0, 0.0 };\n\n#if defined(OPENMP_TARGET)\n#else\n#endif\n    for (int jjz = 0; jjz < idxz_max; jjz++)\n      for (int natom = 0; natom < num_atoms; natom++)\n          {\n            const int j1 = idxz[IDXZ_INDEX(jjz, 0)];\n            const int j2 = idxz[IDXZ_INDEX(jjz, 1)];\n            const int j = idxz[IDXZ_INDEX(jjz, 2)];\n            const int ma1min = idxz[IDXZ_INDEX(jjz, 3)];\n            const int ma2max = idxz[IDXZ_INDEX(jjz, 4)];\n            const int na = idxz[IDXZ_INDEX(jjz, 5)];\n            const int mb1min = idxz[IDXZ_INDEX(jjz, 6)];\n            const int mb2max = idxz[IDXZ_INDEX(jjz, 7)];\n            const int nb = idxz[IDXZ_INDEX(jjz, 8)];\n\n            const double betaj = idxzbeta[jjz];\n\n            \n\n            const double* cgblock = cglist + idxcg_block[j1 + jdim*j2 + jdim*jdim*j];\n\n            int mb = (2 * (mb1min + mb2max) - j1 - j2 + j) / 2;\n            int ma = (2 * (ma1min + ma2max) - j1 - j2 + j) / 2;\n            const int jjdu = idxdu_block[j] + (j + 1) * mb + ma;\n\n            int jju1 = idxu_block[j1] + (j1 + 1) * mb1min;\n            int jju2 = idxu_block[j2] + (j2 + 1) * mb2max;\n            int icgb = mb1min * (j2 + 1) + mb2max;\n\n            double ztmp_r = 0.0;\n            double ztmp_i = 0.0;\n\n            \n\n            \n\n            \n\n\n            for (int ib = 0; ib < nb; ib++) {\n\n              double suma1_r = 0.0;\n              double suma1_i = 0.0;\n\n              int ma1 = ma1min;\n              int ma2 = ma2max;\n              int icga = ma1min * (j2 + 1) + ma2max;\n\n              \n\n              \n\n              \n\n\n              for (int ia = 0; ia < na; ia++) {\n                suma1_r +=\n                  cgblock[icga] *\n                  (ulisttot[INDEX_2D(natom, jju1 + ma1)].re * ulisttot[INDEX_2D(natom, jju2 + ma2)].re -\n                   ulisttot[INDEX_2D(natom, jju1 + ma1)].im * ulisttot[INDEX_2D(natom, jju2 + ma2)].im);\n\n                suma1_i +=\n                  cgblock[icga] *\n                  (ulisttot[INDEX_2D(natom, jju1 + ma1)].re * ulisttot[INDEX_2D(natom, jju2 + ma2)].im +\n                   ulisttot[INDEX_2D(natom, jju1 + ma1)].im * ulisttot[INDEX_2D(natom, jju2 + ma2)].re);\n\n                ma1++;\n                ma2--;\n                icga += j2;\n              } \n\n\n              ztmp_r += cgblock[icgb] * suma1_r;\n              ztmp_i += cgblock[icgb] * suma1_i;\n              jju1 += j1 + 1;\n              jju2 -= j2 + 1;\n              icgb += j2;\n            } \n\n\n            \n\n\n            ylist[INDEX_2D(natom, jjdu)].re += betaj * ztmp_r;\n            ylist[INDEX_2D(natom, jjdu)].im += betaj * ztmp_i;\n\n          } \n\n\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_yi += elapsed.count();\n\n    \n\n    start = system_clock::now();\n#if defined(OPENMP_TARGET)\n#else\n#endif\n    for (int nbor = 0; nbor < num_nbor; nbor++) {\n      for (int natom = 0; natom < num_atoms; natom++) {\n        double wj_in = wj[INDEX_2D(natom, nbor)];\n        double rcut = rcutij[INDEX_2D(natom, nbor)];\n\n        double x = rij[ULIST_INDEX(natom, nbor, 0)];\n        double y = rij[ULIST_INDEX(natom, nbor, 1)];\n        double z = rij[ULIST_INDEX(natom, nbor, 2)];\n        double rsq = x * x + y * y + z * z;\n        double r = sqrt(rsq);\n        double rscale0 = rfac0 * MY_PI / (rcut - rmin0);\n        double theta0 = (r - rmin0) * rscale0;\n        double cs = cos(theta0);\n        double sn = sin(theta0);\n        double z0 = r * cs / sn;\n        double dz0dr = z0 / r - (r * rscale0) * (rsq + z0 * z0) / rsq;\n\n        compute_duarray(natom, nbor, num_atoms, num_nbor, twojmax, \n                        idxdu_max, jdimpq, switch_flag,\n                        x, y, z, z0, r, dz0dr, wj_in, rcut,\n                        rootpqarray, ulist, dulist);\n      }\n    }\n\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_duidrj += elapsed.count();\n\n    start = system_clock::now();\n    \n\n#if (OPENMP_TARGET)\n#else\n#endif\n    for (int nbor = 0; nbor < num_nbor; nbor++) {\n      for (int natom = 0; natom < num_atoms; natom++) {\n        for (int k = 0; k < 3; k++)\n          dedr[ULIST_INDEX(natom, nbor, k)] = 0.0;\n\n        for (int j = 0; j <= twojmax; j++) {\n          int jjdu = idxdu_block[j];\n\n          for (int mb = 0; 2 * mb < j; mb++)\n            for (int ma = 0; ma <= j; ma++) {\n\n              double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n              double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n              for (int k = 0; k < 3; k++)\n                dedr[ULIST_INDEX(natom, nbor, k)] +=\n                  dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                  dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n              jjdu++;\n            } \n\n\n          \n\n\n          if (j % 2 == 0) {\n\n            int mb = j / 2;\n            for (int ma = 0; ma < mb; ma++) {\n              double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n              double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n              for (int k = 0; k < 3; k++)\n                dedr[ULIST_INDEX(natom, nbor, k)] +=\n                  dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                  dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n              jjdu++;\n            }\n\n            double jjjmambyarray_r = ylist[INDEX_2D(natom, jjdu)].re;\n            double jjjmambyarray_i = ylist[INDEX_2D(natom, jjdu)].im;\n\n            for (int k = 0; k < 3; k++)\n              dedr[ULIST_INDEX(natom, nbor, k)] +=\n                (dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                 dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i) *\n                0.5;\n            jjdu++;\n\n          } \n\n\n        } \n\n\n        for (int k = 0; k < 3; k++)\n          dedr[ULIST_INDEX(natom, nbor, k)] *= 2.0;\n\n      } \n\n    }   \n\n\n#if defined(OPENMP_TARGET)\n#endif\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_deidrj += elapsed.count();\n\n    \n\n    \n\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        int j = inside[INDEX_2D(natom, nbor)];\n        f[F_INDEX(natom, 0)] += dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(natom, 1)] += dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(natom, 2)] += dedr[ULIST_INDEX(natom, nbor, 2)];\n        f[F_INDEX(j, 0)] -= dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(j, 1)] -= dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(j, 2)] -= dedr[ULIST_INDEX(natom, nbor, 2)];\n\n      } \n\n    }   \n\n    \n\n    jt = 0;\n    for (int j = 0; j < ntotal; j++) {\n      double ferrx = f[F_INDEX(j, 0)] - refdata.fj[jt++];\n      double ferry = f[F_INDEX(j, 1)] - refdata.fj[jt++];\n      double ferrz = f[F_INDEX(j, 2)] - refdata.fj[jt++];\n      sumsqferr += ferrx * ferrx + ferry * ferry + ferrz * ferrz;\n    }\n\n  }\n  auto stop = myclock::now();\n  myduration elapsed = stop - begin;\n  double duration = elapsed.count(); \n\n  printf(\"-----------------------\\n\");\n  printf(\"Summary of TestSNAP run\\n\");\n  printf(\"-----------------------\\n\");\n  printf(\"natoms = %d \\n\", nlocal);\n  printf(\"nghostatoms = %d \\n\", nghost);\n  printf(\"nsteps = %d \\n\", nsteps);\n  printf(\"nneighs = %d \\n\", ninside);\n  printf(\"twojmax = %d \\n\", twojmax);\n  printf(\"duration = %g [sec]\\n\", duration);\n\n  \n\n  double ktime = elapsed_ui + elapsed_yi + elapsed_duidrj + elapsed_deidrj;\n  printf(\"step time = %g [msec/step]\\n\", 1000.0 * duration / nsteps);\n  printf(\"\\n Individual kernel timings for each step\\n\");\n  printf(\"   compute_ui = %g [msec/step]\\n\", 1000.0 * elapsed_ui / nsteps);\n  printf(\"   compute_yi = %g [msec/step]\\n\", 1000.0 * elapsed_yi / nsteps);\n  printf(\"   compute_duidrj = %g [msec/step]\\n\", 1000.0 * elapsed_duidrj / nsteps);\n  printf(\"   compute_deidrj = %g [msec/step]\\n\", 1000.0 * elapsed_deidrj / nsteps);\n  printf(\"   Total kernel time = %g [msec/step]\\n\", 1000.0 * ktime / nsteps);\n  printf(\"   Percentage of step time = %g%%\\n\\n\", ktime / duration * 100.0);\n  printf(\"grind time = %g [msec/atom-step]\\n\", 1000.0 * duration / (nlocal * nsteps));\n  printf(\"RMS |Fj| deviation %g [eV/A]\\n\", sqrt(sumsqferr / (ntotal * nsteps)));\n\n#if defined(OPENMP_TARGET)\n}\n#endif\n\n\n  free(coeffi);\n  free(idxcg_block);\n  free(idxu_block);\n  free(ulist_parity);\n  free(idxdu_block);\n  free(idxb);\n  free(idxb_block);\n  free(idxz);\n  free(idxzbeta);\n  free(idxz_block);\n  free(rij);\n  free(inside);\n  free(wj);\n  free(rcutij);\n  free(rootpqarray);\n  free(cglist);\n  free(dedr);\n  free(ulist);\n  free(ylist);\n  free(ulisttot);\n  free(dulist);\n  free(f);\n\n  return 0;\n}"}}
{"kernel_name": "testSNAP", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#include <chrono>\n#include <cmath>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include \"snap.h\"\n#include \"utils.cpp\"\n\n#if REFDATA_TWOJ == 14\n#include \"refdata_2J14_W.h\"\n#elif REFDATA_TWOJ == 8\n#include \"refdata_2J8_W.h\"\n#elif REFDATA_TWOJ == 4\n#include \"refdata_2J4_W.h\"\n#else\n#include \"refdata_2J2_W.h\"\n#endif\n\nint nsteps = 1; \n\n\ninline double atomicAdd( double &var, double operand )\n{\n  auto atm = sycl::atomic_ref<double,\n    sycl::memory_order::relaxed,\n    sycl::memory_scope::device,\n    sycl::access::address_space::global_space>(var);\n  return atm.fetch_add(operand);\n}\n\nint main(int argc, char* argv[])\n{\n  options(argc, argv);\n\n  const int switch_flag = 1;     \n\n\n  \n\n  double elapsed_ui = 0.0,\n         elapsed_yi = 0.0,\n         elapsed_duidrj = 0.0,\n         elapsed_deidrj = 0.0;\n\n  const int ninside = refdata.ninside;\n  const int ncoeff = refdata.ncoeff;\n  const int nlocal = refdata.nlocal;\n  const int nghost = refdata.nghost;\n  const int ntotal = nlocal + nghost;\n  const int twojmax = refdata.twojmax;\n  const double rcutfac = refdata.rcutfac;\n\n  const double wself = 1.0;\n  const int num_atoms = nlocal;\n  const int num_nbor = ninside;\n\n  \n\n  double* coeffi = (double*) malloc (sizeof(double) * (ncoeff+1));\n\n  for (int icoeff = 0; icoeff < ncoeff + 1; icoeff++)\n    coeffi[icoeff] = refdata.coeff[icoeff];\n\n  double* beta = coeffi + 1;\n\n  \n\n  const int jdim = twojmax + 1;\n\n  \n\n\n  int *idxcg_block = (int*) malloc(sizeof(int) * jdim * jdim * jdim);\n\n  int idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxcg_block[j1 + j2 *jdim + jdim*jdim*j] = idxcg_count;\n        for (int m1 = 0; m1 <= j1; m1++)\n          for (int m2 = 0; m2 <= j2; m2++)\n            idxcg_count++;\n      }\n  const int idxcg_max = idxcg_count;\n\n  \n\n  \n\n  \n\n\n  int* idxu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxu_block[j] = idxu_count;\n    for (int mb = 0; mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxu_count++;\n  }\n  const int idxu_max = idxu_count;\n\n  \n\n  \n\n  \n\n\n  \n\n  int* ulist_parity = (int*) malloc (sizeof(int) * idxu_max);\n  idxu_count = 0;\n  for (int j = 0; j <= twojmax; j++) {\n    int mbpar = 1;\n    for (int mb = 0; mb <= j; mb++) {\n      int mapar = mbpar;\n      for (int ma = 0; ma <= j; ma++) {\n        ulist_parity[idxu_count] = mapar;\n        mapar = -mapar;\n        idxu_count++;\n      }\n      mbpar = -mbpar;\n    }\n  }\n\n  \n\n  \n\n  \n\n  \n\n\n  int* idxdu_block = (int*) malloc (sizeof(int) * jdim);\n  int idxdu_count = 0;\n\n  for (int j = 0; j <= twojmax; j++) {\n    idxdu_block[j] = idxdu_count;\n    for (int mb = 0; 2 * mb <= j; mb++)\n      for (int ma = 0; ma <= j; ma++)\n        idxdu_count++;\n  }\n  const int idxdu_max = idxdu_count;\n\n  \n\n\n  int idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1)\n          idxb_count++;\n\n  const int idxb_max = idxb_count;\n  SNA_BINDICES* idxb = (SNA_BINDICES*) malloc (sizeof(SNA_BINDICES) * idxb_max);\n\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        if (j >= j1) {\n          idxb[idxb_count].j1 = j1;\n          idxb[idxb_count].j2 = j2;\n          idxb[idxb_count].j = j;\n          idxb_count++;\n        }\n\n  \n\n\n  int* idxb_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n  idxb_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        if (j < j1)\n          continue;\n        idxb_block[j1*jdim*jdim+j2*jdim+j] = idxb_count;\n        idxb_count++;\n      }\n\n\n  \n\n\n  int idxz_count = 0;\n\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2)\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++)\n            idxz_count++;\n\n  const int idxz_max = idxz_count;\n  \n\n  int* idxz = (int*) malloc (sizeof(int) * idxz_max * 9);\n\n  \n\n  double* idxzbeta = (double*) malloc (sizeof(double) * idxz_max);\n\n  \n\n  int* idxz_block = (int*) malloc (sizeof(int) * jdim * jdim * jdim);\n\n  idxz_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        idxz_block[j1*jdim*jdim+j2*jdim+j] = idxz_count;\n\n        \n\n        \n\n        \n\n        \n\n\n        double betaj;\n        if (j >= j1) {\n          const int jjb = idxb_block[j1*jdim*jdim+j2*jdim+j];\n          if (j1 == j) {\n            if (j2 == j) {\n              betaj = 3 * beta[jjb];\n            }\n            else {\n              betaj = 2 * beta[jjb];\n            }\n          } else {\n            betaj = beta[jjb];\n          }\n        } else if (j >= j2) {\n          const int jjb = idxb_block[j*jdim*jdim+j2*jdim+j1];\n          if (j2 == j) {\n            betaj = 2 * beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n          else {\n            betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n          }\n        } else {\n          const int jjb = idxb_block[j2*jdim*jdim+j*jdim+j1];\n          betaj = beta[jjb] * (j1 + 1) / (j + 1.0);\n        }\n\n        for (int mb = 0; 2 * mb <= j; mb++)\n          for (int ma = 0; ma <= j; ma++) {\n\n            idxz[IDXZ_INDEX(idxz_count, 0)] = j1;\n            idxz[IDXZ_INDEX(idxz_count, 1)] = j2;\n            idxz[IDXZ_INDEX(idxz_count, 2)] = j;\n\n            int ma1min = MAX(0, (2 * ma - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 3)] = ma1min;\n            idxz[IDXZ_INDEX(idxz_count, 4)] = (2 * ma - j - (2 * ma1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 5)] =\n              MIN(j1, (2 * ma - j + j2 + j1) / 2) - ma1min + 1;\n\n            int mb1min = MAX(0, (2 * mb - j - j2 + j1) / 2);\n            idxz[IDXZ_INDEX(idxz_count, 6)] = mb1min;\n            idxz[IDXZ_INDEX(idxz_count, 7)] = (2 * mb - j - (2 * mb1min - j1) + j2) / 2;\n            idxz[IDXZ_INDEX(idxz_count, 8)] =\n              MIN(j1, (2 * mb - j + j2 + j1) / 2) - mb1min + 1;\n\n            idxzbeta[idxz_count] = betaj;\n\n            idxz_count++;\n          }\n      }\n  \n\n\n\n  if (compute_ncoeff(twojmax) != ncoeff) {\n    printf(\"ERROR: ncoeff from SNA does not match reference data\\n\");\n    exit(1);\n  }\n\n  \n\n\n  double *rij    = (double*) malloc(sizeof(double) * (num_atoms * num_nbor * 3));\n  double *inside = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *wj     = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n  double *rcutij = (double*) malloc(sizeof(double) * (num_atoms * num_nbor));\n\n  const int jdimpq = twojmax + 2;\n  double* rootpqarray = (double*) malloc(sizeof(double) * jdimpq * jdimpq);\n  double* cglist = (double*) malloc (sizeof(double) * idxcg_max);\n  double* dedr = (double*) malloc (sizeof(double) * num_atoms * num_nbor * 3);\n\n  COMPLEX* ulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * idxu_max);\n  COMPLEX* ylist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxdu_max);\n  COMPLEX* ulisttot = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * idxu_max);\n  COMPLEX* dulist = (COMPLEX*) malloc (sizeof(COMPLEX) * num_atoms * num_nbor * 3 * idxdu_max);\n\n  \n\n  for (int p = 1; p <= twojmax; p++)\n    for (int q = 1; q <= twojmax; q++)\n      rootpqarray[ROOTPQ_INDEX(p, q)] = sqrt(static_cast<double>(p) / q);\n\n  \n\n  double sum, dcg, sfaccg;\n  int m, aa2, bb2, cc2;\n  int ifac;\n\n  idxcg_count = 0;\n  for (int j1 = 0; j1 <= twojmax; j1++)\n    for (int j2 = 0; j2 <= j1; j2++)\n      for (int j = abs(j1 - j2); j <= MIN(twojmax, j1 + j2); j += 2) {\n        for (int m1 = 0; m1 <= j1; m1++) {\n          aa2 = 2 * m1 - j1;\n\n          for (int m2 = 0; m2 <= j2; m2++) {\n\n            \n\n\n            bb2 = 2 * m2 - j2;\n            m = (aa2 + bb2 + j) / 2;\n\n            if (m < 0 || m > j) {\n              cglist[idxcg_count] = 0.0;\n              idxcg_count++;\n              continue;\n            }\n\n            sum = 0.0;\n\n            for (int z = MAX(0, MAX(-(j - j2 + aa2) / 2, -(j - j1 - bb2) / 2));\n                z <=\n                MIN((j1 + j2 - j) / 2, MIN((j1 - aa2) / 2, (j2 + bb2) / 2));\n                z++) {\n              ifac = z % 2 ? -1 : 1;\n              sum += ifac / (factorial(z) * factorial((j1 + j2 - j) / 2 - z) *\n                  factorial((j1 - aa2) / 2 - z) *\n                  factorial((j2 + bb2) / 2 - z) *\n                  factorial((j - j2 + aa2) / 2 + z) *\n                  factorial((j - j1 - bb2) / 2 + z));\n            }\n\n            cc2 = 2 * m - j;\n            dcg = deltacg(j1, j2, j);\n            sfaccg = sqrt(\n                factorial((j1 + aa2) / 2) * factorial((j1 - aa2) / 2) *\n                factorial((j2 + bb2) / 2) * factorial((j2 - bb2) / 2) *\n                factorial((j + cc2) / 2) * factorial((j - cc2) / 2) * (j + 1));\n\n            cglist[idxcg_count] = sum * dcg * sfaccg;\n            idxcg_count++;\n          }\n        }\n      }\n\n  double* f = (double*) malloc (sizeof(double) * ntotal * 3);\n\n  \n\n  double sumsqferr = 0.0;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_idxu_block = sycl::malloc_device<int>(jdim, q);\n  q.memcpy(d_idxu_block, idxu_block, sizeof(int)*jdim);\n\n  int *d_ulist_parity = sycl::malloc_device<int>(idxu_max, q);\n  q.memcpy(d_ulist_parity, ulist_parity, sizeof(int)*idxu_max);\n\n  double *d_rootpqarray = sycl::malloc_device<double>(jdimpq * jdimpq, q);\n  q.memcpy(d_rootpqarray, rootpqarray, sizeof(double)*jdimpq*jdimpq);\n\n  int *d_idxz = sycl::malloc_device<int>(idxz_max * 9, q);\n  q.memcpy(d_idxz, idxz, sizeof(int)*idxz_max*9);\n\n  double *d_idxzbeta = sycl::malloc_device<double>(idxz_max, q);\n  q.memcpy(d_idxzbeta, idxzbeta, sizeof(double)*idxz_max);\n\n  int *d_idxcg_block = sycl::malloc_device<int>(jdim * jdim * jdim, q);\n  q.memcpy(d_idxcg_block, idxcg_block, sizeof(int)*jdim*jdim*jdim);\n\n  int *d_idxdu_block = sycl::malloc_device<int>(jdim, q);\n  q.memcpy(d_idxdu_block, idxdu_block, sizeof(int)*jdim);\n\n  double *d_cglist = sycl::malloc_device<double>(idxcg_max, q);\n  q.memcpy(d_cglist, cglist, sizeof(double)*idxcg_max);\n\n  COMPLEX *d_dulist = sycl::malloc_device<COMPLEX>(num_atoms * num_nbor * 3 * idxdu_max, q);\n  q.memcpy(d_dulist, dulist, sizeof(COMPLEX)*num_atoms*num_nbor*3*idxdu_max);\n\n  COMPLEX *d_ulist = sycl::malloc_device<COMPLEX>(num_atoms * num_nbor * idxu_max, q);\n  q.memcpy(d_ulist, ulist, sizeof(COMPLEX)*num_atoms*num_nbor*idxu_max);\n\n  double *d_dedr = sycl::malloc_device<double>(num_atoms * num_nbor * 3, q);\n  q.memcpy(d_dedr, dedr, sizeof(double)*num_atoms*num_nbor*3);\n\n  COMPLEX *d_ulisttot = sycl::malloc_device<COMPLEX>(num_atoms * idxu_max, q);\n  COMPLEX *d_ylist = sycl::malloc_device<COMPLEX>(num_atoms * idxdu_max, q);\n  double *d_rij = sycl::malloc_device<double>(num_atoms*num_nbor*3, q);\n  double *d_rcutij = sycl::malloc_device<double>(num_atoms*num_nbor, q);\n  double *d_wj = sycl::malloc_device<double>(num_atoms*num_nbor, q);\n\n  \n\n\n  auto begin = myclock::now();\n  for (int istep = 0; istep < nsteps; istep++) {\n\n    time_point<system_clock> start, end;\n    duration<double> elapsed;\n\n    for (int j = 0; j < ntotal * 3; j++) {\n      f[j] = 0.0;\n    }\n\n    int jt = 0, jjt = 0;\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        rij[ULIST_INDEX(natom, nbor, 0)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 1)] = refdata.rij[jt++];\n        rij[ULIST_INDEX(natom, nbor, 2)] = refdata.rij[jt++];\n        inside[INDEX_2D(natom, nbor)] = refdata.jlist[jjt++];\n        wj[INDEX_2D(natom, nbor)] = 1.0;\n        rcutij[INDEX_2D(natom, nbor)] = rcutfac;\n      }\n    }\n\n    q.memcpy(d_rij, rij, sizeof(double)*num_atoms*num_nbor*3);\n    q.memcpy(d_rcutij, rcutij, sizeof(double)*num_atoms*num_nbor);\n    q.memcpy(d_wj, wj, sizeof(double)*num_atoms*num_nbor);\n    q.wait();\n\n    \n\n    start = system_clock::now();\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    sycl::range<1> gws_k1 ((num_atoms*idxu_max+255)/256*256);\n    sycl::range<1> lws_k1 (256);\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class reset_ulisttot>(\n        sycl::nd_range<1>(gws_k1, lws_k1), [=] (sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i < num_atoms*idxu_max) d_ulisttot[i] = {0.0, 0.0};\n      });\n    });\n\n    sycl::range<1> gws_k2 ((num_atoms+255)/256*256);\n    sycl::range<1> lws_k2 (256);\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class set_ulisttot>(\n        sycl::nd_range<1>(gws_k2, lws_k2), [=] (sycl::nd_item<1> item) {\n        int natom = item.get_global_id(0);\n        if (natom < num_atoms)\n          for (int j = 0; j <= twojmax; j++) {\n            int jju = d_idxu_block[j];\n            for (int ma = 0; ma <= j; ma++) {\n              d_ulisttot[INDEX_2D(natom, jju)] = { wself, 0.0 };\n              jju += j + 2;\n            }\n          }\n      });\n    });\n\n    sycl::range<2> gws_k3 ((num_nbor+15)/16*16, (num_atoms+15)/16*16);\n    sycl::range<2> lws_k3 (16, 16);\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class update_ulisttot>(sycl::nd_range<2>(gws_k3, lws_k3), [=] (sycl::nd_item<2> item) {\n\tint nbor = item.get_global_id(0);\n\tint natom = item.get_global_id(1);\n        if (natom < num_atoms && nbor < num_nbor) {\n          double x = d_rij[ULIST_INDEX(natom, nbor, 0)];\n          double y = d_rij[ULIST_INDEX(natom, nbor, 1)];\n          double z = d_rij[ULIST_INDEX(natom, nbor, 2)];\n          double rsq = x * x + y * y + z * z;\n          double r = sycl::sqrt(rsq);\n\n          double theta0 = (r - rmin0) * rfac0 * MY_PI / (d_rcutij[INDEX_2D(natom, nbor)] - rmin0);\n          double z0 = r / sycl::tan(theta0);\n\n          double rootpq;\n          int jju, jjup;\n\n          \n\n\n          double r0inv = 1.0 / sycl::sqrt(r * r + z0 * z0);\n          double a_r = r0inv * z0;\n          double a_i = -r0inv * z;\n          double b_r = r0inv * y;\n          double b_i = -r0inv * x;\n\n          double sfac;\n\n          sfac = compute_sfac(r, d_rcutij[INDEX_2D(natom, nbor)], switch_flag);\n          sfac *= d_wj[INDEX_2D(natom, nbor)];\n\n          \n\n          \n\n\n          \n\n          \n\n\n          \n\n          \n\n\n          \n\n          \n\n          d_ulist[ULIST_INDEX(natom, nbor, 0)].re = 1.0;\n          d_ulist[ULIST_INDEX(natom, nbor, 0)].im = 0.0;\n\n          \n\n          jju = 1;\n          for (int j = 1; j <= twojmax; j++) {\n            int deljju = j + 1;\n            for (int mb = 0; 2 * mb <= j; mb++) {\n              d_ulist[ULIST_INDEX(natom, nbor, jju)].re = 0.0;\n              d_ulist[ULIST_INDEX(natom, nbor, jju)].im = 0.0;\n              jju += deljju;\n            }\n            int ncolhalf = deljju / 2;\n            jju += deljju * ncolhalf;\n          }\n\n          jju = 1;\n          jjup = 0;\n          for (int j = 1; j <= twojmax; j++) {\n            int deljju = j + 1;\n            int deljjup = j;\n            int mb_max = (j + 1) / 2;\n            int ma_max = j;\n            int m_max = ma_max * mb_max;\n\n            \n\n            for (int m_iter = 0; m_iter < m_max; ++m_iter) {\n              int mb = m_iter / ma_max;\n              int ma = m_iter % ma_max;\n              double up_r = d_ulist[ULIST_INDEX(natom, nbor, jjup)].re;\n              double up_i = d_ulist[ULIST_INDEX(natom, nbor, jjup)].im;\n\n              rootpq = d_rootpqarray[ROOTPQ_INDEX(j - ma, j - mb)];\n              d_ulist[ULIST_INDEX(natom, nbor, jju)].re += rootpq * (a_r * up_r + a_i * up_i);\n              d_ulist[ULIST_INDEX(natom, nbor, jju)].im += rootpq * (a_r * up_i - a_i * up_r);\n\n              rootpq = d_rootpqarray[ROOTPQ_INDEX(ma + 1, j - mb)];\n              d_ulist[ULIST_INDEX(natom, nbor, jju+1)].re = -rootpq * (b_r * up_r + b_i * up_i);\n              d_ulist[ULIST_INDEX(natom, nbor, jju+1)].im = -rootpq * (b_r * up_i - b_i * up_r);\n\n              \n\n\n              if (2 * (mb + 1) == j) {\n                rootpq = d_rootpqarray[ROOTPQ_INDEX(j - ma, mb + 1)];\n                d_ulist[ULIST_INDEX(natom, nbor, jju+deljju)].re += rootpq * (b_r * up_r - b_i * up_i);\n                d_ulist[ULIST_INDEX(natom, nbor, jju+deljju)].im += rootpq * (b_r * up_i + b_i * up_r);\n\n                rootpq = d_rootpqarray[ROOTPQ_INDEX(ma + 1, mb + 1)];\n                d_ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].re = rootpq * (a_r * up_r - a_i * up_i);\n                d_ulist[ULIST_INDEX(natom, nbor, jju+deljju+1)].im = rootpq * (a_r * up_i + a_i * up_r);\n              }\n\n              jju++;\n              jjup++;\n\n              if (ma == ma_max - 1)\n                jju++;\n            }\n\n            \n\n            \n\n            \n\n            \n\n            int jjui = d_idxu_block[j];\n            int jjuip = jjui + (j + 1) * (j + 1) - 1;\n            for (int mb = 0; 2 * mb < j; mb++) {\n              for (int ma = 0; ma <= j; ma++) {\n                d_ulist[ULIST_INDEX(natom, nbor, jjuip)].re = d_ulist_parity[jjui] * d_ulist[ULIST_INDEX(natom, nbor, jjui)].re;\n                d_ulist[ULIST_INDEX(natom, nbor, jjuip)].im = d_ulist_parity[jjui] * -d_ulist[ULIST_INDEX(natom, nbor, jjui)].im;\n                jjui++;\n                jjuip--;\n              }\n            }\n\n            \n\n            \n\n            if (j % 2 == 0)\n              jju += deljju;\n            int ncolhalf = deljju / 2;\n            jju += deljju * ncolhalf;\n            int ncolhalfp = deljjup / 2;\n            jjup += deljjup * ncolhalfp;\n          }\n\n          sfac = compute_sfac(r, d_rcutij[INDEX_2D(natom, nbor)], switch_flag);\n          sfac *= d_wj[INDEX_2D(natom, nbor)];\n\n          for (int j = 0; j <= twojmax; j++) {\n            int jju = d_idxu_block[j];\n            for (int mb = 0; mb <= j; mb++)\n              for (int ma = 0; ma <= j; ma++) {\n                atomicAdd(d_ulisttot[INDEX_2D(natom, jju)].re, sfac * d_ulist[ULIST_INDEX(natom, nbor, jju)].re);\n                atomicAdd(d_ulisttot[INDEX_2D(natom, jju)].im, sfac * d_ulist[ULIST_INDEX(natom, nbor, jju)].im);\n                jju++;\n              }\n          }\n        }\n      });\n    });\n\n    q.wait();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_ui += elapsed.count();\n\n    start = system_clock::now();\n\n    \n\n\n    \n\n    sycl::range<1> gws_k4 ((num_atoms*idxdu_max+255)/256*256);\n    sycl::range<1> lws_k4 (256);\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class reset_ylist>(\n        sycl::nd_range<1>(gws_k4, lws_k4), [=] (sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i < num_atoms*idxdu_max) d_ylist[i] = {0.0, 0.0};\n      });\n    });\n\n    sycl::range<2> gws_k5 ((idxz_max+15)/16*16, (num_atoms+15)/16*16);\n    sycl::range<2> lws_k5 (16, 16);\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class compute_yi>(\n        sycl::nd_range<2>(gws_k5, lws_k5), [=] (sycl::nd_item<2> item) {\n        int jjz = item.get_global_id(0);\n        int natom = item.get_global_id(1);\n        if (jjz < idxz_max && natom < num_atoms) {\n          const int j1 = d_idxz[IDXZ_INDEX(jjz, 0)];\n          const int j2 = d_idxz[IDXZ_INDEX(jjz, 1)];\n          const int j = d_idxz[IDXZ_INDEX(jjz, 2)];\n          const int ma1min = d_idxz[IDXZ_INDEX(jjz, 3)];\n          const int ma2max = d_idxz[IDXZ_INDEX(jjz, 4)];\n          const int na = d_idxz[IDXZ_INDEX(jjz, 5)];\n          const int mb1min = d_idxz[IDXZ_INDEX(jjz, 6)];\n          const int mb2max = d_idxz[IDXZ_INDEX(jjz, 7)];\n          const int nb = d_idxz[IDXZ_INDEX(jjz, 8)];\n\n          const double betaj = d_idxzbeta[jjz];\n\n          \n\n          const double* cgblock = d_cglist + d_idxcg_block[j1 + jdim*j2 + jdim*jdim*j];\n\n          int mb = (2 * (mb1min + mb2max) - j1 - j2 + j) / 2;\n          int ma = (2 * (ma1min + ma2max) - j1 - j2 + j) / 2;\n          const int jjdu = d_idxdu_block[j] + (j + 1) * mb + ma;\n\n          int jju1 = d_idxu_block[j1] + (j1 + 1) * mb1min;\n          int jju2 = d_idxu_block[j2] + (j2 + 1) * mb2max;\n          int icgb = mb1min * (j2 + 1) + mb2max;\n\n          double ztmp_r = 0.0;\n          double ztmp_i = 0.0;\n\n          \n\n          \n\n          \n\n\n          for (int ib = 0; ib < nb; ib++) {\n\n            double suma1_r = 0.0;\n            double suma1_i = 0.0;\n\n            int ma1 = ma1min;\n            int ma2 = ma2max;\n            int icga = ma1min * (j2 + 1) + ma2max;\n\n            \n\n            \n\n            \n\n\n            for (int ia = 0; ia < na; ia++) {\n              suma1_r += cgblock[icga] *\n                (d_ulisttot[INDEX_2D(natom, jju1 + ma1)].re * d_ulisttot[INDEX_2D(natom, jju2 + ma2)].re -\n                 d_ulisttot[INDEX_2D(natom, jju1 + ma1)].im * d_ulisttot[INDEX_2D(natom, jju2 + ma2)].im);\n\n              suma1_i += cgblock[icga] *\n                (d_ulisttot[INDEX_2D(natom, jju1 + ma1)].re * d_ulisttot[INDEX_2D(natom, jju2 + ma2)].im +\n                 d_ulisttot[INDEX_2D(natom, jju1 + ma1)].im * d_ulisttot[INDEX_2D(natom, jju2 + ma2)].re);\n\n              ma1++;\n              ma2--;\n              icga += j2;\n           } \n\n\n           ztmp_r += cgblock[icgb] * suma1_r;\n           ztmp_i += cgblock[icgb] * suma1_i;\n           jju1 += j1 + 1;\n           jju2 -= j2 + 1;\n           icgb += j2;\n          } \n\n\n            \n\n\n          atomicAdd(d_ylist[INDEX_2D(natom, jjdu)].re, betaj * ztmp_r);\n          atomicAdd(d_ylist[INDEX_2D(natom, jjdu)].im, betaj * ztmp_i);\n\n        } \n\n      });\n    });\n\n    q.wait();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_yi += elapsed.count();\n\n    \n\n    start = system_clock::now();\n\n    sycl::range<2> gws_k6 ((num_nbor+15)/16*16, (num_atoms+15)/16*16);\n    sycl::range<2> lws_k6 (16, 16);\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class compute_duidrj>(\n        sycl::nd_range<2>(gws_k6, lws_k6), [=] (sycl::nd_item<2> item) {\n\tint nbor = item.get_global_id(0);\n\tint natom = item.get_global_id(1);\n        if (natom < num_atoms && nbor < num_nbor) {\n          double wj_in = d_wj[INDEX_2D(natom, nbor)];\n          double rcut = d_rcutij[INDEX_2D(natom, nbor)];\n\n          double x = d_rij[ULIST_INDEX(natom, nbor, 0)];\n          double y = d_rij[ULIST_INDEX(natom, nbor, 1)];\n          double z = d_rij[ULIST_INDEX(natom, nbor, 2)];\n          double rsq = x * x + y * y + z * z;\n          double r = sycl::sqrt(rsq);\n          double rscale0 = rfac0 * MY_PI / (rcut - rmin0);\n          double theta0 = (r - rmin0) * rscale0;\n          double cs = sycl::cos(theta0);\n          double sn = sycl::sin(theta0);\n          double z0 = r * cs / sn;\n          double dz0dr = z0 / r - (r * rscale0) * (rsq + z0 * z0) / rsq;\n\n          compute_duarray(natom, nbor, num_atoms, num_nbor, twojmax,\n                          idxdu_max, jdimpq, switch_flag,\n                          x, y, z, z0, r, dz0dr, wj_in, rcut,\n                          d_rootpqarray,\n                          d_ulist,\n                          d_dulist);\n         }\n      });\n    });\n\n    q.wait();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_duidrj += elapsed.count();\n\n    start = system_clock::now();\n    \n\n    sycl::range<2> gws_k7 ((num_nbor+15)/16*16, (num_atoms+15)/16*16);\n    sycl::range<2> lws_k7 (16, 16);\n\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class compute_deidrj>(\n        sycl::nd_range<2>(gws_k7, lws_k7), [=] (sycl::nd_item<2> item) {\n\tint nbor = item.get_global_id(0);\n\tint natom = item.get_global_id(1);\n        if (natom < num_atoms && nbor < num_nbor) {\n          for (int k = 0; k < 3; k++)\n            d_dedr[ULIST_INDEX(natom, nbor, k)] = 0.0;\n\n          for (int j = 0; j <= twojmax; j++) {\n            int jjdu = d_idxdu_block[j];\n\n            for (int mb = 0; 2 * mb < j; mb++)\n              for (int ma = 0; ma <= j; ma++) {\n\n                double jjjmambyarray_r = d_ylist[INDEX_2D(natom, jjdu)].re;\n                double jjjmambyarray_i = d_ylist[INDEX_2D(natom, jjdu)].im;\n\n                for (int k = 0; k < 3; k++)\n                  d_dedr[ULIST_INDEX(natom, nbor, k)] +=\n                    d_dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                    d_dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n                jjdu++;\n              } \n\n\n            \n\n\n            if (j % 2 == 0) {\n\n              int mb = j / 2;\n              for (int ma = 0; ma < mb; ma++) {\n                double jjjmambyarray_r = d_ylist[INDEX_2D(natom, jjdu)].re;\n                double jjjmambyarray_i = d_ylist[INDEX_2D(natom, jjdu)].im;\n\n                for (int k = 0; k < 3; k++)\n                  d_dedr[ULIST_INDEX(natom, nbor, k)] +=\n                    d_dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                    d_dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i;\n                jjdu++;\n              }\n\n              double jjjmambyarray_r = d_ylist[INDEX_2D(natom, jjdu)].re;\n              double jjjmambyarray_i = d_ylist[INDEX_2D(natom, jjdu)].im;\n\n              for (int k = 0; k < 3; k++)\n                d_dedr[ULIST_INDEX(natom, nbor, k)] +=\n                  (d_dulist[DULIST_INDEX(natom, nbor, jjdu, k)].re * jjjmambyarray_r +\n                   d_dulist[DULIST_INDEX(natom, nbor, jjdu, k)].im * jjjmambyarray_i) *\n                  0.5;\n              jjdu++;\n\n            } \n\n\n          } \n\n\n          for (int k = 0; k < 3; k++)\n            d_dedr[ULIST_INDEX(natom, nbor, k)] *= 2.0;\n        }\n      });\n    });\n\n    q.wait();\n    end = system_clock::now();\n    elapsed = end - start;\n    elapsed_deidrj += elapsed.count();\n\n    q.memcpy(dedr, d_dedr, sizeof(double)*num_atoms*num_nbor*3).wait();\n\n    \n\n    \n\n    for (int natom = 0; natom < num_atoms; natom++) {\n      for (int nbor = 0; nbor < num_nbor; nbor++) {\n        int j = inside[INDEX_2D(natom, nbor)];\n        f[F_INDEX(natom, 0)] += dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(natom, 1)] += dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(natom, 2)] += dedr[ULIST_INDEX(natom, nbor, 2)];\n        f[F_INDEX(j, 0)] -= dedr[ULIST_INDEX(natom, nbor, 0)];\n        f[F_INDEX(j, 1)] -= dedr[ULIST_INDEX(natom, nbor, 1)];\n        f[F_INDEX(j, 2)] -= dedr[ULIST_INDEX(natom, nbor, 2)];\n\n      } \n\n    }   \n\n    \n\n    jt = 0;\n    for (int j = 0; j < ntotal; j++) {\n      double ferrx = f[F_INDEX(j, 0)] - refdata.fj[jt++];\n      double ferry = f[F_INDEX(j, 1)] - refdata.fj[jt++];\n      double ferrz = f[F_INDEX(j, 2)] - refdata.fj[jt++];\n      sumsqferr += ferrx * ferrx + ferry * ferry + ferrz * ferrz;\n    }\n  }\n  auto stop = myclock::now();\n  myduration elapsed = stop - begin;\n  double duration = elapsed.count();\n\n  printf(\"-----------------------\\n\");\n  printf(\"Summary of TestSNAP run\\n\");\n  printf(\"-----------------------\\n\");\n  printf(\"natoms = %d \\n\", nlocal);\n  printf(\"nghostatoms = %d \\n\", nghost);\n  printf(\"nsteps = %d \\n\", nsteps);\n  printf(\"nneighs = %d \\n\", ninside);\n  printf(\"twojmax = %d \\n\", twojmax);\n  printf(\"duration = %g [sec]\\n\", duration);\n\n  \n\n  double ktime = elapsed_ui + elapsed_yi + elapsed_duidrj + elapsed_deidrj;\n  printf(\"step time = %g [msec/step]\\n\", 1000.0 * duration / nsteps);\n  printf(\"\\n Individual kernel timings for each step\\n\");\n  printf(\"   compute_ui = %g [msec/step]\\n\", 1000.0 * elapsed_ui / nsteps);\n  printf(\"   compute_yi = %g [msec/step]\\n\", 1000.0 * elapsed_yi / nsteps);\n  printf(\"   compute_duidrj = %g [msec/step]\\n\", 1000.0 * elapsed_duidrj / nsteps);\n  printf(\"   compute_deidrj = %g [msec/step]\\n\", 1000.0 * elapsed_deidrj / nsteps);\n  printf(\"   Total kernel time = %g [msec/step]\\n\", 1000.0 * ktime / nsteps);\n  printf(\"   Percentage of step time = %g%%\\n\\n\", ktime / duration * 100.0);\n  printf(\"grind time = %g [msec/atom-step]\\n\", 1000.0 * duration / (nlocal * nsteps));\n  printf(\"RMS |Fj| deviation %g [eV/A]\\n\", sqrt(sumsqferr / (ntotal * nsteps)));\n\n  sycl::free(d_idxu_block, q);\n  sycl::free(d_ulist_parity, q);\n  sycl::free(d_rootpqarray, q);\n  sycl::free(d_idxz, q);\n  sycl::free(d_idxzbeta, q);\n  sycl::free(d_idxcg_block, q);\n  sycl::free(d_idxdu_block, q);\n  sycl::free(d_cglist, q);\n  sycl::free(d_dulist, q);\n  sycl::free(d_ulist, q);\n  sycl::free(d_dedr, q);\n  sycl::free(d_ulisttot, q);\n  sycl::free(d_ylist, q);\n  sycl::free(d_rij, q);\n  sycl::free(d_rcutij, q);\n  sycl::free(d_wj, q);\n\n  free(coeffi);\n  free(idxcg_block);\n  free(idxu_block);\n  free(ulist_parity);\n  free(idxdu_block);\n  free(idxb);\n  free(idxb_block);\n  free(idxz);\n  free(idxzbeta);\n  free(idxz_block);\n  free(rij);\n  free(inside);\n  free(wj);\n  free(rcutij);\n  free(rootpqarray);\n  free(cglist);\n  free(dedr);\n  free(ulist);\n  free(ylist);\n  free(ulisttot);\n  free(dulist);\n  free(f);\n\n  return 0;\n}\n"}}
{"kernel_name": "thomas", "parallel_api": "cuda", "code": {"cuThomasBatch.cu": "\n\n\n\n\n\n\n\n\n#include \"cuThomasBatch.h\"\n\n__global__ void cuThomasBatch(\n            const double *L, const double *D, double *U, double *RHS,\n            const int M,\n            const int BATCHCOUNT\n    ) {\n\n        int tid = threadIdx.x + blockDim.x*blockIdx.x;\n\n        if(tid < BATCHCOUNT) {\n\n            int first = tid;\n            int last  = BATCHCOUNT*(M-1)+tid;\n\n            U[first] /= D[first];\n            RHS[first] /= D[first];\n\n            for (int i = first + BATCHCOUNT; i < last; i+=BATCHCOUNT) {\n                U[i] /= D[i] - L[i] * U[i-BATCHCOUNT];\n                RHS[i] = ( RHS[i] - L[i] * RHS[i-BATCHCOUNT] ) / \n\t\t\t\t\t\t\t( D[i] - L[i] * U[i-BATCHCOUNT] );\n            }\n\n            RHS[last] = ( RHS[last] - L[last] * RHS[last-BATCHCOUNT] ) / \n\t\t\t\t\t\t\t( D[last] - L[last] * U[last-BATCHCOUNT] );\n\n            for (int i = last-BATCHCOUNT; i >= first; i-=BATCHCOUNT) {\n                RHS[i] -= U[i] * RHS[i+BATCHCOUNT];\n            }\n       }\n        \n}\n", "main.cu": "#include <chrono>\n#include <iostream>\n#include <cuda.h>\n#include \"ThomasMatrix.hpp\"\n#include \"utils.hpp\"\n#include \"cuThomasBatch.h\"\n\n\n\nvoid solve_seq(const double* l, const double* d,\n               double* u, double* rhs,\n               const int n, const int N) \n{\n  int first,last;\n  for (int j = 0; j < N; ++j)\n  {\n    first = j*n;\n    last = first + n - 1;\n\n    u[first] /= d[first];\n    rhs[first] /= d[first];\n\n    for (int i = first+1; i < last; i++) {\n      u[i] /= d[i] - l[i]*u[i-1];\n      rhs[i] = (rhs[i] - l[i]*rhs[i-1]) / (d[i] - l[i]*u[i-1]);\n    }\n\n    rhs[last] = (rhs[last] - l[last]*rhs[last-1]) / (d[last] - l[last]*u[last-1]);\n\n    for (int i = last-1; i >= first; i--) {\n      rhs[i] -= u[i]*rhs[i+1];\n    }\n  }\n}\n\nint main(int argc, char const *argv[])\n{\n  if(argc != 5) {\n    std::cout << \"Usage: %s [system size] [#systems] [thread block size] [repeat]\" << std::endl;\n    return -1;\n  }\n\n  const int M = std::stoi(argv[1]);\n  const int N = std::stoi(argv[2]);\n  const int BlockSize = std::stoi(argv[3]);  \n\n  const int repeat = std::stoi(argv[4]);\n\n  const size_t matrix_size = (size_t)M * N;\n  const size_t matrix_size_bytes = matrix_size * sizeof(double);\n\n  \n\n  ThomasMatrix params = loadThomasMatrixSyn(M);\n\n  double* u_seq = (double*) malloc(matrix_size_bytes);\n  double* u_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* u_input = (double*) malloc(matrix_size_bytes);\n\n  double* d_seq = (double*) malloc(matrix_size_bytes);\n  double* d_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* d_input = (double*) malloc(matrix_size_bytes);\n\n  double* l_seq = (double*) malloc(matrix_size_bytes);\n  double* l_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* l_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq = (double*) malloc(matrix_size_bytes);\n  double* rhs_Thomas_host = (double*) malloc(matrix_size_bytes);\n  double* rhs_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq_output = (double*) malloc(matrix_size_bytes);\n  double* rhs_seq_interleave = (double*) malloc(matrix_size_bytes);\n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n    }\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int n = 0; n < repeat; n++) {\n    solve_seq( l_seq, d_seq, u_seq, rhs_seq, M, N );\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average serial execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  for (size_t i = 0; i < matrix_size; ++i) {\n    rhs_seq_output[i] = rhs_seq[i];\n  }\n\n  \n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n\n    }\n  }\n\n  \n\n  for (int i = 0; i < M; ++i)\n  {\n    for (int j = 0; j < N; ++j)\n    {\n      u_Thomas_host[i*N+j] = u_input[j*M+i];\n      l_Thomas_host[i*N+j] = l_input[j*M+i];\n      d_Thomas_host[i*N+j] = d_input[j*M+i];\n      rhs_Thomas_host[i*N+j] = rhs_input[j*M+i];\n      rhs_seq_interleave[i*N+j] = rhs_seq_output[j*M+i];\n    }\n  }\n \n  \n\n\n  double *u_device;\n  double *d_device;\n  double *l_device;\n  double *rhs_device;\n\n  cudaMalloc((void**)&u_device, matrix_size_bytes);\n  cudaMalloc((void**)&l_device, matrix_size_bytes);\n  cudaMalloc((void**)&d_device, matrix_size_bytes);\n  cudaMalloc((void**)&rhs_device, matrix_size_bytes);\n\n  cudaMemcpy(u_device, u_Thomas_host, matrix_size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(l_device, l_Thomas_host, matrix_size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_device, d_Thomas_host, matrix_size_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(rhs_device, rhs_Thomas_host, matrix_size_bytes, cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++) {\n    cuThomasBatch<<<(N/BlockSize)+1, BlockSize>>>(l_device, d_device, u_device, rhs_device, M, N);\n  }\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  cudaMemcpy(rhs_Thomas_host, rhs_device, matrix_size_bytes, cudaMemcpyDeviceToHost);\n  cudaDeviceSynchronize();\n\n  \n\n  calcError(rhs_seq_interleave, rhs_Thomas_host, matrix_size);\n\n  free(u_seq);  \n  free(u_Thomas_host);\n  free(u_input);\n\n  free(d_seq);  \n  free(d_Thomas_host);\n  free(d_input);\n\n  free(l_seq);  \n  free(l_Thomas_host);\n  free(l_input);\n\n  free(rhs_seq);  \n  free(rhs_Thomas_host);\n  free(rhs_input);\n\n  free(rhs_seq_output);\n  free(rhs_seq_interleave);\n\n  cudaFree(l_device);\n  cudaFree(d_device);\n  cudaFree(u_device);\n  cudaFree(rhs_device);\n\n  return 0;\n}\n"}}
{"kernel_name": "thomas", "parallel_api": "hip", "code": {"cuThomasBatch.cu": "\n\n\n\n\n\n\n\n#include \"cuThomasBatch.h\"\n\n__global__ void cuThomasBatch(\n            const double *L, const double *D, double *U, double *RHS,\n            const int M,\n            const int BATCHCOUNT\n    ) {\n\n        int tid = threadIdx.x + blockDim.x*blockIdx.x;\n\n        if(tid < BATCHCOUNT) {\n\n            int first = tid;\n            int last  = BATCHCOUNT*(M-1)+tid;\n\n            U[first] /= D[first];\n            RHS[first] /= D[first];\n\n            for (int i = first + BATCHCOUNT; i < last; i+=BATCHCOUNT) {\n                U[i] /= D[i] - L[i] * U[i-BATCHCOUNT];\n                RHS[i] = ( RHS[i] - L[i] * RHS[i-BATCHCOUNT] ) / \n\t\t\t\t\t\t\t( D[i] - L[i] * U[i-BATCHCOUNT] );\n            }\n\n            RHS[last] = ( RHS[last] - L[last] * RHS[last-BATCHCOUNT] ) / \n\t\t\t\t\t\t\t( D[last] - L[last] * U[last-BATCHCOUNT] );\n\n            for (int i = last-BATCHCOUNT; i >= first; i-=BATCHCOUNT) {\n                RHS[i] -= U[i] * RHS[i+BATCHCOUNT];\n            }\n       }\n        \n}\n", "main.cu": "#include <chrono>\n#include <iostream>\n#include <hip/hip_runtime.h>\n#include \"ThomasMatrix.hpp\"\n#include \"utils.hpp\"\n#include \"cuThomasBatch.h\"\n\n\n\nvoid solve_seq(const double* l, const double* d,\n               double* u, double* rhs,\n               const int n, const int N) \n{\n  int first,last;\n  for (int j = 0; j < N; ++j)\n  {\n    first = j*n;\n    last = first + n - 1;\n\n    u[first] /= d[first];\n    rhs[first] /= d[first];\n\n    for (int i = first+1; i < last; i++) {\n      u[i] /= d[i] - l[i]*u[i-1];\n      rhs[i] = (rhs[i] - l[i]*rhs[i-1]) / (d[i] - l[i]*u[i-1]);\n    }\n\n    rhs[last] = (rhs[last] - l[last]*rhs[last-1]) / (d[last] - l[last]*u[last-1]);\n\n    for (int i = last-1; i >= first; i--) {\n      rhs[i] -= u[i]*rhs[i+1];\n    }\n  }\n}\n\nint main(int argc, char const *argv[])\n{\n  if(argc != 5) {\n    std::cout << \"Usage: %s [system size] [#systems] [thread block size] [repeat]\" << std::endl;\n    return -1;\n  }\n\n  const int M = std::stoi(argv[1]);\n  const int N = std::stoi(argv[2]);\n  const int BlockSize = std::stoi(argv[3]);  \n\n  const int repeat = std::stoi(argv[4]);\n\n  const size_t matrix_size = (size_t)M * N;\n  const size_t matrix_size_bytes = matrix_size * sizeof(double);\n\n  \n\n  ThomasMatrix params = loadThomasMatrixSyn(M);\n\n  double* u_seq = (double*) malloc(matrix_size_bytes);\n  double* u_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* u_input = (double*) malloc(matrix_size_bytes);\n\n  double* d_seq = (double*) malloc(matrix_size_bytes);\n  double* d_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* d_input = (double*) malloc(matrix_size_bytes);\n\n  double* l_seq = (double*) malloc(matrix_size_bytes);\n  double* l_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* l_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq = (double*) malloc(matrix_size_bytes);\n  double* rhs_Thomas_host = (double*) malloc(matrix_size_bytes);\n  double* rhs_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq_output = (double*) malloc(matrix_size_bytes);\n  double* rhs_seq_interleave = (double*) malloc(matrix_size_bytes);\n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n    }\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int n = 0; n < repeat; n++) {\n    solve_seq( l_seq, d_seq, u_seq, rhs_seq, M, N );\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average serial execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  for (size_t i = 0; i < matrix_size; ++i) {\n    rhs_seq_output[i] = rhs_seq[i];\n  }\n\n  \n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n\n    }\n  }\n\n  \n\n  for (int i = 0; i < M; ++i)\n  {\n    for (int j = 0; j < N; ++j)\n    {\n      u_Thomas_host[i*N+j] = u_input[j*M+i];\n      l_Thomas_host[i*N+j] = l_input[j*M+i];\n      d_Thomas_host[i*N+j] = d_input[j*M+i];\n      rhs_Thomas_host[i*N+j] = rhs_input[j*M+i];\n      rhs_seq_interleave[i*N+j] = rhs_seq_output[j*M+i];\n    }\n  }\n \n  \n\n\n  double *u_device;\n  double *d_device;\n  double *l_device;\n  double *rhs_device;\n\n  hipMalloc((void**)&u_device, matrix_size_bytes);\n  hipMalloc((void**)&l_device, matrix_size_bytes);\n  hipMalloc((void**)&d_device, matrix_size_bytes);\n  hipMalloc((void**)&rhs_device, matrix_size_bytes);\n\n  hipMemcpy(u_device, u_Thomas_host, matrix_size_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(l_device, l_Thomas_host, matrix_size_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_device, d_Thomas_host, matrix_size_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(rhs_device, rhs_Thomas_host, matrix_size_bytes, hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++) {\n    cuThomasBatch<<<(N/BlockSize)+1, BlockSize>>>(l_device, d_device, u_device, rhs_device, M, N);\n  }\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  hipMemcpy(rhs_Thomas_host, rhs_device, matrix_size_bytes, hipMemcpyDeviceToHost);\n  hipDeviceSynchronize();\n\n  \n\n  calcError(rhs_seq_interleave, rhs_Thomas_host, matrix_size);\n\n  free(u_seq);  \n  free(u_Thomas_host);\n  free(u_input);\n\n  free(d_seq);  \n  free(d_Thomas_host);\n  free(d_input);\n\n  free(l_seq);  \n  free(l_Thomas_host);\n  free(l_input);\n\n  free(rhs_seq);  \n  free(rhs_Thomas_host);\n  free(rhs_input);\n\n  free(rhs_seq_output);\n  free(rhs_seq_interleave);\n\n  hipFree(l_device);\n  hipFree(d_device);\n  hipFree(u_device);\n  hipFree(rhs_device);\n\n  return 0;\n}\n"}}
{"kernel_name": "thomas", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include \"ThomasMatrix.hpp\"\n#include \"utils.hpp\"\n\n\n\nvoid solve_seq(const double* l, const double* d, double* u, double* rhs, const int n, const int N) \n{\n  int first,last;\n  for (int j = 0; j < N; ++j)\n  {\n    first = j*n;\n    last = first + n - 1;\n\n    u[first] /= d[first];\n    rhs[first] /= d[first];\n\n    for (int i = first+1; i < last; i++) {\n      u[i] /= d[i] - l[i]*u[i-1];\n      rhs[i] = (rhs[i] - l[i]*rhs[i-1]) / (d[i] - l[i]*u[i-1]);\n    }\n\n    rhs[last] = (rhs[last] - l[last]*rhs[last-1]) / (d[last] - l[last]*u[last-1]);\n\n    for (int i = last-1; i >= first; i--) {\n      rhs[i] -= u[i]*rhs[i+1];\n    }\n  }\n}\n\nint main(int argc, char const *argv[])\n{\n  if(argc != 5) {\n    std::cout << \"Usage: %s [system size] [#systems] [thread block size] [repeat]\" << std::endl;\n    return -1;\n  }\n\n  const int M = std::stoi(argv[1]);\n  const int N = std::stoi(argv[2]);\n  const int BlockSize = std::stoi(argv[3]);  \n\n  const int repeat = std::stoi(argv[4]);\n\n  const size_t matrix_size = (size_t)M * N;\n  const size_t matrix_size_bytes = matrix_size * sizeof(double);\n\n  \n\n  ThomasMatrix params = loadThomasMatrixSyn(M);\n\n  \n\n  double* u_seq = (double*) malloc(matrix_size_bytes);\n  double* u_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* u_input = (double*) malloc(matrix_size_bytes);\n\n  double* d_seq = (double*) malloc(matrix_size_bytes);\n  double* d_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* d_input = (double*) malloc(matrix_size_bytes);\n\n  double* l_seq = (double*) malloc(matrix_size_bytes);\n  double* l_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* l_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq = (double*) malloc(matrix_size_bytes);\n  double* rhs_Thomas_host = (double*) malloc(matrix_size_bytes);\n  double* rhs_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq_output = (double*) malloc(matrix_size_bytes);\n  double* rhs_seq_interleave = (double*) malloc(matrix_size_bytes);\n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n\n    }\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  \n\n  for (int n = 0; n < repeat; n++) {\n    solve_seq( l_seq, d_seq, u_seq, rhs_seq, M, N );\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average serial execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  for (size_t i = 0; i < matrix_size; ++i) {\n    rhs_seq_output[i] = rhs_seq[i];\n  }\n\n  \n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n    }\n  }\n\n\n  \n\n  for (int i = 0; i < M; ++i)\n  {\n    for (int j = 0; j < N; ++j)\n    {\n      u_Thomas_host[i*N+j] = u_input[j*M+i];\n      l_Thomas_host[i*N+j] = l_input[j*M+i];\n      d_Thomas_host[i*N+j] = d_input[j*M+i];\n      rhs_Thomas_host[i*N+j] = rhs_input[j*M+i];\n      rhs_seq_interleave[i*N+j] = rhs_seq_output[j*M+i];\n    }\n  }\n\n  \n\n  double *U = u_Thomas_host;\n  double *D = d_Thomas_host;\n  double *L = l_Thomas_host;\n  double *RHS = rhs_Thomas_host;\n\n  #pragma omp target data map(to: L[0:matrix_size], \\\n                                  D[0:matrix_size], \\\n                                  U[0:matrix_size]) \\\n                          map(tofrom: RHS[0:matrix_size])\n  {\n    start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      #pragma omp target teams distribute parallel for thread_limit(BlockSize) nowait\n      for (int tid = 0; tid < N; tid++) {\n        int first = tid;\n        int last  = N*(M-1)+tid;\n\n        U[first] /= D[first];\n        RHS[first] /= D[first];\n\n        for (int i = first + N; i < last; i+=N) {\n          U[i] /= D[i] - L[i] * U[i-N];\n          RHS[i] = ( RHS[i] - L[i] * RHS[i-N] ) / \n                   ( D[i] - L[i] * U[i-N] );\n        }\n\n        RHS[last] = ( RHS[last] - L[last] * RHS[last-N] ) / \n                    ( D[last] - L[last] * U[last-N] );\n\n        for (int i = last-N; i >= first; i-=N) {\n          RHS[i] -= U[i] * RHS[i+N];\n        }\n      }\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  calcError(rhs_seq_interleave, RHS, matrix_size);\n\n  free(u_seq);  \n  free(u_Thomas_host);\n  free(u_input);\n\n  free(d_seq);  \n  free(d_Thomas_host);\n  free(d_input);\n\n  free(l_seq);  \n  free(l_Thomas_host);\n  free(l_input);\n\n  free(rhs_seq);  \n  free(rhs_Thomas_host);\n  free(rhs_input);\n\n  free(rhs_seq_output);\n  free(rhs_seq_interleave);\n\n  return 0;\n}\n"}}
{"kernel_name": "thomas", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include \"ThomasMatrix.hpp\"\n#include \"utils.hpp\"\n\n\n\nvoid solve_seq(const double* l, const double* d, double* u, double* rhs, const int n, const int N) \n{\n  int first,last;\n  for (int j = 0; j < N; ++j)\n  {\n    first = j*n;\n    last = first + n - 1;\n\n    u[first] /= d[first];\n    rhs[first] /= d[first];\n\n    for (int i = first+1; i < last; i++) {\n      u[i] /= d[i] - l[i]*u[i-1];\n      rhs[i] = (rhs[i] - l[i]*rhs[i-1]) / (d[i] - l[i]*u[i-1]);\n    }\n\n    rhs[last] = (rhs[last] - l[last]*rhs[last-1]) / (d[last] - l[last]*u[last-1]);\n\n    for (int i = last-1; i >= first; i--) {\n      rhs[i] -= u[i]*rhs[i+1];\n    }\n  }\n}\n\nint main(int argc, char const *argv[])\n{\n  if(argc != 5) {\n    std::cout << \"Usage: %s [system size] [#systems] [thread block size] [repeat]\" << std::endl;\n    return -1;\n  }\n\n  const int M = std::stoi(argv[1]);\n  const int N = std::stoi(argv[2]);\n  const int BlockSize = std::stoi(argv[3]);  \n\n  const int repeat = std::stoi(argv[4]);\n\n  const size_t matrix_size = (size_t)M * N;\n  const size_t matrix_size_bytes = matrix_size * sizeof(double);\n\n  \n\n  ThomasMatrix params = loadThomasMatrixSyn(M);\n\n  \n\n  double* u_seq = (double*) malloc(matrix_size_bytes);\n  double* u_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* u_input = (double*) malloc(matrix_size_bytes);\n\n  double* d_seq = (double*) malloc(matrix_size_bytes);\n  double* d_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* d_input = (double*) malloc(matrix_size_bytes);\n\n  double* l_seq = (double*) malloc(matrix_size_bytes);\n  double* l_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* l_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq = (double*) malloc(matrix_size_bytes);\n  double* rhs_Thomas_host = (double*) malloc(matrix_size_bytes);\n  double* rhs_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq_output = (double*) malloc(matrix_size_bytes);\n  double* rhs_seq_interleave = (double*) malloc(matrix_size_bytes);\n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n\n    }\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  \n\n  for (int n = 0; n < repeat; n++) {\n    solve_seq( l_seq, d_seq, u_seq, rhs_seq, M, N );\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average serial execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  for (size_t i = 0; i < matrix_size; ++i) {\n    rhs_seq_output[i] = rhs_seq[i];\n  }\n\n  \n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n    }\n  }\n\n\n  \n\n  for (int i = 0; i < M; ++i)\n  {\n    for (int j = 0; j < N; ++j)\n    {\n      u_Thomas_host[i*N+j] = u_input[j*M+i];\n      l_Thomas_host[i*N+j] = l_input[j*M+i];\n      d_Thomas_host[i*N+j] = d_input[j*M+i];\n      rhs_Thomas_host[i*N+j] = rhs_input[j*M+i];\n      rhs_seq_interleave[i*N+j] = rhs_seq_output[j*M+i];\n    }\n  }\n\n  \n\n  double *U = u_Thomas_host;\n  double *D = d_Thomas_host;\n  double *L = l_Thomas_host;\n  double *RHS = rhs_Thomas_host;\n\n    {\n    start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n            for (int tid = 0; tid < N; tid++) {\n        int first = tid;\n        int last  = N*(M-1)+tid;\n\n        U[first] /= D[first];\n        RHS[first] /= D[first];\n\n        for (int i = first + N; i < last; i+=N) {\n          U[i] /= D[i] - L[i] * U[i-N];\n          RHS[i] = ( RHS[i] - L[i] * RHS[i-N] ) / \n                   ( D[i] - L[i] * U[i-N] );\n        }\n\n        RHS[last] = ( RHS[last] - L[last] * RHS[last-N] ) / \n                    ( D[last] - L[last] * U[last-N] );\n\n        for (int i = last-N; i >= first; i-=N) {\n          RHS[i] -= U[i] * RHS[i+N];\n        }\n      }\n    }\n\n    end = std::chrono::steady_clock::now();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n  }\n\n  calcError(rhs_seq_interleave, RHS, matrix_size);\n\n  free(u_seq);  \n  free(u_Thomas_host);\n  free(u_input);\n\n  free(d_seq);  \n  free(d_Thomas_host);\n  free(d_input);\n\n  free(l_seq);  \n  free(l_Thomas_host);\n  free(l_input);\n\n  free(rhs_seq);  \n  free(rhs_Thomas_host);\n  free(rhs_input);\n\n  free(rhs_seq_output);\n  free(rhs_seq_interleave);\n\n  return 0;\n}"}}
{"kernel_name": "thomas", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include <sycl/sycl.hpp>\n#include \"ThomasMatrix.hpp\"\n#include \"utils.hpp\"\n\n\n\nvoid solve_seq(const double* l, const double* d, double* u, double* rhs, const int n, const int N)\n{\n  int first,last;\n  for (int j = 0; j < N; ++j)\n  {\n    first = j*n;\n    last = first + n - 1;\n\n    u[first] /= d[first];\n    rhs[first] /= d[first];\n\n    for (int i = first+1; i < last; i++) {\n      u[i] /= d[i] - l[i]*u[i-1];\n      rhs[i] = (rhs[i] - l[i]*rhs[i-1]) / (d[i] - l[i]*u[i-1]);\n    }\n\n    rhs[last] = (rhs[last] - l[last]*rhs[last-1]) / (d[last] - l[last]*u[last-1]);\n\n    for (int i = last-1; i >= first; i--) {\n      rhs[i] -= u[i]*rhs[i+1];\n    }\n  }\n}\n\nint main(int argc, char const *argv[])\n{\n  if(argc != 5) {\n    std::cout << \"Usage: %s [system size] [#systems] [thread block size] [repeat]\" << std::endl;\n    return -1;\n  }\n\n  const int M = std::stoi(argv[1]);\n  const int N = std::stoi(argv[2]);\n  const int BlockSize = std::stoi(argv[3]);  \n\n  const int repeat = std::stoi(argv[4]);\n\n  const size_t matrix_size = (size_t)M * N;\n  const size_t matrix_size_bytes = matrix_size * sizeof(double);\n\n  \n\n  ThomasMatrix params = loadThomasMatrixSyn(M);\n\n  \n\n  double* u_seq = (double*) malloc(matrix_size_bytes);\n  double* u_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* u_input = (double*) malloc(matrix_size_bytes);\n\n  double* d_seq = (double*) malloc(matrix_size_bytes);\n  double* d_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* d_input = (double*) malloc(matrix_size_bytes);\n\n  double* l_seq = (double*) malloc(matrix_size_bytes);\n  double* l_Thomas_host =  (double*) malloc(matrix_size_bytes);\n  double* l_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq = (double*) malloc(matrix_size_bytes);\n  double* rhs_Thomas_host = (double*) malloc(matrix_size_bytes);\n  double* rhs_input = (double*) malloc(matrix_size_bytes);\n\n  double* rhs_seq_output = (double*) malloc(matrix_size_bytes);\n  double* rhs_seq_interleave = (double*) malloc(matrix_size_bytes);\n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n\n    }\n  }\n\n  auto start = std::chrono::steady_clock::now();\n\n  \n\n  for (int n = 0; n < repeat; n++) {\n    solve_seq( l_seq, d_seq, u_seq, rhs_seq, M, N );\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average serial execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  for (size_t i = 0; i < matrix_size; ++i) {\n    rhs_seq_output[i] = rhs_seq[i];\n  }\n\n  \n\n  for (int i = 0; i < N; ++i)\n  {\n    for (int j = 0; j < M; ++j)\n    {\n      u_seq[(i * M) + j] = params.a[j];\n      u_input[(i * M) + j] = params.a[j];\n\n      d_seq[(i * M) + j] = params.d[j];\n      d_input[(i * M) + j] = params.d[j];\n\n      l_seq[(i * M) + j] = params.b[j];\n      l_input[(i * M) + j] = params.b[j];\n\n      rhs_seq[(i * M) + j] = params.rhs[j];\n      rhs_input[(i * M) + j] = params.rhs[j];\n    }\n  }\n\n\n  \n\n  for (int i = 0; i < M; ++i)\n  {\n    for (int j = 0; j < N; ++j)\n    {\n      u_Thomas_host[i*N+j] = u_input[j*M+i];\n      l_Thomas_host[i*N+j] = l_input[j*M+i];\n      d_Thomas_host[i*N+j] = d_input[j*M+i];\n      rhs_Thomas_host[i*N+j] = rhs_input[j*M+i];\n      rhs_seq_interleave[i*N+j] = rhs_seq_output[j*M+i];\n    }\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  double *u_d = sycl::malloc_device<double>(matrix_size, q);\n  q.memcpy(u_d, u_Thomas_host, matrix_size_bytes);\n\n  double *d_d = sycl::malloc_device<double>(matrix_size, q);\n  q.memcpy(d_d, d_Thomas_host, matrix_size_bytes);\n\n  double *l_d = sycl::malloc_device<double>(matrix_size, q);\n  q.memcpy(l_d, l_Thomas_host, matrix_size_bytes);\n\n  double *rhs_d = sycl::malloc_device<double>(matrix_size, q);\n  q.memcpy(rhs_d, rhs_Thomas_host, matrix_size_bytes);\n\n  sycl::range<1> gws ((N + BlockSize - 1) / BlockSize * BlockSize);\n  sycl::range<1> lws (BlockSize);\n\n  q.wait();\n  start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class thomas>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int tid = item.get_global_id(0);\n        if (tid < N) {\n          int first = tid;\n          int last  = N*(M-1)+tid;\n\n          u_d[first] /= d_d[first];\n          rhs_d[first] /= d_d[first];\n\n          for (int i = first + N; i < last; i+=N) {\n            u_d[i] /= d_d[i] - l_d[i] * u_d[i-N];\n            rhs_d[i] = ( rhs_d[i] - l_d[i] * rhs_d[i-N] ) /\n                       ( d_d[i] - l_d[i] * u_d[i-N] );\n          }\n\n          rhs_d[last] = ( rhs_d[last] - l_d[last] * rhs_d[last-N] ) /\n                        ( d_d[last] - l_d[last] * u_d[last-N] );\n\n          for (int i = last-N; i >= first; i-=N) {\n            rhs_d[i] -= u_d[i] * rhs_d[i+N];\n          }\n        }\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  q.memcpy(rhs_Thomas_host, rhs_d, matrix_size_bytes).wait();\n\n  \n\n  calcError(rhs_seq_interleave, rhs_Thomas_host, matrix_size);\n\n  free(u_seq);\n  free(u_Thomas_host);\n  free(u_input);\n\n  free(d_seq);\n  free(d_Thomas_host);\n  free(d_input);\n\n  free(l_seq);\n  free(l_Thomas_host);\n  free(l_input);\n\n  free(rhs_seq);\n  free(rhs_Thomas_host);\n  free(rhs_input);\n\n  free(rhs_seq_output);\n  free(rhs_seq_interleave);\n\n  sycl::free(l_d, q);\n  sycl::free(d_d, q);\n  sycl::free(u_d, q);\n  sycl::free(rhs_d, q);\n  return 0;\n}\n"}}
{"kernel_name": "tsa", "parallel_api": "cuda", "code": {"main.cu": "#include <complex>\n#include <cmath>\n#include <cstdio>\n#include <cstring>\n#include <chrono>\n#include <cuda.h>\n#include \"kernels.h\"\n#include \"reference.h\"\n\ntemplate <typename T>\nvoid init_p(T *p_real, T *p_imag, int width, int height) {\n  double s = 64.0;\n  for (int j = 1; j <= height; j++) {\n    for (int i = 1; i <= width; i++) {\n      \n\n      std::complex<T> tmp = std::complex<T>(\n        exp(-(pow(i - 180.0, 2.0) + pow(j - 300.0, 2.0)) / (2.0 * pow(s, 2.0))), 0.0) *\n        exp(std::complex<T>(0.0, 0.4 * (i + j - 480.0)));\n\n      p_real[(j-1) * width + i-1] = real(tmp);\n      p_imag[(j-1) * width + i-1] = imag(tmp);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid tsa(int width, int height, int repeat) {\n\n  T * p_real = new T[width * height];\n  T * p_imag = new T[width * height];\n  T * h_real = new T[width * height];\n  T * h_imag = new T[width * height];\n\n  \n\n  init_p(p_real, p_imag, width, height);\n\n  \n\n  T a = cos(0.02);\n  T b = sin(0.02);\n\n  \n\n  memcpy(h_imag, p_imag, sizeof(T)*width*height);\n  memcpy(h_real, p_real, sizeof(T)*width*height);\n  reference(h_real, h_imag, a, b, width, height, repeat);\n\n  \n\n  const int BLOCK_X = 16;\n  \n\n  const int BLOCK_Y = sizeof(T) == 8 ? 32 : 96;\n  \n\n  const int STRIDE_Y = 16;\n\n  \n\n  const int MARGIN_X = 3;\n  const int MARGIN_Y = 4;\n\n  \n\n  const int STEPS = 1;\n\n  dim3 grids ((width + (BLOCK_X - 2 * STEPS * MARGIN_X) - 1) / (BLOCK_X - 2 * STEPS * MARGIN_X),\n              (height + (BLOCK_Y - 2 * STEPS * MARGIN_Y) - 1) / (BLOCK_Y - 2 * STEPS * MARGIN_Y));\n  dim3 blocks (BLOCK_X, STRIDE_Y);\n  int sense = 0;\n\n  \n\n  T *d_real[2];\n  T *d_imag[2];\n\n  cudaMalloc((void**)(&d_real[0]), width * height * sizeof(T));\n  cudaMalloc((void**)(&d_real[1]), width * height * sizeof(T));\n  cudaMalloc((void**)(&d_imag[0]), width * height * sizeof(T));\n  cudaMalloc((void**)(&d_imag[1]), width * height * sizeof(T));\n  cudaMemcpy(d_real[0], p_real, width * height * sizeof(T), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_imag[0], p_imag, width * height * sizeof(T), cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    kernel<T, STEPS, BLOCK_X, BLOCK_Y, MARGIN_X, MARGIN_Y, STRIDE_Y>\n          <<<grids, blocks>>>(a, b, width, height,\n           d_real[sense], d_imag[sense], d_real[1-sense], d_imag[1-sense]);\n    sense = 1 - sense; \n\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  cudaMemcpy(p_real, d_real[sense], width * height * sizeof(T), cudaMemcpyDeviceToHost);\n  cudaMemcpy(p_imag, d_imag[sense], width * height * sizeof(T), cudaMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(p_real[i] - h_real[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n    if (fabs(p_imag[i] - h_imag[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] p_real;\n  delete[] p_imag;\n  delete[] h_real;\n  delete[] h_imag;\n  cudaFree(d_real[0]);\n  cudaFree(d_real[1]);\n  cudaFree(d_imag[0]);\n  cudaFree(d_imag[1]);\n}\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <matrix width> <matrix height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int width = atoi(argv[1]);   \n\n  int height = atoi(argv[2]);  \n\n  int repeat = atoi(argv[3]);  \n\n\n  printf(\"TSA in float32\\n\");\n  tsa<float>(width, height, repeat);\n\n  printf(\"\\n\");\n\n  printf(\"TSA in float64\\n\");\n  tsa<double>(width, height, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "tsa", "parallel_api": "hip", "code": {"main.cu": "#include <complex>\n#include <cmath>\n#include <cstdio>\n#include <cstring>\n#include <chrono>\n#include <hip/hip_runtime.h>\n#include \"kernels.h\"\n#include \"reference.h\"\n\ntemplate <typename T>\nvoid init_p(T *p_real, T *p_imag, int width, int height) {\n  double s = 64.0;\n  for (int j = 1; j <= height; j++) {\n    for (int i = 1; i <= width; i++) {\n      \n\n      std::complex<T> tmp = std::complex<T>(\n        exp(-(pow(i - 180.0, 2.0) + pow(j - 300.0, 2.0)) / (2.0 * pow(s, 2.0))), 0.0) *\n        exp(std::complex<T>(0.0, 0.4 * (i + j - 480.0)));\n\n      p_real[(j-1) * width + i-1] = real(tmp);\n      p_imag[(j-1) * width + i-1] = imag(tmp);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid tsa(int width, int height, int repeat) {\n\n  T * p_real = new T[width * height];\n  T * p_imag = new T[width * height];\n  T * h_real = new T[width * height];\n  T * h_imag = new T[width * height];\n\n  \n\n  init_p(p_real, p_imag, width, height);\n\n  \n\n  T a = cos(0.02);\n  T b = sin(0.02);\n\n  \n\n  memcpy(h_imag, p_imag, sizeof(T)*width*height);\n  memcpy(h_real, p_real, sizeof(T)*width*height);\n  reference(h_real, h_imag, a, b, width, height, repeat);\n\n  \n\n  const int BLOCK_X = 16;\n  \n\n  const int BLOCK_Y = sizeof(T) == 8 ? 32 : 96;\n  \n\n  const int STRIDE_Y = 16;\n\n  \n\n  const int MARGIN_X = 3;\n  const int MARGIN_Y = 4;\n\n  \n\n  const int STEPS = 1;\n\n  dim3 grids ((width + (BLOCK_X - 2 * STEPS * MARGIN_X) - 1) / (BLOCK_X - 2 * STEPS * MARGIN_X),\n              (height + (BLOCK_Y - 2 * STEPS * MARGIN_Y) - 1) / (BLOCK_Y - 2 * STEPS * MARGIN_Y));\n  dim3 blocks (BLOCK_X, STRIDE_Y);\n  int sense = 0;\n\n  \n\n  T *d_real[2];\n  T *d_imag[2];\n\n  hipMalloc((void**)(&d_real[0]), width * height * sizeof(T));\n  hipMalloc((void**)(&d_real[1]), width * height * sizeof(T));\n  hipMalloc((void**)(&d_imag[0]), width * height * sizeof(T));\n  hipMalloc((void**)(&d_imag[1]), width * height * sizeof(T));\n  hipMemcpy(d_real[0], p_real, width * height * sizeof(T), hipMemcpyHostToDevice);\n  hipMemcpy(d_imag[0], p_imag, width * height * sizeof(T), hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(kernel<T, STEPS, BLOCK_X, BLOCK_Y, MARGIN_X, MARGIN_Y, STRIDE_Y>), grids, blocks, 0, 0, a, b, width, height,\n           d_real[sense], d_imag[sense], d_real[1-sense], d_imag[1-sense]);\n    sense = 1 - sense; \n\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  hipMemcpy(p_real, d_real[sense], width * height * sizeof(T), hipMemcpyDeviceToHost);\n  hipMemcpy(p_imag, d_imag[sense], width * height * sizeof(T), hipMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(p_real[i] - h_real[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n    if (fabs(p_imag[i] - h_imag[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] p_real;\n  delete[] p_imag;\n  delete[] h_real;\n  delete[] h_imag;\n  hipFree(d_real[0]);\n  hipFree(d_real[1]);\n  hipFree(d_imag[0]);\n  hipFree(d_imag[1]);\n}\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <matrix width> <matrix height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int width = atoi(argv[1]);   \n\n  int height = atoi(argv[2]);  \n\n  int repeat = atoi(argv[3]);  \n\n\n  printf(\"TSA in float32\\n\");\n  tsa<float>(width, height, repeat);\n\n  printf(\"\\n\");\n\n  printf(\"TSA in float64\\n\");\n  tsa<double>(width, height, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "tsa", "parallel_api": "omp", "code": {"main.cpp": "#include <complex>\n#include <cmath>\n#include <cstdio>\n#include <cstring>\n#include <chrono>\n#include <omp.h>\n#include \"kernels.h\"\n#include \"reference.h\"\n\ntemplate <typename T>\nstatic void init_p(T *p_real, T *p_imag, int width, int height) {\n  double s = 64.0;\n  for (int j = 1; j <= height; j++) {\n    for (int i = 1; i <= width; i++) {\n      \n\n      std::complex<T> tmp = std::complex<T>(\n        exp(-(pow(i - 180.0, 2.0) + pow(j - 300.0, 2.0)) / (2.0 * pow(s, 2.0))), 0.0) *\n        exp(std::complex<T>(0.0, 0.4 * (i + j - 480.0)));\n\n      p_real[(j-1) * width + i-1] = real(tmp);\n      p_imag[(j-1) * width + i-1] = imag(tmp);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid tsa(int width, int height, int repeat) {\n\n  T * p_real = new T[width * height];\n  T * p_imag = new T[width * height];\n  T * h_real = new T[width * height];\n  T * h_imag = new T[width * height];\n\n  \n\n  init_p(p_real, p_imag, width, height);\n\n  \n\n  T a = cos(0.02);\n  T b = sin(0.02);\n\n  \n\n  memcpy(h_imag, p_imag, sizeof(T)*width*height);\n  memcpy(h_real, p_real, sizeof(T)*width*height);\n  reference(h_real, h_imag, a, b, width, height, repeat);\n\n  \n\n  static const int BLOCK_X = 16;\n  \n\n  static const int BLOCK_Y = sizeof(T) == 8 ? 32 : 96;\n  \n\n  static const int STRIDE_Y = 16;\n\n  \n\n  static const int MARGIN_X = 3;\n  static const int MARGIN_Y = 4;\n\n  \n\n  static const int STEPS = 1;\n\n  const int teamX = (width + (BLOCK_X - 2 * STEPS * MARGIN_X) - 1) / (BLOCK_X - 2 * STEPS * MARGIN_X);\n  const int teamY = (height + (BLOCK_Y - 2 * STEPS * MARGIN_Y) - 1) / (BLOCK_Y - 2 * STEPS * MARGIN_Y);\n  int sense = 0;\n\n  \n\n  T *d_real[2];\n  T *d_imag[2];\n\n  d_real[0] = p_real;\n  d_real[1] = new T[width * height];\n  d_imag[0] = p_imag;\n  d_imag[1] = new T[width * height]; \n\n  #pragma omp target data map (to: d_real[0][0:width*height], d_imag[0][0:width*height]) \\\n                          map(alloc: d_real[1][0:width*height], d_imag[1][0:width*height])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      kernel<T, STEPS, BLOCK_X, BLOCK_Y, MARGIN_X, MARGIN_Y, STRIDE_Y>\n          (teamX, teamY, a, b, width, height,\n           d_real[sense], d_imag[sense], d_real[1-sense], d_imag[1-sense]);\n      sense = 1 - sense; \n\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n    #pragma omp target update from (d_real[sense][0:width*height])\n    #pragma omp target update from (d_imag[sense][0:width*height])\n  }\n\n  \n\n  bool ok = true;\n  T *t_real = d_real[sense];\n  T *t_imag = d_imag[sense];\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(t_real[i] - h_real[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n    if (fabs(t_imag[i] - h_imag[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] d_real[0];\n  delete[] d_imag[0];\n  delete[] d_real[1];\n  delete[] d_imag[1];\n  delete[] h_real;\n  delete[] h_imag;\n}\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <matrix width> <matrix height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int width = atoi(argv[1]);   \n\n  int height = atoi(argv[2]);  \n\n  int repeat = atoi(argv[3]);  \n\n\n  printf(\"TSA in float32\\n\");\n  tsa<float>(width, height, repeat);\n\n  printf(\"\\n\");\n\n  printf(\"TSA in float64\\n\");\n  tsa<double>(width, height, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "tsa", "parallel_api": "serial", "code": {"main.cpp": "#include <complex>\n#include <cmath>\n#include <cstdio>\n#include <cstring>\n#include <chrono>\n#include \"kernels.h\"\n#include \"reference.h\"\n\ntemplate <typename T>\nstatic void init_p(T *p_real, T *p_imag, int width, int height) {\n  double s = 64.0;\n  for (int j = 1; j <= height; j++) {\n    for (int i = 1; i <= width; i++) {\n      \n\n      std::complex<T> tmp = std::complex<T>(\n        exp(-(pow(i - 180.0, 2.0) + pow(j - 300.0, 2.0)) / (2.0 * pow(s, 2.0))), 0.0) *\n        exp(std::complex<T>(0.0, 0.4 * (i + j - 480.0)));\n\n      p_real[(j-1) * width + i-1] = real(tmp);\n      p_imag[(j-1) * width + i-1] = imag(tmp);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid tsa(int width, int height, int repeat) {\n\n  T * p_real = new T[width * height];\n  T * p_imag = new T[width * height];\n  T * h_real = new T[width * height];\n  T * h_imag = new T[width * height];\n\n  \n\n  init_p(p_real, p_imag, width, height);\n\n  \n\n  T a = cos(0.02);\n  T b = sin(0.02);\n\n  \n\n  memcpy(h_imag, p_imag, sizeof(T)*width*height);\n  memcpy(h_real, p_real, sizeof(T)*width*height);\n  reference(h_real, h_imag, a, b, width, height, repeat);\n\n  \n\n  static const int BLOCK_X = 16;\n  \n\n  static const int BLOCK_Y = sizeof(T) == 8 ? 32 : 96;\n  \n\n  static const int STRIDE_Y = 16;\n\n  \n\n  static const int MARGIN_X = 3;\n  static const int MARGIN_Y = 4;\n\n  \n\n  static const int STEPS = 1;\n\n  const int teamX = (width + (BLOCK_X - 2 * STEPS * MARGIN_X) - 1) / (BLOCK_X - 2 * STEPS * MARGIN_X);\n  const int teamY = (height + (BLOCK_Y - 2 * STEPS * MARGIN_Y) - 1) / (BLOCK_Y - 2 * STEPS * MARGIN_Y);\n  int sense = 0;\n\n  \n\n  T *d_real[2];\n  T *d_imag[2];\n\n  d_real[0] = p_real;\n  d_real[1] = new T[width * height];\n  d_imag[0] = p_imag;\n  d_imag[1] = new T[width * height]; \n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      kernel<T, STEPS, BLOCK_X, BLOCK_Y, MARGIN_X, MARGIN_Y, STRIDE_Y>\n          (teamX, teamY, a, b, width, height,\n           d_real[sense], d_imag[sense], d_real[1-sense], d_imag[1-sense]);\n      sense = 1 - sense; \n\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n          }\n\n  \n\n  bool ok = true;\n  T *t_real = d_real[sense];\n  T *t_imag = d_imag[sense];\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(t_real[i] - h_real[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n    if (fabs(t_imag[i] - h_imag[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] d_real[0];\n  delete[] d_imag[0];\n  delete[] d_real[1];\n  delete[] d_imag[1];\n  delete[] h_real;\n  delete[] h_imag;\n}\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <matrix width> <matrix height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int width = atoi(argv[1]);   \n\n  int height = atoi(argv[2]);  \n\n  int repeat = atoi(argv[3]);  \n\n\n  printf(\"TSA in float32\\n\");\n  tsa<float>(width, height, repeat);\n\n  printf(\"\\n\");\n\n  printf(\"TSA in float64\\n\");\n  tsa<double>(width, height, repeat);\n  return 0;\n}"}}
{"kernel_name": "tsa", "parallel_api": "sycl", "code": {"main.cpp": "#include <complex>\n#include <cmath>\n#include <cstdio>\n#include <cstring>\n#include <chrono>\n#include <vector>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n#include \"reference.h\"\n\n\n\ntemplate<typename T, int STEPS, int BLOCK_X, int BLOCK_Y, int MARGIN_X, int MARGIN_Y, int STRIDE_Y>\nclass k;\n\ntemplate <typename T>\nvoid init_p(T *p_real, T *p_imag, int width, int height) {\n  double s = 64.0;\n  for (int j = 1; j <= height; j++) {\n    for (int i = 1; i <= width; i++) {\n      \n\n      std::complex<T> tmp = std::complex<T>(\n        exp(-(pow(i - 180.0, 2.0) + pow(j - 300.0, 2.0)) / (2.0 * pow(s, 2.0))), 0.0) *\n        exp(std::complex<T>(0.0, 0.4 * (i + j - 480.0)));\n\n      p_real[(j-1) * width + i-1] = real(tmp);\n      p_imag[(j-1) * width + i-1] = imag(tmp);\n    }\n  }\n}\n\ntemplate <typename T>\nvoid tsa(sycl::queue &q, int width, int height, int repeat) {\n\n  T * p_real = new T[width * height];\n  T * p_imag = new T[width * height];\n  T * h_real = new T[width * height];\n  T * h_imag = new T[width * height];\n\n  \n\n  init_p(p_real, p_imag, width, height);\n\n  \n\n  T a = cos(0.02);\n  T b = sin(0.02);\n\n  \n\n  memcpy(h_imag, p_imag, sizeof(T)*width*height);\n  memcpy(h_real, p_real, sizeof(T)*width*height);\n  reference(h_real, h_imag, a, b, width, height, repeat);\n\n  \n\n  const int BLOCK_X = 16;\n  \n\n  const int BLOCK_Y = sizeof(T) == 8 ? 32 : 96;\n  \n\n  const int STRIDE_Y = 16;\n\n  \n\n  const int MARGIN_X = 3;\n  const int MARGIN_Y = 4;\n\n  \n\n  const int STEPS = 1;\n\n  sycl::range<2> gws ((height + (BLOCK_Y - 2 * STEPS * MARGIN_Y) - 1) /\n                      (BLOCK_Y - 2 * STEPS * MARGIN_Y) * STRIDE_Y,\n                      (width + (BLOCK_X - 2 * STEPS * MARGIN_X) - 1) /\n                      (BLOCK_X - 2 * STEPS * MARGIN_X)  * BLOCK_X);\n\n  sycl::range<2> lws (STRIDE_Y, BLOCK_X);\n\n  int sense = 0;\n\n  T *d_real[2];\n  T *d_imag[2];\n\n  \n\n  d_real[0] = sycl::malloc_device<T>(width * height, q);\n  d_real[1] = sycl::malloc_device<T>(width * height, q);\n  d_imag[0] = sycl::malloc_device<T>(width * height, q);\n  d_imag[1] = sycl::malloc_device<T>(width * height, q);\n  q.memcpy(d_real[0], p_real, width * height * sizeof(T));\n  q.memcpy(d_imag[0], p_imag, width * height * sizeof(T));\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class k<T, STEPS, BLOCK_X, BLOCK_Y, MARGIN_X, MARGIN_Y, STRIDE_Y>>(\n        sycl::nd_range<2>(gws, lws), [=] (sycl::nd_item<2> item) {\n        tsa_kernel<T, STEPS, BLOCK_X, BLOCK_Y, MARGIN_X, MARGIN_Y, STRIDE_Y>\n          (item, a, b, width, height,\n           d_real[sense], d_imag[sense], d_real[1-sense], d_imag[1-sense]);\n      });\n    });\n    sense = 1 - sense; \n\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  q.memcpy(p_real, d_real[sense], width * height * sizeof(T));\n  q.memcpy(p_imag, d_imag[sense], width * height * sizeof(T));\n\n  q.wait();\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < width * height; i++) {\n    if (fabs(p_real[i] - h_real[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n    if (fabs(p_imag[i] - h_imag[i]) > 1e-3) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  delete[] p_real;\n  delete[] p_imag;\n  delete[] h_real;\n  delete[] h_imag;\n  sycl::free(d_real[0], q);\n  sycl::free(d_real[1], q);\n  sycl::free(d_imag[0], q);\n  sycl::free(d_imag[1], q);\n}\n\nint main(int argc, char** argv) {\n  if (argc != 4) {\n    printf(\"Usage: %s <matrix width> <matrix height> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  int width = atoi(argv[1]);   \n\n  int height = atoi(argv[2]);  \n\n  int repeat = atoi(argv[3]);  \n\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  printf(\"TSA in float32\\n\");\n  tsa<float>(q, width, height, repeat);\n\n  printf(\"\\n\");\n\n  printf(\"TSA in float64\\n\");\n  tsa<double>(q, width, height, repeat);\n  return 0;\n}\n"}}
{"kernel_name": "zeropoint", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <cuda.h>\n#include \"reference.h\"\n\n__global__ void zero_point (\n    const float* x_min,\n    const float* x_max,\n    int32_t qmin,\n    int32_t qmax,\n    int size,\n    bool preserve_sparsity,\n    float* scale,\n    int32_t* zero_point)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < size) {\n    float min_val = x_min[i];\n    float max_val = x_max[i];\n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      int symmetric_qmin = -((qmax - qmin) / 2 + 1);\n      int symmetric_qmax = (qmax - qmin) / 2;\n      double max_scale = fmax(\n          fabs(min_val / symmetric_qmin), fabs(max_val / symmetric_qmax));\n      min_val = max_scale * symmetric_qmin;\n      max_val = max_scale * symmetric_qmax;\n    }\n\n    \n\n    \n\n    \n\n    min_val = fminf(min_val, 0.f);\n    max_val = fmaxf(max_val, 0.f);\n    scale[i] = (static_cast<double>(max_val) - min_val) / (qmax - qmin);\n\n    \n\n    \n\n    if (scale[i] == 0.0f || isinf(1.0f / scale[i])) {\n      scale[i] = 0.1;\n    }\n\n    double zero_point_from_min = qmin - min_val / static_cast<double>(scale[i]);\n    double zero_point_from_max = qmax - max_val / static_cast<double>(scale[i]);\n    double zero_point_from_min_error = abs(qmin) + abs(min_val / static_cast<double>(scale[i]));\n    double zero_point_from_max_error = abs(qmax) + abs(max_val / static_cast<double>(scale[i]));\n    double initial_zero_point = zero_point_from_min_error < zero_point_from_max_error\n                                ? zero_point_from_min\n                                : zero_point_from_max;\n\n    \n\n    \n\n    \n\n    \n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      initial_zero_point = static_cast<double>(qmin + qmax) / 2;\n    }\n    \n\n    \n\n    \n\n    \n\n    \n\n    int32_t nudged_zero_point = 0;\n    if (initial_zero_point < qmin) {\n      nudged_zero_point = qmin;\n    } else if (initial_zero_point > qmax) {\n      nudged_zero_point = qmax;\n    } else {\n      nudged_zero_point = nearbyint(initial_zero_point);\n    }\n    zero_point[i] = nudged_zero_point;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of min/max values> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int32_t qmin = -127;\n  int32_t qmax =  127;\n  bool preserve_sparsity = true;\n\n  size_t size_bytes = sizeof(float) * size;\n\n  float *scale = (float*) malloc (size_bytes);\n  float *scale_ref = (float*) malloc (size_bytes);\n  int32_t *zp = (int32_t*) malloc (size_bytes);\n  int32_t *zp_ref = (int32_t*) malloc (size_bytes);\n  float *min = (float*) malloc (size_bytes);\n  float *max = (float*) malloc (size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-1.f, 1.f);\n  for (int i = 0; i < size; i++) {\n    min[i] = distr(g);\n    max[i] = distr(g);\n  }\n  \n  reference (min,\n             max,\n             qmin,\n             qmax,\n             size,\n             preserve_sparsity,\n             scale_ref,\n             zp_ref);\n\n  int32_t *d_zp;\n  cudaMalloc((void**)&d_zp, size_bytes);\n\n  float *d_scale;\n  cudaMalloc((void**)&d_scale, size_bytes);\n\n  float *d_min;\n  cudaMalloc((void**)&d_min, size_bytes);\n  cudaMemcpy(d_min, min, size_bytes, cudaMemcpyHostToDevice);\n\n  float *d_max;\n  cudaMalloc((void**)&d_max, size_bytes);\n  cudaMemcpy(d_max, max, size_bytes, cudaMemcpyHostToDevice);\n\n  const int block_size = 256;\n  dim3 num_blocks = (size + block_size - 1) / block_size;\n  dim3 num_threads(block_size);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    zero_point<<<num_blocks, num_threads>>>(\n        d_min,\n        d_max,\n        qmin,\n        qmax,\n        size,\n        preserve_sparsity,\n        d_scale,\n        d_zp);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of zero-point kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  cudaMemcpy(zp, d_zp, size_bytes, cudaMemcpyDeviceToHost);\n  cudaMemcpy(scale, d_scale, size_bytes, cudaMemcpyDeviceToHost);\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (zp[i] != zp_ref[i] || scale[i] - scale_ref[i] > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  cudaFree(d_zp);\n  cudaFree(d_scale);\n  cudaFree(d_min);\n  cudaFree(d_max);\n\n  free(zp);\n  free(scale);\n  free(zp_ref);\n  free(scale_ref);\n  free(min);\n  free(max);\n\n  return 0;\n}\n"}}
{"kernel_name": "zeropoint", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n__global__ void zero_point (\n    const float* x_min,\n    const float* x_max,\n    int32_t qmin,\n    int32_t qmax,\n    int size,\n    bool preserve_sparsity,\n    float* scale,\n    int32_t* zero_point)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < size) {\n    float min_val = x_min[i];\n    float max_val = x_max[i];\n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      int symmetric_qmin = -((qmax - qmin) / 2 + 1);\n      int symmetric_qmax = (qmax - qmin) / 2;\n      double max_scale = fmax(\n          fabs(min_val / symmetric_qmin), fabs(max_val / symmetric_qmax));\n      min_val = max_scale * symmetric_qmin;\n      max_val = max_scale * symmetric_qmax;\n    }\n\n    \n\n    \n\n    \n\n    min_val = fminf(min_val, 0.f);\n    max_val = fmaxf(max_val, 0.f);\n    scale[i] = (static_cast<double>(max_val) - min_val) / (qmax - qmin);\n\n    \n\n    \n\n    if (scale[i] == 0.0f || isinf(1.0f / scale[i])) {\n      scale[i] = 0.1;\n    }\n\n    double zero_point_from_min = qmin - min_val / static_cast<double>(scale[i]);\n    double zero_point_from_max = qmax - max_val / static_cast<double>(scale[i]);\n    double zero_point_from_min_error = abs(qmin) + abs(min_val / static_cast<double>(scale[i]));\n    double zero_point_from_max_error = abs(qmax) + abs(max_val / static_cast<double>(scale[i]));\n    double initial_zero_point = zero_point_from_min_error < zero_point_from_max_error\n                                ? zero_point_from_min\n                                : zero_point_from_max;\n\n    \n\n    \n\n    \n\n    \n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      initial_zero_point = static_cast<double>(qmin + qmax) / 2;\n    }\n    \n\n    \n\n    \n\n    \n\n    \n\n    int32_t nudged_zero_point = 0;\n    if (initial_zero_point < qmin) {\n      nudged_zero_point = qmin;\n    } else if (initial_zero_point > qmax) {\n      nudged_zero_point = qmax;\n    } else {\n      nudged_zero_point = nearbyint(initial_zero_point);\n    }\n    zero_point[i] = nudged_zero_point;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of min/max values> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int32_t qmin = -127;\n  int32_t qmax =  127;\n  bool preserve_sparsity = true;\n\n  size_t size_bytes = sizeof(float) * size;\n\n  float *scale = (float*) malloc (size_bytes);\n  float *scale_ref = (float*) malloc (size_bytes);\n  int32_t *zp = (int32_t*) malloc (size_bytes);\n  int32_t *zp_ref = (int32_t*) malloc (size_bytes);\n  float *min = (float*) malloc (size_bytes);\n  float *max = (float*) malloc (size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-1.f, 1.f);\n  for (int i = 0; i < size; i++) {\n    min[i] = distr(g);\n    max[i] = distr(g);\n  }\n  \n  reference (min,\n             max,\n             qmin,\n             qmax,\n             size,\n             preserve_sparsity,\n             scale_ref,\n             zp_ref);\n\n  int32_t *d_zp;\n  hipMalloc((void**)&d_zp, size_bytes);\n\n  float *d_scale;\n  hipMalloc((void**)&d_scale, size_bytes);\n\n  float *d_min;\n  hipMalloc((void**)&d_min, size_bytes);\n  hipMemcpy(d_min, min, size_bytes, hipMemcpyHostToDevice);\n\n  float *d_max;\n  hipMalloc((void**)&d_max, size_bytes);\n  hipMemcpy(d_max, max, size_bytes, hipMemcpyHostToDevice);\n\n  const int block_size = 256;\n  dim3 num_blocks = (size + block_size - 1) / block_size;\n  dim3 num_threads(block_size);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    zero_point<<<num_blocks, num_threads>>>(\n        d_min,\n        d_max,\n        qmin,\n        qmax,\n        size,\n        preserve_sparsity,\n        d_scale,\n        d_zp);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of zero-point kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  hipMemcpy(zp, d_zp, size_bytes, hipMemcpyDeviceToHost);\n  hipMemcpy(scale, d_scale, size_bytes, hipMemcpyDeviceToHost);\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (zp[i] != zp_ref[i] || scale[i] - scale_ref[i] > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  hipFree(d_zp);\n  hipFree(d_scale);\n  hipFree(d_min);\n  hipFree(d_max);\n\n  free(zp);\n  free(scale);\n  free(zp_ref);\n  free(scale_ref);\n  free(min);\n  free(max);\n\n  return 0;\n}\n"}}
{"kernel_name": "zeropoint", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <omp.h>\n#include \"reference.h\"\n\nvoid zero_point (\n    const float* x_min,\n    const float* x_max,\n    int32_t qmin,\n    int32_t qmax,\n    int size,\n    bool preserve_sparsity,\n    float* scale,\n    int32_t* zero_point)\n{\n  #pragma omp target teams distribute parallel for num_threads(256)\n  for (int i = 0; i < size; i++) {\n    float min_val = x_min[i];\n    float max_val = x_max[i];\n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      int symmetric_qmin = -((qmax - qmin) / 2 + 1);\n      int symmetric_qmax = (qmax - qmin) / 2;\n      double max_scale = fmax(\n          fabs(min_val / symmetric_qmin), fabs(max_val / symmetric_qmax));\n      min_val = max_scale * symmetric_qmin;\n      max_val = max_scale * symmetric_qmax;\n    }\n\n    \n\n    \n\n    \n\n    min_val = fminf(min_val, 0.f);\n    max_val = fmaxf(max_val, 0.f);\n    scale[i] = (static_cast<double>(max_val) - min_val) / (qmax - qmin);\n\n    \n\n    \n\n    if (scale[i] == 0.0f || isinf(1.0f / scale[i])) {\n      scale[i] = 0.1;\n    }\n\n    double zero_point_from_min = qmin - min_val / static_cast<double>(scale[i]);\n    double zero_point_from_max = qmax - max_val / static_cast<double>(scale[i]);\n    double zero_point_from_min_error = abs(qmin) + abs(min_val / static_cast<double>(scale[i]));\n    double zero_point_from_max_error = abs(qmax) + abs(max_val / static_cast<double>(scale[i]));\n    double initial_zero_point = zero_point_from_min_error < zero_point_from_max_error\n                                ? zero_point_from_min\n                                : zero_point_from_max;\n\n    \n\n    \n\n    \n\n    \n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      initial_zero_point = static_cast<double>(qmin + qmax) / 2;\n    }\n    \n\n    \n\n    \n\n    \n\n    \n\n    int32_t nudged_zero_point = 0;\n    if (initial_zero_point < qmin) {\n      nudged_zero_point = qmin;\n    } else if (initial_zero_point > qmax) {\n      nudged_zero_point = qmax;\n    } else {\n      nudged_zero_point = nearbyint(initial_zero_point);\n    }\n    zero_point[i] = nudged_zero_point;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of min/max values> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int32_t qmin = -127;\n  int32_t qmax =  127;\n  bool preserve_sparsity = true;\n\n  size_t size_bytes = sizeof(float) * size;\n\n  float *scale = (float*) malloc (size_bytes);\n  float *scale_ref = (float*) malloc (size_bytes);\n  int32_t *zp = (int32_t*) malloc (size_bytes);\n  int32_t *zp_ref = (int32_t*) malloc (size_bytes);\n  float *min = (float*) malloc (size_bytes);\n  float *max = (float*) malloc (size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-1.f, 1.f);\n  for (int i = 0; i < size; i++) {\n    min[i] = distr(g);\n    max[i] = distr(g);\n  }\n  \n  reference (min,\n             max,\n             qmin,\n             qmax,\n             size,\n             preserve_sparsity,\n             scale_ref,\n             zp_ref);\n\n  #pragma omp target data map(to: min[0:size], max[0:size]) \\\n                          map(from: scale[0:size], zp[0:size])\n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      zero_point(\n          min,\n          max,\n          qmin,\n          qmax,\n          size,\n          preserve_sparsity,\n          scale,\n          zp);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of zero-point kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (zp[i] != zp_ref[i] || scale[i] - scale_ref[i] > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(zp);\n  free(scale);\n  free(zp_ref);\n  free(scale_ref);\n  free(min);\n  free(max);\n\n  return 0;\n}\n"}}
{"kernel_name": "zeropoint", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include \"reference.h\"\n\nvoid zero_point (\n    const float* x_min,\n    const float* x_max,\n    int32_t qmin,\n    int32_t qmax,\n    int size,\n    bool preserve_sparsity,\n    float* scale,\n    int32_t* zero_point)\n{\n    for (int i = 0; i < size; i++) {\n    float min_val = x_min[i];\n    float max_val = x_max[i];\n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      int symmetric_qmin = -((qmax - qmin) / 2 + 1);\n      int symmetric_qmax = (qmax - qmin) / 2;\n      double max_scale = fmax(\n          fabs(min_val / symmetric_qmin), fabs(max_val / symmetric_qmax));\n      min_val = max_scale * symmetric_qmin;\n      max_val = max_scale * symmetric_qmax;\n    }\n\n    \n\n    \n\n    \n\n    min_val = fminf(min_val, 0.f);\n    max_val = fmaxf(max_val, 0.f);\n    scale[i] = (static_cast<double>(max_val) - min_val) / (qmax - qmin);\n\n    \n\n    \n\n    if (scale[i] == 0.0f || isinf(1.0f / scale[i])) {\n      scale[i] = 0.1;\n    }\n\n    double zero_point_from_min = qmin - min_val / static_cast<double>(scale[i]);\n    double zero_point_from_max = qmax - max_val / static_cast<double>(scale[i]);\n    double zero_point_from_min_error = abs(qmin) + abs(min_val / static_cast<double>(scale[i]));\n    double zero_point_from_max_error = abs(qmax) + abs(max_val / static_cast<double>(scale[i]));\n    double initial_zero_point = zero_point_from_min_error < zero_point_from_max_error\n                                ? zero_point_from_min\n                                : zero_point_from_max;\n\n    \n\n    \n\n    \n\n    \n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      initial_zero_point = static_cast<double>(qmin + qmax) / 2;\n    }\n    \n\n    \n\n    \n\n    \n\n    \n\n    int32_t nudged_zero_point = 0;\n    if (initial_zero_point < qmin) {\n      nudged_zero_point = qmin;\n    } else if (initial_zero_point > qmax) {\n      nudged_zero_point = qmax;\n    } else {\n      nudged_zero_point = nearbyint(initial_zero_point);\n    }\n    zero_point[i] = nudged_zero_point;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of min/max values> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int32_t qmin = -127;\n  int32_t qmax =  127;\n  bool preserve_sparsity = true;\n\n  size_t size_bytes = sizeof(float) * size;\n\n  float *scale = (float*) malloc (size_bytes);\n  float *scale_ref = (float*) malloc (size_bytes);\n  int32_t *zp = (int32_t*) malloc (size_bytes);\n  int32_t *zp_ref = (int32_t*) malloc (size_bytes);\n  float *min = (float*) malloc (size_bytes);\n  float *max = (float*) malloc (size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-1.f, 1.f);\n  for (int i = 0; i < size; i++) {\n    min[i] = distr(g);\n    max[i] = distr(g);\n  }\n  \n  reference (min,\n             max,\n             qmin,\n             qmax,\n             size,\n             preserve_sparsity,\n             scale_ref,\n             zp_ref);\n\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      zero_point(\n          min,\n          max,\n          qmin,\n          qmax,\n          size,\n          preserve_sparsity,\n          scale,\n          zp);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average execution time of zero-point kernel: %f (us)\\n\",\n           (time * 1e-3f) / repeat);\n  }\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (zp[i] != zp_ref[i] || scale[i] - scale_ref[i] > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(zp);\n  free(scale);\n  free(zp_ref);\n  free(scale_ref);\n  free(min);\n  free(max);\n\n  return 0;\n}"}}
{"kernel_name": "zeropoint", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <algorithm>\n#include <chrono>\n#include <random>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nvoid zero_point (\n    sycl::nd_item<1> &item,\n    const float* x_min,\n    const float* x_max,\n    int32_t qmin,\n    int32_t qmax,\n    int size,\n    bool preserve_sparsity,\n    float* scale,\n    int32_t* zero_point)\n{\n  int i = item.get_global_id(0);\n  if (i < size) {\n    float min_val = x_min[i];\n    float max_val = x_max[i];\n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      int symmetric_qmin = -((qmax - qmin) / 2 + 1);\n      int symmetric_qmax = (qmax - qmin) / 2;\n      double max_scale = sycl::fmax(\n          sycl::fabs(min_val / symmetric_qmin), sycl::fabs(max_val / symmetric_qmax));\n      min_val = max_scale * symmetric_qmin;\n      max_val = max_scale * symmetric_qmax;\n    }\n\n    \n\n    \n\n    \n\n    min_val = sycl::fmin(min_val, 0.f);\n    max_val = sycl::fmax(max_val, 0.f);\n    scale[i] = (static_cast<double>(max_val) - min_val) / (qmax - qmin);\n\n    \n\n    \n\n    if (scale[i] == 0.0f || sycl::isinf(1.0f / scale[i])) {\n      scale[i] = 0.1;\n    }\n\n    double zero_point_from_min = qmin - min_val / static_cast<double>(scale[i]);\n    double zero_point_from_max = qmax - max_val / static_cast<double>(scale[i]);\n    double zero_point_from_min_error = sycl::abs(qmin) + sycl::abs(min_val / static_cast<double>(scale[i]));\n    double zero_point_from_max_error = sycl::abs(qmax) + sycl::abs(max_val / static_cast<double>(scale[i]));\n    double initial_zero_point = zero_point_from_min_error < zero_point_from_max_error\n                                ? zero_point_from_min\n                                : zero_point_from_max;\n\n    \n\n    \n\n    \n\n    \n\n    if (min_val < 0 && max_val > 0 && preserve_sparsity) {\n      initial_zero_point = static_cast<double>(qmin + qmax) / 2;\n    }\n    \n\n    \n\n    \n\n    \n\n    \n\n    int32_t nudged_zero_point = 0;\n    if (initial_zero_point < qmin) {\n      nudged_zero_point = qmin;\n    } else if (initial_zero_point > qmax) {\n      nudged_zero_point = qmax;\n    } else {\n      nudged_zero_point = nearbyint(initial_zero_point);\n    }\n    zero_point[i] = nudged_zero_point;\n  }\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <number of min/max values> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int size = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  int32_t qmin = -127;\n  int32_t qmax =  127;\n  bool preserve_sparsity = true;\n\n  size_t size_bytes = sizeof(float) * size;\n\n  float *scale = (float*) malloc (size_bytes);\n  float *scale_ref = (float*) malloc (size_bytes);\n  int32_t *zp = (int32_t*) malloc (size_bytes);\n  int32_t *zp_ref = (int32_t*) malloc (size_bytes);\n  float *min = (float*) malloc (size_bytes);\n  float *max = (float*) malloc (size_bytes);\n\n  std::default_random_engine g (123);\n  std::uniform_real_distribution<float> distr (-1.f, 1.f);\n  for (int i = 0; i < size; i++) {\n    min[i] = distr(g);\n    max[i] = distr(g);\n  }\n\n  reference (min,\n             max,\n             qmin,\n             qmax,\n             size,\n             preserve_sparsity,\n             scale_ref,\n             zp_ref);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int32_t *d_zp = sycl::malloc_device<int32_t>(size, q);\n  float *d_scale = sycl::malloc_device<float>(size, q);\n\n  float *d_min = sycl::malloc_device<float>(size, q);\n  q.memcpy(d_min, min, size_bytes);\n\n  float *d_max = sycl::malloc_device<float>(size, q);\n  q.memcpy(d_max, max, size_bytes);\n\n  const int block_size = 256;\n  sycl::range<1> gws ((size + block_size - 1) / block_size * block_size);\n  sycl::range<1> lws (block_size);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class zp>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        zero_point(\n            item,\n            d_min,\n            d_max,\n            qmin,\n            qmax,\n            size,\n            preserve_sparsity,\n            d_scale,\n            d_zp);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of zero-point kernel: %f (us)\\n\",\n         (time * 1e-3f) / repeat);\n\n  q.memcpy(zp, d_zp, size_bytes);\n  q.memcpy(scale, d_scale, size_bytes);\n  q.wait();\n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (zp[i] != zp_ref[i] || scale[i] - scale_ref[i] > 1e-3f) {\n      ok = false;\n      break;\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  sycl::free(d_zp, q);\n  sycl::free(d_scale, q);\n  sycl::free(d_min, q);\n  sycl::free(d_max, q);\n\n  free(zp);\n  free(scale);\n  free(zp_ref);\n  free(scale_ref);\n  free(min);\n  free(max);\n\n  return 0;\n}\n"}}
