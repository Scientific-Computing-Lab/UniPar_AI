{"kernel_name": "aligned-types", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n\n\n\n\n\n\n\ntypedef unsigned char uchar_misaligned;\n\ntypedef unsigned short int ushort_misaligned;\n\ntypedef struct\n{\n  unsigned char r, g, b, a;\n} uchar4_misaligned;\n\ntypedef struct\n{\n  unsigned int l, a;\n} uint2_misaligned;\n\ntypedef struct\n{\n  unsigned int r, g, b;\n} uint3_misaligned;\n\ntypedef struct\n{\n  unsigned int r, g, b, a;\n} uint4_misaligned;\n\ntypedef struct\n{\n  uint4_misaligned c1, c2;\n}\nuint8_misaligned;\n\n\n\n\n\n\n\n\ntypedef struct __align__(4)\n{\n  unsigned char r, g, b, a;\n}\nuchar4_aligned;\n\ntypedef unsigned int uint_aligned;\n\ntypedef struct __align__(8)\n{\n  unsigned int l, a;\n}\nuint2_aligned;\n\ntypedef struct __align__(16)\n{\n  unsigned int r, g, b;\n}\nuint3_aligned;\n\ntypedef struct __align__(16)\n{\n  unsigned int r, g, b, a;\n}\nuint4_aligned;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntypedef struct __align__(16)\n{\n  uint4_aligned c1, c2;\n}\nuint8_aligned;\n\n\n\n\n\n\n\n\n\n\n\nint iDivUp(int a, int b)\n{\n  return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n\n\nint iDivDown(int a, int b)\n{\n  return a / b;\n}\n\n\n\nint iAlignUp(int a, int b)\n{\n  return (a % b != 0) ? (a - a % b + b) : a;\n}\n\n\n\nint iAlignDown(int a, int b)\n{\n  return a - a % b;\n}\n\n\n\n\n\n\n\n\n\n\n\ntemplate<class TData> __global__ void testKernel(\n          TData *__restrict d_odata,\n    const TData *__restrict d_idata,\n    int numElements\n    )\n{\n  const int pos = blockDim.x * blockIdx.x + threadIdx.x;\n  if (pos < numElements)\n  {\n    d_odata[pos] = d_idata[pos];\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate<class TData> int testCPU(\n    TData *h_odata,\n    TData *h_idata,\n    int numElements,\n    int packedElementSize\n    )\n{\n  for (int pos = 0; pos < numElements; pos++)\n  {\n    TData src = h_idata[pos];\n    TData dst = h_odata[pos];\n\n    for (int i = 0; i < packedElementSize; i++)\n      if (((char *)&src)[i] != ((char *)&dst)[i])\n      {\n        return 0;\n      }\n  }\n  return 1;\n}\n\n\n\n\n\n\n\n\n\n\n\nconst int       MEM_SIZE = 50000000;\nconst int NUM_ITERATIONS = 1000;\n\n\n\nunsigned char *h_idataCPU, *h_odataGPU;\n\n\n\ntemplate<class TData> int runTest(\n  unsigned char *d_idata,\n  unsigned char *d_odata,\n  int packedElementSize,\n  int memory_size)\n{\n  const int totalMemSizeAligned = iAlignDown(memory_size, sizeof(TData));\n  const int         numElements = iDivDown(memory_size, sizeof(TData));\n\n  \n\n  cudaMemset(d_odata, 0, memory_size);\n  \n\n  cudaDeviceSynchronize();\n\n  auto start = std::chrono::high_resolution_clock::now();\n  dim3 grid ((numElements + 255)/256);\n  dim3 block (256);\n  for (int i = 0; i < NUM_ITERATIONS; i++)\n  {\n    testKernel<TData><<<grid, block>>>(\n        (TData *)d_odata,\n        (TData *)d_idata,\n        numElements\n        );\n  }\n\n  cudaDeviceSynchronize();\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<double> elapsed_seconds = end - start;\n  double gpuTime = (double)elapsed_seconds.count() / NUM_ITERATIONS;\n\n  printf(\n      \"Avg. time: %f ms / Copy throughput: %f GB/s.\\n\", gpuTime * 1000,\n      (double)totalMemSizeAligned / (gpuTime * 1073741824.0)\n        );\n\n  \n\n  cudaMemcpy(h_odataGPU, d_odata, memory_size, cudaMemcpyDeviceToHost);\n  int flag = testCPU(\n      (TData *)h_odataGPU,\n      (TData *)h_idataCPU,\n      numElements,\n      packedElementSize\n      );\n\n  printf(flag ? \"\\tTEST OK\\n\" : \"\\tTEST FAILURE\\n\");\n\n  return !flag;\n}\n\nint main(int argc, char **argv)\n{\n  int i, nTotalFailures = 0;\n\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  printf(\"Allocating memory...\\n\");\n  int   MemorySize = (int)(MEM_SIZE) & 0xffffff00; \n\n  h_idataCPU = (unsigned char *)malloc(MemorySize);\n  h_odataGPU = (unsigned char *)malloc(MemorySize);\n\n  unsigned char *d_idata;\n  unsigned char *d_odata;\n  cudaMalloc((void **)&d_idata, MemorySize);\n  cudaMalloc((void **)&d_odata, MemorySize);\n\n  printf(\"Generating host input data array...\\n\");\n\n  for (i = 0; i < MemorySize; i++)\n  {\n    h_idataCPU[i] = (i & 0xFF) + 1;\n  }\n\n  printf(\"Uploading input data to GPU memory...\\n\");\n  cudaMemcpy(d_idata, h_idataCPU, MemorySize, cudaMemcpyHostToDevice);\n\n  printf(\"Testing misaligned types...\\n\");\n  printf(\"uchar_misaligned...\\n\");\n  nTotalFailures += runTest<uchar_misaligned>(d_idata, d_odata, 1, MemorySize);\n\n  printf(\"uchar4_misaligned...\\n\");\n  nTotalFailures += runTest<uchar4_misaligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uchar4_aligned...\\n\");\n  nTotalFailures += runTest<uchar4_aligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"ushort_misaligned...\\n\");\n  nTotalFailures += runTest<ushort_misaligned>(d_idata, d_odata, 2, MemorySize);\n\n  printf(\"uint_aligned...\\n\");\n  nTotalFailures += runTest<uint_aligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uint2_misaligned...\\n\");\n  nTotalFailures += runTest<uint2_misaligned>(d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint2_aligned...\\n\");\n  nTotalFailures += runTest<uint2_aligned>(d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint3_misaligned...\\n\");\n  nTotalFailures += runTest<uint3_misaligned>(d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint3_aligned...\\n\");\n  nTotalFailures += runTest<uint3_aligned>(d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint4_misaligned...\\n\");\n  nTotalFailures += runTest<uint4_misaligned>(d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint4_aligned...\\n\");\n  nTotalFailures += runTest<uint4_aligned>(d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint8_misaligned...\\n\");\n  nTotalFailures += runTest<uint8_misaligned>(d_idata, d_odata, 32, MemorySize);\n\n  printf(\"uint8_aligned...\\n\");\n  nTotalFailures += runTest<uint8_aligned>(d_idata, d_odata, 32, MemorySize);\n\n  printf(\"\\n[alignedTypes] -> Test Results: %d Failures\\n\", nTotalFailures);\n\n  printf(\"Shutting down...\\n\");\n  cudaFree(d_idata);\n  cudaFree(d_odata);\n  free(h_odataGPU);\n  free(h_idataCPU);\n\n  if (nTotalFailures != 0)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}\n"}}
{"kernel_name": "aligned-types", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n\n\n\n\n\n\ntypedef unsigned char uchar_misaligned;\n\ntypedef unsigned short int ushort_misaligned;\n\ntypedef struct\n{\n  unsigned char r, g, b, a;\n} uchar4_misaligned;\n\ntypedef struct\n{\n  unsigned int l, a;\n} uint2_misaligned;\n\ntypedef struct\n{\n  unsigned int r, g, b;\n} uint3_misaligned;\n\ntypedef struct\n{\n  unsigned int r, g, b, a;\n} uint4_misaligned;\n\ntypedef struct\n{\n  uint4_misaligned c1, c2;\n}\nuint8_misaligned;\n\n\n\n\n\n\n\n\ntypedef struct __align__(4)\n{\n  unsigned char r, g, b, a;\n}\nuchar4_aligned;\n\ntypedef unsigned int uint_aligned;\n\ntypedef struct __align__(8)\n{\n  unsigned int l, a;\n}\nuint2_aligned;\n\ntypedef struct __align__(16)\n{\n  unsigned int r, g, b;\n}\nuint3_aligned;\n\ntypedef struct __align__(16)\n{\n  unsigned int r, g, b, a;\n}\nuint4_aligned;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntypedef struct __align__(16)\n{\n  uint4_aligned c1, c2;\n}\nuint8_aligned;\n\n\n\n\n\n\n\n\n\n\n\nint iDivUp(int a, int b)\n{\n  return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n\n\nint iDivDown(int a, int b)\n{\n  return a / b;\n}\n\n\n\nint iAlignUp(int a, int b)\n{\n  return (a % b != 0) ? (a - a % b + b) : a;\n}\n\n\n\nint iAlignDown(int a, int b)\n{\n  return a - a % b;\n}\n\n\n\n\n\n\n\n\n\n\n\ntemplate<class TData> __global__ void testKernel(\n          TData *__restrict d_odata,\n    const TData *__restrict d_idata,\n    int numElements\n    )\n{\n  const int pos = blockDim.x * blockIdx.x + threadIdx.x;\n  if (pos < numElements)\n  {\n    d_odata[pos] = d_idata[pos];\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate<class TData> int testCPU(\n    TData *h_odata,\n    TData *h_idata,\n    int numElements,\n    int packedElementSize\n    )\n{\n  for (int pos = 0; pos < numElements; pos++)\n  {\n    TData src = h_idata[pos];\n    TData dst = h_odata[pos];\n\n    for (int i = 0; i < packedElementSize; i++)\n      if (((char *)&src)[i] != ((char *)&dst)[i])\n      {\n        return 0;\n      }\n  }\n  return 1;\n}\n\n\n\n\n\n\n\n\n\n\n\nconst int       MEM_SIZE = 50000000;\nconst int NUM_ITERATIONS = 1000;\n\n\n\nunsigned char *h_idataCPU, *h_odataGPU;\n\n\n\ntemplate<class TData> int runTest(\n  unsigned char *d_idata,\n  unsigned char *d_odata,\n  int packedElementSize,\n  int memory_size)\n{\n  const int totalMemSizeAligned = iAlignDown(memory_size, sizeof(TData));\n  const int         numElements = iDivDown(memory_size, sizeof(TData));\n\n  \n\n  hipMemset(d_odata, 0, memory_size);\n  \n\n  hipDeviceSynchronize();\n\n  auto start = std::chrono::high_resolution_clock::now();\n  dim3 grid ((numElements + 255)/256);\n  dim3 block (256);\n  for (int i = 0; i < NUM_ITERATIONS; i++)\n  {\n    testKernel<TData><<<grid, block>>>(\n        (TData *)d_odata,\n        (TData *)d_idata,\n        numElements\n        );\n  }\n\n  hipDeviceSynchronize();\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<double> elapsed_seconds = end - start;\n  double gpuTime = (double)elapsed_seconds.count() / NUM_ITERATIONS;\n\n  printf(\n      \"Avg. time: %f ms / Copy throughput: %f GB/s.\\n\", gpuTime * 1000,\n      (double)totalMemSizeAligned / (gpuTime * 1073741824.0)\n        );\n\n  \n\n  hipMemcpy(h_odataGPU, d_odata, memory_size, hipMemcpyDeviceToHost);\n  int flag = testCPU(\n      (TData *)h_odataGPU,\n      (TData *)h_idataCPU,\n      numElements,\n      packedElementSize\n      );\n\n  printf(flag ? \"\\tTEST OK\\n\" : \"\\tTEST FAILURE\\n\");\n\n  return !flag;\n}\n\nint main(int argc, char **argv)\n{\n  int i, nTotalFailures = 0;\n\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  printf(\"Allocating memory...\\n\");\n  int   MemorySize = (int)(MEM_SIZE) & 0xffffff00; \n\n  h_idataCPU = (unsigned char *)malloc(MemorySize);\n  h_odataGPU = (unsigned char *)malloc(MemorySize);\n\n  unsigned char *d_idata;\n  unsigned char *d_odata;\n  hipMalloc((void **)&d_idata, MemorySize);\n  hipMalloc((void **)&d_odata, MemorySize);\n\n  printf(\"Generating host input data array...\\n\");\n\n  for (i = 0; i < MemorySize; i++)\n  {\n    h_idataCPU[i] = (i & 0xFF) + 1;\n  }\n\n  printf(\"Uploading input data to GPU memory...\\n\");\n  hipMemcpy(d_idata, h_idataCPU, MemorySize, hipMemcpyHostToDevice);\n\n  printf(\"Testing misaligned types...\\n\");\n  printf(\"uchar_misaligned...\\n\");\n  nTotalFailures += runTest<uchar_misaligned>(d_idata, d_odata, 1, MemorySize);\n\n  printf(\"uchar4_misaligned...\\n\");\n  nTotalFailures += runTest<uchar4_misaligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uchar4_aligned...\\n\");\n  nTotalFailures += runTest<uchar4_aligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"ushort_misaligned...\\n\");\n  nTotalFailures += runTest<ushort_misaligned>(d_idata, d_odata, 2, MemorySize);\n\n  printf(\"uint_aligned...\\n\");\n  nTotalFailures += runTest<uint_aligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uint2_misaligned...\\n\");\n  nTotalFailures += runTest<uint2_misaligned>(d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint2_aligned...\\n\");\n  nTotalFailures += runTest<uint2_aligned>(d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint3_misaligned...\\n\");\n  nTotalFailures += runTest<uint3_misaligned>(d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint3_aligned...\\n\");\n  nTotalFailures += runTest<uint3_aligned>(d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint4_misaligned...\\n\");\n  nTotalFailures += runTest<uint4_misaligned>(d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint4_aligned...\\n\");\n  nTotalFailures += runTest<uint4_aligned>(d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint8_misaligned...\\n\");\n  nTotalFailures += runTest<uint8_misaligned>(d_idata, d_odata, 32, MemorySize);\n\n  printf(\"uint8_aligned...\\n\");\n  nTotalFailures += runTest<uint8_aligned>(d_idata, d_odata, 32, MemorySize);\n\n  printf(\"\\n[alignedTypes] -> Test Results: %d Failures\\n\", nTotalFailures);\n\n  printf(\"Shutting down...\\n\");\n  hipFree(d_idata);\n  hipFree(d_odata);\n  free(h_odataGPU);\n  free(h_idataCPU);\n\n  if (nTotalFailures != 0)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}\n"}}
{"kernel_name": "aligned-types", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n\n\n\n\n\n\n\ntypedef unsigned char uchar_misaligned;\n\ntypedef unsigned short int ushort_misaligned;\n\ntypedef struct\n{\n  unsigned char r, g, b, a;\n} uchar4_misaligned;\n\ntypedef struct\n{\n  unsigned int l, a;\n} uint2_misaligned;\n\ntypedef struct\n{\n  unsigned int r, g, b;\n} uint3_misaligned;\n\ntypedef struct\n{\n  unsigned int r, g, b, a;\n} uint4_misaligned;\n\ntypedef struct\n{\n  uint4_misaligned c1, c2;\n} uint8_misaligned;\n\n\n\n\n\n\n\n\ntypedef struct __attribute__((__aligned__(4)))\n{\n  unsigned char r, g, b, a;\n}\nuchar4_aligned;\n\ntypedef unsigned int uint_aligned;\n\ntypedef struct __attribute__((__aligned__(8)))\n{\n  unsigned int l, a;\n}\nuint2_aligned;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  unsigned int r, g, b;\n}\nuint3_aligned;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  unsigned int r, g, b, a;\n}\nuint4_aligned;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  uint4_aligned c1, c2;\n}\nuint8_aligned;\n\n\n\n\n\n\n\n\n\n\n\nint iDivUp(int a, int b)\n{\n  return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n\n\nint iDivDown(int a, int b)\n{\n  return a / b;\n}\n\n\n\nint iAlignUp(int a, int b)\n{\n  return (a % b != 0) ? (a - a % b + b) : a;\n}\n\n\n\nint iAlignDown(int a, int b)\n{\n  return a - a % b;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate<class TData> int testCPU(\n    TData *h_odata,\n    TData *h_idata,\n    int numElements,\n    int packedElementSize\n    )\n{\n  for (int pos = 0; pos < numElements; pos++)\n  {\n    TData src = h_idata[pos];\n    TData dst = h_odata[pos];\n\n    for (int i = 0; i < packedElementSize; i++)\n      if (((char *)&src)[i] != ((char *)&dst)[i])\n      {\n        return 0;\n      }\n  }\n  return 1;\n}\n\n\n\n\n\n\n\n\n\n\n\nconst int       MEM_SIZE = 50000000;\nconst int NUM_ITERATIONS = 1000;\n\n\n\nunsigned char *h_idataCPU;\n\ntemplate<class TData> int runTest(\n  unsigned char *d_idata,\n  unsigned char *d_odata,\n  int packedElementSize,\n  int memory_size)\n{\n  const int totalMemSizeAligned = iAlignDown(memory_size, sizeof(TData));\n  const int         numElements = iDivDown(memory_size, sizeof(TData));\n\n  \n\n  #pragma omp target teams distribute parallel for thread_limit(256)\n  for (int i = 0; i < memory_size; i++) \n    d_odata[i] = 0;\n  \n\n  \n\n  auto start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < NUM_ITERATIONS; i++)\n  {\n    #pragma omp target teams distribute parallel for thread_limit(256)\n    for (int pos = 0; pos < numElements; pos++)\n    {\n      reinterpret_cast<TData*>(d_odata)[pos] = \n        reinterpret_cast<TData*>(d_idata)[pos];\n    }\n  }\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<double> elapsed_seconds = end - start;\n  double gpuTime = (double)elapsed_seconds.count() / NUM_ITERATIONS;\n\n  printf(\n      \"Avg. time: %f ms / Copy throughput: %f GB/s.\\n\", gpuTime * 1000,\n      (double)totalMemSizeAligned / (gpuTime * 1073741824.0)\n        );\n\n  \n\n  #pragma omp target update from (d_odata[0:memory_size])\n\n  int flag = testCPU(\n      (TData *)d_odata,\n      (TData *)h_idataCPU,\n      numElements,\n      packedElementSize\n      );\n\n  printf(flag ? \"\\tTEST OK\\n\" : \"\\tTEST FAILURE\\n\");\n\n  return !flag;\n}\n\nint main(int argc, char **argv)\n{\n  int i, nTotalFailures = 0;\n\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  printf(\"Allocating memory...\\n\");\n  int   MemorySize = (int)(MEM_SIZE) & 0xffffff00; \n\n  h_idataCPU = (unsigned char *)malloc(MemorySize);\n  unsigned char *d_odata = (unsigned char *)malloc(MemorySize);\n\n  printf(\"Generating host input data array...\\n\");\n\n  for (i = 0; i < MemorySize; i++)\n  {\n    h_idataCPU[i] = (i & 0xFF) + 1;\n  }\n\n  printf(\"Uploading input data to GPU memory...\\n\");\n  unsigned char *d_idata = h_idataCPU;\n\n#pragma omp target data map(to: d_idata[0:MemorySize]) \\\n                        map(alloc: d_odata[0:MemorySize])\n{\n\n  printf(\"Testing misaligned types...\\n\");\n  printf(\"uchar_misaligned...\\n\");\n  nTotalFailures += runTest<uchar_misaligned>(d_idata, d_odata, 1, MemorySize);\n\n  printf(\"uchar4_misaligned...\\n\");\n  nTotalFailures += runTest<uchar4_misaligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uchar4_aligned...\\n\");\n  nTotalFailures += runTest<uchar4_aligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"ushort_misaligned...\\n\");\n  nTotalFailures += runTest<ushort_misaligned>(d_idata, d_odata, 2, MemorySize);\n\n  printf(\"uint_aligned...\\n\");\n  nTotalFailures += runTest<uint_aligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uint2_misaligned...\\n\");\n  nTotalFailures += runTest<uint2_misaligned>(d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint2_aligned...\\n\");\n  nTotalFailures += runTest<uint2_aligned>(d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint3_misaligned...\\n\");\n  nTotalFailures += runTest<uint3_misaligned>(d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint3_aligned...\\n\");\n  nTotalFailures += runTest<uint3_aligned>(d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint4_misaligned...\\n\");\n  nTotalFailures += runTest<uint4_misaligned>(d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint4_aligned...\\n\");\n  nTotalFailures += runTest<uint4_aligned>(d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint8_misaligned...\\n\");\n  nTotalFailures += runTest<uint8_misaligned>(d_idata, d_odata, 32, MemorySize);\n\n  printf(\"uint8_aligned...\\n\");\n  nTotalFailures += runTest<uint8_aligned>(d_idata, d_odata, 32, MemorySize);\n\n  printf(\"\\n[alignedTypes] -> Test Results: %d Failures\\n\", nTotalFailures);\n\n  printf(\"Shutting down...\\n\");\n}\n  free(d_odata);\n  free(h_idataCPU);\n\n  if (nTotalFailures != 0)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}\n"}}
{"kernel_name": "aligned-types", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <chrono>\n\n\n\n\n\n\n\ntypedef unsigned char uchar_misaligned;\n\ntypedef unsigned short int ushort_misaligned;\n\ntypedef struct\n{\n  unsigned char r, g, b, a;\n} uchar4_misaligned;\n\ntypedef struct\n{\n  unsigned int l, a;\n} uint2_misaligned;\n\ntypedef struct\n{\n  unsigned int r, g, b;\n} uint3_misaligned;\n\ntypedef struct\n{\n  unsigned int r, g, b, a;\n} uint4_misaligned;\n\ntypedef struct\n{\n  uint4_misaligned c1, c2;\n} uint8_misaligned;\n\n\n\n\n\n\n\n\ntypedef struct __attribute__((__aligned__(4)))\n{\n  unsigned char r, g, b, a;\n}\nuchar4_aligned;\n\ntypedef unsigned int uint_aligned;\n\ntypedef struct __attribute__((__aligned__(8)))\n{\n  unsigned int l, a;\n}\nuint2_aligned;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  unsigned int r, g, b;\n}\nuint3_aligned;\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  unsigned int r, g, b, a;\n}\nuint4_aligned;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntypedef struct __attribute__((__aligned__(16)))\n{\n  uint4_aligned c1, c2;\n}\nuint8_aligned;\n\n\n\n\n\n\n\n\n\n\n\nint iDivUp(int a, int b)\n{\n  return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n\n\nint iDivDown(int a, int b)\n{\n  return a / b;\n}\n\n\n\nint iAlignUp(int a, int b)\n{\n  return (a % b != 0) ? (a - a % b + b) : a;\n}\n\n\n\nint iAlignDown(int a, int b)\n{\n  return a - a % b;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate<class TData> int testCPU(\n    TData *h_odata,\n    TData *h_idata,\n    int numElements,\n    int packedElementSize\n    )\n{\n  for (int pos = 0; pos < numElements; pos++)\n  {\n    TData src = h_idata[pos];\n    TData dst = h_odata[pos];\n\n    for (int i = 0; i < packedElementSize; i++)\n      if (((char *)&src)[i] != ((char *)&dst)[i])\n      {\n        return 0;\n      }\n  }\n  return 1;\n}\n\n\n\n\n\n\n\n\n\n\n\nconst int       MEM_SIZE = 50000000;\nconst int NUM_ITERATIONS = 1000;\n\n\n\nunsigned char *h_idataCPU;\n\ntemplate<class TData> int runTest(\n  unsigned char *d_idata,\n  unsigned char *d_odata,\n  int packedElementSize,\n  int memory_size)\n{\n  const int totalMemSizeAligned = iAlignDown(memory_size, sizeof(TData));\n  const int         numElements = iDivDown(memory_size, sizeof(TData));\n\n  \n\n    for (int i = 0; i < memory_size; i++) \n    d_odata[i] = 0;\n  \n\n  \n\n  auto start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < NUM_ITERATIONS; i++)\n  {\n        for (int pos = 0; pos < numElements; pos++)\n    {\n      reinterpret_cast<TData*>(d_odata)[pos] = \n        reinterpret_cast<TData*>(d_idata)[pos];\n    }\n  }\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<double> elapsed_seconds = end - start;\n  double gpuTime = (double)elapsed_seconds.count() / NUM_ITERATIONS;\n\n  printf(\n      \"Avg. time: %f ms / Copy throughput: %f GB/s.\\n\", gpuTime * 1000,\n      (double)totalMemSizeAligned / (gpuTime * 1073741824.0)\n        );\n\n  \n\n  \n  int flag = testCPU(\n      (TData *)d_odata,\n      (TData *)h_idataCPU,\n      numElements,\n      packedElementSize\n      );\n\n  printf(flag ? \"\\tTEST OK\\n\" : \"\\tTEST FAILURE\\n\");\n\n  return !flag;\n}\n\nint main(int argc, char **argv)\n{\n  int i, nTotalFailures = 0;\n\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  printf(\"Allocating memory...\\n\");\n  int   MemorySize = (int)(MEM_SIZE) & 0xffffff00; \n\n  h_idataCPU = (unsigned char *)malloc(MemorySize);\n  unsigned char *d_odata = (unsigned char *)malloc(MemorySize);\n\n  printf(\"Generating host input data array...\\n\");\n\n  for (i = 0; i < MemorySize; i++)\n  {\n    h_idataCPU[i] = (i & 0xFF) + 1;\n  }\n\n  printf(\"Uploading input data to GPU memory...\\n\");\n  unsigned char *d_idata = h_idataCPU;\n\n{\n\n  printf(\"Testing misaligned types...\\n\");\n  printf(\"uchar_misaligned...\\n\");\n  nTotalFailures += runTest<uchar_misaligned>(d_idata, d_odata, 1, MemorySize);\n\n  printf(\"uchar4_misaligned...\\n\");\n  nTotalFailures += runTest<uchar4_misaligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uchar4_aligned...\\n\");\n  nTotalFailures += runTest<uchar4_aligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"ushort_misaligned...\\n\");\n  nTotalFailures += runTest<ushort_misaligned>(d_idata, d_odata, 2, MemorySize);\n\n  printf(\"uint_aligned...\\n\");\n  nTotalFailures += runTest<uint_aligned>(d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uint2_misaligned...\\n\");\n  nTotalFailures += runTest<uint2_misaligned>(d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint2_aligned...\\n\");\n  nTotalFailures += runTest<uint2_aligned>(d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint3_misaligned...\\n\");\n  nTotalFailures += runTest<uint3_misaligned>(d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint3_aligned...\\n\");\n  nTotalFailures += runTest<uint3_aligned>(d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint4_misaligned...\\n\");\n  nTotalFailures += runTest<uint4_misaligned>(d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint4_aligned...\\n\");\n  nTotalFailures += runTest<uint4_aligned>(d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint8_misaligned...\\n\");\n  nTotalFailures += runTest<uint8_misaligned>(d_idata, d_odata, 32, MemorySize);\n\n  printf(\"uint8_aligned...\\n\");\n  nTotalFailures += runTest<uint8_aligned>(d_idata, d_odata, 32, MemorySize);\n\n  printf(\"\\n[alignedTypes] -> Test Results: %d Failures\\n\", nTotalFailures);\n\n  printf(\"Shutting down...\\n\");\n}\n  free(d_odata);\n  free(h_idataCPU);\n\n  if (nTotalFailures != 0)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}"}}
{"kernel_name": "aligned-types", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n\n\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n\n\n\ntemplate <typename TData>\nclass copy_kernel;\n\n\n\n\n\n\n\ntypedef unsigned char uchar_misaligned;\n\ntypedef unsigned short int ushort_misaligned;\n\nstruct uchar4_misaligned\n{\n  unsigned char r, g, b, a;\n};\n\nstruct uint2_misaligned\n{\n  unsigned int l, a;\n};\n\nstruct uint3_misaligned\n{\n  unsigned int r, g, b;\n};\n\nstruct uint4_misaligned\n{\n  unsigned int r, g, b, a;\n};\n\nstruct uint8_misaligned\n{\n  uint4_misaligned c1, c2;\n};\n\n\n\n\n\n\n\nstruct alignas(4) uchar4_aligned\n{\n  unsigned char r, g, b, a;\n};\n\ntypedef unsigned int uint_aligned;\n\nstruct alignas(8) uint2_aligned\n{\n  unsigned int l, a;\n};\n\nstruct alignas(16) uint3_aligned\n{\n  unsigned int r, g, b;\n};\n\nstruct alignas(16) uint4_aligned\n{\n  unsigned int r, g, b, a;\n};\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstruct alignas(16) uint8_aligned\n{\n  uint4_aligned c1, c2;\n};\n\n\n\n\n\n\n\n\n\n\n\nint iDivUp(int a, int b)\n{\n  return (a % b != 0) ? (a / b + 1) : (a / b);\n}\n\n\n\nint iDivDown(int a, int b)\n{\n  return a / b;\n}\n\n\n\nint iAlignUp(int a, int b)\n{\n  return (a % b != 0) ? (a - a % b + b) : a;\n}\n\n\n\nint iAlignDown(int a, int b)\n{\n  return a - a % b;\n}\n\n\n\n\n\n\n\n\n\n\n\ntemplate <typename TData> \nvoid testKernel(      TData *__restrict d_odata,\n                const TData *__restrict d_idata,\n                int numElements,\n                sycl::nd_item<1> &item)\n{\n  const int pos = item.get_global_id(0);\n  if (pos < numElements)\n  {\n    d_odata[pos] = d_idata[pos];\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntemplate <typename TData> \nint testCPU(\n    TData *h_odata,\n    TData *h_idata,\n    int numElements,\n    int packedElementSize)\n{\n  for (int pos = 0; pos < numElements; pos++)\n  {\n    TData src = h_idata[pos];\n    TData dst = h_odata[pos];\n\n    for (int i = 0; i < packedElementSize; i++)\n      if (((char *)&src)[i] != ((char *)&dst)[i])\n      {\n        return 0;\n      }\n  }\n  return 1;\n}\n\n\n\n\n\n\n\n\n\n\n\nconst int       MEM_SIZE = 50000000;\nconst int NUM_ITERATIONS = 1000;\n\n\n\nunsigned char *d_idata, *d_odata;\n\n\nunsigned char *h_idataCPU, *h_odataGPU;\n\ntemplate <typename TData> \nint runTest(\n  sycl::queue &q,\n  unsigned char *d_idata,\n  unsigned char *d_odata,\n  int packedElementSize,\n  int memory_size)\n{\n  const int totalMemSizeAligned = iAlignDown(memory_size, sizeof(TData));\n  const int         numElements = iDivDown(memory_size, sizeof(TData));\n\n  \n\n  q.memset(d_odata, 0, memory_size).wait();\n\n  \n\n  sycl::range<1> gws ((numElements + 255)/256*256);\n  sycl::range<1> lws (256);\n\n  auto start = std::chrono::high_resolution_clock::now();\n\n  for (int i = 0; i < NUM_ITERATIONS; i++)\n  {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class copy_kernel<TData>>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        testKernel<TData>((TData*)d_odata, (TData*)d_idata, numElements, item);\n      });\n    });\n  }\n\n  q.wait();\n\n  auto end = std::chrono::high_resolution_clock::now();\n  std::chrono::duration<double> elapsed_seconds = end - start;\n  double gpuTime = (double)elapsed_seconds.count() / NUM_ITERATIONS;\n\n  printf(\"Avg. time: %f ms / Copy throughput: %f GB/s.\\n\", gpuTime * 1000,\n         (double)totalMemSizeAligned / (gpuTime * 1073741824.0));\n\n  \n\n  q.memcpy(h_odataGPU, d_odata, memory_size).wait();\n\n  int flag = testCPU(\n      (TData *)h_odataGPU,\n      (TData *)h_idataCPU,\n      numElements,\n      packedElementSize);\n\n  printf(flag ? \"\\tTEST OK\\n\" : \"\\tTEST FAILURE\\n\");\n\n  return !flag;\n}\n\nint main(int argc, char **argv)\n{\n  int i, nTotalFailures = 0;\n\n  printf(\"[%s] - Starting...\\n\", argv[0]);\n\n  printf(\"Allocating memory...\\n\");\n  int   MemorySize = (int)(MEM_SIZE) & 0xffffff00; \n\n  h_idataCPU = (unsigned char *)malloc(MemorySize);\n  h_odataGPU = (unsigned char *)malloc(MemorySize);\n\n  printf(\"Generating host input data array...\\n\");\n\n  for (i = 0; i < MemorySize; i++)\n  {\n    h_idataCPU[i] = (i & 0xFF) + 1;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  printf(\"Uploading input data to GPU memory...\\n\");\n  unsigned char *d_idata = sycl::malloc_device<unsigned char>(MemorySize, q);\n  q.memcpy(d_idata, h_idataCPU, MemorySize);\n\n  unsigned char *d_odata = sycl::malloc_device<unsigned char>(MemorySize, q);\n\n  printf(\"Testing misaligned types...\\n\");\n  printf(\"uchar_misaligned...\\n\");\n  nTotalFailures += runTest<uchar_misaligned>(q, d_idata, d_odata, 1, MemorySize);\n\n  printf(\"uchar4_misaligned...\\n\");\n  nTotalFailures += runTest<uchar4_misaligned>(q, d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uchar4_aligned...\\n\");\n  nTotalFailures += runTest<uchar4_aligned>(q, d_idata, d_odata, 4, MemorySize);\n\n  printf(\"ushort_misaligned...\\n\");\n  nTotalFailures += runTest<ushort_misaligned>(q, d_idata, d_odata, 2, MemorySize);\n\n  printf(\"uint_aligned...\\n\");\n  nTotalFailures += runTest<uint_aligned>(q, d_idata, d_odata, 4, MemorySize);\n\n  printf(\"uint2_misaligned...\\n\");\n  nTotalFailures += runTest<uint2_misaligned>(q, d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint2_aligned...\\n\");\n  nTotalFailures += runTest<uint2_aligned>(q, d_idata, d_odata, 8, MemorySize);\n\n  printf(\"uint3_misaligned...\\n\");\n  nTotalFailures += runTest<uint3_misaligned>(q, d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint3_aligned...\\n\");\n  nTotalFailures += runTest<uint3_aligned>(q, d_idata, d_odata, 12, MemorySize);\n\n  printf(\"uint4_misaligned...\\n\");\n  nTotalFailures += runTest<uint4_misaligned>(q, d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint4_aligned...\\n\");\n  nTotalFailures += runTest<uint4_aligned>(q, d_idata, d_odata, 16, MemorySize);\n\n  printf(\"uint8_misaligned...\\n\");\n  nTotalFailures += runTest<uint8_misaligned>(q, d_idata, d_odata, 32, MemorySize);\n\n  printf(\"uint8_aligned...\\n\");\n  nTotalFailures += runTest<uint8_aligned>(q, d_idata, d_odata, 32, MemorySize);\n\n  printf(\"\\n[alignedTypes] -> Test Results: %d Failures\\n\", nTotalFailures);\n\n  printf(\"Shutting down...\\n\");\n  sycl::free(d_odata, q);\n  sycl::free(d_idata, q);\n  free(h_odataGPU);\n  free(h_idataCPU);\n\n  if (nTotalFailures != 0)\n  {\n    printf(\"Test failed!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  printf(\"Test passed\\n\");\n  exit(EXIT_SUCCESS);\n}\n"}}
{"kernel_name": "asta", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <unistd.h>\n#include <string.h>\n#include <assert.h>\n#include <vector>\n#include <algorithm>  \n\n#include <chrono>\n#include <cuda.h>\n\n#include \"support/common.h\"\n#include \"support/verify.h\"\n\n\n\n__global__ void PTTWAC_soa_asta(const int A, \n                                const int B, \n                                const int b, \n                                  T *__restrict__ input, \n                                int *__restrict__ finished, \n                                int *__restrict__ head) \n{\n  __shared__ int lmem[2];\n\n  const int tid = threadIdx.x;\n  int       m   = A * B - 1;\n\n  if(tid == 0) \n\n    lmem[1] = atomicAdd(&head[0], 1);\n  __syncthreads();\n\n  while(lmem[1] < m) {\n    int next_in_cycle = (lmem[1] * A) - m * (lmem[1] / B);\n    if(next_in_cycle == lmem[1]) {\n      if(tid == 0) \n\n        lmem[1] = atomicAdd(&head[0], 1);\n      __syncthreads();\n      continue;\n    }\n    T   data1, data2, data3, data4;\n    int i = tid;\n    if(i < b)\n      data1 = input[lmem[1] * b + i];\n    i += blockDim.x;\n    if(i < b)\n      data2 = input[lmem[1] * b + i];\n    i += blockDim.x;\n    if(i < b)\n      data3 = input[lmem[1] * b + i];\n    i += blockDim.x;\n    if(i < b)\n      data4 = input[lmem[1] * b + i];\n\n    if(tid == 0) {\n      \n\n      lmem[0] = atomicAdd(&finished[lmem[1]], 0);\n    }\n    __syncthreads();\n\n    for(; lmem[0] == 0; next_in_cycle = (next_in_cycle * A) - m * (next_in_cycle / B)) {\n      T backup1, backup2, backup3, backup4;\n      i = tid;\n      if(i < b)\n        backup1 = input[next_in_cycle * b + i];\n      i += blockDim.x;\n      if(i < b)\n        backup2 = input[next_in_cycle * b + i];\n      i += blockDim.x;\n      if(i < b)\n        backup3 = input[next_in_cycle * b + i];\n      i += blockDim.x;\n      if(i < b)\n        backup4 = input[next_in_cycle * b + i];\n\n      if(tid == 0) {\n        lmem[0] = atomicExch(&finished[next_in_cycle], (int)1);\n      }\n      __syncthreads();\n\n      if(!lmem[0]) {\n        i = tid;\n        if(i < b)\n          input[next_in_cycle * b + i] = data1;\n        i += blockDim.x;\n        if(i < b)\n          input[next_in_cycle * b + i] = data2;\n        i += blockDim.x;\n        if(i < b)\n          input[next_in_cycle * b + i] = data3;\n        i += blockDim.x;\n        if(i < b)\n          input[next_in_cycle * b + i] = data4;\n      }\n      i = tid;\n      if(i < b)\n        data1 = backup1;\n      i += blockDim.x;\n      if(i < b)\n        data2 = backup2;\n      i += blockDim.x;\n      if(i < b)\n        data3 = backup3;\n      i += blockDim.x;\n      if(i < b)\n        data4 = backup4;\n    }\n\n    if(tid == 0) \n\n      lmem[1] = atomicAdd(&head[0], 1);\n    __syncthreads();\n  }\n}\n\n\n\n\nstruct Params {\n\n  int device;\n  int n_gpu_threads;\n  int n_gpu_blocks;\n  int n_warmup;\n  int n_reps;\n  int m;\n  int n;\n  int s;\n\n  Params(int argc, char **argv) {\n    device        = 0;\n    n_gpu_threads = 64;\n    n_gpu_blocks  = 16;\n    n_warmup      = 10;\n    n_reps        = 100;\n    m             = 197;\n    n             = 35588;\n    s             = 32;\n    int opt;\n    while((opt = getopt(argc, argv, \"hd:i:g:w:r:m:n:s:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'i': n_gpu_threads = atoi(optarg); break;\n        case 'g': n_gpu_blocks  = atoi(optarg); break;\n        case 'w': n_warmup      = atoi(optarg); break;\n        case 'r': n_reps        = atoi(optarg); break;\n        case 'm': m             = atoi(optarg); break;\n        case 'n': n             = atoi(optarg); break;\n        case 's': s             = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -i <I>    # of device threads per block (default=64)\"\n        \"\\n    -g <G>    # of device blocks (default=16)\"\n        \"\\n    -w <W>    # of untimed warmup iterations (default=10)\"\n        \"\\n    -r <R>    # of timed repetition iterations (default=100)\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -m <M>    matrix height (default=197)\"\n        \"\\n    -n <N>    matrix width (default=35588)\"\n        \"\\n    -s <M>    super-element size (default=32)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(T *x_vector, const Params &p) {\n  int tiled_n = divceil(p.n, p.s);\n  int in_size = p.m * tiled_n * p.s;\n  srand(5432);\n  for(int i = 0; i < in_size; i++) {\n    x_vector[i] = ((T)(rand() % 100) / 100);\n  }\n}\n\n\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int blocks = p.n_gpu_blocks;\n  int threads = p.n_gpu_threads;\n  const int max_gpu_threads = 256;\n  assert(threads <= max_gpu_threads && \n         \"The thread block size is at most 256\");\n\n  \n\n  int tiled_n       = divceil(p.n, p.s);\n  int in_size       = p.m * tiled_n * p.s;\n  int finished_size = p.m * tiled_n;\n\n  size_t in_size_bytes = in_size * sizeof(T);\n  size_t finished_size_bytes = finished_size * sizeof(int);\n\n  T *h_in_out = (T *)malloc(in_size_bytes);\n  int *h_finished = (int *)malloc(finished_size_bytes);\n  int *h_head = (int *)malloc(sizeof(int));\n\n\n  dim3 dimGrid(blocks);\n  dim3 dimBlock(threads);\n\n  T * d_in_out;\n  int * d_finished;\n  int * d_head;\n  cudaMalloc((void**)&d_in_out, in_size_bytes);\n  cudaMalloc((void**)&d_finished, finished_size_bytes);\n  cudaMalloc((void**)&d_head, sizeof(int));\n  T *h_in_backup = (T *)malloc(in_size_bytes);\n\n  \n\n  read_input(h_in_out, p);\n  memset((void *)h_finished, 0, finished_size_bytes);\n  h_head[0] = 0;\n  memcpy(h_in_backup, h_in_out, in_size_bytes); \n\n\n  double time = 0;\n\n  \n\n  for(int rep = 0; rep < p.n_warmup + p.n_reps; rep++) {\n\n    cudaMemcpyAsync(d_in_out, h_in_backup, in_size_bytes, cudaMemcpyHostToDevice, 0);\n    cudaMemcpyAsync(d_finished, h_finished, finished_size_bytes, cudaMemcpyHostToDevice, 0);\n    cudaMemcpyAsync(d_head, h_head, sizeof(int), cudaMemcpyHostToDevice, 0);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    PTTWAC_soa_asta<<<dimGrid, dimBlock>>>(p.m, tiled_n, p.s, d_in_out, d_finished, d_head);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    if (rep >= p.n_warmup) \n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    cudaMemcpy(h_in_out, d_in_out, in_size_bytes, cudaMemcpyDeviceToHost);\n  }\n\n  printf(\"Average kernel execution time %lf (s)\\n\", (time * 1e-9) / p.n_reps);\n\n  \n\n  int status = verify(h_in_out, h_in_backup, tiled_n * p.s, p.m, p.s);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(h_in_out);\n  free(h_finished);\n  free(h_head);\n  free(h_in_backup);\n\n  cudaFree(d_in_out);\n  cudaFree(d_finished);\n  cudaFree(d_head);\n\n  return 0;\n}\n"}}
{"kernel_name": "asta", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <unistd.h>\n#include <string.h>\n#include <assert.h>\n#include <vector>\n#include <algorithm>  \n\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#include \"support/common.h\"\n#include \"support/verify.h\"\n\n\n\n__global__ void PTTWAC_soa_asta(const int A, \n                                const int B, \n                                const int b, \n                                  T *__restrict__ input, \n                                int *__restrict__ finished, \n                                int *__restrict__ head) \n{\n  __shared__ int lmem[2];\n\n  const int tid = threadIdx.x;\n  int       m   = A * B - 1;\n\n  if(tid == 0) \n\n    lmem[1] = atomicAdd(&head[0], 1);\n  __syncthreads();\n\n  while(lmem[1] < m) {\n    int next_in_cycle = (lmem[1] * A) - m * (lmem[1] / B);\n    if(next_in_cycle == lmem[1]) {\n      if(tid == 0) \n\n        lmem[1] = atomicAdd(&head[0], 1);\n      __syncthreads();\n      continue;\n    }\n    T   data1, data2, data3, data4;\n    int i = tid;\n    if(i < b)\n      data1 = input[lmem[1] * b + i];\n    i += blockDim.x;\n    if(i < b)\n      data2 = input[lmem[1] * b + i];\n    i += blockDim.x;\n    if(i < b)\n      data3 = input[lmem[1] * b + i];\n    i += blockDim.x;\n    if(i < b)\n      data4 = input[lmem[1] * b + i];\n\n    if(tid == 0) {\n      \n\n      lmem[0] = atomicAdd(&finished[lmem[1]], 0);\n    }\n    __syncthreads();\n\n    for(; lmem[0] == 0; next_in_cycle = (next_in_cycle * A) - m * (next_in_cycle / B)) {\n      T backup1, backup2, backup3, backup4;\n      i = tid;\n      if(i < b)\n        backup1 = input[next_in_cycle * b + i];\n      i += blockDim.x;\n      if(i < b)\n        backup2 = input[next_in_cycle * b + i];\n      i += blockDim.x;\n      if(i < b)\n        backup3 = input[next_in_cycle * b + i];\n      i += blockDim.x;\n      if(i < b)\n        backup4 = input[next_in_cycle * b + i];\n\n      if(tid == 0) {\n        lmem[0] = atomicExch(&finished[next_in_cycle], (int)1);\n      }\n      __syncthreads();\n\n      if(!lmem[0]) {\n        i = tid;\n        if(i < b)\n          input[next_in_cycle * b + i] = data1;\n        i += blockDim.x;\n        if(i < b)\n          input[next_in_cycle * b + i] = data2;\n        i += blockDim.x;\n        if(i < b)\n          input[next_in_cycle * b + i] = data3;\n        i += blockDim.x;\n        if(i < b)\n          input[next_in_cycle * b + i] = data4;\n      }\n      i = tid;\n      if(i < b)\n        data1 = backup1;\n      i += blockDim.x;\n      if(i < b)\n        data2 = backup2;\n      i += blockDim.x;\n      if(i < b)\n        data3 = backup3;\n      i += blockDim.x;\n      if(i < b)\n        data4 = backup4;\n    }\n\n    if(tid == 0) \n\n      lmem[1] = atomicAdd(&head[0], 1);\n    __syncthreads();\n  }\n}\n\n\n\n\nstruct Params {\n\n  int device;\n  int n_gpu_threads;\n  int n_gpu_blocks;\n  int n_warmup;\n  int n_reps;\n  int m;\n  int n;\n  int s;\n\n  Params(int argc, char **argv) {\n    device        = 0;\n    n_gpu_threads = 64;\n    n_gpu_blocks  = 16;\n    n_warmup      = 10;\n    n_reps        = 100;\n    m             = 197;\n    n             = 35588;\n    s             = 32;\n    int opt;\n    while((opt = getopt(argc, argv, \"hd:i:g:w:r:m:n:s:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'i': n_gpu_threads = atoi(optarg); break;\n        case 'g': n_gpu_blocks  = atoi(optarg); break;\n        case 'w': n_warmup      = atoi(optarg); break;\n        case 'r': n_reps        = atoi(optarg); break;\n        case 'm': m             = atoi(optarg); break;\n        case 'n': n             = atoi(optarg); break;\n        case 's': s             = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -i <I>    # of device threads per block (default=64)\"\n        \"\\n    -g <G>    # of device blocks (default=16)\"\n        \"\\n    -w <W>    # of untimed warmup iterations (default=10)\"\n        \"\\n    -r <R>    # of timed repetition iterations (default=100)\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -m <M>    matrix height (default=197)\"\n        \"\\n    -n <N>    matrix width (default=35588)\"\n        \"\\n    -s <M>    super-element size (default=32)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(T *x_vector, const Params &p) {\n  int tiled_n = divceil(p.n, p.s);\n  int in_size = p.m * tiled_n * p.s;\n  srand(5432);\n  for(int i = 0; i < in_size; i++) {\n    x_vector[i] = ((T)(rand() % 100) / 100);\n  }\n}\n\n\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int blocks = p.n_gpu_blocks;\n  int threads = p.n_gpu_threads;\n  const int max_gpu_threads = 256;\n  assert(threads <= max_gpu_threads && \n         \"The thread block size is at most 256\");\n\n  \n\n  int tiled_n       = divceil(p.n, p.s);\n  int in_size       = p.m * tiled_n * p.s;\n  int finished_size = p.m * tiled_n;\n\n  size_t in_size_bytes = in_size * sizeof(T);\n  size_t finished_size_bytes = finished_size * sizeof(int);\n\n  T *h_in_out = (T *)malloc(in_size_bytes);\n  int *h_finished = (int *)malloc(finished_size_bytes);\n  int *h_head = (int *)malloc(sizeof(int));\n\n\n  dim3 dimGrid(blocks);\n  dim3 dimBlock(threads);\n\n  T * d_in_out;\n  int * d_finished;\n  int * d_head;\n  hipMalloc((void**)&d_in_out, in_size_bytes);\n  hipMalloc((void**)&d_finished, finished_size_bytes);\n  hipMalloc((void**)&d_head, sizeof(int));\n  T *h_in_backup = (T *)malloc(in_size_bytes);\n\n  \n\n  read_input(h_in_out, p);\n  memset((void *)h_finished, 0, finished_size_bytes);\n  h_head[0] = 0;\n  memcpy(h_in_backup, h_in_out, in_size_bytes); \n\n\n  double time = 0;\n\n  \n\n  for(int rep = 0; rep < p.n_warmup + p.n_reps; rep++) {\n\n    hipMemcpyAsync(d_in_out, h_in_backup, in_size_bytes, hipMemcpyHostToDevice, 0);\n    hipMemcpyAsync(d_finished, h_finished, finished_size_bytes, hipMemcpyHostToDevice, 0);\n    hipMemcpyAsync(d_head, h_head, sizeof(int), hipMemcpyHostToDevice, 0);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    PTTWAC_soa_asta<<<dimGrid, dimBlock>>>(p.m, tiled_n, p.s, d_in_out, d_finished, d_head);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    if (rep >= p.n_warmup) \n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    hipMemcpy(h_in_out, d_in_out, in_size_bytes, hipMemcpyDeviceToHost);\n  }\n\n  printf(\"Average kernel execution time %lf (s)\\n\", (time * 1e-9) / p.n_reps);\n\n  \n\n  int status = verify(h_in_out, h_in_backup, tiled_n * p.s, p.m, p.s);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(h_in_out);\n  free(h_finished);\n  free(h_head);\n  free(h_in_backup);\n\n  hipFree(d_in_out);\n  hipFree(d_finished);\n  hipFree(d_head);\n\n  return 0;\n}\n"}}
{"kernel_name": "asta", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <unistd.h>\n#include <string.h>\n#include <assert.h>\n#include <vector>\n#include <algorithm>  \n\n#include <chrono>\n#include <omp.h>\n\n#include \"support/common.h\"\n#include \"support/verify.h\"\n\n\n\n\nstruct Params {\n\n  int device;\n  int n_gpu_threads;\n  int n_gpu_blocks;\n  int n_warmup;\n  int n_reps;\n  int m;\n  int n;\n  int s;\n\n  Params(int argc, char **argv) {\n    device        = 0;\n    n_gpu_threads  = 64;\n    n_gpu_blocks = 16;\n    n_warmup      = 10;\n    n_reps        = 100;\n    m             = 197;\n    n             = 35588;\n    s             = 32;\n    int opt;\n    while((opt = getopt(argc, argv, \"hd:i:g:w:r:m:n:s:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'i': n_gpu_threads  = atoi(optarg); break;\n        case 'g': n_gpu_blocks = atoi(optarg); break;\n        case 'w': n_warmup      = atoi(optarg); break;\n        case 'r': n_reps        = atoi(optarg); break;\n        case 'm': m             = atoi(optarg); break;\n        case 'n': n             = atoi(optarg); break;\n        case 's': s             = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -i <I>    # of device threads per block (default=64)\"\n        \"\\n    -g <G>    # of device blocks (default=16)\"\n        \"\\n    -w <W>    # of warmup iterations (default=10)\"\n        \"\\n    -r <R>    # of repetition iterations (default=100)\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -m <M>    matrix height (default=197)\"\n        \"\\n    -n <N>    matrix width (default=35588)\"\n        \"\\n    -s <M>    super-element size (default=32)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(FP *x_vector, const Params &p) {\n  int tiled_n = divceil(p.n, p.s);\n  int in_size = p.m * tiled_n * p.s;\n  srand(5432);\n  for(int i = 0; i < in_size; i++) {\n    x_vector[i] = ((FP)(rand() % 100) / 100);\n  }\n}\n\n\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int blocks = p.n_gpu_blocks;\n  int threads = p.n_gpu_threads;\n  const int max_gpu_threads = 256;\n  assert(threads <= max_gpu_threads && \n          \"The thread block size is greater than the maximum thread block size that can be used on this device\");\n\n\n  \n\n  int tiled_n       = divceil(p.n, p.s);\n  int in_size       = p.m * tiled_n * p.s;\n  int finished_size = p.m * tiled_n;\n\n  size_t in_size_bytes = in_size * sizeof(FP);\n  size_t finished_size_bytes = finished_size * sizeof(int);\n\n  FP *h_in_out = (FP *)malloc(in_size_bytes);\n  int *h_finished = (int *)malloc(finished_size_bytes);\n  int *h_head = (int *)malloc(sizeof(int));\n  FP *h_in_backup = (FP *)malloc(in_size_bytes);\n\n  \n\n  read_input(h_in_out, p);\n  memcpy(h_in_backup, h_in_out, in_size_bytes); \n\n\n  const int A = p.m;\n  const int B = tiled_n;\n  const int b = p.s;\n\n#pragma omp target data map(alloc: h_in_out[0:in_size], \\\n                                   h_finished[0:finished_size], \\\n                                   h_head[0:1])\n  {\n    double time = 0;\n\n    for(int rep = 0; rep < p.n_warmup + p.n_reps; rep++) {\n\n      memcpy(h_in_out, h_in_backup, in_size_bytes);\n      memset((void *)h_finished, 0, finished_size_bytes);\n      h_head[0] = 0;\n\n#pragma omp target update to(h_in_out[0:in_size]) \n\n#pragma omp target update to(h_finished[0:finished_size]) \n\n#pragma omp target update to(h_head[0:1]) \n\n\n     auto start = std::chrono::steady_clock::now();\n\n#pragma omp target teams num_teams(blocks) thread_limit(threads) \n      {\n        int lmem[2];\n#pragma omp parallel \n        {\n          const int tid = omp_get_thread_num();\n          int       m   = A * B - 1;\n\n          if(tid == 0) {\n\n#pragma omp atomic capture\n            lmem[1] = h_head[0]++;\n          }\n#pragma omp barrier\n\n          while(lmem[1] < m) {\n            int next_in_cycle = (lmem[1] * A) - m * (lmem[1] / B);\n            if(next_in_cycle == lmem[1]) {\n              if(tid == 0) {\n\n#pragma omp atomic capture\n                lmem[1] = h_head[0]++;\n              }\n#pragma omp barrier\n              continue;\n            }\n            FP   data1, data2, data3, data4;\n            int i = tid;\n            if(i < b)\n              data1 = h_in_out[lmem[1] * b + i];\n            i += omp_get_num_threads();\n            if(i < b)\n              data2 = h_in_out[lmem[1] * b + i];\n            i += omp_get_num_threads();\n            if(i < b)\n              data3 = h_in_out[lmem[1] * b + i];\n            i += omp_get_num_threads();\n            if(i < b)\n              data4 = omp_get_num_threads();\n\n            if(tid == 0) {\n#pragma omp atomic read\n              lmem[0] = h_finished[lmem[1]];\n            }\n#pragma omp barrier\n\n            for(; lmem[0] == 0; next_in_cycle = (next_in_cycle * A) - m * (next_in_cycle / B)) {\n              FP backup1, backup2, backup3, backup4;\n              i = tid;\n              if(i < b)\n                backup1 = h_in_out[next_in_cycle * b + i];\n              i += omp_get_num_threads();\n              if(i < b)\n                backup2 = h_in_out[next_in_cycle * b + i];\n              i += omp_get_num_threads();\n              if(i < b)\n                backup3 = h_in_out[next_in_cycle * b + i];\n              i += omp_get_num_threads();\n              if(i < b)\n                backup4 = h_in_out[next_in_cycle * b + i];\n\n              if(tid == 0) {\n#pragma omp atomic capture\n                {\n                  lmem[0] = h_finished[next_in_cycle];\n                  h_finished[next_in_cycle] = (int)1;\n                }\n              }\n#pragma omp barrier\n\n              if(!lmem[0]) {\n                i = tid;\n                if(i < b)\n                  h_in_out[next_in_cycle * b + i] = data1;\n                i += omp_get_num_threads();\n                if(i < b)\n                  h_in_out[next_in_cycle * b + i] = data2;\n                i += omp_get_num_threads();\n                if(i < b)\n                  h_in_out[next_in_cycle * b + i] = data3;\n                i += omp_get_num_threads();\n                if(i < b)\n                  h_in_out[next_in_cycle * b + i] = data4;\n              }\n              i = tid;\n              if(i < b)\n                data1 = backup1;\n              i += omp_get_num_threads();\n              if(i < b)\n                data2 = backup2;\n              i += omp_get_num_threads();\n              if(i < b)\n                data3 = backup3;\n              i += omp_get_num_threads();\n              if(i < b)\n                data4 = backup4;\n            }\n\n            if(tid == 0) { \n\n#pragma omp atomic capture\n              lmem[1] = h_head[0]++;\n            }\n#pragma omp barrier\n          }\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      if (rep >= p.n_warmup) \n        time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    \n\n#pragma omp target update from(h_in_out[0:in_size]) \n\n    }\n\n    printf(\"Average kernel execution time %lf (s)\\n\", (time * 1e-9) / p.n_reps);\n  }\n\n  \n\n  int status = verify(h_in_out, h_in_backup, tiled_n * p.s, p.m, p.s);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(h_in_out);\n  free(h_finished);\n  free(h_head);\n  free(h_in_backup);\n\n  return 0;\n}\n"}}
{"kernel_name": "asta", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <unistd.h>\n#include <string.h>\n#include <assert.h>\n#include <vector>\n#include <algorithm>  \n\n#include <chrono>\n\n#include \"support/common.h\"\n#include \"support/verify.h\"\n\n\n\n\nstruct Params {\n\n  int device;\n  int n_gpu_threads;\n  int n_gpu_blocks;\n  int n_warmup;\n  int n_reps;\n  int m;\n  int n;\n  int s;\n\n  Params(int argc, char **argv) {\n    device        = 0;\n    n_gpu_threads  = 64;\n    n_gpu_blocks = 16;\n    n_warmup      = 10;\n    n_reps        = 100;\n    m             = 197;\n    n             = 35588;\n    s             = 32;\n    int opt;\n    while((opt = getopt(argc, argv, \"hd:i:g:w:r:m:n:s:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'i': n_gpu_threads  = atoi(optarg); break;\n        case 'g': n_gpu_blocks = atoi(optarg); break;\n        case 'w': n_warmup      = atoi(optarg); break;\n        case 'r': n_reps        = atoi(optarg); break;\n        case 'm': m             = atoi(optarg); break;\n        case 'n': n             = atoi(optarg); break;\n        case 's': s             = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -i <I>    # of device threads per block (default=64)\"\n        \"\\n    -g <G>    # of device blocks (default=16)\"\n        \"\\n    -w <W>    # of warmup iterations (default=10)\"\n        \"\\n    -r <R>    # of repetition iterations (default=100)\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -m <M>    matrix height (default=197)\"\n        \"\\n    -n <N>    matrix width (default=35588)\"\n        \"\\n    -s <M>    super-element size (default=32)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(FP *x_vector, const Params &p) {\n  int tiled_n = divceil(p.n, p.s);\n  int in_size = p.m * tiled_n * p.s;\n  srand(5432);\n  for(int i = 0; i < in_size; i++) {\n    x_vector[i] = ((FP)(rand() % 100) / 100);\n  }\n}\n\n\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int blocks = p.n_gpu_blocks;\n  int threads = p.n_gpu_threads;\n  const int max_gpu_threads = 256;\n  assert(threads <= max_gpu_threads && \n          \"The thread block size is greater than the maximum thread block size that can be used on this device\");\n\n\n  \n\n  int tiled_n       = divceil(p.n, p.s);\n  int in_size       = p.m * tiled_n * p.s;\n  int finished_size = p.m * tiled_n;\n\n  size_t in_size_bytes = in_size * sizeof(FP);\n  size_t finished_size_bytes = finished_size * sizeof(int);\n\n  FP *h_in_out = (FP *)malloc(in_size_bytes);\n  int *h_finished = (int *)malloc(finished_size_bytes);\n  int *h_head = (int *)malloc(sizeof(int));\n  FP *h_in_backup = (FP *)malloc(in_size_bytes);\n\n  \n\n  read_input(h_in_out, p);\n  memcpy(h_in_backup, h_in_out, in_size_bytes); \n\n\n  const int A = p.m;\n  const int B = tiled_n;\n  const int b = p.s;\n\n  {\n    double time = 0;\n\n    for(int rep = 0; rep < p.n_warmup + p.n_reps; rep++) {\n\n      memcpy(h_in_out, h_in_backup, in_size_bytes);\n      memset((void *)h_finished, 0, finished_size_bytes);\n      h_head[0] = 0;\n\n\n\n\n\n     auto start = std::chrono::steady_clock::now();\n\n      {\n        int lmem[2];\n        {\n          const int tid = omp_get_thread_num();\n          int       m   = A * B - 1;\n\n          if(tid == 0) {\n\n            lmem[1] = h_head[0]++;\n          }\n\n          while(lmem[1] < m) {\n            int next_in_cycle = (lmem[1] * A) - m * (lmem[1] / B);\n            if(next_in_cycle == lmem[1]) {\n              if(tid == 0) {\n\n                lmem[1] = h_head[0]++;\n              }\n              continue;\n            }\n            FP   data1, data2, data3, data4;\n            int i = tid;\n            if(i < b)\n              data1 = h_in_out[lmem[1] * b + i];\n            i += omp_get_num_threads();\n            if(i < b)\n              data2 = h_in_out[lmem[1] * b + i];\n            i += omp_get_num_threads();\n            if(i < b)\n              data3 = h_in_out[lmem[1] * b + i];\n            i += omp_get_num_threads();\n            if(i < b)\n              data4 = omp_get_num_threads();\n\n            if(tid == 0) {\n              lmem[0] = h_finished[lmem[1]];\n            }\n\n            for(; lmem[0] == 0; next_in_cycle = (next_in_cycle * A) - m * (next_in_cycle / B)) {\n              FP backup1, backup2, backup3, backup4;\n              i = tid;\n              if(i < b)\n                backup1 = h_in_out[next_in_cycle * b + i];\n              i += omp_get_num_threads();\n              if(i < b)\n                backup2 = h_in_out[next_in_cycle * b + i];\n              i += omp_get_num_threads();\n              if(i < b)\n                backup3 = h_in_out[next_in_cycle * b + i];\n              i += omp_get_num_threads();\n              if(i < b)\n                backup4 = h_in_out[next_in_cycle * b + i];\n\n              if(tid == 0) {\n                {\n                  lmem[0] = h_finished[next_in_cycle];\n                  h_finished[next_in_cycle] = (int)1;\n                }\n              }\n\n              if(!lmem[0]) {\n                i = tid;\n                if(i < b)\n                  h_in_out[next_in_cycle * b + i] = data1;\n                i += omp_get_num_threads();\n                if(i < b)\n                  h_in_out[next_in_cycle * b + i] = data2;\n                i += omp_get_num_threads();\n                if(i < b)\n                  h_in_out[next_in_cycle * b + i] = data3;\n                i += omp_get_num_threads();\n                if(i < b)\n                  h_in_out[next_in_cycle * b + i] = data4;\n              }\n              i = tid;\n              if(i < b)\n                data1 = backup1;\n              i += omp_get_num_threads();\n              if(i < b)\n                data2 = backup2;\n              i += omp_get_num_threads();\n              if(i < b)\n                data3 = backup3;\n              i += omp_get_num_threads();\n              if(i < b)\n                data4 = backup4;\n            }\n\n            if(tid == 0) { \n\n              lmem[1] = h_head[0]++;\n            }\n          }\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      if (rep >= p.n_warmup) \n        time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    \n\n\n    }\n\n    printf(\"Average kernel execution time %lf (s)\\n\", (time * 1e-9) / p.n_reps);\n  }\n\n  \n\n  int status = verify(h_in_out, h_in_backup, tiled_n * p.s, p.m, p.s);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(h_in_out);\n  free(h_finished);\n  free(h_head);\n  free(h_in_backup);\n\n  return 0;\n}"}}
{"kernel_name": "asta", "parallel_api": "sycl", "code": {"Makefile.hipsycl": "#===============================================================================\n# User Options\n#===============================================================================\n\n# Compiler can be set below, or via environment variable\nCC        = syclcc\nOPTIMIZE  = yes\nDEBUG     = no\nMARCH     = gfx906\nPLATFORM  = rocm\nDEVICE    = gpu\n\n\n#===============================================================================\n# Program name & source code list\n#===============================================================================\n\nprogram = main\n\nsource = main.cpp\n\nobj = $(source:.cpp=.o)\n\n#===============================================================================\n# Sets Flags\n#===============================================================================\n\n# Standard Flags\nCFLAGS := $(EXTRA_CFLAGS) -Wall -I../include \\\n          --hipsycl-platform=$(PLATFORM) \\\n\t  --hipsycl-gpu-arch=$(MARCH)\n\n# Linker Flags\nLDFLAGS = \n\n# Debug Flags\nifeq ($(DEBUG),yes)\n  CFLAGS += -g\n  LDFLAGS  += -g\nendif\n\n# Optimization Flags\nifeq ($(OPTIMIZE),yes)\n  CFLAGS += -O3\nendif\n\nifeq ($(DEVICE),gpu)\n  CFLAGS +=-DUSE_GPU\nendif\n#===============================================================================\n# Targets to Build\n#===============================================================================\n\n$(program): $(obj)\n\t$(CC) $(CFLAGS) $(obj) -o $@ $(LDFLAGS)\n\n%.o: %.cpp support/common.h support/timer.h support/verify.h\n\t$(CC) $(CFLAGS) -c $< -o $@\n\nclean:\n\trm -rf $(program) $(obj)\n\nrun: $(program)\n\t./$(program)\n\n", "main.cpp": "\n\n\n#include <unistd.h>\n#include <string.h>\n#include <assert.h>\n#include <vector>\n#include <algorithm>  \n\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#include \"support/common.h\"\n#include \"support/verify.h\"\n\n\n\n\nstruct Params {\n\n  int device;\n  int n_gpu_threads;\n  int n_gpu_blocks;\n  int n_warmup;\n  int n_reps;\n  int m;\n  int n;\n  int s;\n\n  Params(int argc, char **argv) {\n    device        = 0;\n    n_gpu_threads = 64;\n    n_gpu_blocks  = 16;\n    n_warmup      = 10;\n    n_reps        = 100;\n    m             = 197;\n    n             = 35588;\n    s             = 32;\n    int opt;\n    while((opt = getopt(argc, argv, \"hd:i:g:w:r:m:n:s:\")) >= 0) {\n      switch(opt) {\n        case 'h':\n          usage();\n          exit(0);\n          break;\n        case 'i': n_gpu_threads = atoi(optarg); break;\n        case 'g': n_gpu_blocks  = atoi(optarg); break;\n        case 'w': n_warmup      = atoi(optarg); break;\n        case 'r': n_reps        = atoi(optarg); break;\n        case 'm': m             = atoi(optarg); break;\n        case 'n': n             = atoi(optarg); break;\n        case 's': s             = atoi(optarg); break;\n        default:\n            fprintf(stderr, \"\\nUnrecognized option!\\n\");\n            usage();\n            exit(0);\n      }\n    }\n  }\n\n  void usage() {\n    fprintf(stderr,\n        \"\\nUsage:  ./main [options]\"\n        \"\\n\"\n        \"\\nGeneral options:\"\n        \"\\n    -h        help\"\n        \"\\n    -i <I>    # of device threads per block (default=64)\"\n        \"\\n    -g <G>    # of device blocks (default=16)\"\n        \"\\n    -w <W>    # of warmup iterations (default=10)\"\n        \"\\n    -r <R>    # of repetition iterations (default=100)\"\n        \"\\n\"\n        \"\\nBenchmark-specific options:\"\n        \"\\n    -m <M>    matrix height (default=197)\"\n        \"\\n    -n <N>    matrix width (default=35588)\"\n        \"\\n    -s <M>    super-element size (default=32)\"\n        \"\\n\");\n  }\n};\n\n\n\nvoid read_input(T *x_vector, const Params &p) {\n  int tiled_n = divceil(p.n, p.s);\n  int in_size = p.m * tiled_n * p.s;\n  srand(5432);\n  for(int i = 0; i < in_size; i++) {\n    x_vector[i] = ((T)(rand() % 100) / 100);\n  }\n}\n\ninline int atomicAdd(int& val, const int delta)\n{\n  sycl::atomic_ref<int, sycl::memory_order::relaxed, \n                   sycl::memory_scope::device,\n                   sycl::access::address_space::global_space> ref(val);\n  return ref.fetch_add(delta);\n}\n\ninline int atomicExch(int& addr, const int val) {\n  sycl::atomic_ref<int, sycl::memory_order::relaxed,\n                   sycl::memory_scope::device,\n                   sycl::access::address_space::global_space> ref(addr);\n  return ref.exchange(val);\n}\n\nint main(int argc, char **argv) {\n\n  const Params p(argc, argv);\n  int blocks = p.n_gpu_blocks;\n  int threads = p.n_gpu_threads;\n  const int max_gpu_threads = 256;\n  assert(threads <= max_gpu_threads && \n         \"The thread block size is at most 256\");\n\n  \n\n  int tiled_n       = divceil(p.n, p.s);\n  int in_size       = p.m * tiled_n * p.s;\n  int finished_size = p.m * tiled_n;\n  \n  size_t in_size_bytes = in_size * sizeof(T);\n  size_t finished_size_bytes = finished_size * sizeof(int);\n\n  T *h_in_out = (T *)malloc(in_size_bytes);\n  int *h_finished = (int *)malloc(finished_size_bytes);\n  int *h_head = (int *)malloc(sizeof(int));\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n    T *d_in_out = sycl::malloc_device<T>(in_size, q);\n  int *d_finished = sycl::malloc_device<int>(finished_size, q);\n  int *d_head = sycl::malloc_device<int>(1, q);\n\n  T *h_in_backup = (T *)malloc(in_size_bytes);\n\n  \n\n  read_input(h_in_out, p);\n  memset((void *)h_finished, 0, finished_size_bytes);\n  h_head[0] = 0;\n  memcpy(h_in_backup, h_in_out, in_size_bytes); \n\n\n  const int A = p.m;\n  const int B = tiled_n;\n  const int b = p.s;\n\n  double time = 0; \n\n  sycl::range<1> gws (blocks*threads);\n  sycl::range<1> lws (threads);\n\n  \n\n  for(int rep = 0; rep < p.n_warmup + p.n_reps; rep++) {\n    q.memcpy(d_in_out, h_in_backup, in_size_bytes);\n    q.memcpy(d_finished, h_finished, finished_size_bytes);\n    q.memcpy(d_head, h_head, sizeof(int));\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<int, 1> lmem(sycl::range<1>(2), cgh);\n      cgh.parallel_for<class asta>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n\n        const int tid = item.get_local_id(0);\n        int       m   = A * B - 1;\n\n        if(tid == 0) \n\n          lmem[1] = atomicAdd(d_head[0], 1);\n        item.barrier(sycl::access::fence_space::local_space);\n\n        while(lmem[1] < m) {\n          int next_in_cycle = (lmem[1] * A) - m * (lmem[1] / B);\n          if(next_in_cycle == lmem[1]) {\n            if(tid == 0) \n\n              lmem[1] = atomicAdd(d_head[0], 1);\n            item.barrier(sycl::access::fence_space::local_space);\n            continue;\n          }\n          T   data1, data2, data3, data4;\n          int i = tid;\n          if(i < b)\n            data1 = d_in_out[lmem[1] * b + i];\n          i += item.get_local_range(0);\n          if(i < b)\n            data2 = d_in_out[lmem[1] * b + i];\n          i += item.get_local_range(0);\n          if(i < b)\n            data3 = d_in_out[lmem[1] * b + i];\n          i += item.get_local_range(0);\n          if(i < b)\n            data4 = d_in_out[lmem[1] * b + i];\n\n          if(tid == 0) {\n            \n\n            lmem[0] = atomicAdd(d_finished[lmem[1]], 0);\n          }\n          item.barrier(sycl::access::fence_space::local_space);\n\n          for(; lmem[0] == 0; next_in_cycle = (next_in_cycle * A) - m * (next_in_cycle / B)) {\n            T backup1, backup2, backup3, backup4;\n            i = tid;\n            if(i < b)\n              backup1 = d_in_out[next_in_cycle * b + i];\n            i += item.get_local_range(0);\n            if(i < b)\n              backup2 = d_in_out[next_in_cycle * b + i];\n            i += item.get_local_range(0);\n            if(i < b)\n              backup3 = d_in_out[next_in_cycle * b + i];\n            i += item.get_local_range(0);\n            if(i < b)\n              backup4 = d_in_out[next_in_cycle * b + i];\n\n            if(tid == 0) {\n              lmem[0] = atomicExch(d_finished[next_in_cycle], (int)1);\n            }\n            item.barrier(sycl::access::fence_space::local_space);\n\n            if(!lmem[0]) {\n              i = tid;\n              if(i < b)\n                d_in_out[next_in_cycle * b + i] = data1;\n              i += item.get_local_range(0);\n              if(i < b)\n                d_in_out[next_in_cycle * b + i] = data2;\n              i += item.get_local_range(0);\n              if(i < b)\n                d_in_out[next_in_cycle * b + i] = data3;\n              i += item.get_local_range(0);\n              if(i < b)\n                d_in_out[next_in_cycle * b + i] = data4;\n            }\n            i = tid;\n            if(i < b)\n              data1 = backup1;\n            i += item.get_local_range(0);\n            if(i < b)\n              data2 = backup2;\n            i += item.get_local_range(0);\n            if(i < b)\n              data3 = backup3;\n            i += item.get_local_range(0);\n            if(i < b)\n              data4 = backup4;\n          }\n\n          if(tid == 0) \n\n            lmem[1] = atomicAdd(d_head[0], 1);\n          item.barrier(sycl::access::fence_space::local_space);\n        }\n      });\n    });\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n\n    if (rep >= p.n_warmup) \n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    q.memcpy(h_in_out, d_in_out, in_size_bytes).wait();\n  }\n\n  printf(\"Average kernel execution time %lf (s)\\n\", (time * 1e-9) / p.n_reps);\n\n  \n\n  int status = verify(h_in_out, h_in_backup, tiled_n * p.s, p.m, p.s);\n  printf(\"%s\\n\", (status == 0) ? \"PASS\" : \"FAIL\");\n\n  \n\n  free(h_in_out);\n  free(h_finished);\n  free(h_head);\n  free(h_in_backup);\n\n  sycl::free(d_in_out, q);\n  sycl::free(d_finished, q);\n  sycl::free(d_head, q);\n  return 0;\n}\n"}}
{"kernel_name": "conversion", "parallel_api": "cuda", "code": {"main.cu": "#include <algorithm>\n#include <chrono>\n#include <cstdio>\n#include <cuda.h>\n#include <cuda_bf16.h>\n#include <cuda_fp16.h>\n\ntypedef unsigned char uchar;\n\ntemplate <typename Td, typename Ts>\n__global__\nvoid cvt (      Td *__restrict__ dst,\n          const Ts *__restrict__ src,\n          const int nelems)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < nelems) {\n    dst[i] = static_cast<Td>(src[i]);\n  }\n}\n\ntemplate <typename Td, typename Ts>\nvoid convert(int nelems, int niters)\n{\n  Ts *src;\n  cudaMalloc((void**)&src, nelems * sizeof(Ts));\n  Td *dst;\n  cudaMalloc((void**)&dst, nelems * sizeof(Td));\n\n  const int ls = std::min(nelems, 256);\n  const int gs = (nelems + ls - 1) / ls;\n  dim3 grid (gs);\n  dim3 block (ls);\n\n  \n\n  cvt<Td, Ts><<<grid, block>>> (dst, src, nelems);\n  cudaDeviceSynchronize();\n\n  auto start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < niters; i++) {\n    cvt<Td, Ts> <<<grid, block>>> (dst, src, nelems);\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::high_resolution_clock::now();\n  double time = std::chrono::duration_cast<std::chrono::microseconds>\n                (end - start).count() / niters / 1.0e6;\n  double size = (sizeof(Td) + sizeof(Ts)) * nelems / 1e9;\n  printf(\"size(GB):%.2f, average time(sec):%f, BW:%f\\n\", size, time, size / time);\n\n  cudaFree(src);\n  cudaFree(dst);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int niters = atoi(argv[2]);\n\n  printf(\"bfloat16 -> half\\n\");\n  convert<half, __nv_bfloat16>(nelems, niters); \n  printf(\"bfloat16 -> float\\n\");\n  convert<float, __nv_bfloat16>(nelems, niters); \n  printf(\"bfloat16 -> int\\n\");\n  convert<int, __nv_bfloat16>(nelems, niters); \n  printf(\"bfloat16 -> char\\n\");\n  convert<char, __nv_bfloat16>(nelems, niters); \n  printf(\"bfloat16 -> uchar\\n\");\n  convert<uchar, __nv_bfloat16>(nelems, niters); \n\n  printf(\"half -> half\\n\");\n  convert<half, half>(nelems, niters); \n  printf(\"half -> float\\n\");\n  convert<float, half>(nelems, niters); \n  printf(\"half -> int\\n\");\n  convert<int, half>(nelems, niters); \n  printf(\"half -> char\\n\");\n  convert<char, half>(nelems, niters); \n  printf(\"half -> uchar\\n\");\n  convert<uchar, half>(nelems, niters); \n\n  printf(\"float -> float\\n\");\n  convert<float, float>(nelems, niters); \n  printf(\"float -> half\\n\");\n  convert<half, float>(nelems, niters); \n  printf(\"float -> int\\n\");\n  convert<int, float>(nelems, niters); \n  printf(\"float -> char\\n\");\n  convert<char, float>(nelems, niters); \n  printf(\"float -> uchar\\n\");\n  convert<uchar, float>(nelems, niters); \n\n  printf(\"int -> int\\n\");\n  convert<int, int>(nelems, niters); \n  printf(\"int -> float\\n\");\n  convert<float, int>(nelems, niters); \n  printf(\"int -> half\\n\");\n  convert<half, int>(nelems, niters); \n  printf(\"int -> char\\n\");\n  convert<char, int>(nelems, niters); \n  printf(\"int -> uchar\\n\");\n  convert<uchar, int>(nelems, niters); \n\n  printf(\"char -> int\\n\");\n  convert<int, char>(nelems, niters); \n  printf(\"char -> float\\n\");\n  convert<float, char>(nelems, niters); \n  printf(\"char -> half\\n\");\n  convert<half, char>(nelems, niters); \n  printf(\"char -> char\\n\");\n  convert<char, char>(nelems, niters); \n  printf(\"char -> uchar\\n\");\n  convert<uchar, char>(nelems, niters); \n\n  printf(\"uchar -> int\\n\");\n  convert<int, uchar>(nelems, niters); \n  printf(\"uchar -> float\\n\");\n  convert<float, uchar>(nelems, niters); \n  printf(\"uchar -> half\\n\");\n  convert<half, uchar>(nelems, niters); \n  printf(\"uchar -> char\\n\");\n  convert<char, uchar>(nelems, niters); \n  printf(\"uchar -> uchar\\n\");\n  convert<uchar, uchar>(nelems, niters); \n\n  return 0;\n}\n"}}
{"kernel_name": "conversion", "parallel_api": "hip", "code": {"main.cu": "#include <algorithm>\n#include <chrono>\n#include <cstdio>\n#include <hip/hip_runtime.h>\n#include <hip/hip_bfloat16.h>\n#include <hip/hip_fp16.h>\n\ntypedef unsigned char uchar;\n\ntemplate <typename Td, typename Ts>\n__global__\nvoid cvt (      Td *__restrict__ dst,\n          const Ts *__restrict__ src,\n          const int nelems)\n{\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < nelems) {\n    dst[i] = static_cast<Td>(src[i]);\n  }\n}\n\ntemplate <typename Td, typename Ts>\nvoid convert(int nelems, int niters)\n{\n  Ts *src;\n  hipMalloc((void**)&src, nelems * sizeof(Ts));\n  Td *dst;\n  hipMalloc((void**)&dst, nelems * sizeof(Td));\n\n  const int ls = std::min(nelems, 256);\n  const int gs = (nelems + ls - 1) / ls;\n  dim3 grid (gs);\n  dim3 block (ls);\n\n  \n\n  cvt<Td, Ts><<<grid, block>>> (dst, src, nelems);\n  hipDeviceSynchronize();\n\n  auto start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < niters; i++) {\n    cvt<Td, Ts> <<<grid, block>>> (dst, src, nelems);\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::high_resolution_clock::now();\n  double time = std::chrono::duration_cast<std::chrono::microseconds>\n                (end - start).count() / niters / 1.0e6;\n  double size = (sizeof(Td) + sizeof(Ts)) * nelems / 1e9;\n  printf(\"size(GB):%.2f, average time(sec):%f, BW:%f\\n\", size, time, size / time);\n\n  hipFree(src);\n  hipFree(dst);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int niters = atoi(argv[2]);\n\n  printf(\"bfloat16 -> half\\n\");\n  convert<half, hip_bfloat16>(nelems, niters); \n  printf(\"bfloat16 -> float\\n\");\n  convert<float, hip_bfloat16>(nelems, niters); \n  printf(\"bfloat16 -> int\\n\");\n  convert<int, hip_bfloat16>(nelems, niters); \n  printf(\"bfloat16 -> char\\n\");\n  convert<char, hip_bfloat16>(nelems, niters); \n  printf(\"bfloat16 -> uchar\\n\");\n  convert<uchar, hip_bfloat16>(nelems, niters); \n\n  printf(\"half -> half\\n\");\n  convert<half, half>(nelems, niters); \n  printf(\"half -> float\\n\");\n  convert<float, half>(nelems, niters); \n  printf(\"half -> int\\n\");\n  convert<int, half>(nelems, niters); \n  printf(\"half -> char\\n\");\n  convert<char, half>(nelems, niters); \n  printf(\"half -> uchar\\n\");\n  convert<uchar, half>(nelems, niters); \n\n  printf(\"float -> float\\n\");\n  convert<float, float>(nelems, niters); \n  printf(\"float -> half\\n\");\n  convert<half, float>(nelems, niters); \n  printf(\"float -> int\\n\");\n  convert<int, float>(nelems, niters); \n  printf(\"float -> char\\n\");\n  convert<char, float>(nelems, niters); \n  printf(\"float -> uchar\\n\");\n  convert<uchar, float>(nelems, niters); \n\n  printf(\"int -> int\\n\");\n  convert<int, int>(nelems, niters); \n  printf(\"int -> float\\n\");\n  convert<float, int>(nelems, niters); \n  printf(\"int -> half\\n\");\n  convert<half, int>(nelems, niters); \n  printf(\"int -> char\\n\");\n  convert<char, int>(nelems, niters); \n  printf(\"int -> uchar\\n\");\n  convert<uchar, int>(nelems, niters); \n\n  printf(\"char -> int\\n\");\n  convert<int, char>(nelems, niters); \n  printf(\"char -> float\\n\");\n  convert<float, char>(nelems, niters); \n  printf(\"char -> half\\n\");\n  convert<half, char>(nelems, niters); \n  printf(\"char -> char\\n\");\n  convert<char, char>(nelems, niters); \n  printf(\"char -> uchar\\n\");\n  convert<uchar, char>(nelems, niters); \n\n  printf(\"uchar -> int\\n\");\n  convert<int, uchar>(nelems, niters); \n  printf(\"uchar -> float\\n\");\n  convert<float, uchar>(nelems, niters); \n  printf(\"uchar -> half\\n\");\n  convert<half, uchar>(nelems, niters); \n  printf(\"uchar -> char\\n\");\n  convert<char, uchar>(nelems, niters); \n  printf(\"uchar -> uchar\\n\");\n  convert<uchar, uchar>(nelems, niters); \n\n  return 0;\n}\n"}}
{"kernel_name": "conversion", "parallel_api": "omp", "code": {"main.cpp": "#include <algorithm>\n#include <chrono>\n#include <cstdio>\n#include <omp.h>\n\ntypedef unsigned char uchar;\n\ntemplate <typename Td, typename Ts>\nvoid convert(int nelems, int niters)\n{\n  Ts *src = (Ts*) malloc (nelems * sizeof(Ts));\n  Td *dst = (Td*) malloc (nelems * sizeof(Td));\n\n  const int ls = std::min(nelems, 256);\n  const int gs = (nelems + ls - 1) / ls;\n\n  #pragma omp target data map(alloc: src[0:nelems], dst[0:nelems])\n  {\n    \n\n    #pragma omp target teams distribute parallel for num_teams(gs) num_threads(ls) \n    for (int i = 0; i < nelems; i++) {\n      dst[i] = static_cast<Td>(src[i]);\n    }\n\n    auto start = std::chrono::high_resolution_clock::now();\n    for (int i = 0; i < niters; i++) {\n      #pragma omp target teams distribute parallel for num_teams(gs) num_threads(ls) \n      for (int i = 0; i < nelems; i++)\n        dst[i] = static_cast<Td>(src[i]);\n    }\n    auto end = std::chrono::high_resolution_clock::now();\n    double time = std::chrono::duration_cast<std::chrono::microseconds>\n                  (end - start).count() / niters / 1.0e6;\n    double size = (sizeof(Td) + sizeof(Ts)) * nelems / 1e9;\n    printf(\"size(GB):%.2f, average time(sec):%f, BW:%f\\n\", size, time, size / time);\n  }\n  free(src);\n  free(dst);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int niters = atoi(argv[2]);\n\n\n\n\n  printf(\"float -> float\\n\");\n  convert<float, float>(nelems, niters); \n  \n\n  \n\n  printf(\"float -> int\\n\");\n  convert<int, float>(nelems, niters); \n  printf(\"float -> char\\n\");\n  convert<char, float>(nelems, niters); \n  printf(\"float -> uchar\\n\");\n  convert<uchar, float>(nelems, niters); \n\n  printf(\"int -> int\\n\");\n  convert<int, int>(nelems, niters); \n  printf(\"int -> float\\n\");\n  convert<float, int>(nelems, niters); \n  \n\n  \n\n  printf(\"int -> char\\n\");\n  convert<char, int>(nelems, niters); \n  printf(\"int -> uchar\\n\");\n  convert<uchar, int>(nelems, niters); \n\n  printf(\"char -> int\\n\");\n  convert<int, char>(nelems, niters); \n  printf(\"char -> float\\n\");\n  convert<float, char>(nelems, niters); \n  \n\n  \n\n  printf(\"char -> char\\n\");\n  convert<char, char>(nelems, niters); \n  printf(\"char -> uchar\\n\");\n  convert<uchar, char>(nelems, niters); \n\n  printf(\"uchar -> int\\n\");\n  convert<int, uchar>(nelems, niters); \n  printf(\"uchar -> float\\n\");\n  convert<float, uchar>(nelems, niters); \n  \n\n  \n\n  printf(\"uchar -> char\\n\");\n  convert<char, uchar>(nelems, niters); \n  printf(\"uchar -> uchar\\n\");\n  convert<uchar, uchar>(nelems, niters); \n\n  return 0;\n}\n"}}
{"kernel_name": "conversion", "parallel_api": "serial", "code": {"main.cpp": "#include <algorithm>\n#include <chrono>\n#include <cstdio>\n\ntypedef unsigned char uchar;\n\ntemplate <typename Td, typename Ts>\nvoid convert(int nelems, int niters)\n{\n  Ts *src = (Ts*) malloc (nelems * sizeof(Ts));\n  Td *dst = (Td*) malloc (nelems * sizeof(Td));\n\n  const int ls = std::min(nelems, 256);\n  const int gs = (nelems + ls - 1) / ls;\n\n    {\n    \n\n        for (int i = 0; i < nelems; i++) {\n      dst[i] = static_cast<Td>(src[i]);\n    }\n\n    auto start = std::chrono::high_resolution_clock::now();\n    for (int i = 0; i < niters; i++) {\n            for (int i = 0; i < nelems; i++)\n        dst[i] = static_cast<Td>(src[i]);\n    }\n    auto end = std::chrono::high_resolution_clock::now();\n    double time = std::chrono::duration_cast<std::chrono::microseconds>\n                  (end - start).count() / niters / 1.0e6;\n    double size = (sizeof(Td) + sizeof(Ts)) * nelems / 1e9;\n    printf(\"size(GB):%.2f, average time(sec):%f, BW:%f\\n\", size, time, size / time);\n  }\n  free(src);\n  free(dst);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int niters = atoi(argv[2]);\n\n\n\n\n  printf(\"float -> float\\n\");\n  convert<float, float>(nelems, niters); \n  \n\n  \n\n  printf(\"float -> int\\n\");\n  convert<int, float>(nelems, niters); \n  printf(\"float -> char\\n\");\n  convert<char, float>(nelems, niters); \n  printf(\"float -> uchar\\n\");\n  convert<uchar, float>(nelems, niters); \n\n  printf(\"int -> int\\n\");\n  convert<int, int>(nelems, niters); \n  printf(\"int -> float\\n\");\n  convert<float, int>(nelems, niters); \n  \n\n  \n\n  printf(\"int -> char\\n\");\n  convert<char, int>(nelems, niters); \n  printf(\"int -> uchar\\n\");\n  convert<uchar, int>(nelems, niters); \n\n  printf(\"char -> int\\n\");\n  convert<int, char>(nelems, niters); \n  printf(\"char -> float\\n\");\n  convert<float, char>(nelems, niters); \n  \n\n  \n\n  printf(\"char -> char\\n\");\n  convert<char, char>(nelems, niters); \n  printf(\"char -> uchar\\n\");\n  convert<uchar, char>(nelems, niters); \n\n  printf(\"uchar -> int\\n\");\n  convert<int, uchar>(nelems, niters); \n  printf(\"uchar -> float\\n\");\n  convert<float, uchar>(nelems, niters); \n  \n\n  \n\n  printf(\"uchar -> char\\n\");\n  convert<char, uchar>(nelems, niters); \n  printf(\"uchar -> uchar\\n\");\n  convert<uchar, uchar>(nelems, niters); \n\n  return 0;\n}"}}
{"kernel_name": "conversion", "parallel_api": "sycl", "code": {"main.cpp": "#include <algorithm>\n#include <chrono>\n#include <cstddef>\n#include <cstdio>\n#include <sycl/sycl.hpp>\n\nusing sycl::ext::oneapi::bfloat16;\nusing sycl::half;\ntypedef unsigned char uchar;\n\ntemplate <typename Td, typename Ts>\nvoid convert(sycl::queue &q, int nelems, int niters)\n{\n  Ts *src = sycl::malloc_device<Ts>(nelems, q);\n  Td *dst = sycl::malloc_device<Td>(nelems, q);\n\n  const int ls = std::min(nelems, 256);\n  const int gs = (nelems + ls - 1) / ls * ls;\n  sycl::range<1> gws (gs);\n  sycl::range<1> lws (ls);\n\n  \n\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n      const int i = item.get_global_id(0);\n      if (i < nelems) {\n        dst[i] = static_cast<Td>(src[i]);\n      }\n    });\n  }).wait();\n\n  const auto start = std::chrono::high_resolution_clock::now();\n  for (int i = 0; i < niters; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for(sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i < nelems) {\n          dst[i] = static_cast<Td>(src[i]);\n        }\n      });\n    });\n  }\n  q.wait();\n  const auto end = std::chrono::high_resolution_clock::now();\n  const double time = std::chrono::duration_cast<std::chrono::microseconds>\n                (end - start).count() / niters / 1.0e6f;\n  const double size = (sizeof(Td) + sizeof(Ts)) * nelems / 1e9;\n  std::printf(\"size(GB):%.2f, average time(sec):%f, BW:%f\\n\", size, time, size / time);\n\n  sycl::free(src, q);\n  sycl::free(dst, q);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 3) {\n    printf(\"Usage: %s <number of elements> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int nelems = atoi(argv[1]);\n  const int niters = atoi(argv[2]);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  std::printf(\"bfloat16 -> half\\n\");\n  convert<half, bfloat16>(q, nelems, niters);\n  std::printf(\"bfloat16 -> float\\n\");\n  convert<float, bfloat16>(q, nelems, niters);\n  std::printf(\"bfloat16 -> int\\n\");\n  convert<int, bfloat16>(q, nelems, niters);\n  std::printf(\"bfloat16 -> char\\n\");\n  convert<char, bfloat16>(q, nelems, niters);\n  std::printf(\"bfloat16 -> unsigned char\\n\");\n  convert<uchar, bfloat16>(q, nelems, niters);\n\n  std::printf(\"half -> half\\n\");\n  convert<half, half>(q, nelems, niters);\n  std::printf(\"half -> float\\n\");\n  convert<float, half>(q, nelems, niters);\n  std::printf(\"half -> int\\n\");\n  convert<int, half>(q, nelems, niters);\n  std::printf(\"half -> char\\n\");\n  convert<char, half>(q, nelems, niters);\n  std::printf(\"half -> uchar\\n\");\n  convert<uchar, half>(q, nelems, niters);\n\n  std::printf(\"float -> float\\n\");\n  convert<float, float>(q, nelems, niters);\n  std::printf(\"float -> half\\n\");\n  convert<half, float>(q, nelems, niters);\n  std::printf(\"float -> int\\n\");\n  convert<int, float>(q, nelems, niters);\n  std::printf(\"float -> char\\n\");\n  convert<char, float>(q, nelems, niters);\n  std::printf(\"float -> uchar\\n\");\n  convert<uchar, float>(q, nelems, niters);\n\n  std::printf(\"int -> int\\n\");\n  convert<int, int>(q, nelems, niters);\n  std::printf(\"int -> float\\n\");\n  convert<float, int>(q, nelems, niters);\n  std::printf(\"int -> half\\n\");\n  convert<half, int>(q, nelems, niters);\n  std::printf(\"int -> char\\n\");\n  convert<char, int>(q, nelems, niters);\n  std::printf(\"int -> uchar\\n\");\n  convert<uchar, int>(q, nelems, niters);\n\n  std::printf(\"char -> int\\n\");\n  convert<int, char>(q, nelems, niters);\n  std::printf(\"char -> float\\n\");\n  convert<float, char>(q, nelems, niters);\n  std::printf(\"char -> half\\n\");\n  convert<half, char>(q, nelems, niters);\n  std::printf(\"char -> char\\n\");\n  convert<char, char>(q, nelems, niters);\n  std::printf(\"char -> uchar\\n\");\n  convert<uchar, char>(q, nelems, niters);\n\n  std::printf(\"uchar -> int\\n\");\n  convert<int, uchar>(q, nelems, niters);\n  std::printf(\"uchar -> float\\n\");\n  convert<float, uchar>(q, nelems, niters);\n  std::printf(\"uchar -> half\\n\");\n  convert<half, uchar>(q, nelems, niters);\n  std::printf(\"uchar -> char\\n\");\n  convert<char, uchar>(q, nelems, niters);\n  std::printf(\"uchar -> uchar\\n\");\n  convert<uchar, uchar>(q, nelems, niters);\n\n  return 0;\n}\n"}}
{"kernel_name": "interleave", "parallel_api": "cuda", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n\n#define NUM_ELEMENTS 4096\n#define COUNT 4096       \n\n\n\n\ntypedef struct\n{\n  unsigned int s0;\n  unsigned int s1;\n  unsigned int s2;\n  unsigned int s3;\n  unsigned int s4;\n  unsigned int s5;\n  unsigned int s6;\n  unsigned int s7;\n  unsigned int s8;\n  unsigned int s9;\n  unsigned int sa;\n  unsigned int sb;\n  unsigned int sc;\n  unsigned int sd;\n  unsigned int se;\n  unsigned int sf;\n} INTERLEAVED_T;\n\n\n\ntypedef INTERLEAVED_T INTERLEAVED_ARRAY_T[NUM_ELEMENTS];\n\n\n\ntypedef unsigned int ARRAY_MEMBER_T[NUM_ELEMENTS];\ntypedef struct\n{\n  ARRAY_MEMBER_T s0;\n  ARRAY_MEMBER_T s1;\n  ARRAY_MEMBER_T s2;\n  ARRAY_MEMBER_T s3;\n  ARRAY_MEMBER_T s4;\n  ARRAY_MEMBER_T s5;\n  ARRAY_MEMBER_T s6;\n  ARRAY_MEMBER_T s7;\n  ARRAY_MEMBER_T s8;\n  ARRAY_MEMBER_T s9;\n  ARRAY_MEMBER_T sa;\n  ARRAY_MEMBER_T sb;\n  ARRAY_MEMBER_T sc;\n  ARRAY_MEMBER_T sd;\n  ARRAY_MEMBER_T se;\n  ARRAY_MEMBER_T sf;\n} NON_INTERLEAVED_T;\n\n\n\n#include \"util.cpp\"\n\n__global__ void add_kernel_interleaved(\n    INTERLEAVED_T * const dest_ptr,\n    const INTERLEAVED_T * const src_ptr,\n    const unsigned int num_elements)\n{\n  const unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid < num_elements)\n  {\n    for (unsigned int i=0; i<COUNT; i++)\n    {\n      dest_ptr[tid].s0 += src_ptr[tid].s0;\n      dest_ptr[tid].s1 += src_ptr[tid].s1;\n      dest_ptr[tid].s2 += src_ptr[tid].s2;\n      dest_ptr[tid].s3 += src_ptr[tid].s3;\n      dest_ptr[tid].s4 += src_ptr[tid].s4;\n      dest_ptr[tid].s5 += src_ptr[tid].s5;\n      dest_ptr[tid].s6 += src_ptr[tid].s6;\n      dest_ptr[tid].s7 += src_ptr[tid].s7;\n      dest_ptr[tid].s8 += src_ptr[tid].s8;\n      dest_ptr[tid].s9 += src_ptr[tid].s9;\n      dest_ptr[tid].sa += src_ptr[tid].sa;\n      dest_ptr[tid].sb += src_ptr[tid].sb;\n      dest_ptr[tid].sc += src_ptr[tid].sc;\n      dest_ptr[tid].sd += src_ptr[tid].sd;\n      dest_ptr[tid].se += src_ptr[tid].se;\n      dest_ptr[tid].sf += src_ptr[tid].sf;\n    }\n  }\n}\n\n__global__ void add_kernel_non_interleaved(\n    NON_INTERLEAVED_T * const dest_ptr,\n    const NON_INTERLEAVED_T * const src_ptr,\n    const unsigned int num_elements)\n{\n  const unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid < num_elements)\n  {\n    for (unsigned int i=0; i<COUNT; i++)\n    {\n      dest_ptr->s0[tid] += src_ptr->s0[tid];\n      dest_ptr->s1[tid] += src_ptr->s1[tid];\n      dest_ptr->s2[tid] += src_ptr->s2[tid];\n      dest_ptr->s3[tid] += src_ptr->s3[tid];\n      dest_ptr->s4[tid] += src_ptr->s4[tid];\n      dest_ptr->s5[tid] += src_ptr->s5[tid];\n      dest_ptr->s6[tid] += src_ptr->s6[tid];\n      dest_ptr->s7[tid] += src_ptr->s7[tid];\n      dest_ptr->s8[tid] += src_ptr->s8[tid];\n      dest_ptr->s9[tid] += src_ptr->s9[tid];\n      dest_ptr->sa[tid] += src_ptr->sa[tid];\n      dest_ptr->sb[tid] += src_ptr->sb[tid];\n      dest_ptr->sc[tid] += src_ptr->sc[tid];\n      dest_ptr->sd[tid] += src_ptr->sd[tid];\n      dest_ptr->se[tid] += src_ptr->se[tid];\n      dest_ptr->sf[tid] += src_ptr->sf[tid];\n    }\n  }\n}\n\nvoid add_test_interleaved(\n    INTERLEAVED_T * const h_dst,\n    const INTERLEAVED_T * const h_src,\n    const int repeat,\n    const unsigned int num_elements)\n{\n  \n\n  const unsigned int num_threads = 256;\n  const unsigned int num_blocks = (num_elements + (num_threads-1)) / num_threads;\n\n  \n\n  const size_t num_bytes = (sizeof(INTERLEAVED_T) * num_elements);\n  INTERLEAVED_T * d_dst;\n  INTERLEAVED_T * d_src;\n  cudaMalloc((void **) &d_src, num_bytes);\n  cudaMalloc((void **) &d_dst, num_bytes);\n  cudaMemcpy(d_src, h_src, num_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_dst, h_dst, num_bytes, cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++)\n    add_kernel_interleaved<<<num_blocks, num_threads>>>(d_dst, d_src, num_elements);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel (interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(h_dst, d_dst, num_bytes, cudaMemcpyDeviceToHost);\n  cudaFree(d_src);\n  cudaFree(d_dst);\n}\n\nvoid add_test_non_interleaved(\n    NON_INTERLEAVED_T * const h_dst,\n    const NON_INTERLEAVED_T * const h_src,\n    const int repeat,\n    const unsigned int num_elements)\n{\n  \n\n  const unsigned int num_threads = 256;\n  const unsigned int num_blocks = (num_elements + (num_threads-1)) / num_threads;\n  \n\n  const size_t num_bytes = sizeof(NON_INTERLEAVED_T);\n  \n\n  NON_INTERLEAVED_T * d_dst;\n  NON_INTERLEAVED_T * d_src;\n  cudaMalloc((void **) &d_src, num_bytes);\n  cudaMalloc((void **) &d_dst, num_bytes);\n  cudaMemcpy(d_src, h_src, num_bytes, cudaMemcpyHostToDevice);\n  cudaMemcpy(d_dst, h_dst, num_bytes, cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++)\n    add_kernel_non_interleaved<<<num_blocks, num_threads>>>(d_dst, d_src, num_elements);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel (non-interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  cudaMemcpy(h_dst, d_dst, num_bytes, cudaMemcpyDeviceToHost);\n  cudaFree(d_src);\n  cudaFree(d_dst);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  NON_INTERLEAVED_T non_interleaved_src, non_interleaved_dst; \n  INTERLEAVED_ARRAY_T interleaved_src, interleaved_dst; \n  initialize (interleaved_src, interleaved_dst, \n              non_interleaved_src, non_interleaved_dst, NUM_ELEMENTS);\n  add_test_non_interleaved(&non_interleaved_dst, &non_interleaved_src,\n                           repeat, NUM_ELEMENTS);\n  add_test_interleaved(interleaved_dst, interleaved_src, repeat, NUM_ELEMENTS);\n  verify(interleaved_dst, non_interleaved_dst, NUM_ELEMENTS);\n  return 0;\n}\n"}}
{"kernel_name": "interleave", "parallel_api": "hip", "code": {"main.cu": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define NUM_ELEMENTS 4096\n#define COUNT 4096       \n\n\n\n\ntypedef struct\n{\n  unsigned int s0;\n  unsigned int s1;\n  unsigned int s2;\n  unsigned int s3;\n  unsigned int s4;\n  unsigned int s5;\n  unsigned int s6;\n  unsigned int s7;\n  unsigned int s8;\n  unsigned int s9;\n  unsigned int sa;\n  unsigned int sb;\n  unsigned int sc;\n  unsigned int sd;\n  unsigned int se;\n  unsigned int sf;\n} INTERLEAVED_T;\n\n\n\ntypedef INTERLEAVED_T INTERLEAVED_ARRAY_T[NUM_ELEMENTS];\n\n\n\ntypedef unsigned int ARRAY_MEMBER_T[NUM_ELEMENTS];\ntypedef struct\n{\n  ARRAY_MEMBER_T s0;\n  ARRAY_MEMBER_T s1;\n  ARRAY_MEMBER_T s2;\n  ARRAY_MEMBER_T s3;\n  ARRAY_MEMBER_T s4;\n  ARRAY_MEMBER_T s5;\n  ARRAY_MEMBER_T s6;\n  ARRAY_MEMBER_T s7;\n  ARRAY_MEMBER_T s8;\n  ARRAY_MEMBER_T s9;\n  ARRAY_MEMBER_T sa;\n  ARRAY_MEMBER_T sb;\n  ARRAY_MEMBER_T sc;\n  ARRAY_MEMBER_T sd;\n  ARRAY_MEMBER_T se;\n  ARRAY_MEMBER_T sf;\n} NON_INTERLEAVED_T;\n\n\n\n#include \"util.cpp\"\n\n__global__ void add_kernel_interleaved(\n    INTERLEAVED_T * const dest_ptr,\n    const INTERLEAVED_T * const src_ptr,\n    const unsigned int num_elements)\n{\n  const unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid < num_elements)\n  {\n    for (unsigned int i=0; i<COUNT; i++)\n    {\n      dest_ptr[tid].s0 += src_ptr[tid].s0;\n      dest_ptr[tid].s1 += src_ptr[tid].s1;\n      dest_ptr[tid].s2 += src_ptr[tid].s2;\n      dest_ptr[tid].s3 += src_ptr[tid].s3;\n      dest_ptr[tid].s4 += src_ptr[tid].s4;\n      dest_ptr[tid].s5 += src_ptr[tid].s5;\n      dest_ptr[tid].s6 += src_ptr[tid].s6;\n      dest_ptr[tid].s7 += src_ptr[tid].s7;\n      dest_ptr[tid].s8 += src_ptr[tid].s8;\n      dest_ptr[tid].s9 += src_ptr[tid].s9;\n      dest_ptr[tid].sa += src_ptr[tid].sa;\n      dest_ptr[tid].sb += src_ptr[tid].sb;\n      dest_ptr[tid].sc += src_ptr[tid].sc;\n      dest_ptr[tid].sd += src_ptr[tid].sd;\n      dest_ptr[tid].se += src_ptr[tid].se;\n      dest_ptr[tid].sf += src_ptr[tid].sf;\n    }\n  }\n}\n\n__global__ void add_kernel_non_interleaved(\n    NON_INTERLEAVED_T * const dest_ptr,\n    const NON_INTERLEAVED_T * const src_ptr,\n    const unsigned int num_elements)\n{\n  const unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid < num_elements)\n  {\n    for (unsigned int i=0; i<COUNT; i++)\n    {\n      dest_ptr->s0[tid] += src_ptr->s0[tid];\n      dest_ptr->s1[tid] += src_ptr->s1[tid];\n      dest_ptr->s2[tid] += src_ptr->s2[tid];\n      dest_ptr->s3[tid] += src_ptr->s3[tid];\n      dest_ptr->s4[tid] += src_ptr->s4[tid];\n      dest_ptr->s5[tid] += src_ptr->s5[tid];\n      dest_ptr->s6[tid] += src_ptr->s6[tid];\n      dest_ptr->s7[tid] += src_ptr->s7[tid];\n      dest_ptr->s8[tid] += src_ptr->s8[tid];\n      dest_ptr->s9[tid] += src_ptr->s9[tid];\n      dest_ptr->sa[tid] += src_ptr->sa[tid];\n      dest_ptr->sb[tid] += src_ptr->sb[tid];\n      dest_ptr->sc[tid] += src_ptr->sc[tid];\n      dest_ptr->sd[tid] += src_ptr->sd[tid];\n      dest_ptr->se[tid] += src_ptr->se[tid];\n      dest_ptr->sf[tid] += src_ptr->sf[tid];\n    }\n  }\n}\n\nvoid add_test_interleaved(\n    INTERLEAVED_T * const h_dst,\n    const INTERLEAVED_T * const h_src,\n    const int repeat,\n    const unsigned int num_elements)\n{\n  \n\n  const unsigned int num_threads = 256;\n  const unsigned int num_blocks = (num_elements + (num_threads-1)) / num_threads;\n\n  \n\n  const size_t num_bytes = (sizeof(INTERLEAVED_T) * num_elements);\n  INTERLEAVED_T * d_dst;\n  INTERLEAVED_T * d_src;\n  hipMalloc((void **) &d_src, num_bytes);\n  hipMalloc((void **) &d_dst, num_bytes);\n  hipMemcpy(d_src, h_src, num_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_dst, h_dst, num_bytes, hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++)\n    hipLaunchKernelGGL(add_kernel_interleaved, num_blocks, num_threads, 0, 0, d_dst, d_src, num_elements);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel (interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(h_dst, d_dst, num_bytes, hipMemcpyDeviceToHost);\n  hipFree(d_src);\n  hipFree(d_dst);\n}\n\nvoid add_test_non_interleaved(\n    NON_INTERLEAVED_T * const h_dst,\n    const NON_INTERLEAVED_T * const h_src,\n    const int repeat,\n    const unsigned int num_elements)\n{\n  \n\n  const unsigned int num_threads = 256;\n  const unsigned int num_blocks = (num_elements + (num_threads-1)) / num_threads;\n  \n\n  const size_t num_bytes = sizeof(NON_INTERLEAVED_T);\n  \n\n  NON_INTERLEAVED_T * d_dst;\n  NON_INTERLEAVED_T * d_src;\n  hipMalloc((void **) &d_src, num_bytes);\n  hipMalloc((void **) &d_dst, num_bytes);\n  hipMemcpy(d_src, h_src, num_bytes, hipMemcpyHostToDevice);\n  hipMemcpy(d_dst, h_dst, num_bytes, hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++)\n    hipLaunchKernelGGL(add_kernel_non_interleaved, num_blocks, num_threads, 0, 0, d_dst, d_src, num_elements);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel (non-interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  hipMemcpy(h_dst, d_dst, num_bytes, hipMemcpyDeviceToHost);\n  hipFree(d_src);\n  hipFree(d_dst);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  NON_INTERLEAVED_T non_interleaved_src, non_interleaved_dst; \n  INTERLEAVED_ARRAY_T interleaved_src, interleaved_dst; \n  initialize (interleaved_src, interleaved_dst, \n              non_interleaved_src, non_interleaved_dst, NUM_ELEMENTS);\n  add_test_non_interleaved(&non_interleaved_dst, &non_interleaved_src,\n                           repeat, NUM_ELEMENTS);\n  add_test_interleaved(interleaved_dst, interleaved_src, repeat, NUM_ELEMENTS);\n  verify(interleaved_dst, non_interleaved_dst, NUM_ELEMENTS);\n  return 0;\n}\n"}}
{"kernel_name": "interleave", "parallel_api": "omp", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <omp.h>\n\n#define NUM_ELEMENTS 4096\n#define COUNT 4096       \n\n\n\n\ntypedef struct\n{\n  unsigned int s0;\n  unsigned int s1;\n  unsigned int s2;\n  unsigned int s3;\n  unsigned int s4;\n  unsigned int s5;\n  unsigned int s6;\n  unsigned int s7;\n  unsigned int s8;\n  unsigned int s9;\n  unsigned int sa;\n  unsigned int sb;\n  unsigned int sc;\n  unsigned int sd;\n  unsigned int se;\n  unsigned int sf;\n} INTERLEAVED_T;\n\n\n\ntypedef INTERLEAVED_T INTERLEAVED_ARRAY_T[NUM_ELEMENTS];\n\n\n\ntypedef unsigned int ARRAY_MEMBER_T[NUM_ELEMENTS];\ntypedef struct\n{\n  ARRAY_MEMBER_T s0;\n  ARRAY_MEMBER_T s1;\n  ARRAY_MEMBER_T s2;\n  ARRAY_MEMBER_T s3;\n  ARRAY_MEMBER_T s4;\n  ARRAY_MEMBER_T s5;\n  ARRAY_MEMBER_T s6;\n  ARRAY_MEMBER_T s7;\n  ARRAY_MEMBER_T s8;\n  ARRAY_MEMBER_T s9;\n  ARRAY_MEMBER_T sa;\n  ARRAY_MEMBER_T sb;\n  ARRAY_MEMBER_T sc;\n  ARRAY_MEMBER_T sd;\n  ARRAY_MEMBER_T se;\n  ARRAY_MEMBER_T sf;\n} NON_INTERLEAVED_T;\n\n\n\n#include \"util.cpp\"\n\nvoid add_test_interleaved(\n    INTERLEAVED_T * const h_dst,\n    const INTERLEAVED_T * const h_src,\n    const unsigned int repeat,\n    const unsigned int num_elements)\n{\n  #pragma omp target data map(to: h_src[0:num_elements]) map(tofrom: h_dst[0:num_elements]) \n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (unsigned int tid = 0; tid < num_elements; tid++)\n      {\n        for (unsigned int i=0; i<COUNT; i++)\n        {\n          h_dst[tid].s0 += h_src[tid].s0;\n          h_dst[tid].s1 += h_src[tid].s1;\n          h_dst[tid].s2 += h_src[tid].s2;\n          h_dst[tid].s3 += h_src[tid].s3;\n          h_dst[tid].s4 += h_src[tid].s4;\n          h_dst[tid].s5 += h_src[tid].s5;\n          h_dst[tid].s6 += h_src[tid].s6;\n          h_dst[tid].s7 += h_src[tid].s7;\n          h_dst[tid].s8 += h_src[tid].s8;\n          h_dst[tid].s9 += h_src[tid].s9;\n          h_dst[tid].sa += h_src[tid].sa;\n          h_dst[tid].sb += h_src[tid].sb;\n          h_dst[tid].sc += h_src[tid].sc;\n          h_dst[tid].sd += h_src[tid].sd;\n          h_dst[tid].se += h_src[tid].se;\n          h_dst[tid].sf += h_src[tid].sf;\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel (interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n}\n\nvoid add_test_non_interleaved(\n    NON_INTERLEAVED_T * const h_dst,\n    const NON_INTERLEAVED_T * const h_src,\n    const unsigned int repeat,\n    const unsigned int num_elements)\n{\n  #pragma omp target data map(to: h_src[0:1]) map(tofrom: h_dst[0:1]) \n  {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n      #pragma omp target teams distribute parallel for thread_limit(256)\n      for (unsigned int tid = 0; tid < num_elements; tid++)\n      {\n        for (unsigned int i=0; i<COUNT; i++)\n        {\n          h_dst->s0[tid] += h_src->s0[tid];\n          h_dst->s1[tid] += h_src->s1[tid];\n          h_dst->s2[tid] += h_src->s2[tid];\n          h_dst->s3[tid] += h_src->s3[tid];\n          h_dst->s4[tid] += h_src->s4[tid];\n          h_dst->s5[tid] += h_src->s5[tid];\n          h_dst->s6[tid] += h_src->s6[tid];\n          h_dst->s7[tid] += h_src->s7[tid];\n          h_dst->s8[tid] += h_src->s8[tid];\n          h_dst->s9[tid] += h_src->s9[tid];\n          h_dst->sa[tid] += h_src->sa[tid];\n          h_dst->sb[tid] += h_src->sb[tid];\n          h_dst->sc[tid] += h_src->sc[tid];\n          h_dst->sd[tid] += h_src->sd[tid];\n          h_dst->se[tid] += h_src->se[tid];\n          h_dst->sf[tid] += h_src->sf[tid];\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel (non-interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  NON_INTERLEAVED_T non_interleaved_src, non_interleaved_dst; \n  INTERLEAVED_ARRAY_T interleaved_src, interleaved_dst; \n  initialize (interleaved_src, interleaved_dst,\n              non_interleaved_src, non_interleaved_dst, NUM_ELEMENTS);\n  add_test_non_interleaved(&non_interleaved_dst, &non_interleaved_src,\n                           repeat, NUM_ELEMENTS);\n  add_test_interleaved(interleaved_dst, interleaved_src, repeat, NUM_ELEMENTS);\n  verify(interleaved_dst, non_interleaved_dst, NUM_ELEMENTS);\n  return 0;\n}\n"}}
{"kernel_name": "interleave", "parallel_api": "serial", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#define NUM_ELEMENTS 4096\n#define COUNT 4096       \n\n\n\n\ntypedef struct\n{\n  unsigned int s0;\n  unsigned int s1;\n  unsigned int s2;\n  unsigned int s3;\n  unsigned int s4;\n  unsigned int s5;\n  unsigned int s6;\n  unsigned int s7;\n  unsigned int s8;\n  unsigned int s9;\n  unsigned int sa;\n  unsigned int sb;\n  unsigned int sc;\n  unsigned int sd;\n  unsigned int se;\n  unsigned int sf;\n} INTERLEAVED_T;\n\n\n\ntypedef INTERLEAVED_T INTERLEAVED_ARRAY_T[NUM_ELEMENTS];\n\n\n\ntypedef unsigned int ARRAY_MEMBER_T[NUM_ELEMENTS];\ntypedef struct\n{\n  ARRAY_MEMBER_T s0;\n  ARRAY_MEMBER_T s1;\n  ARRAY_MEMBER_T s2;\n  ARRAY_MEMBER_T s3;\n  ARRAY_MEMBER_T s4;\n  ARRAY_MEMBER_T s5;\n  ARRAY_MEMBER_T s6;\n  ARRAY_MEMBER_T s7;\n  ARRAY_MEMBER_T s8;\n  ARRAY_MEMBER_T s9;\n  ARRAY_MEMBER_T sa;\n  ARRAY_MEMBER_T sb;\n  ARRAY_MEMBER_T sc;\n  ARRAY_MEMBER_T sd;\n  ARRAY_MEMBER_T se;\n  ARRAY_MEMBER_T sf;\n} NON_INTERLEAVED_T;\n\n\n\n#include \"util.cpp\"\n\nvoid add_test_interleaved(\n    INTERLEAVED_T * const h_dst,\n    const INTERLEAVED_T * const h_src,\n    const unsigned int repeat,\n    const unsigned int num_elements)\n{\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n            for (unsigned int tid = 0; tid < num_elements; tid++)\n      {\n        for (unsigned int i=0; i<COUNT; i++)\n        {\n          h_dst[tid].s0 += h_src[tid].s0;\n          h_dst[tid].s1 += h_src[tid].s1;\n          h_dst[tid].s2 += h_src[tid].s2;\n          h_dst[tid].s3 += h_src[tid].s3;\n          h_dst[tid].s4 += h_src[tid].s4;\n          h_dst[tid].s5 += h_src[tid].s5;\n          h_dst[tid].s6 += h_src[tid].s6;\n          h_dst[tid].s7 += h_src[tid].s7;\n          h_dst[tid].s8 += h_src[tid].s8;\n          h_dst[tid].s9 += h_src[tid].s9;\n          h_dst[tid].sa += h_src[tid].sa;\n          h_dst[tid].sb += h_src[tid].sb;\n          h_dst[tid].sc += h_src[tid].sc;\n          h_dst[tid].sd += h_src[tid].sd;\n          h_dst[tid].se += h_src[tid].se;\n          h_dst[tid].sf += h_src[tid].sf;\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel (interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n}\n\nvoid add_test_non_interleaved(\n    NON_INTERLEAVED_T * const h_dst,\n    const NON_INTERLEAVED_T * const h_src,\n    const unsigned int repeat,\n    const unsigned int num_elements)\n{\n    {\n    auto start = std::chrono::steady_clock::now();\n\n    for (int n = 0; n < repeat; n++) {\n            for (unsigned int tid = 0; tid < num_elements; tid++)\n      {\n        for (unsigned int i=0; i<COUNT; i++)\n        {\n          h_dst->s0[tid] += h_src->s0[tid];\n          h_dst->s1[tid] += h_src->s1[tid];\n          h_dst->s2[tid] += h_src->s2[tid];\n          h_dst->s3[tid] += h_src->s3[tid];\n          h_dst->s4[tid] += h_src->s4[tid];\n          h_dst->s5[tid] += h_src->s5[tid];\n          h_dst->s6[tid] += h_src->s6[tid];\n          h_dst->s7[tid] += h_src->s7[tid];\n          h_dst->s8[tid] += h_src->s8[tid];\n          h_dst->s9[tid] += h_src->s9[tid];\n          h_dst->sa[tid] += h_src->sa[tid];\n          h_dst->sb[tid] += h_src->sb[tid];\n          h_dst->sc[tid] += h_src->sc[tid];\n          h_dst->sd[tid] += h_src->sd[tid];\n          h_dst->se[tid] += h_src->se[tid];\n          h_dst->sf[tid] += h_src->sf[tid];\n        }\n      }\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Average kernel (non-interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n  }\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  NON_INTERLEAVED_T non_interleaved_src, non_interleaved_dst; \n  INTERLEAVED_ARRAY_T interleaved_src, interleaved_dst; \n  initialize (interleaved_src, interleaved_dst,\n              non_interleaved_src, non_interleaved_dst, NUM_ELEMENTS);\n  add_test_non_interleaved(&non_interleaved_dst, &non_interleaved_src,\n                           repeat, NUM_ELEMENTS);\n  add_test_interleaved(interleaved_dst, interleaved_src, repeat, NUM_ELEMENTS);\n  verify(interleaved_dst, non_interleaved_dst, NUM_ELEMENTS);\n  return 0;\n}"}}
{"kernel_name": "interleave", "parallel_api": "sycl", "code": {"main.cpp": "\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <sycl/sycl.hpp>\n\n#define NUM_ELEMENTS 4096\n#define COUNT 4096       \n\n\n\n\ntypedef struct\n{\n  unsigned int s0;\n  unsigned int s1;\n  unsigned int s2;\n  unsigned int s3;\n  unsigned int s4;\n  unsigned int s5;\n  unsigned int s6;\n  unsigned int s7;\n  unsigned int s8;\n  unsigned int s9;\n  unsigned int sa;\n  unsigned int sb;\n  unsigned int sc;\n  unsigned int sd;\n  unsigned int se;\n  unsigned int sf;\n} INTERLEAVED_T;\n\n\n\ntypedef INTERLEAVED_T INTERLEAVED_ARRAY_T[NUM_ELEMENTS];\n\n\n\ntypedef unsigned int ARRAY_MEMBER_T[NUM_ELEMENTS];\ntypedef struct\n{\n  ARRAY_MEMBER_T s0;\n  ARRAY_MEMBER_T s1;\n  ARRAY_MEMBER_T s2;\n  ARRAY_MEMBER_T s3;\n  ARRAY_MEMBER_T s4;\n  ARRAY_MEMBER_T s5;\n  ARRAY_MEMBER_T s6;\n  ARRAY_MEMBER_T s7;\n  ARRAY_MEMBER_T s8;\n  ARRAY_MEMBER_T s9;\n  ARRAY_MEMBER_T sa;\n  ARRAY_MEMBER_T sb;\n  ARRAY_MEMBER_T sc;\n  ARRAY_MEMBER_T sd;\n  ARRAY_MEMBER_T se;\n  ARRAY_MEMBER_T sf;\n} NON_INTERLEAVED_T;\n\n\n\n#include \"util.cpp\"\n\nvoid add_test_interleaved(\n    sycl::queue &q,\n    INTERLEAVED_T * const h_dst,\n    const INTERLEAVED_T * const h_src,\n    const int repeat,\n    const unsigned int num_elements)\n{\n  \n\n  const unsigned int local_work_size = 256;\n  const unsigned int global_work_size = \n\t  (num_elements + (local_work_size-1)) / local_work_size * local_work_size;\n\n  INTERLEAVED_T *d_src = sycl::malloc_device<INTERLEAVED_T>(num_elements, q);\n  INTERLEAVED_T *d_dst = sycl::malloc_device<INTERLEAVED_T>(num_elements, q);\n  \n  const size_t num_bytes = (sizeof(INTERLEAVED_T) * num_elements);\n  q.memcpy(d_src, h_src, num_bytes);\n  q.memcpy(d_dst, h_dst, num_bytes);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class interleaved>(\n        sycl::nd_range<1>(global_work_size, local_work_size), [=](sycl::nd_item<1> item) {\n        const unsigned int tid = item.get_global_id(0);\n        if (tid < num_elements)\n        {\n          for (unsigned int i=0; i<COUNT; i++)\n          {\n            d_dst[tid].s0 += d_src[tid].s0;\n            d_dst[tid].s1 += d_src[tid].s1;\n            d_dst[tid].s2 += d_src[tid].s2;\n            d_dst[tid].s3 += d_src[tid].s3;\n            d_dst[tid].s4 += d_src[tid].s4;\n            d_dst[tid].s5 += d_src[tid].s5;\n            d_dst[tid].s6 += d_src[tid].s6;\n            d_dst[tid].s7 += d_src[tid].s7;\n            d_dst[tid].s8 += d_src[tid].s8;\n            d_dst[tid].s9 += d_src[tid].s9;\n            d_dst[tid].sa += d_src[tid].sa;\n            d_dst[tid].sb += d_src[tid].sb;\n            d_dst[tid].sc += d_src[tid].sc;\n            d_dst[tid].sd += d_src[tid].sd;\n            d_dst[tid].se += d_src[tid].se;\n            d_dst[tid].sf += d_src[tid].sf;\n          }\n        }\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel (interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(h_dst, d_dst, num_bytes).wait();\n  sycl::free(d_src, q);\n  sycl::free(d_dst, q);\n}\n\nvoid add_test_non_interleaved(\n    sycl::queue &q,\n    NON_INTERLEAVED_T * const h_dst,\n    const NON_INTERLEAVED_T * const h_src,\n    const int repeat,\n    const unsigned int num_elements)\n{\n  \n\n  const unsigned int local_work_size = 256;\n  const unsigned int global_work_size = \n\t  (num_elements + (local_work_size-1)) / local_work_size * local_work_size;\n\n  \n\n  NON_INTERLEAVED_T *d_src = sycl::malloc_device<NON_INTERLEAVED_T>(1, q);\n  NON_INTERLEAVED_T *d_dst = sycl::malloc_device<NON_INTERLEAVED_T>(1, q);\n\n  const size_t num_bytes = sizeof(NON_INTERLEAVED_T);\n  q.memcpy(d_src, h_src, num_bytes);\n  q.memcpy(d_dst, h_dst, num_bytes);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class non_interleaved>(\n        sycl::nd_range<1>(global_work_size, local_work_size), [=](sycl::nd_item<1> item) {\n        const unsigned int tid = item.get_global_id(0);\n        if (tid < num_elements)\n        {\n          for (unsigned int i=0; i<COUNT; i++)\n          {\n            d_dst->s0[tid] += d_src->s0[tid];\n            d_dst->s1[tid] += d_src->s1[tid];\n            d_dst->s2[tid] += d_src->s2[tid];\n            d_dst->s3[tid] += d_src->s3[tid];\n            d_dst->s4[tid] += d_src->s4[tid];\n            d_dst->s5[tid] += d_src->s5[tid];\n            d_dst->s6[tid] += d_src->s6[tid];\n            d_dst->s7[tid] += d_src->s7[tid];\n            d_dst->s8[tid] += d_src->s8[tid];\n            d_dst->s9[tid] += d_src->s9[tid];\n            d_dst->sa[tid] += d_src->sa[tid];\n            d_dst->sb[tid] += d_src->sb[tid];\n            d_dst->sc[tid] += d_src->sc[tid];\n            d_dst->sd[tid] += d_src->sd[tid];\n            d_dst->se[tid] += d_src->se[tid];\n            d_dst->sf[tid] += d_src->sf[tid];\n          }\n        }\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel (non-interleaved) execution time %f (s)\\n\", (time * 1e-9f) / repeat);\n\n  q.memcpy(h_dst, d_dst, num_bytes).wait();\n  sycl::free(d_src, q);\n  sycl::free(d_dst, q);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  NON_INTERLEAVED_T non_interleaved_src, non_interleaved_dst; \n  INTERLEAVED_ARRAY_T interleaved_src, interleaved_dst; \n\n  initialize (interleaved_src, interleaved_dst,\n              non_interleaved_src, non_interleaved_dst, NUM_ELEMENTS);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  add_test_non_interleaved(q, &non_interleaved_dst, &non_interleaved_src,\n                           repeat, NUM_ELEMENTS);\n  add_test_interleaved(q, interleaved_dst, interleaved_src,\n                       repeat, NUM_ELEMENTS);\n  verify(interleaved_dst, non_interleaved_dst, NUM_ELEMENTS);\n\n  return 0;\n}\n"}}
{"kernel_name": "kernelLaunch", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <cuda.h>\n\n\n#define DO_NOT_OPTIMIZE_AWAY                                                                       \\\n  unsigned i = blockIdx.x * blockDim.x + threadIdx.x;                                              \\\n  if (out) *out = args.args[i];\n\nstruct SmallKernelArgs {\n  char args[16];\n};\n\nstruct MediumKernelArgs {\n  char args[256];\n};\n\nstruct LargeKernelArgs {\n  char args[4096];\n};\n\n__global__ void KernelWithSmallArgs(SmallKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\n__global__ void KernelWithMediumArgs(MediumKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\n__global__ void KernelWithLargeArgs(LargeKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  SmallKernelArgs small_kernel_args;\n  MediumKernelArgs medium_kernel_args;\n  LargeKernelArgs large_kernel_args;\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    KernelWithSmallArgs<<<1, 1>>>(small_kernel_args, nullptr);\n  }\n  cudaDeviceSynchronize();\n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    KernelWithSmallArgs<<<1, 1>>>(small_kernel_args, nullptr);\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithSmallArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    KernelWithMediumArgs<<<1, 1>>>(medium_kernel_args, nullptr);\n  }\n  cudaDeviceSynchronize();\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    KernelWithMediumArgs<<<1, 1>>>(medium_kernel_args, nullptr);\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithMediumArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    KernelWithLargeArgs<<<1, 1>>>(large_kernel_args, nullptr);\n  }\n  cudaDeviceSynchronize();\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    KernelWithLargeArgs<<<1, 1>>>(large_kernel_args, nullptr);\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithLargeArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "kernelLaunch", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n\n#define DO_NOT_OPTIMIZE_AWAY                                                                       \\\n  unsigned i = blockIdx.x * blockDim.x + threadIdx.x;                                              \\\n  if (out) *out = args.args[i];\n\nstruct SmallKernelArgs {\n  char args[16];\n};\n\nstruct MediumKernelArgs {\n  char args[256];\n};\n\nstruct LargeKernelArgs {\n  char args[4096];\n};\n\n__global__ void KernelWithSmallArgs(SmallKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\n__global__ void KernelWithMediumArgs(MediumKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\n__global__ void KernelWithLargeArgs(LargeKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  SmallKernelArgs small_kernel_args;\n  MediumKernelArgs medium_kernel_args;\n  LargeKernelArgs large_kernel_args;\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    KernelWithSmallArgs<<<1, 1>>>(small_kernel_args, nullptr);\n  }\n  hipDeviceSynchronize();\n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    KernelWithSmallArgs<<<1, 1>>>(small_kernel_args, nullptr);\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithSmallArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    KernelWithMediumArgs<<<1, 1>>>(medium_kernel_args, nullptr);\n  }\n  hipDeviceSynchronize();\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    KernelWithMediumArgs<<<1, 1>>>(medium_kernel_args, nullptr);\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithMediumArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    KernelWithLargeArgs<<<1, 1>>>(large_kernel_args, nullptr);\n  }\n  hipDeviceSynchronize();\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    KernelWithLargeArgs<<<1, 1>>>(large_kernel_args, nullptr);\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithLargeArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "kernelLaunch", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <omp.h>\n\n\n#define DO_NOT_OPTIMIZE_AWAY                                                       \\\n  unsigned i = omp_get_num_teams() * omp_get_num_threads() + omp_get_thread_num(); \\\n  if (out) *out = args.args[i];\n\n#pragma omp declare target\nstruct SmallKernelArgs {\n  char args[16];\n};\n\nstruct MediumKernelArgs {\n  char args[256];\n};\n\nstruct LargeKernelArgs {\n  char args[4096];\n};\n\nvoid KernelWithSmallArgs(SmallKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\nvoid KernelWithMediumArgs(MediumKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\nvoid KernelWithLargeArgs(LargeKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n#pragma omp end declare target\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  SmallKernelArgs small_kernel_args;\n  MediumKernelArgs medium_kernel_args;\n  LargeKernelArgs large_kernel_args;\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target map(to:small_kernel_args)\n    KernelWithSmallArgs(small_kernel_args, nullptr);\n  }\n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target map(to:small_kernel_args)\n    KernelWithSmallArgs(small_kernel_args, nullptr);\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithSmallArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target map(to:medium_kernel_args)\n    KernelWithMediumArgs(medium_kernel_args, nullptr);\n  }\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target map(to:medium_kernel_args)\n    KernelWithMediumArgs(medium_kernel_args, nullptr);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithMediumArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target map(to:large_kernel_args)\n    KernelWithLargeArgs(large_kernel_args, nullptr);\n  }\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n    #pragma omp target map(to:large_kernel_args)\n    KernelWithLargeArgs(large_kernel_args, nullptr);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithLargeArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "kernelLaunch", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n\n\n#define DO_NOT_OPTIMIZE_AWAY                                                       \\\n  unsigned i = omp_get_num_teams() * omp_get_num_threads() + omp_get_thread_num(); \\\n  if (out) *out = args.args[i];\n\nstruct SmallKernelArgs {\n  char args[16];\n};\n\nstruct MediumKernelArgs {\n  char args[256];\n};\n\nstruct LargeKernelArgs {\n  char args[4096];\n};\n\nvoid KernelWithSmallArgs(SmallKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\nvoid KernelWithMediumArgs(MediumKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\nvoid KernelWithLargeArgs(LargeKernelArgs args, char* out) { DO_NOT_OPTIMIZE_AWAY; }\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  SmallKernelArgs small_kernel_args;\n  MediumKernelArgs medium_kernel_args;\n  LargeKernelArgs large_kernel_args;\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n        KernelWithSmallArgs(small_kernel_args, nullptr);\n  }\n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        KernelWithSmallArgs(small_kernel_args, nullptr);\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithSmallArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n        KernelWithMediumArgs(medium_kernel_args, nullptr);\n  }\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        KernelWithMediumArgs(medium_kernel_args, nullptr);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithMediumArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n        KernelWithLargeArgs(large_kernel_args, nullptr);\n  }\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++) {\n        KernelWithLargeArgs(large_kernel_args, nullptr);\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithLargeArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  return 0;\n}"}}
{"kernel_name": "kernelLaunch", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define DO_NOT_OPTIMIZE_AWAY            \\\n  unsigned i = item.get_global_id(0);   \\\n    if (out) *out = args.args[i];\n\nstruct SmallKernelArgs {\n  char args[16];\n};\n\nstruct MediumKernelArgs {\n  char args[256];\n};\n\nstruct LargeKernelArgs {\n  char args[4096];\n};\n\nvoid KernelWithSmallArgs(SmallKernelArgs args, char* out,\n                         const sycl::nd_item<1> &item) { DO_NOT_OPTIMIZE_AWAY; }\n\nvoid KernelWithMediumArgs(MediumKernelArgs args, char* out,\n                          const sycl::nd_item<1> &item) { DO_NOT_OPTIMIZE_AWAY; }\n\nvoid KernelWithLargeArgs(LargeKernelArgs args, char* out,\n                         const sycl::nd_item<1> &item) { DO_NOT_OPTIMIZE_AWAY; }\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  SmallKernelArgs small_kernel_args;\n  MediumKernelArgs medium_kernel_args;\n  LargeKernelArgs large_kernel_args;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n  sycl::range<1> gws (1);\n  sycl::range<1> lws (1);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    q.parallel_for(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        KernelWithSmallArgs(small_kernel_args, nullptr, item);\n    });\n  }\n  q.wait();\n\n  auto start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.parallel_for(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        KernelWithSmallArgs(small_kernel_args, nullptr, item);\n    });\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithSmallArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    q.parallel_for(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        KernelWithMediumArgs(medium_kernel_args, nullptr, item);\n    });\n  }\n  q.wait();\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.parallel_for(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        KernelWithMediumArgs(medium_kernel_args, nullptr, item);\n    });\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithMediumArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    q.parallel_for(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        KernelWithLargeArgs(large_kernel_args, nullptr, item);\n    });\n  }\n  q.wait();\n\n  start = std::chrono::steady_clock::now();\n  for (int i = 0; i < repeat; i++)\n    q.parallel_for(\n      sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        KernelWithLargeArgs(large_kernel_args, nullptr, item);\n    });\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average execution time of kernelWithLargeArgs: %f (us)\\n\", (time * 1e-3f) / repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "layout", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n\n#include <iostream>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <cuda.h>\n\n#define TREE_NUM 4096\n#define TREE_SIZE 4096\n#define GROUP_SIZE 256\n\nstruct AppleTree\n{\n  int apples[TREE_SIZE];\n};\n\nstruct ApplesOnTrees\n{\n  int trees[TREE_NUM];\n};\n\ntemplate <int treeSize>\n__global__\nvoid AoSKernel(const AppleTree *__restrict__ trees, \n               int *__restrict__ outBuf)\n{\n  uint gid = blockIdx.x * blockDim.x + threadIdx.x;\n  uint res = 0;\n  for(int i = 0; i < treeSize; i++)\n  {\n    res += trees[gid].apples[i];\n  }\n  outBuf[gid] = res;\n}\n\ntemplate <int treeSize>\n__global__\nvoid SoAKernel(const ApplesOnTrees *__restrict__ applesOnTrees,\n               int *__restrict__ outBuf)\n{\n  uint gid = blockIdx.x * blockDim.x + threadIdx.x;\n  uint res = 0;\n  for(int i = 0; i < treeSize; i++)\n  {\n    res += applesOnTrees[i].trees[gid];\n  }\n  outBuf[gid] = res;\n}\n\nint main(int argc, char * argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]); \n\n  const int treeSize = TREE_SIZE;\n  const int treeNumber = TREE_NUM;\n  bool fail = false;\n\n  if(iterations < 1)\n  {\n    std::cout<<\"Iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n\n  if(treeNumber < GROUP_SIZE)\n  {\n    std::cout<<\"treeNumber should be larger than the work group size\"<<std::endl;\n    return -1;\n  }\n  if(treeNumber % 256 !=0)\n  {\n    std::cout<<\"treeNumber should be a multiple of 256\"<<std::endl;\n    return -1;\n  }\n\n  const int elements = treeSize * treeNumber;\n  size_t inputSize = elements * sizeof(int);\n  size_t outputSize = treeNumber * sizeof(int);\n\n  \n\n  int* data = (int*) malloc (inputSize);\n\n  \n\n  int *deviceResult = (int *)malloc(outputSize);\n\n  \n\n  int *reference = (int *)malloc(outputSize);\n  memset(reference,0,outputSize);\n  for(int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      reference[i] += i * treeSize + j;\n\n  dim3 grid(treeNumber/GROUP_SIZE);\n  dim3 block(GROUP_SIZE);\n\n  int *inputBuffer;\n  cudaMalloc((void**)&inputBuffer, inputSize);\n\n  int *outputBuffer;\n  cudaMalloc((void**)&outputBuffer, outputSize);\n\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[j + i* treeSize] = j + i* treeSize;\n\n  cudaMemcpy(inputBuffer, data, inputSize, cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++)\n    AoSKernel<treeSize><<<grid, block>>>((AppleTree*)inputBuffer, outputBuffer);\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (AoS): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  cudaMemcpy(deviceResult, outputBuffer, outputSize, cudaMemcpyDeviceToHost);\n\n  for(int i = 0; i < treeNumber; i++)\n  {\n    if(deviceResult[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[i + j* treeNumber] = j + i* treeSize;\n\n  cudaMemcpy(inputBuffer, data, inputSize, cudaMemcpyHostToDevice);\n\n  cudaDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++)\n    SoAKernel<treeSize><<<grid, block>>>((ApplesOnTrees*)inputBuffer, outputBuffer);\n\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (SoA): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  cudaMemcpy(deviceResult, outputBuffer, outputSize, cudaMemcpyDeviceToHost);\n\n  for(int i = 0; i < treeNumber; i++)\n  {\n    if(deviceResult[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n  \n  cudaFree(inputBuffer);\n  cudaFree(outputBuffer);\n  free(deviceResult);\n  free(reference);\n  free(data);\n  return 0;\n}\n"}}
{"kernel_name": "layout", "parallel_api": "hip", "code": {"main.cu": "\n\n\n\n#include <iostream>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define TREE_NUM 4096\n#define TREE_SIZE 4096\n#define GROUP_SIZE 256\n\nstruct AppleTree\n{\n  int apples[TREE_SIZE];\n};\n\nstruct ApplesOnTrees\n{\n  int trees[TREE_NUM];\n};\n\ntemplate <int treeSize>\n__global__\nvoid AoSKernel(const AppleTree *__restrict__ trees, \n               int *__restrict__ outBuf)\n{\n  uint gid = blockIdx.x * blockDim.x + threadIdx.x;\n  uint res = 0;\n  for(int i = 0; i < treeSize; i++)\n  {\n    res += trees[gid].apples[i];\n  }\n  outBuf[gid] = res;\n}\n\ntemplate <int treeSize>\n__global__\nvoid SoAKernel(const ApplesOnTrees *__restrict__ applesOnTrees,\n               int *__restrict__ outBuf)\n{\n  uint gid = blockIdx.x * blockDim.x + threadIdx.x;\n  uint res = 0;\n  for(int i = 0; i < treeSize; i++)\n  {\n    res += applesOnTrees[i].trees[gid];\n  }\n  outBuf[gid] = res;\n}\n\nint main(int argc, char * argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]); \n\n  const int treeSize = TREE_SIZE;\n  const int treeNumber = TREE_NUM;\n  bool fail = false;\n\n  if(iterations < 1)\n  {\n    std::cout<<\"Iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n\n  if(treeNumber < GROUP_SIZE)\n  {\n    std::cout<<\"treeNumber should be larger than the work group size\"<<std::endl;\n    return -1;\n  }\n  if(treeNumber % 256 !=0)\n  {\n    std::cout<<\"treeNumber should be a multiple of 256\"<<std::endl;\n    return -1;\n  }\n\n  const int elements = treeSize * treeNumber;\n  size_t inputSize = elements * sizeof(int);\n  size_t outputSize = treeNumber * sizeof(int);\n\n  \n\n  int* data = (int*) malloc (inputSize);\n\n  \n\n  int *deviceResult = (int *)malloc(outputSize);\n\n  \n\n  int *reference = (int *)malloc(outputSize);\n  memset(reference,0,outputSize);\n  for(int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      reference[i] += i * treeSize + j;\n\n  dim3 grid(treeNumber/GROUP_SIZE);\n  dim3 block(GROUP_SIZE);\n\n  int *inputBuffer;\n  hipMalloc((void**)&inputBuffer, inputSize);\n\n  int *outputBuffer;\n  hipMalloc((void**)&outputBuffer, outputSize);\n\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[j + i* treeSize] = j + i* treeSize;\n\n  hipMemcpy(inputBuffer, data, inputSize, hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++)\n    AoSKernel<treeSize><<<grid, block>>>((AppleTree*)inputBuffer, outputBuffer);\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (AoS): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  hipMemcpy(deviceResult, outputBuffer, outputSize, hipMemcpyDeviceToHost);\n\n  for(int i = 0; i < treeNumber; i++)\n  {\n    if(deviceResult[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[i + j* treeNumber] = j + i* treeSize;\n\n  hipMemcpy(inputBuffer, data, inputSize, hipMemcpyHostToDevice);\n\n  hipDeviceSynchronize();\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++)\n    SoAKernel<treeSize><<<grid, block>>>((ApplesOnTrees*)inputBuffer, outputBuffer);\n\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (SoA): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  hipMemcpy(deviceResult, outputBuffer, outputSize, hipMemcpyDeviceToHost);\n\n  for(int i = 0; i < treeNumber; i++)\n  {\n    if(deviceResult[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n  \n  hipFree(inputBuffer);\n  hipFree(outputBuffer);\n  free(deviceResult);\n  free(reference);\n  free(data);\n  return 0;\n}\n"}}
{"kernel_name": "layout", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n\n#include <iostream>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <omp.h>\n\n#define TREE_NUM 4096\n#define TREE_SIZE 4096\n#define GROUP_SIZE 256\n\nstruct AppleTree\n{\n  int apples[TREE_SIZE];\n};\n\nstruct ApplesOnTrees\n{\n  int trees[TREE_NUM];\n};\n\nint main(int argc, char * argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]); \n\n  const int treeSize = TREE_SIZE;\n  const int treeNumber = TREE_NUM;\n  bool fail = false;\n\n  if(iterations < 1)\n  {\n    std::cout<<\"Iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n\n  if(treeNumber < GROUP_SIZE)\n  {\n    std::cout<<\"treeNumber should be larger than the work group size\"<<std::endl;\n    return -1;\n  }\n  if(treeNumber % 256 !=0)\n  {\n    std::cout<<\"treeNumber should be a multiple of 256\"<<std::endl;\n    return -1;\n  }\n\n  const int elements = treeSize * treeNumber;\n  size_t inputSize = elements * sizeof(int);\n  size_t outputSize = treeNumber * sizeof(int);\n\n  \n\n  int* data = (int*) malloc (inputSize);\n\n  \n\n  int *output = (int *)malloc(outputSize);\n\n  \n\n  int *reference = (int *)malloc(outputSize);\n  memset(reference,0,outputSize);\n  for(int i=0; i < treeNumber; i++)\n    for(int j=0; j < treeSize; j++)\n      reference[i] += i * treeSize + j;\n\n#pragma omp target data map(alloc: data[0:elements], output[0:treeNumber])\n{\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[j + i* treeSize] = j + i* treeSize;\n\n  #pragma omp target update to (data[0:elements])\n\n  AppleTree *trees = (AppleTree*) data;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < iterations; n++) {\n    #pragma omp target teams distribute parallel for thread_limit(GROUP_SIZE) \n    for (uint gid = 0; gid < treeNumber; gid++) \n    {\n      uint res = 0;\n      for(int i = 0; i < treeSize; i++)\n      {\n        res += trees[gid].apples[i];\n      }\n      output[gid] = res;\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (AoS): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  #pragma omp target update from (output[0:treeNumber])\n\n  for(int i=0; i< treeNumber; i++)\n  {\n    if(output[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[i + j* treeNumber] = j + i* treeSize;\n\n  #pragma omp target update to (data[0:elements])\n\n  ApplesOnTrees *applesOnTrees = (ApplesOnTrees*) data;\n\n  start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < iterations; n++) {\n    #pragma omp target teams distribute parallel for thread_limit(GROUP_SIZE) \n    for (uint gid = 0; gid < treeNumber; gid++) \n    {\n      uint res = 0;\n      for(int i = 0; i < treeSize; i++)\n      {\n        res += applesOnTrees[i].trees[gid];\n      }\n      output[gid] = res;\n    }\n  }\n\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (SoA): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  #pragma omp target update from (output[0:treeNumber])\n\n  for(int i=0; i< treeNumber; i++)\n  {\n    if(output[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n\n}\n\n  free(output);\n  free(reference);\n  free(data);\n  return 0;\n}\n\n"}}
{"kernel_name": "layout", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n\n#include <iostream>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n\n#define TREE_NUM 4096\n#define TREE_SIZE 4096\n#define GROUP_SIZE 256\n\nstruct AppleTree\n{\n  int apples[TREE_SIZE];\n};\n\nstruct ApplesOnTrees\n{\n  int trees[TREE_NUM];\n};\n\nint main(int argc, char * argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n  const int iterations = atoi(argv[1]); \n\n  const int treeSize = TREE_SIZE;\n  const int treeNumber = TREE_NUM;\n  bool fail = false;\n\n  if(iterations < 1)\n  {\n    std::cout<<\"Iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n\n  if(treeNumber < GROUP_SIZE)\n  {\n    std::cout<<\"treeNumber should be larger than the work group size\"<<std::endl;\n    return -1;\n  }\n  if(treeNumber % 256 !=0)\n  {\n    std::cout<<\"treeNumber should be a multiple of 256\"<<std::endl;\n    return -1;\n  }\n\n  const int elements = treeSize * treeNumber;\n  size_t inputSize = elements * sizeof(int);\n  size_t outputSize = treeNumber * sizeof(int);\n\n  \n\n  int* data = (int*) malloc (inputSize);\n\n  \n\n  int *output = (int *)malloc(outputSize);\n\n  \n\n  int *reference = (int *)malloc(outputSize);\n  memset(reference,0,outputSize);\n  for(int i=0; i < treeNumber; i++)\n    for(int j=0; j < treeSize; j++)\n      reference[i] += i * treeSize + j;\n\n{\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[j + i* treeSize] = j + i* treeSize;\n\n  \n  AppleTree *trees = (AppleTree*) data;\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < iterations; n++) {\n        for (uint gid = 0; gid < treeNumber; gid++) \n    {\n      uint res = 0;\n      for(int i = 0; i < treeSize; i++)\n      {\n        res += trees[gid].apples[i];\n      }\n      output[gid] = res;\n    }\n  }\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (AoS): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  \n  for(int i=0; i< treeNumber; i++)\n  {\n    if(output[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[i + j* treeNumber] = j + i* treeSize;\n\n  \n  ApplesOnTrees *applesOnTrees = (ApplesOnTrees*) data;\n\n  start = std::chrono::steady_clock::now();\n\n  for (int n = 0; n < iterations; n++) {\n        for (uint gid = 0; gid < treeNumber; gid++) \n    {\n      uint res = 0;\n      for(int i = 0; i < treeSize; i++)\n      {\n        res += applesOnTrees[i].trees[gid];\n      }\n      output[gid] = res;\n    }\n  }\n\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (SoA): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  \n  for(int i=0; i< treeNumber; i++)\n  {\n    if(output[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n\n}\n\n  free(output);\n  free(reference);\n  free(data);\n  return 0;\n}\n"}}
{"kernel_name": "layout", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n\n#include <iostream>\n#include <stdlib.h>\n#include <string.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define TREE_NUM 4096\n#define TREE_SIZE 4096\n#define GROUP_SIZE 256\n\nstruct AppleTree\n{\n  int apples[TREE_SIZE];\n};\n\nstruct ApplesOnTrees\n{\n  int trees[TREE_NUM];\n};\n\nvoid AoSKernel(const AppleTree *__restrict trees,\n               int *__restrict outBuf,\n               int treeSize, sycl::nd_item<1> &item)\n{\n  uint gid = item.get_global_id(0);\n  uint res = 0;\n  for(int i = 0; i < treeSize; i++)\n  {\n    res += trees[gid].apples[i];\n  }\n  outBuf[gid] = res;\n}\n\n\nvoid SoAKernel(const ApplesOnTrees *__restrict applesOnTrees,\n               int *__restrict outBuf,\n               int treeSize, sycl::nd_item<1> &item)\n{\n  uint gid = item.get_global_id(0);\n  uint res = 0;\n  for(int i = 0; i < treeSize; i++)\n  {\n    res += applesOnTrees[i].trees[gid];\n  }\n  outBuf[gid] = res;\n}\n\nint main(int argc, char * argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int iterations = atoi(argv[1]); \n\n  const int treeSize = TREE_SIZE;\n  const int treeNumber = TREE_NUM;\n  bool fail = false;\n\n  if(iterations < 1)\n  {\n    std::cout<<\"Iterations cannot be 0 or negative. Exiting..\\n\";\n    return -1;\n  }\n\n  if(treeNumber < GROUP_SIZE)\n  {\n    std::cout<<\"treeNumber should be larger than the work group size\"<<std::endl;\n    return -1;\n  }\n  if(treeNumber % 256 !=0)\n  {\n    std::cout<<\"treeNumber should be a multiple of 256\"<<std::endl;\n    return -1;\n  }\n\n  const int elements = treeSize * treeNumber;\n  size_t inputSize = elements * sizeof(int);\n  size_t outputSize = treeNumber * sizeof(int);\n\n  \n\n  int* data = (int*) malloc (inputSize);\n\n  \n\n  int *deviceResult = (int *)malloc(outputSize);\n\n  \n\n  int *reference = (int *)malloc(outputSize);\n  memset(reference,0,outputSize);\n  for(int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      reference[i] += i * treeSize + j;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  sycl::range<1> gws(treeNumber);\n  sycl::range<1> lws(GROUP_SIZE);\n\n  int *inputBuffer = sycl::malloc_device<int>(elements, q);\n  int *outputBuffer = sycl::malloc_device<int>(treeNumber, q);\n\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[j + i* treeSize] = j + i* treeSize;\n\n  q.memcpy(inputBuffer, data, inputSize).wait();\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class AoS>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        AoSKernel((AppleTree*)inputBuffer, outputBuffer, treeSize, item);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (AoS): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  q.memcpy(deviceResult, outputBuffer, outputSize).wait();\n\n  for(int i = 0; i< treeNumber; i++)\n  {\n    if(deviceResult[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n\n  \n\n  for (int i = 0; i < treeNumber; i++)\n    for(int j = 0; j < treeSize; j++)\n      data[i + j* treeNumber] = j + i* treeSize;\n\n  q.memcpy(inputBuffer, data, inputSize).wait();\n\n  start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < iterations; i++) {\n    q.submit([&] (sycl::handler &cgh) {\n      cgh.parallel_for<class SoA>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        SoAKernel((ApplesOnTrees*)inputBuffer, outputBuffer, treeSize, item);\n      });\n    });\n  }\n\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average kernel execution time (SoA): \"\n            << (time * 1e-3f) / iterations << \" (us)\\n\";\n\n  q.memcpy(deviceResult, outputBuffer, outputSize).wait();\n\n  for(int i = 0; i< treeNumber; i++)\n  {\n    if(deviceResult[i] != reference[i])\n    {\n      fail = true;\n      break;\n    }\n  }\n\n  if (fail)\n    std::cout << \"FAIL\\n\";\n  else\n    std::cout << \"PASS\\n\";\n\n  sycl::free(inputBuffer, q);\n  sycl::free(outputBuffer, q);\n  free(deviceResult);\n  free(reference);\n  free(data);\n  return 0;\n}\n"}}
{"kernel_name": "mallocFree", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <cuda_runtime.h>\n\n#define NUM_SIZE 19  \n\n#define NUM_ITER 500 \n\n\n#define Clock() std::chrono::steady_clock::now()\n\nvoid valSet(int* A, int val, size_t size) {\n  size_t len = size / sizeof(int);\n  for (size_t i = 0; i < len; i++) {\n    A[i] = val;\n  }\n}\n\nvoid setup(size_t *size, int &num, int **pA, const size_t totalGlobalMem) {\n\n  for (int i = 0; i < num; i++) {\n    size[i] = 1 << (i + 6);\n    if((NUM_ITER + 1) * size[i] > totalGlobalMem) {\n      num = i;\n      break;\n    }\n  }\n  *pA = (int*)malloc(size[num - 1]);\n  valSet(*pA, 1, size[num - 1]);\n}\n\nvoid testInit(size_t size, int type) {\n\n  printf(\"Initial allocation and deallocation\\n\");\n\n  int *Ad = nullptr;\n  auto start = Clock();\n  if (type == 0)\n    cudaMallocManaged(&Ad, size);\n  else if (type == 1)\n    cudaMalloc(&Ad, size);\n  else if (type == 2)\n    cudaHostAlloc(&Ad, size, cudaHostAllocMapped);\n\n  auto end = Clock();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  if (type == 0)\n    printf(\"cudaMallocManaged(%zu) takes %lf us\\n\", size, time * 1e-3);\n  else if (type == 1)\n    printf(\"cudaMalloc(%zu) takes %lf us\\n\", size, time * 1e-3);\n  else if (type == 2)\n    printf(\"cudaHostAlloc(%zu) takes %lf us\\n\", size, time * 1e-3);\n  \n  \n\n  if (type == 2) {\n    start = Clock();\n    cudaFreeHost(Ad);\n    end = Clock();\n    printf(\"cudaFreeHost(%zu) takes %lf us\\n\", size, time * 1e-3);\n  }\n  else {\n    start = Clock();\n    cudaFree(Ad);\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"cudaFree(%zu) takes %lf us\\n\", size, time * 1e-3);\n  }\n\n  printf(\"\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <total global memory size in bytes>\\n\", argv[0]);\n    return 1;\n  }\n   \n  const size_t totalGlobalMem = atol(argv[1]);\n\n  size_t size[NUM_SIZE] = { 0 };\n  int *Ad[NUM_ITER] = { nullptr };\n\n  int num = NUM_SIZE;\n  int *A;\n  setup(size, num, &A, totalGlobalMem);\n\n  printf(\"\\n==== Evaluate cudaMallocManaged and cudaFree ====\\n\");\n  testInit(size[0], 0);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      cudaMallocManaged(&Ad[j], size[i]);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"cudaMallocManaged(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      cudaFree(Ad[j]);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"cudaFree(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  printf(\"\\n==== Evaluate cudaMalloc and cudaFree ====\\n\");\n  testInit(size[0], 1);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      cudaMalloc(&Ad[j], size[i]);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"cudaMalloc(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      cudaFree(Ad[j]);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"cudaFree(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  printf(\"\\n==== Evaluate cudaHostAlloc (cudaHostAllocMapped) and cudaFreeHost ====\\n\");\n  testInit(size[0], 2);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      cudaHostAlloc(&Ad[j], size[i], cudaHostAllocMapped);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"cudaHostAlloc(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      cudaFreeHost(Ad[j]);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"cudaFreeHost(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  free(A);\n  return 0;\n}\n"}}
{"kernel_name": "mallocFree", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define NUM_SIZE 19  \n\n#define NUM_ITER 500 \n\n\n#define Clock() std::chrono::steady_clock::now()\n\nvoid valSet(int* A, int val, size_t size) {\n  size_t len = size / sizeof(int);\n  for (size_t i = 0; i < len; i++) {\n    A[i] = val;\n  }\n}\n\nvoid setup(size_t *size, int &num, int **pA, const size_t totalGlobalMem) {\n\n  for (int i = 0; i < num; i++) {\n    size[i] = 1 << (i + 6);\n    if((NUM_ITER + 1) * size[i] > totalGlobalMem) {\n      num = i;\n      break;\n    }\n  }\n  *pA = (int*)malloc(size[num - 1]);\n  valSet(*pA, 1, size[num - 1]);\n}\n\nvoid testInit(size_t size, int type) {\n\n  printf(\"Initial allocation and deallocation\\n\");\n\n  int *Ad = nullptr;\n  auto start = Clock();\n  if (type == 0)\n    hipMallocManaged(&Ad, size);\n  else if (type == 1)\n    hipMalloc(&Ad, size);\n  else if (type == 2)\n    hipHostMalloc(&Ad, size, hipHostMallocMapped);\n\n  auto end = Clock();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  if (type == 0)\n    printf(\"hipMallocManaged(%zu) takes %lf us\\n\", size, time * 1e-3);\n  else if (type == 1)\n    printf(\"hipMalloc(%zu) takes %lf us\\n\", size, time * 1e-3);\n  else if (type == 2)\n    printf(\"hipHostMalloc(%zu) takes %lf us\\n\", size, time * 1e-3);\n\n  start = Clock();\n  hipFree(Ad);\n  end = Clock();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"hipFree(%zu) takes %lf us\\n\", size, time * 1e-3);\n  printf(\"\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <total global memory size in bytes>\\n\", argv[0]);\n    return 1;\n  }\n   \n  const size_t totalGlobalMem = atol(argv[1]);\n\n  size_t size[NUM_SIZE] = { 0 };\n  int *Ad[NUM_ITER] = { nullptr };\n\n  int num = NUM_SIZE;\n  int *A;\n  setup(size, num, &A, totalGlobalMem);\n\n  printf(\"\\n==== Evaluate hipMallocManaged and hipFree ====\\n\");\n  testInit(size[0], 0);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      hipMallocManaged(&Ad[j], size[i]);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"hipMallocManaged(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      hipFree(Ad[j]);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"hipFree(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  printf(\"\\n==== Evaluate hipMalloc and hipFree ====\\n\");\n  testInit(size[0], 1);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      hipMalloc(&Ad[j], size[i]);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"hipMalloc(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      hipFree(Ad[j]);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"hipFree(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  printf(\"\\n==== Evaluate hipHostMalloc (hipHostMallocMapped) and hipFree ====\\n\");\n  testInit(size[0], 2);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      hipHostMalloc(&Ad[j], size[i], hipHostMallocMapped);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"hipHostMalloc(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      hipFree(Ad[j]);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"hipFree(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  free(A);\n  return 0;\n}\n"}}
{"kernel_name": "mallocFree", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <omp.h>\n\n#define NUM_SIZE 19  \n\n#define NUM_ITER 500 \n\n\n#define Clock() std::chrono::steady_clock::now()\n\n#ifdef UM\n#pragma omp requires unified_shared_memory\n#endif\n\nvoid valSet(int* A, int val, size_t size) {\n  size_t len = size / sizeof(int);\n  for (size_t i = 0; i < len; i++) {\n    A[i] = val;\n  }\n}\n\nvoid setup(size_t *size, int &num, int **pA, const size_t totalGlobalMem) {\n\n  for (int i = 0; i < num; i++) {\n    size[i] = 1 << (i + 6);\n    if((NUM_ITER + 1) * size[i] > totalGlobalMem) {\n      num = i;\n      break;\n    }\n  }\n  *pA = (int*)malloc(size[num - 1]);\n  valSet(*pA, 1, size[num - 1]);\n}\n\nvoid testInit(size_t size, int device_num) {\n\n  printf(\"Initial allocation and deallocation\\n\");\n\n  int *Ad;\n  auto start = Clock();\n  Ad = (int*) omp_target_alloc(size, device_num);\n  auto end = Clock();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"omp_target_alloc(%zu) takes %lf us\\n\", size, time * 1e-3);\n\n  start = Clock();\n  omp_target_free(Ad, device_num);\n  end = Clock();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"omp_target_free(%zu) takes %lf us\\n\", size, time * 1e-3);\n  printf(\"\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <total global memory size in bytes>\\n\", argv[0]);\n    return 1;\n  }\n   \n  const size_t totalGlobalMem = atol(argv[1]);\n\n  size_t size[NUM_SIZE] = { 0 };\n  int *Ad[NUM_ITER] = { nullptr };\n\n  int num = NUM_SIZE;\n  int *A;\n  setup(size, num, &A, totalGlobalMem);\n\n  int device_num = 0;\n\n  testInit(size[0], device_num);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      Ad[j] = (int*) omp_target_alloc(size[i], device_num);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"omp_target_alloc(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      omp_target_free(Ad[j], device_num);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"omp_target_free(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  free(A);\n  return 0;\n}\n"}}
{"kernel_name": "mallocFree", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n\n#define NUM_SIZE 19  \n\n#define NUM_ITER 500 \n\n\n#define Clock() std::chrono::steady_clock::now()\n\n#ifdef UM\n#endif\n\nvoid valSet(int* A, int val, size_t size) {\n  size_t len = size / sizeof(int);\n  for (size_t i = 0; i < len; i++) {\n    A[i] = val;\n  }\n}\n\nvoid setup(size_t *size, int &num, int **pA, const size_t totalGlobalMem) {\n\n  for (int i = 0; i < num; i++) {\n    size[i] = 1 << (i + 6);\n    if((NUM_ITER + 1) * size[i] > totalGlobalMem) {\n      num = i;\n      break;\n    }\n  }\n  *pA = (int*)malloc(size[num - 1]);\n  valSet(*pA, 1, size[num - 1]);\n}\n\nvoid testInit(size_t size, int device_num) {\n\n  printf(\"Initial allocation and deallocation\\n\");\n\n  int *Ad;\n  auto start = Clock();\n  Ad = (int*) omp_target_alloc(size, device_num);\n  auto end = Clock();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"omp_target_alloc(%zu) takes %lf us\\n\", size, time * 1e-3);\n\n  start = Clock();\n  omp_target_free(Ad, device_num);\n  end = Clock();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"omp_target_free(%zu) takes %lf us\\n\", size, time * 1e-3);\n  printf(\"\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <total global memory size in bytes>\\n\", argv[0]);\n    return 1;\n  }\n   \n  const size_t totalGlobalMem = atol(argv[1]);\n\n  size_t size[NUM_SIZE] = { 0 };\n  int *Ad[NUM_ITER] = { nullptr };\n\n  int num = NUM_SIZE;\n  int *A;\n  setup(size, num, &A, totalGlobalMem);\n\n  int device_num = 0;\n\n  testInit(size[0], device_num);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      Ad[j] = (int*) omp_target_alloc(size[i], device_num);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"omp_target_alloc(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      omp_target_free(Ad[j], device_num);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"omp_target_free(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  free(A);\n  return 0;\n}"}}
{"kernel_name": "mallocFree", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <cstdio>\n#include <cstdlib>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define NUM_SIZE 19  \n\n#define NUM_ITER 500 \n\n\n#define Clock() std::chrono::steady_clock::now()\n\nvoid valSet(int* A, int val, size_t size) {\n  size_t len = size / sizeof(int);\n  for (size_t i = 0; i < len; i++) {\n    A[i] = val;\n  }\n}\n\nvoid setup(size_t *size, int &num, int **pA, const size_t totalGlobalMem) {\n\n  for (int i = 0; i < num; i++) {\n    size[i] = 1 << (i + 6);\n    if((NUM_ITER + 1) * size[i] > totalGlobalMem) {\n      num = i;\n      break;\n    }\n  }\n  *pA = (int*)malloc(size[num - 1]);\n  valSet(*pA, 1, size[num - 1]);\n}\n\nvoid testInit(sycl::queue &q, size_t size, int type) {\n  printf(\"Initial allocation and deallocation\\n\");\n\n  int *Ad = nullptr;\n  auto start = Clock();\n  if (type == 0)\n    Ad = (int *)sycl::malloc_shared(size, q);\n  else if (type == 1)\n    Ad = (int *)sycl::malloc_device(size, q);\n  else if (type == 2)\n    Ad = (int *)sycl::malloc_host(size, q);\n\n  auto end = Clock();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n  if (type == 0)\n    printf(\"malloc_shared(%zu) takes %lf us\\n\", size, time * 1e-3);\n  else if (type == 1)\n    printf(\"malloc_device(%zu) takes %lf us\\n\", size, time * 1e-3);\n  else if (type == 2)\n    printf(\"malloc_host(%zu) takes %lf us\\n\", size, time * 1e-3);\n  \n  start = Clock();\n  sycl::free(Ad, q);\n  end = Clock();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"free(%zu) takes %lf us\\n\", size, time * 1e-3);\n\n  printf(\"\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <total global memory size in bytes>\\n\", argv[0]);\n    return 1;\n  }\n   \n  const size_t totalGlobalMem = atol(argv[1]);\n\n  size_t size[NUM_SIZE] = { 0 };\n  int *Ad[NUM_ITER] = { nullptr };\n\n  int num = NUM_SIZE;\n  int *A;\n  setup(size, num, &A, totalGlobalMem);\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  printf(\"\\n==== Evaluate malloc_shared and free ====\\n\");\n  testInit(q, size[0], 0);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      Ad[j] = (int *)sycl::malloc_shared(size[i], q);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"malloc_shared(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      sycl::free(Ad[j], q);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"free(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  printf(\"\\n==== Evaluate malloc_device and free ====\\n\");\n  testInit(q, size[0], 1);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      Ad[j] = (int *)sycl::malloc_device(size[i], q);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"malloc_device(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      sycl::free(Ad[j], q);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"free(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  printf(\"\\n==== Evaluate malloc_host and free ====\\n\");\n  testInit(q, size[0], 2);\n\n  for (int i = 0; i < num; i++) {\n    auto start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      Ad[j] = (int *)sycl::malloc_host(size[i], q);\n    }\n    auto end = Clock();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"malloc_host(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n\n    start = Clock();\n    for (int j = 0; j < NUM_ITER; j++) {\n      sycl::free(Ad[j], q);\n      Ad[j] = nullptr;\n    }\n    end = Clock();\n    time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"free(%zu) takes %lf us\\n\", size[i], time * 1e-3  / NUM_ITER);\n  }\n\n  free(A);\n  return 0;\n}\n"}}
{"kernel_name": "maxFlops", "parallel_api": "cuda", "code": {"main.cu": "#include <chrono>\n#include <iostream>\n#include <cstdlib>\n#include <cuda.h>\n#include \"kernels.h\"\n\n\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\ninline void memcpyH2D(T *d, const T *h, const int n) {\n  cudaMemcpy(d, h, n * sizeof(T), cudaMemcpyHostToDevice);\n}\n\ntemplate <typename T>\nvoid test (const int repeat, const int numFloats) \n{\n  \n\n  T *hostMem = (T*) malloc (sizeof(T) * numFloats);\n\n  srand48(123);\n  for (int j = 0; j < numFloats/2 ; ++j)\n    hostMem[j] = hostMem[numFloats-j-1] = (T)(drand48()*10.0);\n\n  T *deviceMem;\n  cudaMalloc((void**)&deviceMem, numFloats * sizeof(T));\n\n  dim3 threads(BLOCK_SIZE);\n  dim3 blocks((numFloats)/BLOCK_SIZE);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    Add1<T><<< blocks, threads >>>(deviceMem, repeat, 10.0);\n    Add2<T><<< blocks, threads >>>(deviceMem, repeat, 10.0);\n    Add4<T><<< blocks, threads >>>(deviceMem, repeat, 10.0);\n    Add8<T><<< blocks, threads >>>(deviceMem, repeat, 10.0);\n    cudaDeviceSynchronize();\n  }\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  auto k_start = std::chrono::high_resolution_clock::now(); \n  Add1<T><<< blocks, threads >>>(deviceMem, repeat, 10.0);\n  cudaDeviceSynchronize();\n  auto k_end = std::chrono::high_resolution_clock::now(); \n  auto k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add1): %f (s)\\n\", (k_time * 1e-9f));\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  Add2<T><<< blocks, threads >>>(deviceMem, repeat, 10.0);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add2): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  Add4<T><<< blocks, threads >>>(deviceMem, repeat, 10.0);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add4): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  Add8<T><<< blocks, threads >>>(deviceMem, repeat, 10.0);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add8): %f (s)\\n\", k_time * 1e-9f);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    Mul1<T><<< blocks, threads >>>(deviceMem, repeat, 1.01);\n    Mul2<T><<< blocks, threads >>>(deviceMem, repeat, 1.01);\n    Mul4<T><<< blocks, threads >>>(deviceMem, repeat, 1.01);\n    Mul8<T><<< blocks, threads >>>(deviceMem, repeat, 1.01);\n    cudaDeviceSynchronize();\n  }\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  Mul1<T><<< blocks, threads >>>(deviceMem, repeat, 1.01);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul1): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  Mul2<T><<< blocks, threads >>>(deviceMem, repeat, 1.01);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul2): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  Mul4<T><<< blocks, threads >>>(deviceMem, repeat, 1.01);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul4): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  Mul8<T><<< blocks, threads >>>(deviceMem, repeat, 1.01);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul8): %f (s)\\n\", k_time * 1e-9f);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    MAdd1<T><<< blocks, threads >>>(deviceMem, repeat, 10.0, 0.9899);\n    MAdd2<T><<< blocks, threads >>>(deviceMem, repeat, 10.0, 0.9899);\n    MAdd4<T><<< blocks, threads >>>(deviceMem, repeat, 10.0, 0.9899);\n    MAdd8<T><<< blocks, threads >>>(deviceMem, repeat, 10.0, 0.9899);\n    cudaDeviceSynchronize();\n  }\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  MAdd1<T><<< blocks, threads >>>(deviceMem, repeat, 10.0, 0.9899);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd1): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  MAdd2<T><<< blocks, threads >>>(deviceMem, repeat, 10.0, 0.9899);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd2): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  MAdd4<T><<< blocks, threads >>>(deviceMem, repeat, 10.0, 0.9899);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd4): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  MAdd8<T><<< blocks, threads >>>(deviceMem, repeat, 10.0, 0.9899);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd8): %f (s)\\n\", k_time * 1e-9f);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    MulMAdd1<T><<< blocks, threads >>>(deviceMem, repeat, 3.75, 0.355);\n    MulMAdd2<T><<< blocks, threads >>>(deviceMem, repeat, 3.75, 0.355);\n    MulMAdd4<T><<< blocks, threads >>>(deviceMem, repeat, 3.75, 0.355);\n    MulMAdd8<T><<< blocks, threads >>>(deviceMem, repeat, 3.75, 0.355);\n    cudaDeviceSynchronize();\n  }\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  MulMAdd1<T><<< blocks, threads >>>(deviceMem, repeat, 3.75, 0.355);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd1): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  MulMAdd2<T><<< blocks, threads >>>(deviceMem, repeat, 3.75, 0.355);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd2): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  MulMAdd4<T><<< blocks, threads >>>(deviceMem, repeat, 3.75, 0.355);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd4): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  MulMAdd8<T><<< blocks, threads >>>(deviceMem, repeat, 3.75, 0.355);\n  cudaDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd8): %f (s)\\n\", k_time * 1e-9f);\n\n  cudaFree(deviceMem);\n  free(hostMem);\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  const int repeat = atoi(argv[1]);\n\n  \n\n  const int numFloats = 2*1024*1024;\n\n  printf(\"=== Single-precision floating-point kernels ===\\n\");\n  test<float>(repeat, numFloats);\n\n  \n\n  printf(\"=== Double-precision floating-point kernels ===\\n\");\n  test<double>(repeat, numFloats);\n\n  return 0;\n}\n"}}
{"kernel_name": "maxFlops", "parallel_api": "hip", "code": {"main.cu": "#include <chrono>\n#include <iostream>\n#include <cstdlib>\n#include <hip/hip_runtime.h>\n#include \"kernels.h\"\n\n\n\n#define BLOCK_SIZE 256\n\ntemplate <typename T>\ninline void memcpyH2D(T *d, const T *h, const int n) {\n  hipMemcpy(d, h, n * sizeof(T), hipMemcpyHostToDevice);\n}\n\ntemplate <typename T>\nvoid test (const int repeat, const int numFloats) \n{\n  \n\n  T *hostMem = (T*) malloc (sizeof(T) * numFloats);\n\n  srand48(123);\n  for (int j = 0; j < numFloats/2 ; ++j)\n    hostMem[j] = hostMem[numFloats-j-1] = (T)(drand48()*10.0);\n\n  T *deviceMem;\n  hipMalloc((void**)&deviceMem, numFloats * sizeof(T));\n\n  dim3 threads(BLOCK_SIZE);\n  dim3 blocks((numFloats)/BLOCK_SIZE);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(Add1<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(Add2<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(Add4<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(Add8<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0);\n    hipDeviceSynchronize();\n  }\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  auto k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(Add1<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0);\n  hipDeviceSynchronize();\n  auto k_end = std::chrono::high_resolution_clock::now(); \n  auto k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add1): %f (s)\\n\", (k_time * 1e-9f));\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(Add2<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add2): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(Add4<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add4): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(Add8<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add8): %f (s)\\n\", k_time * 1e-9f);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(Mul1<T>), blocks, threads , 0, 0, deviceMem, repeat, 1.01);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(Mul2<T>), blocks, threads , 0, 0, deviceMem, repeat, 1.01);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(Mul4<T>), blocks, threads , 0, 0, deviceMem, repeat, 1.01);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(Mul8<T>), blocks, threads , 0, 0, deviceMem, repeat, 1.01);\n    hipDeviceSynchronize();\n  }\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(Mul1<T>), blocks, threads , 0, 0, deviceMem, repeat, 1.01);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul1): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(Mul2<T>), blocks, threads , 0, 0, deviceMem, repeat, 1.01);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul2): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(Mul4<T>), blocks, threads , 0, 0, deviceMem, repeat, 1.01);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul4): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(Mul8<T>), blocks, threads , 0, 0, deviceMem, repeat, 1.01);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul8): %f (s)\\n\", k_time * 1e-9f);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(MAdd1<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0, 0.9899);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(MAdd2<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0, 0.9899);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(MAdd4<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0, 0.9899);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(MAdd8<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0, 0.9899);\n    hipDeviceSynchronize();\n  }\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(MAdd1<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0, 0.9899);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd1): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(MAdd2<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0, 0.9899);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd2): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(MAdd4<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0, 0.9899);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd4): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(MAdd8<T>), blocks, threads , 0, 0, deviceMem, repeat, 10.0, 0.9899);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd8): %f (s)\\n\", k_time * 1e-9f);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(MulMAdd1<T>), blocks, threads , 0, 0, deviceMem, repeat, 3.75, 0.355);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(MulMAdd2<T>), blocks, threads , 0, 0, deviceMem, repeat, 3.75, 0.355);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(MulMAdd4<T>), blocks, threads , 0, 0, deviceMem, repeat, 3.75, 0.355);\n    hipLaunchKernelGGL(HIP_KERNEL_NAME(MulMAdd8<T>), blocks, threads , 0, 0, deviceMem, repeat, 3.75, 0.355);\n    hipDeviceSynchronize();\n  }\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(MulMAdd1<T>), blocks, threads , 0, 0, deviceMem, repeat, 3.75, 0.355);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd1): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(MulMAdd2<T>), blocks, threads , 0, 0, deviceMem, repeat, 3.75, 0.355);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd2): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(MulMAdd4<T>), blocks, threads , 0, 0, deviceMem, repeat, 3.75, 0.355);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd4): %f (s)\\n\", k_time * 1e-9f);\n\n  memcpyH2D(deviceMem, hostMem, numFloats);\n  k_start = std::chrono::high_resolution_clock::now(); \n  hipLaunchKernelGGL(HIP_KERNEL_NAME(MulMAdd8<T>), blocks, threads , 0, 0, deviceMem, repeat, 3.75, 0.355);\n  hipDeviceSynchronize();\n  k_end = std::chrono::high_resolution_clock::now(); \n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd8): %f (s)\\n\", k_time * 1e-9f);\n\n  hipFree(deviceMem);\n  free(hostMem);\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  const int repeat = atoi(argv[1]);\n\n  \n\n  const int numFloats = 2*1024*1024;\n\n  printf(\"=== Single-precision floating-point kernels ===\\n\");\n  test<float>(repeat, numFloats);\n\n  \n\n  printf(\"=== Double-precision floating-point kernels ===\\n\");\n  test<double>(repeat, numFloats);\n\n  return 0;\n}\n"}}
{"kernel_name": "maxFlops", "parallel_api": "omp", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include <cstdlib>\n#include <omp.h>\n#include \"kernels.h\"\n\ntemplate <typename T>\nvoid test (const int repeat, const int numFloats) \n{\n  \n\n  T *hostMem = (T*) malloc (sizeof(T) * numFloats);\n\n  srand48(123);\n  for (int j = 0; j < numFloats/2 ; ++j)\n    hostMem[j] = hostMem[numFloats-j-1] = (T)(drand48()*10.0);\n\n  #pragma omp target data map(alloc: hostMem[0:numFloats])\n  {\n    \n\n    for (int i = 0; i < 4; i++) {\n      Add1<T>(hostMem, numFloats, repeat, 10.0);\n      Add2<T>(hostMem, numFloats, repeat, 10.0);\n      Add4<T>(hostMem, numFloats, repeat, 10.0);\n      Add8<T>(hostMem, numFloats, repeat, 10.0);\n    }\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    auto k_start = std::chrono::high_resolution_clock::now(); \n    Add1<T>(hostMem, numFloats, repeat, 10.0);\n    auto k_end = std::chrono::high_resolution_clock::now(); \n    auto k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Add1): %f (s)\\n\", (k_time * 1e-9f));\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    Add2<T>(hostMem, numFloats, repeat, 10.0);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Add2): %f (s)\\n\", (k_time * 1e-9f));\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    Add4<T>(hostMem, numFloats, repeat, 10.0);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Add4): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    Add8<T>(hostMem, numFloats, repeat, 10.0);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Add8): %f (s)\\n\", k_time * 1e-9f);\n\n    \n\n    for (int i = 0; i < 4; i++) {\n      Mul1<T>(hostMem, numFloats, repeat, 1.01);\n      Mul2<T>(hostMem, numFloats, repeat, 1.01);\n      Mul4<T>(hostMem, numFloats, repeat, 1.01);\n      Mul8<T>(hostMem, numFloats, repeat, 1.01);\n    }\n\n    k_start = std::chrono::high_resolution_clock::now(); \n    Mul1<T>(hostMem, numFloats, repeat, 1.01);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Mul1): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    Mul2<T>(hostMem, numFloats, repeat, 1.01);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Mul2): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    Mul4<T>(hostMem, numFloats, repeat, 1.01);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Mul4): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    Mul8<T>(hostMem, numFloats, repeat, 1.01);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Mul8): %f (s)\\n\", k_time * 1e-9f);\n\n    \n\n    for (int i = 0; i < 4; i++) {\n      MAdd1<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n      MAdd2<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n      MAdd4<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n      MAdd8<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    }\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    MAdd1<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MAdd1): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    MAdd2<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MAdd2): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    MAdd4<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MAdd4): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    MAdd8<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MAdd8): %f (s)\\n\", k_time * 1e-9f);\n\n    \n\n    for (int i = 0; i < 4; i++) {\n      MulMAdd1<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n      MulMAdd2<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n      MulMAdd4<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n      MulMAdd8<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    }\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    MulMAdd1<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MulMAdd1): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    MulMAdd2<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MulMAdd2): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    MulMAdd4<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MulMAdd4): %f (s)\\n\", k_time * 1e-9f);\n\n    #pragma omp target update to (hostMem[0:numFloats])\n    k_start = std::chrono::high_resolution_clock::now(); \n    MulMAdd8<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MulMAdd8): %f (s)\\n\", k_time * 1e-9f);\n  }\n  \n  free(hostMem);\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  const int repeat = atoi(argv[1]);\n\n  \n\n  const int numFloats = 2*1024*1024;\n\n  printf(\"=== Single-precision floating-point kernels ===\\n\");\n  test<float>(repeat, numFloats);\n\n  \n\n  printf(\"=== Double-precision floating-point kernels ===\\n\");\n  test<double>(repeat, numFloats);\n\n  return 0;\n}\n"}}
{"kernel_name": "maxFlops", "parallel_api": "serial", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include <cstdlib>\n#include \"kernels.h\"\n\ntemplate <typename T>\nvoid test (const int repeat, const int numFloats) \n{\n  \n\n  T *hostMem = (T*) malloc (sizeof(T) * numFloats);\n\n  srand48(123);\n  for (int j = 0; j < numFloats/2 ; ++j)\n    hostMem[j] = hostMem[numFloats-j-1] = (T)(drand48()*10.0);\n\n    {\n    \n\n    for (int i = 0; i < 4; i++) {\n      Add1<T>(hostMem, numFloats, repeat, 10.0);\n      Add2<T>(hostMem, numFloats, repeat, 10.0);\n      Add4<T>(hostMem, numFloats, repeat, 10.0);\n      Add8<T>(hostMem, numFloats, repeat, 10.0);\n    }\n\n        auto k_start = std::chrono::high_resolution_clock::now(); \n    Add1<T>(hostMem, numFloats, repeat, 10.0);\n    auto k_end = std::chrono::high_resolution_clock::now(); \n    auto k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Add1): %f (s)\\n\", (k_time * 1e-9f));\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    Add2<T>(hostMem, numFloats, repeat, 10.0);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Add2): %f (s)\\n\", (k_time * 1e-9f));\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    Add4<T>(hostMem, numFloats, repeat, 10.0);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Add4): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    Add8<T>(hostMem, numFloats, repeat, 10.0);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Add8): %f (s)\\n\", k_time * 1e-9f);\n\n    \n\n    for (int i = 0; i < 4; i++) {\n      Mul1<T>(hostMem, numFloats, repeat, 1.01);\n      Mul2<T>(hostMem, numFloats, repeat, 1.01);\n      Mul4<T>(hostMem, numFloats, repeat, 1.01);\n      Mul8<T>(hostMem, numFloats, repeat, 1.01);\n    }\n\n    k_start = std::chrono::high_resolution_clock::now(); \n    Mul1<T>(hostMem, numFloats, repeat, 1.01);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Mul1): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    Mul2<T>(hostMem, numFloats, repeat, 1.01);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Mul2): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    Mul4<T>(hostMem, numFloats, repeat, 1.01);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Mul4): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    Mul8<T>(hostMem, numFloats, repeat, 1.01);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (Mul8): %f (s)\\n\", k_time * 1e-9f);\n\n    \n\n    for (int i = 0; i < 4; i++) {\n      MAdd1<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n      MAdd2<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n      MAdd4<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n      MAdd8<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    }\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    MAdd1<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MAdd1): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    MAdd2<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MAdd2): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    MAdd4<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MAdd4): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    MAdd8<T>(hostMem, numFloats, repeat, 10.0, 0.9899);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MAdd8): %f (s)\\n\", k_time * 1e-9f);\n\n    \n\n    for (int i = 0; i < 4; i++) {\n      MulMAdd1<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n      MulMAdd2<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n      MulMAdd4<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n      MulMAdd8<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    }\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    MulMAdd1<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MulMAdd1): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    MulMAdd2<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MulMAdd2): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    MulMAdd4<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MulMAdd4): %f (s)\\n\", k_time * 1e-9f);\n\n        k_start = std::chrono::high_resolution_clock::now(); \n    MulMAdd8<T>(hostMem, numFloats, repeat, 3.75, 0.355);\n    k_end = std::chrono::high_resolution_clock::now(); \n    k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n    printf(\"kernel execution time (MulMAdd8): %f (s)\\n\", k_time * 1e-9f);\n  }\n  \n  free(hostMem);\n}\n\nint main(int argc, char* argv[]) \n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  const int repeat = atoi(argv[1]);\n\n  \n\n  const int numFloats = 2*1024*1024;\n\n  printf(\"=== Single-precision floating-point kernels ===\\n\");\n  test<float>(repeat, numFloats);\n\n  \n\n  printf(\"=== Double-precision floating-point kernels ===\\n\");\n  test<double>(repeat, numFloats);\n\n  return 0;\n}"}}
{"kernel_name": "maxFlops", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <iostream>\n#include <cstdlib>\n#include <sycl/sycl.hpp>\n#include \"kernels.h\"\n\n\n\n#define BLOCK_SIZE 256\n\ntemplate <class T>\nvoid test (sycl::queue &q, const int repeat, const int numFloats)\n{\n  \n\n  T *hostMem = (T*) malloc (sizeof(T) * numFloats);\n\n  srand48(123);\n  for (int j = 0; j < numFloats/2 ; ++j)\n    hostMem[j] = hostMem[numFloats-j-1] = (T)(drand48()*10.0);\n\n  T *deviceMem = sycl::malloc_device<T>(numFloats, q);\n\n  sycl::range<1> gws (numFloats);\n  sycl::range<1> lws (BLOCK_SIZE);\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        Add1<T>(item, deviceMem, repeat, 10.0);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        Add2<T>(item, deviceMem, repeat, 10.0);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        Add4<T>(item, deviceMem, repeat, 10.0);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        Add8<T>(item, deviceMem, repeat, 10.0);\n      });\n    });\n    q.wait();\n  }\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  auto k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class add1<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      Add1<T>(item, deviceMem, repeat, 10.0);\n    });\n  });\n  q.wait();\n  auto k_end = std::chrono::high_resolution_clock::now();\n  auto k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add1): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class add2<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      Add2<T>(item, deviceMem, repeat, 10.0);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add2): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class add4<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      Add4<T>(item, deviceMem, repeat, 10.0);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add4): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class add8<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      Add8<T>(item, deviceMem, repeat, 10.0);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Add8): %f (s)\\n\", (k_time * 1e-9f));\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        Mul1<T>(item, deviceMem, repeat, 1.01);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        Mul2<T>(item, deviceMem, repeat, 1.01);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        Mul4<T>(item, deviceMem, repeat, 1.01);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        Mul8<T>(item, deviceMem, repeat, 1.01);\n      });\n    });\n    q.wait();\n  }\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class mul1<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      Mul1<T>(item, deviceMem, repeat, 1.01);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul1): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class mul2<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      Mul2<T>(item, deviceMem, repeat, 1.01);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul2): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class mul4<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      Mul4<T>(item, deviceMem, repeat, 1.01);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul4): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class mul8<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      Mul8<T>(item, deviceMem, repeat, 1.01);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (Mul8): %f (s)\\n\", (k_time * 1e-9f));\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        MAdd1<T>(item, deviceMem, repeat, 10.0, 0.9899);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        MAdd2<T>(item, deviceMem, repeat, 10.0, 0.9899);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        MAdd4<T>(item, deviceMem, repeat, 10.0, 0.9899);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        MAdd8<T>(item, deviceMem, repeat, 10.0, 0.9899);\n      });\n    });\n    q.wait();\n  }\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class madd1<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      MAdd1<T>(item, deviceMem, repeat, 10.0, 0.9899);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd1): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class madd2<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      MAdd2<T>(item, deviceMem, repeat, 10.0, 0.9899);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd2): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class madd4<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      MAdd4<T>(item, deviceMem, repeat, 10.0, 0.9899);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd4): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class madd8<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      MAdd8<T>(item, deviceMem, repeat, 10.0, 0.9899);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MAdd8): %f (s)\\n\", (k_time * 1e-9f));\n\n  \n\n  for (int i = 0; i < 4; i++) {\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        MulMAdd1<T>(item, deviceMem, repeat, 3.75, 0.355);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        MulMAdd2<T>(item, deviceMem, repeat, 3.75, 0.355);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        MulMAdd4<T>(item, deviceMem, repeat, 3.75, 0.355);\n      });\n    });\n    q.submit([&](sycl::handler &cgh) {\n      cgh.parallel_for<>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        MulMAdd8<T>(item, deviceMem, repeat, 3.75, 0.355);\n      });\n    });\n    q.wait();\n  }\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class mmadd1<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      MulMAdd1<T>(item, deviceMem, repeat, 3.75, 0.355);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd1): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class mmadd2<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      MulMAdd2<T>(item, deviceMem, repeat, 3.75, 0.355);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd2): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class mmadd4<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      MulMAdd4<T>(item, deviceMem, repeat, 3.75, 0.355);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd4): %f (s)\\n\", (k_time * 1e-9f));\n\n  q.memcpy(deviceMem, hostMem, sizeof(T) * numFloats).wait();\n  k_start = std::chrono::high_resolution_clock::now();\n  q.submit([&](sycl::handler &cgh) {\n    cgh.parallel_for<class mmadd8<T>>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n      MulMAdd8<T>(item, deviceMem, repeat, 3.75, 0.355);\n    });\n  });\n  q.wait();\n  k_end = std::chrono::high_resolution_clock::now();\n  k_time = std::chrono::duration_cast<std::chrono::nanoseconds>(k_end - k_start).count();\n  printf(\"kernel execution time (MulMAdd8): %f (s)\\n\", (k_time * 1e-9f));\n\n  free(hostMem);\n  sycl::free(deviceMem, q);\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  \n\n  const int repeat = atoi(argv[1]);\n\n  \n\n  const int numFloats = 2*1024*1024;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  printf(\"=== Single-precision floating-point kernels ===\\n\");\n  test<float>(q, repeat, numFloats);\n\n  \n\n  printf(\"=== Double-precision floating-point kernels ===\\n\");\n  test<double>(q, repeat, numFloats);\n\n  return 0;\n}\n"}}
{"kernel_name": "mixbench", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\n__global__ void benchmark_func(float *g_data,\n                               const int compute_iterations)\n{\n  const unsigned int blockSize = blockDim.x;\n  const int stride = blockSize;\n  int idx = blockIdx.x*blockSize*granularity + threadIdx.x;\n  const int big_stride = gridDim.x*blockSize*granularity;\n\n  float tmps[granularity];\n  for(int k=0; k<fusion_degree; k++) {\n    #pragma unroll\n    for(int j=0; j<granularity; j++) {\n      \n\n      tmps[j] = g_data[idx+j*stride+k*big_stride];\n\n      \n\n      for(int i=0; i<compute_iterations; i++)\n        tmps[j] = tmps[j]*tmps[j]+seed;\n    }\n\n    \n\n    float sum = 0.f;\n    #pragma unroll\n    for(int j=0; j<granularity; j+=2)\n      sum += tmps[j]*tmps[j+1];\n\n    #pragma unroll\n    for(int j=0; j<granularity; j++)\n      g_data[idx+k*big_stride] = sum;\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size/block_dim;\n\n  float *d_cd;\n  cudaMalloc((void**)&d_cd, size*sizeof(float));\n  cudaMemcpy(d_cd, cd,  size*sizeof(float), cudaMemcpyHostToDevice);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    benchmark_func<<<grid_dim, block_dim>>>(d_cd, i);\n  }\n\n  cudaDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    benchmark_func<<<grid_dim, block_dim>>>(d_cd, i);\n  }\n\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  cudaMemcpy(cd, d_cd, size*sizeof(float), cudaMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(cd);\n  cudaFree(d_cd);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mixbench", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\n__global__ void benchmark_func(float *g_data,\n                               const int compute_iterations)\n{\n  const unsigned int blockSize = blockDim.x;\n  const int stride = blockSize;\n  int idx = blockIdx.x*blockSize*granularity + threadIdx.x;\n  const int big_stride = gridDim.x*blockSize*granularity;\n\n  float tmps[granularity];\n  for(int k=0; k<fusion_degree; k++) {\n    #pragma unroll\n    for(int j=0; j<granularity; j++) {\n      \n\n      tmps[j] = g_data[idx+j*stride+k*big_stride];\n\n      \n\n      for(int i=0; i<compute_iterations; i++)\n        tmps[j] = tmps[j]*tmps[j]+seed;\n    }\n\n    \n\n    float sum = 0.f;\n    #pragma unroll\n    for(int j=0; j<granularity; j+=2)\n      sum += tmps[j]*tmps[j+1];\n\n    #pragma unroll\n    for(int j=0; j<granularity; j++)\n      g_data[idx+k*big_stride] = sum;\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size/block_dim;\n\n  float *d_cd;\n  hipMalloc((void**)&d_cd, size*sizeof(float));\n  hipMemcpy(d_cd, cd,  size*sizeof(float), hipMemcpyHostToDevice);\n\n  \n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(benchmark_func, grid_dim, 0, 0, d_cd, block_dim, i);\n  }\n\n  hipDeviceSynchronize();\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    hipLaunchKernelGGL(benchmark_func, grid_dim, 0, 0, d_cd, block_dim, i);\n  }\n\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n\n  hipMemcpy(cd, d_cd, size*sizeof(float), hipMemcpyDeviceToHost);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(cd);\n  hipFree(d_cd);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mixbench", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\nvoid benchmark_func(float *cd, int grid_dim, int block_dim, int compute_iterations) { \n      \n  #pragma omp target teams num_teams(grid_dim) thread_limit(block_dim)\n  { \n    #pragma omp parallel \n    {\n      const unsigned int blockSize = block_dim;\n      const int stride = blockSize;\n      int idx = omp_get_team_num()*blockSize*granularity + omp_get_thread_num();\n      const int big_stride = omp_get_num_teams()*blockSize*granularity;\n      float tmps[granularity];\n      for(int k=0; k<fusion_degree; k++) {\n        #pragma unroll\n        for(int j=0; j<granularity; j++) {\n          \n\n          tmps[j] = cd[idx+j*stride+k*big_stride];\n\n          \n\n          for(int i=0; i<compute_iterations; i++)\n            tmps[j] = tmps[j]*tmps[j]+(float)seed;\n        }\n\n        \n\n        float sum = 0;\n        #pragma unroll\n        for(int j=0; j<granularity; j+=2)\n          sum += tmps[j]*tmps[j+1];\n\n        #pragma unroll\n        for(int j=0; j<granularity; j++)\n          cd[idx+k*big_stride] = sum;\n      }\n    }\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size/block_dim;\n\n  #pragma omp target data map(tofrom: cd[0:size]) \n  {\n    \n\n    for (int i = 0; i < repeat; i++) {\n      benchmark_func(cd, grid_dim, block_dim, i);\n    }\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      benchmark_func(cd, grid_dim, block_dim, i);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  }\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(cd);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "mixbench", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <chrono>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\nvoid benchmark_func(float *cd, int grid_dim, int block_dim, int compute_iterations) { \n      \n    { \n        {\n      const unsigned int blockSize = block_dim;\n      const int stride = blockSize;\n      int idx = omp_get_team_num()*blockSize*granularity + omp_get_thread_num();\n      const int big_stride = omp_get_num_teams()*blockSize*granularity;\n      float tmps[granularity];\n      for(int k=0; k<fusion_degree; k++) {\n                for(int j=0; j<granularity; j++) {\n          \n\n          tmps[j] = cd[idx+j*stride+k*big_stride];\n\n          \n\n          for(int i=0; i<compute_iterations; i++)\n            tmps[j] = tmps[j]*tmps[j]+(float)seed;\n        }\n\n        \n\n        float sum = 0;\n                for(int j=0; j<granularity; j+=2)\n          sum += tmps[j]*tmps[j+1];\n\n                for(int j=0; j<granularity; j++)\n          cd[idx+k*big_stride] = sum;\n      }\n    }\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size/block_dim;\n\n    {\n    \n\n    for (int i = 0; i < repeat; i++) {\n      benchmark_func(cd, grid_dim, block_dim, i);\n    }\n\n    auto start = std::chrono::steady_clock::now();\n\n    for (int i = 0; i < repeat; i++) {\n      benchmark_func(cd, grid_dim, block_dim, i);\n    }\n\n    auto end = std::chrono::steady_clock::now();\n    auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n    printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  }\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n\n  free(cd);\n}\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}"}}
{"kernel_name": "mixbench", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n#include <math.h>\n#include <sycl/sycl.hpp>\n\n#define VECTOR_SIZE (8*1024*1024)\n#define granularity (8)\n#define fusion_degree (4)\n#define seed 0.1f\n\nvoid benchmark_func(sycl::nd_item<1> &item,\n                    float *g_data,\n                    const int compute_iterations)\n{\n  const unsigned int blockSize = item.get_local_range(0);\n  const int stride = blockSize;\n  int idx = item.get_group(0)*blockSize*granularity + item.get_local_id(0);\n  const int big_stride = item.get_group_range(0)*blockSize*granularity;\n\n  float tmps[granularity];\n  for(int k=0; k<fusion_degree; k++){\n    #pragma unroll\n    for(int j=0; j<granularity; j++){\n      \n\n      tmps[j] = g_data[idx+j*stride+k*big_stride];\n      \n\n      for(int i=0; i<compute_iterations; i++)\n        tmps[j] = tmps[j]*tmps[j]+(float)seed;\n    }\n    \n\n    float sum = 0;\n    #pragma unroll\n    for(int j=0; j<granularity; j+=2)\n      sum += tmps[j]*tmps[j+1];\n    #pragma unroll\n    for(int j=0; j<granularity; j++)\n      g_data[idx+k*big_stride] = sum;\n  }\n}\n\nvoid mixbenchGPU(long size, int repeat) {\n  const char *benchtype = \"compute with global memory (block strided)\";\n  printf(\"Trade-off type:%s\\n\", benchtype);\n  float *cd = (float*) malloc (size*sizeof(float));\n  for (int i = 0; i < size; i++) cd[i] = 0;\n\n  const long reduced_grid_size = size/granularity/128;\n  const int block_dim = 256;\n  const int grid_dim = reduced_grid_size;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  float *d_cd = sycl::malloc_device<float>(size, q);\n  q.memcpy(d_cd, cd, sizeof(float) * size);\n\n  sycl::range<1> gws (grid_dim);\n  sycl::range<1> lws (block_dim);\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class mixbench_warmup>(\n        sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        benchmark_func(item, d_cd, i);\n      });\n    });\n  }\n  q.wait();\n\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class mixbench_timing>(\n        sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        benchmark_func(item, d_cd, i);\n      });\n    });\n  }\n\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  \n  q.memcpy(cd, d_cd, sizeof(float) * size).wait();\n  sycl::free(d_cd, q);\n\n  \n\n  bool ok = true;\n  for (int i = 0; i < size; i++) {\n    if (cd[i] != 0) {\n      if (fabsf(cd[i] - 0.050807f) > 1e-6f) {\n        ok = false;\n        printf(\"Verification failed at index %d: %f\\n\", i, cd[i]);\n        break;\n      }\n    }\n  }\n\n  free(cd);\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n}\n\n\nint main(int argc, char* argv[]) {\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  unsigned int datasize = VECTOR_SIZE*sizeof(float);\n\n  printf(\"Buffer size: %dMB\\n\", datasize/(1024*1024));\n\n  mixbenchGPU(VECTOR_SIZE, repeat);\n\n  return 0;\n}\n"}}
{"kernel_name": "openmp", "parallel_api": "cuda", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <cuda.h>\n#include \"reference.h\"\n\n\n\n__global__ void addConstant(int *g_a, const int b, const int repeat) {\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  for (int i = 0; i < repeat; i++)\n    g_a[idx] += i % b;\n}\n\nint main(int argc, char *argv[]) {\n\n  printf(\"%s Starting...\\n\\n\", argv[0]);\n  const int repeat = atoi(argv[1]);\n\n  int num_gpus = 1; \n\n\n  printf(\"number of host CPUs:\\t%d\\n\", omp_get_num_procs());\n  printf(\"number of devices:\\t%d\\n\", num_gpus);\n\n  \n\n  unsigned int nwords = num_gpus * 33554432;\n  unsigned int nbytes = nwords * sizeof(int);\n  int b = 3;   \n\n  int *a = (int *)malloc(nbytes); \n\n\n  if (NULL == a) {\n    printf(\"couldn't allocate CPU memory\\n\");\n    return 1;\n  }\n\n  double overhead = 0; \n\n\n  \n\n  \n\n  for (int i = 0; i < 2; i++) {\n    for (int f = 1; f <= 32; f = f*2) {\n      double start = omp_get_wtime();\n      omp_set_num_threads(f * num_gpus); \n      #pragma omp parallel\n      {\n        unsigned int cpu_thread_id = omp_get_thread_num();\n        unsigned int num_cpu_threads = omp_get_num_threads();\n\n        \n\n        unsigned int nwords_per_kernel = nwords / num_cpu_threads;\n        unsigned int nbytes_per_kernel = nbytes / num_cpu_threads;\n        int *sub_a = a + cpu_thread_id * nwords_per_kernel;\n\n        for (unsigned int n = 0; n < nwords_per_kernel; n++)\n          sub_a[n] = n + cpu_thread_id * nwords_per_kernel;\n\n        dim3 gpu_threads(256);\n        dim3 gpu_blocks(nwords / (256 * num_cpu_threads));\n\n        \n\n        int *d_a = 0;\n        cudaMalloc((void **)&d_a, nbytes_per_kernel);\n        cudaMemcpy(d_a, sub_a, nbytes_per_kernel, cudaMemcpyHostToDevice);\n        addConstant<<<gpu_blocks, gpu_threads>>>(d_a, b, repeat);\n        cudaMemcpy(sub_a, d_a, nbytes_per_kernel, cudaMemcpyDeviceToHost);\n        cudaFree(d_a);\n      }\n      double end = omp_get_wtime();\n      printf(\"Work took %f seconds with %d CPU threads\\n\", end - start, f*num_gpus);\n      \n      if (f == 1) {\n        if (i == 0) \n          overhead = end - start;\n        else\n          overhead = overhead - (end - start);\n      }\n      \n\n      bool bResult = correctResult(a, nwords, b, repeat);\n      printf(\"%s\\n\", bResult ? \"PASS\" : \"FAIL\");\n    }\n  }\n  printf(\"Runtime overhead of first run is %f seconds\\n\", overhead);\n\n  free(a);\n  return 0;\n}\n"}}
{"kernel_name": "openmp", "parallel_api": "hip", "code": {"main.cu": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <hip/hip_runtime.h>\n#include \"reference.h\"\n\n\n\n__global__ void addConstant(int *g_a, const int b, const int repeat) {\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  for (int i = 0; i < repeat; i++)\n    g_a[idx] += i % b;\n}\n\nint main(int argc, char *argv[]) {\n\n  printf(\"%s Starting...\\n\\n\", argv[0]);\n  const int repeat = atoi(argv[1]);\n\n  int num_gpus = 1; \n\n\n  printf(\"number of host CPUs:\\t%d\\n\", omp_get_num_procs());\n  printf(\"number of devices:\\t%d\\n\", num_gpus);\n\n  \n\n  unsigned int nwords = num_gpus * 33554432;\n  unsigned int nbytes = nwords * sizeof(int);\n  int b = 3;   \n\n  int *a = (int *)malloc(nbytes); \n\n\n  if (NULL == a) {\n    printf(\"couldn't allocate CPU memory\\n\");\n    return 1;\n  }\n\n  double overhead = 0; \n\n\n  \n\n  \n\n  for (int i = 0; i < 2; i++) {\n    for (int f = 1; f <= 32; f = f*2) {\n      double start = omp_get_wtime();\n      omp_set_num_threads(f * num_gpus); \n      #pragma omp parallel\n      {\n        unsigned int cpu_thread_id = omp_get_thread_num();\n        unsigned int num_cpu_threads = omp_get_num_threads();\n\n        \n\n        unsigned int nwords_per_kernel = nwords / num_cpu_threads;\n        unsigned int nbytes_per_kernel = nbytes / num_cpu_threads;\n        int *sub_a = a + cpu_thread_id * nwords_per_kernel;\n\n        for (unsigned int n = 0; n < nwords_per_kernel; n++)\n          sub_a[n] = n + cpu_thread_id * nwords_per_kernel;\n\n        dim3 gpu_threads(256);\n        dim3 gpu_blocks(nwords / (256 * num_cpu_threads));\n\n        \n\n        int *d_a = 0;\n        hipMalloc((void **)&d_a, nbytes_per_kernel);\n        hipMemcpy(d_a, sub_a, nbytes_per_kernel, hipMemcpyHostToDevice);\n        hipLaunchKernelGGL(addConstant, gpu_blocks, gpu_threads, 0, 0, d_a, b, repeat);\n        hipMemcpy(sub_a, d_a, nbytes_per_kernel, hipMemcpyDeviceToHost);\n        hipFree(d_a);\n      }\n      double end = omp_get_wtime();\n      printf(\"Work took %f seconds with %d CPU threads\\n\", end - start, f*num_gpus);\n      \n      if (f == 1) {\n        if (i == 0) \n          overhead = end - start;\n        else\n          overhead = overhead - (end - start);\n      }\n      \n\n      bool bResult = correctResult(a, nwords, b, repeat);\n      printf(\"%s\\n\", bResult ? \"PASS\" : \"FAIL\");\n    }\n  }\n  printf(\"Runtime overhead of first run is %f seconds\\n\", overhead);\n\n  free(a);\n  return 0;\n}\n"}}
{"kernel_name": "openmp", "parallel_api": "omp", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include \"reference.h\"\n\nint main(int argc, char *argv[]) {\n\n  printf(\"%s Starting...\\n\\n\", argv[0]);\n  const int repeat = atoi(argv[1]);\n\n  int num_gpus = 1; \n\n\n  printf(\"number of host CPUs:\\t%d\\n\", omp_get_num_procs());\n  printf(\"number of devices:\\t%d\\n\", num_gpus);\n\n  \n\n  unsigned int nwords = num_gpus * 33554432;\n  unsigned int nbytes = nwords * sizeof(int);\n  int b = 3;   \n\n  int *a = (int *)malloc(nbytes); \n\n\n  if (NULL == a) {\n    printf(\"couldn't allocate CPU memory\\n\");\n    return 1;\n  }\n  double overhead; \n\n\n  \n\n  \n\n  for (int i = 0; i < 2; i++) {\n    for (int f = 1; f <= 32; f = f*2) {\n      double start = omp_get_wtime();\n      omp_set_num_threads(f * num_gpus); \n      #pragma omp parallel\n      {\n        unsigned int cpu_thread_id = omp_get_thread_num();\n        unsigned int num_cpu_threads = omp_get_num_threads();\n\n        \n\n        unsigned int nwords_per_kernel = nwords / num_cpu_threads;\n        int *sub_a = a + cpu_thread_id * nwords_per_kernel;\n\n        for (unsigned int n = 0; n < nwords_per_kernel; n++)\n          sub_a[n] = n + cpu_thread_id * nwords_per_kernel;\n\n        #pragma omp target data map (tofrom: sub_a[0:nwords_per_kernel])\n        {\n          #pragma omp target teams distribute parallel for thread_limit(256)\n          for (int idx = 0; idx < nwords_per_kernel; idx++) {\n            for (int i = 0; i < repeat; i++)\n              sub_a[idx] += i % b;\n          }\n        }\n      }\n      double end = omp_get_wtime();\n      printf(\"Work took %f seconds with %d CPU threads\\n\", end - start, f*num_gpus);\n      \n      if (f == 1) {\n        if (i == 0) \n          overhead = end - start;\n        else\n          overhead = overhead - (end - start);\n      }\n      \n\n      bool bResult = correctResult(a, nwords, b, repeat);\n      printf(\"%s\\n\", bResult ? \"PASS\" : \"FAIL\");\n    }\n  }\n  printf(\"Runtime overhead of first run is %f seconds\\n\", overhead);\n\n  free(a);\n  return 0;\n}\n"}}
{"kernel_name": "openmp", "parallel_api": "serial", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include \"reference.h\"\n\nint main(int argc, char *argv[]) {\n\n  printf(\"%s Starting...\\n\\n\", argv[0]);\n  const int repeat = atoi(argv[1]);\n\n  int num_gpus = 1; \n\n\n  printf(\"number of host CPUs:\\t%d\\n\", omp_get_num_procs());\n  printf(\"number of devices:\\t%d\\n\", num_gpus);\n\n  \n\n  unsigned int nwords = num_gpus * 33554432;\n  unsigned int nbytes = nwords * sizeof(int);\n  int b = 3;   \n\n  int *a = (int *)malloc(nbytes); \n\n\n  if (NULL == a) {\n    printf(\"couldn't allocate CPU memory\\n\");\n    return 1;\n  }\n  double overhead; \n\n\n  \n\n  \n\n  for (int i = 0; i < 2; i++) {\n    for (int f = 1; f <= 32; f = f*2) {\n      double start = omp_get_wtime();\n      omp_set_num_threads(f * num_gpus); \n            {\n        unsigned int cpu_thread_id = omp_get_thread_num();\n        unsigned int num_cpu_threads = omp_get_num_threads();\n\n        \n\n        unsigned int nwords_per_kernel = nwords / num_cpu_threads;\n        int *sub_a = a + cpu_thread_id * nwords_per_kernel;\n\n        for (unsigned int n = 0; n < nwords_per_kernel; n++)\n          sub_a[n] = n + cpu_thread_id * nwords_per_kernel;\n\n                {\n                    for (int idx = 0; idx < nwords_per_kernel; idx++) {\n            for (int i = 0; i < repeat; i++)\n              sub_a[idx] += i % b;\n          }\n        }\n      }\n      double end = omp_get_wtime();\n      printf(\"Work took %f seconds with %d CPU threads\\n\", end - start, f*num_gpus);\n      \n      if (f == 1) {\n        if (i == 0) \n          overhead = end - start;\n        else\n          overhead = overhead - (end - start);\n      }\n      \n\n      bool bResult = correctResult(a, nwords, b, repeat);\n      printf(\"%s\\n\", bResult ? \"PASS\" : \"FAIL\");\n    }\n  }\n  printf(\"Runtime overhead of first run is %f seconds\\n\", overhead);\n\n  free(a);\n  return 0;\n}"}}
{"kernel_name": "openmp", "parallel_api": "sycl", "code": {"main.cpp": "\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sycl/sycl.hpp>\n#include \"reference.h\"\n\nint main(int argc, char *argv[]) {\n\n  printf(\"%s Starting...\\n\\n\", argv[0]);\n  const int repeat = atoi(argv[1]);\n\n  int num_gpus = 1; \n\n\n  printf(\"number of host CPUs:\\t%d\\n\", omp_get_num_procs());\n  printf(\"number of devices:\\t%d\\n\", num_gpus);\n\n  \n\n  unsigned int nwords = num_gpus * 33554432;\n  unsigned int nbytes = nwords * sizeof(int);\n  int b = 3;   \n\n  int *a = (int *)malloc(nbytes); \n\n\n  if (NULL == a) {\n    printf(\"couldn't allocate CPU memory\\n\");\n    return 1;\n  }\n\n  double overhead = 0; \n\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  \n\n  \n\n  for (int i = 0; i < 2; i++) {\n    for (int f = 1; f <= 32; f = f*2) {\n      double start = omp_get_wtime();\n      omp_set_num_threads(f * num_gpus);\n      #pragma omp parallel\n      {\n        unsigned int cpu_thread_id = omp_get_thread_num();\n        unsigned int num_cpu_threads = omp_get_num_threads();\n\n        \n\n        unsigned int nwords_per_kernel = nwords / num_cpu_threads;\n        unsigned int nbytes_per_kernel = nbytes / num_cpu_threads;\n        int *sub_a = a + cpu_thread_id * nwords_per_kernel;\n\n        for (unsigned int n = 0; n < nwords_per_kernel; n++)\n          sub_a[n] = n + cpu_thread_id * nwords_per_kernel;\n\n        sycl::range<1> lws (256);\n        sycl::range<1> gws (nwords_per_kernel);\n\n        \n\n        int *d_a = sycl::malloc_device<int>(nwords_per_kernel, q);\n        q.memcpy(d_a, sub_a, nbytes_per_kernel);\n        q.submit([&] (sycl::handler &cgh) {\n          cgh.parallel_for<class addConstant>(\n            sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n            int idx = item.get_global_id(0);\n            for (int i = 0; i < repeat; i++)\n              d_a[idx] += i % b;\n          });\n        });\n        q.memcpy(sub_a, d_a, nbytes_per_kernel).wait();\n        sycl::free(d_a, q);\n      }\n      double end = omp_get_wtime();\n      printf(\"Work took %f seconds with %d CPU threads\\n\", end - start, f*num_gpus);\n\n      if (f == 1) {\n        if (i == 0)\n          overhead = end - start;\n        else\n          overhead -= (end - start);\n      }\n      \n\n      bool bResult = correctResult(a, nwords, b, repeat);\n      printf(\"%s\\n\", bResult ? \"PASS\" : \"FAIL\");\n    }\n  }\n  printf(\"Runtime overhead of first run is %f seconds\\n\", overhead);\n\n  free(a);\n  return 0;\n}\n"}}
{"kernel_name": "popcount", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <cuda.h>\n\n#define m1  0x5555555555555555\n#define m2  0x3333333333333333 \n#define m4  0x0f0f0f0f0f0f0f0f \n#define h01 0x0101010101010101\n\n#define BLOCK_SIZE 256\n\n\n\nint popcount_ref(unsigned long x)\n{\n  int count;\n  for (count=0; x; count++)\n    x &= x - 1;\n  return count;\n}\n\n\n\n__global__ void pc1 (const unsigned long* __restrict__ data,int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  unsigned long x = data[i];\n  x -= (x >> 1) & m1;             \n\n  x = (x & m2) + ((x >> 2) & m2); \n\n  x = (x + (x >> 4)) & m4;        \n\n  x += x >>  8;  \n\n  x += x >> 16;  \n\n  x += x >> 32;  \n\n  r[i] = x & 0x7f;\n}\n\n__global__ void pc2 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  unsigned long x = data[i];\n  x -= (x >> 1) & m1;             \n\n  x = (x & m2) + ((x >> 2) & m2); \n\n  x = (x + (x >> 4)) & m4;        \n\n  r[i] = (x * h01) >> 56;  \n\n}\n\n__global__ void pc3 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  char count;\n  unsigned long x = data[i];\n  for (count=0; x; count++) x &= x - 1;\n  r[i] = count;\n}\n\n__global__ void pc4 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  unsigned long x = data[i];\n  char cnt = 0;\n  for (char i = 0; i < 64; i++)\n  {\n    cnt = cnt + (x & 0x1);\n    x = x >> 1;\n  }\n  r[i] = cnt;\n}\n\n__global__ void pc5 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  unsigned long x = data[i];\n  const unsigned char a[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n  const unsigned char b[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n  const unsigned char c[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n  const unsigned char d[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n\n  unsigned char i1 = a[(x & 0xFF)];\n  unsigned char i2 = a[(x >> 8) & 0xFF];\n  unsigned char i3 = b[(x >> 16) & 0xFF];\n  unsigned char i4 = b[(x >> 24) & 0xFF];\n  unsigned char i5 = c[(x >> 32) & 0xFF];\n  unsigned char i6 = c[(x >> 40) & 0xFF];\n  unsigned char i7 = d[(x >> 48) & 0xFF];\n  unsigned char i8 = d[(x >> 56) & 0xFF];\n  r[i] = (i1+i2)+(i3+i4)+(i5+i6)+(i7+i8);\n}\n\n__global__ void pc6 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  r[i] = __popcll(data[i]);\n}\n\nvoid checkResults(const unsigned long *d, const int *r, const int length)\n{\n  int error = 0;\n  for (int i=0;i<length;i++)\n    if (popcount_ref(d[i]) != r[i]) {\n      error = 1;\n      break;\n    }\n\n  if (error)\n    printf(\"Fail\\n\");\n  else\n    printf(\"Success\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  unsigned long *data = NULL;\n  int *result = NULL;\n  int s1 = posix_memalign((void**)&data, 1024, length*sizeof(unsigned long));\n  int s2 = posix_memalign((void**)&result, 1024, length*sizeof(int));\n  if (s1 != 0 || s2 != 0) {\n    printf(\"Error: posix_memalign fails\\n\");\n    if (s1 == 0) free(data);\n    if (s2 == 0) free(result);\n    return 1;\n  }\n\n  \n\n  srand(2);\n  for (int i = 0; i < length; i++) {\n    unsigned long t = (unsigned long)rand() << 32;\n    data[i] = t | rand();\n  }\n\n  \n\n\n  unsigned long* d_data;\n  cudaMalloc((void**)&d_data, sizeof(unsigned long)*length);\n  cudaMemcpy(d_data, data, sizeof(unsigned long)*length, cudaMemcpyHostToDevice);\n\n  int* d_result;\n  cudaMalloc((void**)&d_result, sizeof(int)*length);\n\n  dim3 grids ((length+BLOCK_SIZE-1)/BLOCK_SIZE);\n  dim3 threads (BLOCK_SIZE);\n\n  auto start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    pc1<<<grids, threads>>>(d_data, d_result, length);\n  }\n  cudaDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc1): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  cudaMemcpy(result, d_result, sizeof(int)*length, cudaMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    pc2<<<grids, threads>>>(d_data, d_result, length);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc2): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  cudaMemcpy(result, d_result, sizeof(int)*length, cudaMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    pc3<<<grids, threads>>>(d_data, d_result, length);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc3): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  cudaMemcpy(result, d_result, sizeof(int)*length, cudaMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    pc4<<<grids, threads>>>(d_data, d_result, length);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc4): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  cudaMemcpy(result, d_result, sizeof(int)*length, cudaMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    pc5<<<grids, threads>>>(d_data, d_result, length);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc5): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  cudaMemcpy(result, d_result, sizeof(int)*length, cudaMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    pc6<<<grids, threads>>>(d_data, d_result, length);\n  }\n  cudaDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc6): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  cudaMemcpy(result, d_result, sizeof(int)*length, cudaMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  cudaFree(d_data);\n  cudaFree(d_result);\n  free(data);\n  free(result);\n  return 0;\n}\n"}}
{"kernel_name": "popcount", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n#define m1  0x5555555555555555\n#define m2  0x3333333333333333 \n#define m4  0x0f0f0f0f0f0f0f0f \n#define h01 0x0101010101010101\n\n#define BLOCK_SIZE 256\n\n\n\nint popcount_ref(unsigned long x)\n{\n  int count;\n  for (count=0; x; count++)\n    x &= x - 1;\n  return count;\n}\n\n\n\n__global__ void pc1 (const unsigned long* __restrict__ data,int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  unsigned long x = data[i];\n  x -= (x >> 1) & m1;             \n\n  x = (x & m2) + ((x >> 2) & m2); \n\n  x = (x + (x >> 4)) & m4;        \n\n  x += x >>  8;  \n\n  x += x >> 16;  \n\n  x += x >> 32;  \n\n  r[i] = x & 0x7f;\n}\n\n__global__ void pc2 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  unsigned long x = data[i];\n  x -= (x >> 1) & m1;             \n\n  x = (x & m2) + ((x >> 2) & m2); \n\n  x = (x + (x >> 4)) & m4;        \n\n  r[i] = (x * h01) >> 56;  \n\n}\n\n__global__ void pc3 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  char count;\n  unsigned long x = data[i];\n  for (count=0; x; count++) x &= x - 1;\n  r[i] = count;\n}\n\n__global__ void pc4 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  unsigned long x = data[i];\n  char cnt = 0;\n  for (char i = 0; i < 64; i++)\n  {\n    cnt = cnt + (x & 0x1);\n    x = x >> 1;\n  }\n  r[i] = cnt;\n}\n\n__global__ void pc5 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  unsigned long x = data[i];\n  const unsigned char a[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n  const unsigned char b[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n  const unsigned char c[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n  const unsigned char d[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n\n  unsigned char i1 = a[(x & 0xFF)];\n  unsigned char i2 = a[(x >> 8) & 0xFF];\n  unsigned char i3 = b[(x >> 16) & 0xFF];\n  unsigned char i4 = b[(x >> 24) & 0xFF];\n  unsigned char i5 = c[(x >> 32) & 0xFF];\n  unsigned char i6 = c[(x >> 40) & 0xFF];\n  unsigned char i7 = d[(x >> 48) & 0xFF];\n  unsigned char i8 = d[(x >> 56) & 0xFF];\n  r[i] = (i1+i2)+(i3+i4)+(i5+i6)+(i7+i8);\n}\n\n__global__ void pc6 (const unsigned long* __restrict__ data, int* __restrict__ r, const int length)\n{\n  int i = blockIdx.x*blockDim.x+threadIdx.x;\n  if (i >= length) return;\n  r[i] = __popcll(data[i]);\n}\n\nvoid checkResults(const unsigned long *d, const int *r, const int length)\n{\n  int error = 0;\n  for (int i=0;i<length;i++)\n    if (popcount_ref(d[i]) != r[i]) {\n      error = 1;\n      break;\n    }\n\n  if (error)\n    printf(\"Fail\\n\");\n  else\n    printf(\"Success\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  unsigned long *data = NULL;\n  int *result = NULL;\n  int s1 = posix_memalign((void**)&data, 1024, length*sizeof(unsigned long));\n  int s2 = posix_memalign((void**)&result, 1024, length*sizeof(int));\n  if (s1 != 0 || s2 != 0) {\n    printf(\"Error: posix_memalign fails\\n\");\n    if (s1 == 0) free(data);\n    if (s2 == 0) free(result);\n    return 1;\n  }\n\n  \n\n  srand(2);\n  for (int i = 0; i < length; i++) {\n    unsigned long t = (unsigned long)rand() << 32;\n    data[i] = t | rand();\n  }\n\n  \n\n\n  unsigned long* d_data;\n  hipMalloc((void**)&d_data, sizeof(unsigned long)*length);\n  hipMemcpy(d_data, data, sizeof(unsigned long)*length, hipMemcpyHostToDevice);\n\n  int* d_result;\n  hipMalloc((void**)&d_result, sizeof(int)*length);\n\n  dim3 grids ((length+BLOCK_SIZE-1)/BLOCK_SIZE);\n  dim3 threads (BLOCK_SIZE);\n\n  auto start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    hipLaunchKernelGGL(pc1, grids, threads, 0, 0, d_data, d_result, length);\n  }\n  hipDeviceSynchronize();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc1): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  hipMemcpy(result, d_result, sizeof(int)*length, hipMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    hipLaunchKernelGGL(pc2, grids, threads, 0, 0, d_data, d_result, length);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc2): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  hipMemcpy(result, d_result, sizeof(int)*length, hipMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    hipLaunchKernelGGL(pc3, grids, threads, 0, 0, d_data, d_result, length);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc3): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  hipMemcpy(result, d_result, sizeof(int)*length, hipMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    hipLaunchKernelGGL(pc4, grids, threads, 0, 0, d_data, d_result, length);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc4): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  hipMemcpy(result, d_result, sizeof(int)*length, hipMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    hipLaunchKernelGGL(pc5, grids, threads, 0, 0, d_data, d_result, length);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc5): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  hipMemcpy(result, d_result, sizeof(int)*length, hipMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    hipLaunchKernelGGL(pc6, grids, threads, 0, 0, d_data, d_result, length);\n  }\n  hipDeviceSynchronize();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc6): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  hipMemcpy(result, d_result, sizeof(int)*length, hipMemcpyDeviceToHost);\n  checkResults(data, result, length);\n  \n\n\n  hipFree(d_data);\n  hipFree(d_result);\n  free(data);\n  free(result);\n  return 0;\n}\n"}}
{"kernel_name": "popcount", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#define m1  0x5555555555555555\n#define m2  0x3333333333333333 \n#define m4  0x0f0f0f0f0f0f0f0f \n#define h01 0x0101010101010101\n\n#define BLOCK_SIZE 256\n\n\n\nint popcount_ref(unsigned long x)\n{\n  int count;\n  for (count=0; x; count++)\n    x &= x - 1;\n  return count;\n}\n\nvoid checkResults(const unsigned long *d, const int *r, const int length)\n{\n  int error = 0;\n  for (int i=0;i<length;i++)\n    if (popcount_ref(d[i]) != r[i]) {\n      error = 1;\n      break;\n    }\n\n  if (error)\n    printf(\"Fail\\n\");\n  else\n    printf(\"Success\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  unsigned long *data = NULL;\n  int *result = NULL;\n  int s1 = posix_memalign((void**)&data, 1024, length*sizeof(unsigned long));\n  int s2 = posix_memalign((void**)&result, 1024, length*sizeof(int));\n  if (s1 != 0 || s2 != 0) {\n    printf(\"Error: posix_memalign fails\\n\");\n    if (s1 == 0) free(data);\n    if (s2 == 0) free(result);\n    return 1;\n  }\n\n  \n\n  srand(2);\n  for (int i = 0; i < length; i++) {\n    unsigned long t = (unsigned long)rand() << 32;\n    data[i] = t | rand();\n  }\n\n#pragma omp target data map(to: data[0:length]) \\\n                        map(alloc: result[0:length])\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n    for (int i = 0; i < length; i++) {\n       unsigned long x = data[i];\n       x -= (x >> 1) & m1;             \n\n       x = (x & m2) + ((x >> 2) & m2); \n\n       x = (x + (x >> 4)) & m4;        \n\n       x += x >>  8;  \n\n       x += x >> 16;  \n\n       x += x >> 32;  \n\n       result[i] = x & 0x7f;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc1): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  #pragma omp target update from (result[0:length])\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n    for (int i = 0; i < length; i++) {\n      unsigned long x = data[i];\n      x -= (x >> 1) & m1;             \n\n      x = (x & m2) + ((x >> 2) & m2); \n\n      x = (x + (x >> 4)) & m4;        \n\n      result[i] = (x * h01) >> 56;  \n\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc2): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  #pragma omp target update from (result[0:length])\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n    for (int i = 0; i < length; i++) {\n        char count;\n        unsigned long x = data[i];\n        for (count=0; x; count++) x &= x - 1;\n        result[i] = count;\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc3): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  #pragma omp target update from (result[0:length])\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n    for (int i = 0; i < length; i++) {\n        unsigned long x = data[i];\n        char cnt = 0;\n        for (char i = 0; i < 64; i++)\n        {\n          cnt = cnt + (x & 0x1);\n          x = x >> 1;\n        }\n        result[i] = cnt;\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc4): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  #pragma omp target update from (result[0:length])\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n    for (int i = 0; i < length; i++) {\n      unsigned long x = data[i];\n      const unsigned char a[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n      const unsigned char b[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n      const unsigned char c[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n      const unsigned char d[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n\n      unsigned char i1 = a[(x & 0xFF)];\n      unsigned char i2 = a[(x >> 8) & 0xFF];\n      unsigned char i3 = b[(x >> 16) & 0xFF];\n      unsigned char i4 = b[(x >> 24) & 0xFF];\n      unsigned char i5 = c[(x >> 32) & 0xFF];\n      unsigned char i6 = c[(x >> 40) & 0xFF];\n      unsigned char i7 = d[(x >> 48) & 0xFF];\n      unsigned char i8 = d[(x >> 56) & 0xFF];\n      result[i] = (i1+i2)+(i3+i4)+(i5+i6)+(i7+i8);\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc5): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  #pragma omp target update from (result[0:length])\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    #pragma omp target teams distribute parallel for thread_limit(BLOCK_SIZE)\n    for (int i = 0; i < length; i++) {\n        result[i] = __builtin_popcountll(data[i]);\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc6): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  #pragma omp target update from (result[0:length])\n  checkResults(data, result, length);\n}\n\n  free(data);\n  free(result);\n  return 0;\n}\n"}}
{"kernel_name": "popcount", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n\n#define m1  0x5555555555555555\n#define m2  0x3333333333333333 \n#define m4  0x0f0f0f0f0f0f0f0f \n#define h01 0x0101010101010101\n\n#define BLOCK_SIZE 256\n\n\n\nint popcount_ref(unsigned long x)\n{\n  int count;\n  for (count=0; x; count++)\n    x &= x - 1;\n  return count;\n}\n\nvoid checkResults(const unsigned long *d, const int *r, const int length)\n{\n  int error = 0;\n  for (int i=0;i<length;i++)\n    if (popcount_ref(d[i]) != r[i]) {\n      error = 1;\n      break;\n    }\n\n  if (error)\n    printf(\"Fail\\n\");\n  else\n    printf(\"Success\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  unsigned long *data = NULL;\n  int *result = NULL;\n  int s1 = posix_memalign((void**)&data, 1024, length*sizeof(unsigned long));\n  int s2 = posix_memalign((void**)&result, 1024, length*sizeof(int));\n  if (s1 != 0 || s2 != 0) {\n    printf(\"Error: posix_memalign fails\\n\");\n    if (s1 == 0) free(data);\n    if (s2 == 0) free(result);\n    return 1;\n  }\n\n  \n\n  srand(2);\n  for (int i = 0; i < length; i++) {\n    unsigned long t = (unsigned long)rand() << 32;\n    data[i] = t | rand();\n  }\n\n{\n  auto start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n        for (int i = 0; i < length; i++) {\n       unsigned long x = data[i];\n       x -= (x >> 1) & m1;             \n\n       x = (x & m2) + ((x >> 2) & m2); \n\n       x = (x + (x >> 4)) & m4;        \n\n       x += x >>  8;  \n\n       x += x >> 16;  \n\n       x += x >> 32;  \n\n       result[i] = x & 0x7f;\n    }\n  }\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc1): %f (us)\\n\", (time * 1e-3) / repeat);\n\n    checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n        for (int i = 0; i < length; i++) {\n      unsigned long x = data[i];\n      x -= (x >> 1) & m1;             \n\n      x = (x & m2) + ((x >> 2) & m2); \n\n      x = (x + (x >> 4)) & m4;        \n\n      result[i] = (x * h01) >> 56;  \n\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc2): %f (us)\\n\", (time * 1e-3) / repeat);\n\n    checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n        for (int i = 0; i < length; i++) {\n        char count;\n        unsigned long x = data[i];\n        for (count=0; x; count++) x &= x - 1;\n        result[i] = count;\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc3): %f (us)\\n\", (time * 1e-3) / repeat);\n\n    checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n        for (int i = 0; i < length; i++) {\n        unsigned long x = data[i];\n        char cnt = 0;\n        for (char i = 0; i < 64; i++)\n        {\n          cnt = cnt + (x & 0x1);\n          x = x >> 1;\n        }\n        result[i] = cnt;\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc4): %f (us)\\n\", (time * 1e-3) / repeat);\n\n    checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n        for (int i = 0; i < length; i++) {\n      unsigned long x = data[i];\n      const unsigned char a[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n      const unsigned char b[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n      const unsigned char c[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n      const unsigned char d[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n\n      unsigned char i1 = a[(x & 0xFF)];\n      unsigned char i2 = a[(x >> 8) & 0xFF];\n      unsigned char i3 = b[(x >> 16) & 0xFF];\n      unsigned char i4 = b[(x >> 24) & 0xFF];\n      unsigned char i5 = c[(x >> 32) & 0xFF];\n      unsigned char i6 = c[(x >> 40) & 0xFF];\n      unsigned char i7 = d[(x >> 48) & 0xFF];\n      unsigned char i8 = d[(x >> 56) & 0xFF];\n      result[i] = (i1+i2)+(i3+i4)+(i5+i6)+(i7+i8);\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc5): %f (us)\\n\", (time * 1e-3) / repeat);\n\n    checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n        for (int i = 0; i < length; i++) {\n        result[i] = __builtin_popcountll(data[i]);\n    }\n  }\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc6): %f (us)\\n\", (time * 1e-3) / repeat);\n\n    checkResults(data, result, length);\n}\n\n  free(data);\n  free(result);\n  return 0;\n}"}}
{"kernel_name": "popcount", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define m1  0x5555555555555555\n#define m2  0x3333333333333333\n#define m4  0x0f0f0f0f0f0f0f0f\n#define h01 0x0101010101010101\n\n#define BLOCK_SIZE 256\n\n\n\nint popcount_ref(unsigned long x)\n{\n  int count;\n  for (count=0; x; count++)\n    x &= x - 1;\n  return count;\n}\n\nvoid checkResults(const unsigned long *d, const int *r, const int length)\n{\n  int error = 0;\n  for (int i=0;i<length;i++)\n    if (popcount_ref(d[i]) != r[i]) {\n      error = 1;\n      break;\n    }\n\n  if (error)\n    printf(\"Fail\\n\");\n  else\n    printf(\"Success\\n\");\n}\n\nint main(int argc, char* argv[])\n{\n  if (argc != 3) {\n    printf(\"Usage: %s <length> <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int length = atoi(argv[1]);\n  const int repeat = atoi(argv[2]);\n\n  unsigned long *data = NULL;\n  int *result = NULL;\n  int s1 = posix_memalign((void**)&data, 1024, length*sizeof(unsigned long));\n  int s2 = posix_memalign((void**)&result, 1024, length*sizeof(int));\n  if (s1 != 0 || s2 != 0) {\n    printf(\"Error: posix_memalign fails\\n\");\n    if (s1 == 0) free(data);\n    if (s2 == 0) free(result);\n    return 1;\n  }\n\n  \n\n  srand(2);\n  for (unsigned long i = 0; i < length; i++) {\n    unsigned long t = (unsigned long)rand() << 32;\n    data[i] = t | rand();\n  }\n\n  \n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  unsigned long *d_data = sycl::malloc_device<unsigned long>(length, q);\n  q.memcpy(d_data, data, sizeof(unsigned long)*length);\n  int *d_r = sycl::malloc_device<int>(length, q);\n\n  sycl::range<1> gws ((length+BLOCK_SIZE-1)/BLOCK_SIZE*BLOCK_SIZE);\n  sycl::range<1> lws (BLOCK_SIZE);\n\n  q.wait();\n  auto start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class pc1>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i >= length) return;\n        unsigned long x = d_data[i];\n        x -= (x >> 1) & m1;             \n\n        x = (x & m2) + ((x >> 2) & m2); \n\n        x = (x + (x >> 4)) & m4;        \n\n        x += x >>  8;  \n\n        x += x >> 16;  \n\n        x += x >> 32;  \n\n        d_r[i] = x & 0x7f;\n      });\n    });\n  }\n  q.wait();\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc1): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  q.memcpy(result, d_r, sizeof(int)*length).wait();\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class pc2>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i >= length) return;\n        unsigned long x = d_data[i];\n        x -= (x >> 1) & m1;             \n\n        x = (x & m2) + ((x >> 2) & m2); \n\n        x = (x + (x >> 4)) & m4;        \n\n        d_r[i] = (x * h01) >> 56;  \n\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc2): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  q.memcpy(result, d_r, sizeof(int)*length).wait();\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class pc3>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i >= length) return;\n        char count;\n        unsigned long x = d_data[i];\n        for (count=0; x; count++) x &= x - 1;\n        d_r[i] = count;\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc3): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  q.memcpy(result, d_r, sizeof(int)*length).wait();\n  checkResults(data, result, length);\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class pc4>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i >= length) return;\n        unsigned long x = d_data[i];\n        char cnt = 0;\n        for (char i = 0; i < 64; i++)\n        {\n          cnt = cnt + (x & 0x1);\n          x = x >> 1;\n        }\n        d_r[i] = cnt;\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc4): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  q.memcpy(result, d_r, sizeof(int)*length).wait();\n  checkResults(data, result, length);\n\n  \n\n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class pc5>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i >= length) return;\n        unsigned long x = d_data[i];\n        const unsigned char a[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n        const unsigned char b[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n        const unsigned char c[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n        const unsigned char d[256] = { 0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,1,2,2,3,2,3,3,4,2,3,3,4,3,4,4,5,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,2,3,3,4,3,4,4,5,3,4,4,5,4,5,5,6,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,3,4,4,5,4,5,5,6,4,5,5,6,5,6,6,7,4,5,5,6,5,6,6,7,5,6,6,7,6,7,7,8};\n\n        unsigned char i1 = a[(x & 0xFF)];\n        unsigned char i2 = a[(x >> 8) & 0xFF];\n        unsigned char i3 = b[(x >> 16) & 0xFF];\n        unsigned char i4 = b[(x >> 24) & 0xFF];\n        unsigned char i5 = c[(x >> 32) & 0xFF];\n        unsigned char i6 = c[(x >> 40) & 0xFF];\n        unsigned char i7 = d[(x >> 48) & 0xFF];\n        unsigned char i8 = d[(x >> 56) & 0xFF];\n        d_r[i] = (i1+i2)+(i3+i4)+(i5+i6)+(i7+i8);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc5): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  q.memcpy(result, d_r, sizeof(int)*length).wait();\n  checkResults(data, result, length);\n  \n\n\n  \n\n  start = std::chrono::steady_clock::now();\n  for (int n = 0; n < repeat; n++) {\n    q.submit([&](sycl::handler &h) {\n      h.parallel_for<class pc6>(sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n        int i = item.get_global_id(0);\n        if (i >= length) return;\n        d_r[i] = sycl::popcount(d_data[i]);\n      });\n    });\n  }\n  q.wait();\n  end = std::chrono::steady_clock::now();\n  time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  printf(\"Average kernel execution time (pc6): %f (us)\\n\", (time * 1e-3) / repeat);\n\n  q.memcpy(result, d_r, sizeof(int)*length).wait();\n  checkResults(data, result, length);\n\n  sycl::free(d_data, q);\n  sycl::free(d_r, q);\n  free(data);\n  free(result);\n  return 0;\n}\n"}}
{"kernel_name": "reverse", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n#include <cuda.h>\n\n__global__ void reverse (int *d, const int len)\n{\n  __shared__ int s[256];\n  int t = threadIdx.x;\n  s[t] = d[t];\n  __syncthreads();\n  d[t] = s[len-t-1];\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n  const int elem_size = len * sizeof(int);\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n  int *d_test;\n  cudaMalloc((void**)&d_test, elem_size);\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100, 9999);\n\n  long time = 0;\n\n  for (int i = 0; i < iteration; i++) {\n    const int count = distribution(generator);\n\n    cudaMemcpy(d_test, gold_even, elem_size, cudaMemcpyHostToDevice);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int j = 0; j < count; j++)\n      reverse<<<1, len>>> (d_test, len);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    cudaMemcpy(test, d_test, elem_size, cudaMemcpyDeviceToHost);\n\n    if (count % 2 == 0)\n      error = memcmp(test, gold_even, elem_size);\n    else\n      error = memcmp(test, gold_odd, elem_size);\n    \n    if (error) break;\n  }\n  \n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  cudaFree(d_test);\n  return 0;\n}\n"}}
{"kernel_name": "reverse", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n__global__ void reverse (int *d, const int len)\n{\n  __shared__ int s[256];\n  int t = threadIdx.x;\n  s[t] = d[t];\n  __syncthreads();\n  d[t] = s[len-t-1];\n}\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n  const int elem_size = len * sizeof(int);\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n  int *d_test;\n  hipMalloc((void**)&d_test, elem_size);\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100, 9999);\n\n  long time = 0;\n\n  for (int i = 0; i < iteration; i++) {\n    const int count = distribution(generator);\n\n    hipMemcpy(d_test, gold_even, elem_size, hipMemcpyHostToDevice);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int j = 0; j < count; j++)\n      hipLaunchKernelGGL(reverse, 1, len, 0, 0, d_test, len);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    hipMemcpy(test, d_test, elem_size, hipMemcpyDeviceToHost);\n\n    if (count % 2 == 0)\n      error = memcmp(test, gold_even, elem_size);\n    else\n      error = memcmp(test, gold_odd, elem_size);\n    \n    if (error) break;\n  }\n  \n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  hipFree(d_test);\n  return 0;\n}\n"}}
{"kernel_name": "reverse", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n#include <omp.h>\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n  const int elem_size = len * sizeof(int);\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100, 9999);\n\n  long time = 0;\n\n  #pragma omp target data map(alloc: test[0:len]) \n  {\n    for (int i = 0; i < iteration; i++) {\n      const int count = distribution(generator);\n\n      memcpy(test, gold_even, elem_size);\n      #pragma omp target update to (test[0:len])\n\n      auto start = std::chrono::steady_clock::now();\n\n      for (int j = 0; j < count; j++) {\n        #pragma omp target teams num_teams(1) thread_limit(len)\n        {\n          int s[len];\n          #pragma omp parallel \n          {\n            int t = omp_get_thread_num();\n            s[t] = test[t];\n            #pragma omp barrier\n            test[t] = s[len-t-1];\n          }\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n      #pragma omp target update from (test[0:len])\n\n      if (count % 2 == 0)\n        error = memcmp(test, gold_even, elem_size);\n      else\n        error = memcmp(test, gold_odd, elem_size);\n      \n      if (error) break;\n    }\n  }\n\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  return 0;\n}\n"}}
{"kernel_name": "reverse", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n  const int elem_size = len * sizeof(int);\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100, 9999);\n\n  long time = 0;\n\n    {\n    for (int i = 0; i < iteration; i++) {\n      const int count = distribution(generator);\n\n      memcpy(test, gold_even, elem_size);\n      \n      auto start = std::chrono::steady_clock::now();\n\n      for (int j = 0; j < count; j++) {\n                {\n          int s[len];\n                    {\n            int t = omp_get_thread_num();\n            s[t] = test[t];\n                        test[t] = s[len-t-1];\n          }\n        }\n      }\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n      \n      if (count % 2 == 0)\n        error = memcmp(test, gold_even, elem_size);\n      else\n        error = memcmp(test, gold_odd, elem_size);\n      \n      if (error) break;\n    }\n  }\n\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  return 0;\n}"}}
{"kernel_name": "reverse", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <random>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\nint main(int argc, char* argv[]) {\n\n  if (argc != 2) {\n    printf(\"Usage: ./%s <iterations>\\n\", argv[0]);\n    return 1;\n  }\n\n  \n\n  const int iteration = atoi(argv[1]);\n\n  \n\n  const int len = 256;\n\n  \n\n  int test[len];\n\n  \n\n  int error = 0;\n  int gold_odd[len];\n  int gold_even[len];\n\n  for (int i = 0; i < len; i++) {\n    gold_odd[i] = len-i-1;\n    gold_even[i] = i;\n  }\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  int *d_test = sycl::malloc_device<int>(len, q);\n  sycl::range<1> gws (len);\n  sycl::range<1> lws (len);\n\n  std::default_random_engine generator (123);\n  \n\n  std::uniform_int_distribution<int> distribution(100,9999);\n\n  long time = 0;\n\n  for (int i = 0; i < iteration; i++) {\n    const int count = distribution(generator);\n\n    q.memcpy(d_test, gold_even, sizeof(int) * len);\n\n    q.wait();\n    auto start = std::chrono::steady_clock::now();\n\n    for (int j = 0; j < count; j++) {\n      q.submit([&](sycl::handler &cgh) {\n        sycl::local_accessor <int, 1> s (lws, cgh);\n        cgh.parallel_for<class blockReverse>(\n          sycl::nd_range<1>(gws, lws), [=](sycl::nd_item<1> item) {\n          int t = item.get_local_id(0);\n          s[t] = d_test[t];\n          item.barrier(sycl::access::fence_space::local_space);\n          d_test[t] = s[len-t-1];\n        });\n      });\n    }\n\n    q.wait();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    q.memcpy(test, d_test, sizeof(int) * len).wait();\n\n    if (count % 2 == 0)\n      error = memcmp(test, gold_even, len*sizeof(int));\n    else\n      error = memcmp(test, gold_odd, len*sizeof(int));\n\n    if (error) break;\n  }\n\n  printf(\"Total kernel execution time: %f (s)\\n\", time * 1e-9f);\n  printf(\"%s\\n\", error ? \"FAIL\" : \"PASS\");\n\n  free(d_test, q);\n\n  return 0;\n}\n"}}
{"kernel_name": "threadfence", "parallel_api": "cuda", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <cuda.h>\n\n__global__ void sum (\n    const float*__restrict__ array,\n    const int N,\n    unsigned int *__restrict__ count,\n    volatile float*__restrict__ result)\n{\n  __shared__ bool isLastBlockDone;\n  __shared__ float partialSum;\n\n  \n\n  unsigned int bid = blockIdx.x;\n  unsigned int num_blocks = gridDim.x;\n  unsigned int block_size = blockDim.x;\n  unsigned int lid = threadIdx.x;\n  unsigned int gid = bid * block_size + lid;\n\n  if (lid == 0) partialSum = 0;\n  __syncthreads();\n\n  if (gid < N)\n    atomicAdd(&partialSum, array[gid]);\n\n  __syncthreads();\n\n  if (lid == 0) {\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    result[bid] = partialSum;\n\n    \n\n    \n\n    \n\n    __threadfence();\n\n    \n\n    unsigned int value = atomicAdd(count, 1);\n\n    \n\n    \n\n    isLastBlockDone = (value == (num_blocks - 1));\n  }\n\n  \n\n  \n\n  __syncthreads();\n\n  if (isLastBlockDone) {\n\n    \n\n    \n\n    if (lid == 0) partialSum = 0;\n    __syncthreads();\n\n    for (int i = lid; i < num_blocks; i += block_size)\n      atomicAdd(&partialSum, result[i]);\n\n    __syncthreads();\n\n    if (lid == 0) {\n      \n\n      \n\n      \n\n      \n\n      result[0] = partialSum;\n      *count = 0;\n    }\n  }\n}\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <repeat> <array length>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n\n  const int blocks = 256;\n  const int grids = (N + blocks - 1) / blocks;\n\n  float* h_array = (float*) malloc (N * sizeof(float));\n  float h_sum;\n\n  float* d_result;\n  cudaMalloc((void**)&d_result, grids * sizeof(float));\n\n  float* d_array;\n  cudaMalloc((void**)&d_array, N * sizeof(float));\n\n  unsigned int* d_count;\n  cudaMalloc((void**)&d_count, sizeof(unsigned int));\n  cudaMemset(d_count, 0u, sizeof(unsigned int));\n\n  bool ok = true;\n  double time = 0.0;\n\n  for (int i = 0; i < N; i++) h_array[i] = -1.f;\n\n  for (int n = 0; n < repeat; n++) {\n\n    cudaMemcpy(d_array, h_array, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    cudaDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    sum <<< grids, blocks >>> (d_array, N, d_count, d_result);\n\n    cudaDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    cudaMemcpy(&h_sum, d_result, sizeof(float), cudaMemcpyDeviceToHost);\n\n    if (h_sum != -1.f * N) {\n      ok = false;\n      break;\n    }\n  }\n\n  if (ok) printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(h_array);\n  cudaFree(d_result);\n  cudaFree(d_array);\n  cudaFree(d_count);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n"}}
{"kernel_name": "threadfence", "parallel_api": "hip", "code": {"main.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <hip/hip_runtime.h>\n\n__global__ void sum (\n    const float*__restrict__ array,\n    const int N,\n    unsigned int *__restrict__ count,\n    volatile float*__restrict__ result)\n{\n  __shared__ bool isLastBlockDone;\n  __shared__ float partialSum;\n\n  \n\n  unsigned int bid = blockIdx.x;\n  unsigned int num_blocks = gridDim.x;\n  unsigned int block_size = blockDim.x;\n  unsigned int lid = threadIdx.x;\n  unsigned int gid = bid * block_size + lid;\n\n  if (lid == 0) partialSum = 0;\n  __syncthreads();\n\n  if (gid < N)\n    atomicAdd(&partialSum, array[gid]);\n\n  __syncthreads();\n\n  if (lid == 0) {\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    result[bid] = partialSum;\n\n    \n\n    \n\n    \n\n    __threadfence();\n\n    \n\n    unsigned int value = atomicAdd(count, 1);\n\n    \n\n    \n\n    isLastBlockDone = (value == (num_blocks - 1));\n  }\n\n  \n\n  \n\n  __syncthreads();\n\n  if (isLastBlockDone) {\n\n    \n\n    \n\n    if (lid == 0) partialSum = 0;\n    __syncthreads();\n\n    for (int i = lid; i < num_blocks; i += block_size)\n      atomicAdd(&partialSum, result[i]);\n\n    __syncthreads();\n\n    if (lid == 0) {\n      \n\n      \n\n      \n\n      \n\n      result[0] = partialSum;\n      *count = 0;\n    }\n  }\n}\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <repeat> <array length>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n\n  const int blocks = 256;\n  const int grids = (N + blocks - 1) / blocks;\n\n  float* h_array = (float*) malloc (N * sizeof(float));\n  float h_sum;\n\n  float* d_result;\n  hipMalloc((void**)&d_result, grids * sizeof(float));\n\n  float* d_array;\n  hipMalloc((void**)&d_array, N * sizeof(float));\n\n  unsigned int* d_count;\n  hipMalloc((void**)&d_count, sizeof(unsigned int));\n  hipMemset(d_count, 0u, sizeof(unsigned int));\n\n  bool ok = true;\n  double time = 0.0;\n\n  for (int i = 0; i < N; i++) h_array[i] = -1.f;\n\n  for (int n = 0; n < repeat; n++) {\n\n    hipMemcpy(d_array, h_array, N * sizeof(float), hipMemcpyHostToDevice);\n\n    hipDeviceSynchronize();\n    auto start = std::chrono::steady_clock::now();\n\n    hipLaunchKernelGGL(sum, grids, blocks , 0, 0, d_array, N, d_count, d_result);\n\n    hipDeviceSynchronize();\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    hipMemcpy(&h_sum, d_result, sizeof(float), hipMemcpyDeviceToHost);\n\n    if (h_sum != -1.f * N) {\n      ok = false;\n      break;\n    }\n  }\n\n  if (ok) printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(h_array);\n  hipFree(d_result);\n  hipFree(d_array);\n  hipFree(d_count);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n"}}
{"kernel_name": "threadfence", "parallel_api": "omp", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <omp.h>\n\nvoid sum (\n    const int teams,\n    const int blocks,\n    const float*__restrict array,\n    const int N,\n    unsigned int *__restrict count,\n    volatile float*__restrict result)\n{\n  #pragma omp target teams num_teams(teams) thread_limit(blocks)\n  {\n    bool isLastBlockDone;\n    float partialSum;\n    #pragma omp parallel \n    {\n      \n\n      unsigned int bid = omp_get_team_num();\n      unsigned int num_blocks = teams;\n      unsigned int block_size = blocks;\n      unsigned int lid = omp_get_thread_num();\n      unsigned int gid = bid * block_size + lid;\n\n      if (lid == 0) partialSum = 0;\n      #pragma omp barrier\n\n      if (gid < N) {\n        #pragma omp atomic update\n        partialSum += array[gid];\n      }\n\n      #pragma omp barrier\n\n      if (lid == 0) {\n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        result[bid] = partialSum;\n\n        \n\n        unsigned int value;\n        #pragma omp atomic capture\n        value = (*count)++;\n\n        \n\n        \n\n        isLastBlockDone = (value == (num_blocks - 1));\n      }\n\n      \n\n      \n\n      #pragma omp barrier\n\n      if (isLastBlockDone) {\n\n        \n\n        \n\n        if (lid == 0) partialSum = 0;\n        #pragma omp barrier\n\n        for (int i = lid; i < num_blocks; i += block_size) {\n          #pragma omp atomic update\n          partialSum += result[i];\n        }\n\n        #pragma omp barrier\n\n        if (lid == 0) {\n\n          \n\n          \n\n          \n\n          \n\n          result[0] = partialSum;\n          *count = 0;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <repeat> <array length>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n\n  const int blocks = 256;\n  const int grids = (N + blocks - 1) / blocks;\n\n  float* h_array = (float*) malloc (N * sizeof(float));\n\n  float* h_result = (float*) malloc (grids * sizeof(float));\n\n  unsigned int* h_count = (unsigned int*) malloc (sizeof(unsigned int));\n  h_count[0] = 0;\n\n  bool ok = true;\n  double time = 0.0;\n\n  for (int i = 0; i < N; i++) h_array[i] = -1.f;\n  \n  #pragma omp target data map (to: h_array[0:N], h_count[0:1]) \\\n                          map (alloc: h_result[0:grids])\n  {\n    for (int n = 0; n < repeat; n++) {\n  \n      \n\n  \n      auto start = std::chrono::steady_clock::now();\n\n      sum (grids, blocks, h_array, N, h_count, h_result);\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  \n      #pragma omp target update from (h_result[0:1])\n  \n      if (h_result[0] != -1.f * N) {\n        ok = false;\n        break;\n      }\n    }\n  }\n\n  if (ok) printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(h_array);\n  free(h_count);\n  free(h_result);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n"}}
{"kernel_name": "threadfence", "parallel_api": "serial", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n\nvoid sum (\n    const int teams,\n    const int blocks,\n    const float*__restrict array,\n    const int N,\n    unsigned int *__restrict count,\n    volatile float*__restrict result)\n{\n    {\n    bool isLastBlockDone;\n    float partialSum;\n        {\n      \n\n      unsigned int bid = omp_get_team_num();\n      unsigned int num_blocks = teams;\n      unsigned int block_size = blocks;\n      unsigned int lid = omp_get_thread_num();\n      unsigned int gid = bid * block_size + lid;\n\n      if (lid == 0) partialSum = 0;\n      \n      if (gid < N) {\n                partialSum += array[gid];\n      }\n\n      \n      if (lid == 0) {\n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        \n\n        result[bid] = partialSum;\n\n        \n\n        unsigned int value;\n                value = (*count)++;\n\n        \n\n        \n\n        isLastBlockDone = (value == (num_blocks - 1));\n      }\n\n      \n\n      \n\n      \n      if (isLastBlockDone) {\n\n        \n\n        \n\n        if (lid == 0) partialSum = 0;\n        \n        for (int i = lid; i < num_blocks; i += block_size) {\n                    partialSum += result[i];\n        }\n\n        \n        if (lid == 0) {\n\n          \n\n          \n\n          \n\n          \n\n          result[0] = partialSum;\n          *count = 0;\n        }\n      }\n    }\n  }\n}\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <repeat> <array length>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n\n  const int blocks = 256;\n  const int grids = (N + blocks - 1) / blocks;\n\n  float* h_array = (float*) malloc (N * sizeof(float));\n\n  float* h_result = (float*) malloc (grids * sizeof(float));\n\n  unsigned int* h_count = (unsigned int*) malloc (sizeof(unsigned int));\n  h_count[0] = 0;\n\n  bool ok = true;\n  double time = 0.0;\n\n  for (int i = 0; i < N; i++) h_array[i] = -1.f;\n  \n    {\n    for (int n = 0; n < repeat; n++) {\n  \n      \n\n  \n      auto start = std::chrono::steady_clock::now();\n\n      sum (grids, blocks, h_array, N, h_count, h_result);\n\n      auto end = std::chrono::steady_clock::now();\n      time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  \n        \n      if (h_result[0] != -1.f * N) {\n        ok = false;\n        break;\n      }\n    }\n  }\n\n  if (ok) printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(h_array);\n  free(h_count);\n  free(h_result);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}"}}
{"kernel_name": "threadfence", "parallel_api": "sycl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <chrono>\n#include <sycl/sycl.hpp>\n\n#define syncthreads() item.barrier(sycl::access::fence_space::local_space)\n#define threadfence() sycl::atomic_fence(sycl::memory_order::acq_rel,\\\n                                         sycl::memory_scope::device)\n\nvoid sum (\n    sycl::nd_item<1> &item,\n    float &partialSum,\n    bool &isLastBlockDone,\n    const float*__restrict array,\n    const int N,\n    unsigned int *__restrict count,\n    volatile float*__restrict result)\n{\n\n  \n\n  unsigned int bid = item.get_group(0);\n  unsigned int num_blocks = item.get_group_range(0);\n  unsigned int block_size = item.get_local_range(0);\n  unsigned int lid = item.get_local_id(0);\n  unsigned int gid = bid * block_size + lid;\n\n  auto psum = sycl::atomic_ref<float,\n              sycl::memory_order::relaxed,\n              sycl::memory_scope::work_group,\n              sycl::access::address_space::local_space> (partialSum);\n\n  if (lid == 0) partialSum = 0;\n  syncthreads();\n\n  if (gid < N)\n    psum.fetch_add(array[gid]);\n\n  syncthreads();\n\n  if (lid == 0) {\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n    result[bid] = partialSum;\n\n    \n\n    \n\n    \n\n    threadfence();\n\n    \n\n    auto gmem_write = sycl::atomic_ref<unsigned int,\n                      sycl::memory_order::relaxed,\n                      sycl::memory_scope::device,\n                      sycl::access::address_space::global_space> (*count);\n    unsigned int value = gmem_write.fetch_add(1u);\n\n    \n\n    \n\n    isLastBlockDone = (value == (num_blocks - 1));\n  }\n\n  \n\n  \n\n  syncthreads();\n\n  if (isLastBlockDone) {\n\n    \n\n    \n\n    if (lid == 0) partialSum = 0;\n    syncthreads();\n\n    for (int i = lid; i < num_blocks; i += block_size)\n      psum.fetch_add(result[i]);\n\n    syncthreads();\n\n    if (lid == 0) {\n\n      \n\n      \n\n      \n\n      \n\n      result[0] = partialSum;\n      *count = 0;\n    }\n  }\n}\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    printf(\"Usage: %s <repeat> <array length>\\n\", argv[0]);\n    return 1;\n  }\n\n  const int repeat = atoi(argv[1]);\n  const int N = atoi(argv[2]);\n\n  float* h_array = (float*) malloc (N * sizeof(float));\n  float h_sum;\n\n#ifdef USE_GPU\n  sycl::queue q(sycl::gpu_selector_v, sycl::property::queue::in_order());\n#else\n  sycl::queue q(sycl::cpu_selector_v, sycl::property::queue::in_order());\n#endif\n\n  const int blocks = 256;\n  const int grids = (N + blocks - 1) / blocks;\n  sycl::range<1> gws (grids * blocks);\n  sycl::range<1> lws (blocks);\n\n  float *d_result = sycl::malloc_device<float>(grids, q);\n  float *d_array = sycl::malloc_device<float>(N, q);\n  unsigned int *d_count = sycl::malloc_device<unsigned int>(1, q);\n\n  q.memset(d_count, 0, sizeof(unsigned int));\n\n  bool ok = true;\n  double time = 0.0;\n\n  for (int i = 0; i < N; i++) h_array[i] = -1.f;\n\n  for (int n = 0; n < repeat; n++) {\n\n    q.memcpy(d_array, h_array, N * sizeof(float)).wait();\n\n    auto start = std::chrono::steady_clock::now();\n\n    q.submit([&] (sycl::handler &cgh) {\n      sycl::local_accessor<float, 0> lsum (cgh);\n      sycl::local_accessor<bool, 0> isLastBlockDone (cgh);\n      cgh.parallel_for<class reduce>(\n        sycl::nd_range<1>(gws, lws), [=] (sycl::nd_item<1> item) {\n        sum (item, lsum, isLastBlockDone,\n             d_array, N, d_count, d_result);\n      });\n    }).wait();\n\n    auto end = std::chrono::steady_clock::now();\n    time += std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n\n    q.memcpy(&h_sum, d_result, sizeof(float)).wait();\n\n    if (h_sum != -1.f * N) {\n      ok = false;\n      break;\n    }\n  }\n\n  if (ok) printf(\"Average kernel execution time: %f (ms)\\n\", (time * 1e-6f) / repeat);\n\n  free(h_array);\n  sycl::free(d_result, q);\n  sycl::free(d_array, q);\n  sycl::free(d_count, q);\n\n  printf(\"%s\\n\", ok ? \"PASS\" : \"FAIL\");\n  return 0;\n}\n"}}
{"kernel_name": "wordcount", "parallel_api": "cuda", "code": {"wc.cu": "#include <thrust/device_vector.h>\n#include <thrust/reduce.h>\n#include <thrust/functional.h>\n#include <thrust/inner_product.h>\n#include <vector>\n#include <numeric>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__host__ __device__\nbool is_alpha(const char c)\n{\n  return (c >= 'A' && c <= 'z');\n}\n\n\n\nstruct is_word_start\n: public thrust::binary_function<const char&, const char&, bool>\n{\n  __host__ __device__\n  bool operator()(const char& left, const char& right) const\n  {\n    return is_alpha(right) && !is_alpha(left);\n  }\n};\n\n\nint word_count(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  thrust::device_vector<char> d_input(input.begin(), input.end());\n\n  \n\n  int wc = thrust::inner_product(d_input.begin(), d_input.end() - 1,  \n\n      d_input.begin() + 1,             \n\n      0,                               \n\n      thrust::plus<int>(),             \n\n      is_word_start());                \n\n\n  \n\n  if (is_alpha(d_input.front())) wc++;\n\n  return wc;\n}\n\nint word_count_reference(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  int wc = std::inner_product(\n      input.cbegin(), input.cend() - 1, \n\n      input.cbegin() + 1,               \n\n      0,                                \n\n      std::plus<int>(),                 \n\n      is_word_start());                 \n\n\n  \n\n  if (is_alpha(input.front())) wc++;\n\n  return wc;\n}\n"}}
{"kernel_name": "wordcount", "parallel_api": "hip", "code": {"wc.cu": "#include <thrust/device_vector.h>\n#include <thrust/reduce.h>\n#include <thrust/functional.h>\n#include <thrust/inner_product.h>\n#include <vector>\n#include <numeric>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n__host__ __device__\nbool is_alpha(const char c)\n{\n  return (c >= 'A' && c <= 'z');\n}\n\n\n\nstruct is_word_start\n: public thrust::binary_function<const char&, const char&, bool>\n{\n  __host__ __device__\n  bool operator()(const char& left, const char& right) const\n  {\n    return is_alpha(right) && !is_alpha(left);\n  }\n};\n\n\nint word_count(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  thrust::device_vector<char> d_input(input.begin(), input.end());\n\n  \n\n  int wc = thrust::inner_product(d_input.begin(), d_input.end() - 1,  \n\n      d_input.begin() + 1,             \n\n      0,                               \n\n      thrust::plus<int>(),             \n\n      is_word_start());                \n\n\n  \n\n  if (is_alpha(d_input.front())) wc++;\n\n  return wc;\n}\n\nint word_count_reference(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  int wc = std::inner_product(\n      input.cbegin(), input.cend() - 1, \n\n      input.cbegin() + 1,               \n\n      0,                                \n\n      std::plus<int>(),                 \n\n      is_word_start());                 \n\n\n  \n\n  if (is_alpha(input.front())) wc++;\n\n  return wc;\n}\n"}}
{"kernel_name": "wordcount", "parallel_api": "omp", "code": {"wc.cpp": "#include <functional>\n#include <numeric>\n#include <vector>\n#include <omp.h>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#pragma omp declare target\ninline bool is_alpha(const char c)\n{\n  return (c >= 'A' && c <= 'z');\n}\n#pragma omp end declare target\n\n\n\nstruct is_word_start\n{\n  bool operator()(const char& left, const char& right) const\n  {\n    return is_alpha(right) && !is_alpha(left);\n  }\n};\n\nint word_count(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  const char *in = input.data();\n  const size_t size = input.size();\n  \n  \n\n  int wc = 0;\n  #pragma omp target data map (to: in[0:size]) map(tofrom: wc) \n  {\n    #pragma omp target teams distribute parallel for thread_limit(256) reduction(+:wc)\n    for (int i = 0; i < size - 1; i++) {\n      wc += !is_alpha(in[i]) && is_alpha(in[i+1]);\n    }\n  }\n\n  \n\n  if (is_alpha(in[0])) wc++;\n\n  return wc;\n}\n\nint word_count_reference(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  int wc = std::inner_product(\n      input.cbegin(), input.cend() - 1, \n\n      input.cbegin() + 1,               \n\n      0,                                \n\n      std::plus<int>(),                 \n\n      is_word_start());                 \n\n\n  \n\n  if (is_alpha(input.front())) wc++;\n\n  return wc;\n}\n"}}
{"kernel_name": "wordcount", "parallel_api": "serial", "code": {"wc.cpp": "#include <functional>\n#include <numeric>\n#include <vector>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninline bool is_alpha(const char c)\n{\n  return (c >= 'A' && c <= 'z');\n}\n\n\n\nstruct is_word_start\n{\n  bool operator()(const char& left, const char& right) const\n  {\n    return is_alpha(right) && !is_alpha(left);\n  }\n};\n\nint word_count(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  const char *in = input.data();\n  const size_t size = input.size();\n  \n  \n\n  int wc = 0;\n    {\n        for (int i = 0; i < size - 1; i++) {\n      wc += !is_alpha(in[i]) && is_alpha(in[i+1]);\n    }\n  }\n\n  \n\n  if (is_alpha(in[0])) wc++;\n\n  return wc;\n}\n\nint word_count_reference(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  int wc = std::inner_product(\n      input.cbegin(), input.cend() - 1, \n\n      input.cbegin() + 1,               \n\n      0,                                \n\n      std::plus<int>(),                 \n\n      is_word_start());                 \n\n\n  \n\n  if (is_alpha(input.front())) wc++;\n\n  return wc;\n}"}}
{"kernel_name": "wordcount", "parallel_api": "sycl", "code": {"main.cpp": "#include <chrono>\n#include <cstring>\n#include <iostream>\n#include <vector>\n\nint word_count(const std::vector<char> &input);\nint word_count_reference(const std::vector<char> &input);\n\nint main(int argc, char* argv[])\n{\n  if (argc != 2) {\n    printf(\"Usage: %s <repeat>\\n\", argv[0]);\n    return 1;\n  }\n  const int repeat = atoi(argv[1]);\n\n  \n\n  \n\n  const char raw_input[] = \"  But the raven, sitting lonely on the placid bust, spoke only,\\n\"\n                           \"  That one word, as if his soul in that one word he did outpour.\\n\"\n                           \"  Nothing further then he uttered - not a feather then he fluttered -\\n\"\n                           \"  Till I scarcely more than muttered `Other friends have flown before -\\n\"\n                           \"  On the morrow he will leave me, as my hopes have flown before.'\\n\"\n                           \"  Then the bird said, `Nevermore.'\\n\";\n\n  std::cout << \"Text sample:\" << std::endl;\n  std::cout << raw_input << std::endl;\n  \n  std::vector<char> input(raw_input, raw_input + sizeof(raw_input));\n\n  \n\n  int wc = word_count_reference(input);\n  std::cout << \"Host: Text sample contains \" << wc << \" words\" << std::endl;\n\n  wc = word_count(input);\n  std::cout << \"Device: Text sample contains \" << wc << \" words\" << std::endl;\n  \n  std::cout << \"Test word count with random inputs\\n\";\n  srand(123);\n  bool ok = true;\n  const char tab[] = \"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ\";\n  const int size = strlen(tab);\n\n  \n\n  for (size_t i = 1; i <= 1e8; i = i * 10) {\n    std::vector<char> random_input(i);\n    for (size_t c = 0; c < i; c++) random_input[c] = tab[rand() % size];\n    if (word_count_reference(random_input) != word_count(random_input)) {\n      ok = false;\n      break;\n    }\n  }\n  std::cout << (ok ? \"PASS\" : \"FAIL\") << std::endl;\n      \n  \n\n  const size_t len = 1024*1024*1024;  \n  std::vector<char> random_input(len);\n  for (size_t c = 0; c < len; c++) random_input[c] = tab[rand() % size];\n\n  std::cout << \"Performance evaluation for random texts of character length \" << len << std::endl;\n  auto start = std::chrono::steady_clock::now();\n\n  for (int i = 0; i < repeat; i++) word_count(random_input);\n\n  auto end = std::chrono::steady_clock::now();\n  auto time = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n  std::cout << \"Average time of word count: \" << time * 1e-9f / repeat << \" (s)\\n\";\n\n  return 0;\n}\n", "wc.cpp": "#include <oneapi/dpl/execution>\n#include <oneapi/dpl/algorithm>\n#include <oneapi/dpl/numeric>\n#include <numeric>  \n\n#include <vector>\n\n\n\n\n\n\n\n\n\n\n\n\nbool is_alpha(const char c)\n{\n  return (c >= 'A' && c <= 'z');\n}\n\n\n\nstruct is_word_start\n{\n  bool operator()(const char& left, const char& right) const\n  {\n    return is_alpha(right) && !is_alpha(left);\n  }\n};\n\nint word_count_reference(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  int wc = std::inner_product(\n      input.cbegin(), input.cend() - 1, \n\n      input.cbegin() + 1,               \n\n      0,                                \n\n      std::plus<int>(),                 \n\n      is_word_start());                 \n\n\n  \n\n  if (is_alpha(input.front())) wc++;\n  \n  return wc;\n}\n\nint word_count(const std::vector<char> &input)\n{\n  \n\n  if (input.empty()) return 0;\n\n  \n\n  \n\n  int wc = oneapi::dpl::transform_reduce(\n           oneapi::dpl::execution::dpcpp_default,\n           input.cbegin(), input.cend() - 1, \n\n           input.cbegin() + 1,               \n\n           0,                                \n\n           std::plus<int>(),                 \n\n           is_word_start());                 \n\n\n  \n\n  if (is_alpha(input.front())) wc++;\n  \n  return wc;\n}\n\n"}}
